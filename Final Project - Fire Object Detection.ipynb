{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52c73e0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62522f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.retinanet import RetinaNet\n",
    "import torch\n",
    "from torchvision.models.detection import RetinaNet\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "import datetime\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "from torchvision.ops import nms\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import VOCDetection\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn, RetinaNet_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1395c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Setup complete  (20 CPUs, 15.7 GB RAM, 407.3/475.7 GB disk)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
     ]
    }
   ],
   "source": [
    "# Use cuda device\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "ultralytics.checks()\n",
    "\n",
    "#@title Select YOLO11 ðŸš€ logger {run: 'auto'}\n",
    "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
    "\n",
    "if logger == 'Comet':\n",
    "  %pip install -q comet_ml\n",
    "  import comet_ml; comet_ml.init()\n",
    "elif logger == 'TensorBoard':\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir ."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "728131fa",
   "metadata": {},
   "source": [
    " Result of Adam:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAA/CAYAAABwznmqAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACsiSURBVHhe7Z1PaBvXFv+//fGz4FniNZVthFsPkTYmIItRaQ3RqmnQRlR1oVq48CqGvFWyshZaiBZUEJhooYWcTb2KMUkhXqgLMzzBQwSXLkxRCxpkbULBAiUYPctqX5FEkRfvt+jc+7szHo1GHsmx4/sBgzX/79xzzj33nHvnvnXz5s3/gcPhcDgcDodzbfg/+g0cDofD4XA4nDcb7gByOBwOh8PhXDO4A8jhcDgcDodzzeAOIIfD4XA4HM41gzuAHA6HMwKSJCGXy+k3cy4puVwOkiTpN3M41x7uAF5BRFHEkydPsLm5CUEQ9LuHkkqlUCgULq1RlCTp3GUzQhRFbG5uQhRF/S7L5HI5FAoFFAoFpFIpzT5Jkui+Z8+eIRqNavZzOBxjiC0qFAqGTrWZ3nHeLKLRKJ49e8bt6AXy1jg+AyNJElZWVnB4eIhkMqnf/caRy+Xg8/no716vh1wuB0VRNMdNClEUkUwm0e12sb6+jkajoT/ElFQqheXlZezu7mJ7e1u/+7USjUaxurqKnZ0dyLKs2TdIzqzURyqVgtfrHfl9CYKAr7/+GvV6Hdlslv7e39+n706SJIRCoZGvTcrDYvTsRkiShHA4rDnWaJsZRA4wwn0J+nd+enqKp0+f0jpjy6bfNwwi39PT0wCAcrmMbDarP2wg7LMdHx9r6oUtM2FUPZAkCYFA4FrYuosilUphdnZ24DvN5XJotVojyQEhl8uhWq2OVMeTgtiPubk5um1U3YPN9zEMs/ZlmG7a0XuCKIpYW1vD999/P/K558XOc+vrlG2f9PuMrm3n3nYZSwQwEAjgxx9/hMvlshVluUocHh4iFoshFouhVqshmUxeWNkVRUE8Hsf9+/dHcjgI2WwWsVjsUhhEFkEQEI1GUavVDBXATM6G1Uc2m0Wn08E//vEPzXnDuHv3LjqdDjVyjUYD+/v7CAQC+kNHZnt7G7FYDLu7u+j1eshkMojH4yM1BOdFkiT4/X5kMhnEYjE0m008ePBgpKjr7u4ufedffPEFrbNoNIpwOIytrS3EYjFUKhWsrq6eqTMjBEHAgwcPUKvVEIvFsLW1hWAwaDlanUql4HK5kEgkEIvF0Ol0sLa2pjmmXC7T576MesB582FlsNlsnrFXrwtJkpBMJg3blWG6aUfvXyd2n3ttbQ2dTgexWAyZTAYej4dGqxuNBu7fv0/rulgsaq5t9952se0AiqIIt9uNX3/9FZ1OB8FgEFCFZXNzUxO2128jv41SAGSfpI63MQoLS0zqzSilSc5j/6zce1SKxSIA0LLncjmkUilNeoN9NlFN4eqfadB+Nh06LGVidi67T/8uCew7Y48R1TSqJEk0TD/ONC1UZwsAvvvuO/2ugXJmhL4+CHt7e1hcXLSsXIIg4IMPPsDe3p5me6VSMXRCJ8Gg+rCDIAgIhUKo1WrU2dzb24PT6RxLme7cuYNms0kdQqP6ILKol+G7d+/C6XTSc2RZxsuXLy053KIowu/3Y39/nzZge3t7cLvdYymXXfS6yZY9Go3i8ePH+OSTT+gxrH4Ns1dm137dsDZrXDI8SQRBwKNHj/DNN9/Qd0n0kLXjg8pF2iVyLKm7zc1NeDweej5hY2MD3W4XkUiEbmOv/eTJEyq/ZLvP58Py8rJhfetlwaqdFkURgUAAX331Ff744w/97qG6aUXvLyN2njsajcLj8dA2QlEU1Go1eL1ew3d+cnKC09NT+tvOvceBbQcwGAyi3+9DURS0Wi0qDI1GA/V6XfMi3G43HA4HDg4OAJ3nnEgk4HK5zjhDKysraLVaiMViePnyJe7cuQOownrz5k3qWe/u7iIcDlNFkSQJHo8HmUwGiUQCx8fHODw8pJEcK/e2w/LyMmZnZxGLxVAulxEKhSAIAgRdLyqTycDv91NjIaohdrI/FotpIn0kelcul3V3/It4PD7wXBI5zGQy6PV6+lPPRE/0vRGn04lwOIyHDx8ik8nA6XRSp20cBAIB1Ot1w97nIDkbBUVR0O/3LSsXKbeiKBqDfPv2bXQ6Hf3hY2dYfZwXvR6KoojV1VVMT09jZmZGf/hICIIAl8uFarVKfz948ADT09OYn5/XH36G+fl5NJtN6pimUin4fD64XC5Dg6rn9PQUJycn9DeRJSvnTprPPvsMuVyO6r3H49E4FNPT04jH49jZ2TmjX8Ps1bBrvy6i0Sj+/PNPao8qlQqi0eilqA8zHA4H5ufnsbOzg4WFBbRaLZTLZWp3zMq1vb2NcrlM2yOSdVhfX0ez2dTd6S8Z7XQ6mJ2dBQyi87VajUbnif0/PDzURBHZ1LlZG2CGoigDo38YopsffvihLb1/Xdi1VzMzM+h2u5phOMvLy3A6nXC73frDsbS0hHa7DUVRbN97HNh2ANlG++DgQNPbLhaLcDgc9HcwGES73YYsyxBFES6XC0+ePAGY1Jrec2adtmq1ShsCRVGQyWTocZVKBaenp/TcQCBAhZU4o+Rcq/e2SjweR7fbxfPnz+m24+NjbGxsAAAODg7gcDjou+n3+zTKRXoMxLBEIhF0u13DKJhVzlMO0SB68t1336Hb7VKH6fT0FDs7O1AUBYqioNlsjk1QiTIcHR3pdwFD5EyPUX2AMbRWn3lmZgb9fh+iKGJxcRGPHj3Cq1ev8Ntvv+kPHTtW6sMM1mFl//QOx+bmJtLpNEqlEg4PDy2/G6idM3Jdo85TLpdDPp9HvV5HuVymDRyYzsigMV8kiuL1erGzs0P1xwxFUdBut2knEaoskPFKhEGRk0mTyWRoQzFIf4rFImRZ1uy3Yq/Mrm1FFiaFLMvI5/P0N2sLLzv7+/vo9Xro9Xo0MkMYVq5sNotms4nV1VUsLi5CluWBjhUAtFot+n8gEECpVKL1qW9HrTCoDWAzCuRv1KiskW6+8847dL+Z3k+KcZTLznOHQiE8e/YM4XAYjx8/1vgiIhORDQaDZzJKsHlvO/xf/YZRENW0HBv+jEajCAaD1Elot9tYWlqCLMsIBAIab/fGjRtIp9Oaax4fH2t+k+Ohjplix+vkDAaiE1qtFvx+P0RRRLvdhtfrpQ6EKIqW7m2Gz+dDoVAADAaaA9BEsmRZpiHeYDCI9957T2M8oDq6ADA7O4tOp2NqLMzY2NjA119/Ta8/ygB3ffTkInG73XA6nfrNgAU5g4X6ILRarZGUq9VqYWlpCS9evMDvv/8Oh8Nh2IufBHbqw2xwuCiKmJqawurqKpUPQU0Ls/pmBuu4iWrUOpVK0Y7LysoKyuUyPS6nDlq3AokqJBIJNBoNSJKEfr+PdrutP/QMT548QTKZpLJAxowSWWDfi6AO0M7lcgMd0XEiGUz6Yd9Jr9dDpVKhv8kzRaPRofbK7NpmsjBpyDvWT3q46lgpF5HFQWOaWYhNIh3hlZUVTX2ybdswzNoAu3I+SDdJp9iO3tvBbrnsPPfc3Bw+/fRTPHz4kLZNYLIPpLMLxlbOzMzQAIWde9vFVgQwGAzi7bffxr1791AoFJDP5zE3N6dJz1WrVXi9Xnz00UdwuVwaA0cGvpNQ9Sjh6lQqRVO8JO3BKuDR0RGmp6eRTqepIrBRNTv3hm7SwSjnQTXcJK2nD+HbrfgGM+h0a2sLkUjEck9/ampKkwI0c8rGTbvdRrfb1W8GLMqZ1fqYnZ21/I5JBIU1zv1+n+634pDYwaw+9GNJCN1uF+122zTqQ951uVymDQNJC5/H4SQRJzBRVjZyPyy6y3J0dIRer4dvv/2W1uH8/LzlThExtkQWfv3114HOY0PNDFwE0WgUkUhEM3GGdPqsYGavhl3bTBYmDZmAQ+zd1taWodxeNYaVS1DTeb/88otmiI8RoijC4/Fo7BJblzHdJKthmLUBdiJlZrr5888/29J7u5y3XHbt1cnJCXq9Hs2MgckcGdkcNjpv997jwJYDOD8/r2l4Y+pYPI/HQ8PVxOF7//33Ua/XNWmKfr9PPePzQBo76FI9JJrBKpF+LJzde5+XSqUCp9M5cDbqwcEBFhYWTA2GVRqNhmVjSwSTjFUEk47Wp1InAVEGfUoMFuXMCqMql/64paUlOBwO3Lp1C2B6eJNgWH00Gg1MTU3RdDCReRJ5JmOF9H/b29vU8QkGg9RARiIROsaSEFW/yzVsELkkSVhYWKBjCqvVKnw+H5VhMnic7fyRtIg+BUuOYXvMfr//TGSSGHwzPYmqnxT697//bVhXJIqsv/akYCO6kiRpshdmWLFXZtc2k4WLgDjvgjrLf2pqSn/IlcSsXMS+FwoFlEolzfh0FuIokmE/RDcHHU9otVoD07ws+jYgmUyekQOrzuUw3bSi95PCTrmsPLegTuTRO5WKoqDb7SKqjv/U22E9UXXSyCi2cpKc2wEUBAFer/eM8SQPThomRVFQr9dx+/ZtWmiogrm+vg6Xy6Xx2o3GEhlRLBbhdDqRz+dRKBTQ7/dpBLChjpFhxygVmNlQdu9tB0VRkMvl4Pf7NfcmAiDLMp4+fYpIJHLmuYkQFgoFLC8v07QnaUTZsQaFQgHpdBq1Wk3zvTqynUTUWIFOJpPodDr0nfr9fk1vb9JUq1WatidYlTMriKIIh8MxknLNzs6iWq1ieXkZ7777LgDg448/NhzHMSqkPlZWVmi0mp3xZ1YfiqJgZ2eHykk+n0eH+VzNMLLZLCqVCo2qjvKNRL2ckYlBxNhub29jd3eX6t8o3yYk+uHxeKislkoly84KG+1aXV1FLpejz8XqT6FQwJdffomnT59avrYdZFlGs9mk7zsUCuHVq1f6wwwZZq/sXHvS7O3tYWFhgcro0dERdUhGsWfsrNeLsNPDMCtXKpVCMBik4/6eP3+ObreLZDJJO4+kLERv9RP9arUa0uk0rWt9J4xks4htMHpnBYM2wAx9fczNzSGfz9N7D9NNO3r/OrHz3EQ3odZFXh3HR+ywvj6+/PJLzTdu7dx7HIzlQ9CXDcHgY71kG1s5nMvFpOuIjK2weu1oNIrPP/8cGxsbpgopnfND0JyricQ/BH2lyF2iD0FzhiO+hg9BX1fOHQG8zBiNXRPViR/6tB7n8tBoNCDLMvx+/9CxG6OSUj+pMsrsalmW0W63Nam3RCIx9mfjcDgcDueieSMdQEVRUCqVNCnge/fuoVgs8l7gJUeWZZRKJTqmYhyIogiv13uudPbGxoYm9Xbr1i3DaCBJl+jHiHA4HA5nOGTMcTqdPvPpJs5keCNTwBwOh8PhcDicwbyREUAOh8PhcDgczmC4A8jhcDgcDodzzeAOIIfD4XA4HM41gzuAHA6Hw+FwONcM7gByOBzOCEiSdGYFE87lJZfLma4Yw+FcV7gDeAUhXxfXfx3eKmS1hMtqFCVJOnfZjBBFEZubm6ZLKw2DLD1WMFiJgKzoUbC4/iSHw/kLduUWI6faTO84bxbkMzDcjl4cY3EASQNopMBvIqxRKhQKmuW7OPaIRqMIh8N0GSWWQXI2rD7IcoQPHjwY2akkyyO1Wi3EYjEkEgl4vd4zzvPx8TESiYTl9SehcxwHPfsgJEk6c6zRNjPYxneU82DwzvUGmzvFHCuQdYrL5bJ+F8Cs8Xp4eKjfdSXRL0d4Ht2Dqn+TcojNAgz6pc30z2BH72VZxhdffIFMJkOXdb0o7Dy3vk717RPr2BYMlvUjEJuqb1smyVgcwEAggB9//BEul2tkQb6qHB4e0kWna7UaksnkhZVdURTE43HN+pGjQIzuZfsotqAuql6r1QydKDM5G1Yf2WwWnU6HLtJulbt372rW2CXrTAcCAf2hI7O9vY1YLIbd3V30ej1kMhnE43HDD02PG0mS4Pf7kclkEIvF0Gw2R3aQd3d3DRdeJ0781tYWYrEYKpUKVldXz9QZh3NdKZfLVHeazeYZe/W6kCQJyWTSsF0RBAEPHjxArVZDLBbD1tYWgsEgdViuqt7bfe61tTV0Oh3EYjFkMhl4PB7qGIuiiM8//xxPnz5FTA0gADjTDkmSBLfbjf/+97+a7ZPGtgMoiiLcbjd+/fVXdDodBINBgPGK2R6CfpuZ50z2Sep4GyPPXB9B0XvO+ihFgemxmN17VIrFIgDQspPeGRthYZ9tWC9Kv5/tMQxLmZidy+7Tv0sC+87YY0Q1jSpJEu3NDOrJnJe7d+8CzELnLIPkzAh9fRD29vawuLhoWbEFQcAHH3yAvb09zfZKpWLohE6CQfVhB0EQEAqFUKvVqLO5t7cHp9M5ljLduXMHzWaTOoSD6uO6oddNVn+j0SgeP36MTz75hB7D6tcwe2V27dcNa7PGJcOTRBAEPHr0CN988w19l0bRmUHlIu0SOZbU3ebmJjweDz2fsLGxgW63i0gkQrcNis6T7T6fD8vLy4b1rZcFq3ZaFEUEAgF89dVX+OOPP/S7cffuXTidTqrPsizj5cuXtDN8VfXeznNHo1F4PB7aRiiKglqtBq/XC0EQ6HsnDnWj0UCn09FcQxRFhMNh/PTTT+j3+5p9k8a2AxgMBtHv96EoClqtFhWGRqOBer1OXwTUNXodDgcODg4AneecSCTgcrnOOEMrKys0/fby5UvcuXMHUF/azZs3aS9qd3cX4XCYKookSfB4PMhkMkgkEjg+Psbh4SGN5Fi5tx2Wl5cxOzuLmJreCIVCVCDYXlQmk4Hf76fGQhRFJJNJuj8Wi2kifcNSJvF4fOC5JHI4KMSeUtfLTSQShj0hp9OJcDiMhw8fIpPJwOl0UqdtHAQCAdTrdcPe5yA5GwVFUdDv9y0pNtS6gHoea5Bv3759RoknwbD6OC96PRRFEaurq5iensbMzIz+8JEQBAEulwvVapX+fvDgAaanpzE/P68//Frx2WefIZfLaSIFrEMxPT2NeDyOnZ2dM/o1zF4Nu/brIhqN4s8//6T2qFKpIDrGZR4nhcPhwPz8PHZ2drCwsIBWq4VyuUztjlm5tre3US6XaXtEoj3r6+toNpu6O/1/p2B2dhYwiM7XajUanSf2//DwUBNFTCaT9HpmbYAZiqIMjP4BwPz8PJrNJu00plIp+Hw+uFwufPjhh1dS7+3aq5mZGXS7XfpOJEnC8vIynE4n3G43bXNI/UmShIWFBWp7odZXs9nEv/71L+bKF4NtB5BttA8ODuB2u2kDVSwW4XA46O9gMIh2uw1ZliGKIlwuF548eQIwqTXWYYSa2iNOW7VahcvlgiAIUBQFmUyGHlepVHB6ekrPDQQCVFiJM0rOtXpvq8TjcXS7XTx//pxuOz4+xsbGBgDg4OAADoeDvpt+v0+jXKTHQAxLJBJBt9s1jIJZ5TzlEEURfr8f+/v71AB899136Ha71GE6PT3Fzs4OFEWBoihoNpuWlMQKRBGPjo70u4AhcqbHqD7AGFqrzzwzM4N+vw9RFLG4uIhHjx7h1atX+O233/SHjh0r9WEG67Cyf3qHY3NzE+l0GqVSCYeHh5bfDdTOGbmuUecpl8shn8+jXq+jXC7TBu66kslkaEMxSH+KxSJkWdbst2KvzK5tRRYmhSzLyOfz9DdrCy87+/v76PV66PV6NCpEGFaubDaLZrOJ1dVVLC4uGo5pZmm1WvT/QCCAUqlE61PfjlphUBtglBUbNSpLIpxerxc7OztwOBx455136P7XoffjKJed5w6FQnj27BnC4TAeP35MfZFGo4H79++jXq8jn8/TAAo7XMbtdlPdvmhsOYCimpYj3izxdkkDpSgK2u02lpaWAFWwWU/7xo0bSKfTtMJWVlaYq/8FOR7qmCm2N8NWun4B6VarBY/HA1EUIQgCvF4vdSCs3tsMn89Hz3W5XFhfX9coOBvJkmUZ//znP6EoCmZmZvDee+8hn8/T85eXl+l5s7Oz6HQ6psbCDOJ0kuuPYuRPT09xcnKi33whuN1uOJ1O/WbAgpzBQn0QWq3WSIrdarWwtLSEFy9e4Pfff4fD4TDsxU8CO/VBIgX6v2113OfU1BRWV1exv7+PWCyG58+fmzrgesjg/BgTxWadQDZyn81mMTs7q2nkriOk4SR/Pp9Ps7/X66FSqdDfyWQS2WzWkr0yu/YwWZgkgi51fe/ePUxNTekPu3JYKdeTJ08gCAJevHhhOKaZhdgk0hFmO1f6tm0YZm0Aq7fkb5SJaz6fD6FQCIlEAvfv38ff/vY39Pt92il+XXpvt1x2nntubg6ffvopHj58iHg8jrfeegtQO2pETkg2sFarIZ1OQ5IkCOqY9x9++IE6+xeNLQcwGAzi7bffxr1791AoFJDP5zE3N6dJz1WrVXi9Xnz00UdwuVwaA0cGvrOVZjVcnUqlaIo3pjZCbFrz6OgI09PTSKfTtKfGRtXs3Bu6SQejnAdmxih7bxLCtyp0gyA9jpg6SDcSiVh2AqempjQpQDOnbNy02210u139ZsCinFmtj1EUm0RQWOPMjtFot9v0/0lgVh8nJyc4PT1ljv6LbreLdrttGvUh77pcLlMngKSFz+NwkogTmCgrG7kfFt29DkSjUUQiEc3EmVFmtprZq2HXNpOFSbO2tgYA1N5tbW0Zyu1VY1i5BDWV+Msvv2iG+BghiiI8Ho/GLrF1GRvRmTFrA+xEyo6OjtDr9fDtt99S+zo/P49Op4Off/75ter9ectl116dnJyg1+vRzBiYzFG73abjJkmEL5vN0iFhH330EW7cuEGdfdKuraysWB63aRdbDuD8/Lym4Y2pY/FI5A1qahYA3n//fdTrdU2aot/vIx6Pa645CqSxg5r2I70kQR3kziqRfiyc3Xufl0qlAqfTeWYWEOHg4AALCwumBsMqjUbDsrEljTgZqwgmHa1PpU4Cooj6lBgsypkVRlFsqAaPZWlpCQ6HA7du3QKYgb2TYFh9NBoNTE1N0SgokXkSeTaL+jTUIRHBYJAayEgkQsdYEqLq5wuGGSP9uJZqtQqfz0dlmBhBtvN3HWEjupIknYkADsKKvTK7tpksXAQko0EiHvpI2VXFrFzEvhcKBZRKJc34dBbiKJJhP0Q3Bx1PaLVaA9O8LPo2wE6kjOgvkUMyTIVk6V6n3tspl5XnFtRInt6pVBQF3W6Xjv/U22GoHXlST4Kajex0Onj69Cm++OIL+rxkrsLu7q5pEGOcnNsBJAVhU7RghIRNA9frddy+fVsz8LHRaGB9fR0ul0vjtRuNJTKiWCzC6XTSMHe/36cRwIY6RoYNoxeY2VB2720HRVGQy+Xg9/s19ybCJ8synj59ikgkcua5iRAW1LQxSXuSGWCibvZXOp1GrVajhp6kidLpNI2osQKdTCbR6XToO/X7/Zre3qSpVqvw+/0aw2dVzqwgiiIcDsdIBml2dhbVahXLy8t49913AQAff/zxmZnB54HUx8rKCo1WszP+zOpDURTs7OxQOcnn8+gwn6sZRjabRaVSoVFVr9c7MG2uRy9n+nEt29vb2N3dpfoXDoeRy+VeW5rjMiDLMprNJn3foVAIr1690h9myDB7Zefak2Zvbw8LCwtURo+OjqhDMoo9Y2e9XoSdHoZZuVKpFILBIB339/z5c3S7XSSTSdp5JGUhequf6EdShaSu9Z0wks0itsHonRUM2gAz9PUxNzeHfD5P703aLo/HQ69dKpXota+q3tt5bqKbUOsir44hJHZ4e3tbY2dJfbOTdl4nb928efN/+o1XHUEQ8PXXX2N/f58KJ9nGVg7ncjHpOsrlcmi1WpavHY1G8fnnn2NjY8PUGEiShFAoZNmB4lxtJElCIBC4NEacY04ul0O1WrXkBHFeP6IoYm1tDd9//72lCB7n/Jw7AniZMRq7Jooibty4cSatx7k8NBoNyLIMv98/dOzGqJBPqowyu1qWZbTbbU3qLZFIjP3ZOBwOh8O5aN5IB1BRFJRKJU0K+N69eygWi7wXeMmRZRmlUomOqRgHoijC6/WeK529sbGhSb3dunXLMBpI0iX6MSIcDofDGQ4ZczzqrGfO+XkjU8AcDofD4XA4nMG8kRFADofD4XA4HM5guAPI4XA4HA6Hc83gDiCHw+FwOBzONYM7gBwOh8PhcDjXDO4AcjgczghIkkQ/vMu5/ORyubGsrMThvGlwB/AKQr72rv86vFXI2qCX1ShKknTushkhiiI2NzdNl1YaBrvWpH4lArKiR8Hi+pMcDucv2HWKjZxqM73jvFmQz8BwO3pxjMUBJA2gkQK/ibBGqVAoaJbv4tgjGo0iHA7TZZRYBsnZsPogyxE+ePBgZKeSLI/UarXoeo1er/eM83x8fIxEImF5/UnoHMdBzz4ISZLOHGu0zQy28R3lPKPnZutFvxxVwWApKw4HzDrF5XJZvwtg1ng9PDzU77qSsMutnUf3CLlcbmIOsVmAQa/b+mew0xmWZRlffPEFMpkMXdb1orDz3Po61bdPYJxbo30E0o7p25ZJMhYHMBAI4Mcff4TL5RpZkK8qh4eHdBHnWq2GZDJ5YWVXFAXxePzcC0YTo3vZPootqIuq12o1QyfKTM6G1Uc2m0Wn06GLtFvl7t27mjV2yTrTgUBAf+jIbG9vIxaLYXd3F71eD5lMBvF43PBD0+NGkiT4/X5kMhnEYjE0m03LDjJ5bv0i5q1Wix7T7XbptWOx2LlllcN5EymXy1Q3ms3mGXv1upAkCclk0lBXBUHAgwcPUKvVEIvFsLW1hWAwSB0W0nnf2tpCLBZDpVLB6urqpSiXGXafe21tDZ1OB7FYDJlMBh6PR+MYp1IpRKNR/Oc//9GcxyJJEtxuN/773//qd00U2w6gKIpwu9349ddf0el0EAwGAcYrZl+EfpuZ50z2Sep4GyPPXB+J0HvO+shQgemxmN17VIrFIgDQspPeGRthYZ9tWC9Kv5/tiQ1LmZidy+7Tv0sC+87YY0Q1jSpJEg3TG/UQ7XD37l2AWeicZZCcGaGvD8Le3h4WFxctK7YgCPjggw+wt7en2V6pVAyd0EkwqD7sIAgCQqEQarUadTb39vbgdDrPVSZRFOFwOOh75xij101Wf6PRKB4/foxPPvmEHsPq1zB7ZXbt1w1rs8Ylw5NEEAQ8evQI33zzDX2XRtGZQeUi7RI5ltTd5uYmPB4PPZ+wsbGBbreLSCRCtw2KzpPtPp8Py8vLhvWtlwWrdloURQQCAXz11Vf4448/9Ltx9+5dOJ1OqueyLOPly5e0M3znzh00m03aeR9khy8bdp47Go3C4/HQNkJRFNRqNXi9XghqQOPvf/877t+/j36/rz8dUN97OBzGTz/9NPCYSWHbAQwGg+j3+1AUBa1WiwpDo9FAvV6nLwLqGr0OhwMHBweAznNOJBJwuVxnnKGVlRWafnv58iXu3LkDqC/t5s2btBe1u7uLcDhMFUWSJHg8HmQyGRqhODw8pJEcK/e2w/LyMmZnZxFT0xuhUAiCIEDQ9aIymQz8fj81FqIoIplM0v366MmwlEk8Hh94LokcDgqxp9T1chOJhGFPyOl0IhwO4+HDh8hkMnA6ndRpGweBQAD1et2w9zlIzkZBURT0+31Lig21LqCexxrk27dvo9Pp6A8fO8Pq47zo9VAURayurmJ6ehozMzP6w4dy584dvHjx4kIil1eZzz77DLlcThMpYB2K6elpxONx7OzsnNGvYfZq2LVfF9FoFH/++Se1R5VKBdExLvM4KRwOB+bn57Gzs4OFhQW0Wi2Uy2Vqd8zKtb29jXK5TNsjknVYX19Hs9nU3emvtrLT6WB2dhYwiM7XajUanSf2//DwUBNFTCaT9HpmbYAZiqIMjP4BwPz8PJrNJtXzVCoFn88Hl8uFDz/8EC6XC9VqFWCihdPT05ifn9dd6fIgCIKt556ZmUG326XvRJIkLC8vw+l0wu12Q5ZlfPXVV/rTNMTjcTSbTfzrX//S75o4th1AttE+ODiA2+2mDVSxWITD4aC/g8Eg2u02ZFmGKIpwuVx48uQJwKTWWIcRamqPOG3VahUulwuCIEBRFGQyGXpcpVLB6ekpPTcQCFBhJc4oOdfqva0Sj8fR7Xbx/Plzuu34+BgbGxsAgIODAzgcDvpu+v0+jXKRHgMxLJFIBN1u1zAKZpXzlEMURfj9fuzv71MD8N1336Hb7VKH6fT0FDs7O1AUBYqioNlsWlISKxBFPDo60u8ChsiZHqP6AGNorT7zzMwM+v0+RFHE4uIiHj16hFevXuG3337THzp2rNSHGazDyv7pHY7NzU2k02mUSiUcHh5afjeEaDQKt9t9JvrndDqRTqfPREeuM5lMhjYUg/SnWCxClmXNfiv2yuzaVmRhUsiyjHw+T3+ztvCys7+/j16vh16vd0a+h5Urm82i2WxidXUVi4uLhmOaWdjhE4FAAKVSidanvh21wqA2wCgrNqp+kgin1+vFzs4OHA4H3nnnHbo/l8shn8+jXq+jXC5Tx3aSjKNcdp47FArh2bNnCIfDePz4scYXMYPYT6LbF40tB1BU03IkkqDoIiyKoqDdbmNpaQlQBZv1tG/cuEEbiUKhgJWVFebqf0GOhzr2iO3NsJWuX0C61WrB4/FAFEUIggCv10sdCKv3NsPn89FzXS4X1tfXNQrORrJkWcY///lPKIqCmZkZvPfee8jn8/T85eVlet7s7Cw6nY6psTCDOJ3k+qMY+dPTU5ycnOg3XwhutxtOp1O/GbAgZ7BQH4RWqzWSYrdaLSwtLeHFixf4/fff4XA4DHvxk8BOfZBIgf5vWx33OTU1hdXVVezv7yMWi+H58+emDvgg7ty5g3a7TRsrMJFmcs9isYgvv/xyJGP8JkIaTvLn8/k0+3u9HiqVCv2dTCaRzWYt2Suzaw+ThUki6FLX9+7dw9TUlP6wK4eVcj158gSCIODFixeGY5pZiE0iHeGVlRV6bX3bNgyzNoBMqmH/Rpm45vP5EAqFkEgkcP/+ffztb39Dv9+nnWI2Y5fNZjE7O6txbieF3XLZee65uTl8+umnePjwIeLxON566y1A7aiZIagp4h9++EFjPy8SWw5gMBjE22+/jXv37qFQKCCfz2Nubk6TnqtWq/B6vfjoo4/gcrk0Bo4MfGcrzWq4OpVK0RRvTE17sGnNo6MjTE9PI51O054aG1Wzc2/oJh2Mch6YGaPsvUkI36rQDaLRaOD+/fuIqYN0I5GIZSdwampKkwI0c8rGTbvdRrfb1W8GLMqZ1foYRbFJBIU1zuwYjXa7Tf+fBGb1cXJygtPTU+bov+h2u2i326ZRH/Kuy+UydQJIWngUh1M//mUQlUrFcMjBdSIajSISiWB3d5fK6SgzW83s1bBrm8nCpFlbWwMAau+2trYM5faqMaxcgppK/OWXXzRDfIwQRREej0djl9i6jI3ozJi1AXYiZUdHR+j1evj222+pfZ2fn0en08HPP/+MTqejydgNy+qMk/OWq6Fmhc773CcnJ+j1ejQzBiZzNKx9EEURN27coM4+addWVlYsj9u0iy0HcH5+XtPwxtSxeCTyBtX4A8D777+Per2uSVP0+33E43HNNUeBNHZQ036klySog9xZJdKPhbN77/NSqVTgdDoHzkY9ODjAwsKCqcGwSqPRsGxsSdqIjFUEk47Wp1InAVFEfUoMFuXMCqMoNlSDx7K0tASHw4Fbt24BFnp4dhhWH41GA1NTU5pJV6FQiEaezaI+DXVIRDAYpAYyEonQMZaEqPrpgkHGSD94ehDxePzMta8jbERXkqQzEcBBWLFXZtc2k4WLgGQ0SMRDHym7qpiVi9j3QqGAUqmkGZ/OQhxFMuyH6Oag4wmtVmtgmpdF3wbYiZSRtpzIIRmmQrJ01WoVPp+Ptl1k0ggb9JkUdspl5bkFNeKrdyoVRUG320VUHf+pt8NmyOpnb8jzkrkKu7u7pkGMcXJuB1BQ06psihaMkLBp4Hq9jtu3b9MUHlTBXF9fh8vl0njtVidiFItFOJ1OGubu9/s0ytBQx8iwYfQCMxvK7r3toCgKcrkc/H6/5t5E+GRZxtOnTxGJRM48NxHCgpo2JmlPMgNM1M3+SqfTqNVq1NCTNFE6naYRNVagk8kkOp0Ofad+v1/T25s01WoVfr9fY/isypkVRHW26igGaXZ2FtVqFcvLy3j33XcBAB9//PHQqJcVSH2srKzQaDU748+sPhRFwc7ODpWTfD6PDvO5mmFks1lUKhUaVfV6vQPT5kZIkoSFhQXD96BPRwK4MIN2WZFlGc1mk77vUCiEV69e6Q8zZJi9snPtSbO3t4eFhQUqo0dHR9QhGcWesbNeL8JOD8OsXKlUCsFgkI77e/78ObrdLpLJJO08krIQvdVP9KvVapqUv74TRrJZxDYYvbOCQRtghr4+5ubmkM/n6b1J2+XxeOi1S6USvfb29jZ2d3dpuxsOh5HL5S59x8/OcxPdhFoXeXUMIbHDehnWy/jr5q2bN2/+T7/xqiMIAr7++mvs7+9T4STb2MrhXC4mXUe5XA6tVsvytaPRKD7//HNsbGyYGgNJkhAKhUZyoDhXF0mSEAgENDMvOZeXXC6HarVqyQnivH5EUcTa2hq+//57SxE8zvk5dwTwMmM0do3k2/VpPc7lodFoQJZl+P3+oWM3RoV8UmWU2dWyLKPdbmtSb4lEYuzPxuFwOBzORfNGOoCKoqBUKmlSwPfu3UOxWOS9wEuOLMsolUp0TMU4EEURXq/3XOnsjY0NTert1q1bhtFAki7RjxHhcDgcznDImONRZz1zzs8bmQLmcDgcDofD4QzmjYwAcjgcDofD4XAGwx1ADofD4XA4nGsGdwA5HA6Hw+FwrhncAeRwOBwOh8O5ZnAHkMPhcEZAkqRL8yFXznByudxYVlbicN40/h96YdTo2fxCWwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "27dadea7",
   "metadata": {},
   "source": [
    "Result of AdamW:\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "dc19af56",
   "metadata": {},
   "source": [
    "Result of SGD:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ac250",
   "metadata": {},
   "source": [
    "The best mAP for Retinanet is 0.613"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8bc959",
   "metadata": {},
   "source": [
    "# Different Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d5200",
   "metadata": {},
   "source": [
    "## YOLOv11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1994a2",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29a6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train339, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train339, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lancemontojo/general/9afc3ecf87f94da696a500de73e8a426\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in 'c:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 13.96.9 MB/s, size: 33.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\train\\labels.cache... 544 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 544/544 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 13.24.4 MB/s, size: 20.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\valid\\labels.cache... 231 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train339\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train339\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      3.94G      1.596      6.416       2.17         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.156      0.248      0.107     0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      4.01G      1.744      2.816      2.338         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.043     0.0794     0.0342     0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      4.02G       1.98      2.575      2.551         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264     0.0246      0.228     0.0132    0.00393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      4.02G      2.019      2.542      2.544         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264     0.0485     0.0255      0.012    0.00396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      4.01G      1.921      2.286      2.449         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.238      0.238      0.125     0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      4.02G      1.741      2.067      2.267         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.194      0.267      0.177      0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      4.01G      1.634      1.998      2.151         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.382      0.432      0.372      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      4.02G       1.59      1.786      2.078         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.485       0.45      0.445       0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      4.01G      1.574      1.683      2.055         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.571      0.497      0.519      0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      4.02G      1.471      1.608       1.96         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.55      0.487      0.531      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs\\detect\\train339\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\train339\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\train339\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.55      0.484      0.531      0.278\n",
      "               Class B        128        157      0.505      0.408      0.442      0.221\n",
      "               Class F        105        107      0.594      0.561       0.62      0.334\n",
      "Speed: 0.4ms preprocess, 4.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train339\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : dry_orca_355\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lancemontojo/general/9afc3ecf87f94da696a500de73e8a426\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [11]               : (0.00018170299999999996, 0.0013238268039215688)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [11]               : (0.00018170299999999996, 0.0013238268039215688)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [11]               : (0.00018170299999999996, 0.0013238268039215688)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [11]     : (0.012, 0.5311832177138651)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [11]  : (0.00393, 0.27762278153311176)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [11] : (0.02457, 0.57077)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [11]    : (0.02548, 0.49698)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 21.551\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 9428566\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 5.091\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [10]       : (1.47063, 2.0189)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [10]       : (1.60788, 6.41583)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [10]       : (1.95982, 2.551)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [10]         : (1.6973, 3.42096)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [10]         : (1.84249, 127.6148)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [10]         : (2.08793, 12.04756)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from                 : ultralytics\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cutmix          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : yolo11s.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs\\detect\\train339\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 17\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (18.28 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 10 file(s), remaining 17.96 MB/22.25 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 14.94 MB/18.28 MB, Throughput 205.76 KB/s, ETA ~75s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 12.05 MB/18.28 MB, Throughput 197.12 KB/s, ETA ~63s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 9.13 MB/18.28 MB, Throughput 199.25 KB/s, ETA ~47s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 6.17 MB/18.28 MB, Throughput 201.18 KB/s, ETA ~32s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 3.27 MB/18.28 MB, Throughput 197.99 KB/s, ETA ~17s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 562.91 KB/18.28 MB, Throughput 185.40 KB/s, ETA ~4s\n"
     ]
    }
   ],
   "source": [
    "model_YOLO1 = YOLO('yolo11s.pt')  \n",
    "results = model_YOLO1.train(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml', \n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff91c0",
   "metadata": {},
   "source": [
    "### Increase epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69275a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.142 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train352\\weights\\best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train353, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train353, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lancemontojo/general/86cd9ec561a243fb831faf2c3129b564\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in 'c:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 35.09.6 MB/s, size: 33.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\train\\labels.cache... 544 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 544/544 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 29.716.2 MB/s, size: 20.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\valid\\labels.cache... 231 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train353\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train353\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.94G      1.064       1.09       1.45         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:12<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.785      0.716      0.814      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      4.01G     0.9863     0.9641      1.379         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.691      0.744      0.783      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      4.02G      1.159      1.055      1.492         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.716      0.689      0.775      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      4.02G      1.206      1.149      1.541         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.718      0.679      0.744      0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      4.01G      1.175      1.132      1.512         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.731      0.599      0.715      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      4.02G      1.212      1.149      1.555         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.745      0.633      0.718      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      4.01G      1.216      1.222      1.567         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.638      0.548      0.569       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      4.02G      1.201      1.166      1.538         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.668      0.669      0.711      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      4.01G      1.146        1.1      1.498         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.706      0.669       0.74      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      4.02G      1.176      1.142      1.522         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.719      0.578      0.676      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      4.01G      1.232       1.17      1.563         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.736      0.619      0.699        0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      4.02G      1.252      1.153      1.579         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.77      0.711      0.764      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      4.01G      1.239       1.18      1.578         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.677      0.715      0.729      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      4.02G      1.253      1.226      1.574         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.744      0.614      0.735       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      4.01G      1.233      1.158      1.561         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.715      0.632      0.747       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      4.02G      1.213      1.155      1.561         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.708      0.646      0.688      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      4.01G      1.188      1.134      1.552         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.756      0.685      0.788      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      4.02G      1.195      1.167      1.524         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.718      0.638      0.714       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      4.01G      1.181      1.104      1.542         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.721       0.71      0.737      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      4.02G      1.164      1.083      1.512         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.779      0.727      0.798      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      4.01G      1.178      1.124      1.523         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.719      0.688      0.747      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      4.02G       1.13      1.082      1.475         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.779      0.668      0.769      0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      4.01G      1.189      1.118      1.523         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.804      0.727      0.793      0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      4.02G      1.164      1.101      1.516         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.719      0.652      0.731      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      4.01G      1.153      1.085      1.489         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.611      0.675      0.658      0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      4.02G      1.107       1.04      1.455         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.747      0.659      0.723      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      4.01G      1.147      1.102      1.509         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.76      0.712      0.754      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      4.02G      1.171      1.094      1.503         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264        0.8      0.706      0.799      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      4.01G      1.104      1.006      1.448         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.787      0.668       0.78      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      4.02G      1.121      1.024      1.482         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.758      0.727      0.789      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      4.01G       1.12       1.01      1.449         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.785      0.683      0.792      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      4.05G      1.089      1.024      1.455         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.801      0.727      0.837      0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      4.01G      1.128      1.033      1.481         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.769      0.659      0.765      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      4.02G      1.106      0.993      1.465         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.85       0.75      0.856      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      4.01G       1.11       1.03      1.466         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.869      0.708      0.843      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      4.02G      1.122      1.003      1.504         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.791      0.762      0.841      0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      4.01G      1.123      0.997      1.469         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.782      0.805      0.865      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      4.02G      1.124     0.9812      1.485         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.785       0.77      0.829      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      4.01G      1.071     0.9466      1.442         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.743      0.678      0.775       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      4.02G      1.093     0.9637      1.469         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.774      0.719      0.807      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      4.01G      1.097     0.9689      1.449         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.808      0.744      0.825      0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      4.02G      1.068     0.9717      1.452         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.831       0.67      0.796      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      4.01G       1.05     0.9649      1.429         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.776      0.769      0.853       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      4.02G      1.064     0.9341      1.423         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.789      0.737       0.84      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      4.01G      1.074     0.9297      1.427         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.811      0.736      0.825      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      4.04G      1.062     0.9095      1.429         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.845      0.746      0.841      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      4.01G      1.097     0.9593      1.453         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.842      0.732       0.85      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      4.02G      1.052     0.9109      1.425         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.799      0.776      0.858      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      4.01G       1.06     0.9568      1.452         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.837       0.72       0.85       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      4.02G      1.013     0.9336      1.418         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.842      0.735      0.856      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      4.01G       1.02     0.8945      1.411         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.778      0.771      0.827      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      4.02G      1.028     0.8805      1.438         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.725       0.69      0.794      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      4.01G      1.039     0.9147      1.409         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.869      0.746      0.845      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      4.02G      1.001      0.868      1.391         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.889      0.772      0.881      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      4.01G     0.9958     0.8939      1.377         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.787      0.792      0.849      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      4.02G     0.9913      0.841      1.373         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.868      0.745      0.841      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      4.01G      1.013      0.887      1.382         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.813      0.834      0.872      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      4.02G     0.9604      0.808      1.372         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.876      0.783      0.887      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      4.01G     0.9656     0.8439      1.371         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.834      0.774      0.871      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      4.02G     0.9854     0.8415      1.381         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.851        0.8      0.884      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      4.01G     0.9619     0.8312      1.367         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.85      0.749      0.835      0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      4.02G      0.977     0.8497       1.39         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.83      0.792      0.881      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      4.01G     0.9714     0.8567      1.389         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.784      0.778       0.84      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      4.02G     0.9299      0.779       1.34         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.894      0.728      0.869      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      4.01G     0.9558     0.7666      1.343         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.893      0.809        0.9      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      4.02G     0.9755     0.8135      1.367         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.909      0.821      0.906      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      4.01G     0.9237     0.7563      1.328         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.898      0.812      0.906      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      4.02G     0.9667     0.7808      1.357         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.887      0.812      0.912      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      4.01G     0.9845     0.8058      1.366         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.847      0.771      0.877      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      4.02G     0.9276     0.7449      1.314         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.862      0.797      0.889       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      4.01G     0.9563     0.7853      1.356         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.879      0.781      0.884      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      4.02G       0.93     0.7671      1.334         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.89      0.791      0.905      0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      4.01G     0.9196     0.7891      1.336         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.862      0.808      0.896       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      4.02G     0.9389      0.781      1.341         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.85      0.814      0.898      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      4.01G     0.8931     0.7248      1.309         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.883      0.786      0.896      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      4.02G     0.8894     0.7404      1.322         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.874        0.8      0.892      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      4.01G     0.9005     0.7151      1.312         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.894      0.802      0.907      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      4.02G     0.8652     0.7329      1.301         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.857      0.809      0.896      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      4.01G      0.905     0.7408      1.336         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.801      0.841       0.89      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      4.02G     0.9041     0.7325      1.319         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.837      0.823      0.889      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      4.01G     0.8656      0.688      1.285         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.835      0.857      0.917      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      4.02G     0.8936     0.7314      1.305         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.843      0.865      0.915       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      4.01G     0.8874     0.7325      1.314         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.865      0.845      0.908      0.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      4.02G     0.8577     0.6912      1.294         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.92       0.81      0.909      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      4.01G     0.8717     0.7064      1.302         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.918      0.824      0.919       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      4.02G     0.8621     0.7121      1.299         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.914       0.83      0.916      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      4.01G     0.8442     0.6752      1.279         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.905      0.817      0.908      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      4.02G     0.8393     0.6784      1.268         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.906      0.837      0.918      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      4.01G      0.879     0.6941      1.298         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.876      0.856      0.916      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      4.02G     0.8605     0.7074      1.294         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.866      0.833      0.899      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      4.01G     0.7613     0.5896      1.315         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.854      0.834      0.894        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      4.02G      0.758      0.519      1.332         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.875      0.818      0.894      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      4.01G     0.7185     0.4892      1.285         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.895      0.793        0.9      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      4.02G     0.7064     0.4644      1.284         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264        0.9       0.79      0.896      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      4.01G     0.6917     0.4628      1.264         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.859      0.846        0.9      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      4.02G     0.6991     0.4594      1.261         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.882      0.833      0.908      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      4.01G     0.6802     0.4418      1.256         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.88      0.835      0.903      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      4.02G     0.6908     0.4429       1.25         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.907      0.812      0.906      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      4.01G     0.6482     0.4506      1.221         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.858      0.832      0.903      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      4.02G     0.6807     0.4401      1.251         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.86      0.843      0.908       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.270 hours.\n",
      "Optimizer stripped from runs\\detect\\train353\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\train353\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\train353\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.86      0.843      0.908       0.63\n",
      "               Class B        128        157      0.867      0.732      0.861      0.598\n",
      "               Class F        105        107      0.853      0.953      0.955      0.662\n",
      "Speed: 0.3ms preprocess, 4.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train353\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : solid_shed_9972\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lancemontojo/general/86cd9ec561a243fb831faf2c3129b564\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [101]               : (3.3173300000000017e-05, 0.001617973856862745)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [101]               : (3.3173300000000017e-05, 0.001617973856862745)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [101]               : (3.3173300000000017e-05, 0.001617973856862745)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [101]     : (0.56863, 0.91943)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [101]  : (0.28028, 0.6299021500055871)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [101] : (0.61132, 0.92006)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [101]    : (0.54773, 0.86523)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs               : 21.551\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters           : 9428566\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)    : 4.531\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [100]       : (0.6482, 1.25329)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [100]       : (0.44009, 1.22606)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [100]       : (1.22098, 1.57947)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [100]         : (1.05877, 1.83348)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [100]         : (0.71391, 1.56019)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [100]         : (1.49255, 2.28965)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from                 : ultralytics\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cutmix          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train352\\weights\\best.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.937\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train353\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs\\detect\\train353\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.0005\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (18.30 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 2 metrics, params and output messages\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 13 file(s), remaining 19.12 MB/23.67 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 15.36 MB/18.30 MB, Throughput 256.78 KB/s, ETA ~62s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 12.59 MB/18.30 MB, Throughput 188.61 KB/s, ETA ~69s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 10.06 MB/18.30 MB, Throughput 172.62 KB/s, ETA ~60s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 7.84 MB/18.30 MB, Throughput 151.31 KB/s, ETA ~54s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 5.59 MB/18.30 MB, Throughput 153.45 KB/s, ETA ~38s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 3.50 MB/18.30 MB, Throughput 142.78 KB/s, ETA ~26s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 1.44 MB/18.30 MB, Throughput 140.65 KB/s, ETA ~11s\n"
     ]
    }
   ],
   "source": [
    "model_YOLO1 = YOLO(r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train352\\weights\\best.pt')  \n",
    "results = model_YOLO1.train(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml', \n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6aaed2",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e980d0d",
   "metadata": {},
   "source": [
    "#### Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa448855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs\\detect\\tune43'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/10 iterations complete  (436.39s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30137 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.5499, 'metrics/recall(B)': 0.48705, 'metrics/mAP50(B)': 0.53107, 'metrics/mAP50-95(B)': 0.27585, 'val/box_loss': 1.6973, 'val/cls_loss': 1.84249, 'val/dfl_loss': 2.08793, 'fitness': 0.30137}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train355\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/10 with hyperparameters: {'lr0': 0.00892, 'lrf': 0.01, 'momentum': 0.89545, 'weight_decay': 0.00057, 'warmup_epochs': 2.51627, 'warmup_momentum': 0.95, 'degrees': 0.0, 'translate': 0.09415, 'scale': 0.49374, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.43077, 'mosaic': 0.81746, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m2/10 iterations complete  (830.11s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.31421 observed at iteration 2\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.61047, 'metrics/recall(B)': 0.5511, 'metrics/mAP50(B)': 0.55342, 'metrics/mAP50-95(B)': 0.28763, 'val/box_loss': 1.61388, 'val/cls_loss': 1.80492, 'val/dfl_loss': 2.02289, 'fitness': 0.31421}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train356\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00892\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 2.51627\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.43077\n",
      "mosaic: 0.81746\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/10 with hyperparameters: {'lr0': 0.00913, 'lrf': 0.01, 'momentum': 0.89545, 'weight_decay': 0.00057, 'warmup_epochs': 3.13637, 'warmup_momentum': 0.95, 'degrees': 0.0, 'translate': 0.09415, 'scale': 0.49374, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.3394, 'mosaic': 0.89799, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m3/10 iterations complete  (1225.02s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/10 with hyperparameters: {'lr0': 0.00797, 'lrf': 0.01, 'momentum': 0.98, 'weight_decay': 0.00047, 'warmup_epochs': 3.4985, 'warmup_momentum': 0.95, 'degrees': 0.0, 'translate': 0.12667, 'scale': 0.48295, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.31803, 'mosaic': 0.9388, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m4/10 iterations complete  (1666.80s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/10 with hyperparameters: {'lr0': 0.00831, 'lrf': 0.01083, 'momentum': 0.88263, 'weight_decay': 0.00057, 'warmup_epochs': 3.21501, 'warmup_momentum': 0.69104, 'degrees': 0.0, 'translate': 0.09415, 'scale': 0.49374, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.37327, 'mosaic': 0.82508, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m5/10 iterations complete  (2095.35s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/10 with hyperparameters: {'lr0': 0.00909, 'lrf': 0.01, 'momentum': 0.89545, 'weight_decay': 0.00044, 'warmup_epochs': 3.09913, 'warmup_momentum': 0.95, 'degrees': 0.0, 'translate': 0.09415, 'scale': 0.63647, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.32037, 'mosaic': 0.89799, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m6/10 iterations complete  (2535.18s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.98, 'weight_decay': 0.00056, 'warmup_epochs': 2.62417, 'warmup_momentum': 0.82699, 'degrees': 0.0, 'translate': 0.09057, 'scale': 0.63647, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.34783, 'mosaic': 0.89799, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m7/10 iterations complete  (3023.43s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.85, 'weight_decay': 0.00046, 'warmup_epochs': 2.43317, 'warmup_momentum': 0.75635, 'degrees': 0.0, 'translate': 0.09057, 'scale': 0.66163, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.3952, 'mosaic': 0.88863, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m8/10 iterations complete  (4243.47s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/10 with hyperparameters: {'lr0': 0.00946, 'lrf': 0.01, 'momentum': 0.89545, 'weight_decay': 0.00064, 'warmup_epochs': 3.13637, 'warmup_momentum': 0.95, 'degrees': 0.0, 'translate': 0.10962, 'scale': 0.49101, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.25764, 'mosaic': 0.87668, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m9/10 iterations complete  (4675.62s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 10/10 with hyperparameters: {'lr0': 0.00859, 'lrf': 0.01139, 'momentum': 0.98, 'weight_decay': 0.00059, 'warmup_epochs': 3.13637, 'warmup_momentum': 0.95, 'degrees': 0.0, 'translate': 0.06815, 'scale': 0.5162, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.28709, 'mosaic': 0.78594, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune43\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune43\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m10/10 iterations complete  (5136.61s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune43\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.38333 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.6894, 'metrics/recall(B)': 0.61438, 'metrics/mAP50(B)': 0.63894, 'metrics/mAP50-95(B)': 0.35493, 'val/box_loss': 1.53711, 'val/cls_loss': 1.49718, 'val/dfl_loss': 1.94056, 'fitness': 0.38333}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train357\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune43\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_YOLO2 = YOLO('yolo11s.pt')  \n",
    "best_hyperparameters = model_YOLO2.tune(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml',\n",
    "    epochs=10,\n",
    "    iterations=10,\n",
    "    space={\n",
    "        # Optimizer params\n",
    "        'lr0': [0.0005, 0.01],\n",
    "        'lrf': [0.01, 0.2],\n",
    "        'momentum': [0.85, 0.98],\n",
    "        'weight_decay': [0.00005, 0.002],\n",
    "        'warmup_epochs': [1.0, 5.0],\n",
    "        'warmup_momentum': [0.4, 0.95],\n",
    "\n",
    "        # Data augmentation\n",
    "        'degrees': [0.0, 10.0],\n",
    "        'translate': [0.0, 0.2],\n",
    "        'scale': [0.4, 0.8],\n",
    "        'shear': [0.0, 5.0],\n",
    "        'perspective': [0.0, 0.001],\n",
    "        'flipud': [0.0, 0.2],\n",
    "        'fliplr': [0.0, 0.5],\n",
    "        'mosaic': [0.5, 1.0],\n",
    "        'mixup': [0.0, 0.3],\n",
    "        'copy_paste': [0.0, 0.3],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345ced97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "lr0: 0.00913\n",
      "lrf: 0.01\n",
      "momentum: 0.89545\n",
      "weight_decay: 0.00057\n",
      "warmup_epochs: 3.13637\n",
      "warmup_momentum: 0.95\n",
      "degrees: 0.0\n",
      "translate: 0.09415\n",
      "scale: 0.49374\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.3394\n",
      "mosaic: 0.89799\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\tune43\\best_hyperparameters.yaml', 'r') as f:\n",
    "    best_hyp = yaml.safe_load(f)\n",
    "\n",
    "print(\"Best hyperparameters found:\")\n",
    "for k, v in best_hyp.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a4fa3",
   "metadata": {},
   "source": [
    "#### Training with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0356be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.142 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.3394, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00913, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train353\\weights\\best.pt, momentum=0.89545, mosaic=0.89799, multi_scale=False, name=train368, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train368, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.49374, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.09415, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.13637, warmup_momentum=0.95, weight_decay=0.00057, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lancemontojo/general/3e1ce40e5e0d4e35918852ac4fc039db\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in 'c:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 35.723.3 MB/s, size: 33.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\train\\labels.cache... 544 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 544/544 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 30.910.4 MB/s, size: 20.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\valid\\labels.cache... 231 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train368\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00913, momentum=0.89545) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.00057), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train368\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.92G     0.9075     0.8032      1.331         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.779      0.649      0.659      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      3.96G     0.9625     0.8204      1.363         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.747      0.649      0.704      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      3.97G     0.9744     0.8489      1.369         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.726      0.707      0.781      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      3.96G      1.019     0.8727      1.396         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.871      0.761      0.846      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      3.97G     0.9679     0.8213      1.345         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.844      0.803      0.872      0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      3.96G     0.9903     0.8587      1.356         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.865      0.746      0.845       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      3.97G     0.9878     0.7935      1.365         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.742      0.632      0.689      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      3.96G     0.9849     0.8341      1.359         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:06<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.822      0.782      0.838      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      3.97G      1.008     0.8276      1.371         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.865       0.78      0.871      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      3.96G      1.008     0.8351      1.374         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.836      0.715      0.845      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      3.97G     0.9854     0.8313      1.362         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.828      0.797      0.868      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      3.96G     0.9582     0.7908      1.346         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.88      0.829      0.904        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      3.97G     0.9511     0.7942      1.336         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.799       0.78      0.836      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      3.96G     0.9423     0.8151      1.346         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.852      0.714      0.839      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      3.97G     0.9604     0.7924      1.329         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.876      0.689      0.836      0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      3.96G      0.973     0.7847      1.344         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.851      0.751      0.842      0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      3.97G     0.9446     0.7555      1.329         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.883      0.785      0.878      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      3.96G     0.9812     0.8116      1.366         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.838      0.745       0.83      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      3.97G     0.9717     0.8156      1.352         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.613      0.438      0.443      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      3.96G     0.9495     0.7853      1.349         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.877      0.708      0.836      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      3.97G     0.9429     0.7727       1.34         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.873      0.793      0.889      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      3.96G     0.9222     0.7541      1.304         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.899      0.753      0.885        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      3.97G     0.9434     0.8029      1.331         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.858      0.756      0.847      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      3.96G       0.96     0.7951      1.341         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.812      0.656      0.779      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      3.97G     0.9288     0.7776      1.332         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.897       0.78      0.872       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      3.96G     0.9546     0.7725      1.326         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.857      0.803      0.875      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      3.97G     0.8953     0.7555      1.294         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.824      0.796      0.853      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      3.96G     0.9246     0.7663      1.317         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.842      0.811       0.89       0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      3.96G     0.9224     0.7501      1.323         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.833      0.797       0.87      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      3.96G     0.9233      0.752      1.313         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.834      0.793      0.878      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      3.97G     0.9342     0.7289      1.329         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.822      0.799      0.861      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      3.96G       0.93     0.7363      1.332         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.826      0.738      0.838      0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      3.97G     0.9018     0.7205      1.294         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.869      0.803      0.888      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      3.96G     0.8995      0.735      1.326         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.864      0.829      0.897      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      3.97G     0.8853     0.6983      1.306         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.909      0.821      0.897      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      3.96G     0.9048     0.7362      1.315         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.847       0.84      0.882      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      3.97G     0.8907     0.6957      1.281         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.87      0.764      0.861      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      3.96G      0.912     0.7418      1.326         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.828      0.839      0.901      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      3.97G     0.9333     0.7414      1.319         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.83      0.834      0.883      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      3.96G      0.873     0.7208      1.285         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.91      0.818      0.902      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      3.97G     0.8676     0.7071      1.301         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.866       0.81      0.888        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      3.96G     0.8992     0.7247      1.298         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.877      0.834      0.891      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      3.97G     0.8774     0.7169      1.295         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.929      0.797        0.9      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      3.97G     0.8737     0.7097      1.291         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.88      0.801      0.897      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      3.97G     0.8702      0.684      1.278         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.878      0.784      0.888      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      3.96G     0.8736     0.6929      1.291         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.878      0.801       0.88      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      3.97G     0.8742     0.6948      1.293         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.895      0.818      0.882      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      3.96G     0.8477     0.6702      1.278         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.911      0.821       0.91      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      3.97G     0.8288     0.6757      1.275         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.898      0.836      0.913      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      3.96G     0.8439     0.6697      1.282         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896      0.831      0.912      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      3.97G     0.8461     0.6779      1.268         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.895      0.815      0.903      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      3.96G     0.8421     0.6661      1.275         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.894      0.828      0.912      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      3.97G     0.8342     0.6539      1.274         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.869      0.851      0.914      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      3.96G     0.8688     0.6975      1.288         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.877      0.833      0.908      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      3.97G     0.8141     0.6683      1.255         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.837      0.845      0.892        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      3.96G     0.8395     0.6746      1.273         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.892      0.791      0.884      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      3.97G     0.8066     0.6671      1.268         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.842      0.841        0.9      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      3.96G     0.8206     0.6693      1.259         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.919      0.806      0.907      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      3.97G     0.8269     0.6496      1.266         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.859      0.856      0.912      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      3.96G     0.8081     0.6527      1.262         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.877      0.858       0.92      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      3.97G     0.8128     0.6425      1.247         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.898      0.829      0.917      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      3.96G     0.8274     0.6649      1.272         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.883      0.844       0.91      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      3.97G     0.8057     0.6425      1.245         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.903      0.856      0.907      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      3.96G     0.7918      0.628      1.246         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  3.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896      0.849      0.913      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      3.97G     0.7961     0.6126      1.241         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.852      0.856      0.903      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      3.96G     0.7524     0.6137      1.231         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.88      0.847      0.902      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      3.97G     0.7824     0.6184      1.232         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.888      0.851      0.918      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      3.96G     0.7692     0.6171      1.233         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.874      0.849      0.911      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      3.99G      0.802      0.627      1.248         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.888      0.829      0.905      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      3.96G     0.7976     0.6334      1.247         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.891      0.821      0.906      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      3.97G     0.7631      0.614      1.229         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.882      0.843      0.904      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      3.96G     0.7907     0.6427       1.25         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.882      0.848      0.917      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      3.97G     0.7677     0.6172      1.219         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.849      0.864      0.908       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      3.96G     0.7719     0.6181      1.226         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.882      0.856       0.91       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      3.97G     0.7845     0.6128       1.23         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.885      0.846      0.917      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      3.96G     0.7613      0.591      1.227         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.887      0.849      0.919      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      3.97G     0.7581      0.605      1.214         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.875      0.856      0.913       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      3.96G     0.7994     0.6271      1.254         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.899      0.836      0.914      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      3.97G     0.7694     0.6099      1.227         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.886       0.84      0.922      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      3.96G     0.7578     0.6018      1.225         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  3.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896      0.832      0.914      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      3.97G     0.7366     0.5743      1.213         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.867      0.858      0.911      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      3.96G     0.7685     0.6164      1.232         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.886      0.854      0.903      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      3.97G     0.7644     0.5861      1.216         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896      0.855       0.92       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      3.96G     0.7453     0.5979      1.224         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.899      0.841      0.917      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      3.97G     0.7392     0.5997      1.219         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.913      0.835      0.921      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      3.96G     0.7669     0.6072       1.23         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.913       0.83      0.919      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      3.97G     0.7545     0.5904      1.206         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.901      0.841      0.918      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      3.96G       0.75     0.6078      1.215         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.926      0.822      0.913      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      3.97G     0.7493     0.5887      1.216         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.91      0.844      0.921      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      3.96G     0.7366     0.5732      1.208         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.877      0.855       0.92      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      3.97G     0.6154     0.4548      1.197         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  3.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.857      0.874      0.913       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      3.96G     0.6306     0.4508      1.217         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.841      0.883      0.911      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      3.97G     0.6173     0.4284      1.201         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.853      0.873      0.911      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      3.96G     0.6098     0.4292      1.206         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.847      0.884      0.909      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      3.97G     0.6119     0.4255      1.197         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.861       0.87      0.909      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      3.96G        0.6     0.4185      1.179         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.859       0.86       0.91      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      3.97G     0.5952     0.4019      1.182         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.859      0.863      0.912      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      3.96G     0.6158      0.421      1.191         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.854      0.864      0.914      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      3.97G     0.5941     0.4208      1.173         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.859      0.856      0.913      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      3.96G     0.6161     0.4195      1.203         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.839      0.869      0.909      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.368 hours.\n",
      "Optimizer stripped from runs\\detect\\train368\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\train368\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\train368\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.877      0.855      0.919      0.655\n",
      "               Class B        128        157      0.884      0.776      0.884      0.642\n",
      "               Class F        105        107      0.871      0.935      0.954      0.668\n",
      "Speed: 0.6ms preprocess, 4.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train368\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : surrounding_tundra_2217\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lancemontojo/general/3e1ce40e5e0d4e35918852ac4fc039db\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [101]               : (9.353002641113118e-05, 0.07197467289719627)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [101]               : (9.353002641113118e-05, 0.009109942964728928)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [101]               : (9.353002641113118e-05, 0.009109942964728928)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [101]     : (0.44336, 0.92172)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [101]  : (0.19847, 0.6549217932867681)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [101] : (0.61258, 0.92923)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [101]    : (0.43806, 0.88428)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs               : 21.551\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters           : 9428566\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)    : 4.95\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [100]       : (0.59406, 1.01907)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [100]       : (0.40186, 0.87274)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [100]       : (1.1729, 1.39649)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [100]         : (1.02036, 2.00936)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [100]         : (0.67612, 2.21317)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [100]         : (1.47741, 2.60438)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from                 : ultralytics\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cutmix          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.3394\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.00913\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train353\\weights\\best.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.89545\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 0.89799\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train368\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : SGD\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs\\detect\\train368\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.49374\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.09415\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.13637\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.95\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.00057\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (18.30 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 2 metrics, params and output messages\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 14 file(s), remaining 18.87 MB/23.94 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 14.94 MB/18.30 MB, Throughput 267.97 KB/s, ETA ~58s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 11.90 MB/18.30 MB, Throughput 206.71 KB/s, ETA ~59s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 8.84 MB/18.30 MB, Throughput 208.86 KB/s, ETA ~44s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 5.84 MB/18.30 MB, Throughput 204.80 KB/s, ETA ~30s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 2.95 MB/18.30 MB, Throughput 197.12 KB/s, ETA ~16s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n"
     ]
    }
   ],
   "source": [
    "model_YOLO2 = YOLO(r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train353\\weights\\best.pt')\n",
    "\n",
    "results_2 = model_YOLO2.train(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml', \n",
    "    epochs=100,  # Total number of epochs, \n",
    "    imgsz=640,  # Image size\n",
    "\n",
    "    # Best hyperparameters from tuning\n",
    "    lr0=0.00913,\n",
    "    lrf=0.01,\n",
    "    momentum=0.89545,\n",
    "    weight_decay=0.00057,\n",
    "    warmup_epochs=3.13637,\n",
    "    warmup_momentum=0.95,\n",
    "    degrees=0.0,\n",
    "    translate=0.09415,\n",
    "    scale=0.49374,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.3394,\n",
    "    mosaic=0.89799,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    "    \n",
    "    optimizer='SGD', \n",
    "    cos_lr=True  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853c3a1",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66057e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "Backbone requires_grad flags:\n",
      "conv.weight: False\n",
      "conv.bias: False\n",
      "New https://pypi.org/project/ultralytics/8.3.142 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train370\\weights\\best.pt, momentum=0.98, mosaic=0.81706, multi_scale=False, name=train371, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train371, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.4, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11386, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.50243, warmup_momentum=0.8, weight_decay=0.00039, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 94/499 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lancemontojo/general/aa71eef39d6c4de3b27d7f63f655f040\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in 'c:\\\\Users\\\\Jerome\\\\anaconda3\\\\CPE313_MONTOJO' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 127.959.5 MB/s, size: 33.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\train\\labels.cache... 544 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 544/544 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 17.15.3 MB/s, size: 20.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\valid\\labels.cache... 231 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train371\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.98) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.00039), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train371\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.93G          1     0.9647      1.418         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.822      0.802      0.872      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      3.97G     0.8974     0.7943      1.338         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.913       0.84      0.911      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      3.97G     0.9155     0.7806      1.349         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.888       0.79      0.878      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      3.97G     0.9479     0.7947       1.35         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.868        0.8      0.888      0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      3.97G      1.026     0.8731      1.455         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.765      0.802      0.837       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      3.97G      1.033     0.9125      1.447         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.767      0.778      0.838      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      3.97G      1.043      0.941      1.458         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.721      0.779        0.8      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      3.97G      1.124     0.9779      1.508         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.739      0.704      0.785      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      3.98G      1.132      1.015      1.524         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.751      0.662       0.77      0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      3.96G      1.111      1.021       1.51         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.792      0.689      0.784       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      3.98G      1.129       1.03      1.514         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.738      0.716      0.762      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      3.98G      1.095     0.9848      1.513         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.657      0.699      0.718      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      3.98G      1.171      1.037      1.548         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.653      0.688      0.694      0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      3.98G      1.151      1.037      1.534         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.759      0.744      0.803      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      3.98G      1.149       1.03      1.535         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.807      0.789      0.822       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      3.98G      1.134     0.9976      1.519         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.781      0.733      0.814      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      3.98G      1.097      1.003      1.516         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.744      0.725      0.783      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      3.98G      1.133       1.01      1.531         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.717      0.757       0.77      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      3.98G      1.106      0.989      1.524         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.714      0.711      0.756      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      3.98G      1.103     0.9844      1.508         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.801      0.762      0.838      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      3.98G      1.156      1.068      1.554         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.79       0.81      0.845      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      3.98G      1.117      1.011      1.506         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.803      0.751      0.804      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      3.98G      1.118     0.9673      1.512         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.824      0.755      0.837      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      3.98G      1.123      1.008      1.516         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.778      0.757      0.815      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      3.98G      1.099     0.9976      1.505         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.788      0.746      0.804       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      3.98G      1.106     0.9832      1.494         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.844      0.697       0.82      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      3.98G      1.109     0.9508      1.506         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.806      0.736      0.816      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      3.98G      1.102     0.9395      1.499         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.821      0.739      0.812      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      3.98G      1.081     0.9772      1.497         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.827      0.712      0.836        0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      3.98G      1.116     0.9471      1.511         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.818       0.76       0.83      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      3.98G      1.108     0.9895      1.516         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.805      0.743      0.831      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      3.98G      1.077     0.9728      1.481         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.836      0.748      0.855      0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      3.98G      1.092     0.9486      1.471         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.852      0.782      0.876      0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      3.98G      1.091     0.9295      1.483         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.833      0.754      0.844      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      3.98G       1.05     0.8862      1.443         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.892       0.75      0.868      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      3.98G      1.069     0.9123      1.466         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.832      0.746      0.836      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      3.98G      1.053     0.9286      1.478         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.838       0.81      0.871      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      3.98G      1.065     0.8994      1.468         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.883      0.775      0.864      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      3.98G      1.058      0.919      1.446         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.873      0.779       0.86      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      3.98G      1.002     0.8923      1.435         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.871      0.772      0.861      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      3.98G      1.006     0.8635      1.416         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.861      0.791      0.874      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      3.98G      1.047     0.8777      1.443         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.873      0.817      0.877       0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      3.98G      1.028     0.8629      1.448         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.922      0.776        0.9      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      3.98G      1.027     0.8447      1.434         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.895      0.803      0.898      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      3.98G      1.026     0.8344      1.446         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.851      0.789      0.859      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      3.98G     0.9732     0.8085      1.417         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.827      0.803      0.853       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      3.98G      1.016     0.8425      1.409         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.78      0.812      0.851      0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      3.98G     0.9786     0.8662      1.408         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.838      0.811      0.878      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      3.98G      1.012     0.8398       1.43         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.816      0.813      0.878      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      3.98G     0.9654     0.8336      1.389         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.843      0.787      0.869      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      3.98G      0.976     0.8404      1.392         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.852      0.826      0.868      0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      3.98G     0.9481     0.7891      1.387         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.865      0.813      0.875      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      3.98G     0.9533     0.7664      1.388         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.923      0.832      0.899      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      3.98G      0.962     0.8227      1.393         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.888      0.833      0.889      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      3.98G     0.9508     0.7772        1.4         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.905      0.839      0.904        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      3.98G     0.9283     0.7744      1.353         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.893      0.817      0.905      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      3.98G      0.926     0.7724      1.386         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.895      0.836      0.912      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      3.98G     0.9269     0.7812       1.35         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.886      0.852      0.915      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      3.98G     0.9357     0.7484      1.347         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.869      0.838      0.903      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      3.98G     0.9306     0.7477       1.38         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.883      0.811       0.91      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      3.98G     0.9114     0.7467      1.351         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.872      0.824      0.899      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      3.98G     0.9047     0.7109      1.351         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.887      0.846      0.897      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      3.98G     0.9235      0.744      1.356         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.894      0.814       0.89      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      3.98G     0.9038     0.7456      1.321         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.938      0.817      0.894      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      3.98G     0.9134      0.758      1.339         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.91      0.835      0.908      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      3.98G     0.8801       0.71       1.32         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:07<00:00,  4.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.911      0.839      0.884      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      3.98G     0.8807     0.7125      1.329         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.935       0.84      0.911       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      3.98G     0.8888     0.7262      1.347         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264       0.93      0.827      0.911      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      3.98G     0.8572     0.6854      1.315         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.908      0.843      0.911      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      3.98G     0.8159     0.6345      1.288         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.931      0.857      0.916      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      3.98G      0.844     0.6877      1.312         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.934       0.84      0.917      0.617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      3.98G     0.8616     0.6875      1.308         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.942      0.838      0.926      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      3.98G     0.8293     0.6689      1.301         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.944      0.867      0.931      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      3.98G     0.8382     0.6475      1.297         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.937      0.848      0.921      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      3.98G     0.8468      0.659       1.32         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.919      0.865      0.922      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      3.98G     0.8511      0.648      1.314         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.905      0.859       0.92      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      3.98G      0.837     0.6668      1.287         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.887      0.865      0.915      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      3.98G     0.8058     0.6513       1.28         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896       0.85      0.914      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      3.98G     0.8291     0.6349      1.288         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.923      0.841      0.909      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      3.98G     0.8183     0.6508      1.282         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:11<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.914       0.84      0.904      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      3.98G     0.7824     0.5954      1.275         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.912      0.836      0.901       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      3.98G     0.8148     0.6373      1.283         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.932      0.835      0.904      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      3.98G     0.8153     0.6305      1.278         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.922      0.839      0.908      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      3.98G     0.7855     0.6121      1.268         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.876      0.853      0.913      0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      3.98G     0.7875     0.6362      1.266         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896      0.861      0.914      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      3.98G     0.7707     0.6131      1.239         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.898      0.855      0.917      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      3.98G     0.7678      0.621      1.259         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.909      0.852      0.917      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      3.98G     0.7774     0.6413      1.247         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.909      0.847      0.918      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      3.98G      0.765      0.589      1.244         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.915       0.85      0.917      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      3.98G     0.7609     0.5951      1.249         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.928      0.851      0.921      0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      3.98G     0.6122      0.434       1.19         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.919       0.85      0.917       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      3.98G      0.643     0.4426      1.226         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:10<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.924      0.848      0.915      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      3.98G      0.613     0.4264      1.208         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.926      0.835      0.911      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      3.98G     0.6165     0.4176      1.205         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.895      0.862      0.913      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      3.98G     0.5932      0.404       1.19         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  3.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.899      0.854      0.914      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      3.98G     0.6134     0.4009      1.193         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.891      0.857      0.917      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      3.98G      0.604      0.399      1.196         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.935      0.832      0.919      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      3.98G      0.587     0.3993      1.165         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:09<00:00,  3.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.896       0.86      0.918      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      3.98G     0.5927     0.3972      1.189         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.909      0.853       0.92      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      3.98G     0.5985     0.3959      1.199         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:08<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.919       0.85      0.921      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.342 hours.\n",
      "Optimizer stripped from runs\\detect\\train371\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\train371\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\train371\\weights\\best.pt...\n",
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.903      0.858      0.917      0.654\n",
      "               Class B        128        157      0.879       0.79      0.881      0.627\n",
      "               Class F        105        107      0.926      0.925      0.953       0.68\n",
      "Speed: 0.3ms preprocess, 5.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train371\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : loyal_radian_1380\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lancemontojo/general/aa71eef39d6c4de3b27d7f63f655f040\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [101]               : (0.0001024425261896289, 0.07504201680672269)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [101]               : (0.0001024425261896289, 0.009978031724785246)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [101]               : (0.0001024425261896289, 0.009978031724785246)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [101]     : (0.69385, 0.93063)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [101]  : (0.38417, 0.65393)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [101] : (0.65292, 0.94391)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [101]    : (0.66163, 0.86694)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs               : 21.551\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters           : 9428566\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)    : 3.935\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [100]       : (0.58704, 1.17109)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [100]       : (0.39595, 1.06777)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [100]       : (1.16514, 1.5539)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [100]         : (1.02488, 1.53246)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [100]         : (0.66945, 1.32206)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [100]         : (1.48592, 1.94084)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from                 : ultralytics\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_batch_logging_interval  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_confusion_matrix_on_eval : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     log_image_predictions        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_image_predictions        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     agnostic_nms    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     amp             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     augment         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     auto_augment    : randaugment\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch           : 16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bgr             : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box             : 7.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     classes         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     close_mosaic    : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls             : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conf            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste_mode : flip\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cutmix          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     data            : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     deterministic   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dfl             : 1.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dnn             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout         : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dynamic         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embed           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs          : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     erasing         : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr          : 0.5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud          : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     format          : torchscript\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fraction        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     half            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h           : 0.015\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s           : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz           : 640\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     int8            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou             : 0.7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     keras           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     kobj            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     line_width      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf             : 0.01\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mask_ratio      : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_det         : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mode            : train\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model           : C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train370\\weights\\best.pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum        : 0.98\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic          : 0.81706\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name            : train371\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nbs             : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nms             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     opset           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimize        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer       : SGD\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     overlap_mask    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience        : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     plots           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pose            : 12.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pretrained      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     profile         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     retina_masks    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_conf       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_crop       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir        : runs\\detect\\train371\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_frames     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_json       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period     : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_txt        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale           : 0.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_boxes      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_conf       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     show_labels     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     simplify        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     split           : val\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     stream_buffer   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     task            : detect\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     time            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     tracker         : botsort.yaml\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate       : 0.11386\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     verbose         : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     vid_stride      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     visualize       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr  : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs   : 3.50243\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum : 0.8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay    : 0.00039\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers         : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workspace       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (18.30 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 2 metrics, params and output messages\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 14 file(s), remaining 19.68 MB/23.96 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 15.26 MB/18.30 MB, Throughput 301.20 KB/s, ETA ~52s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 12.39 MB/18.30 MB, Throughput 196.06 KB/s, ETA ~65s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 9.62 MB/18.30 MB, Throughput 188.60 KB/s, ETA ~53s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 6.73 MB/18.30 MB, Throughput 197.14 KB/s, ETA ~35s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 3.92 MB/18.30 MB, Throughput 191.80 KB/s, ETA ~21s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 1.06 MB/18.30 MB, Throughput 195.20 KB/s, ETA ~6s\n"
     ]
    }
   ],
   "source": [
    "model_YOLO3 = YOLO(r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train370\\weights\\best.pt')\n",
    "\n",
    "try:\n",
    "    model_YOLO3.model.fuse()\n",
    "except Exception as e:\n",
    "    print(f\"Fuse error (can ignore): {e}\")\n",
    "\n",
    "for param in model_YOLO3.model.model[0].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "print(\"Backbone requires_grad flags:\")\n",
    "for name, param in model_YOLO3.model.model[0].named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "\n",
    "results_3 = model_YOLO3.train(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml',\n",
    "    epochs=100,  # Total number of epoch\n",
    "    imgsz=640,  # Image size\n",
    "\n",
    "    # Best hyperparameters from tuning\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    momentum=0.98,\n",
    "    weight_decay=0.00039,\n",
    "    warmup_epochs=3.50243,\n",
    "    warmup_momentum=0.8,\n",
    "    degrees=0.0,\n",
    "    translate=0.11386,\n",
    "    scale=0.4,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=0.81706,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    "\n",
    "    \n",
    "    optimizer='SGD',  \n",
    "    cos_lr=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a02f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 99.656.9 MB/s, size: 32.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\valid\\labels.cache... 231 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.977      0.669      0.825      0.648\n",
      "               Class B        128        157      0.988      0.516      0.751      0.607\n",
      "               Class F        105        107      0.967      0.822      0.899      0.689\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val49\u001b[0m\n",
      "IoU=0.65 mAP50: 0.8251471998476492\n",
      "IoU=0.65 mAP50-95: 0.6479288928679018\n"
     ]
    }
   ],
   "source": [
    "model_YOLO3 = YOLO(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train371\\weights\\best.pt\")\n",
    "\n",
    "results = model_YOLO3.val(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml',\n",
    "    conf=0.8,\n",
    ")\n",
    "\n",
    "print(\"IoU=0.65 mAP50:\", results.box.map50)\n",
    "print(\"IoU=0.65 mAP50-95:\", results.box.map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc30e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.141  Python-3.12.9 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 52.125.6 MB/s, size: 27.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\valid\\labels.cache... 231 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        231        264      0.971      0.659      0.822       0.65\n",
      "               Class B        128        157      0.989      0.561      0.776      0.633\n",
      "               Class F        105        107      0.953      0.757      0.868      0.667\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val48\u001b[0m\n",
      "IoU=0.65 mAP50: 0.8219447798990562\n",
      "IoU=0.65 mAP50-95: 0.6503589536920116\n"
     ]
    }
   ],
   "source": [
    "model_YOLO3 = YOLO(r\"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\runs\\detect\\train368\\weights\\best.pt\")\n",
    "\n",
    "results = model_YOLO3.val(\n",
    "    data=r'C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2\\data.yaml',\n",
    "    conf=0.8,\n",
    ")\n",
    "\n",
    "print(\"IoU=0.65 mAP50:\", results.box.map50)\n",
    "print(\"IoU=0.65 mAP50-95:\", results.box.map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460351fb",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7ed31534",
   "metadata": {},
   "source": [
    "Result of YOLOv11\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c0c7b",
   "metadata": {},
   "source": [
    "## RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99876d49",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0e4f37",
   "metadata": {},
   "source": [
    "The PyTorch RetinaNet implementation from this link will be used: https://github.com/yhenon/pytorch-retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yhenon/pytorch-retinanet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c37965",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c556ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\pytorch-retinanet\n",
      "CUDA available: True\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Num training images: 544\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 0 | Iteration: 0 | Classification loss: 2.96009 | Regression loss: 0.56314 | Running loss: 3.52322\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 1.28138 | Regression loss: 0.93375 | Running loss: 2.86918\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 1.21886 | Regression loss: 1.14611 | Running loss: 2.70111\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 3.45100 | Regression loss: 0.00000 | Running loss: 2.88858\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 2.69258 | Regression loss: 0.00000 | Running loss: 2.84938\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 1.12188 | Regression loss: 1.02533 | Running loss: 2.73235\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 1.28464 | Regression loss: 0.49612 | Running loss: 2.59641\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 1.43205 | Regression loss: 0.00000 | Running loss: 2.45086\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 1.00783 | Regression loss: 1.03424 | Running loss: 2.40544\n",
      "Epoch: 0 | Iteration: 9 | Classification loss: 1.11908 | Regression loss: 1.12498 | Running loss: 2.38930\n",
      "Epoch: 0 | Iteration: 10 | Classification loss: 0.95017 | Regression loss: 0.98781 | Running loss: 2.34827\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 0.49614 | Regression loss: 0.00000 | Running loss: 2.19393\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 1.05421 | Regression loss: 1.05479 | Running loss: 2.18740\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 0.98010 | Regression loss: 0.97143 | Running loss: 2.17055\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 0.88140 | Regression loss: 1.00506 | Running loss: 2.15161\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 0.71406 | Regression loss: 0.00000 | Running loss: 2.06176\n",
      "Epoch: 0 | Iteration: 16 | Classification loss: 0.94966 | Regression loss: 0.97621 | Running loss: 2.05377\n",
      "Epoch: 0 | Iteration: 17 | Classification loss: 1.03784 | Regression loss: 0.00000 | Running loss: 1.99733\n",
      "Epoch: 0 | Iteration: 18 | Classification loss: 1.15524 | Regression loss: 0.00000 | Running loss: 1.95301\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 0.59245 | Regression loss: 0.00000 | Running loss: 1.88498\n",
      "Epoch: 0 | Iteration: 20 | Classification loss: 0.67670 | Regression loss: 0.00000 | Running loss: 1.82744\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 0.85868 | Regression loss: 0.97905 | Running loss: 1.82791\n",
      "Epoch: 0 | Iteration: 22 | Classification loss: 0.80650 | Regression loss: 0.91241 | Running loss: 1.82317\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 0.44069 | Regression loss: 0.00000 | Running loss: 1.76557\n",
      "Epoch: 0 | Iteration: 24 | Classification loss: 0.21574 | Regression loss: 0.00000 | Running loss: 1.70358\n",
      "Epoch: 0 | Iteration: 25 | Classification loss: 0.77345 | Regression loss: 1.23464 | Running loss: 1.71529\n",
      "Epoch: 0 | Iteration: 26 | Classification loss: 0.94576 | Regression loss: 1.00946 | Running loss: 1.72417\n",
      "Epoch: 0 | Iteration: 27 | Classification loss: 0.12526 | Regression loss: 0.00000 | Running loss: 1.66707\n",
      "Epoch: 0 | Iteration: 28 | Classification loss: 0.10496 | Regression loss: 0.00000 | Running loss: 1.61320\n",
      "Epoch: 0 | Iteration: 29 | Classification loss: 0.81905 | Regression loss: 1.10132 | Running loss: 1.62344\n",
      "Epoch: 0 | Iteration: 30 | Classification loss: 0.72058 | Regression loss: 1.16704 | Running loss: 1.63196\n",
      "Epoch: 0 | Iteration: 31 | Classification loss: 0.93195 | Regression loss: 1.00124 | Running loss: 1.64138\n",
      "Epoch: 0 | Iteration: 32 | Classification loss: 0.43751 | Regression loss: 0.54540 | Running loss: 1.62142\n",
      "Epoch: 0 | Iteration: 33 | Classification loss: 0.04693 | Regression loss: 0.00000 | Running loss: 1.57512\n",
      "Epoch: 0 | Iteration: 34 | Classification loss: 0.70688 | Regression loss: 1.03228 | Running loss: 1.57980\n",
      "Epoch: 0 | Iteration: 35 | Classification loss: 0.79689 | Regression loss: 0.87855 | Running loss: 1.58246\n",
      "Epoch: 0 | Iteration: 36 | Classification loss: 0.48420 | Regression loss: 0.97988 | Running loss: 1.57926\n",
      "Epoch: 0 | Iteration: 37 | Classification loss: 0.04052 | Regression loss: 0.00000 | Running loss: 1.53877\n",
      "Epoch: 0 | Iteration: 38 | Classification loss: 0.36269 | Regression loss: 1.04256 | Running loss: 1.53534\n",
      "Epoch: 0 | Iteration: 39 | Classification loss: 2.71227 | Regression loss: 0.00000 | Running loss: 1.56477\n",
      "Epoch: 0 | Iteration: 40 | Classification loss: 0.35261 | Regression loss: 0.99896 | Running loss: 1.55957\n",
      "Epoch: 0 | Iteration: 41 | Classification loss: 0.26723 | Regression loss: 0.00000 | Running loss: 1.52880\n",
      "Epoch: 0 | Iteration: 42 | Classification loss: 0.51235 | Regression loss: 0.98219 | Running loss: 1.52800\n",
      "Epoch: 0 | Iteration: 43 | Classification loss: 1.93117 | Regression loss: 0.55054 | Running loss: 1.54967\n",
      "Epoch: 0 | Iteration: 44 | Classification loss: 0.73521 | Regression loss: 1.15872 | Running loss: 1.55732\n",
      "Epoch: 0 | Iteration: 45 | Classification loss: 0.02633 | Regression loss: 0.00000 | Running loss: 1.52404\n",
      "Epoch: 0 | Iteration: 46 | Classification loss: 0.01919 | Regression loss: 0.00000 | Running loss: 1.49202\n",
      "Epoch: 0 | Iteration: 47 | Classification loss: 1.46918 | Regression loss: 1.50778 | Running loss: 1.52296\n",
      "Epoch: 0 | Iteration: 48 | Classification loss: 0.92672 | Regression loss: 0.96627 | Running loss: 1.53051\n",
      "Epoch: 0 | Iteration: 49 | Classification loss: 0.77565 | Regression loss: 0.95382 | Running loss: 1.53449\n",
      "Epoch: 0 | Iteration: 50 | Classification loss: 0.66201 | Regression loss: 0.88724 | Running loss: 1.53478\n",
      "Epoch: 0 | Iteration: 51 | Classification loss: 0.07835 | Regression loss: 0.00000 | Running loss: 1.50677\n",
      "Epoch: 0 | Iteration: 52 | Classification loss: 0.37939 | Regression loss: 0.48332 | Running loss: 1.49462\n",
      "Epoch: 0 | Iteration: 53 | Classification loss: 0.93356 | Regression loss: 0.91138 | Running loss: 1.50111\n",
      "Epoch: 0 | Iteration: 54 | Classification loss: 0.64402 | Regression loss: 0.85951 | Running loss: 1.50115\n",
      "Epoch: 0 | Iteration: 55 | Classification loss: 0.38533 | Regression loss: 0.45401 | Running loss: 1.48933\n",
      "Epoch: 0 | Iteration: 56 | Classification loss: 0.76719 | Regression loss: 1.01090 | Running loss: 1.49440\n",
      "Epoch: 0 | Iteration: 57 | Classification loss: 0.70200 | Regression loss: 0.91324 | Running loss: 1.49648\n",
      "Epoch: 0 | Iteration: 58 | Classification loss: 0.52331 | Regression loss: 0.96329 | Running loss: 1.49632\n",
      "Epoch: 0 | Iteration: 59 | Classification loss: 0.42343 | Regression loss: 0.96682 | Running loss: 1.49455\n",
      "Epoch: 0 | Iteration: 60 | Classification loss: 0.50980 | Regression loss: 1.06264 | Running loss: 1.49582\n",
      "Epoch: 0 | Iteration: 61 | Classification loss: 0.21168 | Regression loss: 0.00000 | Running loss: 1.47511\n",
      "Epoch: 0 | Iteration: 62 | Classification loss: 0.41482 | Regression loss: 0.89950 | Running loss: 1.47256\n",
      "Epoch: 0 | Iteration: 63 | Classification loss: 0.57643 | Regression loss: 1.19451 | Running loss: 1.47722\n",
      "Epoch: 0 | Iteration: 64 | Classification loss: 4.14437 | Regression loss: 0.46623 | Running loss: 1.52543\n",
      "Epoch: 0 | Iteration: 65 | Classification loss: 0.41784 | Regression loss: 0.86403 | Running loss: 1.52174\n",
      "Epoch: 0 | Iteration: 66 | Classification loss: 0.50862 | Regression loss: 1.01841 | Running loss: 1.52182\n",
      "Epoch: 0 | Iteration: 67 | Classification loss: 0.03944 | Regression loss: 0.00000 | Running loss: 1.50002\n",
      "Epoch: 0 | Iteration: 68 | Classification loss: 0.05131 | Regression loss: 0.00000 | Running loss: 1.47902\n",
      "Epoch: 0 | Iteration: 69 | Classification loss: 0.14537 | Regression loss: 0.00000 | Running loss: 1.45997\n",
      "Epoch: 0 | Iteration: 70 | Classification loss: 0.60629 | Regression loss: 0.89840 | Running loss: 1.46060\n",
      "Epoch: 0 | Iteration: 71 | Classification loss: 0.70915 | Regression loss: 0.93417 | Running loss: 1.46314\n",
      "Epoch: 0 | Iteration: 72 | Classification loss: 0.01794 | Regression loss: 0.00000 | Running loss: 1.44334\n",
      "Epoch: 0 | Iteration: 73 | Classification loss: 0.62245 | Regression loss: 0.84188 | Running loss: 1.44362\n",
      "Epoch: 0 | Iteration: 74 | Classification loss: 0.61283 | Regression loss: 0.94246 | Running loss: 1.44511\n",
      "Epoch: 0 | Iteration: 75 | Classification loss: 0.43994 | Regression loss: 1.27822 | Running loss: 1.44871\n",
      "Epoch: 0 | Iteration: 76 | Classification loss: 0.43071 | Regression loss: 0.84351 | Running loss: 1.44644\n",
      "Epoch: 0 | Iteration: 77 | Classification loss: 0.18443 | Regression loss: 0.00000 | Running loss: 1.43026\n",
      "Epoch: 0 | Iteration: 78 | Classification loss: 0.08144 | Regression loss: 0.00000 | Running loss: 1.41319\n",
      "Epoch: 0 | Iteration: 79 | Classification loss: 0.58262 | Regression loss: 1.08649 | Running loss: 1.41639\n",
      "Epoch: 0 | Iteration: 80 | Classification loss: 0.01239 | Regression loss: 0.00000 | Running loss: 1.39905\n",
      "Epoch: 0 | Iteration: 81 | Classification loss: 1.68940 | Regression loss: 1.19595 | Running loss: 1.41718\n",
      "Epoch: 0 | Iteration: 82 | Classification loss: 0.80393 | Regression loss: 1.04015 | Running loss: 1.42232\n",
      "Epoch: 0 | Iteration: 83 | Classification loss: 0.43772 | Regression loss: 1.23013 | Running loss: 1.42524\n",
      "Epoch: 0 | Iteration: 84 | Classification loss: 0.01638 | Regression loss: 0.00000 | Running loss: 1.40867\n",
      "Epoch: 0 | Iteration: 85 | Classification loss: 0.58437 | Regression loss: 0.00000 | Running loss: 1.39908\n",
      "Epoch: 0 | Iteration: 86 | Classification loss: 0.40778 | Regression loss: 0.79347 | Running loss: 1.39681\n",
      "Epoch: 0 | Iteration: 87 | Classification loss: 0.40765 | Regression loss: 0.00000 | Running loss: 1.38557\n",
      "Epoch: 0 | Iteration: 88 | Classification loss: 0.01289 | Regression loss: 0.00000 | Running loss: 1.37015\n",
      "Epoch: 0 | Iteration: 89 | Classification loss: 0.27431 | Regression loss: 0.43581 | Running loss: 1.36281\n",
      "Epoch: 0 | Iteration: 90 | Classification loss: 0.30160 | Regression loss: 0.99053 | Running loss: 1.36204\n",
      "Epoch: 0 | Iteration: 91 | Classification loss: 0.00928 | Regression loss: 0.00000 | Running loss: 1.34733\n",
      "Epoch: 0 | Iteration: 92 | Classification loss: 0.34360 | Regression loss: 0.47635 | Running loss: 1.34166\n",
      "Epoch: 0 | Iteration: 93 | Classification loss: 0.00665 | Regression loss: 0.00000 | Running loss: 1.32746\n",
      "Epoch: 0 | Iteration: 94 | Classification loss: 0.21115 | Regression loss: 0.00000 | Running loss: 1.31571\n",
      "Epoch: 0 | Iteration: 95 | Classification loss: 0.02306 | Regression loss: 0.00000 | Running loss: 1.30224\n",
      "Epoch: 0 | Iteration: 96 | Classification loss: 0.31100 | Regression loss: 1.03519 | Running loss: 1.30270\n",
      "Epoch: 0 | Iteration: 97 | Classification loss: 0.00282 | Regression loss: 0.00000 | Running loss: 1.28943\n",
      "Epoch: 0 | Iteration: 98 | Classification loss: 0.01519 | Regression loss: 0.00000 | Running loss: 1.27656\n",
      "Epoch: 0 | Iteration: 99 | Classification loss: 0.01443 | Regression loss: 0.00000 | Running loss: 1.26394\n",
      "Epoch: 0 | Iteration: 100 | Classification loss: 0.94957 | Regression loss: 1.29922 | Running loss: 1.27369\n",
      "Epoch: 0 | Iteration: 101 | Classification loss: 1.58338 | Regression loss: 1.04595 | Running loss: 1.28698\n",
      "Epoch: 0 | Iteration: 102 | Classification loss: 0.00094 | Regression loss: 0.00000 | Running loss: 1.27450\n",
      "Epoch: 0 | Iteration: 103 | Classification loss: 0.00057 | Regression loss: 0.00000 | Running loss: 1.26225\n",
      "Epoch: 0 | Iteration: 104 | Classification loss: 2.17883 | Regression loss: 1.30082 | Running loss: 1.28336\n",
      "Epoch: 0 | Iteration: 105 | Classification loss: 0.00015 | Regression loss: 0.00000 | Running loss: 1.27126\n",
      "Epoch: 0 | Iteration: 106 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.25938\n",
      "Epoch: 0 | Iteration: 107 | Classification loss: 1.29564 | Regression loss: 1.27840 | Running loss: 1.27155\n",
      "Epoch: 0 | Iteration: 108 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.25989\n",
      "Epoch: 0 | Iteration: 109 | Classification loss: 1.46637 | Regression loss: 1.04583 | Running loss: 1.27127\n",
      "Epoch: 0 | Iteration: 110 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.25982\n",
      "Epoch: 0 | Iteration: 111 | Classification loss: 2.11788 | Regression loss: 0.88326 | Running loss: 1.27537\n",
      "Epoch: 0 | Iteration: 112 | Classification loss: 1.99507 | Regression loss: 1.19043 | Running loss: 1.29227\n",
      "Epoch: 0 | Iteration: 113 | Classification loss: 1.15110 | Regression loss: 0.51041 | Running loss: 1.29551\n",
      "Epoch: 0 | Iteration: 114 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28424\n",
      "Epoch: 0 | Iteration: 115 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.27317\n",
      "Epoch: 0 | Iteration: 116 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.26229\n",
      "Epoch: 0 | Iteration: 117 | Classification loss: 0.94777 | Regression loss: 0.43122 | Running loss: 1.26328\n",
      "Epoch: 0 | Iteration: 118 | Classification loss: 0.03653 | Regression loss: 0.00000 | Running loss: 1.25297\n",
      "Epoch: 0 | Iteration: 119 | Classification loss: 1.16040 | Regression loss: 1.29676 | Running loss: 1.26301\n",
      "Epoch: 0 | Iteration: 120 | Classification loss: 0.00114 | Regression loss: 0.00000 | Running loss: 1.25258\n",
      "Epoch: 0 | Iteration: 121 | Classification loss: 0.63356 | Regression loss: 0.39224 | Running loss: 1.25072\n",
      "Epoch: 0 | Iteration: 122 | Classification loss: 0.00337 | Regression loss: 0.00000 | Running loss: 1.24058\n",
      "Epoch: 0 | Iteration: 123 | Classification loss: 0.74591 | Regression loss: 0.51029 | Running loss: 1.24070\n",
      "Epoch: 0 | Iteration: 124 | Classification loss: 0.00351 | Regression loss: 0.00000 | Running loss: 1.23081\n",
      "Epoch: 0 | Iteration: 125 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.22104\n",
      "Epoch: 0 | Iteration: 126 | Classification loss: 1.20148 | Regression loss: 1.03636 | Running loss: 1.22904\n",
      "Epoch: 0 | Iteration: 127 | Classification loss: 0.00285 | Regression loss: 0.00000 | Running loss: 1.21946\n",
      "Epoch: 0 | Iteration: 128 | Classification loss: 0.00192 | Regression loss: 0.00000 | Running loss: 1.21003\n",
      "Epoch: 0 | Iteration: 129 | Classification loss: 0.92396 | Regression loss: 0.90883 | Running loss: 1.21482\n",
      "Epoch: 0 | Iteration: 130 | Classification loss: 0.00083 | Regression loss: 0.00000 | Running loss: 1.20555\n",
      "Epoch: 0 | Iteration: 131 | Classification loss: 0.49204 | Regression loss: 0.45057 | Running loss: 1.20356\n",
      "Epoch: 0 | Iteration: 132 | Classification loss: 1.06834 | Regression loss: 0.59471 | Running loss: 1.20701\n",
      "Epoch: 0 | Iteration: 133 | Classification loss: 1.40372 | Regression loss: 0.78118 | Running loss: 1.21431\n",
      "Epoch: 0 | Iteration: 134 | Classification loss: 0.47475 | Regression loss: 0.43326 | Running loss: 1.21204\n",
      "Epoch: 0 | Iteration: 135 | Classification loss: 1.00886 | Regression loss: 0.79858 | Running loss: 1.21642\n",
      "Epoch: 0 | Iteration: 136 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.20754\n",
      "Epoch: 0 | Iteration: 137 | Classification loss: 0.00635 | Regression loss: 0.00000 | Running loss: 1.19884\n",
      "Epoch: 0 | Iteration: 138 | Classification loss: 1.99414 | Regression loss: 1.06157 | Running loss: 1.21219\n",
      "Epoch: 0 | Iteration: 139 | Classification loss: 0.86420 | Regression loss: 0.93050 | Running loss: 1.21636\n",
      "Epoch: 0 | Iteration: 140 | Classification loss: 0.00045 | Regression loss: 0.00000 | Running loss: 1.20773\n",
      "Epoch: 0 | Iteration: 141 | Classification loss: 0.73056 | Regression loss: 0.83157 | Running loss: 1.21023\n",
      "Epoch: 0 | Iteration: 142 | Classification loss: 0.00031 | Regression loss: 0.00000 | Running loss: 1.20177\n",
      "Epoch: 0 | Iteration: 143 | Classification loss: 0.00693 | Regression loss: 0.00000 | Running loss: 1.19347\n",
      "Epoch: 0 | Iteration: 144 | Classification loss: 0.60378 | Regression loss: 0.52244 | Running loss: 1.19301\n",
      "Epoch: 0 | Iteration: 145 | Classification loss: 0.65087 | Regression loss: 0.92528 | Running loss: 1.19563\n",
      "Epoch: 0 | Iteration: 146 | Classification loss: 0.55835 | Regression loss: 0.86110 | Running loss: 1.19715\n",
      "Epoch: 0 | Iteration: 147 | Classification loss: 0.70433 | Regression loss: 0.98552 | Running loss: 1.20048\n",
      "Epoch: 0 | Iteration: 148 | Classification loss: 0.05491 | Regression loss: 0.00000 | Running loss: 1.19279\n",
      "Epoch: 0 | Iteration: 149 | Classification loss: 0.98181 | Regression loss: 1.02256 | Running loss: 1.19820\n",
      "Epoch: 0 | Iteration: 150 | Classification loss: 0.00078 | Regression loss: 0.00000 | Running loss: 1.19027\n",
      "Epoch: 0 | Iteration: 151 | Classification loss: 0.44654 | Regression loss: 0.81808 | Running loss: 1.19076\n",
      "Epoch: 0 | Iteration: 152 | Classification loss: 0.43777 | Regression loss: 0.00000 | Running loss: 1.18584\n",
      "Epoch: 0 | Iteration: 153 | Classification loss: 0.17703 | Regression loss: 0.00000 | Running loss: 1.17929\n",
      "Epoch: 0 | Iteration: 154 | Classification loss: 0.00054 | Regression loss: 0.00000 | Running loss: 1.17169\n",
      "Epoch: 0 | Iteration: 155 | Classification loss: 0.49914 | Regression loss: 1.02169 | Running loss: 1.17392\n",
      "Epoch: 0 | Iteration: 156 | Classification loss: 0.49640 | Regression loss: 0.97780 | Running loss: 1.17584\n",
      "Epoch: 0 | Iteration: 157 | Classification loss: 0.62376 | Regression loss: 0.78170 | Running loss: 1.17729\n",
      "Epoch: 0 | Iteration: 158 | Classification loss: 0.30189 | Regression loss: 1.01413 | Running loss: 1.17816\n",
      "Epoch: 0 | Iteration: 159 | Classification loss: 0.00043 | Regression loss: 0.00000 | Running loss: 1.17080\n",
      "Epoch: 0 | Iteration: 160 | Classification loss: 0.53719 | Regression loss: 0.84142 | Running loss: 1.17209\n",
      "Epoch: 0 | Iteration: 161 | Classification loss: 0.92386 | Regression loss: 0.61300 | Running loss: 1.17434\n",
      "Epoch: 0 | Iteration: 162 | Classification loss: 0.31927 | Regression loss: 0.98193 | Running loss: 1.17512\n",
      "Epoch: 0 | Iteration: 163 | Classification loss: 2.40080 | Regression loss: 0.93928 | Running loss: 1.18832\n",
      "Epoch: 0 | Iteration: 164 | Classification loss: 59.39325 | Regression loss: 0.00000 | Running loss: 1.54108\n",
      "Epoch: 0 | Iteration: 165 | Classification loss: 0.01271 | Regression loss: 0.00000 | Running loss: 1.53187\n",
      "Epoch: 0 | Iteration: 166 | Classification loss: 0.23120 | Regression loss: 0.85012 | Running loss: 1.52917\n",
      "Epoch: 0 | Iteration: 167 | Classification loss: 0.11353 | Regression loss: 0.45904 | Running loss: 1.52348\n",
      "Epoch: 0 | Iteration: 168 | Classification loss: 0.00043 | Regression loss: 0.00000 | Running loss: 1.51447\n",
      "Epoch: 0 | Iteration: 169 | Classification loss: 0.00014 | Regression loss: 0.00000 | Running loss: 1.50556\n",
      "Epoch: 0 | Iteration: 170 | Classification loss: 0.92011 | Regression loss: 0.97243 | Running loss: 1.50782\n",
      "Epoch: 0 | Iteration: 171 | Classification loss: 0.83347 | Regression loss: 0.98295 | Running loss: 1.50962\n",
      "Epoch: 0 | Iteration: 172 | Classification loss: 0.54205 | Regression loss: 1.02415 | Running loss: 1.50995\n",
      "Epoch: 0 | Iteration: 173 | Classification loss: 0.07723 | Regression loss: 0.00000 | Running loss: 1.50171\n",
      "Epoch: 0 | Iteration: 174 | Classification loss: 0.00122 | Regression loss: 0.00000 | Running loss: 1.49314\n",
      "Epoch: 0 | Iteration: 175 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.48465\n",
      "Epoch: 0 | Iteration: 176 | Classification loss: 0.00011 | Regression loss: 0.00000 | Running loss: 1.47627\n",
      "Epoch: 0 | Iteration: 177 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.46797\n",
      "Epoch: 0 | Iteration: 178 | Classification loss: 1.42097 | Regression loss: 1.13356 | Running loss: 1.47404\n",
      "Epoch: 0 | Iteration: 179 | Classification loss: 0.84860 | Regression loss: 0.87208 | Running loss: 1.47541\n",
      "Epoch: 0 | Iteration: 180 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.46726\n",
      "Epoch: 0 | Iteration: 181 | Classification loss: 1.90192 | Regression loss: 1.08189 | Running loss: 1.47559\n",
      "Epoch: 0 | Iteration: 182 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.46753\n",
      "Epoch: 0 | Iteration: 183 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.45956\n",
      "Epoch: 0 | Iteration: 184 | Classification loss: 1.53973 | Regression loss: 0.94056 | Running loss: 1.46507\n",
      "Epoch: 0 | Iteration: 185 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.45720\n",
      "Epoch: 0 | Iteration: 186 | Classification loss: 1.62944 | Regression loss: 1.00147 | Running loss: 1.46347\n",
      "Epoch: 0 | Iteration: 187 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.45569\n",
      "Epoch: 0 | Iteration: 188 | Classification loss: 0.69338 | Regression loss: 0.69343 | Running loss: 1.45532\n",
      "Epoch: 0 | Iteration: 189 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.44766\n",
      "Epoch: 0 | Iteration: 190 | Classification loss: 0.40947 | Regression loss: 0.47690 | Running loss: 1.44473\n",
      "Epoch: 0 | Iteration: 191 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.43720\n",
      "Epoch: 0 | Iteration: 192 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.42975\n",
      "Epoch: 0 | Iteration: 193 | Classification loss: 0.17841 | Regression loss: 0.81788 | Running loss: 1.42752\n",
      "Epoch: 0 | Iteration: 194 | Classification loss: 0.44020 | Regression loss: 1.13273 | Running loss: 1.42827\n",
      "Epoch: 0 | Iteration: 195 | Classification loss: 14.96901 | Regression loss: 0.30780 | Running loss: 1.49892\n",
      "Epoch: 0 | Iteration: 196 | Classification loss: 1.26322 | Regression loss: 0.00000 | Running loss: 1.49773\n",
      "Epoch: 0 | Iteration: 197 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.49016\n",
      "Epoch: 0 | Iteration: 198 | Classification loss: 0.00016 | Regression loss: 0.00000 | Running loss: 1.48267\n",
      "Epoch: 0 | Iteration: 199 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 1.47526\n",
      "Epoch: 0 | Iteration: 200 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.46792\n",
      "Epoch: 0 | Iteration: 201 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.46065\n",
      "Epoch: 0 | Iteration: 202 | Classification loss: 0.75485 | Regression loss: 0.84310 | Running loss: 1.46133\n",
      "Epoch: 0 | Iteration: 203 | Classification loss: 0.00261 | Regression loss: 0.00000 | Running loss: 1.45418\n",
      "Epoch: 0 | Iteration: 204 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.44709\n",
      "Epoch: 0 | Iteration: 205 | Classification loss: 0.00024 | Regression loss: 0.00000 | Running loss: 1.44006\n",
      "Epoch: 0 | Iteration: 206 | Classification loss: 0.82439 | Regression loss: 0.51275 | Running loss: 1.43957\n",
      "Epoch: 0 | Iteration: 207 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.43265\n",
      "Epoch: 0 | Iteration: 208 | Classification loss: 1.17347 | Regression loss: 0.89609 | Running loss: 1.43569\n",
      "Epoch: 0 | Iteration: 209 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.42886\n",
      "Epoch: 0 | Iteration: 210 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.42208\n",
      "Epoch: 0 | Iteration: 211 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.41538\n",
      "Epoch: 0 | Iteration: 212 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 1.40873\n",
      "Epoch: 0 | Iteration: 213 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.40215\n",
      "Epoch: 0 | Iteration: 214 | Classification loss: 0.78126 | Regression loss: 0.53018 | Running loss: 1.40173\n",
      "Epoch: 0 | Iteration: 215 | Classification loss: 0.00011 | Regression loss: 0.00000 | Running loss: 1.39524\n",
      "Epoch: 0 | Iteration: 216 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.38881\n",
      "Epoch: 0 | Iteration: 217 | Classification loss: 1.69992 | Regression loss: 1.05937 | Running loss: 1.39510\n",
      "Epoch: 0 | Iteration: 218 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.38873\n",
      "Epoch: 0 | Iteration: 219 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.38241\n",
      "Epoch: 0 | Iteration: 220 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.37616\n",
      "Epoch: 0 | Iteration: 221 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.36996\n",
      "Epoch: 0 | Iteration: 222 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.36382\n",
      "Epoch: 0 | Iteration: 223 | Classification loss: 1.70968 | Regression loss: 0.96290 | Running loss: 1.36966\n",
      "Epoch: 0 | Iteration: 224 | Classification loss: 1.77349 | Regression loss: 1.00579 | Running loss: 1.37592\n",
      "Epoch: 0 | Iteration: 225 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.36983\n",
      "Epoch: 0 | Iteration: 226 | Classification loss: 0.00016 | Regression loss: 0.00000 | Running loss: 1.36380\n",
      "Epoch: 0 | Iteration: 227 | Classification loss: 1.20863 | Regression loss: 0.85004 | Running loss: 1.36685\n",
      "Epoch: 0 | Iteration: 228 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.36088\n",
      "Epoch: 0 | Iteration: 229 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.35496\n",
      "Epoch: 0 | Iteration: 230 | Classification loss: 0.00037 | Regression loss: 0.00000 | Running loss: 1.34910\n",
      "Epoch: 0 | Iteration: 231 | Classification loss: 0.00009 | Regression loss: 0.00000 | Running loss: 1.34328\n",
      "Epoch: 0 | Iteration: 232 | Classification loss: 0.00031 | Regression loss: 0.00000 | Running loss: 1.33752\n",
      "Epoch: 0 | Iteration: 233 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.33181\n",
      "Epoch: 0 | Iteration: 234 | Classification loss: 1.19489 | Regression loss: 0.88834 | Running loss: 1.33500\n",
      "Epoch: 0 | Iteration: 235 | Classification loss: 0.80572 | Regression loss: 0.40112 | Running loss: 1.33446\n",
      "Epoch: 0 | Iteration: 236 | Classification loss: 1.43915 | Regression loss: 0.90536 | Running loss: 1.33872\n",
      "Epoch: 0 | Iteration: 237 | Classification loss: 1.17530 | Regression loss: 0.87843 | Running loss: 1.34173\n",
      "Epoch: 0 | Iteration: 238 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.33611\n",
      "Epoch: 0 | Iteration: 239 | Classification loss: 1.37789 | Regression loss: 0.61821 | Running loss: 1.33886\n",
      "Epoch: 0 | Iteration: 240 | Classification loss: 0.94424 | Regression loss: 0.95018 | Running loss: 1.34117\n",
      "Epoch: 0 | Iteration: 241 | Classification loss: 0.00066 | Regression loss: 0.00000 | Running loss: 1.33563\n",
      "Epoch: 0 | Iteration: 242 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 1.33013\n",
      "Epoch: 0 | Iteration: 243 | Classification loss: 0.53828 | Regression loss: 0.43358 | Running loss: 1.32866\n",
      "Epoch: 0 | Iteration: 244 | Classification loss: 0.00028 | Regression loss: 0.00000 | Running loss: 1.32324\n",
      "Epoch: 0 | Iteration: 245 | Classification loss: 0.96323 | Regression loss: 1.06100 | Running loss: 1.32609\n",
      "Epoch: 0 | Iteration: 246 | Classification loss: 0.82420 | Regression loss: 0.86084 | Running loss: 1.32754\n",
      "Epoch: 0 | Iteration: 247 | Classification loss: 0.00152 | Regression loss: 0.00000 | Running loss: 1.32220\n",
      "Epoch: 0 | Iteration: 248 | Classification loss: 0.02571 | Regression loss: 0.00000 | Running loss: 1.31699\n",
      "Epoch: 0 | Iteration: 249 | Classification loss: 0.27966 | Regression loss: 0.35274 | Running loss: 1.31425\n",
      "Epoch: 0 | Iteration: 250 | Classification loss: 0.54926 | Regression loss: 0.47812 | Running loss: 1.31311\n",
      "Epoch: 0 | Iteration: 251 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.30790\n",
      "Epoch: 0 | Iteration: 252 | Classification loss: 0.51382 | Regression loss: 0.94407 | Running loss: 1.30849\n",
      "Epoch: 0 | Iteration: 253 | Classification loss: 0.29839 | Regression loss: 0.75277 | Running loss: 1.30748\n",
      "Epoch: 0 | Iteration: 254 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.30235\n",
      "Epoch: 0 | Iteration: 255 | Classification loss: 0.69942 | Regression loss: 0.69502 | Running loss: 1.30271\n",
      "Epoch: 0 | Iteration: 256 | Classification loss: 0.55858 | Regression loss: 0.45633 | Running loss: 1.30159\n",
      "Epoch: 0 | Iteration: 257 | Classification loss: 0.00012 | Regression loss: 0.00000 | Running loss: 1.29655\n",
      "Epoch: 0 | Iteration: 258 | Classification loss: 1.45407 | Regression loss: 1.08449 | Running loss: 1.30134\n",
      "Epoch: 0 | Iteration: 259 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.29634\n",
      "Epoch: 0 | Iteration: 260 | Classification loss: 0.13040 | Regression loss: 0.36600 | Running loss: 1.29327\n",
      "Epoch: 0 | Iteration: 261 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28834\n",
      "Epoch: 0 | Iteration: 262 | Classification loss: 0.50814 | Regression loss: 0.79735 | Running loss: 1.28840\n",
      "Epoch: 0 | Iteration: 263 | Classification loss: 0.66105 | Regression loss: 0.84701 | Running loss: 1.28923\n",
      "Epoch: 0 | Iteration: 264 | Classification loss: 0.94113 | Regression loss: 0.95614 | Running loss: 1.29153\n",
      "Epoch: 0 | Iteration: 265 | Classification loss: 0.85387 | Regression loss: 0.89754 | Running loss: 1.29326\n",
      "Epoch: 0 | Iteration: 266 | Classification loss: 0.67743 | Regression loss: 0.88726 | Running loss: 1.29427\n",
      "Epoch: 0 | Iteration: 267 | Classification loss: 0.39835 | Regression loss: 0.74937 | Running loss: 1.29373\n",
      "Epoch: 0 | Iteration: 268 | Classification loss: 1.34345 | Regression loss: 0.64731 | Running loss: 1.29632\n",
      "Epoch: 0 | Iteration: 269 | Classification loss: 0.40683 | Regression loss: 1.08567 | Running loss: 1.29704\n",
      "Epoch: 0 | Iteration: 270 | Classification loss: 1.27803 | Regression loss: 0.29084 | Running loss: 1.29805\n",
      "Epoch: 0 | Iteration: 271 | Classification loss: 19.65166 | Regression loss: 0.00000 | Running loss: 1.36552\n",
      "Evaluating dataset\n",
      "0/231\n",
      "1/231\n",
      "2/231\n",
      "3/231\n",
      "4/231\n",
      "5/231\n",
      "6/231\n",
      "7/231\n",
      "8/231\n",
      "9/231\n",
      "10/231\n",
      "11/231\n",
      "12/231\n",
      "13/231\n",
      "14/231\n",
      "15/231\n",
      "16/231\n",
      "17/231\n",
      "18/231\n",
      "19/231\n",
      "20/231\n",
      "21/231\n",
      "22/231\n",
      "23/231\n",
      "24/231\n",
      "25/231\n",
      "26/231\n",
      "27/231\n",
      "28/231\n",
      "29/231\n",
      "30/231\n",
      "31/231\n",
      "32/231\n",
      "33/231\n",
      "34/231\n",
      "35/231\n",
      "36/231\n",
      "37/231\n",
      "38/231\n",
      "39/231\n",
      "40/231\n",
      "41/231\n",
      "42/231\n",
      "43/231\n",
      "44/231\n",
      "45/231\n",
      "46/231\n",
      "47/231\n",
      "48/231\n",
      "49/231\n",
      "50/231\n",
      "51/231\n",
      "52/231\n",
      "53/231\n",
      "54/231\n",
      "55/231\n",
      "56/231\n",
      "57/231\n",
      "58/231\n",
      "59/231\n",
      "60/231\n",
      "61/231\n",
      "62/231\n",
      "63/231\n",
      "64/231\n",
      "65/231\n",
      "66/231\n",
      "67/231\n",
      "68/231\n",
      "69/231\n",
      "70/231\n",
      "71/231\n",
      "72/231\n",
      "73/231\n",
      "74/231\n",
      "75/231\n",
      "76/231\n",
      "77/231\n",
      "78/231\n",
      "79/231\n",
      "80/231\n",
      "81/231\n",
      "82/231\n",
      "83/231\n",
      "84/231\n",
      "85/231\n",
      "86/231\n",
      "87/231\n",
      "88/231\n",
      "89/231\n",
      "90/231\n",
      "91/231\n",
      "92/231\n",
      "93/231\n",
      "94/231\n",
      "95/231\n",
      "96/231\n",
      "97/231\n",
      "98/231\n",
      "99/231\n",
      "100/231\n",
      "101/231\n",
      "102/231\n",
      "103/231\n",
      "104/231\n",
      "105/231\n",
      "106/231\n",
      "107/231\n",
      "108/231\n",
      "109/231\n",
      "110/231\n",
      "111/231\n",
      "112/231\n",
      "113/231\n",
      "114/231\n",
      "115/231\n",
      "116/231\n",
      "117/231\n",
      "118/231\n",
      "119/231\n",
      "120/231\n",
      "121/231\n",
      "122/231\n",
      "123/231\n",
      "124/231\n",
      "125/231\n",
      "126/231\n",
      "127/231\n",
      "128/231\n",
      "129/231\n",
      "130/231\n",
      "131/231\n",
      "132/231\n",
      "133/231\n",
      "134/231\n",
      "135/231\n",
      "136/231\n",
      "137/231\n",
      "138/231\n",
      "139/231\n",
      "140/231\n",
      "141/231\n",
      "142/231\n",
      "143/231\n",
      "144/231\n",
      "145/231\n",
      "146/231\n",
      "147/231\n",
      "148/231\n",
      "149/231\n",
      "150/231\n",
      "151/231\n",
      "152/231\n",
      "153/231\n",
      "154/231\n",
      "155/231\n",
      "156/231\n",
      "157/231\n",
      "158/231\n",
      "159/231\n",
      "160/231\n",
      "161/231\n",
      "162/231\n",
      "163/231\n",
      "164/231\n",
      "165/231\n",
      "166/231\n",
      "167/231\n",
      "168/231\n",
      "169/231\n",
      "170/231\n",
      "171/231\n",
      "172/231\n",
      "173/231\n",
      "174/231\n",
      "175/231\n",
      "176/231\n",
      "177/231\n",
      "178/231\n",
      "179/231\n",
      "180/231\n",
      "181/231\n",
      "182/231\n",
      "183/231\n",
      "184/231\n",
      "185/231\n",
      "186/231\n",
      "187/231\n",
      "188/231\n",
      "189/231\n",
      "190/231\n",
      "191/231\n",
      "192/231\n",
      "193/231\n",
      "194/231\n",
      "195/231\n",
      "196/231\n",
      "197/231\n",
      "198/231\n",
      "199/231\n",
      "200/231\n",
      "201/231\n",
      "202/231\n",
      "203/231\n",
      "204/231\n",
      "205/231\n",
      "206/231\n",
      "207/231\n",
      "208/231\n",
      "209/231\n",
      "210/231\n",
      "211/231\n",
      "212/231\n",
      "213/231\n",
      "214/231\n",
      "215/231\n",
      "216/231\n",
      "217/231\n",
      "218/231\n",
      "219/231\n",
      "220/231\n",
      "221/231\n",
      "222/231\n",
      "223/231\n",
      "224/231\n",
      "225/231\n",
      "226/231\n",
      "227/231\n",
      "228/231\n",
      "229/231\n",
      "230/231\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 1 | Iteration: 0 | Classification loss: 0.58430 | Regression loss: 1.01665 | Running loss: 1.36639\n",
      "Epoch: 1 | Iteration: 1 | Classification loss: 2.21448 | Regression loss: 0.00000 | Running loss: 1.36948\n",
      "Epoch: 1 | Iteration: 2 | Classification loss: 5.19181 | Regression loss: 0.44751 | Running loss: 1.38501\n",
      "Epoch: 1 | Iteration: 3 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.37999\n",
      "Epoch: 1 | Iteration: 4 | Classification loss: 0.57056 | Regression loss: 0.91440 | Running loss: 1.38037\n",
      "Epoch: 1 | Iteration: 5 | Classification loss: 0.41173 | Regression loss: 0.76238 | Running loss: 1.37963\n",
      "Epoch: 1 | Iteration: 6 | Classification loss: 0.00307 | Regression loss: 0.00000 | Running loss: 1.37469\n",
      "Epoch: 1 | Iteration: 7 | Classification loss: 0.02660 | Regression loss: 0.00000 | Running loss: 1.36988\n",
      "Epoch: 1 | Iteration: 8 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.36500\n",
      "Epoch: 1 | Iteration: 9 | Classification loss: 0.00014 | Regression loss: 0.00000 | Running loss: 1.36016\n",
      "Epoch: 1 | Iteration: 10 | Classification loss: 1.12669 | Regression loss: 0.83474 | Running loss: 1.36229\n",
      "Epoch: 1 | Iteration: 11 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.35749\n",
      "Epoch: 1 | Iteration: 12 | Classification loss: 0.93089 | Regression loss: 0.67954 | Running loss: 1.35838\n",
      "Epoch: 1 | Iteration: 13 | Classification loss: 1.14479 | Regression loss: 0.90322 | Running loss: 1.36079\n",
      "Epoch: 1 | Iteration: 14 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.35605\n",
      "Epoch: 1 | Iteration: 15 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.35134\n",
      "Epoch: 1 | Iteration: 16 | Classification loss: 1.04358 | Regression loss: 0.68706 | Running loss: 1.35265\n",
      "Epoch: 1 | Iteration: 17 | Classification loss: 1.35672 | Regression loss: 1.00740 | Running loss: 1.35614\n",
      "Epoch: 1 | Iteration: 18 | Classification loss: 1.04255 | Regression loss: 1.00661 | Running loss: 1.35852\n",
      "Epoch: 1 | Iteration: 19 | Classification loss: 0.68060 | Regression loss: 0.55922 | Running loss: 1.35812\n",
      "Epoch: 1 | Iteration: 20 | Classification loss: 0.00363 | Regression loss: 0.00000 | Running loss: 1.35349\n",
      "Epoch: 1 | Iteration: 21 | Classification loss: 0.51771 | Regression loss: 0.42678 | Running loss: 1.35210\n",
      "Epoch: 1 | Iteration: 22 | Classification loss: 0.28286 | Regression loss: 0.33541 | Running loss: 1.34961\n",
      "Epoch: 1 | Iteration: 23 | Classification loss: 0.00495 | Regression loss: 0.00000 | Running loss: 1.34507\n",
      "Epoch: 1 | Iteration: 24 | Classification loss: 0.80308 | Regression loss: 0.62586 | Running loss: 1.34535\n",
      "Epoch: 1 | Iteration: 25 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.34084\n",
      "Epoch: 1 | Iteration: 26 | Classification loss: 0.58298 | Regression loss: 0.91047 | Running loss: 1.34135\n",
      "Epoch: 1 | Iteration: 27 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.33688\n",
      "Epoch: 1 | Iteration: 28 | Classification loss: 0.00369 | Regression loss: 0.00000 | Running loss: 1.33245\n",
      "Epoch: 1 | Iteration: 29 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.32804\n",
      "Epoch: 1 | Iteration: 30 | Classification loss: 0.27419 | Regression loss: 0.65875 | Running loss: 1.32673\n",
      "Epoch: 1 | Iteration: 31 | Classification loss: 0.38470 | Regression loss: 0.60936 | Running loss: 1.32564\n",
      "Epoch: 1 | Iteration: 32 | Classification loss: 0.09462 | Regression loss: 0.35665 | Running loss: 1.32277\n",
      "Epoch: 1 | Iteration: 33 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.31845\n",
      "Epoch: 1 | Iteration: 34 | Classification loss: 0.39727 | Regression loss: 0.61502 | Running loss: 1.31745\n",
      "Epoch: 1 | Iteration: 35 | Classification loss: 0.73459 | Regression loss: 0.00000 | Running loss: 1.31556\n",
      "Epoch: 1 | Iteration: 36 | Classification loss: 0.37071 | Regression loss: 0.55149 | Running loss: 1.31429\n",
      "Epoch: 1 | Iteration: 37 | Classification loss: 0.00041 | Regression loss: 0.00000 | Running loss: 1.31005\n",
      "Epoch: 1 | Iteration: 38 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.30584\n",
      "Epoch: 1 | Iteration: 39 | Classification loss: 0.69571 | Regression loss: 0.73854 | Running loss: 1.30625\n",
      "Epoch: 1 | Iteration: 40 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.30207\n",
      "Epoch: 1 | Iteration: 41 | Classification loss: 0.41499 | Regression loss: 0.45782 | Running loss: 1.30071\n",
      "Epoch: 1 | Iteration: 42 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.29658\n",
      "Epoch: 1 | Iteration: 43 | Classification loss: 4.57773 | Regression loss: 0.24188 | Running loss: 1.30773\n",
      "Epoch: 1 | Iteration: 44 | Classification loss: 0.05004 | Regression loss: 0.00000 | Running loss: 1.30376\n",
      "Epoch: 1 | Iteration: 45 | Classification loss: 0.00011 | Regression loss: 0.00000 | Running loss: 1.29966\n",
      "Epoch: 1 | Iteration: 46 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.29559\n",
      "Epoch: 1 | Iteration: 47 | Classification loss: 0.00980 | Regression loss: 0.00000 | Running loss: 1.29157\n",
      "Epoch: 1 | Iteration: 48 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.28754\n",
      "Epoch: 1 | Iteration: 49 | Classification loss: 0.65554 | Regression loss: 0.85074 | Running loss: 1.28822\n",
      "Epoch: 1 | Iteration: 50 | Classification loss: 0.96589 | Regression loss: 0.90306 | Running loss: 1.29002\n",
      "Epoch: 1 | Iteration: 51 | Classification loss: 0.94250 | Regression loss: 0.80052 | Running loss: 1.29142\n",
      "Epoch: 1 | Iteration: 52 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.28745\n",
      "Epoch: 1 | Iteration: 53 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28350\n",
      "Epoch: 1 | Iteration: 54 | Classification loss: 0.70765 | Regression loss: 0.82350 | Running loss: 1.28425\n",
      "Epoch: 1 | Iteration: 55 | Classification loss: 0.72563 | Regression loss: 0.98557 | Running loss: 1.28556\n",
      "Epoch: 1 | Iteration: 56 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28165\n",
      "Epoch: 1 | Iteration: 57 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.27776\n",
      "Epoch: 1 | Iteration: 58 | Classification loss: 0.76605 | Regression loss: 1.03098 | Running loss: 1.27933\n",
      "Epoch: 1 | Iteration: 59 | Classification loss: 0.97657 | Regression loss: 0.82855 | Running loss: 1.28092\n",
      "Epoch: 1 | Iteration: 60 | Classification loss: 0.44654 | Regression loss: 0.71463 | Running loss: 1.28056\n",
      "Epoch: 1 | Iteration: 61 | Classification loss: 0.61793 | Regression loss: 0.77883 | Running loss: 1.28091\n",
      "Epoch: 1 | Iteration: 62 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.27708\n",
      "Epoch: 1 | Iteration: 63 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.27328\n",
      "Epoch: 1 | Iteration: 64 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.26950\n",
      "Epoch: 1 | Iteration: 65 | Classification loss: 0.00128 | Regression loss: 0.00000 | Running loss: 1.26575\n",
      "Epoch: 1 | Iteration: 66 | Classification loss: 1.45596 | Regression loss: 0.68649 | Running loss: 1.26834\n",
      "Epoch: 1 | Iteration: 67 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.26461\n",
      "Epoch: 1 | Iteration: 68 | Classification loss: 5.38928 | Regression loss: 0.00000 | Running loss: 1.27670\n",
      "Epoch: 1 | Iteration: 69 | Classification loss: 0.51103 | Regression loss: 0.64916 | Running loss: 1.27636\n",
      "Epoch: 1 | Iteration: 70 | Classification loss: 0.57604 | Regression loss: 0.00000 | Running loss: 1.27432\n",
      "Epoch: 1 | Iteration: 71 | Classification loss: 1.01402 | Regression loss: 0.94855 | Running loss: 1.27632\n",
      "Epoch: 1 | Iteration: 72 | Classification loss: 0.31226 | Regression loss: 0.81626 | Running loss: 1.27589\n",
      "Epoch: 1 | Iteration: 73 | Classification loss: 0.00029 | Regression loss: 0.00000 | Running loss: 1.27221\n",
      "Epoch: 1 | Iteration: 74 | Classification loss: 0.55406 | Regression loss: 0.81522 | Running loss: 1.27248\n",
      "Epoch: 1 | Iteration: 75 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.26883\n",
      "Epoch: 1 | Iteration: 76 | Classification loss: 0.30869 | Regression loss: 0.32263 | Running loss: 1.26700\n",
      "Epoch: 1 | Iteration: 77 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.26338\n",
      "Epoch: 1 | Iteration: 78 | Classification loss: 0.00032 | Regression loss: 0.00000 | Running loss: 1.25978\n",
      "Epoch: 1 | Iteration: 79 | Classification loss: 0.66146 | Regression loss: 0.78782 | Running loss: 1.26032\n",
      "Epoch: 1 | Iteration: 80 | Classification loss: 0.57756 | Regression loss: 0.77466 | Running loss: 1.26058\n",
      "Epoch: 1 | Iteration: 81 | Classification loss: 0.47416 | Regression loss: 0.43373 | Running loss: 1.25959\n",
      "Epoch: 1 | Iteration: 82 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.25604\n",
      "Epoch: 1 | Iteration: 83 | Classification loss: 0.42886 | Regression loss: 0.63852 | Running loss: 1.25551\n",
      "Epoch: 1 | Iteration: 84 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.25199\n",
      "Epoch: 1 | Iteration: 85 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.24849\n",
      "Epoch: 1 | Iteration: 86 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.24502\n",
      "Epoch: 1 | Iteration: 87 | Classification loss: 0.95898 | Regression loss: 0.87955 | Running loss: 1.24666\n",
      "Epoch: 1 | Iteration: 88 | Classification loss: 0.94295 | Regression loss: 0.77769 | Running loss: 1.24798\n",
      "Epoch: 1 | Iteration: 89 | Classification loss: 0.20371 | Regression loss: 0.37458 | Running loss: 1.24613\n",
      "Epoch: 1 | Iteration: 90 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.24269\n",
      "Epoch: 1 | Iteration: 91 | Classification loss: 13.66017 | Regression loss: 0.00000 | Running loss: 1.27681\n",
      "Epoch: 1 | Iteration: 92 | Classification loss: 7.64973 | Regression loss: 0.43386 | Running loss: 1.29546\n",
      "Epoch: 1 | Iteration: 93 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.29192\n",
      "Epoch: 1 | Iteration: 94 | Classification loss: 1.97588 | Regression loss: 0.00000 | Running loss: 1.29378\n",
      "Epoch: 1 | Iteration: 95 | Classification loss: 0.25713 | Regression loss: 0.51224 | Running loss: 1.29236\n",
      "Epoch: 1 | Iteration: 96 | Classification loss: 0.28340 | Regression loss: 0.86957 | Running loss: 1.29198\n",
      "Epoch: 1 | Iteration: 97 | Classification loss: 1.28814 | Regression loss: 0.74142 | Running loss: 1.29397\n",
      "Epoch: 1 | Iteration: 98 | Classification loss: 0.16783 | Regression loss: 0.32986 | Running loss: 1.29183\n",
      "Epoch: 1 | Iteration: 99 | Classification loss: 0.00012 | Regression loss: 0.00000 | Running loss: 1.28835\n",
      "Epoch: 1 | Iteration: 100 | Classification loss: 0.49354 | Regression loss: 0.70789 | Running loss: 1.28812\n",
      "Epoch: 1 | Iteration: 101 | Classification loss: 0.20538 | Regression loss: 0.34751 | Running loss: 1.28615\n",
      "Epoch: 1 | Iteration: 102 | Classification loss: 0.09134 | Regression loss: 0.37340 | Running loss: 1.28396\n",
      "Epoch: 1 | Iteration: 103 | Classification loss: 0.07518 | Regression loss: 0.00000 | Running loss: 1.28075\n",
      "Epoch: 1 | Iteration: 104 | Classification loss: 0.40268 | Regression loss: 0.62839 | Running loss: 1.28009\n",
      "Epoch: 1 | Iteration: 105 | Classification loss: 0.28395 | Regression loss: 0.69812 | Running loss: 1.27930\n",
      "Epoch: 1 | Iteration: 106 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.27592\n",
      "Epoch: 1 | Iteration: 107 | Classification loss: 1.16928 | Regression loss: 0.47101 | Running loss: 1.27688\n",
      "Epoch: 1 | Iteration: 108 | Classification loss: 0.09681 | Regression loss: 0.00000 | Running loss: 1.27379\n",
      "Epoch: 1 | Iteration: 109 | Classification loss: 0.39767 | Regression loss: 0.77538 | Running loss: 1.27352\n",
      "Epoch: 1 | Iteration: 110 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.27020\n",
      "Epoch: 1 | Iteration: 111 | Classification loss: 0.35837 | Regression loss: 0.75014 | Running loss: 1.26978\n",
      "Epoch: 1 | Iteration: 112 | Classification loss: 0.41593 | Regression loss: 0.91835 | Running loss: 1.26994\n",
      "Epoch: 1 | Iteration: 113 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.26665\n",
      "Epoch: 1 | Iteration: 114 | Classification loss: 0.39382 | Regression loss: 0.70250 | Running loss: 1.26621\n",
      "Epoch: 1 | Iteration: 115 | Classification loss: 0.32026 | Regression loss: 0.67467 | Running loss: 1.26551\n",
      "Epoch: 1 | Iteration: 116 | Classification loss: 0.45867 | Regression loss: 0.72549 | Running loss: 1.26530\n",
      "Epoch: 1 | Iteration: 117 | Classification loss: 0.97522 | Regression loss: 1.05132 | Running loss: 1.26726\n",
      "Epoch: 1 | Iteration: 118 | Classification loss: 0.00148 | Regression loss: 0.00000 | Running loss: 1.26402\n",
      "Epoch: 1 | Iteration: 119 | Classification loss: 0.00686 | Regression loss: 0.00000 | Running loss: 1.26081\n",
      "Epoch: 1 | Iteration: 120 | Classification loss: 0.85092 | Regression loss: 1.04328 | Running loss: 1.26242\n",
      "Epoch: 1 | Iteration: 121 | Classification loss: 0.35832 | Regression loss: 0.34159 | Running loss: 1.26100\n",
      "Epoch: 1 | Iteration: 122 | Classification loss: 1.08458 | Regression loss: 0.00000 | Running loss: 1.26055\n",
      "Epoch: 1 | Iteration: 123 | Classification loss: 0.38927 | Regression loss: 1.14052 | Running loss: 1.26123\n",
      "Epoch: 1 | Iteration: 124 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.25805\n",
      "Epoch: 1 | Iteration: 125 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.25489\n",
      "Epoch: 1 | Iteration: 126 | Classification loss: 0.66230 | Regression loss: 0.64951 | Running loss: 1.25503\n",
      "Epoch: 1 | Iteration: 127 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.25190\n",
      "Epoch: 1 | Iteration: 128 | Classification loss: 0.71541 | Regression loss: 0.85895 | Running loss: 1.25270\n",
      "Epoch: 1 | Iteration: 129 | Classification loss: 0.42493 | Regression loss: 0.56331 | Running loss: 1.25204\n",
      "Epoch: 1 | Iteration: 130 | Classification loss: 0.00025 | Regression loss: 0.00000 | Running loss: 1.24894\n",
      "Epoch: 1 | Iteration: 131 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.24585\n",
      "Epoch: 1 | Iteration: 132 | Classification loss: 0.70205 | Regression loss: 0.85437 | Running loss: 1.24661\n",
      "Epoch: 1 | Iteration: 133 | Classification loss: 0.71187 | Regression loss: 0.82156 | Running loss: 1.24732\n",
      "Epoch: 1 | Iteration: 134 | Classification loss: 0.95224 | Regression loss: 0.59344 | Running loss: 1.24805\n",
      "Epoch: 1 | Iteration: 135 | Classification loss: 1.53148 | Regression loss: 0.76185 | Running loss: 1.25061\n",
      "Epoch: 1 | Iteration: 136 | Classification loss: 0.13424 | Regression loss: 0.44215 | Running loss: 1.24896\n",
      "Epoch: 1 | Iteration: 137 | Classification loss: 1.12665 | Regression loss: 0.00000 | Running loss: 1.24867\n",
      "Epoch: 1 | Iteration: 138 | Classification loss: 8.63825 | Regression loss: 0.00000 | Running loss: 1.26665\n",
      "Epoch: 1 | Iteration: 139 | Classification loss: 1.34624 | Regression loss: 0.90351 | Running loss: 1.26903\n",
      "Epoch: 1 | Iteration: 140 | Classification loss: 0.61388 | Regression loss: 0.00000 | Running loss: 1.26745\n",
      "Epoch: 1 | Iteration: 141 | Classification loss: 0.46606 | Regression loss: 0.92822 | Running loss: 1.26775\n",
      "Epoch: 1 | Iteration: 142 | Classification loss: 0.07838 | Regression loss: 0.00000 | Running loss: 1.26489\n",
      "Epoch: 1 | Iteration: 143 | Classification loss: 0.22972 | Regression loss: 0.70273 | Running loss: 1.26409\n",
      "Epoch: 1 | Iteration: 144 | Classification loss: 0.16378 | Regression loss: 0.49805 | Running loss: 1.26264\n",
      "Epoch: 1 | Iteration: 145 | Classification loss: 0.63180 | Regression loss: 0.85692 | Running loss: 1.26318\n",
      "Epoch: 1 | Iteration: 146 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.26017\n",
      "Epoch: 1 | Iteration: 147 | Classification loss: 0.04934 | Regression loss: 0.00000 | Running loss: 1.25729\n",
      "Epoch: 1 | Iteration: 148 | Classification loss: 0.00130 | Regression loss: 0.00000 | Running loss: 1.25430\n",
      "Epoch: 1 | Iteration: 149 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.25133\n",
      "Epoch: 1 | Iteration: 150 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.24837\n",
      "Epoch: 1 | Iteration: 151 | Classification loss: 0.66967 | Regression loss: 0.94132 | Running loss: 1.24923\n",
      "Epoch: 1 | Iteration: 152 | Classification loss: 0.40133 | Regression loss: 0.60139 | Running loss: 1.24865\n",
      "Epoch: 1 | Iteration: 153 | Classification loss: 0.83903 | Regression loss: 0.91986 | Running loss: 1.24985\n",
      "Epoch: 1 | Iteration: 154 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.24692\n",
      "Epoch: 1 | Iteration: 155 | Classification loss: 0.00022 | Regression loss: 0.00000 | Running loss: 1.24401\n",
      "Epoch: 1 | Iteration: 156 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.24111\n",
      "Epoch: 1 | Iteration: 157 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.23822\n",
      "Epoch: 1 | Iteration: 158 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.23535\n",
      "Epoch: 1 | Iteration: 159 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23249\n",
      "Epoch: 1 | Iteration: 160 | Classification loss: 1.46397 | Regression loss: 0.80121 | Running loss: 1.23487\n",
      "Epoch: 1 | Iteration: 161 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.23203\n",
      "Epoch: 1 | Iteration: 162 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.22919\n",
      "Epoch: 1 | Iteration: 163 | Classification loss: 0.59787 | Regression loss: 0.75798 | Running loss: 1.22949\n",
      "Epoch: 1 | Iteration: 164 | Classification loss: 0.27208 | Regression loss: 0.55636 | Running loss: 1.22857\n",
      "Epoch: 1 | Iteration: 165 | Classification loss: 0.42294 | Regression loss: 0.77008 | Running loss: 1.22849\n",
      "Epoch: 1 | Iteration: 166 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.22569\n",
      "Epoch: 1 | Iteration: 167 | Classification loss: 0.24239 | Regression loss: 0.94736 | Running loss: 1.22561\n",
      "Epoch: 1 | Iteration: 168 | Classification loss: 1.03062 | Regression loss: 0.22807 | Running loss: 1.22568\n",
      "Epoch: 1 | Iteration: 169 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.22291\n",
      "Epoch: 1 | Iteration: 170 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.22015\n",
      "Epoch: 1 | Iteration: 171 | Classification loss: 0.08811 | Regression loss: 0.00000 | Running loss: 1.21760\n",
      "Epoch: 1 | Iteration: 172 | Classification loss: 0.36366 | Regression loss: 1.07782 | Running loss: 1.21810\n",
      "Epoch: 1 | Iteration: 173 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.21537\n",
      "Epoch: 1 | Iteration: 174 | Classification loss: 0.29415 | Regression loss: 0.96351 | Running loss: 1.21546\n",
      "Epoch: 1 | Iteration: 175 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.21275\n",
      "Epoch: 1 | Iteration: 176 | Classification loss: 0.00218 | Regression loss: 0.00000 | Running loss: 1.21006\n",
      "Epoch: 1 | Iteration: 177 | Classification loss: 0.54588 | Regression loss: 0.92074 | Running loss: 1.21063\n",
      "Epoch: 1 | Iteration: 178 | Classification loss: 0.31284 | Regression loss: 0.87239 | Running loss: 1.21057\n",
      "Epoch: 1 | Iteration: 179 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.20789\n",
      "Epoch: 1 | Iteration: 180 | Classification loss: 1.15090 | Regression loss: 0.65917 | Running loss: 1.20922\n",
      "Epoch: 1 | Iteration: 181 | Classification loss: 0.98074 | Regression loss: 0.91335 | Running loss: 1.21073\n",
      "Epoch: 1 | Iteration: 182 | Classification loss: 0.17653 | Regression loss: 0.32635 | Running loss: 1.20917\n",
      "Epoch: 1 | Iteration: 183 | Classification loss: 1.17959 | Regression loss: 0.68873 | Running loss: 1.21062\n",
      "Epoch: 1 | Iteration: 184 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.20797\n",
      "Epoch: 1 | Iteration: 185 | Classification loss: 1.68496 | Regression loss: 0.00000 | Running loss: 1.20901\n",
      "Epoch: 1 | Iteration: 186 | Classification loss: 0.22241 | Regression loss: 0.35854 | Running loss: 1.20764\n",
      "Epoch: 1 | Iteration: 187 | Classification loss: 0.84384 | Regression loss: 0.68100 | Running loss: 1.20833\n",
      "Epoch: 1 | Iteration: 188 | Classification loss: 0.55733 | Regression loss: 0.46336 | Running loss: 1.20793\n",
      "Epoch: 1 | Iteration: 189 | Classification loss: 6.53348 | Regression loss: 0.96963 | Running loss: 1.22155\n",
      "Epoch: 1 | Iteration: 190 | Classification loss: 3.59015 | Regression loss: 0.65344 | Running loss: 1.22808\n",
      "Epoch: 1 | Iteration: 191 | Classification loss: 0.29346 | Regression loss: 0.00000 | Running loss: 1.22606\n",
      "Epoch: 1 | Iteration: 192 | Classification loss: 1.25601 | Regression loss: 0.00000 | Running loss: 1.22613\n",
      "Epoch: 1 | Iteration: 193 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.22350\n",
      "Epoch: 1 | Iteration: 194 | Classification loss: 0.75496 | Regression loss: 0.81234 | Running loss: 1.22423\n",
      "Epoch: 1 | Iteration: 195 | Classification loss: 0.26698 | Regression loss: 1.01246 | Running loss: 1.22435\n",
      "Epoch: 1 | Iteration: 196 | Classification loss: 0.26446 | Regression loss: 0.35461 | Running loss: 1.22306\n",
      "Epoch: 1 | Iteration: 197 | Classification loss: 0.22376 | Regression loss: 0.67863 | Running loss: 1.22238\n",
      "Epoch: 1 | Iteration: 198 | Classification loss: 1.04076 | Regression loss: 0.94936 | Running loss: 1.22401\n",
      "Epoch: 1 | Iteration: 199 | Classification loss: 0.34132 | Regression loss: 0.40828 | Running loss: 1.22300\n",
      "Epoch: 1 | Iteration: 200 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.22042\n",
      "Epoch: 1 | Iteration: 201 | Classification loss: 0.00351 | Regression loss: 0.00000 | Running loss: 1.21785\n",
      "Epoch: 1 | Iteration: 202 | Classification loss: 0.65360 | Regression loss: 1.13595 | Running loss: 1.21905\n",
      "Epoch: 1 | Iteration: 203 | Classification loss: 0.31291 | Regression loss: 0.61158 | Running loss: 1.21844\n",
      "Epoch: 1 | Iteration: 204 | Classification loss: 0.00126 | Regression loss: 0.00000 | Running loss: 1.21588\n",
      "Epoch: 1 | Iteration: 205 | Classification loss: 0.01279 | Regression loss: 0.00000 | Running loss: 1.21337\n",
      "Epoch: 1 | Iteration: 206 | Classification loss: 0.33731 | Regression loss: 0.00000 | Running loss: 1.21154\n",
      "Epoch: 1 | Iteration: 207 | Classification loss: 0.00927 | Regression loss: 0.00000 | Running loss: 1.20903\n",
      "Epoch: 1 | Iteration: 208 | Classification loss: 0.00185 | Regression loss: 0.00000 | Running loss: 1.20652\n",
      "Epoch: 1 | Iteration: 209 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 1.20402\n",
      "Epoch: 1 | Iteration: 210 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.20153\n",
      "Epoch: 1 | Iteration: 211 | Classification loss: 0.84330 | Regression loss: 0.83593 | Running loss: 1.20251\n",
      "Epoch: 1 | Iteration: 212 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.20004\n",
      "Epoch: 1 | Iteration: 213 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.19757\n",
      "Epoch: 1 | Iteration: 214 | Classification loss: 1.77556 | Regression loss: 0.95380 | Running loss: 1.20071\n",
      "Epoch: 1 | Iteration: 215 | Classification loss: 1.54766 | Regression loss: 0.66912 | Running loss: 1.20279\n",
      "Epoch: 1 | Iteration: 216 | Classification loss: 1.53635 | Regression loss: 0.85407 | Running loss: 1.20522\n",
      "Epoch: 1 | Iteration: 217 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.20276\n",
      "Epoch: 1 | Iteration: 218 | Classification loss: 1.15717 | Regression loss: 0.75964 | Running loss: 1.20422\n",
      "Epoch: 1 | Iteration: 219 | Classification loss: 0.67338 | Regression loss: 0.84694 | Running loss: 1.20486\n",
      "Epoch: 1 | Iteration: 220 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.20242\n",
      "Epoch: 1 | Iteration: 221 | Classification loss: 0.44720 | Regression loss: 0.42062 | Running loss: 1.20174\n",
      "Epoch: 1 | Iteration: 222 | Classification loss: 1.13209 | Regression loss: 0.91406 | Running loss: 1.20344\n",
      "Epoch: 1 | Iteration: 223 | Classification loss: 0.91434 | Regression loss: 0.85176 | Running loss: 1.20458\n",
      "Epoch: 1 | Iteration: 224 | Classification loss: 0.42419 | Regression loss: 0.49398 | Running loss: 1.20400\n",
      "Epoch: 1 | Iteration: 225 | Classification loss: 0.00009 | Regression loss: 0.00000 | Running loss: 1.20158\n",
      "Epoch: 1 | Iteration: 226 | Classification loss: 0.12225 | Regression loss: 0.00000 | Running loss: 1.19942\n",
      "Epoch: 1 | Iteration: 227 | Classification loss: 0.51024 | Regression loss: 0.73181 | Running loss: 1.19951\n",
      "Epoch: 1 | Iteration: 228 | Classification loss: 0.58505 | Regression loss: 0.00000 | Running loss: 1.19363\n",
      "Epoch: 1 | Iteration: 229 | Classification loss: 15.84375 | Regression loss: 0.38334 | Running loss: 1.22165\n",
      "Epoch: 1 | Iteration: 230 | Classification loss: 0.22307 | Regression loss: 0.70306 | Running loss: 1.21878\n",
      "Epoch: 1 | Iteration: 231 | Classification loss: 0.00026 | Regression loss: 0.00000 | Running loss: 1.21188\n",
      "Epoch: 1 | Iteration: 232 | Classification loss: 0.00216 | Regression loss: 0.00000 | Running loss: 1.20649\n",
      "Epoch: 1 | Iteration: 233 | Classification loss: 0.35582 | Regression loss: 0.79086 | Running loss: 1.20449\n",
      "Epoch: 1 | Iteration: 234 | Classification loss: 0.39475 | Regression loss: 0.96748 | Running loss: 1.20366\n",
      "Epoch: 1 | Iteration: 235 | Classification loss: 0.31576 | Regression loss: 0.58683 | Running loss: 1.20260\n",
      "Epoch: 1 | Iteration: 236 | Classification loss: 0.24146 | Regression loss: 0.61225 | Running loss: 1.20022\n",
      "Epoch: 1 | Iteration: 237 | Classification loss: 0.36201 | Regression loss: 0.41056 | Running loss: 1.19728\n",
      "Epoch: 1 | Iteration: 238 | Classification loss: 0.60467 | Regression loss: 0.29902 | Running loss: 1.19521\n",
      "Epoch: 1 | Iteration: 239 | Classification loss: 0.82418 | Regression loss: 0.81799 | Running loss: 1.19750\n",
      "Epoch: 1 | Iteration: 240 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.19328\n",
      "Epoch: 1 | Iteration: 241 | Classification loss: 0.48388 | Regression loss: 0.00000 | Running loss: 1.19035\n",
      "Epoch: 1 | Iteration: 242 | Classification loss: 0.56515 | Regression loss: 1.02281 | Running loss: 1.18975\n",
      "Epoch: 1 | Iteration: 243 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.18832\n",
      "Epoch: 1 | Iteration: 244 | Classification loss: 0.00023 | Regression loss: 0.00000 | Running loss: 1.18447\n",
      "Epoch: 1 | Iteration: 245 | Classification loss: 0.96504 | Regression loss: 0.89715 | Running loss: 1.18612\n",
      "Epoch: 1 | Iteration: 246 | Classification loss: 0.54353 | Regression loss: 0.94805 | Running loss: 1.18679\n",
      "Epoch: 1 | Iteration: 247 | Classification loss: 0.73651 | Regression loss: 0.80887 | Running loss: 1.18870\n",
      "Epoch: 1 | Iteration: 248 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.18735\n",
      "Epoch: 1 | Iteration: 249 | Classification loss: 0.39398 | Regression loss: 0.58065 | Running loss: 1.18562\n",
      "Epoch: 1 | Iteration: 250 | Classification loss: 0.62953 | Regression loss: 0.74658 | Running loss: 1.18493\n",
      "Epoch: 1 | Iteration: 251 | Classification loss: 0.91179 | Regression loss: 1.10549 | Running loss: 1.18809\n",
      "Epoch: 1 | Iteration: 252 | Classification loss: 0.37422 | Regression loss: 0.38892 | Running loss: 1.18918\n",
      "Epoch: 1 | Iteration: 253 | Classification loss: 0.43139 | Regression loss: 0.54881 | Running loss: 1.18713\n",
      "Epoch: 1 | Iteration: 254 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.18322\n",
      "Epoch: 1 | Iteration: 255 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.18296\n",
      "Epoch: 1 | Iteration: 256 | Classification loss: 0.00802 | Regression loss: 0.00000 | Running loss: 1.18277\n",
      "Epoch: 1 | Iteration: 257 | Classification loss: 0.28898 | Regression loss: 0.40685 | Running loss: 1.18032\n",
      "Epoch: 1 | Iteration: 258 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17655\n",
      "Epoch: 1 | Iteration: 259 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17268\n",
      "Epoch: 1 | Iteration: 260 | Classification loss: 0.13648 | Regression loss: 0.74755 | Running loss: 1.17248\n",
      "Epoch: 1 | Iteration: 261 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17239\n",
      "Epoch: 1 | Iteration: 262 | Classification loss: 0.07995 | Regression loss: 0.00000 | Running loss: 1.16907\n",
      "Epoch: 1 | Iteration: 263 | Classification loss: 0.00052 | Regression loss: 0.00000 | Running loss: 1.16572\n",
      "Epoch: 1 | Iteration: 264 | Classification loss: 0.33371 | Regression loss: 0.56915 | Running loss: 1.16460\n",
      "Epoch: 1 | Iteration: 265 | Classification loss: 0.44858 | Regression loss: 0.73261 | Running loss: 1.16688\n",
      "Epoch: 1 | Iteration: 266 | Classification loss: 0.76322 | Regression loss: 1.01958 | Running loss: 1.16763\n",
      "Epoch: 1 | Iteration: 267 | Classification loss: 0.64594 | Regression loss: 0.87602 | Running loss: 1.16525\n",
      "Epoch: 1 | Iteration: 268 | Classification loss: 1.51743 | Regression loss: 0.78101 | Running loss: 1.16715\n",
      "Epoch: 1 | Iteration: 269 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16661\n",
      "Epoch: 1 | Iteration: 270 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16362\n",
      "Epoch: 1 | Iteration: 271 | Classification loss: 0.45878 | Regression loss: 0.25828 | Running loss: 1.16009\n",
      "Evaluating dataset\n",
      "0/231\n",
      "1/231\n",
      "2/231\n",
      "3/231\n",
      "4/231\n",
      "5/231\n",
      "6/231\n",
      "7/231\n",
      "8/231\n",
      "9/231\n",
      "10/231\n",
      "11/231\n",
      "12/231\n",
      "13/231\n",
      "14/231\n",
      "15/231\n",
      "16/231\n",
      "17/231\n",
      "18/231\n",
      "19/231\n",
      "20/231\n",
      "21/231\n",
      "22/231\n",
      "23/231\n",
      "24/231\n",
      "25/231\n",
      "26/231\n",
      "27/231\n",
      "28/231\n",
      "29/231\n",
      "30/231\n",
      "31/231\n",
      "32/231\n",
      "33/231\n",
      "34/231\n",
      "35/231\n",
      "36/231\n",
      "37/231\n",
      "38/231\n",
      "39/231\n",
      "40/231\n",
      "41/231\n",
      "42/231\n",
      "43/231\n",
      "44/231\n",
      "45/231\n",
      "46/231\n",
      "47/231\n",
      "48/231\n",
      "49/231\n",
      "50/231\n",
      "51/231\n",
      "52/231\n",
      "53/231\n",
      "54/231\n",
      "55/231\n",
      "56/231\n",
      "57/231\n",
      "58/231\n",
      "59/231\n",
      "60/231\n",
      "61/231\n",
      "62/231\n",
      "63/231\n",
      "64/231\n",
      "65/231\n",
      "66/231\n",
      "67/231\n",
      "68/231\n",
      "69/231\n",
      "70/231\n",
      "71/231\n",
      "72/231\n",
      "73/231\n",
      "74/231\n",
      "75/231\n",
      "76/231\n",
      "77/231\n",
      "78/231\n",
      "79/231\n",
      "80/231\n",
      "81/231\n",
      "82/231\n",
      "83/231\n",
      "84/231\n",
      "85/231\n",
      "86/231\n",
      "87/231\n",
      "88/231\n",
      "89/231\n",
      "90/231\n",
      "91/231\n",
      "92/231\n",
      "93/231\n",
      "94/231\n",
      "95/231\n",
      "96/231\n",
      "97/231\n",
      "98/231\n",
      "99/231\n",
      "100/231\n",
      "101/231\n",
      "102/231\n",
      "103/231\n",
      "104/231\n",
      "105/231\n",
      "106/231\n",
      "107/231\n",
      "108/231\n",
      "109/231\n",
      "110/231\n",
      "111/231\n",
      "112/231\n",
      "113/231\n",
      "114/231\n",
      "115/231\n",
      "116/231\n",
      "117/231\n",
      "118/231\n",
      "119/231\n",
      "120/231\n",
      "121/231\n",
      "122/231\n",
      "123/231\n",
      "124/231\n",
      "125/231\n",
      "126/231\n",
      "127/231\n",
      "128/231\n",
      "129/231\n",
      "130/231\n",
      "131/231\n",
      "132/231\n",
      "133/231\n",
      "134/231\n",
      "135/231\n",
      "136/231\n",
      "137/231\n",
      "138/231\n",
      "139/231\n",
      "140/231\n",
      "141/231\n",
      "142/231\n",
      "143/231\n",
      "144/231\n",
      "145/231\n",
      "146/231\n",
      "147/231\n",
      "148/231\n",
      "149/231\n",
      "150/231\n",
      "151/231\n",
      "152/231\n",
      "153/231\n",
      "154/231\n",
      "155/231\n",
      "156/231\n",
      "157/231\n",
      "158/231\n",
      "159/231\n",
      "160/231\n",
      "161/231\n",
      "162/231\n",
      "163/231\n",
      "164/231\n",
      "165/231\n",
      "166/231\n",
      "167/231\n",
      "168/231\n",
      "169/231\n",
      "170/231\n",
      "171/231\n",
      "172/231\n",
      "173/231\n",
      "174/231\n",
      "175/231\n",
      "176/231\n",
      "177/231\n",
      "178/231\n",
      "179/231\n",
      "180/231\n",
      "181/231\n",
      "182/231\n",
      "183/231\n",
      "184/231\n",
      "185/231\n",
      "186/231\n",
      "187/231\n",
      "188/231\n",
      "189/231\n",
      "190/231\n",
      "191/231\n",
      "192/231\n",
      "193/231\n",
      "194/231\n",
      "195/231\n",
      "196/231\n",
      "197/231\n",
      "198/231\n",
      "199/231\n",
      "200/231\n",
      "201/231\n",
      "202/231\n",
      "203/231\n",
      "204/231\n",
      "205/231\n",
      "206/231\n",
      "207/231\n",
      "208/231\n",
      "209/231\n",
      "210/231\n",
      "211/231\n",
      "212/231\n",
      "213/231\n",
      "214/231\n",
      "215/231\n",
      "216/231\n",
      "217/231\n",
      "218/231\n",
      "219/231\n",
      "220/231\n",
      "221/231\n",
      "222/231\n",
      "223/231\n",
      "224/231\n",
      "225/231\n",
      "226/231\n",
      "227/231\n",
      "228/231\n",
      "229/231\n",
      "230/231\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 2 | Iteration: 0 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.15631\n",
      "Epoch: 2 | Iteration: 1 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.15625\n",
      "Epoch: 2 | Iteration: 2 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.15622\n",
      "Epoch: 2 | Iteration: 3 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.15026\n",
      "Epoch: 2 | Iteration: 4 | Classification loss: 0.00017 | Regression loss: 0.00000 | Running loss: 1.14648\n",
      "Epoch: 2 | Iteration: 5 | Classification loss: 1.37248 | Regression loss: 0.95981 | Running loss: 1.14768\n",
      "Epoch: 2 | Iteration: 6 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.14458\n",
      "Epoch: 2 | Iteration: 7 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.14443\n",
      "Epoch: 2 | Iteration: 8 | Classification loss: 0.94982 | Regression loss: 1.02332 | Running loss: 1.14665\n",
      "Epoch: 2 | Iteration: 9 | Classification loss: 0.53538 | Regression loss: 0.73295 | Running loss: 1.14549\n",
      "Epoch: 2 | Iteration: 10 | Classification loss: 0.41569 | Regression loss: 0.62602 | Running loss: 1.14457\n",
      "Epoch: 2 | Iteration: 11 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.14289\n",
      "Epoch: 2 | Iteration: 12 | Classification loss: 0.51980 | Regression loss: 0.47628 | Running loss: 1.14133\n",
      "Epoch: 2 | Iteration: 13 | Classification loss: 0.69601 | Regression loss: 0.76983 | Running loss: 1.14103\n",
      "Epoch: 2 | Iteration: 14 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.13806\n",
      "Epoch: 2 | Iteration: 15 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.13528\n",
      "Epoch: 2 | Iteration: 16 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.13213\n",
      "Epoch: 2 | Iteration: 17 | Classification loss: 0.33397 | Regression loss: 0.82036 | Running loss: 1.13402\n",
      "Epoch: 2 | Iteration: 18 | Classification loss: 0.00445 | Regression loss: 0.00000 | Running loss: 1.13140\n",
      "Epoch: 2 | Iteration: 19 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.12785\n",
      "Epoch: 2 | Iteration: 20 | Classification loss: 0.00197 | Regression loss: 0.00000 | Running loss: 1.11864\n",
      "Epoch: 2 | Iteration: 21 | Classification loss: 0.32707 | Regression loss: 0.73430 | Running loss: 1.11820\n",
      "Epoch: 2 | Iteration: 22 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.11514\n",
      "Epoch: 2 | Iteration: 23 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.11506\n",
      "Epoch: 2 | Iteration: 24 | Classification loss: 0.00561 | Regression loss: 0.00000 | Running loss: 1.11497\n",
      "Epoch: 2 | Iteration: 25 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.11468\n",
      "Epoch: 2 | Iteration: 26 | Classification loss: 0.50081 | Regression loss: 0.55301 | Running loss: 1.11378\n",
      "Epoch: 2 | Iteration: 27 | Classification loss: 0.35587 | Regression loss: 0.31973 | Running loss: 1.11184\n",
      "Epoch: 2 | Iteration: 28 | Classification loss: 0.36691 | Regression loss: 0.53834 | Running loss: 1.11362\n",
      "Epoch: 2 | Iteration: 29 | Classification loss: 0.66183 | Regression loss: 0.62344 | Running loss: 1.11326\n",
      "Epoch: 2 | Iteration: 30 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.11015\n",
      "Epoch: 2 | Iteration: 31 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.10671\n",
      "Epoch: 2 | Iteration: 32 | Classification loss: 0.25151 | Regression loss: 0.60980 | Running loss: 1.10589\n",
      "Epoch: 2 | Iteration: 33 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.10552\n",
      "Epoch: 2 | Iteration: 34 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.10536\n",
      "Epoch: 2 | Iteration: 35 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.10202\n",
      "Epoch: 2 | Iteration: 36 | Classification loss: 0.59188 | Regression loss: 0.66471 | Running loss: 1.10451\n",
      "Epoch: 2 | Iteration: 37 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.09874\n",
      "Epoch: 2 | Iteration: 38 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.09505\n",
      "Epoch: 2 | Iteration: 39 | Classification loss: 0.02795 | Regression loss: 0.00000 | Running loss: 1.09177\n",
      "Epoch: 2 | Iteration: 40 | Classification loss: 0.45175 | Regression loss: 0.79976 | Running loss: 1.09424\n",
      "Epoch: 2 | Iteration: 41 | Classification loss: 1.27991 | Regression loss: 0.32688 | Running loss: 1.09628\n",
      "Epoch: 2 | Iteration: 42 | Classification loss: 0.55423 | Regression loss: 0.72261 | Running loss: 1.09643\n",
      "Epoch: 2 | Iteration: 43 | Classification loss: 0.25316 | Regression loss: 0.35132 | Running loss: 1.09683\n",
      "Epoch: 2 | Iteration: 44 | Classification loss: 0.29724 | Regression loss: 0.82545 | Running loss: 1.09905\n",
      "Epoch: 2 | Iteration: 45 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.09763\n",
      "Epoch: 2 | Iteration: 46 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.09504\n",
      "Epoch: 2 | Iteration: 47 | Classification loss: 0.46829 | Regression loss: 0.66832 | Running loss: 1.09730\n",
      "Epoch: 2 | Iteration: 48 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.09566\n",
      "Epoch: 2 | Iteration: 49 | Classification loss: 0.30477 | Regression loss: 0.89280 | Running loss: 1.09804\n",
      "Epoch: 2 | Iteration: 50 | Classification loss: 0.31517 | Regression loss: 0.99033 | Running loss: 1.10023\n",
      "Epoch: 2 | Iteration: 51 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.10018\n",
      "Epoch: 2 | Iteration: 52 | Classification loss: 0.28190 | Regression loss: 0.40985 | Running loss: 1.09887\n",
      "Epoch: 2 | Iteration: 53 | Classification loss: 0.00020 | Regression loss: 0.00000 | Running loss: 1.09887\n",
      "Epoch: 2 | Iteration: 54 | Classification loss: 0.00016 | Regression loss: 0.00000 | Running loss: 1.09884\n",
      "Epoch: 2 | Iteration: 55 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.09881\n",
      "Epoch: 2 | Iteration: 56 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.09431\n",
      "Epoch: 2 | Iteration: 57 | Classification loss: 0.47215 | Regression loss: 0.78850 | Running loss: 1.09157\n",
      "Epoch: 2 | Iteration: 58 | Classification loss: 0.82537 | Regression loss: 0.67372 | Running loss: 1.09457\n",
      "Epoch: 2 | Iteration: 59 | Classification loss: 0.67051 | Regression loss: 0.40259 | Running loss: 1.09672\n",
      "Epoch: 2 | Iteration: 60 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.08976\n",
      "Epoch: 2 | Iteration: 61 | Classification loss: 0.70090 | Regression loss: 0.55473 | Running loss: 1.09227\n",
      "Epoch: 2 | Iteration: 62 | Classification loss: 0.24067 | Regression loss: 0.83966 | Running loss: 1.09443\n",
      "Epoch: 2 | Iteration: 63 | Classification loss: 0.39675 | Regression loss: 0.73598 | Running loss: 1.09154\n",
      "Epoch: 2 | Iteration: 64 | Classification loss: 0.23012 | Regression loss: 0.77995 | Running loss: 1.09357\n",
      "Epoch: 2 | Iteration: 65 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.08854\n",
      "Epoch: 2 | Iteration: 66 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.08854\n",
      "Epoch: 2 | Iteration: 67 | Classification loss: 0.72945 | Regression loss: 0.80277 | Running loss: 1.08560\n",
      "Epoch: 2 | Iteration: 68 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.07923\n",
      "Epoch: 2 | Iteration: 69 | Classification loss: 0.52490 | Regression loss: 0.79732 | Running loss: 1.07855\n",
      "Epoch: 2 | Iteration: 70 | Classification loss: 152.57819 | Regression loss: 0.00000 | Running loss: 1.38371\n",
      "Epoch: 2 | Iteration: 71 | Classification loss: 9.90242 | Regression loss: 0.91071 | Running loss: 1.40534\n",
      "Epoch: 2 | Iteration: 72 | Classification loss: 35.88948 | Regression loss: 0.00000 | Running loss: 1.47711\n",
      "Epoch: 2 | Iteration: 73 | Classification loss: 92.38294 | Regression loss: 0.35933 | Running loss: 1.65984\n",
      "Epoch: 2 | Iteration: 74 | Classification loss: 0.44906 | Regression loss: 0.68296 | Running loss: 1.66203\n",
      "Epoch: 2 | Iteration: 75 | Classification loss: 0.36173 | Regression loss: 0.74756 | Running loss: 1.65934\n",
      "Epoch: 2 | Iteration: 76 | Classification loss: 0.21147 | Regression loss: 0.67068 | Running loss: 1.66110\n",
      "Epoch: 2 | Iteration: 77 | Classification loss: 0.01167 | Regression loss: 0.00000 | Running loss: 1.65907\n",
      "Epoch: 2 | Iteration: 78 | Classification loss: 0.45954 | Regression loss: 0.43124 | Running loss: 1.66085\n",
      "Epoch: 2 | Iteration: 79 | Classification loss: 0.45740 | Regression loss: 0.51417 | Running loss: 1.66028\n",
      "Epoch: 2 | Iteration: 80 | Classification loss: 0.49287 | Regression loss: 0.75163 | Running loss: 1.66276\n",
      "Epoch: 2 | Iteration: 81 | Classification loss: 0.27012 | Regression loss: 0.62248 | Running loss: 1.66454\n",
      "Epoch: 2 | Iteration: 82 | Classification loss: 0.29490 | Regression loss: 0.70450 | Running loss: 1.66207\n",
      "Epoch: 2 | Iteration: 83 | Classification loss: 0.12876 | Regression loss: 0.00000 | Running loss: 1.66232\n",
      "Epoch: 2 | Iteration: 84 | Classification loss: 0.01379 | Regression loss: 0.00000 | Running loss: 1.66234\n",
      "Epoch: 2 | Iteration: 85 | Classification loss: 0.36647 | Regression loss: 0.51746 | Running loss: 1.66044\n",
      "Epoch: 2 | Iteration: 86 | Classification loss: 0.72102 | Regression loss: 0.80554 | Running loss: 1.66350\n",
      "Epoch: 2 | Iteration: 87 | Classification loss: 0.48137 | Regression loss: 0.66564 | Running loss: 1.66390\n",
      "Epoch: 2 | Iteration: 88 | Classification loss: 0.92286 | Regression loss: 0.00000 | Running loss: 1.66242\n",
      "Epoch: 2 | Iteration: 89 | Classification loss: 0.05951 | Regression loss: 0.00000 | Running loss: 1.65817\n",
      "Epoch: 2 | Iteration: 90 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.65636\n",
      "Epoch: 2 | Iteration: 91 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.65274\n",
      "Epoch: 2 | Iteration: 92 | Classification loss: 0.00294 | Regression loss: 0.00000 | Running loss: 1.65275\n",
      "Epoch: 2 | Iteration: 93 | Classification loss: 0.46578 | Regression loss: 0.58348 | Running loss: 1.65483\n",
      "Epoch: 2 | Iteration: 94 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.64872\n",
      "Epoch: 2 | Iteration: 95 | Classification loss: 0.83496 | Regression loss: 0.71114 | Running loss: 1.64823\n",
      "Epoch: 2 | Iteration: 96 | Classification loss: 0.20627 | Regression loss: 0.17355 | Running loss: 1.64898\n",
      "Epoch: 2 | Iteration: 97 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.64586\n",
      "Epoch: 2 | Iteration: 98 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.64586\n",
      "Epoch: 2 | Iteration: 99 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.64585\n",
      "Epoch: 2 | Iteration: 100 | Classification loss: 1.04291 | Regression loss: 0.82547 | Running loss: 1.64733\n",
      "Epoch: 2 | Iteration: 101 | Classification loss: 0.34315 | Regression loss: 0.48875 | Running loss: 1.64584\n",
      "Epoch: 2 | Iteration: 102 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.64300\n",
      "Epoch: 2 | Iteration: 103 | Classification loss: 0.46131 | Regression loss: 0.70346 | Running loss: 1.64195\n",
      "Epoch: 2 | Iteration: 104 | Classification loss: 0.44530 | Regression loss: 0.64826 | Running loss: 1.64403\n",
      "Epoch: 2 | Iteration: 105 | Classification loss: 0.43430 | Regression loss: 0.34167 | Running loss: 1.64157\n",
      "Epoch: 2 | Iteration: 106 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.64157\n",
      "Epoch: 2 | Iteration: 107 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.63904\n",
      "Epoch: 2 | Iteration: 108 | Classification loss: 0.65250 | Regression loss: 0.95781 | Running loss: 1.64139\n",
      "Epoch: 2 | Iteration: 109 | Classification loss: 0.27663 | Regression loss: 0.52134 | Running loss: 1.64263\n",
      "Epoch: 2 | Iteration: 110 | Classification loss: 0.56835 | Regression loss: 0.37186 | Running loss: 1.64451\n",
      "Epoch: 2 | Iteration: 111 | Classification loss: 0.50152 | Regression loss: 0.75074 | Running loss: 1.64397\n",
      "Epoch: 2 | Iteration: 112 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.64102\n",
      "Epoch: 2 | Iteration: 113 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.63821\n",
      "Epoch: 2 | Iteration: 114 | Classification loss: 0.26608 | Regression loss: 0.81983 | Running loss: 1.63775\n",
      "Epoch: 2 | Iteration: 115 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.63775\n",
      "Epoch: 2 | Iteration: 116 | Classification loss: 1.04735 | Regression loss: 0.57533 | Running loss: 1.63824\n",
      "Epoch: 2 | Iteration: 117 | Classification loss: 0.28726 | Regression loss: 0.67552 | Running loss: 1.63709\n",
      "Epoch: 2 | Iteration: 118 | Classification loss: 0.19947 | Regression loss: 0.49049 | Running loss: 1.63587\n",
      "Epoch: 2 | Iteration: 119 | Classification loss: 0.45004 | Regression loss: 0.69094 | Running loss: 1.63147\n",
      "Epoch: 2 | Iteration: 120 | Classification loss: 0.18367 | Regression loss: 0.74281 | Running loss: 1.51454\n",
      "Epoch: 2 | Iteration: 121 | Classification loss: 0.22308 | Regression loss: 0.52347 | Running loss: 1.51600\n",
      "Epoch: 2 | Iteration: 122 | Classification loss: 0.25581 | Regression loss: 0.66045 | Running loss: 1.51567\n",
      "Epoch: 2 | Iteration: 123 | Classification loss: 2.91532 | Regression loss: 0.28857 | Running loss: 1.52094\n",
      "Epoch: 2 | Iteration: 124 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.52094\n",
      "Epoch: 2 | Iteration: 125 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.52094\n",
      "Epoch: 2 | Iteration: 126 | Classification loss: 0.32473 | Regression loss: 0.32942 | Running loss: 1.51846\n",
      "Epoch: 2 | Iteration: 127 | Classification loss: 0.44712 | Regression loss: 0.77457 | Running loss: 1.51727\n",
      "Epoch: 2 | Iteration: 128 | Classification loss: 0.24875 | Regression loss: 0.58420 | Running loss: 1.51580\n",
      "Epoch: 2 | Iteration: 129 | Classification loss: 0.29973 | Regression loss: 0.63038 | Running loss: 1.51751\n",
      "Epoch: 2 | Iteration: 130 | Classification loss: 0.56073 | Regression loss: 0.73747 | Running loss: 1.52010\n",
      "Epoch: 2 | Iteration: 131 | Classification loss: 0.00025 | Regression loss: 0.00000 | Running loss: 1.52010\n",
      "Epoch: 2 | Iteration: 132 | Classification loss: 0.25960 | Regression loss: 0.65965 | Running loss: 1.52194\n",
      "Epoch: 2 | Iteration: 133 | Classification loss: 0.26206 | Regression loss: 0.51426 | Running loss: 1.52349\n",
      "Epoch: 2 | Iteration: 134 | Classification loss: 0.00032 | Regression loss: 0.00000 | Running loss: 1.51839\n",
      "Epoch: 2 | Iteration: 135 | Classification loss: 0.00871 | Regression loss: 0.00000 | Running loss: 1.51496\n",
      "Epoch: 2 | Iteration: 136 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.51496\n",
      "Epoch: 2 | Iteration: 137 | Classification loss: 0.66204 | Regression loss: 0.24788 | Running loss: 1.51081\n",
      "Epoch: 2 | Iteration: 138 | Classification loss: 0.60040 | Regression loss: 0.83282 | Running loss: 1.51368\n",
      "Epoch: 2 | Iteration: 139 | Classification loss: 0.64208 | Regression loss: 0.43960 | Running loss: 1.51584\n",
      "Epoch: 2 | Iteration: 140 | Classification loss: 0.32854 | Regression loss: 0.60105 | Running loss: 1.51274\n",
      "Epoch: 2 | Iteration: 141 | Classification loss: 0.05470 | Regression loss: 0.26728 | Running loss: 1.51339\n",
      "Epoch: 2 | Iteration: 142 | Classification loss: 0.40055 | Regression loss: 0.41036 | Running loss: 1.50975\n",
      "Epoch: 2 | Iteration: 143 | Classification loss: 1.58521 | Regression loss: 0.65434 | Running loss: 1.51423\n",
      "Epoch: 2 | Iteration: 144 | Classification loss: 0.34105 | Regression loss: 0.00000 | Running loss: 1.51213\n",
      "Epoch: 2 | Iteration: 145 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.51213\n",
      "Epoch: 2 | Iteration: 146 | Classification loss: 0.59149 | Regression loss: 0.73618 | Running loss: 1.51302\n",
      "Epoch: 2 | Iteration: 147 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.51302\n",
      "Epoch: 2 | Iteration: 148 | Classification loss: 0.26009 | Regression loss: 0.72506 | Running loss: 1.51499\n",
      "Epoch: 2 | Iteration: 149 | Classification loss: 0.39872 | Regression loss: 0.30859 | Running loss: 1.51441\n",
      "Epoch: 2 | Iteration: 150 | Classification loss: 0.31524 | Regression loss: 0.48284 | Running loss: 1.51286\n",
      "Epoch: 2 | Iteration: 151 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.48231\n",
      "Epoch: 2 | Iteration: 152 | Classification loss: 0.01850 | Regression loss: 0.00000 | Running loss: 1.47982\n",
      "Epoch: 2 | Iteration: 153 | Classification loss: 0.08236 | Regression loss: 0.00000 | Running loss: 1.47998\n",
      "Epoch: 2 | Iteration: 154 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.47998\n",
      "Epoch: 2 | Iteration: 155 | Classification loss: 0.63295 | Regression loss: 0.00000 | Running loss: 1.48125\n",
      "Epoch: 2 | Iteration: 156 | Classification loss: 0.15658 | Regression loss: 0.65064 | Running loss: 1.48286\n",
      "Epoch: 2 | Iteration: 157 | Classification loss: 0.37508 | Regression loss: 0.66772 | Running loss: 1.48495\n",
      "Epoch: 2 | Iteration: 158 | Classification loss: 0.35892 | Regression loss: 0.73722 | Running loss: 1.48394\n",
      "Epoch: 2 | Iteration: 159 | Classification loss: 0.34397 | Regression loss: 0.45045 | Running loss: 1.48553\n",
      "Epoch: 2 | Iteration: 160 | Classification loss: 0.00377 | Regression loss: 0.00000 | Running loss: 1.48553\n",
      "Epoch: 2 | Iteration: 161 | Classification loss: 0.11616 | Regression loss: 0.20361 | Running loss: 1.48617\n",
      "Epoch: 2 | Iteration: 162 | Classification loss: 0.27423 | Regression loss: 0.73197 | Running loss: 1.48551\n",
      "Epoch: 2 | Iteration: 163 | Classification loss: 0.30496 | Regression loss: 0.30771 | Running loss: 1.48674\n",
      "Epoch: 2 | Iteration: 164 | Classification loss: 0.21026 | Regression loss: 0.67889 | Running loss: 1.48437\n",
      "Epoch: 2 | Iteration: 165 | Classification loss: 0.36361 | Regression loss: 0.51410 | Running loss: 1.48613\n",
      "Epoch: 2 | Iteration: 166 | Classification loss: 0.17426 | Regression loss: 0.52733 | Running loss: 1.48753\n",
      "Epoch: 2 | Iteration: 167 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.48753\n",
      "Epoch: 2 | Iteration: 168 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.48753\n",
      "Epoch: 2 | Iteration: 169 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.48753\n",
      "Epoch: 2 | Iteration: 170 | Classification loss: 0.00055 | Regression loss: 0.00000 | Running loss: 1.48491\n",
      "Epoch: 2 | Iteration: 171 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.48491\n",
      "Epoch: 2 | Iteration: 172 | Classification loss: 0.35567 | Regression loss: 0.65935 | Running loss: 1.48694\n",
      "Epoch: 2 | Iteration: 173 | Classification loss: 1.54142 | Regression loss: 0.29454 | Running loss: 1.48509\n",
      "Epoch: 2 | Iteration: 174 | Classification loss: 0.07239 | Regression loss: 0.00000 | Running loss: 1.48524\n",
      "Epoch: 2 | Iteration: 175 | Classification loss: 0.25872 | Regression loss: 0.47908 | Running loss: 1.48671\n",
      "Epoch: 2 | Iteration: 176 | Classification loss: 1.10800 | Regression loss: 0.43199 | Running loss: 1.48979\n",
      "Epoch: 2 | Iteration: 177 | Classification loss: 1.55929 | Regression loss: 0.92298 | Running loss: 1.49476\n",
      "Epoch: 2 | Iteration: 178 | Classification loss: 0.42819 | Regression loss: 0.72375 | Running loss: 1.49706\n",
      "Epoch: 2 | Iteration: 179 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.49172\n",
      "Epoch: 2 | Iteration: 180 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.48616\n",
      "Epoch: 2 | Iteration: 181 | Classification loss: 0.25765 | Regression loss: 0.25356 | Running loss: 1.48718\n",
      "Epoch: 2 | Iteration: 182 | Classification loss: 0.57880 | Regression loss: 0.74145 | Running loss: 1.48982\n",
      "Epoch: 2 | Iteration: 183 | Classification loss: 0.25774 | Regression loss: 0.61788 | Running loss: 1.48746\n",
      "Epoch: 2 | Iteration: 184 | Classification loss: 0.33182 | Regression loss: 0.65008 | Running loss: 1.48942\n",
      "Epoch: 2 | Iteration: 185 | Classification loss: 0.42745 | Regression loss: 0.61396 | Running loss: 1.49150\n",
      "Epoch: 2 | Iteration: 186 | Classification loss: 0.39186 | Regression loss: 0.00000 | Running loss: 1.49229\n",
      "Epoch: 2 | Iteration: 187 | Classification loss: 0.48299 | Regression loss: 0.00000 | Running loss: 1.49325\n",
      "Epoch: 2 | Iteration: 188 | Classification loss: 0.09318 | Regression loss: 0.20754 | Running loss: 1.49385\n",
      "Epoch: 2 | Iteration: 189 | Classification loss: 0.41819 | Regression loss: 0.66604 | Running loss: 1.49602\n",
      "Epoch: 2 | Iteration: 190 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.49185\n",
      "Epoch: 2 | Iteration: 191 | Classification loss: 0.00007 | Regression loss: 0.00000 | Running loss: 1.48944\n",
      "Epoch: 2 | Iteration: 192 | Classification loss: 0.33386 | Regression loss: 0.35819 | Running loss: 1.48614\n",
      "Epoch: 2 | Iteration: 193 | Classification loss: 0.00821 | Regression loss: 0.00000 | Running loss: 1.48204\n",
      "Epoch: 2 | Iteration: 194 | Classification loss: 0.89938 | Regression loss: 0.97770 | Running loss: 1.48580\n",
      "Epoch: 2 | Iteration: 195 | Classification loss: 0.00053 | Regression loss: 0.00000 | Running loss: 1.48181\n",
      "Epoch: 2 | Iteration: 196 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.47802\n",
      "Epoch: 2 | Iteration: 197 | Classification loss: 0.51587 | Regression loss: 0.34963 | Running loss: 1.47975\n",
      "Epoch: 2 | Iteration: 198 | Classification loss: 0.00013 | Regression loss: 0.00000 | Running loss: 1.47975\n",
      "Epoch: 2 | Iteration: 199 | Classification loss: 0.40226 | Regression loss: 0.58411 | Running loss: 1.47978\n",
      "Epoch: 2 | Iteration: 200 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.47978\n",
      "Epoch: 2 | Iteration: 201 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.47573\n",
      "Epoch: 2 | Iteration: 202 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.47236\n",
      "Epoch: 2 | Iteration: 203 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.47236\n",
      "Epoch: 2 | Iteration: 204 | Classification loss: 0.83582 | Regression loss: 0.82422 | Running loss: 1.47562\n",
      "Epoch: 2 | Iteration: 205 | Classification loss: 0.28800 | Regression loss: 0.27443 | Running loss: 1.47548\n",
      "Epoch: 2 | Iteration: 206 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.47343\n",
      "Epoch: 2 | Iteration: 207 | Classification loss: 0.06045 | Regression loss: 0.00000 | Running loss: 1.47355\n",
      "Epoch: 2 | Iteration: 208 | Classification loss: 0.16287 | Regression loss: 0.51915 | Running loss: 1.47200\n",
      "Epoch: 2 | Iteration: 209 | Classification loss: 0.42349 | Regression loss: 0.64056 | Running loss: 1.47202\n",
      "Epoch: 2 | Iteration: 210 | Classification loss: 0.23999 | Regression loss: 0.22061 | Running loss: 1.47295\n",
      "Epoch: 2 | Iteration: 211 | Classification loss: 0.42457 | Regression loss: 0.73239 | Running loss: 1.47247\n",
      "Epoch: 2 | Iteration: 212 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.47044\n",
      "Epoch: 2 | Iteration: 213 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.47044\n",
      "Epoch: 2 | Iteration: 214 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.46536\n",
      "Epoch: 2 | Iteration: 215 | Classification loss: 0.59972 | Regression loss: 0.57011 | Running loss: 1.46770\n",
      "Epoch: 2 | Iteration: 216 | Classification loss: 0.45023 | Regression loss: 0.79583 | Running loss: 1.46920\n",
      "Epoch: 2 | Iteration: 217 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.46920\n",
      "Epoch: 2 | Iteration: 218 | Classification loss: 0.59563 | Regression loss: 0.61416 | Running loss: 1.46901\n",
      "Epoch: 2 | Iteration: 219 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.46600\n",
      "Epoch: 2 | Iteration: 220 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.46220\n",
      "Epoch: 2 | Iteration: 221 | Classification loss: 0.97658 | Regression loss: 0.55864 | Running loss: 1.46177\n",
      "Epoch: 2 | Iteration: 222 | Classification loss: 0.00012 | Regression loss: 0.00000 | Running loss: 1.45864\n",
      "Epoch: 2 | Iteration: 223 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.45634\n",
      "Epoch: 2 | Iteration: 224 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.45236\n",
      "Epoch: 2 | Iteration: 225 | Classification loss: 0.29813 | Regression loss: 0.62402 | Running loss: 1.45122\n",
      "Epoch: 2 | Iteration: 226 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.44808\n",
      "Epoch: 2 | Iteration: 227 | Classification loss: 0.16722 | Regression loss: 0.36392 | Running loss: 1.40984\n",
      "Epoch: 2 | Iteration: 228 | Classification loss: 0.20503 | Regression loss: 0.62228 | Running loss: 1.40830\n",
      "Epoch: 2 | Iteration: 229 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.40387\n",
      "Epoch: 2 | Iteration: 230 | Classification loss: 0.41798 | Regression loss: 0.34760 | Running loss: 1.39412\n",
      "Epoch: 2 | Iteration: 231 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.39412\n",
      "Epoch: 2 | Iteration: 232 | Classification loss: 0.19178 | Regression loss: 0.76504 | Running loss: 1.39306\n",
      "Epoch: 2 | Iteration: 233 | Classification loss: 0.25629 | Regression loss: 0.57797 | Running loss: 1.39238\n",
      "Epoch: 2 | Iteration: 234 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.39238\n",
      "Epoch: 2 | Iteration: 235 | Classification loss: 0.30594 | Regression loss: 0.58979 | Running loss: 1.39412\n",
      "Epoch: 2 | Iteration: 236 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.39412\n",
      "Epoch: 2 | Iteration: 237 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.39412\n",
      "Epoch: 2 | Iteration: 238 | Classification loss: 0.43633 | Regression loss: 0.59045 | Running loss: 1.39225\n",
      "Epoch: 2 | Iteration: 239 | Classification loss: 0.95181 | Regression loss: 0.96680 | Running loss: 1.39608\n",
      "Epoch: 2 | Iteration: 240 | Classification loss: 0.18881 | Regression loss: 0.47650 | Running loss: 1.39419\n",
      "Epoch: 2 | Iteration: 241 | Classification loss: 0.17270 | Regression loss: 0.63304 | Running loss: 1.39171\n",
      "Epoch: 2 | Iteration: 242 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.39171\n",
      "Epoch: 2 | Iteration: 243 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.39171\n",
      "Epoch: 2 | Iteration: 244 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.38825\n",
      "Epoch: 2 | Iteration: 245 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.38352\n",
      "Epoch: 2 | Iteration: 246 | Classification loss: 0.33374 | Regression loss: 0.72509 | Running loss: 1.38154\n",
      "Epoch: 2 | Iteration: 247 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37906\n",
      "Epoch: 2 | Iteration: 248 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37905\n",
      "Epoch: 2 | Iteration: 249 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37716\n",
      "Epoch: 2 | Iteration: 250 | Classification loss: 0.18432 | Regression loss: 0.51831 | Running loss: 1.37733\n",
      "Epoch: 2 | Iteration: 251 | Classification loss: 0.12316 | Regression loss: 0.35547 | Running loss: 1.37828\n",
      "Epoch: 2 | Iteration: 252 | Classification loss: 0.31745 | Regression loss: 0.00000 | Running loss: 1.37606\n",
      "Epoch: 2 | Iteration: 253 | Classification loss: 0.02995 | Regression loss: 0.00000 | Running loss: 1.37611\n",
      "Epoch: 2 | Iteration: 254 | Classification loss: 0.10030 | Regression loss: 0.20293 | Running loss: 1.37373\n",
      "Epoch: 2 | Iteration: 255 | Classification loss: 0.52278 | Regression loss: 0.54110 | Running loss: 1.37586\n",
      "Epoch: 2 | Iteration: 256 | Classification loss: 0.32722 | Regression loss: 0.63477 | Running loss: 1.37778\n",
      "Epoch: 2 | Iteration: 257 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37778\n",
      "Epoch: 2 | Iteration: 258 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.37591\n",
      "Epoch: 2 | Iteration: 259 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37392\n",
      "Epoch: 2 | Iteration: 260 | Classification loss: 0.76640 | Regression loss: 0.68173 | Running loss: 1.37592\n",
      "Epoch: 2 | Iteration: 261 | Classification loss: 0.38301 | Regression loss: 0.68167 | Running loss: 1.37805\n",
      "Epoch: 2 | Iteration: 262 | Classification loss: 0.36042 | Regression loss: 0.66274 | Running loss: 1.37807\n",
      "Epoch: 2 | Iteration: 263 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37660\n",
      "Epoch: 2 | Iteration: 264 | Classification loss: 1.70766 | Regression loss: 0.65810 | Running loss: 1.37949\n",
      "Epoch: 2 | Iteration: 265 | Classification loss: 0.96972 | Regression loss: 0.00000 | Running loss: 1.38143\n",
      "Epoch: 2 | Iteration: 266 | Classification loss: 0.47109 | Regression loss: 0.88462 | Running loss: 1.38414\n",
      "Epoch: 2 | Iteration: 267 | Classification loss: 0.17859 | Regression loss: 0.29546 | Running loss: 1.38222\n",
      "Epoch: 2 | Iteration: 268 | Classification loss: 0.44692 | Regression loss: 0.90710 | Running loss: 1.38493\n",
      "Epoch: 2 | Iteration: 269 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.38318\n",
      "Epoch: 2 | Iteration: 270 | Classification loss: 0.01683 | Regression loss: 0.00000 | Running loss: 1.38321\n",
      "Epoch: 2 | Iteration: 271 | Classification loss: 0.07387 | Regression loss: 0.35115 | Running loss: 1.37442\n",
      "Evaluating dataset\n",
      "0/231\n",
      "1/231\n",
      "2/231\n",
      "3/231\n",
      "4/231\n",
      "5/231\n",
      "6/231\n",
      "7/231\n",
      "8/231\n",
      "9/231\n",
      "10/231\n",
      "11/231\n",
      "12/231\n",
      "13/231\n",
      "14/231\n",
      "15/231\n",
      "16/231\n",
      "17/231\n",
      "18/231\n",
      "19/231\n",
      "20/231\n",
      "21/231\n",
      "22/231\n",
      "23/231\n",
      "24/231\n",
      "25/231\n",
      "26/231\n",
      "27/231\n",
      "28/231\n",
      "29/231\n",
      "30/231\n",
      "31/231\n",
      "32/231\n",
      "33/231\n",
      "34/231\n",
      "35/231\n",
      "36/231\n",
      "37/231\n",
      "38/231\n",
      "39/231\n",
      "40/231\n",
      "41/231\n",
      "42/231\n",
      "43/231\n",
      "44/231\n",
      "45/231\n",
      "46/231\n",
      "47/231\n",
      "48/231\n",
      "49/231\n",
      "50/231\n",
      "51/231\n",
      "52/231\n",
      "53/231\n",
      "54/231\n",
      "55/231\n",
      "56/231\n",
      "57/231\n",
      "58/231\n",
      "59/231\n",
      "60/231\n",
      "61/231\n",
      "62/231\n",
      "63/231\n",
      "64/231\n",
      "65/231\n",
      "66/231\n",
      "67/231\n",
      "68/231\n",
      "69/231\n",
      "70/231\n",
      "71/231\n",
      "72/231\n",
      "73/231\n",
      "74/231\n",
      "75/231\n",
      "76/231\n",
      "77/231\n",
      "78/231\n",
      "79/231\n",
      "80/231\n",
      "81/231\n",
      "82/231\n",
      "83/231\n",
      "84/231\n",
      "85/231\n",
      "86/231\n",
      "87/231\n",
      "88/231\n",
      "89/231\n",
      "90/231\n",
      "91/231\n",
      "92/231\n",
      "93/231\n",
      "94/231\n",
      "95/231\n",
      "96/231\n",
      "97/231\n",
      "98/231\n",
      "99/231\n",
      "100/231\n",
      "101/231\n",
      "102/231\n",
      "103/231\n",
      "104/231\n",
      "105/231\n",
      "106/231\n",
      "107/231\n",
      "108/231\n",
      "109/231\n",
      "110/231\n",
      "111/231\n",
      "112/231\n",
      "113/231\n",
      "114/231\n",
      "115/231\n",
      "116/231\n",
      "117/231\n",
      "118/231\n",
      "119/231\n",
      "120/231\n",
      "121/231\n",
      "122/231\n",
      "123/231\n",
      "124/231\n",
      "125/231\n",
      "126/231\n",
      "127/231\n",
      "128/231\n",
      "129/231\n",
      "130/231\n",
      "131/231\n",
      "132/231\n",
      "133/231\n",
      "134/231\n",
      "135/231\n",
      "136/231\n",
      "137/231\n",
      "138/231\n",
      "139/231\n",
      "140/231\n",
      "141/231\n",
      "142/231\n",
      "143/231\n",
      "144/231\n",
      "145/231\n",
      "146/231\n",
      "147/231\n",
      "148/231\n",
      "149/231\n",
      "150/231\n",
      "151/231\n",
      "152/231\n",
      "153/231\n",
      "154/231\n",
      "155/231\n",
      "156/231\n",
      "157/231\n",
      "158/231\n",
      "159/231\n",
      "160/231\n",
      "161/231\n",
      "162/231\n",
      "163/231\n",
      "164/231\n",
      "165/231\n",
      "166/231\n",
      "167/231\n",
      "168/231\n",
      "169/231\n",
      "170/231\n",
      "171/231\n",
      "172/231\n",
      "173/231\n",
      "174/231\n",
      "175/231\n",
      "176/231\n",
      "177/231\n",
      "178/231\n",
      "179/231\n",
      "180/231\n",
      "181/231\n",
      "182/231\n",
      "183/231\n",
      "184/231\n",
      "185/231\n",
      "186/231\n",
      "187/231\n",
      "188/231\n",
      "189/231\n",
      "190/231\n",
      "191/231\n",
      "192/231\n",
      "193/231\n",
      "194/231\n",
      "195/231\n",
      "196/231\n",
      "197/231\n",
      "198/231\n",
      "199/231\n",
      "200/231\n",
      "201/231\n",
      "202/231\n",
      "203/231\n",
      "204/231\n",
      "205/231\n",
      "206/231\n",
      "207/231\n",
      "208/231\n",
      "209/231\n",
      "210/231\n",
      "211/231\n",
      "212/231\n",
      "213/231\n",
      "214/231\n",
      "215/231\n",
      "216/231\n",
      "217/231\n",
      "218/231\n",
      "219/231\n",
      "220/231\n",
      "221/231\n",
      "222/231\n",
      "223/231\n",
      "224/231\n",
      "225/231\n",
      "226/231\n",
      "227/231\n",
      "228/231\n",
      "229/231\n",
      "230/231\n",
      "Loading and preparing results...\n",
      "DONE (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.656\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 3 | Iteration: 0 | Classification loss: 0.09217 | Regression loss: 0.21734 | Running loss: 1.37494\n",
      "Epoch: 3 | Iteration: 1 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37494\n",
      "Epoch: 3 | Iteration: 2 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37494\n",
      "Epoch: 3 | Iteration: 3 | Classification loss: 0.30009 | Regression loss: 0.48858 | Running loss: 1.37650\n",
      "Epoch: 3 | Iteration: 4 | Classification loss: 0.41714 | Regression loss: 0.72656 | Running loss: 1.37879\n",
      "Epoch: 3 | Iteration: 5 | Classification loss: 0.61688 | Regression loss: 0.90250 | Running loss: 1.37881\n",
      "Epoch: 3 | Iteration: 6 | Classification loss: 0.41788 | Regression loss: 0.71779 | Running loss: 1.37735\n",
      "Epoch: 3 | Iteration: 7 | Classification loss: 0.43880 | Regression loss: 0.40891 | Running loss: 1.37556\n",
      "Epoch: 3 | Iteration: 8 | Classification loss: 0.37652 | Regression loss: 0.79768 | Running loss: 1.37791\n",
      "Epoch: 3 | Iteration: 9 | Classification loss: 0.35143 | Regression loss: 0.53241 | Running loss: 1.37967\n",
      "Epoch: 3 | Iteration: 10 | Classification loss: 0.00102 | Regression loss: 0.00000 | Running loss: 1.37661\n",
      "Epoch: 3 | Iteration: 11 | Classification loss: 0.00010 | Regression loss: 0.00000 | Running loss: 1.37319\n",
      "Epoch: 3 | Iteration: 12 | Classification loss: 0.18525 | Regression loss: 0.60157 | Running loss: 1.37476\n",
      "Epoch: 3 | Iteration: 13 | Classification loss: 0.00209 | Regression loss: 0.00000 | Running loss: 1.37477\n",
      "Epoch: 3 | Iteration: 14 | Classification loss: 0.21896 | Regression loss: 0.58126 | Running loss: 1.37277\n",
      "Epoch: 3 | Iteration: 15 | Classification loss: 0.53609 | Regression loss: 0.27489 | Running loss: 1.37079\n",
      "Epoch: 3 | Iteration: 16 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.36846\n",
      "Epoch: 3 | Iteration: 17 | Classification loss: 0.11884 | Regression loss: 0.27591 | Running loss: 1.36646\n",
      "Epoch: 3 | Iteration: 18 | Classification loss: 0.13720 | Regression loss: 0.41067 | Running loss: 1.36756\n",
      "Epoch: 3 | Iteration: 19 | Classification loss: 0.78152 | Regression loss: 0.35689 | Running loss: 1.36983\n",
      "Epoch: 3 | Iteration: 20 | Classification loss: 0.30066 | Regression loss: 0.62283 | Running loss: 1.37168\n",
      "Epoch: 3 | Iteration: 21 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.37168\n",
      "Epoch: 3 | Iteration: 22 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.36739\n",
      "Epoch: 3 | Iteration: 23 | Classification loss: 0.31103 | Regression loss: 0.51865 | Running loss: 1.36905\n",
      "Epoch: 3 | Iteration: 24 | Classification loss: 0.17266 | Regression loss: 0.57741 | Running loss: 1.35977\n",
      "Epoch: 3 | Iteration: 25 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.35745\n",
      "Epoch: 3 | Iteration: 26 | Classification loss: 1.19473 | Regression loss: 0.92198 | Running loss: 1.36053\n",
      "Epoch: 3 | Iteration: 27 | Classification loss: 0.00021 | Regression loss: 0.00000 | Running loss: 1.35661\n",
      "Epoch: 3 | Iteration: 28 | Classification loss: 0.10555 | Regression loss: 0.00000 | Running loss: 1.35456\n",
      "Epoch: 3 | Iteration: 29 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.35456\n",
      "Epoch: 3 | Iteration: 30 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.35182\n",
      "Epoch: 3 | Iteration: 31 | Classification loss: 0.13368 | Regression loss: 0.43002 | Running loss: 1.35295\n",
      "Epoch: 3 | Iteration: 32 | Classification loss: 0.26651 | Regression loss: 0.61191 | Running loss: 1.35345\n",
      "Epoch: 3 | Iteration: 33 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.35345\n",
      "Epoch: 3 | Iteration: 34 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.35345\n",
      "Epoch: 3 | Iteration: 35 | Classification loss: 0.49009 | Regression loss: 0.47804 | Running loss: 1.35248\n",
      "Epoch: 3 | Iteration: 36 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.34978\n",
      "Epoch: 3 | Iteration: 37 | Classification loss: 0.52937 | Regression loss: 0.56339 | Running loss: 1.35015\n",
      "Epoch: 3 | Iteration: 38 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.35015\n",
      "Epoch: 3 | Iteration: 39 | Classification loss: 0.07019 | Regression loss: 0.23201 | Running loss: 1.34862\n",
      "Epoch: 3 | Iteration: 40 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.34862\n",
      "Epoch: 3 | Iteration: 41 | Classification loss: 0.20366 | Regression loss: 0.56557 | Running loss: 1.35016\n",
      "Epoch: 3 | Iteration: 42 | Classification loss: 0.46316 | Regression loss: 0.82973 | Running loss: 1.35274\n",
      "Epoch: 3 | Iteration: 43 | Classification loss: 0.15245 | Regression loss: 0.28219 | Running loss: 1.34993\n",
      "Epoch: 3 | Iteration: 44 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.34649\n",
      "Epoch: 3 | Iteration: 45 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.34534\n",
      "Epoch: 3 | Iteration: 46 | Classification loss: 6.67618 | Regression loss: 0.00000 | Running loss: 1.35869\n",
      "Epoch: 3 | Iteration: 47 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.33137\n",
      "Epoch: 3 | Iteration: 48 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.31520\n",
      "Epoch: 3 | Iteration: 49 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.31520\n",
      "Epoch: 3 | Iteration: 50 | Classification loss: 2.62717 | Regression loss: 0.74907 | Running loss: 1.31800\n",
      "Epoch: 3 | Iteration: 51 | Classification loss: 2.27923 | Regression loss: 0.44776 | Running loss: 1.32192\n",
      "Epoch: 3 | Iteration: 52 | Classification loss: 0.26017 | Regression loss: 0.47590 | Running loss: 1.32108\n",
      "Epoch: 3 | Iteration: 53 | Classification loss: 0.56264 | Regression loss: 0.00000 | Running loss: 1.31815\n",
      "Epoch: 3 | Iteration: 54 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31715\n",
      "Epoch: 3 | Iteration: 55 | Classification loss: 0.46193 | Regression loss: 0.63500 | Running loss: 1.31935\n",
      "Epoch: 3 | Iteration: 56 | Classification loss: 0.19746 | Regression loss: 0.48613 | Running loss: 1.31831\n",
      "Epoch: 3 | Iteration: 57 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31721\n",
      "Epoch: 3 | Iteration: 58 | Classification loss: 0.25984 | Regression loss: 0.30669 | Running loss: 1.31741\n",
      "Epoch: 3 | Iteration: 59 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31726\n",
      "Epoch: 3 | Iteration: 60 | Classification loss: 0.13712 | Regression loss: 0.27021 | Running loss: 1.31601\n",
      "Epoch: 3 | Iteration: 61 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31405\n",
      "Epoch: 3 | Iteration: 62 | Classification loss: 0.35820 | Regression loss: 0.59950 | Running loss: 1.31596\n",
      "Epoch: 3 | Iteration: 63 | Classification loss: 0.31850 | Regression loss: 0.55921 | Running loss: 1.31444\n",
      "Epoch: 3 | Iteration: 64 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.31424\n",
      "Epoch: 3 | Iteration: 65 | Classification loss: 0.39688 | Regression loss: 0.66712 | Running loss: 1.31403\n",
      "Epoch: 3 | Iteration: 66 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31403\n",
      "Epoch: 3 | Iteration: 67 | Classification loss: 0.40997 | Regression loss: 0.58623 | Running loss: 1.31380\n",
      "Epoch: 3 | Iteration: 68 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.31113\n",
      "Epoch: 3 | Iteration: 69 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31113\n",
      "Epoch: 3 | Iteration: 70 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.30894\n",
      "Epoch: 3 | Iteration: 71 | Classification loss: 0.31273 | Regression loss: 0.65914 | Running loss: 1.30889\n",
      "Epoch: 3 | Iteration: 72 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.30653\n",
      "Epoch: 3 | Iteration: 73 | Classification loss: 0.13822 | Regression loss: 0.41392 | Running loss: 1.30358\n",
      "Epoch: 3 | Iteration: 74 | Classification loss: 0.94002 | Regression loss: 0.55331 | Running loss: 1.30656\n",
      "Epoch: 3 | Iteration: 75 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.30655\n",
      "Epoch: 3 | Iteration: 76 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.30276\n",
      "Epoch: 3 | Iteration: 77 | Classification loss: 0.23535 | Regression loss: 0.73815 | Running loss: 1.30331\n",
      "Epoch: 3 | Iteration: 78 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.30114\n",
      "Epoch: 3 | Iteration: 79 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.29808\n",
      "Epoch: 3 | Iteration: 80 | Classification loss: 13.48919 | Regression loss: 0.22990 | Running loss: 1.32552\n",
      "Epoch: 3 | Iteration: 81 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.32552\n",
      "Epoch: 3 | Iteration: 82 | Classification loss: 0.25209 | Regression loss: 0.36653 | Running loss: 1.32413\n",
      "Epoch: 3 | Iteration: 83 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.32413\n",
      "Epoch: 3 | Iteration: 84 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.32098\n",
      "Epoch: 3 | Iteration: 85 | Classification loss: 0.21752 | Regression loss: 0.49481 | Running loss: 1.32043\n",
      "Epoch: 3 | Iteration: 86 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.32043\n",
      "Epoch: 3 | Iteration: 87 | Classification loss: 0.37062 | Regression loss: 0.70095 | Running loss: 1.32257\n",
      "Epoch: 3 | Iteration: 88 | Classification loss: 0.21765 | Regression loss: 0.68741 | Running loss: 1.32127\n",
      "Epoch: 3 | Iteration: 89 | Classification loss: 0.14783 | Regression loss: 0.27592 | Running loss: 1.31905\n",
      "Epoch: 3 | Iteration: 90 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.31596\n",
      "Epoch: 3 | Iteration: 91 | Classification loss: 0.36016 | Regression loss: 0.69698 | Running loss: 1.31349\n",
      "Epoch: 3 | Iteration: 92 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31233\n",
      "Epoch: 3 | Iteration: 93 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.31008\n",
      "Epoch: 3 | Iteration: 94 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.29280\n",
      "Epoch: 3 | Iteration: 95 | Classification loss: 0.16427 | Regression loss: 0.00000 | Running loss: 1.28863\n",
      "Epoch: 3 | Iteration: 96 | Classification loss: 0.22505 | Regression loss: 0.41946 | Running loss: 1.28869\n",
      "Epoch: 3 | Iteration: 97 | Classification loss: 0.16026 | Regression loss: 0.50849 | Running loss: 1.28724\n",
      "Epoch: 3 | Iteration: 98 | Classification loss: 0.41996 | Regression loss: 0.66512 | Running loss: 1.28926\n",
      "Epoch: 3 | Iteration: 99 | Classification loss: 0.31447 | Regression loss: 0.61586 | Running loss: 1.28925\n",
      "Epoch: 3 | Iteration: 100 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28793\n",
      "Epoch: 3 | Iteration: 101 | Classification loss: 0.25718 | Regression loss: 0.26575 | Running loss: 1.28600\n",
      "Epoch: 3 | Iteration: 102 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28600\n",
      "Epoch: 3 | Iteration: 103 | Classification loss: 0.16360 | Regression loss: 0.48408 | Running loss: 1.28719\n",
      "Epoch: 3 | Iteration: 104 | Classification loss: 0.42278 | Regression loss: 0.75303 | Running loss: 1.28954\n",
      "Epoch: 3 | Iteration: 105 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28954\n",
      "Epoch: 3 | Iteration: 106 | Classification loss: 0.29125 | Regression loss: 0.39930 | Running loss: 1.29092\n",
      "Epoch: 3 | Iteration: 107 | Classification loss: 0.12373 | Regression loss: 0.39957 | Running loss: 1.28875\n",
      "Epoch: 3 | Iteration: 108 | Classification loss: 0.16309 | Regression loss: 0.52732 | Running loss: 1.28812\n",
      "Epoch: 3 | Iteration: 109 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28461\n",
      "Epoch: 3 | Iteration: 110 | Classification loss: 0.30640 | Regression loss: 0.77513 | Running loss: 1.28677\n",
      "Epoch: 3 | Iteration: 111 | Classification loss: 0.26450 | Regression loss: 0.51812 | Running loss: 1.28833\n",
      "Epoch: 3 | Iteration: 112 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28833\n",
      "Epoch: 3 | Iteration: 113 | Classification loss: 0.10782 | Regression loss: 0.49312 | Running loss: 1.28954\n",
      "Epoch: 3 | Iteration: 114 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28954\n",
      "Epoch: 3 | Iteration: 115 | Classification loss: 0.15887 | Regression loss: 0.62423 | Running loss: 1.29110\n",
      "Epoch: 3 | Iteration: 116 | Classification loss: 0.14125 | Regression loss: 0.42796 | Running loss: 1.28771\n",
      "Epoch: 3 | Iteration: 117 | Classification loss: 0.25446 | Regression loss: 0.65461 | Running loss: 1.28953\n",
      "Epoch: 3 | Iteration: 118 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28953\n",
      "Epoch: 3 | Iteration: 119 | Classification loss: 0.22395 | Regression loss: 0.63900 | Running loss: 1.28854\n",
      "Epoch: 3 | Iteration: 120 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.28688\n",
      "Epoch: 3 | Iteration: 121 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28450\n",
      "Epoch: 3 | Iteration: 122 | Classification loss: 0.05698 | Regression loss: 0.23946 | Running loss: 1.28509\n",
      "Epoch: 3 | Iteration: 123 | Classification loss: 0.00014 | Regression loss: 0.00000 | Running loss: 1.28271\n",
      "Epoch: 3 | Iteration: 124 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28020\n",
      "Epoch: 3 | Iteration: 125 | Classification loss: 0.65538 | Regression loss: 0.00000 | Running loss: 1.28151\n",
      "Epoch: 3 | Iteration: 126 | Classification loss: 0.48288 | Regression loss: 0.40039 | Running loss: 1.28327\n",
      "Epoch: 3 | Iteration: 127 | Classification loss: 0.10785 | Regression loss: 0.24061 | Running loss: 1.28379\n",
      "Epoch: 3 | Iteration: 128 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28091\n",
      "Epoch: 3 | Iteration: 129 | Classification loss: 0.37102 | Regression loss: 0.59375 | Running loss: 1.28284\n",
      "Epoch: 3 | Iteration: 130 | Classification loss: 0.89268 | Regression loss: 0.96202 | Running loss: 1.28403\n",
      "Epoch: 3 | Iteration: 131 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28403\n",
      "Epoch: 3 | Iteration: 132 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.28403\n",
      "Epoch: 3 | Iteration: 133 | Classification loss: 0.57942 | Regression loss: 0.44184 | Running loss: 1.28314\n",
      "Epoch: 3 | Iteration: 134 | Classification loss: 0.11373 | Regression loss: 0.42061 | Running loss: 1.28184\n",
      "Epoch: 3 | Iteration: 135 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.28184\n",
      "Epoch: 3 | Iteration: 136 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.27822\n",
      "Epoch: 3 | Iteration: 137 | Classification loss: 0.22224 | Regression loss: 0.59730 | Running loss: 1.27607\n",
      "Epoch: 3 | Iteration: 138 | Classification loss: 0.09387 | Regression loss: 0.00000 | Running loss: 1.27525\n",
      "Epoch: 3 | Iteration: 139 | Classification loss: 0.15213 | Regression loss: 0.37837 | Running loss: 1.27257\n",
      "Epoch: 3 | Iteration: 140 | Classification loss: 0.13614 | Regression loss: 0.39306 | Running loss: 1.27363\n",
      "Epoch: 3 | Iteration: 141 | Classification loss: 0.17873 | Regression loss: 0.59215 | Running loss: 1.27180\n",
      "Epoch: 3 | Iteration: 142 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.27064\n",
      "Epoch: 3 | Iteration: 143 | Classification loss: 0.09320 | Regression loss: 0.33225 | Running loss: 1.26844\n",
      "Epoch: 3 | Iteration: 144 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.26640\n",
      "Epoch: 3 | Iteration: 145 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 1.25140\n",
      "Epoch: 3 | Iteration: 146 | Classification loss: 0.21492 | Regression loss: 0.51045 | Running loss: 1.24436\n",
      "Epoch: 3 | Iteration: 147 | Classification loss: 0.24952 | Regression loss: 0.25794 | Running loss: 1.24479\n",
      "Epoch: 3 | Iteration: 148 | Classification loss: 0.85893 | Regression loss: 0.83138 | Running loss: 1.24566\n",
      "Epoch: 3 | Iteration: 149 | Classification loss: 0.25467 | Regression loss: 0.29899 | Running loss: 1.24676\n",
      "Epoch: 3 | Iteration: 150 | Classification loss: 0.26490 | Regression loss: 0.48878 | Running loss: 1.24514\n",
      "Epoch: 3 | Iteration: 151 | Classification loss: 0.07514 | Regression loss: 0.00000 | Running loss: 1.24273\n",
      "Epoch: 3 | Iteration: 152 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.24149\n",
      "Epoch: 3 | Iteration: 153 | Classification loss: 0.00008 | Regression loss: 0.00000 | Running loss: 1.23968\n",
      "Epoch: 3 | Iteration: 154 | Classification loss: 0.12982 | Regression loss: 0.25754 | Running loss: 1.23648\n",
      "Epoch: 3 | Iteration: 155 | Classification loss: 0.01991 | Regression loss: 0.00000 | Running loss: 1.23502\n",
      "Epoch: 3 | Iteration: 156 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23502\n",
      "Epoch: 3 | Iteration: 157 | Classification loss: 0.00015 | Regression loss: 0.00000 | Running loss: 1.23501\n",
      "Epoch: 3 | Iteration: 158 | Classification loss: 0.01718 | Regression loss: 0.00000 | Running loss: 1.23147\n",
      "Epoch: 3 | Iteration: 159 | Classification loss: 0.16329 | Regression loss: 0.68365 | Running loss: 1.23131\n",
      "Epoch: 3 | Iteration: 160 | Classification loss: 0.33005 | Regression loss: 0.63323 | Running loss: 1.23324\n",
      "Epoch: 3 | Iteration: 161 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23321\n",
      "Epoch: 3 | Iteration: 162 | Classification loss: 0.00041 | Regression loss: 0.00000 | Running loss: 1.23254\n",
      "Epoch: 3 | Iteration: 163 | Classification loss: 0.49543 | Regression loss: 0.57072 | Running loss: 1.23465\n",
      "Epoch: 3 | Iteration: 164 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23465\n",
      "Epoch: 3 | Iteration: 165 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.23465\n",
      "Epoch: 3 | Iteration: 166 | Classification loss: 1.52458 | Regression loss: 0.37183 | Running loss: 1.23844\n",
      "Epoch: 3 | Iteration: 167 | Classification loss: 0.63513 | Regression loss: 0.54016 | Running loss: 1.23743\n",
      "Epoch: 3 | Iteration: 168 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23743\n",
      "Epoch: 3 | Iteration: 169 | Classification loss: 0.98617 | Regression loss: 0.70623 | Running loss: 1.24082\n",
      "Epoch: 3 | Iteration: 170 | Classification loss: 1.76322 | Regression loss: 0.70235 | Running loss: 1.24029\n",
      "Epoch: 3 | Iteration: 171 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23586\n",
      "Epoch: 3 | Iteration: 172 | Classification loss: 0.32838 | Regression loss: 0.32703 | Running loss: 1.23239\n",
      "Epoch: 3 | Iteration: 173 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.23239\n",
      "Epoch: 3 | Iteration: 174 | Classification loss: 0.38354 | Regression loss: 0.54115 | Running loss: 1.23040\n",
      "Epoch: 3 | Iteration: 175 | Classification loss: 0.43801 | Regression loss: 0.64770 | Running loss: 1.22953\n",
      "Epoch: 3 | Iteration: 176 | Classification loss: 0.12827 | Regression loss: 0.15015 | Running loss: 1.23009\n",
      "Epoch: 3 | Iteration: 177 | Classification loss: 0.42287 | Regression loss: 0.74729 | Running loss: 1.23069\n",
      "Epoch: 3 | Iteration: 178 | Classification loss: 0.23746 | Regression loss: 0.56575 | Running loss: 1.22821\n",
      "Epoch: 3 | Iteration: 179 | Classification loss: 0.46842 | Regression loss: 0.46372 | Running loss: 1.22654\n",
      "Epoch: 3 | Iteration: 180 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.22470\n",
      "Epoch: 3 | Iteration: 181 | Classification loss: 0.00144 | Regression loss: 0.00000 | Running loss: 1.22471\n",
      "Epoch: 3 | Iteration: 182 | Classification loss: 0.55762 | Regression loss: 0.00000 | Running loss: 1.22558\n",
      "Epoch: 3 | Iteration: 183 | Classification loss: 0.07006 | Regression loss: 0.00000 | Running loss: 1.22323\n",
      "Epoch: 3 | Iteration: 184 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.22206\n",
      "Epoch: 3 | Iteration: 185 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.18961\n",
      "Epoch: 3 | Iteration: 186 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.18776\n",
      "Epoch: 3 | Iteration: 187 | Classification loss: 0.24366 | Regression loss: 0.60415 | Running loss: 1.18945\n",
      "Epoch: 3 | Iteration: 188 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.18945\n",
      "Epoch: 3 | Iteration: 189 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.18715\n",
      "Epoch: 3 | Iteration: 190 | Classification loss: 0.84798 | Regression loss: 0.61107 | Running loss: 1.18735\n",
      "Epoch: 3 | Iteration: 191 | Classification loss: 0.67443 | Regression loss: 0.63510 | Running loss: 1.18816\n",
      "Epoch: 3 | Iteration: 192 | Classification loss: 0.25737 | Regression loss: 0.35252 | Running loss: 1.18767\n",
      "Epoch: 3 | Iteration: 193 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 1.18613\n",
      "Epoch: 3 | Iteration: 194 | Classification loss: 0.76540 | Regression loss: 0.37531 | Running loss: 1.18660\n",
      "Epoch: 3 | Iteration: 195 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.18332\n",
      "Epoch: 3 | Iteration: 196 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.18332\n",
      "Epoch: 3 | Iteration: 197 | Classification loss: 0.16231 | Regression loss: 0.80805 | Running loss: 1.18429\n",
      "Epoch: 3 | Iteration: 198 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.18112\n",
      "Epoch: 3 | Iteration: 199 | Classification loss: 0.10306 | Regression loss: 0.17553 | Running loss: 1.18167\n",
      "Epoch: 3 | Iteration: 200 | Classification loss: 0.45106 | Regression loss: 0.66378 | Running loss: 1.18390\n",
      "Epoch: 3 | Iteration: 201 | Classification loss: 0.44945 | Regression loss: 0.20284 | Running loss: 1.18148\n",
      "Epoch: 3 | Iteration: 202 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17850\n",
      "Epoch: 3 | Iteration: 203 | Classification loss: 0.33506 | Regression loss: 0.60945 | Running loss: 1.17730\n",
      "Epoch: 3 | Iteration: 204 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17730\n",
      "Epoch: 3 | Iteration: 205 | Classification loss: 0.25314 | Regression loss: 0.59533 | Running loss: 1.17705\n",
      "Epoch: 3 | Iteration: 206 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17429\n",
      "Epoch: 3 | Iteration: 207 | Classification loss: 0.00072 | Regression loss: 0.00000 | Running loss: 1.17026\n",
      "Epoch: 3 | Iteration: 208 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16873\n",
      "Epoch: 3 | Iteration: 209 | Classification loss: 0.45448 | Regression loss: 0.80166 | Running loss: 1.16929\n",
      "Epoch: 3 | Iteration: 210 | Classification loss: 0.33493 | Regression loss: 0.64095 | Running loss: 1.17124\n",
      "Epoch: 3 | Iteration: 211 | Classification loss: 0.31535 | Regression loss: 0.50574 | Running loss: 1.17288\n",
      "Epoch: 3 | Iteration: 212 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17286\n",
      "Epoch: 3 | Iteration: 213 | Classification loss: 0.36817 | Regression loss: 0.59085 | Running loss: 1.17339\n",
      "Epoch: 3 | Iteration: 214 | Classification loss: 0.15737 | Regression loss: 0.57861 | Running loss: 1.17486\n",
      "Epoch: 3 | Iteration: 215 | Classification loss: 0.27910 | Regression loss: 0.47126 | Running loss: 1.17636\n",
      "Epoch: 3 | Iteration: 216 | Classification loss: 0.15335 | Regression loss: 0.52877 | Running loss: 1.17596\n",
      "Epoch: 3 | Iteration: 217 | Classification loss: 0.19622 | Regression loss: 0.28060 | Running loss: 1.17691\n",
      "Epoch: 3 | Iteration: 218 | Classification loss: 0.09132 | Regression loss: 0.38631 | Running loss: 1.17771\n",
      "Epoch: 3 | Iteration: 219 | Classification loss: 0.13601 | Regression loss: 0.57973 | Running loss: 1.17914\n",
      "Epoch: 3 | Iteration: 220 | Classification loss: 0.20760 | Regression loss: 0.61824 | Running loss: 1.17898\n",
      "Epoch: 3 | Iteration: 221 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 1.17662\n",
      "Epoch: 3 | Iteration: 222 | Classification loss: 0.26084 | Regression loss: 0.21580 | Running loss: 1.17401\n",
      "Epoch: 3 | Iteration: 223 | Classification loss: 0.21444 | Regression loss: 0.49262 | Running loss: 1.17238\n",
      "Epoch: 3 | Iteration: 224 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 1.16778\n",
      "Epoch: 3 | Iteration: 225 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16778\n",
      "Epoch: 3 | Iteration: 226 | Classification loss: 0.00017 | Regression loss: 0.00000 | Running loss: 1.16778\n",
      "Epoch: 3 | Iteration: 227 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16635\n",
      "Epoch: 3 | Iteration: 228 | Classification loss: 1.07133 | Regression loss: 0.40295 | Running loss: 1.16930\n",
      "Epoch: 3 | Iteration: 229 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16930\n",
      "Epoch: 3 | Iteration: 230 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16930\n",
      "Epoch: 3 | Iteration: 231 | Classification loss: 0.74433 | Regression loss: 0.63140 | Running loss: 1.17205\n",
      "Epoch: 3 | Iteration: 232 | Classification loss: 1.63446 | Regression loss: 0.77288 | Running loss: 1.17686\n",
      "Epoch: 3 | Iteration: 233 | Classification loss: 0.20122 | Regression loss: 0.22066 | Running loss: 1.17304\n",
      "Epoch: 3 | Iteration: 234 | Classification loss: 0.33058 | Regression loss: 0.61318 | Running loss: 1.17493\n",
      "Epoch: 3 | Iteration: 235 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17493\n",
      "Epoch: 3 | Iteration: 236 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 1.17098\n",
      "Epoch: 3 | Iteration: 237 | Classification loss: 0.40785 | Regression loss: 0.63972 | Running loss: 1.17054\n",
      "Epoch: 3 | Iteration: 238 | Classification loss: 0.21889 | Regression loss: 0.32746 | Running loss: 1.16955\n",
      "Epoch: 3 | Iteration: 239 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16955\n",
      "Epoch: 3 | Iteration: 240 | Classification loss: 0.01574 | Regression loss: 0.00000 | Running loss: 1.16759\n",
      "Epoch: 3 | Iteration: 241 | Classification loss: 0.35143 | Regression loss: 0.56512 | Running loss: 1.16649\n",
      "Epoch: 3 | Iteration: 242 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16649\n",
      "Epoch: 3 | Iteration: 243 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16649\n",
      "Epoch: 3 | Iteration: 244 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16649\n",
      "Epoch: 3 | Iteration: 245 | Classification loss: 0.22028 | Regression loss: 0.46921 | Running loss: 1.16556\n",
      "Epoch: 3 | Iteration: 246 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16555\n",
      "Epoch: 3 | Iteration: 247 | Classification loss: 0.18575 | Regression loss: 0.60942 | Running loss: 1.16714\n",
      "Epoch: 3 | Iteration: 248 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16714\n",
      "Epoch: 3 | Iteration: 249 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16502\n",
      "Epoch: 3 | Iteration: 250 | Classification loss: 0.60327 | Regression loss: 0.46014 | Running loss: 1.16714\n",
      "Epoch: 3 | Iteration: 251 | Classification loss: 0.00018 | Regression loss: 0.00000 | Running loss: 1.16715\n",
      "Epoch: 3 | Iteration: 252 | Classification loss: 1.01431 | Regression loss: 0.89783 | Running loss: 1.17096\n",
      "Epoch: 3 | Iteration: 253 | Classification loss: 0.84882 | Regression loss: 0.69481 | Running loss: 1.17405\n",
      "Epoch: 3 | Iteration: 254 | Classification loss: 0.42675 | Regression loss: 0.59982 | Running loss: 1.17399\n",
      "Epoch: 3 | Iteration: 255 | Classification loss: 0.65142 | Regression loss: 0.69170 | Running loss: 1.17533\n",
      "Epoch: 3 | Iteration: 256 | Classification loss: 0.94030 | Regression loss: 0.00000 | Running loss: 1.17540\n",
      "Epoch: 3 | Iteration: 257 | Classification loss: 0.34197 | Regression loss: 0.58571 | Running loss: 1.17468\n",
      "Epoch: 3 | Iteration: 258 | Classification loss: 0.42224 | Regression loss: 0.98913 | Running loss: 1.17750\n",
      "Epoch: 3 | Iteration: 259 | Classification loss: 0.17176 | Regression loss: 0.60293 | Running loss: 1.17905\n",
      "Epoch: 3 | Iteration: 260 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17733\n",
      "Epoch: 3 | Iteration: 261 | Classification loss: 0.32428 | Regression loss: 0.40993 | Running loss: 1.17880\n",
      "Epoch: 3 | Iteration: 262 | Classification loss: 0.21971 | Regression loss: 0.66353 | Running loss: 1.18057\n",
      "Epoch: 3 | Iteration: 263 | Classification loss: 0.10508 | Regression loss: 0.33972 | Running loss: 1.18145\n",
      "Epoch: 3 | Iteration: 264 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17894\n",
      "Epoch: 3 | Iteration: 265 | Classification loss: 0.17065 | Regression loss: 0.50653 | Running loss: 1.18030\n",
      "Epoch: 3 | Iteration: 266 | Classification loss: 0.74247 | Regression loss: 0.37486 | Running loss: 1.18253\n",
      "Epoch: 3 | Iteration: 267 | Classification loss: 0.12687 | Regression loss: 0.17505 | Running loss: 1.18308\n",
      "Epoch: 3 | Iteration: 268 | Classification loss: 0.02122 | Regression loss: 0.00000 | Running loss: 1.18062\n",
      "Epoch: 3 | Iteration: 269 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17740\n",
      "Epoch: 3 | Iteration: 270 | Classification loss: 0.32854 | Regression loss: 0.83997 | Running loss: 1.17719\n",
      "Epoch: 3 | Iteration: 271 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17598\n",
      "Evaluating dataset\n",
      "0/231\n",
      "1/231\n",
      "2/231\n",
      "3/231\n",
      "4/231\n",
      "5/231\n",
      "6/231\n",
      "7/231\n",
      "8/231\n",
      "9/231\n",
      "10/231\n",
      "11/231\n",
      "12/231\n",
      "13/231\n",
      "14/231\n",
      "15/231\n",
      "16/231\n",
      "17/231\n",
      "18/231\n",
      "19/231\n",
      "20/231\n",
      "21/231\n",
      "22/231\n",
      "23/231\n",
      "24/231\n",
      "25/231\n",
      "26/231\n",
      "27/231\n",
      "28/231\n",
      "29/231\n",
      "30/231\n",
      "31/231\n",
      "32/231\n",
      "33/231\n",
      "34/231\n",
      "35/231\n",
      "36/231\n",
      "37/231\n",
      "38/231\n",
      "39/231\n",
      "40/231\n",
      "41/231\n",
      "42/231\n",
      "43/231\n",
      "44/231\n",
      "45/231\n",
      "46/231\n",
      "47/231\n",
      "48/231\n",
      "49/231\n",
      "50/231\n",
      "51/231\n",
      "52/231\n",
      "53/231\n",
      "54/231\n",
      "55/231\n",
      "56/231\n",
      "57/231\n",
      "58/231\n",
      "59/231\n",
      "60/231\n",
      "61/231\n",
      "62/231\n",
      "63/231\n",
      "64/231\n",
      "65/231\n",
      "66/231\n",
      "67/231\n",
      "68/231\n",
      "69/231\n",
      "70/231\n",
      "71/231\n",
      "72/231\n",
      "73/231\n",
      "74/231\n",
      "75/231\n",
      "76/231\n",
      "77/231\n",
      "78/231\n",
      "79/231\n",
      "80/231\n",
      "81/231\n",
      "82/231\n",
      "83/231\n",
      "84/231\n",
      "85/231\n",
      "86/231\n",
      "87/231\n",
      "88/231\n",
      "89/231\n",
      "90/231\n",
      "91/231\n",
      "92/231\n",
      "93/231\n",
      "94/231\n",
      "95/231\n",
      "96/231\n",
      "97/231\n",
      "98/231\n",
      "99/231\n",
      "100/231\n",
      "101/231\n",
      "102/231\n",
      "103/231\n",
      "104/231\n",
      "105/231\n",
      "106/231\n",
      "107/231\n",
      "108/231\n",
      "109/231\n",
      "110/231\n",
      "111/231\n",
      "112/231\n",
      "113/231\n",
      "114/231\n",
      "115/231\n",
      "116/231\n",
      "117/231\n",
      "118/231\n",
      "119/231\n",
      "120/231\n",
      "121/231\n",
      "122/231\n",
      "123/231\n",
      "124/231\n",
      "125/231\n",
      "126/231\n",
      "127/231\n",
      "128/231\n",
      "129/231\n",
      "130/231\n",
      "131/231\n",
      "132/231\n",
      "133/231\n",
      "134/231\n",
      "135/231\n",
      "136/231\n",
      "137/231\n",
      "138/231\n",
      "139/231\n",
      "140/231\n",
      "141/231\n",
      "142/231\n",
      "143/231\n",
      "144/231\n",
      "145/231\n",
      "146/231\n",
      "147/231\n",
      "148/231\n",
      "149/231\n",
      "150/231\n",
      "151/231\n",
      "152/231\n",
      "153/231\n",
      "154/231\n",
      "155/231\n",
      "156/231\n",
      "157/231\n",
      "158/231\n",
      "159/231\n",
      "160/231\n",
      "161/231\n",
      "162/231\n",
      "163/231\n",
      "164/231\n",
      "165/231\n",
      "166/231\n",
      "167/231\n",
      "168/231\n",
      "169/231\n",
      "170/231\n",
      "171/231\n",
      "172/231\n",
      "173/231\n",
      "174/231\n",
      "175/231\n",
      "176/231\n",
      "177/231\n",
      "178/231\n",
      "179/231\n",
      "180/231\n",
      "181/231\n",
      "182/231\n",
      "183/231\n",
      "184/231\n",
      "185/231\n",
      "186/231\n",
      "187/231\n",
      "188/231\n",
      "189/231\n",
      "190/231\n",
      "191/231\n",
      "192/231\n",
      "193/231\n",
      "194/231\n",
      "195/231\n",
      "196/231\n",
      "197/231\n",
      "198/231\n",
      "199/231\n",
      "200/231\n",
      "201/231\n",
      "202/231\n",
      "203/231\n",
      "204/231\n",
      "205/231\n",
      "206/231\n",
      "207/231\n",
      "208/231\n",
      "209/231\n",
      "210/231\n",
      "211/231\n",
      "212/231\n",
      "213/231\n",
      "214/231\n",
      "215/231\n",
      "216/231\n",
      "217/231\n",
      "218/231\n",
      "219/231\n",
      "220/231\n",
      "221/231\n",
      "222/231\n",
      "223/231\n",
      "224/231\n",
      "225/231\n",
      "226/231\n",
      "227/231\n",
      "228/231\n",
      "229/231\n",
      "230/231\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.739\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 4 | Iteration: 0 | Classification loss: 0.21202 | Regression loss: 0.34229 | Running loss: 1.17484\n",
      "Epoch: 4 | Iteration: 1 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17484\n",
      "Epoch: 4 | Iteration: 2 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17484\n",
      "Epoch: 4 | Iteration: 3 | Classification loss: 0.49234 | Regression loss: 0.46892 | Running loss: 1.17449\n",
      "Epoch: 4 | Iteration: 4 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17449\n",
      "Epoch: 4 | Iteration: 5 | Classification loss: 0.44398 | Regression loss: 0.31373 | Running loss: 1.17361\n",
      "Epoch: 4 | Iteration: 6 | Classification loss: 0.24444 | Regression loss: 0.41390 | Running loss: 1.17232\n",
      "Epoch: 4 | Iteration: 7 | Classification loss: 0.21919 | Regression loss: 0.44529 | Running loss: 1.17365\n",
      "Epoch: 4 | Iteration: 8 | Classification loss: 0.00012 | Regression loss: 0.00000 | Running loss: 1.17226\n",
      "Epoch: 4 | Iteration: 9 | Classification loss: 0.15110 | Regression loss: 0.15281 | Running loss: 1.17287\n",
      "Epoch: 4 | Iteration: 10 | Classification loss: 0.11848 | Regression loss: 0.51669 | Running loss: 1.17414\n",
      "Epoch: 4 | Iteration: 11 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.17414\n",
      "Epoch: 4 | Iteration: 12 | Classification loss: 0.63040 | Regression loss: 0.45537 | Running loss: 1.17631\n",
      "Epoch: 4 | Iteration: 13 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.17379\n",
      "Epoch: 4 | Iteration: 14 | Classification loss: 0.42053 | Regression loss: 0.31007 | Running loss: 1.17225\n",
      "Epoch: 4 | Iteration: 15 | Classification loss: 0.09975 | Regression loss: 0.00000 | Running loss: 1.17031\n",
      "Epoch: 4 | Iteration: 16 | Classification loss: 0.00132 | Regression loss: 0.00000 | Running loss: 1.17031\n",
      "Epoch: 4 | Iteration: 17 | Classification loss: 0.10545 | Regression loss: 0.21753 | Running loss: 1.16844\n",
      "Epoch: 4 | Iteration: 18 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 1.16628\n",
      "Epoch: 4 | Iteration: 19 | Classification loss: 1.08102 | Regression loss: 0.69443 | Running loss: 1.16757\n",
      "Epoch: 4 | Iteration: 20 | Classification loss: 0.27033 | Regression loss: 0.36432 | Running loss: 1.16682\n",
      "Epoch: 4 | Iteration: 21 | Classification loss: 0.24025 | Regression loss: 0.53724 | Running loss: 1.16837\n",
      "Epoch: 4 | Iteration: 22 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 1.16837\n",
      "Epoch: 4 | Iteration: 23 | Classification loss: 0.21919 | Regression loss: 0.48367 | Running loss: 1.16671\n",
      "Epoch: 4 | Iteration: 24 | Classification loss: 0.00392 | Regression loss: 0.00000 | Running loss: 1.16672\n",
      "Epoch: 4 | Iteration: 25 | Classification loss: 0.18772 | Regression loss: 0.52948 | Running loss: 1.16551\n",
      "Epoch: 4 | Iteration: 26 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.86036\n",
      "Epoch: 4 | Iteration: 27 | Classification loss: 0.31222 | Regression loss: 0.35109 | Running loss: 0.84006\n",
      "Epoch: 4 | Iteration: 28 | Classification loss: 1.87977 | Regression loss: 1.00569 | Running loss: 0.77405\n",
      "Epoch: 4 | Iteration: 29 | Classification loss: 1.03258 | Regression loss: 0.95860 | Running loss: 0.59255\n",
      "Epoch: 4 | Iteration: 30 | Classification loss: 0.16026 | Regression loss: 0.28569 | Running loss: 0.59117\n",
      "Epoch: 4 | Iteration: 31 | Classification loss: 0.21040 | Regression loss: 0.38592 | Running loss: 0.59015\n",
      "Epoch: 4 | Iteration: 32 | Classification loss: 0.81425 | Regression loss: 0.67978 | Running loss: 0.59137\n",
      "Epoch: 4 | Iteration: 33 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.59135\n",
      "Epoch: 4 | Iteration: 34 | Classification loss: 0.13550 | Regression loss: 0.66184 | Running loss: 0.59116\n",
      "Epoch: 4 | Iteration: 35 | Classification loss: 0.15585 | Regression loss: 0.40215 | Running loss: 0.59033\n",
      "Epoch: 4 | Iteration: 36 | Classification loss: 0.04192 | Regression loss: 0.09884 | Running loss: 0.58813\n",
      "Epoch: 4 | Iteration: 37 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.58634\n",
      "Epoch: 4 | Iteration: 38 | Classification loss: 0.00041 | Regression loss: 0.00000 | Running loss: 0.58434\n",
      "Epoch: 4 | Iteration: 39 | Classification loss: 0.21660 | Regression loss: 0.62935 | Running loss: 0.58578\n",
      "Epoch: 4 | Iteration: 40 | Classification loss: 0.28008 | Regression loss: 0.43095 | Running loss: 0.58717\n",
      "Epoch: 4 | Iteration: 41 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.58540\n",
      "Epoch: 4 | Iteration: 42 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.58235\n",
      "Epoch: 4 | Iteration: 43 | Classification loss: 0.43472 | Regression loss: 0.89331 | Running loss: 0.58271\n",
      "Epoch: 4 | Iteration: 44 | Classification loss: 0.00298 | Regression loss: 0.00000 | Running loss: 0.58087\n",
      "Epoch: 4 | Iteration: 45 | Classification loss: 0.23408 | Regression loss: 0.50953 | Running loss: 0.58224\n",
      "Epoch: 4 | Iteration: 46 | Classification loss: 0.13756 | Regression loss: 0.24738 | Running loss: 0.58301\n",
      "Epoch: 4 | Iteration: 47 | Classification loss: 0.22186 | Regression loss: 0.40701 | Running loss: 0.58427\n",
      "Epoch: 4 | Iteration: 48 | Classification loss: 0.18454 | Regression loss: 0.38133 | Running loss: 0.58540\n",
      "Epoch: 4 | Iteration: 49 | Classification loss: 0.01112 | Regression loss: 0.00000 | Running loss: 0.58332\n",
      "Epoch: 4 | Iteration: 50 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.58332\n",
      "Epoch: 4 | Iteration: 51 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.58023\n",
      "Epoch: 4 | Iteration: 52 | Classification loss: 0.32208 | Regression loss: 0.88961 | Running loss: 0.58189\n",
      "Epoch: 4 | Iteration: 53 | Classification loss: 0.23062 | Regression loss: 0.41853 | Running loss: 0.58319\n",
      "Epoch: 4 | Iteration: 54 | Classification loss: 0.42716 | Regression loss: 0.68409 | Running loss: 0.58541\n",
      "Epoch: 4 | Iteration: 55 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.58541\n",
      "Epoch: 4 | Iteration: 56 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.58167\n",
      "Epoch: 4 | Iteration: 57 | Classification loss: 0.14827 | Regression loss: 0.46197 | Running loss: 0.58123\n",
      "Epoch: 4 | Iteration: 58 | Classification loss: 0.12680 | Regression loss: 0.65041 | Running loss: 0.58279\n",
      "Epoch: 4 | Iteration: 59 | Classification loss: 0.29357 | Regression loss: 0.68594 | Running loss: 0.58242\n",
      "Epoch: 4 | Iteration: 60 | Classification loss: 0.55309 | Regression loss: 0.57812 | Running loss: 0.58249\n",
      "Epoch: 4 | Iteration: 61 | Classification loss: 0.21484 | Regression loss: 0.40098 | Running loss: 0.58217\n",
      "Epoch: 4 | Iteration: 62 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.58217\n",
      "Epoch: 4 | Iteration: 63 | Classification loss: 0.27000 | Regression loss: 0.64082 | Running loss: 0.58399\n",
      "Epoch: 4 | Iteration: 64 | Classification loss: 0.00204 | Regression loss: 0.00000 | Running loss: 0.58078\n",
      "Epoch: 4 | Iteration: 65 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.57918\n",
      "Epoch: 4 | Iteration: 66 | Classification loss: 0.23800 | Regression loss: 0.59382 | Running loss: 0.57896\n",
      "Epoch: 4 | Iteration: 67 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.57646\n",
      "Epoch: 4 | Iteration: 68 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.57646\n",
      "Epoch: 4 | Iteration: 69 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.57646\n",
      "Epoch: 4 | Iteration: 70 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.57429\n",
      "Epoch: 4 | Iteration: 71 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.57429\n",
      "Epoch: 4 | Iteration: 72 | Classification loss: 0.19939 | Regression loss: 0.29466 | Running loss: 0.57203\n",
      "Epoch: 4 | Iteration: 73 | Classification loss: 0.38126 | Regression loss: 0.52635 | Running loss: 0.57192\n",
      "Epoch: 4 | Iteration: 74 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.57054\n",
      "Epoch: 4 | Iteration: 75 | Classification loss: 0.16872 | Regression loss: 0.65422 | Running loss: 0.56990\n",
      "Epoch: 4 | Iteration: 76 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.56805\n",
      "Epoch: 4 | Iteration: 77 | Classification loss: 0.00122 | Regression loss: 0.00000 | Running loss: 0.56656\n",
      "Epoch: 4 | Iteration: 78 | Classification loss: 0.19124 | Regression loss: 0.59783 | Running loss: 0.56630\n",
      "Epoch: 4 | Iteration: 79 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55990\n",
      "Epoch: 4 | Iteration: 80 | Classification loss: 0.62619 | Regression loss: 0.58844 | Running loss: 0.56233\n",
      "Epoch: 4 | Iteration: 81 | Classification loss: 0.03892 | Regression loss: 0.21252 | Running loss: 0.56283\n",
      "Epoch: 4 | Iteration: 82 | Classification loss: 0.21006 | Regression loss: 0.60958 | Running loss: 0.56316\n",
      "Epoch: 4 | Iteration: 83 | Classification loss: 0.24187 | Regression loss: 0.51459 | Running loss: 0.56223\n",
      "Epoch: 4 | Iteration: 84 | Classification loss: 0.30086 | Regression loss: 0.57918 | Running loss: 0.56232\n",
      "Epoch: 4 | Iteration: 85 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.56046\n",
      "Epoch: 4 | Iteration: 86 | Classification loss: 0.34380 | Regression loss: 0.82279 | Running loss: 0.56020\n",
      "Epoch: 4 | Iteration: 87 | Classification loss: 0.14606 | Regression loss: 0.47616 | Running loss: 0.56144\n",
      "Epoch: 4 | Iteration: 88 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55961\n",
      "Epoch: 4 | Iteration: 89 | Classification loss: 0.30163 | Regression loss: 0.33580 | Running loss: 0.55933\n",
      "Epoch: 4 | Iteration: 90 | Classification loss: 0.00496 | Regression loss: 0.00000 | Running loss: 0.55934\n",
      "Epoch: 4 | Iteration: 91 | Classification loss: 0.00071 | Regression loss: 0.00000 | Running loss: 0.55932\n",
      "Epoch: 4 | Iteration: 92 | Classification loss: 0.07627 | Regression loss: 0.47430 | Running loss: 0.56042\n",
      "Epoch: 4 | Iteration: 93 | Classification loss: 0.14230 | Regression loss: 0.38898 | Running loss: 0.55966\n",
      "Epoch: 4 | Iteration: 94 | Classification loss: 0.18370 | Regression loss: 0.49299 | Running loss: 0.55815\n",
      "Epoch: 4 | Iteration: 95 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55599\n",
      "Epoch: 4 | Iteration: 96 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55413\n",
      "Epoch: 4 | Iteration: 97 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55349\n",
      "Epoch: 4 | Iteration: 98 | Classification loss: 0.38068 | Regression loss: 0.60923 | Running loss: 0.55384\n",
      "Epoch: 4 | Iteration: 99 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.54936\n",
      "Epoch: 4 | Iteration: 100 | Classification loss: 0.17054 | Regression loss: 0.31432 | Running loss: 0.54965\n",
      "Epoch: 4 | Iteration: 101 | Classification loss: 0.46612 | Regression loss: 0.61868 | Running loss: 0.55182\n",
      "Epoch: 4 | Iteration: 102 | Classification loss: 0.21129 | Regression loss: 0.17695 | Running loss: 0.54994\n",
      "Epoch: 4 | Iteration: 103 | Classification loss: 0.50644 | Regression loss: 0.71744 | Running loss: 0.55239\n",
      "Epoch: 4 | Iteration: 104 | Classification loss: 0.10873 | Regression loss: 0.44025 | Running loss: 0.55152\n",
      "Epoch: 4 | Iteration: 105 | Classification loss: 0.41709 | Regression loss: 0.43244 | Running loss: 0.55180\n",
      "Epoch: 4 | Iteration: 106 | Classification loss: 0.17995 | Regression loss: 0.51858 | Running loss: 0.55160\n",
      "Epoch: 4 | Iteration: 107 | Classification loss: 0.22455 | Regression loss: 0.42972 | Running loss: 0.55291\n",
      "Epoch: 4 | Iteration: 108 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 0.55288\n",
      "Epoch: 4 | Iteration: 109 | Classification loss: 0.31542 | Regression loss: 0.53851 | Running loss: 0.55442\n",
      "Epoch: 4 | Iteration: 110 | Classification loss: 0.45097 | Regression loss: 0.18747 | Running loss: 0.55570\n",
      "Epoch: 4 | Iteration: 111 | Classification loss: 0.00151 | Regression loss: 0.00000 | Running loss: 0.55443\n",
      "Epoch: 4 | Iteration: 112 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55282\n",
      "Epoch: 4 | Iteration: 113 | Classification loss: 0.80650 | Regression loss: 0.44061 | Running loss: 0.55323\n",
      "Epoch: 4 | Iteration: 114 | Classification loss: 0.24214 | Regression loss: 0.39244 | Running loss: 0.55230\n",
      "Epoch: 4 | Iteration: 115 | Classification loss: 0.27246 | Regression loss: 0.26607 | Running loss: 0.55179\n",
      "Epoch: 4 | Iteration: 116 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55178\n",
      "Epoch: 4 | Iteration: 117 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.55114\n",
      "Epoch: 4 | Iteration: 118 | Classification loss: 0.10722 | Regression loss: 0.20480 | Running loss: 0.54976\n",
      "Epoch: 4 | Iteration: 119 | Classification loss: 0.26238 | Regression loss: 0.54919 | Running loss: 0.55015\n",
      "Epoch: 4 | Iteration: 120 | Classification loss: 0.19599 | Regression loss: 0.47838 | Running loss: 0.54972\n",
      "Epoch: 4 | Iteration: 121 | Classification loss: 0.09061 | Regression loss: 0.26725 | Running loss: 0.54868\n",
      "Epoch: 4 | Iteration: 122 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.54728\n",
      "Epoch: 4 | Iteration: 123 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.54728\n",
      "Epoch: 4 | Iteration: 124 | Classification loss: 0.13308 | Regression loss: 0.30849 | Running loss: 0.54816\n",
      "Epoch: 4 | Iteration: 125 | Classification loss: 0.03913 | Regression loss: 0.28734 | Running loss: 0.54882\n",
      "Epoch: 4 | Iteration: 126 | Classification loss: 0.74914 | Regression loss: 0.48220 | Running loss: 0.55128\n",
      "Epoch: 4 | Iteration: 127 | Classification loss: 0.04346 | Regression loss: 0.15193 | Running loss: 0.55167\n",
      "Epoch: 4 | Iteration: 128 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.54964\n",
      "Epoch: 4 | Iteration: 129 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.54597\n",
      "Epoch: 4 | Iteration: 130 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.54582\n",
      "Epoch: 4 | Iteration: 131 | Classification loss: 0.71062 | Regression loss: 0.00000 | Running loss: 0.54577\n",
      "Epoch: 4 | Iteration: 132 | Classification loss: 0.14519 | Regression loss: 0.46870 | Running loss: 0.54392\n",
      "Epoch: 4 | Iteration: 133 | Classification loss: 0.25877 | Regression loss: 0.37837 | Running loss: 0.54023\n",
      "Epoch: 4 | Iteration: 134 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53792\n",
      "Epoch: 4 | Iteration: 135 | Classification loss: 0.29005 | Regression loss: 0.53514 | Running loss: 0.53957\n",
      "Epoch: 4 | Iteration: 136 | Classification loss: 0.07983 | Regression loss: 0.00000 | Running loss: 0.53973\n",
      "Epoch: 4 | Iteration: 137 | Classification loss: 0.64058 | Regression loss: 0.76950 | Running loss: 0.54153\n",
      "Epoch: 4 | Iteration: 138 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53889\n",
      "Epoch: 4 | Iteration: 139 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53714\n",
      "Epoch: 4 | Iteration: 140 | Classification loss: 0.10463 | Regression loss: 0.17143 | Running loss: 0.53573\n",
      "Epoch: 4 | Iteration: 141 | Classification loss: 0.58848 | Regression loss: 0.51156 | Running loss: 0.53584\n",
      "Epoch: 4 | Iteration: 142 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53506\n",
      "Epoch: 4 | Iteration: 143 | Classification loss: 0.44230 | Regression loss: 0.42714 | Running loss: 0.53583\n",
      "Epoch: 4 | Iteration: 144 | Classification loss: 0.18118 | Regression loss: 0.66768 | Running loss: 0.53693\n",
      "Epoch: 4 | Iteration: 145 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53476\n",
      "Epoch: 4 | Iteration: 146 | Classification loss: 0.34627 | Regression loss: 0.55690 | Running loss: 0.53657\n",
      "Epoch: 4 | Iteration: 147 | Classification loss: 0.28669 | Regression loss: 0.56183 | Running loss: 0.53826\n",
      "Epoch: 4 | Iteration: 148 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53688\n",
      "Epoch: 4 | Iteration: 149 | Classification loss: 0.00036 | Regression loss: 0.00000 | Running loss: 0.53686\n",
      "Epoch: 4 | Iteration: 150 | Classification loss: 0.29686 | Regression loss: 0.64140 | Running loss: 0.53499\n",
      "Epoch: 4 | Iteration: 151 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53499\n",
      "Epoch: 4 | Iteration: 152 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53499\n",
      "Epoch: 4 | Iteration: 153 | Classification loss: 0.19792 | Regression loss: 0.30829 | Running loss: 0.53427\n",
      "Epoch: 4 | Iteration: 154 | Classification loss: 0.33697 | Regression loss: 0.62766 | Running loss: 0.53620\n",
      "Epoch: 4 | Iteration: 155 | Classification loss: 0.07466 | Regression loss: 0.25270 | Running loss: 0.53488\n",
      "Epoch: 4 | Iteration: 156 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53488\n",
      "Epoch: 4 | Iteration: 157 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53488\n",
      "Epoch: 4 | Iteration: 158 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53488\n",
      "Epoch: 4 | Iteration: 159 | Classification loss: 0.09513 | Regression loss: 0.23004 | Running loss: 0.53553\n",
      "Epoch: 4 | Iteration: 160 | Classification loss: 0.17129 | Regression loss: 0.40282 | Running loss: 0.53336\n",
      "Epoch: 4 | Iteration: 161 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53223\n",
      "Epoch: 4 | Iteration: 162 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.53223\n",
      "Epoch: 4 | Iteration: 163 | Classification loss: 0.19192 | Regression loss: 0.45545 | Running loss: 0.53341\n",
      "Epoch: 4 | Iteration: 164 | Classification loss: 0.10674 | Regression loss: 0.49253 | Running loss: 0.53324\n",
      "Epoch: 4 | Iteration: 165 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53111\n",
      "Epoch: 4 | Iteration: 166 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.53019\n",
      "Epoch: 4 | Iteration: 167 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.52788\n",
      "Epoch: 4 | Iteration: 168 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52788\n",
      "Epoch: 4 | Iteration: 169 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.52788\n",
      "Epoch: 4 | Iteration: 170 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.52788\n",
      "Epoch: 4 | Iteration: 171 | Classification loss: 0.33166 | Regression loss: 0.57780 | Running loss: 0.52736\n",
      "Epoch: 4 | Iteration: 172 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52486\n",
      "Epoch: 4 | Iteration: 173 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.52486\n",
      "Epoch: 4 | Iteration: 174 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52244\n",
      "Epoch: 4 | Iteration: 175 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.52244\n",
      "Epoch: 4 | Iteration: 176 | Classification loss: 0.35586 | Regression loss: 0.79017 | Running loss: 0.52474\n",
      "Epoch: 4 | Iteration: 177 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.52167\n",
      "Epoch: 4 | Iteration: 178 | Classification loss: 0.25925 | Regression loss: 0.56459 | Running loss: 0.52331\n",
      "Epoch: 4 | Iteration: 179 | Classification loss: 0.28011 | Regression loss: 0.25154 | Running loss: 0.52438\n",
      "Epoch: 4 | Iteration: 180 | Classification loss: 0.00753 | Regression loss: 0.00000 | Running loss: 0.52439\n",
      "Epoch: 4 | Iteration: 181 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52255\n",
      "Epoch: 4 | Iteration: 182 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52255\n",
      "Epoch: 4 | Iteration: 183 | Classification loss: 0.26257 | Regression loss: 0.42982 | Running loss: 0.52287\n",
      "Epoch: 4 | Iteration: 184 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52122\n",
      "Epoch: 4 | Iteration: 185 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.52122\n",
      "Epoch: 4 | Iteration: 186 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51968\n",
      "Epoch: 4 | Iteration: 187 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.51968\n",
      "Epoch: 4 | Iteration: 188 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 0.51777\n",
      "Epoch: 4 | Iteration: 189 | Classification loss: 0.00010 | Regression loss: 0.00000 | Running loss: 0.51610\n",
      "Epoch: 4 | Iteration: 190 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51610\n",
      "Epoch: 4 | Iteration: 191 | Classification loss: 0.64334 | Regression loss: 0.61135 | Running loss: 0.51682\n",
      "Epoch: 4 | Iteration: 192 | Classification loss: 0.55632 | Regression loss: 0.59849 | Running loss: 0.51913\n",
      "Epoch: 4 | Iteration: 193 | Classification loss: 0.22935 | Regression loss: 0.32254 | Running loss: 0.52023\n",
      "Epoch: 4 | Iteration: 194 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51818\n",
      "Epoch: 4 | Iteration: 195 | Classification loss: 0.15758 | Regression loss: 0.44392 | Running loss: 0.51555\n",
      "Epoch: 4 | Iteration: 196 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.51422\n",
      "Epoch: 4 | Iteration: 197 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51260\n",
      "Epoch: 4 | Iteration: 198 | Classification loss: 0.81065 | Regression loss: 0.70095 | Running loss: 0.51563\n",
      "Epoch: 4 | Iteration: 199 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.51563\n",
      "Epoch: 4 | Iteration: 200 | Classification loss: 0.17685 | Regression loss: 0.51502 | Running loss: 0.51701\n",
      "Epoch: 4 | Iteration: 201 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.51701\n",
      "Epoch: 4 | Iteration: 202 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.51489\n",
      "Epoch: 4 | Iteration: 203 | Classification loss: 0.00088 | Regression loss: 0.00000 | Running loss: 0.51489\n",
      "Epoch: 4 | Iteration: 204 | Classification loss: 0.13786 | Regression loss: 0.50017 | Running loss: 0.51617\n",
      "Epoch: 4 | Iteration: 205 | Classification loss: 0.55373 | Regression loss: 0.62309 | Running loss: 0.51852\n",
      "Epoch: 4 | Iteration: 206 | Classification loss: 0.35406 | Regression loss: 0.75239 | Running loss: 0.51933\n",
      "Epoch: 4 | Iteration: 207 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51837\n",
      "Epoch: 4 | Iteration: 208 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51774\n",
      "Epoch: 4 | Iteration: 209 | Classification loss: 0.15254 | Regression loss: 0.30629 | Running loss: 0.51860\n",
      "Epoch: 4 | Iteration: 210 | Classification loss: 0.14818 | Regression loss: 0.44483 | Running loss: 0.51918\n",
      "Epoch: 4 | Iteration: 211 | Classification loss: 0.46424 | Regression loss: 0.42359 | Running loss: 0.51883\n",
      "Epoch: 4 | Iteration: 212 | Classification loss: 0.92739 | Regression loss: 0.31459 | Running loss: 0.51938\n",
      "Epoch: 4 | Iteration: 213 | Classification loss: 0.65241 | Regression loss: 0.76243 | Running loss: 0.52221\n",
      "Epoch: 4 | Iteration: 214 | Classification loss: 0.34504 | Regression loss: 0.66388 | Running loss: 0.52423\n",
      "Epoch: 4 | Iteration: 215 | Classification loss: 0.24635 | Regression loss: 0.56084 | Running loss: 0.52585\n",
      "Epoch: 4 | Iteration: 216 | Classification loss: 0.00312 | Regression loss: 0.00000 | Running loss: 0.52296\n",
      "Epoch: 4 | Iteration: 217 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.52083\n",
      "Epoch: 4 | Iteration: 218 | Classification loss: 0.22490 | Regression loss: 0.44456 | Running loss: 0.52012\n",
      "Epoch: 4 | Iteration: 219 | Classification loss: 0.21973 | Regression loss: 0.40051 | Running loss: 0.52136\n",
      "Epoch: 4 | Iteration: 220 | Classification loss: 0.14700 | Regression loss: 0.37360 | Running loss: 0.51767\n",
      "Epoch: 4 | Iteration: 221 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51573\n",
      "Epoch: 4 | Iteration: 222 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51302\n",
      "Epoch: 4 | Iteration: 223 | Classification loss: 0.62400 | Regression loss: 0.24114 | Running loss: 0.51380\n",
      "Epoch: 4 | Iteration: 224 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.51109\n",
      "Epoch: 4 | Iteration: 225 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.51109\n",
      "Epoch: 4 | Iteration: 226 | Classification loss: 0.48074 | Regression loss: 0.58338 | Running loss: 0.51319\n",
      "Epoch: 4 | Iteration: 227 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51234\n",
      "Epoch: 4 | Iteration: 228 | Classification loss: 0.32661 | Regression loss: 0.60834 | Running loss: 0.51359\n",
      "Epoch: 4 | Iteration: 229 | Classification loss: 0.32049 | Regression loss: 0.31949 | Running loss: 0.51487\n",
      "Epoch: 4 | Iteration: 230 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 0.51487\n",
      "Epoch: 4 | Iteration: 231 | Classification loss: 0.39056 | Regression loss: 0.52444 | Running loss: 0.51512\n",
      "Epoch: 4 | Iteration: 232 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.51283\n",
      "Epoch: 4 | Iteration: 233 | Classification loss: 0.22737 | Regression loss: 0.60492 | Running loss: 0.51146\n",
      "Epoch: 4 | Iteration: 234 | Classification loss: 0.38081 | Regression loss: 0.00000 | Running loss: 0.50995\n",
      "Epoch: 4 | Iteration: 235 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50826\n",
      "Epoch: 4 | Iteration: 236 | Classification loss: 0.11954 | Regression loss: 0.39554 | Running loss: 0.50694\n",
      "Epoch: 4 | Iteration: 237 | Classification loss: 0.13660 | Regression loss: 0.53286 | Running loss: 0.50651\n",
      "Epoch: 4 | Iteration: 238 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50651\n",
      "Epoch: 4 | Iteration: 239 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50651\n",
      "Epoch: 4 | Iteration: 240 | Classification loss: 0.18218 | Regression loss: 0.43993 | Running loss: 0.50618\n",
      "Epoch: 4 | Iteration: 241 | Classification loss: 0.24404 | Regression loss: 0.52999 | Running loss: 0.50772\n",
      "Epoch: 4 | Iteration: 242 | Classification loss: 0.26692 | Regression loss: 0.73701 | Running loss: 0.50813\n",
      "Epoch: 4 | Iteration: 243 | Classification loss: 0.26314 | Regression loss: 0.66008 | Running loss: 0.50835\n",
      "Epoch: 4 | Iteration: 244 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 0.50835\n",
      "Epoch: 4 | Iteration: 245 | Classification loss: 0.31087 | Regression loss: 0.79856 | Running loss: 0.50978\n",
      "Epoch: 4 | Iteration: 246 | Classification loss: 0.36640 | Regression loss: 0.00000 | Running loss: 0.50942\n",
      "Epoch: 4 | Iteration: 247 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 0.50714\n",
      "Epoch: 4 | Iteration: 248 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.50529\n",
      "Epoch: 4 | Iteration: 249 | Classification loss: 0.12261 | Regression loss: 0.48302 | Running loss: 0.50651\n",
      "Epoch: 4 | Iteration: 250 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50651\n",
      "Epoch: 4 | Iteration: 251 | Classification loss: 0.14804 | Regression loss: 0.62598 | Running loss: 0.50639\n",
      "Epoch: 4 | Iteration: 252 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.50489\n",
      "Epoch: 4 | Iteration: 253 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50489\n",
      "Epoch: 4 | Iteration: 254 | Classification loss: 0.12190 | Regression loss: 0.43566 | Running loss: 0.50178\n",
      "Epoch: 4 | Iteration: 255 | Classification loss: 0.32790 | Regression loss: 0.50046 | Running loss: 0.50343\n",
      "Epoch: 4 | Iteration: 256 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50322\n",
      "Epoch: 4 | Iteration: 257 | Classification loss: 0.12052 | Regression loss: 0.27355 | Running loss: 0.50401\n",
      "Epoch: 4 | Iteration: 258 | Classification loss: 0.30248 | Regression loss: 0.49443 | Running loss: 0.50560\n",
      "Epoch: 4 | Iteration: 259 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50448\n",
      "Epoch: 4 | Iteration: 260 | Classification loss: 0.23623 | Regression loss: 0.43240 | Running loss: 0.50406\n",
      "Epoch: 4 | Iteration: 261 | Classification loss: 0.25269 | Regression loss: 0.52291 | Running loss: 0.50561\n",
      "Epoch: 4 | Iteration: 262 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50561\n",
      "Epoch: 4 | Iteration: 263 | Classification loss: 0.00017 | Regression loss: 0.00000 | Running loss: 0.50367\n",
      "Epoch: 4 | Iteration: 264 | Classification loss: 0.06419 | Regression loss: 0.18038 | Running loss: 0.50416\n",
      "Epoch: 4 | Iteration: 265 | Classification loss: 0.33065 | Regression loss: 0.52529 | Running loss: 0.50369\n",
      "Epoch: 4 | Iteration: 266 | Classification loss: 0.16640 | Regression loss: 0.41686 | Running loss: 0.50485\n",
      "Epoch: 4 | Iteration: 267 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50425\n",
      "Epoch: 4 | Iteration: 268 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50425\n",
      "Epoch: 4 | Iteration: 269 | Classification loss: 0.00000 | Regression loss: 0.00000 | Running loss: 0.50271\n",
      "Epoch: 4 | Iteration: 270 | Classification loss: 0.05053 | Regression loss: 0.20707 | Running loss: 0.50064\n",
      "Epoch: 4 | Iteration: 271 | Classification loss: 0.24515 | Regression loss: 0.54234 | Running loss: 0.50135\n",
      "Evaluating dataset\n",
      "0/231\n",
      "1/231\n",
      "2/231\n",
      "3/231\n",
      "4/231\n",
      "5/231\n",
      "6/231\n",
      "7/231\n",
      "8/231\n",
      "9/231\n",
      "10/231\n",
      "11/231\n",
      "12/231\n",
      "13/231\n",
      "14/231\n",
      "15/231\n",
      "16/231\n",
      "17/231\n",
      "18/231\n",
      "19/231\n",
      "20/231\n",
      "21/231\n",
      "22/231\n",
      "23/231\n",
      "24/231\n",
      "25/231\n",
      "26/231\n",
      "27/231\n",
      "28/231\n",
      "29/231\n",
      "30/231\n",
      "31/231\n",
      "32/231\n",
      "33/231\n",
      "34/231\n",
      "35/231\n",
      "36/231\n",
      "37/231\n",
      "38/231\n",
      "39/231\n",
      "40/231\n",
      "41/231\n",
      "42/231\n",
      "43/231\n",
      "44/231\n",
      "45/231\n",
      "46/231\n",
      "47/231\n",
      "48/231\n",
      "49/231\n",
      "50/231\n",
      "51/231\n",
      "52/231\n",
      "53/231\n",
      "54/231\n",
      "55/231\n",
      "56/231\n",
      "57/231\n",
      "58/231\n",
      "59/231\n",
      "60/231\n",
      "61/231\n",
      "62/231\n",
      "63/231\n",
      "64/231\n",
      "65/231\n",
      "66/231\n",
      "67/231\n",
      "68/231\n",
      "69/231\n",
      "70/231\n",
      "71/231\n",
      "72/231\n",
      "73/231\n",
      "74/231\n",
      "75/231\n",
      "76/231\n",
      "77/231\n",
      "78/231\n",
      "79/231\n",
      "80/231\n",
      "81/231\n",
      "82/231\n",
      "83/231\n",
      "84/231\n",
      "85/231\n",
      "86/231\n",
      "87/231\n",
      "88/231\n",
      "89/231\n",
      "90/231\n",
      "91/231\n",
      "92/231\n",
      "93/231\n",
      "94/231\n",
      "95/231\n",
      "96/231\n",
      "97/231\n",
      "98/231\n",
      "99/231\n",
      "100/231\n",
      "101/231\n",
      "102/231\n",
      "103/231\n",
      "104/231\n",
      "105/231\n",
      "106/231\n",
      "107/231\n",
      "108/231\n",
      "109/231\n",
      "110/231\n",
      "111/231\n",
      "112/231\n",
      "113/231\n",
      "114/231\n",
      "115/231\n",
      "116/231\n",
      "117/231\n",
      "118/231\n",
      "119/231\n",
      "120/231\n",
      "121/231\n",
      "122/231\n",
      "123/231\n",
      "124/231\n",
      "125/231\n",
      "126/231\n",
      "127/231\n",
      "128/231\n",
      "129/231\n",
      "130/231\n",
      "131/231\n",
      "132/231\n",
      "133/231\n",
      "134/231\n",
      "135/231\n",
      "136/231\n",
      "137/231\n",
      "138/231\n",
      "139/231\n",
      "140/231\n",
      "141/231\n",
      "142/231\n",
      "143/231\n",
      "144/231\n",
      "145/231\n",
      "146/231\n",
      "147/231\n",
      "148/231\n",
      "149/231\n",
      "150/231\n",
      "151/231\n",
      "152/231\n",
      "153/231\n",
      "154/231\n",
      "155/231\n",
      "156/231\n",
      "157/231\n",
      "158/231\n",
      "159/231\n",
      "160/231\n",
      "161/231\n",
      "162/231\n",
      "163/231\n",
      "164/231\n",
      "165/231\n",
      "166/231\n",
      "167/231\n",
      "168/231\n",
      "169/231\n",
      "170/231\n",
      "171/231\n",
      "172/231\n",
      "173/231\n",
      "174/231\n",
      "175/231\n",
      "176/231\n",
      "177/231\n",
      "178/231\n",
      "179/231\n",
      "180/231\n",
      "181/231\n",
      "182/231\n",
      "183/231\n",
      "184/231\n",
      "185/231\n",
      "186/231\n",
      "187/231\n",
      "188/231\n",
      "189/231\n",
      "190/231\n",
      "191/231\n",
      "192/231\n",
      "193/231\n",
      "194/231\n",
      "195/231\n",
      "196/231\n",
      "197/231\n",
      "198/231\n",
      "199/231\n",
      "200/231\n",
      "201/231\n",
      "202/231\n",
      "203/231\n",
      "204/231\n",
      "205/231\n",
      "206/231\n",
      "207/231\n",
      "208/231\n",
      "209/231\n",
      "210/231\n",
      "211/231\n",
      "212/231\n",
      "213/231\n",
      "214/231\n",
      "215/231\n",
      "216/231\n",
      "217/231\n",
      "218/231\n",
      "219/231\n",
      "220/231\n",
      "221/231\n",
      "222/231\n",
      "223/231\n",
      "224/231\n",
      "225/231\n",
      "226/231\n",
      "227/231\n",
      "228/231\n",
      "229/231\n",
      "230/231\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "%cd C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\pytorch-retinanet\n",
    "!python train.py --dataset coco --coco_path \"C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\APOY 2 COCO\" --depth 50 --epochs 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a64cfd",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da2914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\pytorch-retinanet\n",
      "CUDA available: True\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Num training images: 1636\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 0 | Iteration: 0 | Classification loss: 1.40361 | Regression loss: 0.90093 | Running loss: 2.30454\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 1.25881 | Regression loss: 1.00572 | Running loss: 2.28454\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 1.38673 | Regression loss: 1.31907 | Running loss: 2.42496\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 1.31322 | Regression loss: 0.91630 | Running loss: 2.37610\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 1.30577 | Regression loss: 1.00424 | Running loss: 2.36288\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 1.24084 | Regression loss: 1.04297 | Running loss: 2.34970\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 1.20669 | Regression loss: 1.07081 | Running loss: 2.33939\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 1.21042 | Regression loss: 1.22857 | Running loss: 2.35184\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 1.31843 | Regression loss: 1.15188 | Running loss: 2.36500\n",
      "Epoch: 0 | Iteration: 9 | Classification loss: 1.12471 | Regression loss: 0.98726 | Running loss: 2.33970\n",
      "Epoch: 0 | Iteration: 10 | Classification loss: 1.11295 | Regression loss: 1.08538 | Running loss: 2.32685\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 1.12476 | Regression loss: 1.04293 | Running loss: 2.31358\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 1.04259 | Regression loss: 1.05340 | Running loss: 2.29685\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 1.12916 | Regression loss: 0.95962 | Running loss: 2.28198\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 1.10347 | Regression loss: 1.16616 | Running loss: 2.28116\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 1.09365 | Regression loss: 1.12735 | Running loss: 2.27740\n",
      "Epoch: 0 | Iteration: 16 | Classification loss: 1.19703 | Regression loss: 1.02972 | Running loss: 2.27442\n",
      "Epoch: 0 | Iteration: 17 | Classification loss: 1.10819 | Regression loss: 1.10498 | Running loss: 2.27102\n",
      "Epoch: 0 | Iteration: 18 | Classification loss: 1.19222 | Regression loss: 1.02393 | Running loss: 2.26813\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 1.17567 | Regression loss: 1.01859 | Running loss: 2.26444\n",
      "Epoch: 0 | Iteration: 20 | Classification loss: 1.00392 | Regression loss: 1.05486 | Running loss: 2.25464\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 1.21547 | Regression loss: 1.09577 | Running loss: 2.25722\n",
      "Epoch: 0 | Iteration: 22 | Classification loss: 1.14875 | Regression loss: 1.08164 | Running loss: 2.25605\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 1.07256 | Regression loss: 1.10014 | Running loss: 2.25258\n",
      "Epoch: 0 | Iteration: 24 | Classification loss: 1.10957 | Regression loss: 1.06135 | Running loss: 2.24931\n",
      "Epoch: 0 | Iteration: 25 | Classification loss: 1.10215 | Regression loss: 0.99416 | Running loss: 2.24343\n",
      "Epoch: 0 | Iteration: 26 | Classification loss: 1.12818 | Regression loss: 1.04170 | Running loss: 2.24070\n",
      "Epoch: 0 | Iteration: 27 | Classification loss: 1.10287 | Regression loss: 1.07159 | Running loss: 2.23834\n",
      "Epoch: 0 | Iteration: 28 | Classification loss: 1.07146 | Regression loss: 0.95899 | Running loss: 2.23117\n",
      "Epoch: 0 | Iteration: 29 | Classification loss: 1.01703 | Regression loss: 1.10661 | Running loss: 2.22758\n",
      "Epoch: 0 | Iteration: 30 | Classification loss: 0.97456 | Regression loss: 1.09956 | Running loss: 2.22263\n",
      "Epoch: 0 | Iteration: 31 | Classification loss: 1.02144 | Regression loss: 1.02800 | Running loss: 2.21722\n",
      "Epoch: 0 | Iteration: 32 | Classification loss: 1.10381 | Regression loss: 1.03771 | Running loss: 2.21493\n",
      "Epoch: 0 | Iteration: 33 | Classification loss: 0.92190 | Regression loss: 1.07545 | Running loss: 2.20853\n",
      "Epoch: 0 | Iteration: 34 | Classification loss: 1.03105 | Regression loss: 1.04790 | Running loss: 2.20483\n",
      "Epoch: 0 | Iteration: 35 | Classification loss: 1.10392 | Regression loss: 1.00147 | Running loss: 2.20206\n",
      "Epoch: 0 | Iteration: 36 | Classification loss: 0.99396 | Regression loss: 0.98339 | Running loss: 2.19599\n",
      "Epoch: 0 | Iteration: 37 | Classification loss: 0.97640 | Regression loss: 0.92144 | Running loss: 2.18814\n",
      "Epoch: 0 | Iteration: 38 | Classification loss: 1.03753 | Regression loss: 0.96896 | Running loss: 2.18349\n",
      "Epoch: 0 | Iteration: 39 | Classification loss: 3.40191 | Regression loss: 0.62814 | Running loss: 2.22965\n",
      "Epoch: 0 | Iteration: 40 | Classification loss: 0.90471 | Regression loss: 1.07345 | Running loss: 2.22352\n",
      "Epoch: 0 | Iteration: 41 | Classification loss: 1.19361 | Regression loss: 0.93935 | Running loss: 2.22136\n",
      "Epoch: 0 | Iteration: 42 | Classification loss: 1.26715 | Regression loss: 1.11694 | Running loss: 2.22514\n",
      "Epoch: 0 | Iteration: 43 | Classification loss: 1.24192 | Regression loss: 0.97896 | Running loss: 2.22505\n",
      "Epoch: 0 | Iteration: 44 | Classification loss: 0.85204 | Regression loss: 0.98387 | Running loss: 2.21640\n",
      "Epoch: 0 | Iteration: 45 | Classification loss: 1.18496 | Regression loss: 0.96036 | Running loss: 2.21485\n",
      "Epoch: 0 | Iteration: 46 | Classification loss: 0.91600 | Regression loss: 0.92043 | Running loss: 2.20680\n",
      "Epoch: 0 | Iteration: 47 | Classification loss: 1.16298 | Regression loss: 0.91772 | Running loss: 2.20418\n",
      "Epoch: 0 | Iteration: 48 | Classification loss: 1.07992 | Regression loss: 1.02527 | Running loss: 2.20216\n",
      "Epoch: 0 | Iteration: 49 | Classification loss: 0.79119 | Regression loss: 0.96106 | Running loss: 2.19316\n",
      "Epoch: 0 | Iteration: 50 | Classification loss: 0.85083 | Regression loss: 0.74868 | Running loss: 2.18152\n",
      "Epoch: 0 | Iteration: 51 | Classification loss: 0.95832 | Regression loss: 1.22743 | Running loss: 2.18160\n",
      "Epoch: 0 | Iteration: 52 | Classification loss: 0.85658 | Regression loss: 1.04620 | Running loss: 2.17634\n",
      "Epoch: 0 | Iteration: 53 | Classification loss: 0.39574 | Regression loss: 0.97544 | Running loss: 2.16143\n",
      "Epoch: 0 | Iteration: 54 | Classification loss: 0.57305 | Regression loss: 0.82166 | Running loss: 2.14749\n",
      "Epoch: 0 | Iteration: 55 | Classification loss: 1.01279 | Regression loss: 0.88728 | Running loss: 2.14307\n",
      "Epoch: 0 | Iteration: 56 | Classification loss: 1.25566 | Regression loss: 0.92512 | Running loss: 2.14373\n",
      "Epoch: 0 | Iteration: 57 | Classification loss: 1.21314 | Regression loss: 0.96234 | Running loss: 2.14428\n",
      "Epoch: 0 | Iteration: 58 | Classification loss: 0.68637 | Regression loss: 0.98465 | Running loss: 2.13626\n",
      "Epoch: 0 | Iteration: 59 | Classification loss: 1.20375 | Regression loss: 1.32227 | Running loss: 2.14275\n",
      "Epoch: 0 | Iteration: 60 | Classification loss: 0.65415 | Regression loss: 0.98495 | Running loss: 2.13450\n",
      "Epoch: 0 | Iteration: 61 | Classification loss: 0.64808 | Regression loss: 1.00222 | Running loss: 2.12669\n",
      "Epoch: 0 | Iteration: 62 | Classification loss: 1.02995 | Regression loss: 1.40576 | Running loss: 2.13159\n",
      "Epoch: 0 | Iteration: 63 | Classification loss: 0.67892 | Regression loss: 0.87089 | Running loss: 2.12250\n",
      "Epoch: 0 | Iteration: 64 | Classification loss: 0.67232 | Regression loss: 0.90142 | Running loss: 2.11406\n",
      "Epoch: 0 | Iteration: 65 | Classification loss: 0.66842 | Regression loss: 0.99560 | Running loss: 2.10724\n",
      "Epoch: 0 | Iteration: 66 | Classification loss: 1.08775 | Regression loss: 1.05149 | Running loss: 2.10772\n",
      "Epoch: 0 | Iteration: 67 | Classification loss: 0.66383 | Regression loss: 0.93767 | Running loss: 2.10027\n",
      "Epoch: 0 | Iteration: 68 | Classification loss: 1.05808 | Regression loss: 1.16590 | Running loss: 2.10207\n",
      "Epoch: 0 | Iteration: 69 | Classification loss: 0.96305 | Regression loss: 1.25981 | Running loss: 2.10379\n",
      "Epoch: 0 | Iteration: 70 | Classification loss: 0.97013 | Regression loss: 0.94543 | Running loss: 2.10114\n",
      "Epoch: 0 | Iteration: 71 | Classification loss: 0.52841 | Regression loss: 0.87634 | Running loss: 2.09147\n",
      "Epoch: 0 | Iteration: 72 | Classification loss: 0.79922 | Regression loss: 0.98782 | Running loss: 2.08730\n",
      "Epoch: 0 | Iteration: 73 | Classification loss: 0.75467 | Regression loss: 0.94322 | Running loss: 2.08204\n",
      "Epoch: 0 | Iteration: 74 | Classification loss: 0.61449 | Regression loss: 1.09504 | Running loss: 2.07707\n",
      "Epoch: 0 | Iteration: 75 | Classification loss: 0.57444 | Regression loss: 0.75666 | Running loss: 2.06725\n",
      "Epoch: 0 | Iteration: 76 | Classification loss: 0.65062 | Regression loss: 0.88741 | Running loss: 2.06038\n",
      "Epoch: 0 | Iteration: 77 | Classification loss: 0.62764 | Regression loss: 1.00332 | Running loss: 2.05488\n",
      "Epoch: 0 | Iteration: 78 | Classification loss: 0.53568 | Regression loss: 0.87657 | Running loss: 2.04674\n",
      "Epoch: 0 | Iteration: 79 | Classification loss: 0.56168 | Regression loss: 0.96254 | Running loss: 2.04021\n",
      "Epoch: 0 | Iteration: 80 | Classification loss: 0.68130 | Regression loss: 0.98005 | Running loss: 2.03553\n",
      "Epoch: 0 | Iteration: 81 | Classification loss: 0.65781 | Regression loss: 1.11499 | Running loss: 2.03233\n",
      "Epoch: 0 | Iteration: 82 | Classification loss: 0.78019 | Regression loss: 1.01385 | Running loss: 2.02946\n",
      "Epoch: 0 | Iteration: 83 | Classification loss: 0.55370 | Regression loss: 1.02665 | Running loss: 2.02411\n",
      "Epoch: 0 | Iteration: 84 | Classification loss: 0.51285 | Regression loss: 0.77143 | Running loss: 2.01541\n",
      "Epoch: 0 | Iteration: 85 | Classification loss: 0.44083 | Regression loss: 0.86324 | Running loss: 2.00714\n",
      "Epoch: 0 | Iteration: 86 | Classification loss: 0.52235 | Regression loss: 1.14429 | Running loss: 2.00322\n",
      "Epoch: 0 | Iteration: 87 | Classification loss: 0.78231 | Regression loss: 1.03873 | Running loss: 2.00115\n",
      "Epoch: 0 | Iteration: 88 | Classification loss: 0.88605 | Regression loss: 0.97593 | Running loss: 1.99959\n",
      "Epoch: 0 | Iteration: 89 | Classification loss: 0.46585 | Regression loss: 0.91746 | Running loss: 1.99274\n",
      "Epoch: 0 | Iteration: 90 | Classification loss: 0.68669 | Regression loss: 1.06646 | Running loss: 1.99011\n",
      "Epoch: 0 | Iteration: 91 | Classification loss: 0.78210 | Regression loss: 1.14586 | Running loss: 1.98943\n",
      "Epoch: 0 | Iteration: 92 | Classification loss: 0.55888 | Regression loss: 0.89135 | Running loss: 1.98363\n",
      "Epoch: 0 | Iteration: 93 | Classification loss: 0.74344 | Regression loss: 1.01581 | Running loss: 1.98125\n",
      "Epoch: 0 | Iteration: 94 | Classification loss: 1.23304 | Regression loss: 1.04483 | Running loss: 1.98437\n",
      "Epoch: 0 | Iteration: 95 | Classification loss: 0.58659 | Regression loss: 0.47189 | Running loss: 1.97472\n",
      "Epoch: 0 | Iteration: 96 | Classification loss: 0.63141 | Regression loss: 0.71830 | Running loss: 1.96828\n",
      "Epoch: 0 | Iteration: 97 | Classification loss: 0.65741 | Regression loss: 0.95311 | Running loss: 1.96463\n",
      "Epoch: 0 | Iteration: 98 | Classification loss: 0.85510 | Regression loss: 1.00959 | Running loss: 1.96362\n",
      "Epoch: 0 | Iteration: 99 | Classification loss: 0.76019 | Regression loss: 0.95513 | Running loss: 1.96114\n",
      "Epoch: 0 | Iteration: 100 | Classification loss: 0.77122 | Regression loss: 0.94495 | Running loss: 1.95871\n",
      "Epoch: 0 | Iteration: 101 | Classification loss: 0.67032 | Regression loss: 1.03813 | Running loss: 1.95626\n",
      "Epoch: 0 | Iteration: 102 | Classification loss: 0.41442 | Regression loss: 0.83662 | Running loss: 1.94941\n",
      "Epoch: 0 | Iteration: 103 | Classification loss: 0.50315 | Regression loss: 0.94503 | Running loss: 1.94459\n",
      "Epoch: 0 | Iteration: 104 | Classification loss: 0.74042 | Regression loss: 0.91767 | Running loss: 1.94186\n",
      "Epoch: 0 | Iteration: 105 | Classification loss: 1.44644 | Regression loss: 0.94789 | Running loss: 1.94613\n",
      "Epoch: 0 | Iteration: 106 | Classification loss: 1.38099 | Regression loss: 0.88051 | Running loss: 1.94908\n",
      "Epoch: 0 | Iteration: 107 | Classification loss: 1.24330 | Regression loss: 0.75268 | Running loss: 1.94951\n",
      "Epoch: 0 | Iteration: 108 | Classification loss: 0.46338 | Regression loss: 0.56908 | Running loss: 1.94110\n",
      "Epoch: 0 | Iteration: 109 | Classification loss: 0.42628 | Regression loss: 0.84598 | Running loss: 1.93502\n",
      "Epoch: 0 | Iteration: 110 | Classification loss: 0.56332 | Regression loss: 0.82752 | Running loss: 1.93012\n",
      "Epoch: 0 | Iteration: 111 | Classification loss: 0.67732 | Regression loss: 0.89802 | Running loss: 1.92695\n",
      "Epoch: 0 | Iteration: 112 | Classification loss: 0.82511 | Regression loss: 1.01321 | Running loss: 1.92617\n",
      "Epoch: 0 | Iteration: 113 | Classification loss: 0.72652 | Regression loss: 1.02130 | Running loss: 1.92460\n",
      "Epoch: 0 | Iteration: 114 | Classification loss: 0.81301 | Regression loss: 0.98443 | Running loss: 1.92350\n",
      "Epoch: 0 | Iteration: 115 | Classification loss: 0.54744 | Regression loss: 0.77841 | Running loss: 1.91834\n",
      "Epoch: 0 | Iteration: 116 | Classification loss: 0.61417 | Regression loss: 0.80959 | Running loss: 1.91412\n",
      "Epoch: 0 | Iteration: 117 | Classification loss: 0.51450 | Regression loss: 0.80534 | Running loss: 1.90908\n",
      "Epoch: 0 | Iteration: 118 | Classification loss: 0.74504 | Regression loss: 1.07104 | Running loss: 1.90830\n",
      "Epoch: 0 | Iteration: 119 | Classification loss: 1.33690 | Regression loss: 1.14519 | Running loss: 1.91308\n",
      "Epoch: 0 | Iteration: 120 | Classification loss: 0.85025 | Regression loss: 0.93279 | Running loss: 1.91201\n",
      "Epoch: 0 | Iteration: 121 | Classification loss: 0.35726 | Regression loss: 0.79487 | Running loss: 1.90578\n",
      "Epoch: 0 | Iteration: 122 | Classification loss: 0.83706 | Regression loss: 1.01158 | Running loss: 1.90531\n",
      "Epoch: 0 | Iteration: 123 | Classification loss: 1.11256 | Regression loss: 0.75280 | Running loss: 1.90499\n",
      "Epoch: 0 | Iteration: 124 | Classification loss: 1.85652 | Regression loss: 0.80210 | Running loss: 1.91102\n",
      "Epoch: 0 | Iteration: 125 | Classification loss: 0.66859 | Regression loss: 0.94619 | Running loss: 1.90867\n",
      "Epoch: 0 | Iteration: 126 | Classification loss: 0.61141 | Regression loss: 0.90397 | Running loss: 1.90557\n",
      "Epoch: 0 | Iteration: 127 | Classification loss: 0.61818 | Regression loss: 0.95820 | Running loss: 1.90300\n",
      "Epoch: 0 | Iteration: 128 | Classification loss: 0.63587 | Regression loss: 0.82723 | Running loss: 1.89959\n",
      "Epoch: 0 | Iteration: 129 | Classification loss: 0.77029 | Regression loss: 1.44165 | Running loss: 1.90199\n",
      "Epoch: 0 | Iteration: 130 | Classification loss: 0.47581 | Regression loss: 0.77359 | Running loss: 1.89701\n",
      "Epoch: 0 | Iteration: 131 | Classification loss: 0.56927 | Regression loss: 0.78684 | Running loss: 1.89291\n",
      "Epoch: 0 | Iteration: 132 | Classification loss: 0.68772 | Regression loss: 1.21773 | Running loss: 1.89301\n",
      "Epoch: 0 | Iteration: 133 | Classification loss: 0.62836 | Regression loss: 0.83205 | Running loss: 1.88978\n",
      "Epoch: 0 | Iteration: 134 | Classification loss: 0.59315 | Regression loss: 0.78175 | Running loss: 1.88596\n",
      "Epoch: 0 | Iteration: 135 | Classification loss: 0.79639 | Regression loss: 0.54651 | Running loss: 1.88197\n",
      "Epoch: 0 | Iteration: 136 | Classification loss: 0.55925 | Regression loss: 0.82067 | Running loss: 1.87831\n",
      "Epoch: 0 | Iteration: 137 | Classification loss: 0.26714 | Regression loss: 0.80801 | Running loss: 1.87249\n",
      "Epoch: 0 | Iteration: 138 | Classification loss: 0.52324 | Regression loss: 1.27813 | Running loss: 1.87198\n",
      "Epoch: 0 | Iteration: 139 | Classification loss: 0.59668 | Regression loss: 0.55656 | Running loss: 1.86684\n",
      "Epoch: 0 | Iteration: 140 | Classification loss: 0.59196 | Regression loss: 1.00526 | Running loss: 1.86493\n",
      "Epoch: 0 | Iteration: 141 | Classification loss: 0.69161 | Regression loss: 1.01077 | Running loss: 1.86378\n",
      "Epoch: 0 | Iteration: 142 | Classification loss: 0.67003 | Regression loss: 1.12502 | Running loss: 1.86330\n",
      "Epoch: 0 | Iteration: 143 | Classification loss: 0.89670 | Regression loss: 1.03021 | Running loss: 1.86375\n",
      "Epoch: 0 | Iteration: 144 | Classification loss: 0.91907 | Regression loss: 0.97569 | Running loss: 1.86396\n",
      "Epoch: 0 | Iteration: 145 | Classification loss: 0.75147 | Regression loss: 0.85454 | Running loss: 1.86219\n",
      "Epoch: 0 | Iteration: 146 | Classification loss: 0.59556 | Regression loss: 1.02665 | Running loss: 1.86056\n",
      "Epoch: 0 | Iteration: 147 | Classification loss: 0.73786 | Regression loss: 0.97327 | Running loss: 1.85955\n",
      "Epoch: 0 | Iteration: 148 | Classification loss: 0.48212 | Regression loss: 1.05728 | Running loss: 1.85740\n",
      "Epoch: 0 | Iteration: 149 | Classification loss: 0.55364 | Regression loss: 0.94296 | Running loss: 1.85500\n",
      "Epoch: 0 | Iteration: 150 | Classification loss: 0.53849 | Regression loss: 0.70758 | Running loss: 1.85096\n",
      "Epoch: 0 | Iteration: 151 | Classification loss: 0.61978 | Regression loss: 0.85727 | Running loss: 1.84850\n",
      "Epoch: 0 | Iteration: 152 | Classification loss: 0.59676 | Regression loss: 0.82281 | Running loss: 1.84570\n",
      "Epoch: 0 | Iteration: 153 | Classification loss: 0.85057 | Regression loss: 0.91781 | Running loss: 1.84520\n",
      "Epoch: 0 | Iteration: 154 | Classification loss: 0.67848 | Regression loss: 0.89020 | Running loss: 1.84341\n",
      "Epoch: 0 | Iteration: 155 | Classification loss: 0.46497 | Regression loss: 0.51738 | Running loss: 1.83790\n",
      "Epoch: 0 | Iteration: 156 | Classification loss: 0.56115 | Regression loss: 0.61672 | Running loss: 1.83369\n",
      "Epoch: 0 | Iteration: 157 | Classification loss: 0.48151 | Regression loss: 0.63818 | Running loss: 1.82917\n",
      "Epoch: 0 | Iteration: 158 | Classification loss: 0.40539 | Regression loss: 0.73167 | Running loss: 1.82482\n",
      "Epoch: 0 | Iteration: 159 | Classification loss: 0.65908 | Regression loss: 0.54182 | Running loss: 1.82092\n",
      "Epoch: 0 | Iteration: 160 | Classification loss: 0.56261 | Regression loss: 0.92739 | Running loss: 1.81886\n",
      "Epoch: 0 | Iteration: 161 | Classification loss: 0.48873 | Regression loss: 0.93616 | Running loss: 1.81643\n",
      "Epoch: 0 | Iteration: 162 | Classification loss: 0.32679 | Regression loss: 0.79929 | Running loss: 1.81220\n",
      "Epoch: 0 | Iteration: 163 | Classification loss: 0.74821 | Regression loss: 0.86162 | Running loss: 1.81096\n",
      "Epoch: 0 | Iteration: 164 | Classification loss: 0.76819 | Regression loss: 0.94335 | Running loss: 1.81036\n",
      "Epoch: 0 | Iteration: 165 | Classification loss: 0.68385 | Regression loss: 0.86572 | Running loss: 1.80879\n",
      "Epoch: 0 | Iteration: 166 | Classification loss: 0.67311 | Regression loss: 0.79324 | Running loss: 1.80674\n",
      "Epoch: 0 | Iteration: 167 | Classification loss: 0.64830 | Regression loss: 1.02666 | Running loss: 1.80595\n",
      "Epoch: 0 | Iteration: 168 | Classification loss: 0.65011 | Regression loss: 0.87846 | Running loss: 1.80431\n",
      "Epoch: 0 | Iteration: 169 | Classification loss: 1.22790 | Regression loss: 1.11736 | Running loss: 1.80750\n",
      "Epoch: 0 | Iteration: 170 | Classification loss: 0.59690 | Regression loss: 0.70128 | Running loss: 1.80452\n",
      "Epoch: 0 | Iteration: 171 | Classification loss: 0.46308 | Regression loss: 0.61082 | Running loss: 1.80027\n",
      "Epoch: 0 | Iteration: 172 | Classification loss: 0.48669 | Regression loss: 0.83384 | Running loss: 1.79750\n",
      "Epoch: 0 | Iteration: 173 | Classification loss: 0.57538 | Regression loss: 0.83988 | Running loss: 1.79530\n",
      "Epoch: 0 | Iteration: 174 | Classification loss: 0.32969 | Regression loss: 0.77626 | Running loss: 1.79136\n",
      "Epoch: 0 | Iteration: 175 | Classification loss: 0.99063 | Regression loss: 0.97633 | Running loss: 1.79236\n",
      "Epoch: 0 | Iteration: 176 | Classification loss: 0.85861 | Regression loss: 0.91279 | Running loss: 1.79224\n",
      "Epoch: 0 | Iteration: 177 | Classification loss: 0.91948 | Regression loss: 1.32101 | Running loss: 1.79476\n",
      "Epoch: 0 | Iteration: 178 | Classification loss: 0.52798 | Regression loss: 0.84208 | Running loss: 1.79239\n",
      "Epoch: 0 | Iteration: 179 | Classification loss: 1.44435 | Regression loss: 1.07152 | Running loss: 1.79640\n",
      "Epoch: 0 | Iteration: 180 | Classification loss: 1.34998 | Regression loss: 1.10505 | Running loss: 1.80004\n",
      "Epoch: 0 | Iteration: 181 | Classification loss: 0.61821 | Regression loss: 0.92197 | Running loss: 1.79862\n",
      "Epoch: 0 | Iteration: 182 | Classification loss: 0.73101 | Regression loss: 0.88229 | Running loss: 1.79760\n",
      "Epoch: 0 | Iteration: 183 | Classification loss: 0.62219 | Regression loss: 0.55198 | Running loss: 1.79421\n",
      "Epoch: 0 | Iteration: 184 | Classification loss: 0.42563 | Regression loss: 0.48192 | Running loss: 1.78942\n",
      "Epoch: 0 | Iteration: 185 | Classification loss: 0.69464 | Regression loss: 1.07269 | Running loss: 1.78930\n",
      "Epoch: 0 | Iteration: 186 | Classification loss: 0.54464 | Regression loss: 1.15238 | Running loss: 1.78881\n",
      "Epoch: 0 | Iteration: 187 | Classification loss: 0.39797 | Regression loss: 0.45963 | Running loss: 1.78386\n",
      "Epoch: 0 | Iteration: 188 | Classification loss: 0.81348 | Regression loss: 0.99147 | Running loss: 1.78397\n",
      "Epoch: 0 | Iteration: 189 | Classification loss: 0.73349 | Regression loss: 0.68878 | Running loss: 1.78206\n",
      "Epoch: 0 | Iteration: 190 | Classification loss: 0.53276 | Regression loss: 0.78334 | Running loss: 1.77962\n",
      "Epoch: 0 | Iteration: 191 | Classification loss: 0.50880 | Regression loss: 0.64560 | Running loss: 1.77637\n",
      "Epoch: 0 | Iteration: 192 | Classification loss: 0.62480 | Regression loss: 0.91998 | Running loss: 1.77517\n",
      "Epoch: 0 | Iteration: 193 | Classification loss: 0.53256 | Regression loss: 0.87706 | Running loss: 1.77328\n",
      "Epoch: 0 | Iteration: 194 | Classification loss: 0.62299 | Regression loss: 1.04869 | Running loss: 1.77276\n",
      "Epoch: 0 | Iteration: 195 | Classification loss: 0.61286 | Regression loss: 0.90818 | Running loss: 1.77148\n",
      "Epoch: 0 | Iteration: 196 | Classification loss: 0.57818 | Regression loss: 0.82317 | Running loss: 1.76960\n",
      "Epoch: 0 | Iteration: 197 | Classification loss: 0.70224 | Regression loss: 0.87022 | Running loss: 1.76860\n",
      "Epoch: 0 | Iteration: 198 | Classification loss: 0.70130 | Regression loss: 0.99939 | Running loss: 1.76826\n",
      "Epoch: 0 | Iteration: 199 | Classification loss: 0.34457 | Regression loss: 0.59343 | Running loss: 1.76411\n",
      "Epoch: 0 | Iteration: 200 | Classification loss: 0.63027 | Regression loss: 1.09757 | Running loss: 1.76393\n",
      "Epoch: 0 | Iteration: 201 | Classification loss: 0.73460 | Regression loss: 0.91577 | Running loss: 1.76337\n",
      "Epoch: 0 | Iteration: 202 | Classification loss: 0.84817 | Regression loss: 1.16877 | Running loss: 1.76462\n",
      "Epoch: 0 | Iteration: 203 | Classification loss: 0.41629 | Regression loss: 0.00000 | Running loss: 1.75801\n",
      "Epoch: 0 | Iteration: 204 | Classification loss: 0.42806 | Regression loss: 0.60124 | Running loss: 1.75445\n",
      "Epoch: 0 | Iteration: 205 | Classification loss: 0.37062 | Regression loss: 0.90643 | Running loss: 1.75214\n",
      "Epoch: 0 | Iteration: 206 | Classification loss: 0.51744 | Regression loss: 0.78250 | Running loss: 1.74995\n",
      "Epoch: 0 | Iteration: 207 | Classification loss: 0.33558 | Regression loss: 0.55627 | Running loss: 1.74583\n",
      "Epoch: 0 | Iteration: 208 | Classification loss: 0.57023 | Regression loss: 0.76134 | Running loss: 1.74384\n",
      "Epoch: 0 | Iteration: 209 | Classification loss: 0.32323 | Regression loss: 0.72572 | Running loss: 1.74054\n",
      "Epoch: 0 | Iteration: 210 | Classification loss: 0.77678 | Regression loss: 0.86085 | Running loss: 1.74005\n",
      "Epoch: 0 | Iteration: 211 | Classification loss: 0.54958 | Regression loss: 0.65568 | Running loss: 1.73753\n",
      "Epoch: 0 | Iteration: 212 | Classification loss: 1.01283 | Regression loss: 0.85921 | Running loss: 1.73816\n",
      "Epoch: 0 | Iteration: 213 | Classification loss: 0.93055 | Regression loss: 1.10070 | Running loss: 1.73953\n",
      "Epoch: 0 | Iteration: 214 | Classification loss: 0.80661 | Regression loss: 1.07561 | Running loss: 1.74019\n",
      "Epoch: 0 | Iteration: 215 | Classification loss: 0.51154 | Regression loss: 0.73373 | Running loss: 1.73790\n",
      "Epoch: 0 | Iteration: 216 | Classification loss: 0.59397 | Regression loss: 0.50688 | Running loss: 1.73496\n",
      "Epoch: 0 | Iteration: 217 | Classification loss: 0.92056 | Regression loss: 0.80617 | Running loss: 1.73493\n",
      "Epoch: 0 | Iteration: 218 | Classification loss: 0.48306 | Regression loss: 0.76158 | Running loss: 1.73269\n",
      "Epoch: 0 | Iteration: 219 | Classification loss: 0.61513 | Regression loss: 0.98968 | Running loss: 1.73211\n",
      "Epoch: 0 | Iteration: 220 | Classification loss: 0.57170 | Regression loss: 1.04158 | Running loss: 1.73157\n",
      "Epoch: 0 | Iteration: 221 | Classification loss: 0.58648 | Regression loss: 0.76694 | Running loss: 1.72986\n",
      "Epoch: 0 | Iteration: 222 | Classification loss: 0.60747 | Regression loss: 0.79045 | Running loss: 1.72838\n",
      "Epoch: 0 | Iteration: 223 | Classification loss: 0.46365 | Regression loss: 0.55718 | Running loss: 1.72522\n",
      "Epoch: 0 | Iteration: 224 | Classification loss: 0.36126 | Regression loss: 0.55423 | Running loss: 1.72162\n",
      "Epoch: 0 | Iteration: 225 | Classification loss: 0.48836 | Regression loss: 0.72030 | Running loss: 1.71935\n",
      "Epoch: 0 | Iteration: 226 | Classification loss: 0.45093 | Regression loss: 0.80338 | Running loss: 1.71730\n",
      "Epoch: 0 | Iteration: 227 | Classification loss: 0.55097 | Regression loss: 0.97902 | Running loss: 1.71648\n",
      "Epoch: 0 | Iteration: 228 | Classification loss: 0.49991 | Regression loss: 0.80412 | Running loss: 1.71468\n",
      "Epoch: 0 | Iteration: 229 | Classification loss: 0.61271 | Regression loss: 0.87349 | Running loss: 1.71368\n",
      "Epoch: 0 | Iteration: 230 | Classification loss: 0.50212 | Regression loss: 0.48518 | Running loss: 1.71054\n",
      "Epoch: 0 | Iteration: 231 | Classification loss: 0.67897 | Regression loss: 0.85175 | Running loss: 1.70976\n",
      "Epoch: 0 | Iteration: 232 | Classification loss: 0.68857 | Regression loss: 0.89281 | Running loss: 1.70921\n",
      "Epoch: 0 | Iteration: 233 | Classification loss: 0.65022 | Regression loss: 0.74611 | Running loss: 1.70788\n",
      "Epoch: 0 | Iteration: 234 | Classification loss: 0.67461 | Regression loss: 0.94082 | Running loss: 1.70748\n",
      "Epoch: 0 | Iteration: 235 | Classification loss: 0.38772 | Regression loss: 0.73834 | Running loss: 1.70502\n",
      "Epoch: 0 | Iteration: 236 | Classification loss: 0.50947 | Regression loss: 0.84846 | Running loss: 1.70355\n",
      "Epoch: 0 | Iteration: 237 | Classification loss: 0.70496 | Regression loss: 0.71347 | Running loss: 1.70236\n",
      "Epoch: 0 | Iteration: 238 | Classification loss: 0.41976 | Regression loss: 0.72690 | Running loss: 1.70003\n",
      "Epoch: 0 | Iteration: 239 | Classification loss: 0.46574 | Regression loss: 0.82161 | Running loss: 1.69831\n",
      "Epoch: 0 | Iteration: 240 | Classification loss: 0.38461 | Regression loss: 0.54655 | Running loss: 1.69513\n",
      "Epoch: 0 | Iteration: 241 | Classification loss: 0.41747 | Regression loss: 0.55502 | Running loss: 1.69214\n",
      "Epoch: 0 | Iteration: 242 | Classification loss: 0.33543 | Regression loss: 0.49636 | Running loss: 1.68860\n",
      "Epoch: 0 | Iteration: 243 | Classification loss: 0.78655 | Regression loss: 0.99213 | Running loss: 1.68897\n",
      "Epoch: 0 | Iteration: 244 | Classification loss: 0.62839 | Regression loss: 0.83146 | Running loss: 1.68804\n",
      "Epoch: 0 | Iteration: 245 | Classification loss: 0.62152 | Regression loss: 0.63706 | Running loss: 1.68629\n",
      "Epoch: 0 | Iteration: 246 | Classification loss: 0.53007 | Regression loss: 0.93602 | Running loss: 1.68540\n",
      "Epoch: 0 | Iteration: 247 | Classification loss: 0.42043 | Regression loss: 0.82809 | Running loss: 1.68364\n",
      "Epoch: 0 | Iteration: 248 | Classification loss: 0.66967 | Regression loss: 0.93670 | Running loss: 1.68333\n",
      "Epoch: 0 | Iteration: 249 | Classification loss: 0.74019 | Regression loss: 0.90109 | Running loss: 1.68316\n",
      "Epoch: 0 | Iteration: 250 | Classification loss: 0.42030 | Regression loss: 0.89859 | Running loss: 1.68171\n",
      "Epoch: 0 | Iteration: 251 | Classification loss: 0.51190 | Regression loss: 0.88662 | Running loss: 1.68058\n",
      "Epoch: 0 | Iteration: 252 | Classification loss: 0.63790 | Regression loss: 0.85901 | Running loss: 1.67986\n",
      "Epoch: 0 | Iteration: 253 | Classification loss: 0.55478 | Regression loss: 0.88226 | Running loss: 1.67890\n",
      "Epoch: 0 | Iteration: 254 | Classification loss: 0.73556 | Regression loss: 0.90995 | Running loss: 1.67877\n",
      "Epoch: 0 | Iteration: 255 | Classification loss: 0.61086 | Regression loss: 0.80744 | Running loss: 1.67775\n",
      "Epoch: 0 | Iteration: 256 | Classification loss: 0.32529 | Regression loss: 0.63187 | Running loss: 1.67495\n",
      "Epoch: 0 | Iteration: 257 | Classification loss: 0.55113 | Regression loss: 1.01834 | Running loss: 1.67454\n",
      "Epoch: 0 | Iteration: 258 | Classification loss: 0.45284 | Regression loss: 0.88131 | Running loss: 1.67323\n",
      "Epoch: 0 | Iteration: 259 | Classification loss: 0.52095 | Regression loss: 0.78638 | Running loss: 1.67182\n",
      "Epoch: 0 | Iteration: 260 | Classification loss: 0.49642 | Regression loss: 0.86985 | Running loss: 1.67065\n",
      "Epoch: 0 | Iteration: 261 | Classification loss: 0.43250 | Regression loss: 0.51027 | Running loss: 1.66787\n",
      "Epoch: 0 | Iteration: 262 | Classification loss: 0.51999 | Regression loss: 0.91713 | Running loss: 1.66699\n",
      "Epoch: 0 | Iteration: 263 | Classification loss: 0.47901 | Regression loss: 0.80701 | Running loss: 1.66555\n",
      "Epoch: 0 | Iteration: 264 | Classification loss: 0.71342 | Regression loss: 0.43263 | Running loss: 1.66359\n",
      "Epoch: 0 | Iteration: 265 | Classification loss: 0.38373 | Regression loss: 0.96900 | Running loss: 1.66242\n",
      "Epoch: 0 | Iteration: 266 | Classification loss: 0.97417 | Regression loss: 0.98217 | Running loss: 1.66352\n",
      "Epoch: 0 | Iteration: 267 | Classification loss: 0.53920 | Regression loss: 0.83254 | Running loss: 1.66243\n",
      "Epoch: 0 | Iteration: 268 | Classification loss: 0.30543 | Regression loss: 0.54015 | Running loss: 1.65940\n",
      "Epoch: 0 | Iteration: 269 | Classification loss: 0.41472 | Regression loss: 0.66054 | Running loss: 1.65723\n",
      "Epoch: 0 | Iteration: 270 | Classification loss: 0.48671 | Regression loss: 0.80272 | Running loss: 1.65588\n",
      "Epoch: 0 | Iteration: 271 | Classification loss: 0.59280 | Regression loss: 0.77345 | Running loss: 1.65481\n",
      "Epoch: 0 | Iteration: 272 | Classification loss: 0.40838 | Regression loss: 0.97267 | Running loss: 1.65381\n",
      "Epoch: 0 | Iteration: 273 | Classification loss: 0.69618 | Regression loss: 0.95388 | Running loss: 1.65379\n",
      "Epoch: 0 | Iteration: 274 | Classification loss: 1.51729 | Regression loss: 0.84203 | Running loss: 1.65636\n",
      "Epoch: 0 | Iteration: 275 | Classification loss: 0.85871 | Regression loss: 0.88832 | Running loss: 1.65669\n",
      "Epoch: 0 | Iteration: 276 | Classification loss: 0.71635 | Regression loss: 0.75611 | Running loss: 1.65602\n",
      "Epoch: 0 | Iteration: 277 | Classification loss: 0.46902 | Regression loss: 0.69883 | Running loss: 1.65427\n",
      "Epoch: 0 | Iteration: 278 | Classification loss: 0.53363 | Regression loss: 0.85980 | Running loss: 1.65333\n",
      "Epoch: 0 | Iteration: 279 | Classification loss: 0.48133 | Regression loss: 0.67814 | Running loss: 1.65157\n",
      "Epoch: 0 | Iteration: 280 | Classification loss: 0.52256 | Regression loss: 0.64844 | Running loss: 1.64986\n",
      "Epoch: 0 | Iteration: 281 | Classification loss: 0.54405 | Regression loss: 1.19070 | Running loss: 1.65016\n",
      "Epoch: 0 | Iteration: 282 | Classification loss: 0.68925 | Regression loss: 0.81699 | Running loss: 1.64965\n",
      "Epoch: 0 | Iteration: 283 | Classification loss: 0.39043 | Regression loss: 0.84507 | Running loss: 1.64819\n",
      "Epoch: 0 | Iteration: 284 | Classification loss: 0.76499 | Regression loss: 0.42015 | Running loss: 1.64657\n",
      "Epoch: 0 | Iteration: 285 | Classification loss: 0.51099 | Regression loss: 0.70524 | Running loss: 1.64506\n",
      "Epoch: 0 | Iteration: 286 | Classification loss: 0.70602 | Regression loss: 0.88974 | Running loss: 1.64489\n",
      "Epoch: 0 | Iteration: 287 | Classification loss: 0.50897 | Regression loss: 0.81719 | Running loss: 1.64378\n",
      "Epoch: 0 | Iteration: 288 | Classification loss: 0.53388 | Regression loss: 0.96737 | Running loss: 1.64329\n",
      "Epoch: 0 | Iteration: 289 | Classification loss: 0.51777 | Regression loss: 1.07620 | Running loss: 1.64312\n",
      "Epoch: 0 | Iteration: 290 | Classification loss: 0.68245 | Regression loss: 1.00402 | Running loss: 1.64327\n",
      "Epoch: 0 | Iteration: 291 | Classification loss: 0.61120 | Regression loss: 0.61378 | Running loss: 1.64184\n",
      "Epoch: 0 | Iteration: 292 | Classification loss: 0.60730 | Regression loss: 0.52227 | Running loss: 1.64009\n",
      "Epoch: 0 | Iteration: 293 | Classification loss: 0.58210 | Regression loss: 0.48355 | Running loss: 1.63814\n",
      "Epoch: 0 | Iteration: 294 | Classification loss: 0.59268 | Regression loss: 0.89788 | Running loss: 1.63764\n",
      "Epoch: 0 | Iteration: 295 | Classification loss: 0.55103 | Regression loss: 0.73515 | Running loss: 1.63645\n",
      "Epoch: 0 | Iteration: 296 | Classification loss: 0.49903 | Regression loss: 0.54430 | Running loss: 1.63445\n",
      "Epoch: 0 | Iteration: 297 | Classification loss: 0.48691 | Regression loss: 0.72728 | Running loss: 1.63304\n",
      "Epoch: 0 | Iteration: 298 | Classification loss: 0.53576 | Regression loss: 0.77882 | Running loss: 1.63198\n",
      "Epoch: 0 | Iteration: 299 | Classification loss: 0.44747 | Regression loss: 0.74110 | Running loss: 1.63050\n",
      "Epoch: 0 | Iteration: 300 | Classification loss: 0.81586 | Regression loss: 0.93910 | Running loss: 1.63091\n",
      "Epoch: 0 | Iteration: 301 | Classification loss: 0.58227 | Regression loss: 0.54807 | Running loss: 1.62925\n",
      "Epoch: 0 | Iteration: 302 | Classification loss: 0.63549 | Regression loss: 0.40815 | Running loss: 1.62732\n",
      "Epoch: 0 | Iteration: 303 | Classification loss: 0.66839 | Regression loss: 0.57625 | Running loss: 1.62606\n",
      "Epoch: 0 | Iteration: 304 | Classification loss: 0.39983 | Regression loss: 0.49917 | Running loss: 1.62368\n",
      "Epoch: 0 | Iteration: 305 | Classification loss: 0.72293 | Regression loss: 0.79910 | Running loss: 1.62335\n",
      "Epoch: 0 | Iteration: 306 | Classification loss: 0.29821 | Regression loss: 0.46767 | Running loss: 1.62055\n",
      "Epoch: 0 | Iteration: 307 | Classification loss: 0.64207 | Regression loss: 0.73737 | Running loss: 1.61977\n",
      "Epoch: 0 | Iteration: 308 | Classification loss: 0.75549 | Regression loss: 0.89759 | Running loss: 1.61988\n",
      "Epoch: 0 | Iteration: 309 | Classification loss: 0.42513 | Regression loss: 0.43554 | Running loss: 1.61743\n",
      "Epoch: 0 | Iteration: 310 | Classification loss: 0.62717 | Regression loss: 0.53792 | Running loss: 1.61597\n",
      "Epoch: 0 | Iteration: 311 | Classification loss: 0.73465 | Regression loss: 0.81359 | Running loss: 1.61576\n",
      "Epoch: 0 | Iteration: 312 | Classification loss: 0.36686 | Regression loss: 0.49472 | Running loss: 1.61335\n",
      "Epoch: 0 | Iteration: 313 | Classification loss: 0.54918 | Regression loss: 0.84018 | Running loss: 1.61263\n",
      "Epoch: 0 | Iteration: 314 | Classification loss: 0.79939 | Regression loss: 0.99263 | Running loss: 1.61320\n",
      "Epoch: 0 | Iteration: 315 | Classification loss: 0.65995 | Regression loss: 0.78294 | Running loss: 1.61266\n",
      "Epoch: 0 | Iteration: 316 | Classification loss: 0.63174 | Regression loss: 0.88086 | Running loss: 1.61235\n",
      "Epoch: 0 | Iteration: 317 | Classification loss: 0.41800 | Regression loss: 0.83493 | Running loss: 1.61122\n",
      "Epoch: 0 | Iteration: 318 | Classification loss: 0.82963 | Regression loss: 0.87389 | Running loss: 1.61151\n",
      "Epoch: 0 | Iteration: 319 | Classification loss: 0.64929 | Regression loss: 0.83654 | Running loss: 1.61112\n",
      "Epoch: 0 | Iteration: 320 | Classification loss: 0.61895 | Regression loss: 1.04262 | Running loss: 1.61127\n",
      "Epoch: 0 | Iteration: 321 | Classification loss: 0.83367 | Regression loss: 0.94409 | Running loss: 1.61179\n",
      "Epoch: 0 | Iteration: 322 | Classification loss: 0.39073 | Regression loss: 0.60967 | Running loss: 1.60990\n",
      "Epoch: 0 | Iteration: 323 | Classification loss: 0.61109 | Regression loss: 0.61700 | Running loss: 1.60872\n",
      "Epoch: 0 | Iteration: 324 | Classification loss: 0.69833 | Regression loss: 0.97099 | Running loss: 1.60890\n",
      "Epoch: 0 | Iteration: 325 | Classification loss: 0.44645 | Regression loss: 0.58067 | Running loss: 1.60712\n",
      "Epoch: 0 | Iteration: 326 | Classification loss: 0.62558 | Regression loss: 0.94409 | Running loss: 1.60701\n",
      "Epoch: 0 | Iteration: 327 | Classification loss: 0.53116 | Regression loss: 1.15602 | Running loss: 1.60725\n",
      "Epoch: 0 | Iteration: 328 | Classification loss: 0.45741 | Regression loss: 0.69755 | Running loss: 1.60588\n",
      "Epoch: 0 | Iteration: 329 | Classification loss: 0.55121 | Regression loss: 0.84772 | Running loss: 1.60525\n",
      "Epoch: 0 | Iteration: 330 | Classification loss: 0.76816 | Regression loss: 1.09722 | Running loss: 1.60603\n",
      "Epoch: 0 | Iteration: 331 | Classification loss: 0.33590 | Regression loss: 0.59604 | Running loss: 1.60400\n",
      "Epoch: 0 | Iteration: 332 | Classification loss: 0.45569 | Regression loss: 0.66706 | Running loss: 1.60256\n",
      "Epoch: 0 | Iteration: 333 | Classification loss: 0.43475 | Regression loss: 0.72023 | Running loss: 1.60122\n",
      "Epoch: 0 | Iteration: 334 | Classification loss: 0.42095 | Regression loss: 0.86924 | Running loss: 1.60029\n",
      "Epoch: 0 | Iteration: 335 | Classification loss: 0.42852 | Regression loss: 0.66150 | Running loss: 1.59877\n",
      "Epoch: 0 | Iteration: 336 | Classification loss: 0.52241 | Regression loss: 0.84921 | Running loss: 1.59810\n",
      "Epoch: 0 | Iteration: 337 | Classification loss: 0.80726 | Regression loss: 0.65151 | Running loss: 1.59769\n",
      "Epoch: 0 | Iteration: 338 | Classification loss: 0.52442 | Regression loss: 0.88898 | Running loss: 1.59714\n",
      "Epoch: 0 | Iteration: 339 | Classification loss: 0.37717 | Regression loss: 0.76684 | Running loss: 1.59581\n",
      "Epoch: 0 | Iteration: 340 | Classification loss: 0.25304 | Regression loss: 0.63535 | Running loss: 1.59373\n",
      "Epoch: 0 | Iteration: 341 | Classification loss: 0.52813 | Regression loss: 0.70677 | Running loss: 1.59269\n",
      "Epoch: 0 | Iteration: 342 | Classification loss: 0.51089 | Regression loss: 0.71333 | Running loss: 1.59161\n",
      "Epoch: 0 | Iteration: 343 | Classification loss: 0.62062 | Regression loss: 0.49455 | Running loss: 1.59023\n",
      "Epoch: 0 | Iteration: 344 | Classification loss: 0.57804 | Regression loss: 0.48504 | Running loss: 1.58870\n",
      "Epoch: 0 | Iteration: 345 | Classification loss: 0.41876 | Regression loss: 0.65623 | Running loss: 1.58721\n",
      "Epoch: 0 | Iteration: 346 | Classification loss: 0.34077 | Regression loss: 0.46420 | Running loss: 1.58496\n",
      "Epoch: 0 | Iteration: 347 | Classification loss: 0.78431 | Regression loss: 0.83245 | Running loss: 1.58505\n",
      "Epoch: 0 | Iteration: 348 | Classification loss: 0.61310 | Regression loss: 0.74102 | Running loss: 1.58439\n",
      "Epoch: 0 | Iteration: 349 | Classification loss: 0.55254 | Regression loss: 0.85182 | Running loss: 1.58387\n",
      "Epoch: 0 | Iteration: 350 | Classification loss: 0.56615 | Regression loss: 0.74041 | Running loss: 1.58308\n",
      "Epoch: 0 | Iteration: 351 | Classification loss: 0.67710 | Regression loss: 0.70731 | Running loss: 1.58252\n",
      "Epoch: 0 | Iteration: 352 | Classification loss: 0.38826 | Regression loss: 0.44460 | Running loss: 1.58040\n",
      "Epoch: 0 | Iteration: 353 | Classification loss: 0.62502 | Regression loss: 0.80904 | Running loss: 1.57998\n",
      "Epoch: 0 | Iteration: 354 | Classification loss: 0.58513 | Regression loss: 0.42975 | Running loss: 1.57839\n",
      "Epoch: 0 | Iteration: 355 | Classification loss: 0.45845 | Regression loss: 0.76873 | Running loss: 1.57740\n",
      "Epoch: 0 | Iteration: 356 | Classification loss: 0.36063 | Regression loss: 0.64498 | Running loss: 1.57580\n",
      "Epoch: 0 | Iteration: 357 | Classification loss: 0.48628 | Regression loss: 0.79635 | Running loss: 1.57498\n",
      "Epoch: 0 | Iteration: 358 | Classification loss: 0.45581 | Regression loss: 0.69191 | Running loss: 1.57379\n",
      "Epoch: 0 | Iteration: 359 | Classification loss: 0.59920 | Regression loss: 0.86476 | Running loss: 1.57349\n",
      "Epoch: 0 | Iteration: 360 | Classification loss: 0.42819 | Regression loss: 0.42669 | Running loss: 1.57150\n",
      "Epoch: 0 | Iteration: 361 | Classification loss: 0.47453 | Regression loss: 0.86069 | Running loss: 1.57085\n",
      "Epoch: 0 | Iteration: 362 | Classification loss: 0.42914 | Regression loss: 0.30302 | Running loss: 1.56853\n",
      "Epoch: 0 | Iteration: 363 | Classification loss: 0.50507 | Regression loss: 0.26454 | Running loss: 1.56634\n",
      "Epoch: 0 | Iteration: 364 | Classification loss: 0.56089 | Regression loss: 0.77646 | Running loss: 1.56571\n",
      "Epoch: 0 | Iteration: 365 | Classification loss: 0.30497 | Regression loss: 0.58265 | Running loss: 1.56386\n",
      "Epoch: 0 | Iteration: 366 | Classification loss: 0.65936 | Regression loss: 0.66514 | Running loss: 1.56321\n",
      "Epoch: 0 | Iteration: 367 | Classification loss: 0.47332 | Regression loss: 0.75101 | Running loss: 1.56229\n",
      "Epoch: 0 | Iteration: 368 | Classification loss: 0.41862 | Regression loss: 0.59647 | Running loss: 1.56080\n",
      "Epoch: 0 | Iteration: 369 | Classification loss: 0.30247 | Regression loss: 0.87589 | Running loss: 1.55977\n",
      "Epoch: 0 | Iteration: 370 | Classification loss: 0.35062 | Regression loss: 0.27157 | Running loss: 1.55724\n",
      "Epoch: 0 | Iteration: 371 | Classification loss: 0.70264 | Regression loss: 0.71862 | Running loss: 1.55688\n",
      "Epoch: 0 | Iteration: 372 | Classification loss: 0.46831 | Regression loss: 0.54900 | Running loss: 1.55543\n",
      "Epoch: 0 | Iteration: 373 | Classification loss: 0.60071 | Regression loss: 0.66252 | Running loss: 1.55465\n",
      "Epoch: 0 | Iteration: 374 | Classification loss: 0.66314 | Regression loss: 0.81151 | Running loss: 1.55444\n",
      "Epoch: 0 | Iteration: 375 | Classification loss: 0.70195 | Regression loss: 0.80418 | Running loss: 1.55431\n",
      "Epoch: 0 | Iteration: 376 | Classification loss: 0.41991 | Regression loss: 0.67681 | Running loss: 1.55309\n",
      "Epoch: 0 | Iteration: 377 | Classification loss: 0.58756 | Regression loss: 0.86963 | Running loss: 1.55284\n",
      "Epoch: 0 | Iteration: 378 | Classification loss: 0.43858 | Regression loss: 0.73210 | Running loss: 1.55183\n",
      "Epoch: 0 | Iteration: 379 | Classification loss: 0.50115 | Regression loss: 0.65153 | Running loss: 1.55078\n",
      "Epoch: 0 | Iteration: 380 | Classification loss: 0.44033 | Regression loss: 0.78009 | Running loss: 1.54991\n",
      "Epoch: 0 | Iteration: 381 | Classification loss: 0.67148 | Regression loss: 0.91397 | Running loss: 1.55001\n",
      "Epoch: 0 | Iteration: 382 | Classification loss: 0.56645 | Regression loss: 0.80320 | Running loss: 1.54954\n",
      "Epoch: 0 | Iteration: 383 | Classification loss: 0.36342 | Regression loss: 0.73777 | Running loss: 1.54837\n",
      "Epoch: 0 | Iteration: 384 | Classification loss: 0.51323 | Regression loss: 1.15269 | Running loss: 1.54867\n",
      "Epoch: 0 | Iteration: 385 | Classification loss: 0.45761 | Regression loss: 0.68981 | Running loss: 1.54763\n",
      "Epoch: 0 | Iteration: 386 | Classification loss: 0.43344 | Regression loss: 0.75857 | Running loss: 1.54672\n",
      "Epoch: 0 | Iteration: 387 | Classification loss: 0.43707 | Regression loss: 0.73829 | Running loss: 1.54576\n",
      "Epoch: 0 | Iteration: 388 | Classification loss: 0.58156 | Regression loss: 0.82111 | Running loss: 1.54539\n",
      "Epoch: 0 | Iteration: 389 | Classification loss: 0.64655 | Regression loss: 0.87035 | Running loss: 1.54532\n",
      "Epoch: 0 | Iteration: 390 | Classification loss: 0.39323 | Regression loss: 0.73669 | Running loss: 1.54426\n",
      "Epoch: 0 | Iteration: 391 | Classification loss: 0.44121 | Regression loss: 0.66302 | Running loss: 1.54313\n",
      "Epoch: 0 | Iteration: 392 | Classification loss: 0.39658 | Regression loss: 0.78222 | Running loss: 1.54221\n",
      "Epoch: 0 | Iteration: 393 | Classification loss: 0.69784 | Regression loss: 0.62110 | Running loss: 1.54164\n",
      "Epoch: 0 | Iteration: 394 | Classification loss: 0.46314 | Regression loss: 0.55950 | Running loss: 1.54033\n",
      "Epoch: 0 | Iteration: 395 | Classification loss: 0.68887 | Regression loss: 0.95580 | Running loss: 1.54059\n",
      "Epoch: 0 | Iteration: 396 | Classification loss: 0.51318 | Regression loss: 0.67455 | Running loss: 1.53970\n",
      "Epoch: 0 | Iteration: 397 | Classification loss: 0.38959 | Regression loss: 0.73177 | Running loss: 1.53865\n",
      "Epoch: 0 | Iteration: 398 | Classification loss: 0.41987 | Regression loss: 0.35564 | Running loss: 1.53674\n",
      "Epoch: 0 | Iteration: 399 | Classification loss: 0.50836 | Regression loss: 0.88685 | Running loss: 1.53638\n",
      "Epoch: 0 | Iteration: 400 | Classification loss: 0.44539 | Regression loss: 0.72461 | Running loss: 1.53547\n",
      "Epoch: 0 | Iteration: 401 | Classification loss: 0.53607 | Regression loss: 1.05799 | Running loss: 1.53561\n",
      "Epoch: 0 | Iteration: 402 | Classification loss: 0.48578 | Regression loss: 0.53782 | Running loss: 1.53434\n",
      "Epoch: 0 | Iteration: 403 | Classification loss: 0.29403 | Regression loss: 0.56867 | Running loss: 1.53268\n",
      "Epoch: 0 | Iteration: 404 | Classification loss: 0.48012 | Regression loss: 0.76983 | Running loss: 1.53198\n",
      "Epoch: 0 | Iteration: 405 | Classification loss: 0.55733 | Regression loss: 0.58816 | Running loss: 1.53103\n",
      "Epoch: 0 | Iteration: 406 | Classification loss: 0.68421 | Regression loss: 0.78576 | Running loss: 1.53088\n",
      "Epoch: 0 | Iteration: 407 | Classification loss: 0.38538 | Regression loss: 0.50813 | Running loss: 1.52932\n",
      "Epoch: 0 | Iteration: 408 | Classification loss: 0.57047 | Regression loss: 0.87259 | Running loss: 1.52911\n",
      "Epoch: 0 | Iteration: 409 | Classification loss: 0.32879 | Regression loss: 0.73544 | Running loss: 1.52797\n",
      "Epoch: 0 | Iteration: 410 | Classification loss: 0.48286 | Regression loss: 0.35216 | Running loss: 1.52629\n",
      "Epoch: 0 | Iteration: 411 | Classification loss: 0.46428 | Regression loss: 0.73673 | Running loss: 1.52550\n",
      "Epoch: 0 | Iteration: 412 | Classification loss: 0.59020 | Regression loss: 0.99775 | Running loss: 1.52565\n",
      "Epoch: 0 | Iteration: 413 | Classification loss: 0.47304 | Regression loss: 0.87582 | Running loss: 1.52522\n",
      "Epoch: 0 | Iteration: 414 | Classification loss: 0.68071 | Regression loss: 1.09419 | Running loss: 1.52582\n",
      "Epoch: 0 | Iteration: 415 | Classification loss: 0.55183 | Regression loss: 0.70648 | Running loss: 1.52518\n",
      "Epoch: 0 | Iteration: 416 | Classification loss: 0.42315 | Regression loss: 1.04047 | Running loss: 1.52503\n",
      "Epoch: 0 | Iteration: 417 | Classification loss: 0.45316 | Regression loss: 0.67084 | Running loss: 1.52407\n",
      "Epoch: 0 | Iteration: 418 | Classification loss: 0.61473 | Regression loss: 0.76438 | Running loss: 1.52373\n",
      "Epoch: 0 | Iteration: 419 | Classification loss: 0.52374 | Regression loss: 0.78239 | Running loss: 1.52321\n",
      "Epoch: 0 | Iteration: 420 | Classification loss: 0.70676 | Regression loss: 0.88934 | Running loss: 1.52338\n",
      "Epoch: 0 | Iteration: 421 | Classification loss: 0.43079 | Regression loss: 0.62187 | Running loss: 1.52227\n",
      "Epoch: 0 | Iteration: 422 | Classification loss: 0.61708 | Regression loss: 0.86621 | Running loss: 1.52218\n",
      "Epoch: 0 | Iteration: 423 | Classification loss: 0.55073 | Regression loss: 0.41587 | Running loss: 1.52087\n",
      "Epoch: 0 | Iteration: 424 | Classification loss: 0.49836 | Regression loss: 0.87308 | Running loss: 1.52051\n",
      "Epoch: 0 | Iteration: 425 | Classification loss: 0.42298 | Regression loss: 0.52402 | Running loss: 1.51917\n",
      "Epoch: 0 | Iteration: 426 | Classification loss: 0.36842 | Regression loss: 0.56629 | Running loss: 1.51780\n",
      "Epoch: 0 | Iteration: 427 | Classification loss: 0.41450 | Regression loss: 0.78751 | Running loss: 1.51706\n",
      "Epoch: 0 | Iteration: 428 | Classification loss: 0.59067 | Regression loss: 0.96424 | Running loss: 1.51715\n",
      "Epoch: 0 | Iteration: 429 | Classification loss: 0.44128 | Regression loss: 0.55930 | Running loss: 1.51595\n",
      "Epoch: 0 | Iteration: 430 | Classification loss: 0.40858 | Regression loss: 0.60203 | Running loss: 1.51478\n",
      "Epoch: 0 | Iteration: 431 | Classification loss: 0.63891 | Regression loss: 0.83555 | Running loss: 1.51468\n",
      "Epoch: 0 | Iteration: 432 | Classification loss: 0.37598 | Regression loss: 0.76070 | Running loss: 1.51381\n",
      "Epoch: 0 | Iteration: 433 | Classification loss: 0.47427 | Regression loss: 0.59535 | Running loss: 1.51279\n",
      "Epoch: 0 | Iteration: 434 | Classification loss: 1.27251 | Regression loss: 0.32797 | Running loss: 1.51299\n",
      "Epoch: 0 | Iteration: 435 | Classification loss: 0.23511 | Regression loss: 0.50397 | Running loss: 1.51121\n",
      "Epoch: 0 | Iteration: 436 | Classification loss: 0.45848 | Regression loss: 0.68352 | Running loss: 1.51037\n",
      "Epoch: 0 | Iteration: 437 | Classification loss: 0.88615 | Regression loss: 0.98435 | Running loss: 1.51119\n",
      "Epoch: 0 | Iteration: 438 | Classification loss: 0.69140 | Regression loss: 0.78291 | Running loss: 1.51111\n",
      "Epoch: 0 | Iteration: 439 | Classification loss: 0.67341 | Regression loss: 0.83616 | Running loss: 1.51110\n",
      "Epoch: 0 | Iteration: 440 | Classification loss: 0.42043 | Regression loss: 0.46488 | Running loss: 1.50968\n",
      "Epoch: 0 | Iteration: 441 | Classification loss: 0.45871 | Regression loss: 0.86971 | Running loss: 1.50927\n",
      "Epoch: 0 | Iteration: 442 | Classification loss: 0.51677 | Regression loss: 0.70126 | Running loss: 1.50862\n",
      "Epoch: 0 | Iteration: 443 | Classification loss: 0.25469 | Regression loss: 0.63572 | Running loss: 1.50722\n",
      "Epoch: 0 | Iteration: 444 | Classification loss: 0.42280 | Regression loss: 0.58988 | Running loss: 1.50611\n",
      "Epoch: 0 | Iteration: 445 | Classification loss: 0.62243 | Regression loss: 0.82320 | Running loss: 1.50598\n",
      "Epoch: 0 | Iteration: 446 | Classification loss: 0.62890 | Regression loss: 0.71852 | Running loss: 1.50562\n",
      "Epoch: 0 | Iteration: 447 | Classification loss: 0.42435 | Regression loss: 0.61915 | Running loss: 1.50459\n",
      "Epoch: 0 | Iteration: 448 | Classification loss: 0.39666 | Regression loss: 0.49925 | Running loss: 1.50323\n",
      "Epoch: 0 | Iteration: 449 | Classification loss: 0.38269 | Regression loss: 0.72867 | Running loss: 1.50236\n",
      "Epoch: 0 | Iteration: 450 | Classification loss: 0.56251 | Regression loss: 0.82452 | Running loss: 1.50211\n",
      "Epoch: 0 | Iteration: 451 | Classification loss: 0.72523 | Regression loss: 0.89680 | Running loss: 1.50237\n",
      "Epoch: 0 | Iteration: 452 | Classification loss: 0.71112 | Regression loss: 0.86224 | Running loss: 1.50253\n",
      "Epoch: 0 | Iteration: 453 | Classification loss: 1.56808 | Regression loss: 0.00000 | Running loss: 1.50267\n",
      "Epoch: 0 | Iteration: 454 | Classification loss: 0.39830 | Regression loss: 0.63126 | Running loss: 1.50163\n",
      "Epoch: 0 | Iteration: 455 | Classification loss: 0.43080 | Regression loss: 0.57936 | Running loss: 1.50056\n",
      "Epoch: 0 | Iteration: 456 | Classification loss: 0.38773 | Regression loss: 0.70256 | Running loss: 1.49966\n",
      "Epoch: 0 | Iteration: 457 | Classification loss: 0.69438 | Regression loss: 0.85789 | Running loss: 1.49977\n",
      "Epoch: 0 | Iteration: 458 | Classification loss: 0.33801 | Regression loss: 0.89099 | Running loss: 1.49918\n",
      "Epoch: 0 | Iteration: 459 | Classification loss: 0.39031 | Regression loss: 0.70763 | Running loss: 1.49831\n",
      "Epoch: 0 | Iteration: 460 | Classification loss: 0.62014 | Regression loss: 0.87496 | Running loss: 1.49831\n",
      "Epoch: 0 | Iteration: 461 | Classification loss: 0.50449 | Regression loss: 0.65589 | Running loss: 1.49757\n",
      "Epoch: 0 | Iteration: 462 | Classification loss: 0.38848 | Regression loss: 0.57210 | Running loss: 1.49641\n",
      "Epoch: 0 | Iteration: 463 | Classification loss: 0.24201 | Regression loss: 0.43377 | Running loss: 1.49465\n",
      "Epoch: 0 | Iteration: 464 | Classification loss: 0.45990 | Regression loss: 0.80562 | Running loss: 1.49415\n",
      "Epoch: 0 | Iteration: 465 | Classification loss: 0.62039 | Regression loss: 0.86413 | Running loss: 1.49413\n",
      "Epoch: 0 | Iteration: 466 | Classification loss: 0.65351 | Regression loss: 1.09988 | Running loss: 1.49469\n",
      "Epoch: 0 | Iteration: 467 | Classification loss: 0.51374 | Regression loss: 0.87991 | Running loss: 1.49447\n",
      "Epoch: 0 | Iteration: 468 | Classification loss: 0.54106 | Regression loss: 0.71274 | Running loss: 1.49396\n",
      "Epoch: 0 | Iteration: 469 | Classification loss: 0.62324 | Regression loss: 0.55131 | Running loss: 1.49328\n",
      "Epoch: 0 | Iteration: 470 | Classification loss: 0.61550 | Regression loss: 1.24085 | Running loss: 1.49405\n",
      "Epoch: 0 | Iteration: 471 | Classification loss: 0.50820 | Regression loss: 0.31776 | Running loss: 1.49263\n",
      "Epoch: 0 | Iteration: 472 | Classification loss: 0.74938 | Regression loss: 1.12078 | Running loss: 1.49343\n",
      "Epoch: 0 | Iteration: 473 | Classification loss: 0.47603 | Regression loss: 0.57035 | Running loss: 1.49249\n",
      "Epoch: 0 | Iteration: 474 | Classification loss: 0.68130 | Regression loss: 0.73610 | Running loss: 1.49233\n",
      "Epoch: 0 | Iteration: 475 | Classification loss: 0.57376 | Regression loss: 0.71219 | Running loss: 1.49190\n",
      "Epoch: 0 | Iteration: 476 | Classification loss: 0.65417 | Regression loss: 0.88698 | Running loss: 1.49200\n",
      "Epoch: 0 | Iteration: 477 | Classification loss: 0.56082 | Regression loss: 0.93729 | Running loss: 1.49201\n",
      "Epoch: 0 | Iteration: 478 | Classification loss: 0.78748 | Regression loss: 0.76508 | Running loss: 1.49214\n",
      "Epoch: 0 | Iteration: 479 | Classification loss: 0.52335 | Regression loss: 0.51997 | Running loss: 1.49120\n",
      "Epoch: 0 | Iteration: 480 | Classification loss: 0.48532 | Regression loss: 0.61048 | Running loss: 1.49038\n",
      "Epoch: 0 | Iteration: 481 | Classification loss: 0.59947 | Regression loss: 0.65883 | Running loss: 1.48990\n",
      "Epoch: 0 | Iteration: 482 | Classification loss: 0.54166 | Regression loss: 0.79999 | Running loss: 1.48959\n",
      "Epoch: 0 | Iteration: 483 | Classification loss: 0.60298 | Regression loss: 1.20704 | Running loss: 1.49026\n",
      "Epoch: 0 | Iteration: 484 | Classification loss: 0.36761 | Regression loss: 0.48594 | Running loss: 1.48894\n",
      "Epoch: 0 | Iteration: 485 | Classification loss: 0.70220 | Regression loss: 0.88212 | Running loss: 1.48914\n",
      "Epoch: 0 | Iteration: 486 | Classification loss: 0.48181 | Regression loss: 0.91066 | Running loss: 1.48894\n",
      "Epoch: 0 | Iteration: 487 | Classification loss: 0.55872 | Regression loss: 0.66682 | Running loss: 1.48840\n",
      "Epoch: 0 | Iteration: 488 | Classification loss: 0.47167 | Regression loss: 0.48607 | Running loss: 1.48732\n",
      "Epoch: 0 | Iteration: 489 | Classification loss: 0.53937 | Regression loss: 0.47404 | Running loss: 1.48635\n",
      "Epoch: 0 | Iteration: 490 | Classification loss: 0.65603 | Regression loss: 1.24275 | Running loss: 1.48719\n",
      "Epoch: 0 | Iteration: 491 | Classification loss: 0.38088 | Regression loss: 0.63871 | Running loss: 1.48624\n",
      "Epoch: 0 | Iteration: 492 | Classification loss: 0.35069 | Regression loss: 0.36089 | Running loss: 1.48467\n",
      "Epoch: 0 | Iteration: 493 | Classification loss: 0.41844 | Regression loss: 0.62334 | Running loss: 1.48377\n",
      "Epoch: 0 | Iteration: 494 | Classification loss: 0.36602 | Regression loss: 0.64916 | Running loss: 1.48282\n",
      "Epoch: 0 | Iteration: 495 | Classification loss: 0.50147 | Regression loss: 0.67353 | Running loss: 1.48220\n",
      "Epoch: 0 | Iteration: 496 | Classification loss: 0.30686 | Regression loss: 0.66311 | Running loss: 1.48117\n",
      "Epoch: 0 | Iteration: 497 | Classification loss: 0.39866 | Regression loss: 0.55418 | Running loss: 1.48011\n",
      "Epoch: 0 | Iteration: 498 | Classification loss: 0.56069 | Regression loss: 0.51092 | Running loss: 1.47929\n",
      "Epoch: 0 | Iteration: 499 | Classification loss: 0.43813 | Regression loss: 0.59774 | Running loss: 1.47841\n",
      "Epoch: 0 | Iteration: 500 | Classification loss: 0.57801 | Regression loss: 0.83636 | Running loss: 1.47663\n",
      "Epoch: 0 | Iteration: 501 | Classification loss: 0.60626 | Regression loss: 0.83831 | Running loss: 1.47499\n",
      "Epoch: 0 | Iteration: 502 | Classification loss: 0.57916 | Regression loss: 0.52527 | Running loss: 1.47178\n",
      "Epoch: 0 | Iteration: 503 | Classification loss: 0.44644 | Regression loss: 1.00708 | Running loss: 1.47023\n",
      "Epoch: 0 | Iteration: 504 | Classification loss: 0.79103 | Regression loss: 0.98309 | Running loss: 1.46916\n",
      "Epoch: 0 | Iteration: 505 | Classification loss: 0.51054 | Regression loss: 0.90459 | Running loss: 1.46742\n",
      "Epoch: 0 | Iteration: 506 | Classification loss: 0.37966 | Regression loss: 0.78060 | Running loss: 1.46519\n",
      "Epoch: 0 | Iteration: 507 | Classification loss: 0.36110 | Regression loss: 0.55631 | Running loss: 1.46214\n",
      "Epoch: 0 | Iteration: 508 | Classification loss: 0.28671 | Regression loss: 0.43299 | Running loss: 1.45864\n",
      "Epoch: 0 | Iteration: 509 | Classification loss: 0.41736 | Regression loss: 0.66171 | Running loss: 1.45658\n",
      "Epoch: 0 | Iteration: 510 | Classification loss: 0.58480 | Regression loss: 0.78316 | Running loss: 1.45492\n",
      "Epoch: 0 | Iteration: 511 | Classification loss: 0.82461 | Regression loss: 0.88206 | Running loss: 1.45399\n",
      "Epoch: 0 | Iteration: 512 | Classification loss: 0.34505 | Regression loss: 0.55243 | Running loss: 1.45160\n",
      "Epoch: 0 | Iteration: 513 | Classification loss: 0.31858 | Regression loss: 0.40336 | Running loss: 1.44886\n",
      "Epoch: 0 | Iteration: 514 | Classification loss: 0.52898 | Regression loss: 0.72110 | Running loss: 1.44682\n",
      "Epoch: 0 | Iteration: 515 | Classification loss: 0.45680 | Regression loss: 0.92540 | Running loss: 1.44515\n",
      "Epoch: 0 | Iteration: 516 | Classification loss: 0.34280 | Regression loss: 0.45255 | Running loss: 1.44228\n",
      "Epoch: 0 | Iteration: 517 | Classification loss: 0.42570 | Regression loss: 0.64037 | Running loss: 1.43999\n",
      "Epoch: 0 | Iteration: 518 | Classification loss: 0.43085 | Regression loss: 0.61947 | Running loss: 1.43766\n",
      "Epoch: 0 | Iteration: 519 | Classification loss: 0.41546 | Regression loss: 0.69553 | Running loss: 1.43549\n",
      "Epoch: 0 | Iteration: 520 | Classification loss: 0.59967 | Regression loss: 0.40501 | Running loss: 1.43338\n",
      "Epoch: 0 | Iteration: 521 | Classification loss: 0.65839 | Regression loss: 0.93414 | Running loss: 1.43195\n",
      "Epoch: 0 | Iteration: 522 | Classification loss: 0.27347 | Regression loss: 0.50802 | Running loss: 1.42905\n",
      "Epoch: 0 | Iteration: 523 | Classification loss: 0.51693 | Regression loss: 0.81663 | Running loss: 1.42737\n",
      "Epoch: 0 | Iteration: 524 | Classification loss: 0.50782 | Regression loss: 0.80930 | Running loss: 1.42566\n",
      "Epoch: 0 | Iteration: 525 | Classification loss: 0.40887 | Regression loss: 0.40069 | Running loss: 1.42309\n",
      "Epoch: 0 | Iteration: 526 | Classification loss: 0.22191 | Regression loss: 0.41901 | Running loss: 1.42003\n",
      "Epoch: 0 | Iteration: 527 | Classification loss: 0.54527 | Regression loss: 0.82624 | Running loss: 1.41843\n",
      "Epoch: 0 | Iteration: 528 | Classification loss: 0.56124 | Regression loss: 0.63180 | Running loss: 1.41675\n",
      "Epoch: 0 | Iteration: 529 | Classification loss: 0.65040 | Regression loss: 0.73397 | Running loss: 1.41527\n",
      "Epoch: 0 | Iteration: 530 | Classification loss: 0.41042 | Regression loss: 0.63676 | Running loss: 1.41322\n",
      "Epoch: 0 | Iteration: 531 | Classification loss: 0.44675 | Regression loss: 0.64279 | Running loss: 1.41130\n",
      "Epoch: 0 | Iteration: 532 | Classification loss: 0.41743 | Regression loss: 0.67251 | Running loss: 1.40920\n",
      "Epoch: 0 | Iteration: 533 | Classification loss: 0.53274 | Regression loss: 0.76292 | Running loss: 1.40779\n",
      "Epoch: 0 | Iteration: 534 | Classification loss: 0.40164 | Regression loss: 0.65892 | Running loss: 1.40576\n",
      "Epoch: 0 | Iteration: 535 | Classification loss: 0.32129 | Regression loss: 0.58709 | Running loss: 1.40336\n",
      "Epoch: 0 | Iteration: 536 | Classification loss: 0.45318 | Regression loss: 0.73187 | Running loss: 1.40178\n",
      "Epoch: 0 | Iteration: 537 | Classification loss: 0.53550 | Regression loss: 1.08873 | Running loss: 1.40123\n",
      "Epoch: 0 | Iteration: 538 | Classification loss: 0.71077 | Regression loss: 0.80693 | Running loss: 1.40025\n",
      "Epoch: 0 | Iteration: 539 | Classification loss: 0.39581 | Regression loss: 0.73391 | Running loss: 1.39445\n",
      "Epoch: 0 | Iteration: 540 | Classification loss: 0.49412 | Regression loss: 0.54841 | Running loss: 1.39258\n",
      "Epoch: 0 | Iteration: 541 | Classification loss: 0.36239 | Regression loss: 0.57862 | Running loss: 1.39020\n",
      "Epoch: 0 | Iteration: 542 | Classification loss: 0.38623 | Regression loss: 0.62026 | Running loss: 1.38744\n",
      "Epoch: 0 | Iteration: 543 | Classification loss: 0.58868 | Regression loss: 0.55679 | Running loss: 1.38529\n",
      "Epoch: 0 | Iteration: 544 | Classification loss: 0.33509 | Regression loss: 0.63887 | Running loss: 1.38357\n",
      "Epoch: 0 | Iteration: 545 | Classification loss: 0.79811 | Regression loss: 0.37028 | Running loss: 1.38161\n",
      "Epoch: 0 | Iteration: 546 | Classification loss: 0.35335 | Regression loss: 0.66622 | Running loss: 1.37998\n",
      "Epoch: 0 | Iteration: 547 | Classification loss: 0.40310 | Regression loss: 0.57720 | Running loss: 1.37778\n",
      "Epoch: 0 | Iteration: 548 | Classification loss: 0.66617 | Regression loss: 0.66627 | Running loss: 1.37623\n",
      "Epoch: 0 | Iteration: 549 | Classification loss: 0.59184 | Regression loss: 0.80786 | Running loss: 1.37553\n",
      "Epoch: 0 | Iteration: 550 | Classification loss: 0.42334 | Regression loss: 0.43423 | Running loss: 1.37404\n",
      "Epoch: 0 | Iteration: 551 | Classification loss: 0.39981 | Regression loss: 0.68676 | Running loss: 1.37184\n",
      "Epoch: 0 | Iteration: 552 | Classification loss: 0.47105 | Regression loss: 0.74844 | Running loss: 1.37048\n",
      "Epoch: 0 | Iteration: 553 | Classification loss: 0.43498 | Regression loss: 0.77677 | Running loss: 1.37016\n",
      "Epoch: 0 | Iteration: 554 | Classification loss: 0.53065 | Regression loss: 0.96335 | Running loss: 1.37036\n",
      "Epoch: 0 | Iteration: 555 | Classification loss: 0.67338 | Regression loss: 1.09652 | Running loss: 1.37010\n",
      "Epoch: 0 | Iteration: 556 | Classification loss: 0.42556 | Regression loss: 0.65574 | Running loss: 1.36790\n",
      "Epoch: 0 | Iteration: 557 | Classification loss: 0.54416 | Regression loss: 0.56977 | Running loss: 1.36578\n",
      "Epoch: 0 | Iteration: 558 | Classification loss: 0.44361 | Regression loss: 0.49132 | Running loss: 1.36430\n",
      "Epoch: 0 | Iteration: 559 | Classification loss: 0.42736 | Regression loss: 0.53601 | Running loss: 1.36118\n",
      "Epoch: 0 | Iteration: 560 | Classification loss: 0.28690 | Regression loss: 0.42133 | Running loss: 1.35932\n",
      "Epoch: 0 | Iteration: 561 | Classification loss: 0.24386 | Regression loss: 0.58324 | Running loss: 1.35767\n",
      "Epoch: 0 | Iteration: 562 | Classification loss: 0.41777 | Regression loss: 0.49110 | Running loss: 1.35462\n",
      "Epoch: 0 | Iteration: 563 | Classification loss: 0.34055 | Regression loss: 0.51978 | Running loss: 1.35324\n",
      "Epoch: 0 | Iteration: 564 | Classification loss: 0.42919 | Regression loss: 0.61355 | Running loss: 1.35218\n",
      "Epoch: 0 | Iteration: 565 | Classification loss: 0.68240 | Regression loss: 0.84535 | Running loss: 1.35190\n",
      "Epoch: 0 | Iteration: 566 | Classification loss: 0.56259 | Regression loss: 0.43722 | Running loss: 1.34962\n",
      "Epoch: 0 | Iteration: 567 | Classification loss: 0.50015 | Regression loss: 0.87709 | Running loss: 1.34918\n",
      "Epoch: 0 | Iteration: 568 | Classification loss: 0.42849 | Regression loss: 0.62142 | Running loss: 1.34683\n",
      "Epoch: 0 | Iteration: 569 | Classification loss: 0.48125 | Regression loss: 0.54525 | Running loss: 1.34443\n",
      "Epoch: 0 | Iteration: 570 | Classification loss: 0.73119 | Regression loss: 0.95442 | Running loss: 1.34397\n",
      "Epoch: 0 | Iteration: 571 | Classification loss: 0.42233 | Regression loss: 0.83145 | Running loss: 1.34367\n",
      "Epoch: 0 | Iteration: 572 | Classification loss: 0.78814 | Regression loss: 0.96076 | Running loss: 1.34360\n",
      "Epoch: 0 | Iteration: 573 | Classification loss: 0.34785 | Regression loss: 1.07843 | Running loss: 1.34305\n",
      "Epoch: 0 | Iteration: 574 | Classification loss: 0.51844 | Regression loss: 0.85538 | Running loss: 1.34238\n",
      "Epoch: 0 | Iteration: 575 | Classification loss: 0.41598 | Regression loss: 0.43209 | Running loss: 1.34142\n",
      "Epoch: 0 | Iteration: 576 | Classification loss: 0.40174 | Regression loss: 0.52612 | Running loss: 1.34020\n",
      "Epoch: 0 | Iteration: 577 | Classification loss: 0.40255 | Regression loss: 0.73961 | Running loss: 1.33922\n",
      "Epoch: 0 | Iteration: 578 | Classification loss: 0.48071 | Regression loss: 0.52909 | Running loss: 1.33841\n",
      "Epoch: 0 | Iteration: 579 | Classification loss: 0.54400 | Regression loss: 0.36938 | Running loss: 1.33719\n",
      "Epoch: 0 | Iteration: 580 | Classification loss: 0.44542 | Regression loss: 0.54896 | Running loss: 1.33586\n",
      "Epoch: 0 | Iteration: 581 | Classification loss: 0.45790 | Regression loss: 0.75220 | Running loss: 1.33473\n",
      "Epoch: 0 | Iteration: 582 | Classification loss: 0.42740 | Regression loss: 0.58327 | Running loss: 1.33317\n",
      "Epoch: 0 | Iteration: 583 | Classification loss: 0.65192 | Regression loss: 0.93798 | Running loss: 1.33318\n",
      "Epoch: 0 | Iteration: 584 | Classification loss: 0.57327 | Regression loss: 0.78844 | Running loss: 1.33334\n",
      "Epoch: 0 | Iteration: 585 | Classification loss: 0.35044 | Regression loss: 0.65005 | Running loss: 1.33273\n",
      "Epoch: 0 | Iteration: 586 | Classification loss: 0.32005 | Regression loss: 0.56673 | Running loss: 1.33117\n",
      "Epoch: 0 | Iteration: 587 | Classification loss: 0.51182 | Regression loss: 0.75599 | Running loss: 1.33007\n",
      "Epoch: 0 | Iteration: 588 | Classification loss: 0.40302 | Regression loss: 0.38709 | Running loss: 1.32792\n",
      "Epoch: 0 | Iteration: 589 | Classification loss: 0.46730 | Regression loss: 0.53884 | Running loss: 1.32717\n",
      "Epoch: 0 | Iteration: 590 | Classification loss: 0.48317 | Regression loss: 0.62374 | Running loss: 1.32588\n",
      "Epoch: 0 | Iteration: 591 | Classification loss: 0.28248 | Regression loss: 0.48137 | Running loss: 1.32355\n",
      "Epoch: 0 | Iteration: 592 | Classification loss: 0.41105 | Regression loss: 0.63893 | Running loss: 1.32275\n",
      "Epoch: 0 | Iteration: 593 | Classification loss: 0.52688 | Regression loss: 0.80983 | Running loss: 1.32190\n",
      "Epoch: 0 | Iteration: 594 | Classification loss: 0.77568 | Regression loss: 0.88561 | Running loss: 1.32067\n",
      "Epoch: 0 | Iteration: 595 | Classification loss: 0.37102 | Regression loss: 0.56895 | Running loss: 1.32043\n",
      "Epoch: 0 | Iteration: 596 | Classification loss: 0.28512 | Regression loss: 0.43812 | Running loss: 1.31918\n",
      "Epoch: 0 | Iteration: 597 | Classification loss: 0.46104 | Regression loss: 0.57612 | Running loss: 1.31803\n",
      "Epoch: 0 | Iteration: 598 | Classification loss: 0.48667 | Regression loss: 0.79832 | Running loss: 1.31687\n",
      "Epoch: 0 | Iteration: 599 | Classification loss: 0.67552 | Regression loss: 0.79464 | Running loss: 1.31638\n",
      "Epoch: 0 | Iteration: 600 | Classification loss: 0.70773 | Regression loss: 0.49796 | Running loss: 1.31536\n",
      "Epoch: 0 | Iteration: 601 | Classification loss: 0.44097 | Regression loss: 0.68529 | Running loss: 1.31420\n",
      "Epoch: 0 | Iteration: 602 | Classification loss: 0.54319 | Regression loss: 0.72624 | Running loss: 1.31423\n",
      "Epoch: 0 | Iteration: 603 | Classification loss: 0.27331 | Regression loss: 0.53903 | Running loss: 1.31296\n",
      "Epoch: 0 | Iteration: 604 | Classification loss: 0.41717 | Regression loss: 0.39150 | Running loss: 1.31126\n",
      "Epoch: 0 | Iteration: 605 | Classification loss: 0.39773 | Regression loss: 0.66823 | Running loss: 1.30861\n",
      "Epoch: 0 | Iteration: 606 | Classification loss: 0.53033 | Regression loss: 0.77063 | Running loss: 1.30668\n",
      "Epoch: 0 | Iteration: 607 | Classification loss: 0.43590 | Regression loss: 0.43405 | Running loss: 1.30443\n",
      "Epoch: 0 | Iteration: 608 | Classification loss: 0.29920 | Regression loss: 0.60555 | Running loss: 1.30418\n",
      "Epoch: 0 | Iteration: 609 | Classification loss: 0.53079 | Regression loss: 1.04065 | Running loss: 1.30478\n",
      "Epoch: 0 | Iteration: 610 | Classification loss: 0.50097 | Regression loss: 0.48412 | Running loss: 1.30396\n",
      "Epoch: 0 | Iteration: 611 | Classification loss: 0.46871 | Regression loss: 0.62952 | Running loss: 1.30301\n",
      "Epoch: 0 | Iteration: 612 | Classification loss: 0.42447 | Regression loss: 0.72005 | Running loss: 1.30162\n",
      "Epoch: 0 | Iteration: 613 | Classification loss: 0.41544 | Regression loss: 0.74711 | Running loss: 1.30045\n",
      "Epoch: 0 | Iteration: 614 | Classification loss: 0.43985 | Regression loss: 0.60548 | Running loss: 1.29895\n",
      "Epoch: 0 | Iteration: 615 | Classification loss: 0.38456 | Regression loss: 0.51822 | Running loss: 1.29810\n",
      "Epoch: 0 | Iteration: 616 | Classification loss: 0.39927 | Regression loss: 0.76351 | Running loss: 1.29758\n",
      "Epoch: 0 | Iteration: 617 | Classification loss: 0.36344 | Regression loss: 0.48541 | Running loss: 1.29664\n",
      "Epoch: 0 | Iteration: 618 | Classification loss: 0.41943 | Regression loss: 0.61515 | Running loss: 1.29507\n",
      "Epoch: 0 | Iteration: 619 | Classification loss: 0.32998 | Regression loss: 0.49983 | Running loss: 1.29177\n",
      "Epoch: 0 | Iteration: 620 | Classification loss: 0.38426 | Regression loss: 0.44107 | Running loss: 1.28985\n",
      "Epoch: 0 | Iteration: 621 | Classification loss: 0.54965 | Regression loss: 0.53881 | Running loss: 1.28973\n",
      "Epoch: 0 | Iteration: 622 | Classification loss: 0.36085 | Regression loss: 0.48854 | Running loss: 1.28773\n",
      "Epoch: 0 | Iteration: 623 | Classification loss: 0.49777 | Regression loss: 0.59697 | Running loss: 1.28619\n",
      "Epoch: 0 | Iteration: 624 | Classification loss: 0.55081 | Regression loss: 0.62401 | Running loss: 1.28322\n",
      "Epoch: 0 | Iteration: 625 | Classification loss: 0.56285 | Regression loss: 0.36803 | Running loss: 1.28185\n",
      "Epoch: 0 | Iteration: 626 | Classification loss: 0.30816 | Regression loss: 0.52206 | Running loss: 1.28048\n",
      "Epoch: 0 | Iteration: 627 | Classification loss: 0.47698 | Regression loss: 0.73946 | Running loss: 1.27976\n",
      "Epoch: 0 | Iteration: 628 | Classification loss: 0.46738 | Regression loss: 0.65104 | Running loss: 1.27907\n",
      "Epoch: 0 | Iteration: 629 | Classification loss: 0.42900 | Regression loss: 0.86740 | Running loss: 1.27724\n",
      "Epoch: 0 | Iteration: 630 | Classification loss: 0.38362 | Regression loss: 0.51357 | Running loss: 1.27654\n",
      "Epoch: 0 | Iteration: 631 | Classification loss: 0.39963 | Regression loss: 0.53572 | Running loss: 1.27570\n",
      "Epoch: 0 | Iteration: 632 | Classification loss: 0.46130 | Regression loss: 0.65513 | Running loss: 1.27412\n",
      "Epoch: 0 | Iteration: 633 | Classification loss: 0.35507 | Regression loss: 0.59379 | Running loss: 1.27309\n",
      "Epoch: 0 | Iteration: 634 | Classification loss: 0.47955 | Regression loss: 0.40309 | Running loss: 1.27211\n",
      "Epoch: 0 | Iteration: 635 | Classification loss: 0.49676 | Regression loss: 0.80514 | Running loss: 1.27203\n",
      "Epoch: 0 | Iteration: 636 | Classification loss: 0.34615 | Regression loss: 0.64073 | Running loss: 1.27124\n",
      "Epoch: 0 | Iteration: 637 | Classification loss: 0.26683 | Regression loss: 0.51174 | Running loss: 1.27065\n",
      "Epoch: 0 | Iteration: 638 | Classification loss: 0.28626 | Regression loss: 0.52008 | Running loss: 1.26866\n",
      "Epoch: 0 | Iteration: 639 | Classification loss: 0.54381 | Regression loss: 0.71912 | Running loss: 1.26888\n",
      "Epoch: 0 | Iteration: 640 | Classification loss: 0.34657 | Regression loss: 0.54149 | Running loss: 1.26746\n",
      "Epoch: 0 | Iteration: 641 | Classification loss: 0.59323 | Regression loss: 0.81130 | Running loss: 1.26686\n",
      "Epoch: 0 | Iteration: 642 | Classification loss: 0.51332 | Regression loss: 0.71788 | Running loss: 1.26574\n",
      "Epoch: 0 | Iteration: 643 | Classification loss: 0.42561 | Regression loss: 0.85217 | Running loss: 1.26444\n",
      "Epoch: 0 | Iteration: 644 | Classification loss: 0.30621 | Regression loss: 0.59413 | Running loss: 1.26245\n",
      "Epoch: 0 | Iteration: 645 | Classification loss: 0.53234 | Regression loss: 1.08412 | Running loss: 1.26247\n",
      "Epoch: 0 | Iteration: 646 | Classification loss: 0.22133 | Regression loss: 0.54524 | Running loss: 1.26076\n",
      "Epoch: 0 | Iteration: 647 | Classification loss: 0.17980 | Regression loss: 0.41102 | Running loss: 1.25852\n",
      "Epoch: 0 | Iteration: 648 | Classification loss: 0.52481 | Regression loss: 0.72882 | Running loss: 1.25795\n",
      "Epoch: 0 | Iteration: 649 | Classification loss: 0.51495 | Regression loss: 0.76729 | Running loss: 1.25752\n",
      "Epoch: 0 | Iteration: 650 | Classification loss: 0.45896 | Regression loss: 0.59401 | Running loss: 1.25713\n",
      "Epoch: 0 | Iteration: 651 | Classification loss: 0.54127 | Regression loss: 1.01421 | Running loss: 1.25729\n",
      "Epoch: 0 | Iteration: 652 | Classification loss: 0.62323 | Regression loss: 0.98770 | Running loss: 1.25767\n",
      "Epoch: 0 | Iteration: 653 | Classification loss: 0.65355 | Regression loss: 0.85953 | Running loss: 1.25716\n",
      "Epoch: 0 | Iteration: 654 | Classification loss: 0.66933 | Regression loss: 0.83490 | Running loss: 1.25703\n",
      "Epoch: 0 | Iteration: 655 | Classification loss: 0.40796 | Regression loss: 0.62960 | Running loss: 1.25714\n",
      "Epoch: 0 | Iteration: 656 | Classification loss: 0.29008 | Regression loss: 0.67374 | Running loss: 1.25671\n",
      "Epoch: 0 | Iteration: 657 | Classification loss: 0.47585 | Regression loss: 0.60711 | Running loss: 1.25664\n",
      "Epoch: 0 | Iteration: 658 | Classification loss: 0.37954 | Regression loss: 0.59225 | Running loss: 1.25631\n",
      "Epoch: 0 | Iteration: 659 | Classification loss: 0.55106 | Regression loss: 0.72818 | Running loss: 1.25647\n",
      "Epoch: 0 | Iteration: 660 | Classification loss: 0.34190 | Regression loss: 0.63024 | Running loss: 1.25543\n",
      "Epoch: 0 | Iteration: 661 | Classification loss: 0.57436 | Regression loss: 0.37259 | Running loss: 1.25448\n",
      "Epoch: 0 | Iteration: 662 | Classification loss: 0.38182 | Regression loss: 0.38638 | Running loss: 1.25376\n",
      "Epoch: 0 | Iteration: 663 | Classification loss: 0.38023 | Regression loss: 0.44726 | Running loss: 1.25219\n",
      "Epoch: 0 | Iteration: 664 | Classification loss: 0.43455 | Regression loss: 0.73403 | Running loss: 1.25111\n",
      "Epoch: 0 | Iteration: 665 | Classification loss: 0.52468 | Regression loss: 0.61745 | Running loss: 1.25029\n",
      "Epoch: 0 | Iteration: 666 | Classification loss: 0.23397 | Regression loss: 0.50283 | Running loss: 1.24883\n",
      "Epoch: 0 | Iteration: 667 | Classification loss: 0.38527 | Regression loss: 0.61226 | Running loss: 1.24748\n",
      "Epoch: 0 | Iteration: 668 | Classification loss: 0.19460 | Regression loss: 0.49244 | Running loss: 1.24580\n",
      "Epoch: 0 | Iteration: 669 | Classification loss: 0.29467 | Regression loss: 0.47031 | Running loss: 1.24264\n",
      "Epoch: 0 | Iteration: 670 | Classification loss: 0.58290 | Regression loss: 0.58961 | Running loss: 1.24238\n",
      "Epoch: 0 | Iteration: 671 | Classification loss: 1.25344 | Regression loss: 0.84887 | Running loss: 1.24444\n",
      "Epoch: 0 | Iteration: 672 | Classification loss: 0.39914 | Regression loss: 0.49740 | Running loss: 1.24359\n",
      "Epoch: 0 | Iteration: 673 | Classification loss: 0.41748 | Regression loss: 0.45184 | Running loss: 1.24250\n",
      "Epoch: 0 | Iteration: 674 | Classification loss: 0.73592 | Regression loss: 0.98953 | Running loss: 1.24374\n",
      "Epoch: 0 | Iteration: 675 | Classification loss: 0.69651 | Regression loss: 1.01950 | Running loss: 1.24324\n",
      "Epoch: 0 | Iteration: 676 | Classification loss: 0.35275 | Regression loss: 0.42454 | Running loss: 1.24125\n",
      "Epoch: 0 | Iteration: 677 | Classification loss: 0.58122 | Regression loss: 0.74833 | Running loss: 1.23943\n",
      "Epoch: 0 | Iteration: 678 | Classification loss: 0.28210 | Regression loss: 0.45539 | Running loss: 1.23816\n",
      "Epoch: 0 | Iteration: 679 | Classification loss: 1.21934 | Regression loss: 0.16996 | Running loss: 1.23591\n",
      "Epoch: 0 | Iteration: 680 | Classification loss: 0.41220 | Regression loss: 0.75158 | Running loss: 1.23333\n",
      "Epoch: 0 | Iteration: 681 | Classification loss: 0.41891 | Regression loss: 0.85173 | Running loss: 1.23279\n",
      "Epoch: 0 | Iteration: 682 | Classification loss: 0.31046 | Regression loss: 0.46909 | Running loss: 1.23112\n",
      "Epoch: 0 | Iteration: 683 | Classification loss: 0.37752 | Regression loss: 0.31039 | Running loss: 1.23015\n",
      "Epoch: 0 | Iteration: 684 | Classification loss: 0.54679 | Regression loss: 0.82455 | Running loss: 1.23108\n",
      "Epoch: 0 | Iteration: 685 | Classification loss: 0.39360 | Regression loss: 0.49992 | Running loss: 1.22933\n",
      "Epoch: 0 | Iteration: 686 | Classification loss: 0.73697 | Regression loss: 0.70967 | Running loss: 1.22883\n",
      "Epoch: 0 | Iteration: 687 | Classification loss: 0.38759 | Regression loss: 0.38915 | Running loss: 1.22867\n",
      "Epoch: 0 | Iteration: 688 | Classification loss: 0.50773 | Regression loss: 0.66825 | Running loss: 1.22741\n",
      "Epoch: 0 | Iteration: 689 | Classification loss: 0.41155 | Regression loss: 0.57198 | Running loss: 1.22653\n",
      "Epoch: 0 | Iteration: 690 | Classification loss: 0.49116 | Regression loss: 0.44187 | Running loss: 1.22576\n",
      "Epoch: 0 | Iteration: 691 | Classification loss: 0.45054 | Regression loss: 0.44141 | Running loss: 1.22524\n",
      "Epoch: 0 | Iteration: 692 | Classification loss: 0.52876 | Regression loss: 0.99764 | Running loss: 1.22520\n",
      "Epoch: 0 | Iteration: 693 | Classification loss: 0.57057 | Regression loss: 0.39687 | Running loss: 1.22432\n",
      "Epoch: 0 | Iteration: 694 | Classification loss: 0.30502 | Regression loss: 0.63153 | Running loss: 1.22285\n",
      "Epoch: 0 | Iteration: 695 | Classification loss: 0.34650 | Regression loss: 0.62867 | Running loss: 1.22176\n",
      "Epoch: 0 | Iteration: 696 | Classification loss: 0.25083 | Regression loss: 0.33947 | Running loss: 1.22013\n",
      "Epoch: 0 | Iteration: 697 | Classification loss: 0.34024 | Regression loss: 0.40495 | Running loss: 1.21848\n",
      "Epoch: 0 | Iteration: 698 | Classification loss: 0.46262 | Regression loss: 0.58356 | Running loss: 1.21717\n",
      "Epoch: 0 | Iteration: 699 | Classification loss: 0.55855 | Regression loss: 0.59373 | Running loss: 1.21760\n",
      "Epoch: 0 | Iteration: 700 | Classification loss: 0.62119 | Regression loss: 0.86459 | Running loss: 1.21712\n",
      "Epoch: 0 | Iteration: 701 | Classification loss: 0.37116 | Regression loss: 0.45515 | Running loss: 1.21547\n",
      "Epoch: 0 | Iteration: 702 | Classification loss: 0.44461 | Regression loss: 0.38214 | Running loss: 1.21309\n",
      "Epoch: 0 | Iteration: 703 | Classification loss: 0.44767 | Regression loss: 0.45624 | Running loss: 1.21406\n",
      "Epoch: 0 | Iteration: 704 | Classification loss: 0.22488 | Regression loss: 0.47662 | Running loss: 1.21341\n",
      "Epoch: 0 | Iteration: 705 | Classification loss: 0.61513 | Regression loss: 0.82628 | Running loss: 1.21374\n",
      "Epoch: 0 | Iteration: 706 | Classification loss: 0.53429 | Regression loss: 0.72762 | Running loss: 1.21366\n",
      "Epoch: 0 | Iteration: 707 | Classification loss: 0.55203 | Regression loss: 0.52789 | Running loss: 1.21404\n",
      "Epoch: 0 | Iteration: 708 | Classification loss: 0.59870 | Regression loss: 0.78956 | Running loss: 1.21415\n",
      "Epoch: 0 | Iteration: 709 | Classification loss: 0.25505 | Regression loss: 0.66910 | Running loss: 1.21390\n",
      "Epoch: 0 | Iteration: 710 | Classification loss: 0.55035 | Regression loss: 0.72987 | Running loss: 1.21318\n",
      "Epoch: 0 | Iteration: 711 | Classification loss: 0.57504 | Regression loss: 0.93710 | Running loss: 1.21380\n",
      "Epoch: 0 | Iteration: 712 | Classification loss: 0.39767 | Regression loss: 0.40044 | Running loss: 1.21165\n",
      "Epoch: 0 | Iteration: 713 | Classification loss: 0.49312 | Regression loss: 0.53073 | Running loss: 1.20964\n",
      "Epoch: 0 | Iteration: 714 | Classification loss: 0.28856 | Regression loss: 0.37148 | Running loss: 1.20719\n",
      "Epoch: 0 | Iteration: 715 | Classification loss: 0.44895 | Regression loss: 0.53831 | Running loss: 1.20668\n",
      "Epoch: 0 | Iteration: 716 | Classification loss: 0.45875 | Regression loss: 0.53627 | Running loss: 1.20646\n",
      "Epoch: 0 | Iteration: 717 | Classification loss: 0.41227 | Regression loss: 0.26189 | Running loss: 1.20436\n",
      "Epoch: 0 | Iteration: 718 | Classification loss: 0.38044 | Regression loss: 0.71542 | Running loss: 1.20406\n",
      "Epoch: 0 | Iteration: 719 | Classification loss: 0.60542 | Regression loss: 0.60244 | Running loss: 1.20327\n",
      "Epoch: 0 | Iteration: 720 | Classification loss: 0.50151 | Regression loss: 0.74066 | Running loss: 1.20252\n",
      "Epoch: 0 | Iteration: 721 | Classification loss: 0.62046 | Regression loss: 0.63312 | Running loss: 1.20233\n",
      "Epoch: 0 | Iteration: 722 | Classification loss: 0.34533 | Regression loss: 0.47474 | Running loss: 1.20117\n",
      "Epoch: 0 | Iteration: 723 | Classification loss: 0.69883 | Regression loss: 0.84277 | Running loss: 1.20221\n",
      "Epoch: 0 | Iteration: 724 | Classification loss: 0.77679 | Regression loss: 0.95481 | Running loss: 1.20384\n",
      "Epoch: 0 | Iteration: 725 | Classification loss: 0.53103 | Regression loss: 0.63064 | Running loss: 1.20375\n",
      "Epoch: 0 | Iteration: 726 | Classification loss: 0.44910 | Regression loss: 0.51549 | Running loss: 1.20317\n",
      "Epoch: 0 | Iteration: 727 | Classification loss: 0.44248 | Regression loss: 0.63523 | Running loss: 1.20227\n",
      "Epoch: 0 | Iteration: 728 | Classification loss: 0.58302 | Regression loss: 0.55059 | Running loss: 1.20192\n",
      "Epoch: 0 | Iteration: 729 | Classification loss: 0.44927 | Regression loss: 0.62508 | Running loss: 1.20110\n",
      "Epoch: 0 | Iteration: 730 | Classification loss: 0.42792 | Regression loss: 0.59368 | Running loss: 1.20117\n",
      "Epoch: 0 | Iteration: 731 | Classification loss: 0.38403 | Regression loss: 0.53599 | Running loss: 1.19995\n",
      "Epoch: 0 | Iteration: 732 | Classification loss: 0.39436 | Regression loss: 0.51520 | Running loss: 1.19860\n",
      "Epoch: 0 | Iteration: 733 | Classification loss: 0.48477 | Regression loss: 0.55043 | Running loss: 1.19788\n",
      "Epoch: 0 | Iteration: 734 | Classification loss: 0.57332 | Regression loss: 0.88931 | Running loss: 1.19758\n",
      "Epoch: 0 | Iteration: 735 | Classification loss: 0.49916 | Regression loss: 0.76403 | Running loss: 1.19785\n",
      "Epoch: 0 | Iteration: 736 | Classification loss: 0.92448 | Regression loss: 0.96491 | Running loss: 1.19891\n",
      "Epoch: 0 | Iteration: 737 | Classification loss: 0.37411 | Regression loss: 0.62419 | Running loss: 1.19807\n",
      "Epoch: 0 | Iteration: 738 | Classification loss: 0.51848 | Regression loss: 0.52956 | Running loss: 1.19788\n",
      "Epoch: 0 | Iteration: 739 | Classification loss: 0.40146 | Regression loss: 0.65667 | Running loss: 1.19742\n",
      "Epoch: 0 | Iteration: 740 | Classification loss: 0.45985 | Regression loss: 0.58788 | Running loss: 1.19765\n",
      "Epoch: 0 | Iteration: 741 | Classification loss: 0.39485 | Regression loss: 0.52309 | Running loss: 1.19754\n",
      "Epoch: 0 | Iteration: 742 | Classification loss: 0.44805 | Regression loss: 0.62810 | Running loss: 1.19803\n",
      "Epoch: 0 | Iteration: 743 | Classification loss: 0.30841 | Regression loss: 0.54816 | Running loss: 1.19619\n",
      "Epoch: 0 | Iteration: 744 | Classification loss: 0.77424 | Regression loss: 1.02277 | Running loss: 1.19686\n",
      "Epoch: 0 | Iteration: 745 | Classification loss: 0.54621 | Regression loss: 0.53563 | Running loss: 1.19651\n",
      "Epoch: 0 | Iteration: 746 | Classification loss: 0.50440 | Regression loss: 0.70159 | Running loss: 1.19599\n",
      "Epoch: 0 | Iteration: 747 | Classification loss: 0.32867 | Regression loss: 0.50274 | Running loss: 1.19515\n",
      "Epoch: 0 | Iteration: 748 | Classification loss: 0.32438 | Regression loss: 0.52261 | Running loss: 1.19363\n",
      "Epoch: 0 | Iteration: 749 | Classification loss: 0.41691 | Regression loss: 0.51905 | Running loss: 1.19222\n",
      "Epoch: 0 | Iteration: 750 | Classification loss: 0.34969 | Regression loss: 0.35439 | Running loss: 1.19099\n",
      "Epoch: 0 | Iteration: 751 | Classification loss: 0.44920 | Regression loss: 0.71879 | Running loss: 1.19053\n",
      "Epoch: 0 | Iteration: 752 | Classification loss: 0.59051 | Regression loss: 0.60837 | Running loss: 1.18994\n",
      "Epoch: 0 | Iteration: 753 | Classification loss: 0.65193 | Regression loss: 0.94517 | Running loss: 1.19026\n",
      "Epoch: 0 | Iteration: 754 | Classification loss: 0.29931 | Regression loss: 0.43938 | Running loss: 1.18844\n",
      "Epoch: 0 | Iteration: 755 | Classification loss: 0.53970 | Regression loss: 0.67140 | Running loss: 1.18803\n",
      "Epoch: 0 | Iteration: 756 | Classification loss: 0.36451 | Regression loss: 0.61474 | Running loss: 1.18807\n",
      "Epoch: 0 | Iteration: 757 | Classification loss: 0.55601 | Regression loss: 0.66440 | Running loss: 1.18737\n",
      "Epoch: 0 | Iteration: 758 | Classification loss: 0.54929 | Regression loss: 0.89931 | Running loss: 1.18760\n",
      "Epoch: 0 | Iteration: 759 | Classification loss: 0.42087 | Regression loss: 0.50689 | Running loss: 1.18684\n",
      "Epoch: 0 | Iteration: 760 | Classification loss: 0.55244 | Regression loss: 0.42267 | Running loss: 1.18606\n",
      "Epoch: 0 | Iteration: 761 | Classification loss: 0.27404 | Regression loss: 0.36913 | Running loss: 1.18546\n",
      "Epoch: 0 | Iteration: 762 | Classification loss: 0.33303 | Regression loss: 0.39014 | Running loss: 1.18404\n",
      "Epoch: 0 | Iteration: 763 | Classification loss: 0.40408 | Regression loss: 0.36503 | Running loss: 1.18300\n",
      "Epoch: 0 | Iteration: 764 | Classification loss: 0.38535 | Regression loss: 0.52251 | Running loss: 1.18252\n",
      "Epoch: 0 | Iteration: 765 | Classification loss: 0.62265 | Regression loss: 0.82456 | Running loss: 1.18271\n",
      "Epoch: 0 | Iteration: 766 | Classification loss: 0.28551 | Regression loss: 0.40211 | Running loss: 1.18018\n",
      "Epoch: 0 | Iteration: 767 | Classification loss: 0.53376 | Regression loss: 0.53870 | Running loss: 1.17958\n",
      "Epoch: 0 | Iteration: 768 | Classification loss: 0.54692 | Regression loss: 0.66244 | Running loss: 1.18031\n",
      "Epoch: 0 | Iteration: 769 | Classification loss: 0.63697 | Regression loss: 0.83957 | Running loss: 1.18111\n",
      "Epoch: 0 | Iteration: 770 | Classification loss: 0.37259 | Regression loss: 0.65077 | Running loss: 1.18058\n",
      "Epoch: 0 | Iteration: 771 | Classification loss: 0.32484 | Regression loss: 0.69100 | Running loss: 1.17987\n",
      "Epoch: 0 | Iteration: 772 | Classification loss: 0.26941 | Regression loss: 0.48938 | Running loss: 1.17863\n",
      "Epoch: 0 | Iteration: 773 | Classification loss: 0.40774 | Regression loss: 0.52145 | Running loss: 1.17719\n",
      "Epoch: 0 | Iteration: 774 | Classification loss: 0.55683 | Regression loss: 0.64319 | Running loss: 1.17487\n",
      "Epoch: 0 | Iteration: 775 | Classification loss: 0.27134 | Regression loss: 0.69053 | Running loss: 1.17330\n",
      "Epoch: 0 | Iteration: 776 | Classification loss: 0.43805 | Regression loss: 0.75374 | Running loss: 1.17274\n",
      "Epoch: 0 | Iteration: 777 | Classification loss: 0.39424 | Regression loss: 0.54922 | Running loss: 1.17229\n",
      "Epoch: 0 | Iteration: 778 | Classification loss: 0.66546 | Regression loss: 0.95607 | Running loss: 1.17275\n",
      "Epoch: 0 | Iteration: 779 | Classification loss: 0.48472 | Regression loss: 0.69718 | Running loss: 1.17279\n",
      "Epoch: 0 | Iteration: 780 | Classification loss: 0.41935 | Regression loss: 0.60314 | Running loss: 1.17249\n",
      "Epoch: 0 | Iteration: 781 | Classification loss: 0.41451 | Regression loss: 0.93906 | Running loss: 1.17173\n",
      "Epoch: 0 | Iteration: 782 | Classification loss: 0.58229 | Regression loss: 0.60432 | Running loss: 1.17109\n",
      "Epoch: 0 | Iteration: 783 | Classification loss: 0.81946 | Regression loss: 0.69874 | Running loss: 1.17166\n",
      "Epoch: 0 | Iteration: 784 | Classification loss: 0.42025 | Regression loss: 0.70428 | Running loss: 1.17154\n",
      "Epoch: 0 | Iteration: 785 | Classification loss: 0.72005 | Regression loss: 0.85721 | Running loss: 1.17226\n",
      "Epoch: 0 | Iteration: 786 | Classification loss: 0.31666 | Regression loss: 0.52680 | Running loss: 1.17075\n",
      "Epoch: 0 | Iteration: 787 | Classification loss: 0.47419 | Regression loss: 0.60519 | Running loss: 1.17026\n",
      "Epoch: 0 | Iteration: 788 | Classification loss: 0.43193 | Regression loss: 0.59270 | Running loss: 1.16931\n",
      "Epoch: 0 | Iteration: 789 | Classification loss: 0.44454 | Regression loss: 0.84794 | Running loss: 1.16870\n",
      "Epoch: 0 | Iteration: 790 | Classification loss: 0.64243 | Regression loss: 0.81909 | Running loss: 1.16825\n",
      "Epoch: 0 | Iteration: 791 | Classification loss: 0.36589 | Regression loss: 0.57112 | Running loss: 1.16768\n",
      "Epoch: 0 | Iteration: 792 | Classification loss: 0.51388 | Regression loss: 0.38968 | Running loss: 1.16723\n",
      "Epoch: 0 | Iteration: 793 | Classification loss: 0.42248 | Regression loss: 0.57373 | Running loss: 1.16709\n",
      "Epoch: 0 | Iteration: 794 | Classification loss: 0.34740 | Regression loss: 0.57152 | Running loss: 1.16594\n",
      "Epoch: 0 | Iteration: 795 | Classification loss: 0.63747 | Regression loss: 0.85858 | Running loss: 1.16636\n",
      "Epoch: 0 | Iteration: 796 | Classification loss: 0.40182 | Regression loss: 0.62106 | Running loss: 1.16632\n",
      "Epoch: 0 | Iteration: 797 | Classification loss: 0.38294 | Regression loss: 0.48861 | Running loss: 1.16564\n",
      "Epoch: 0 | Iteration: 798 | Classification loss: 0.57519 | Regression loss: 0.97842 | Running loss: 1.16612\n",
      "Epoch: 0 | Iteration: 799 | Classification loss: 0.56304 | Regression loss: 0.59856 | Running loss: 1.16606\n",
      "Epoch: 0 | Iteration: 800 | Classification loss: 0.54652 | Regression loss: 0.86159 | Running loss: 1.16537\n",
      "Epoch: 0 | Iteration: 801 | Classification loss: 0.32448 | Regression loss: 0.70877 | Running loss: 1.16517\n",
      "Epoch: 0 | Iteration: 802 | Classification loss: 0.51600 | Regression loss: 0.37415 | Running loss: 1.16487\n",
      "Epoch: 0 | Iteration: 803 | Classification loss: 0.42579 | Regression loss: 0.38848 | Running loss: 1.16401\n",
      "Epoch: 0 | Iteration: 804 | Classification loss: 0.36253 | Regression loss: 0.46550 | Running loss: 1.16386\n",
      "Epoch: 0 | Iteration: 805 | Classification loss: 0.49216 | Regression loss: 0.65348 | Running loss: 1.16311\n",
      "Epoch: 0 | Iteration: 806 | Classification loss: 0.56738 | Regression loss: 0.61829 | Running loss: 1.16395\n",
      "Epoch: 0 | Iteration: 807 | Classification loss: 0.23474 | Regression loss: 0.41556 | Running loss: 1.16249\n",
      "Epoch: 0 | Iteration: 808 | Classification loss: 0.33346 | Regression loss: 0.43586 | Running loss: 1.16073\n",
      "Epoch: 0 | Iteration: 809 | Classification loss: 0.55414 | Regression loss: 0.47744 | Running loss: 1.16107\n",
      "Epoch: 0 | Iteration: 810 | Classification loss: 0.41047 | Regression loss: 0.76359 | Running loss: 1.16108\n",
      "Epoch: 0 | Iteration: 811 | Classification loss: 0.53507 | Regression loss: 0.76718 | Running loss: 1.16059\n",
      "Epoch: 0 | Iteration: 812 | Classification loss: 0.69282 | Regression loss: 0.74304 | Running loss: 1.16174\n",
      "Epoch: 0 | Iteration: 813 | Classification loss: 0.75507 | Regression loss: 0.88160 | Running loss: 1.16224\n",
      "Epoch: 0 | Iteration: 814 | Classification loss: 0.42753 | Regression loss: 0.62313 | Running loss: 1.16075\n",
      "Epoch: 0 | Iteration: 815 | Classification loss: 0.54666 | Regression loss: 0.84565 | Running loss: 1.16065\n",
      "Epoch: 0 | Iteration: 816 | Classification loss: 0.33251 | Regression loss: 0.50262 | Running loss: 1.15930\n",
      "Epoch: 0 | Iteration: 817 | Classification loss: 0.48542 | Regression loss: 0.82914 | Running loss: 1.15942\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.45s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 1 | Iteration: 0 | Classification loss: 0.61335 | Regression loss: 0.65932 | Running loss: 1.15856\n",
      "Epoch: 1 | Iteration: 1 | Classification loss: 0.18064 | Regression loss: 0.00000 | Running loss: 1.15595\n",
      "Epoch: 1 | Iteration: 2 | Classification loss: 0.35699 | Regression loss: 0.61975 | Running loss: 1.15458\n",
      "Epoch: 1 | Iteration: 3 | Classification loss: 0.47927 | Regression loss: 0.60884 | Running loss: 1.15320\n",
      "Epoch: 1 | Iteration: 4 | Classification loss: 0.56285 | Regression loss: 0.80480 | Running loss: 1.15393\n",
      "Epoch: 1 | Iteration: 5 | Classification loss: 0.44309 | Regression loss: 0.65476 | Running loss: 1.15367\n",
      "Epoch: 1 | Iteration: 6 | Classification loss: 0.49845 | Regression loss: 0.55682 | Running loss: 1.15245\n",
      "Epoch: 1 | Iteration: 7 | Classification loss: 0.58545 | Regression loss: 0.80465 | Running loss: 1.15317\n",
      "Epoch: 1 | Iteration: 8 | Classification loss: 0.43003 | Regression loss: 0.54700 | Running loss: 1.15199\n",
      "Epoch: 1 | Iteration: 9 | Classification loss: 0.45515 | Regression loss: 0.62327 | Running loss: 1.15077\n",
      "Epoch: 1 | Iteration: 10 | Classification loss: 0.46455 | Regression loss: 0.56194 | Running loss: 1.15051\n",
      "Epoch: 1 | Iteration: 11 | Classification loss: 0.31550 | Regression loss: 0.40280 | Running loss: 1.14915\n",
      "Epoch: 1 | Iteration: 12 | Classification loss: 0.61266 | Regression loss: 0.72894 | Running loss: 1.14810\n",
      "Epoch: 1 | Iteration: 13 | Classification loss: 0.56582 | Regression loss: 0.76371 | Running loss: 1.14890\n",
      "Epoch: 1 | Iteration: 14 | Classification loss: 0.43159 | Regression loss: 0.54791 | Running loss: 1.14861\n",
      "Epoch: 1 | Iteration: 15 | Classification loss: 0.43615 | Regression loss: 0.58460 | Running loss: 1.14834\n",
      "Epoch: 1 | Iteration: 16 | Classification loss: 0.48955 | Regression loss: 0.73552 | Running loss: 1.14821\n",
      "Epoch: 1 | Iteration: 17 | Classification loss: 0.39942 | Regression loss: 0.54723 | Running loss: 1.14793\n",
      "Epoch: 1 | Iteration: 18 | Classification loss: 0.48514 | Regression loss: 0.47714 | Running loss: 1.14711\n",
      "Epoch: 1 | Iteration: 19 | Classification loss: 0.31698 | Regression loss: 0.50434 | Running loss: 1.14583\n",
      "Epoch: 1 | Iteration: 20 | Classification loss: 0.36868 | Regression loss: 0.43275 | Running loss: 1.14461\n",
      "Epoch: 1 | Iteration: 21 | Classification loss: 0.21452 | Regression loss: 0.36935 | Running loss: 1.14349\n",
      "Epoch: 1 | Iteration: 22 | Classification loss: 0.32203 | Regression loss: 0.39770 | Running loss: 1.14315\n",
      "Epoch: 1 | Iteration: 23 | Classification loss: 0.58127 | Regression loss: 0.70560 | Running loss: 1.14325\n",
      "Epoch: 1 | Iteration: 24 | Classification loss: 0.24924 | Regression loss: 0.26632 | Running loss: 1.14184\n",
      "Epoch: 1 | Iteration: 25 | Classification loss: 0.46199 | Regression loss: 0.60623 | Running loss: 1.14174\n",
      "Epoch: 1 | Iteration: 26 | Classification loss: 0.66815 | Regression loss: 0.97167 | Running loss: 1.14290\n",
      "Epoch: 1 | Iteration: 27 | Classification loss: 0.57740 | Regression loss: 0.92335 | Running loss: 1.14375\n",
      "Epoch: 1 | Iteration: 28 | Classification loss: 0.34623 | Regression loss: 0.56326 | Running loss: 1.14396\n",
      "Epoch: 1 | Iteration: 29 | Classification loss: 0.25356 | Regression loss: 0.57755 | Running loss: 1.14239\n",
      "Epoch: 1 | Iteration: 30 | Classification loss: 0.52039 | Regression loss: 0.63415 | Running loss: 1.14199\n",
      "Epoch: 1 | Iteration: 31 | Classification loss: 0.15407 | Regression loss: 0.44706 | Running loss: 1.14038\n",
      "Epoch: 1 | Iteration: 32 | Classification loss: 0.40923 | Regression loss: 0.61072 | Running loss: 1.13981\n",
      "Epoch: 1 | Iteration: 33 | Classification loss: 0.66333 | Regression loss: 0.72246 | Running loss: 1.13981\n",
      "Epoch: 1 | Iteration: 34 | Classification loss: 0.39389 | Regression loss: 0.77063 | Running loss: 1.14047\n",
      "Epoch: 1 | Iteration: 35 | Classification loss: 0.53622 | Regression loss: 0.69218 | Running loss: 1.14006\n",
      "Epoch: 1 | Iteration: 36 | Classification loss: 0.43484 | Regression loss: 0.77633 | Running loss: 1.14045\n",
      "Epoch: 1 | Iteration: 37 | Classification loss: 0.17417 | Regression loss: 0.41492 | Running loss: 1.13918\n",
      "Epoch: 1 | Iteration: 38 | Classification loss: 0.31111 | Regression loss: 0.40575 | Running loss: 1.13860\n",
      "Epoch: 1 | Iteration: 39 | Classification loss: 0.64447 | Regression loss: 0.72344 | Running loss: 1.13877\n",
      "Epoch: 1 | Iteration: 40 | Classification loss: 0.52095 | Regression loss: 0.48083 | Running loss: 1.13848\n",
      "Epoch: 1 | Iteration: 41 | Classification loss: 0.35820 | Regression loss: 0.36279 | Running loss: 1.13699\n",
      "Epoch: 1 | Iteration: 42 | Classification loss: 0.47036 | Regression loss: 0.71951 | Running loss: 1.13766\n",
      "Epoch: 1 | Iteration: 43 | Classification loss: 0.60767 | Regression loss: 0.69151 | Running loss: 1.13759\n",
      "Epoch: 1 | Iteration: 44 | Classification loss: 0.63112 | Regression loss: 0.57146 | Running loss: 1.13853\n",
      "Epoch: 1 | Iteration: 45 | Classification loss: 0.45690 | Regression loss: 0.65488 | Running loss: 1.13922\n",
      "Epoch: 1 | Iteration: 46 | Classification loss: 0.39757 | Regression loss: 0.65813 | Running loss: 1.13865\n",
      "Epoch: 1 | Iteration: 47 | Classification loss: 0.65467 | Regression loss: 0.80934 | Running loss: 1.13981\n",
      "Epoch: 1 | Iteration: 48 | Classification loss: 0.47746 | Regression loss: 0.44566 | Running loss: 1.13900\n",
      "Epoch: 1 | Iteration: 49 | Classification loss: 0.37468 | Regression loss: 0.45449 | Running loss: 1.13821\n",
      "Epoch: 1 | Iteration: 50 | Classification loss: 0.31403 | Regression loss: 0.47914 | Running loss: 1.13777\n",
      "Epoch: 1 | Iteration: 51 | Classification loss: 0.35335 | Regression loss: 0.55140 | Running loss: 1.13722\n",
      "Epoch: 1 | Iteration: 52 | Classification loss: 0.37623 | Regression loss: 0.41915 | Running loss: 1.13757\n",
      "Epoch: 1 | Iteration: 53 | Classification loss: 0.58335 | Regression loss: 0.43579 | Running loss: 1.13676\n",
      "Epoch: 1 | Iteration: 54 | Classification loss: 0.41344 | Regression loss: 0.27114 | Running loss: 1.13610\n",
      "Epoch: 1 | Iteration: 55 | Classification loss: 0.40955 | Regression loss: 0.41679 | Running loss: 1.13523\n",
      "Epoch: 1 | Iteration: 56 | Classification loss: 0.71266 | Regression loss: 0.83131 | Running loss: 1.13536\n",
      "Epoch: 1 | Iteration: 57 | Classification loss: 0.38192 | Regression loss: 0.52432 | Running loss: 1.13416\n",
      "Epoch: 1 | Iteration: 58 | Classification loss: 0.36416 | Regression loss: 0.39143 | Running loss: 1.13348\n",
      "Epoch: 1 | Iteration: 59 | Classification loss: 0.48946 | Regression loss: 0.56524 | Running loss: 1.13268\n",
      "Epoch: 1 | Iteration: 60 | Classification loss: 0.39170 | Regression loss: 0.40251 | Running loss: 1.13192\n",
      "Epoch: 1 | Iteration: 61 | Classification loss: 0.34478 | Regression loss: 0.43092 | Running loss: 1.13117\n",
      "Epoch: 1 | Iteration: 62 | Classification loss: 0.35374 | Regression loss: 0.39864 | Running loss: 1.13023\n",
      "Epoch: 1 | Iteration: 63 | Classification loss: 0.36880 | Regression loss: 0.59730 | Running loss: 1.12900\n",
      "Epoch: 1 | Iteration: 64 | Classification loss: 0.55611 | Regression loss: 0.86169 | Running loss: 1.12909\n",
      "Epoch: 1 | Iteration: 65 | Classification loss: 0.54836 | Regression loss: 0.72241 | Running loss: 1.12943\n",
      "Epoch: 1 | Iteration: 66 | Classification loss: 0.42378 | Regression loss: 0.70926 | Running loss: 1.12836\n",
      "Epoch: 1 | Iteration: 67 | Classification loss: 0.52017 | Regression loss: 0.67031 | Running loss: 1.12845\n",
      "Epoch: 1 | Iteration: 68 | Classification loss: 0.36165 | Regression loss: 0.43830 | Running loss: 1.12767\n",
      "Epoch: 1 | Iteration: 69 | Classification loss: 0.41512 | Regression loss: 0.38211 | Running loss: 1.12691\n",
      "Epoch: 1 | Iteration: 70 | Classification loss: 0.45508 | Regression loss: 0.86842 | Running loss: 1.12675\n",
      "Epoch: 1 | Iteration: 71 | Classification loss: 0.50178 | Regression loss: 0.64960 | Running loss: 1.12602\n",
      "Epoch: 1 | Iteration: 72 | Classification loss: 0.43587 | Regression loss: 0.56777 | Running loss: 1.12577\n",
      "Epoch: 1 | Iteration: 73 | Classification loss: 0.40159 | Regression loss: 0.61863 | Running loss: 1.12560\n",
      "Epoch: 1 | Iteration: 74 | Classification loss: 0.44594 | Regression loss: 0.64315 | Running loss: 1.12542\n",
      "Epoch: 1 | Iteration: 75 | Classification loss: 0.46749 | Regression loss: 0.66930 | Running loss: 1.12506\n",
      "Epoch: 1 | Iteration: 76 | Classification loss: 0.49270 | Regression loss: 0.75431 | Running loss: 1.12551\n",
      "Epoch: 1 | Iteration: 77 | Classification loss: 0.49018 | Regression loss: 0.67029 | Running loss: 1.12454\n",
      "Epoch: 1 | Iteration: 78 | Classification loss: 0.59353 | Regression loss: 0.64672 | Running loss: 1.12464\n",
      "Epoch: 1 | Iteration: 79 | Classification loss: 0.59700 | Regression loss: 1.14455 | Running loss: 1.12588\n",
      "Epoch: 1 | Iteration: 80 | Classification loss: 0.53274 | Regression loss: 0.65873 | Running loss: 1.12671\n",
      "Epoch: 1 | Iteration: 81 | Classification loss: 0.44315 | Regression loss: 0.50067 | Running loss: 1.12581\n",
      "Epoch: 1 | Iteration: 82 | Classification loss: 0.37248 | Regression loss: 0.49356 | Running loss: 1.12520\n",
      "Epoch: 1 | Iteration: 83 | Classification loss: 0.41217 | Regression loss: 0.49294 | Running loss: 1.12383\n",
      "Epoch: 1 | Iteration: 84 | Classification loss: 0.34407 | Regression loss: 0.46505 | Running loss: 1.12340\n",
      "Epoch: 1 | Iteration: 85 | Classification loss: 0.47187 | Regression loss: 0.62957 | Running loss: 1.12387\n",
      "Epoch: 1 | Iteration: 86 | Classification loss: 0.25982 | Regression loss: 0.37845 | Running loss: 1.12265\n",
      "Epoch: 1 | Iteration: 87 | Classification loss: 0.38537 | Regression loss: 0.37907 | Running loss: 1.12189\n",
      "Epoch: 1 | Iteration: 88 | Classification loss: 0.44437 | Regression loss: 0.59701 | Running loss: 1.12103\n",
      "Epoch: 1 | Iteration: 89 | Classification loss: 0.46562 | Regression loss: 0.59413 | Running loss: 1.12136\n",
      "Epoch: 1 | Iteration: 90 | Classification loss: 0.35298 | Regression loss: 0.78732 | Running loss: 1.12076\n",
      "Epoch: 1 | Iteration: 91 | Classification loss: 0.41232 | Regression loss: 0.55958 | Running loss: 1.12057\n",
      "Epoch: 1 | Iteration: 92 | Classification loss: 0.23664 | Regression loss: 0.58815 | Running loss: 1.12055\n",
      "Epoch: 1 | Iteration: 93 | Classification loss: 0.52094 | Regression loss: 1.15550 | Running loss: 1.12150\n",
      "Epoch: 1 | Iteration: 94 | Classification loss: 0.62597 | Regression loss: 0.61284 | Running loss: 1.12081\n",
      "Epoch: 1 | Iteration: 95 | Classification loss: 0.27450 | Regression loss: 0.68059 | Running loss: 1.12002\n",
      "Epoch: 1 | Iteration: 96 | Classification loss: 0.59164 | Regression loss: 0.34249 | Running loss: 1.11834\n",
      "Epoch: 1 | Iteration: 97 | Classification loss: 0.48609 | Regression loss: 0.57014 | Running loss: 1.11793\n",
      "Epoch: 1 | Iteration: 98 | Classification loss: 0.44354 | Regression loss: 0.63310 | Running loss: 1.11716\n",
      "Epoch: 1 | Iteration: 99 | Classification loss: 0.18410 | Regression loss: 0.41232 | Running loss: 1.11610\n",
      "Epoch: 1 | Iteration: 100 | Classification loss: 0.46214 | Regression loss: 0.54846 | Running loss: 1.11537\n",
      "Epoch: 1 | Iteration: 101 | Classification loss: 0.71257 | Regression loss: 0.91889 | Running loss: 1.11602\n",
      "Epoch: 1 | Iteration: 102 | Classification loss: 0.38326 | Regression loss: 0.62476 | Running loss: 1.11484\n",
      "Epoch: 1 | Iteration: 103 | Classification loss: 0.26534 | Regression loss: 0.46814 | Running loss: 1.11420\n",
      "Epoch: 1 | Iteration: 104 | Classification loss: 0.65028 | Regression loss: 0.90984 | Running loss: 1.11436\n",
      "Epoch: 1 | Iteration: 105 | Classification loss: 0.78808 | Regression loss: 0.87832 | Running loss: 1.11576\n",
      "Epoch: 1 | Iteration: 106 | Classification loss: 0.44660 | Regression loss: 0.58664 | Running loss: 1.11508\n",
      "Epoch: 1 | Iteration: 107 | Classification loss: 0.46491 | Regression loss: 0.36670 | Running loss: 1.11485\n",
      "Epoch: 1 | Iteration: 108 | Classification loss: 0.51691 | Regression loss: 0.66755 | Running loss: 1.11535\n",
      "Epoch: 1 | Iteration: 109 | Classification loss: 0.36262 | Regression loss: 0.59949 | Running loss: 1.11487\n",
      "Epoch: 1 | Iteration: 110 | Classification loss: 0.40989 | Regression loss: 0.53550 | Running loss: 1.11365\n",
      "Epoch: 1 | Iteration: 111 | Classification loss: 0.36132 | Regression loss: 0.60857 | Running loss: 1.11359\n",
      "Epoch: 1 | Iteration: 112 | Classification loss: 0.41266 | Regression loss: 0.77619 | Running loss: 1.11394\n",
      "Epoch: 1 | Iteration: 113 | Classification loss: 0.41104 | Regression loss: 0.45013 | Running loss: 1.11272\n",
      "Epoch: 1 | Iteration: 114 | Classification loss: 0.38337 | Regression loss: 0.75878 | Running loss: 1.11273\n",
      "Epoch: 1 | Iteration: 115 | Classification loss: 0.49437 | Regression loss: 0.77695 | Running loss: 1.11313\n",
      "Epoch: 1 | Iteration: 116 | Classification loss: 0.33041 | Regression loss: 0.36829 | Running loss: 1.11133\n",
      "Epoch: 1 | Iteration: 117 | Classification loss: 0.43441 | Regression loss: 0.51577 | Running loss: 1.11175\n",
      "Epoch: 1 | Iteration: 118 | Classification loss: 0.25204 | Regression loss: 0.65279 | Running loss: 1.11128\n",
      "Epoch: 1 | Iteration: 119 | Classification loss: 0.32344 | Regression loss: 0.56858 | Running loss: 1.10932\n",
      "Epoch: 1 | Iteration: 120 | Classification loss: 0.37417 | Regression loss: 0.59579 | Running loss: 1.10831\n",
      "Epoch: 1 | Iteration: 121 | Classification loss: 0.41035 | Regression loss: 0.56642 | Running loss: 1.10725\n",
      "Epoch: 1 | Iteration: 122 | Classification loss: 0.19882 | Regression loss: 0.24143 | Running loss: 1.10636\n",
      "Epoch: 1 | Iteration: 123 | Classification loss: 0.99297 | Regression loss: 1.12796 | Running loss: 1.10794\n",
      "Epoch: 1 | Iteration: 124 | Classification loss: 0.44286 | Regression loss: 0.78716 | Running loss: 1.10796\n",
      "Epoch: 1 | Iteration: 125 | Classification loss: 0.28391 | Regression loss: 0.54643 | Running loss: 1.10784\n",
      "Epoch: 1 | Iteration: 126 | Classification loss: 0.21380 | Regression loss: 0.48423 | Running loss: 1.10722\n",
      "Epoch: 1 | Iteration: 127 | Classification loss: 0.43582 | Regression loss: 0.66566 | Running loss: 1.10653\n",
      "Epoch: 1 | Iteration: 128 | Classification loss: 0.18840 | Regression loss: 0.24770 | Running loss: 1.10470\n",
      "Epoch: 1 | Iteration: 129 | Classification loss: 0.44837 | Regression loss: 0.59187 | Running loss: 1.10470\n",
      "Epoch: 1 | Iteration: 130 | Classification loss: 0.52998 | Regression loss: 0.75583 | Running loss: 1.10548\n",
      "Epoch: 1 | Iteration: 131 | Classification loss: 0.48429 | Regression loss: 0.74687 | Running loss: 1.10572\n",
      "Epoch: 1 | Iteration: 132 | Classification loss: 0.43389 | Regression loss: 0.43145 | Running loss: 1.10467\n",
      "Epoch: 1 | Iteration: 133 | Classification loss: 0.29856 | Regression loss: 0.29913 | Running loss: 1.10263\n",
      "Epoch: 1 | Iteration: 134 | Classification loss: 0.19488 | Regression loss: 0.42875 | Running loss: 1.10073\n",
      "Epoch: 1 | Iteration: 135 | Classification loss: 0.45914 | Regression loss: 0.43243 | Running loss: 1.09937\n",
      "Epoch: 1 | Iteration: 136 | Classification loss: 0.53880 | Regression loss: 0.50370 | Running loss: 1.09940\n",
      "Epoch: 1 | Iteration: 137 | Classification loss: 0.46463 | Regression loss: 0.58951 | Running loss: 1.09949\n",
      "Epoch: 1 | Iteration: 138 | Classification loss: 0.53656 | Regression loss: 0.25212 | Running loss: 1.09888\n",
      "Epoch: 1 | Iteration: 139 | Classification loss: 0.48951 | Regression loss: 0.57008 | Running loss: 1.09790\n",
      "Epoch: 1 | Iteration: 140 | Classification loss: 0.19717 | Regression loss: 0.49246 | Running loss: 1.09682\n",
      "Epoch: 1 | Iteration: 141 | Classification loss: 0.28479 | Regression loss: 0.43576 | Running loss: 1.09606\n",
      "Epoch: 1 | Iteration: 142 | Classification loss: 0.28299 | Regression loss: 0.38913 | Running loss: 1.09442\n",
      "Epoch: 1 | Iteration: 143 | Classification loss: 0.56879 | Regression loss: 0.37287 | Running loss: 1.09398\n",
      "Epoch: 1 | Iteration: 144 | Classification loss: 0.52078 | Regression loss: 0.68441 | Running loss: 1.09447\n",
      "Epoch: 1 | Iteration: 145 | Classification loss: 0.30571 | Regression loss: 0.64121 | Running loss: 1.09501\n",
      "Epoch: 1 | Iteration: 146 | Classification loss: 0.43398 | Regression loss: 0.52601 | Running loss: 1.09440\n",
      "Epoch: 1 | Iteration: 147 | Classification loss: 0.24768 | Regression loss: 0.25840 | Running loss: 1.09244\n",
      "Epoch: 1 | Iteration: 148 | Classification loss: 0.47879 | Regression loss: 0.63786 | Running loss: 1.09117\n",
      "Epoch: 1 | Iteration: 149 | Classification loss: 0.34000 | Regression loss: 0.63141 | Running loss: 1.09033\n",
      "Epoch: 1 | Iteration: 150 | Classification loss: 0.46430 | Regression loss: 0.83778 | Running loss: 1.09042\n",
      "Epoch: 1 | Iteration: 151 | Classification loss: 0.34130 | Regression loss: 0.40564 | Running loss: 1.08957\n",
      "Epoch: 1 | Iteration: 152 | Classification loss: 0.30977 | Regression loss: 0.44168 | Running loss: 1.08736\n",
      "Epoch: 1 | Iteration: 153 | Classification loss: 0.39008 | Regression loss: 0.67488 | Running loss: 1.08784\n",
      "Epoch: 1 | Iteration: 154 | Classification loss: 0.27536 | Regression loss: 0.39578 | Running loss: 1.08544\n",
      "Epoch: 1 | Iteration: 155 | Classification loss: 0.37868 | Regression loss: 0.42458 | Running loss: 1.08495\n",
      "Epoch: 1 | Iteration: 156 | Classification loss: 0.30326 | Regression loss: 0.47640 | Running loss: 1.08368\n",
      "Epoch: 1 | Iteration: 157 | Classification loss: 0.59986 | Regression loss: 0.60523 | Running loss: 1.08351\n",
      "Epoch: 1 | Iteration: 158 | Classification loss: 0.52333 | Regression loss: 0.63990 | Running loss: 1.08276\n",
      "Epoch: 1 | Iteration: 159 | Classification loss: 0.38231 | Regression loss: 0.53672 | Running loss: 1.08160\n",
      "Epoch: 1 | Iteration: 160 | Classification loss: 0.55469 | Regression loss: 0.37252 | Running loss: 1.08035\n",
      "Epoch: 1 | Iteration: 161 | Classification loss: 0.62273 | Regression loss: 0.76269 | Running loss: 1.08103\n",
      "Epoch: 1 | Iteration: 162 | Classification loss: 0.41968 | Regression loss: 0.18337 | Running loss: 1.08005\n",
      "Epoch: 1 | Iteration: 163 | Classification loss: 0.39051 | Regression loss: 1.04836 | Running loss: 1.08041\n",
      "Epoch: 1 | Iteration: 164 | Classification loss: 0.35499 | Regression loss: 0.49653 | Running loss: 1.07943\n",
      "Epoch: 1 | Iteration: 165 | Classification loss: 0.35584 | Regression loss: 0.58739 | Running loss: 1.07770\n",
      "Epoch: 1 | Iteration: 166 | Classification loss: 0.30809 | Regression loss: 0.49173 | Running loss: 1.07759\n",
      "Epoch: 1 | Iteration: 167 | Classification loss: 0.30234 | Regression loss: 0.45791 | Running loss: 1.07594\n",
      "Epoch: 1 | Iteration: 168 | Classification loss: 0.63867 | Regression loss: 0.65955 | Running loss: 1.07575\n",
      "Epoch: 1 | Iteration: 169 | Classification loss: 0.37536 | Regression loss: 0.71092 | Running loss: 1.07547\n",
      "Epoch: 1 | Iteration: 170 | Classification loss: 0.39051 | Regression loss: 0.58050 | Running loss: 1.07550\n",
      "Epoch: 1 | Iteration: 171 | Classification loss: 0.26114 | Regression loss: 0.36029 | Running loss: 1.07472\n",
      "Epoch: 1 | Iteration: 172 | Classification loss: 0.39017 | Regression loss: 0.43101 | Running loss: 1.07256\n",
      "Epoch: 1 | Iteration: 173 | Classification loss: 0.41847 | Regression loss: 0.55066 | Running loss: 1.07246\n",
      "Epoch: 1 | Iteration: 174 | Classification loss: 0.23921 | Regression loss: 0.36181 | Running loss: 1.07224\n",
      "Epoch: 1 | Iteration: 175 | Classification loss: 0.29180 | Regression loss: 0.37209 | Running loss: 1.07148\n",
      "Epoch: 1 | Iteration: 176 | Classification loss: 0.48370 | Regression loss: 0.82693 | Running loss: 1.07207\n",
      "Epoch: 1 | Iteration: 177 | Classification loss: 0.45630 | Regression loss: 0.59307 | Running loss: 1.07182\n",
      "Epoch: 1 | Iteration: 178 | Classification loss: 0.43775 | Regression loss: 0.37989 | Running loss: 1.07152\n",
      "Epoch: 1 | Iteration: 179 | Classification loss: 0.27874 | Regression loss: 0.44421 | Running loss: 1.07106\n",
      "Epoch: 1 | Iteration: 180 | Classification loss: 0.37119 | Regression loss: 0.62979 | Running loss: 1.07092\n",
      "Epoch: 1 | Iteration: 181 | Classification loss: 0.30231 | Regression loss: 0.51360 | Running loss: 1.07048\n",
      "Epoch: 1 | Iteration: 182 | Classification loss: 0.56844 | Regression loss: 0.53032 | Running loss: 1.06985\n",
      "Epoch: 1 | Iteration: 183 | Classification loss: 0.45390 | Regression loss: 1.04538 | Running loss: 1.06995\n",
      "Epoch: 1 | Iteration: 184 | Classification loss: 0.34256 | Regression loss: 0.48968 | Running loss: 1.06941\n",
      "Epoch: 1 | Iteration: 185 | Classification loss: 0.47115 | Regression loss: 0.75221 | Running loss: 1.06895\n",
      "Epoch: 1 | Iteration: 186 | Classification loss: 0.50023 | Regression loss: 0.79990 | Running loss: 1.06800\n",
      "Epoch: 1 | Iteration: 187 | Classification loss: 0.71229 | Regression loss: 0.73521 | Running loss: 1.06807\n",
      "Epoch: 1 | Iteration: 188 | Classification loss: 0.40338 | Regression loss: 0.53907 | Running loss: 1.06763\n",
      "Epoch: 1 | Iteration: 189 | Classification loss: 0.24546 | Regression loss: 0.29838 | Running loss: 1.06688\n",
      "Epoch: 1 | Iteration: 190 | Classification loss: 0.46821 | Regression loss: 0.89468 | Running loss: 1.06817\n",
      "Epoch: 1 | Iteration: 191 | Classification loss: 0.44425 | Regression loss: 0.65815 | Running loss: 1.06822\n",
      "Epoch: 1 | Iteration: 192 | Classification loss: 0.64793 | Regression loss: 0.66584 | Running loss: 1.06811\n",
      "Epoch: 1 | Iteration: 193 | Classification loss: 0.37080 | Regression loss: 0.42278 | Running loss: 1.06628\n",
      "Epoch: 1 | Iteration: 194 | Classification loss: 0.30398 | Regression loss: 0.54398 | Running loss: 1.06618\n",
      "Epoch: 1 | Iteration: 195 | Classification loss: 0.68949 | Regression loss: 0.87330 | Running loss: 1.06787\n",
      "Epoch: 1 | Iteration: 196 | Classification loss: 0.52024 | Regression loss: 0.57557 | Running loss: 1.06756\n",
      "Epoch: 1 | Iteration: 197 | Classification loss: 0.70099 | Regression loss: 0.61581 | Running loss: 1.06743\n",
      "Epoch: 1 | Iteration: 198 | Classification loss: 0.48466 | Regression loss: 0.73747 | Running loss: 1.06828\n",
      "Epoch: 1 | Iteration: 199 | Classification loss: 0.59036 | Regression loss: 0.51531 | Running loss: 1.06836\n",
      "Epoch: 1 | Iteration: 200 | Classification loss: 0.57799 | Regression loss: 0.66617 | Running loss: 1.06875\n",
      "Epoch: 1 | Iteration: 201 | Classification loss: 0.38365 | Regression loss: 0.58526 | Running loss: 1.06846\n",
      "Epoch: 1 | Iteration: 202 | Classification loss: 0.68034 | Regression loss: 0.79214 | Running loss: 1.06940\n",
      "Epoch: 1 | Iteration: 203 | Classification loss: 0.45066 | Regression loss: 0.54741 | Running loss: 1.06821\n",
      "Epoch: 1 | Iteration: 204 | Classification loss: 0.53153 | Regression loss: 0.77386 | Running loss: 1.06926\n",
      "Epoch: 1 | Iteration: 205 | Classification loss: 0.50585 | Regression loss: 0.75898 | Running loss: 1.06912\n",
      "Epoch: 1 | Iteration: 206 | Classification loss: 0.37667 | Regression loss: 0.61115 | Running loss: 1.06846\n",
      "Epoch: 1 | Iteration: 207 | Classification loss: 0.26757 | Regression loss: 0.53858 | Running loss: 1.06845\n",
      "Epoch: 1 | Iteration: 208 | Classification loss: 0.39641 | Regression loss: 0.75367 | Running loss: 1.06947\n",
      "Epoch: 1 | Iteration: 209 | Classification loss: 0.42519 | Regression loss: 0.47445 | Running loss: 1.06853\n",
      "Epoch: 1 | Iteration: 210 | Classification loss: 0.33422 | Regression loss: 0.32773 | Running loss: 1.06747\n",
      "Epoch: 1 | Iteration: 211 | Classification loss: 0.43602 | Regression loss: 0.78713 | Running loss: 1.06714\n",
      "Epoch: 1 | Iteration: 212 | Classification loss: 0.25235 | Regression loss: 0.34081 | Running loss: 1.06624\n",
      "Epoch: 1 | Iteration: 213 | Classification loss: 0.33704 | Regression loss: 0.64716 | Running loss: 1.06603\n",
      "Epoch: 1 | Iteration: 214 | Classification loss: 0.59576 | Regression loss: 0.75406 | Running loss: 1.06655\n",
      "Epoch: 1 | Iteration: 215 | Classification loss: 0.51555 | Regression loss: 0.71000 | Running loss: 1.06640\n",
      "Epoch: 1 | Iteration: 216 | Classification loss: 0.44978 | Regression loss: 0.35809 | Running loss: 1.06590\n",
      "Epoch: 1 | Iteration: 217 | Classification loss: 0.25286 | Regression loss: 0.40678 | Running loss: 1.06540\n",
      "Epoch: 1 | Iteration: 218 | Classification loss: 0.45502 | Regression loss: 0.50582 | Running loss: 1.06495\n",
      "Epoch: 1 | Iteration: 219 | Classification loss: 0.46448 | Regression loss: 0.42069 | Running loss: 1.06348\n",
      "Epoch: 1 | Iteration: 220 | Classification loss: 0.50538 | Regression loss: 0.31178 | Running loss: 1.06207\n",
      "Epoch: 1 | Iteration: 221 | Classification loss: 0.47727 | Regression loss: 0.68832 | Running loss: 1.06215\n",
      "Epoch: 1 | Iteration: 222 | Classification loss: 0.36628 | Regression loss: 0.79865 | Running loss: 1.06239\n",
      "Epoch: 1 | Iteration: 223 | Classification loss: 0.42489 | Regression loss: 0.25395 | Running loss: 1.06187\n",
      "Epoch: 1 | Iteration: 224 | Classification loss: 0.43832 | Regression loss: 0.61806 | Running loss: 1.06197\n",
      "Epoch: 1 | Iteration: 225 | Classification loss: 0.25614 | Regression loss: 0.24086 | Running loss: 1.06067\n",
      "Epoch: 1 | Iteration: 226 | Classification loss: 0.37191 | Regression loss: 0.62851 | Running loss: 1.06072\n",
      "Epoch: 1 | Iteration: 227 | Classification loss: 0.15740 | Regression loss: 0.34204 | Running loss: 1.05938\n",
      "Epoch: 1 | Iteration: 228 | Classification loss: 0.37707 | Regression loss: 0.53755 | Running loss: 1.05917\n",
      "Epoch: 1 | Iteration: 229 | Classification loss: 0.44969 | Regression loss: 0.33292 | Running loss: 1.05878\n",
      "Epoch: 1 | Iteration: 230 | Classification loss: 0.50727 | Regression loss: 0.66591 | Running loss: 1.05846\n",
      "Epoch: 1 | Iteration: 231 | Classification loss: 0.18796 | Regression loss: 0.41637 | Running loss: 1.05687\n",
      "Epoch: 1 | Iteration: 232 | Classification loss: 0.36421 | Regression loss: 0.39093 | Running loss: 1.05666\n",
      "Epoch: 1 | Iteration: 233 | Classification loss: 0.39560 | Regression loss: 0.45527 | Running loss: 1.05619\n",
      "Epoch: 1 | Iteration: 234 | Classification loss: 0.34308 | Regression loss: 0.69608 | Running loss: 1.05583\n",
      "Epoch: 1 | Iteration: 235 | Classification loss: 0.33759 | Regression loss: 0.36511 | Running loss: 1.05481\n",
      "Epoch: 1 | Iteration: 236 | Classification loss: 0.41747 | Regression loss: 0.52032 | Running loss: 1.05370\n",
      "Epoch: 1 | Iteration: 237 | Classification loss: 0.36368 | Regression loss: 0.61575 | Running loss: 1.05212\n",
      "Epoch: 1 | Iteration: 238 | Classification loss: 0.39623 | Regression loss: 0.56632 | Running loss: 1.05188\n",
      "Epoch: 1 | Iteration: 239 | Classification loss: 0.49248 | Regression loss: 0.67930 | Running loss: 1.05200\n",
      "Epoch: 1 | Iteration: 240 | Classification loss: 0.55526 | Regression loss: 0.45372 | Running loss: 1.05215\n",
      "Epoch: 1 | Iteration: 241 | Classification loss: 0.75995 | Regression loss: 0.82986 | Running loss: 1.05340\n",
      "Epoch: 1 | Iteration: 242 | Classification loss: 0.42646 | Regression loss: 0.54574 | Running loss: 1.05393\n",
      "Epoch: 1 | Iteration: 243 | Classification loss: 0.59366 | Regression loss: 0.74518 | Running loss: 1.05495\n",
      "Epoch: 1 | Iteration: 244 | Classification loss: 0.56843 | Regression loss: 0.72957 | Running loss: 1.05573\n",
      "Epoch: 1 | Iteration: 245 | Classification loss: 0.37386 | Regression loss: 0.45368 | Running loss: 1.05566\n",
      "Epoch: 1 | Iteration: 246 | Classification loss: 0.37742 | Regression loss: 0.74481 | Running loss: 1.05582\n",
      "Epoch: 1 | Iteration: 247 | Classification loss: 0.51072 | Regression loss: 0.41890 | Running loss: 1.05463\n",
      "Epoch: 1 | Iteration: 248 | Classification loss: 0.24915 | Regression loss: 0.45070 | Running loss: 1.05403\n",
      "Epoch: 1 | Iteration: 249 | Classification loss: 0.49532 | Regression loss: 0.49960 | Running loss: 1.05326\n",
      "Epoch: 1 | Iteration: 250 | Classification loss: 0.37905 | Regression loss: 0.43597 | Running loss: 1.05279\n",
      "Epoch: 1 | Iteration: 251 | Classification loss: 0.28875 | Regression loss: 0.41352 | Running loss: 1.05214\n",
      "Epoch: 1 | Iteration: 252 | Classification loss: 0.37653 | Regression loss: 0.49679 | Running loss: 1.05052\n",
      "Epoch: 1 | Iteration: 253 | Classification loss: 0.53990 | Regression loss: 0.79839 | Running loss: 1.05069\n",
      "Epoch: 1 | Iteration: 254 | Classification loss: 0.42281 | Regression loss: 0.56852 | Running loss: 1.04917\n",
      "Epoch: 1 | Iteration: 255 | Classification loss: 0.67140 | Regression loss: 0.41451 | Running loss: 1.04849\n",
      "Epoch: 1 | Iteration: 256 | Classification loss: 0.34131 | Regression loss: 0.56823 | Running loss: 1.04756\n",
      "Epoch: 1 | Iteration: 257 | Classification loss: 0.26159 | Regression loss: 0.56979 | Running loss: 1.04753\n",
      "Epoch: 1 | Iteration: 258 | Classification loss: 0.62964 | Regression loss: 0.51213 | Running loss: 1.04796\n",
      "Epoch: 1 | Iteration: 259 | Classification loss: 0.54992 | Regression loss: 0.59706 | Running loss: 1.04797\n",
      "Epoch: 1 | Iteration: 260 | Classification loss: 0.43174 | Regression loss: 0.36482 | Running loss: 1.04754\n",
      "Epoch: 1 | Iteration: 261 | Classification loss: 0.46495 | Regression loss: 0.84315 | Running loss: 1.04833\n",
      "Epoch: 1 | Iteration: 262 | Classification loss: 0.46513 | Regression loss: 0.54312 | Running loss: 1.04836\n",
      "Epoch: 1 | Iteration: 263 | Classification loss: 0.40306 | Regression loss: 0.48722 | Running loss: 1.04772\n",
      "Epoch: 1 | Iteration: 264 | Classification loss: 0.39882 | Regression loss: 0.41377 | Running loss: 1.04732\n",
      "Epoch: 1 | Iteration: 265 | Classification loss: 0.16893 | Regression loss: 0.37063 | Running loss: 1.04522\n",
      "Epoch: 1 | Iteration: 266 | Classification loss: 0.36900 | Regression loss: 0.35970 | Running loss: 1.04396\n",
      "Epoch: 1 | Iteration: 267 | Classification loss: 0.41204 | Regression loss: 0.93514 | Running loss: 1.04465\n",
      "Epoch: 1 | Iteration: 268 | Classification loss: 0.34084 | Regression loss: 0.52863 | Running loss: 1.04462\n",
      "Epoch: 1 | Iteration: 269 | Classification loss: 0.51192 | Regression loss: 0.69559 | Running loss: 1.04449\n",
      "Epoch: 1 | Iteration: 270 | Classification loss: 0.61240 | Regression loss: 0.83709 | Running loss: 1.04581\n",
      "Epoch: 1 | Iteration: 271 | Classification loss: 0.51299 | Regression loss: 0.70621 | Running loss: 1.04624\n",
      "Epoch: 1 | Iteration: 272 | Classification loss: 0.50359 | Regression loss: 0.71042 | Running loss: 1.04645\n",
      "Epoch: 1 | Iteration: 273 | Classification loss: 0.34930 | Regression loss: 0.50518 | Running loss: 1.04664\n",
      "Epoch: 1 | Iteration: 274 | Classification loss: 0.35773 | Regression loss: 0.49127 | Running loss: 1.04623\n",
      "Epoch: 1 | Iteration: 275 | Classification loss: 0.44544 | Regression loss: 0.61537 | Running loss: 1.04568\n",
      "Epoch: 1 | Iteration: 276 | Classification loss: 0.50539 | Regression loss: 0.69016 | Running loss: 1.04475\n",
      "Epoch: 1 | Iteration: 277 | Classification loss: 0.52137 | Regression loss: 0.55795 | Running loss: 1.04503\n",
      "Epoch: 1 | Iteration: 278 | Classification loss: 0.32751 | Regression loss: 0.41057 | Running loss: 1.04506\n",
      "Epoch: 1 | Iteration: 279 | Classification loss: 0.44636 | Regression loss: 0.64040 | Running loss: 1.04516\n",
      "Epoch: 1 | Iteration: 280 | Classification loss: 0.41821 | Regression loss: 0.82606 | Running loss: 1.04508\n",
      "Epoch: 1 | Iteration: 281 | Classification loss: 0.24138 | Regression loss: 0.26467 | Running loss: 1.04315\n",
      "Epoch: 1 | Iteration: 282 | Classification loss: 0.41686 | Regression loss: 0.76591 | Running loss: 1.04310\n",
      "Epoch: 1 | Iteration: 283 | Classification loss: 0.34237 | Regression loss: 0.45671 | Running loss: 1.04245\n",
      "Epoch: 1 | Iteration: 284 | Classification loss: 0.41597 | Regression loss: 1.02140 | Running loss: 1.04278\n",
      "Epoch: 1 | Iteration: 285 | Classification loss: 0.50045 | Regression loss: 0.37159 | Running loss: 1.04290\n",
      "Epoch: 1 | Iteration: 286 | Classification loss: 0.39472 | Regression loss: 0.73340 | Running loss: 1.04354\n",
      "Epoch: 1 | Iteration: 287 | Classification loss: 0.36412 | Regression loss: 0.40830 | Running loss: 1.04295\n",
      "Epoch: 1 | Iteration: 288 | Classification loss: 0.60498 | Regression loss: 0.88382 | Running loss: 1.04333\n",
      "Epoch: 1 | Iteration: 289 | Classification loss: 0.55013 | Regression loss: 0.58374 | Running loss: 1.04386\n",
      "Epoch: 1 | Iteration: 290 | Classification loss: 0.46952 | Regression loss: 0.62156 | Running loss: 1.04423\n",
      "Epoch: 1 | Iteration: 291 | Classification loss: 0.32731 | Regression loss: 0.55561 | Running loss: 1.04285\n",
      "Epoch: 1 | Iteration: 292 | Classification loss: 0.34122 | Regression loss: 0.58481 | Running loss: 1.04274\n",
      "Epoch: 1 | Iteration: 293 | Classification loss: 0.41978 | Regression loss: 0.61662 | Running loss: 1.04261\n",
      "Epoch: 1 | Iteration: 294 | Classification loss: 0.53826 | Regression loss: 0.29950 | Running loss: 1.04200\n",
      "Epoch: 1 | Iteration: 295 | Classification loss: 0.54348 | Regression loss: 0.81737 | Running loss: 1.04240\n",
      "Epoch: 1 | Iteration: 296 | Classification loss: 0.26780 | Regression loss: 0.47683 | Running loss: 1.04179\n",
      "Epoch: 1 | Iteration: 297 | Classification loss: 0.37177 | Regression loss: 0.61172 | Running loss: 1.04196\n",
      "Epoch: 1 | Iteration: 298 | Classification loss: 0.49125 | Regression loss: 0.55428 | Running loss: 1.04172\n",
      "Epoch: 1 | Iteration: 299 | Classification loss: 0.39486 | Regression loss: 0.42760 | Running loss: 1.04167\n",
      "Epoch: 1 | Iteration: 300 | Classification loss: 0.48703 | Regression loss: 0.51790 | Running loss: 1.04161\n",
      "Epoch: 1 | Iteration: 301 | Classification loss: 0.51214 | Regression loss: 0.70083 | Running loss: 1.04238\n",
      "Epoch: 1 | Iteration: 302 | Classification loss: 0.40199 | Regression loss: 0.61570 | Running loss: 1.04276\n",
      "Epoch: 1 | Iteration: 303 | Classification loss: 0.58020 | Regression loss: 0.79257 | Running loss: 1.04333\n",
      "Epoch: 1 | Iteration: 304 | Classification loss: 0.40143 | Regression loss: 0.33219 | Running loss: 1.04310\n",
      "Epoch: 1 | Iteration: 305 | Classification loss: 0.26841 | Regression loss: 0.64395 | Running loss: 1.04273\n",
      "Epoch: 1 | Iteration: 306 | Classification loss: 0.54576 | Regression loss: 0.76496 | Running loss: 1.04300\n",
      "Epoch: 1 | Iteration: 307 | Classification loss: 0.90225 | Regression loss: 0.00000 | Running loss: 1.04295\n",
      "Epoch: 1 | Iteration: 308 | Classification loss: 0.65488 | Regression loss: 1.13573 | Running loss: 1.04487\n",
      "Epoch: 1 | Iteration: 309 | Classification loss: 0.32287 | Regression loss: 0.50140 | Running loss: 1.04408\n",
      "Epoch: 1 | Iteration: 310 | Classification loss: 0.50240 | Regression loss: 0.69103 | Running loss: 1.04423\n",
      "Epoch: 1 | Iteration: 311 | Classification loss: 0.32457 | Regression loss: 0.50397 | Running loss: 1.04330\n",
      "Epoch: 1 | Iteration: 312 | Classification loss: 0.28315 | Regression loss: 0.36514 | Running loss: 1.04280\n",
      "Epoch: 1 | Iteration: 313 | Classification loss: 0.32670 | Regression loss: 0.40290 | Running loss: 1.04239\n",
      "Epoch: 1 | Iteration: 314 | Classification loss: 0.39221 | Regression loss: 0.50102 | Running loss: 1.04194\n",
      "Epoch: 1 | Iteration: 315 | Classification loss: 0.47795 | Regression loss: 0.66969 | Running loss: 1.04234\n",
      "Epoch: 1 | Iteration: 316 | Classification loss: 0.45592 | Regression loss: 0.33531 | Running loss: 1.04216\n",
      "Epoch: 1 | Iteration: 317 | Classification loss: 0.58383 | Regression loss: 1.01784 | Running loss: 1.04276\n",
      "Epoch: 1 | Iteration: 318 | Classification loss: 0.26185 | Regression loss: 0.47674 | Running loss: 1.04226\n",
      "Epoch: 1 | Iteration: 319 | Classification loss: 0.51996 | Regression loss: 0.69684 | Running loss: 1.04314\n",
      "Epoch: 1 | Iteration: 320 | Classification loss: 0.20975 | Regression loss: 0.29515 | Running loss: 1.04253\n",
      "Epoch: 1 | Iteration: 321 | Classification loss: 0.64365 | Regression loss: 0.62220 | Running loss: 1.04254\n",
      "Epoch: 1 | Iteration: 322 | Classification loss: 0.36858 | Regression loss: 0.56354 | Running loss: 1.04263\n",
      "Epoch: 1 | Iteration: 323 | Classification loss: 0.47527 | Regression loss: 0.56906 | Running loss: 1.04191\n",
      "Epoch: 1 | Iteration: 324 | Classification loss: 0.33763 | Regression loss: 0.41563 | Running loss: 1.04095\n",
      "Epoch: 1 | Iteration: 325 | Classification loss: 0.49691 | Regression loss: 0.59800 | Running loss: 1.04058\n",
      "Epoch: 1 | Iteration: 326 | Classification loss: 0.37706 | Regression loss: 0.62020 | Running loss: 1.04078\n",
      "Epoch: 1 | Iteration: 327 | Classification loss: 0.21391 | Regression loss: 0.42353 | Running loss: 1.03882\n",
      "Epoch: 1 | Iteration: 328 | Classification loss: 0.69680 | Regression loss: 0.90394 | Running loss: 1.04049\n",
      "Epoch: 1 | Iteration: 329 | Classification loss: 0.26563 | Regression loss: 0.42009 | Running loss: 1.04068\n",
      "Epoch: 1 | Iteration: 330 | Classification loss: 0.26897 | Regression loss: 0.19762 | Running loss: 1.03910\n",
      "Epoch: 1 | Iteration: 331 | Classification loss: 0.48728 | Regression loss: 0.50000 | Running loss: 1.03851\n",
      "Epoch: 1 | Iteration: 332 | Classification loss: 0.31914 | Regression loss: 0.41548 | Running loss: 1.03788\n",
      "Epoch: 1 | Iteration: 333 | Classification loss: 0.29392 | Regression loss: 0.37313 | Running loss: 1.03610\n",
      "Epoch: 1 | Iteration: 334 | Classification loss: 0.54704 | Regression loss: 0.54744 | Running loss: 1.03507\n",
      "Epoch: 1 | Iteration: 335 | Classification loss: 0.31982 | Regression loss: 0.69691 | Running loss: 1.03408\n",
      "Epoch: 1 | Iteration: 336 | Classification loss: 0.40482 | Regression loss: 0.65704 | Running loss: 1.03319\n",
      "Epoch: 1 | Iteration: 337 | Classification loss: 0.33599 | Regression loss: 0.40643 | Running loss: 1.03260\n",
      "Epoch: 1 | Iteration: 338 | Classification loss: 0.39507 | Regression loss: 0.55646 | Running loss: 1.03258\n",
      "Epoch: 1 | Iteration: 339 | Classification loss: 0.23551 | Regression loss: 0.65850 | Running loss: 1.03220\n",
      "Epoch: 1 | Iteration: 340 | Classification loss: 0.22904 | Regression loss: 0.51734 | Running loss: 1.03175\n",
      "Epoch: 1 | Iteration: 341 | Classification loss: 0.35978 | Regression loss: 0.48279 | Running loss: 1.03087\n",
      "Epoch: 1 | Iteration: 342 | Classification loss: 0.44194 | Regression loss: 0.55802 | Running loss: 1.03093\n",
      "Epoch: 1 | Iteration: 343 | Classification loss: 0.50319 | Regression loss: 0.66338 | Running loss: 1.03137\n",
      "Epoch: 1 | Iteration: 344 | Classification loss: 0.28933 | Regression loss: 0.44197 | Running loss: 1.03130\n",
      "Epoch: 1 | Iteration: 345 | Classification loss: 0.47121 | Regression loss: 0.61133 | Running loss: 1.03181\n",
      "Epoch: 1 | Iteration: 346 | Classification loss: 0.37863 | Regression loss: 0.54428 | Running loss: 1.03131\n",
      "Epoch: 1 | Iteration: 347 | Classification loss: 0.35471 | Regression loss: 0.30953 | Running loss: 1.03036\n",
      "Epoch: 1 | Iteration: 348 | Classification loss: 0.40088 | Regression loss: 0.34515 | Running loss: 1.03038\n",
      "Epoch: 1 | Iteration: 349 | Classification loss: 0.48110 | Regression loss: 0.57285 | Running loss: 1.03049\n",
      "Epoch: 1 | Iteration: 350 | Classification loss: 0.18708 | Regression loss: 0.27574 | Running loss: 1.03004\n",
      "Epoch: 1 | Iteration: 351 | Classification loss: 0.60674 | Regression loss: 0.72967 | Running loss: 1.03118\n",
      "Epoch: 1 | Iteration: 352 | Classification loss: 0.20518 | Regression loss: 0.61849 | Running loss: 1.03049\n",
      "Epoch: 1 | Iteration: 353 | Classification loss: 0.24584 | Regression loss: 0.51447 | Running loss: 1.02780\n",
      "Epoch: 1 | Iteration: 354 | Classification loss: 0.23353 | Regression loss: 0.62323 | Running loss: 1.02772\n",
      "Epoch: 1 | Iteration: 355 | Classification loss: 0.31059 | Regression loss: 0.29901 | Running loss: 1.02720\n",
      "Epoch: 1 | Iteration: 356 | Classification loss: 0.35410 | Regression loss: 0.55807 | Running loss: 1.02558\n",
      "Epoch: 1 | Iteration: 357 | Classification loss: 0.52812 | Regression loss: 0.50222 | Running loss: 1.02421\n",
      "Epoch: 1 | Iteration: 358 | Classification loss: 0.43476 | Regression loss: 1.05165 | Running loss: 1.02562\n",
      "Epoch: 1 | Iteration: 359 | Classification loss: 0.39976 | Regression loss: 0.50701 | Running loss: 1.02478\n",
      "Epoch: 1 | Iteration: 360 | Classification loss: 0.67583 | Regression loss: 0.84828 | Running loss: 1.02635\n",
      "Epoch: 1 | Iteration: 361 | Classification loss: 0.43789 | Regression loss: 0.63606 | Running loss: 1.02572\n",
      "Epoch: 1 | Iteration: 362 | Classification loss: 0.39299 | Regression loss: 0.73669 | Running loss: 1.02565\n",
      "Epoch: 1 | Iteration: 363 | Classification loss: 0.38436 | Regression loss: 0.39129 | Running loss: 1.02466\n",
      "Epoch: 1 | Iteration: 364 | Classification loss: 0.42718 | Regression loss: 0.75376 | Running loss: 1.02547\n",
      "Epoch: 1 | Iteration: 365 | Classification loss: 0.35900 | Regression loss: 0.36456 | Running loss: 1.02554\n",
      "Epoch: 1 | Iteration: 366 | Classification loss: 0.37810 | Regression loss: 0.55012 | Running loss: 1.02465\n",
      "Epoch: 1 | Iteration: 367 | Classification loss: 0.25578 | Regression loss: 0.22434 | Running loss: 1.02382\n",
      "Epoch: 1 | Iteration: 368 | Classification loss: 0.16016 | Regression loss: 0.34640 | Running loss: 1.02194\n",
      "Epoch: 1 | Iteration: 369 | Classification loss: 0.38648 | Regression loss: 0.56450 | Running loss: 1.02229\n",
      "Epoch: 1 | Iteration: 370 | Classification loss: 0.26835 | Regression loss: 0.53955 | Running loss: 1.02156\n",
      "Epoch: 1 | Iteration: 371 | Classification loss: 0.53967 | Regression loss: 0.52001 | Running loss: 1.02171\n",
      "Epoch: 1 | Iteration: 372 | Classification loss: 0.19196 | Regression loss: 0.41996 | Running loss: 1.02107\n",
      "Epoch: 1 | Iteration: 373 | Classification loss: 0.46343 | Regression loss: 0.61684 | Running loss: 1.02144\n",
      "Epoch: 1 | Iteration: 374 | Classification loss: 0.33517 | Regression loss: 0.58217 | Running loss: 1.02022\n",
      "Epoch: 1 | Iteration: 375 | Classification loss: 0.31087 | Regression loss: 0.64150 | Running loss: 1.02019\n",
      "Epoch: 1 | Iteration: 376 | Classification loss: 0.18800 | Regression loss: 0.17000 | Running loss: 1.01904\n",
      "Epoch: 1 | Iteration: 377 | Classification loss: 0.52427 | Regression loss: 0.68573 | Running loss: 1.01951\n",
      "Epoch: 1 | Iteration: 378 | Classification loss: 0.38020 | Regression loss: 0.63697 | Running loss: 1.02036\n",
      "Epoch: 1 | Iteration: 379 | Classification loss: 0.34603 | Regression loss: 0.47447 | Running loss: 1.02051\n",
      "Epoch: 1 | Iteration: 380 | Classification loss: 0.63973 | Regression loss: 0.88746 | Running loss: 1.02147\n",
      "Epoch: 1 | Iteration: 381 | Classification loss: 0.30742 | Regression loss: 0.70254 | Running loss: 1.02119\n",
      "Epoch: 1 | Iteration: 382 | Classification loss: 0.40841 | Regression loss: 0.65428 | Running loss: 1.02034\n",
      "Epoch: 1 | Iteration: 383 | Classification loss: 0.39664 | Regression loss: 0.44009 | Running loss: 1.02036\n",
      "Epoch: 1 | Iteration: 384 | Classification loss: 0.38551 | Regression loss: 0.76528 | Running loss: 1.02101\n",
      "Epoch: 1 | Iteration: 385 | Classification loss: 0.28217 | Regression loss: 0.56482 | Running loss: 1.02090\n",
      "Epoch: 1 | Iteration: 386 | Classification loss: 0.25410 | Regression loss: 0.55179 | Running loss: 1.02111\n",
      "Epoch: 1 | Iteration: 387 | Classification loss: 0.47058 | Regression loss: 0.48694 | Running loss: 1.02014\n",
      "Epoch: 1 | Iteration: 388 | Classification loss: 0.65326 | Regression loss: 0.79672 | Running loss: 1.02051\n",
      "Epoch: 1 | Iteration: 389 | Classification loss: 0.51968 | Regression loss: 0.57062 | Running loss: 1.02054\n",
      "Epoch: 1 | Iteration: 390 | Classification loss: 0.47646 | Regression loss: 0.52628 | Running loss: 1.01976\n",
      "Epoch: 1 | Iteration: 391 | Classification loss: 0.37579 | Regression loss: 0.77451 | Running loss: 1.02022\n",
      "Epoch: 1 | Iteration: 392 | Classification loss: 0.44875 | Regression loss: 0.60581 | Running loss: 1.01976\n",
      "Epoch: 1 | Iteration: 393 | Classification loss: 0.37659 | Regression loss: 0.48944 | Running loss: 1.01847\n",
      "Epoch: 1 | Iteration: 394 | Classification loss: 0.43953 | Regression loss: 0.65427 | Running loss: 1.01906\n",
      "Epoch: 1 | Iteration: 395 | Classification loss: 0.35733 | Regression loss: 0.72711 | Running loss: 1.01919\n",
      "Epoch: 1 | Iteration: 396 | Classification loss: 0.36830 | Regression loss: 0.38585 | Running loss: 1.01937\n",
      "Epoch: 1 | Iteration: 397 | Classification loss: 0.39283 | Regression loss: 0.60991 | Running loss: 1.01940\n",
      "Epoch: 1 | Iteration: 398 | Classification loss: 0.34357 | Regression loss: 0.47360 | Running loss: 1.01905\n",
      "Epoch: 1 | Iteration: 399 | Classification loss: 0.46476 | Regression loss: 0.51554 | Running loss: 1.01966\n",
      "Epoch: 1 | Iteration: 400 | Classification loss: 0.49440 | Regression loss: 0.22958 | Running loss: 1.01892\n",
      "Epoch: 1 | Iteration: 401 | Classification loss: 0.39978 | Regression loss: 0.65540 | Running loss: 1.01861\n",
      "Epoch: 1 | Iteration: 402 | Classification loss: 0.42526 | Regression loss: 0.52603 | Running loss: 1.01803\n",
      "Epoch: 1 | Iteration: 403 | Classification loss: 0.70100 | Regression loss: 0.88350 | Running loss: 1.01869\n",
      "Epoch: 1 | Iteration: 404 | Classification loss: 0.58309 | Regression loss: 0.27099 | Running loss: 1.01876\n",
      "Epoch: 1 | Iteration: 405 | Classification loss: 0.59978 | Regression loss: 0.65503 | Running loss: 1.01819\n",
      "Epoch: 1 | Iteration: 406 | Classification loss: 0.66545 | Regression loss: 0.82554 | Running loss: 1.01771\n",
      "Epoch: 1 | Iteration: 407 | Classification loss: 0.29296 | Regression loss: 0.30313 | Running loss: 1.01657\n",
      "Epoch: 1 | Iteration: 408 | Classification loss: 0.35790 | Regression loss: 0.40783 | Running loss: 1.01618\n",
      "Epoch: 1 | Iteration: 409 | Classification loss: 0.50453 | Regression loss: 0.62666 | Running loss: 1.01628\n",
      "Epoch: 1 | Iteration: 410 | Classification loss: 0.38718 | Regression loss: 0.67831 | Running loss: 1.01615\n",
      "Epoch: 1 | Iteration: 411 | Classification loss: 0.45071 | Regression loss: 0.51775 | Running loss: 1.01594\n",
      "Epoch: 1 | Iteration: 412 | Classification loss: 0.34088 | Regression loss: 0.63296 | Running loss: 1.01584\n",
      "Epoch: 1 | Iteration: 413 | Classification loss: 0.33053 | Regression loss: 0.35414 | Running loss: 1.01537\n",
      "Epoch: 1 | Iteration: 414 | Classification loss: 0.57167 | Regression loss: 0.75930 | Running loss: 1.01621\n",
      "Epoch: 1 | Iteration: 415 | Classification loss: 0.61077 | Regression loss: 0.75176 | Running loss: 1.01687\n",
      "Epoch: 1 | Iteration: 416 | Classification loss: 0.29673 | Regression loss: 0.35217 | Running loss: 1.01524\n",
      "Epoch: 1 | Iteration: 417 | Classification loss: 0.33844 | Regression loss: 0.51907 | Running loss: 1.01443\n",
      "Epoch: 1 | Iteration: 418 | Classification loss: 0.35353 | Regression loss: 0.75599 | Running loss: 1.01287\n",
      "Epoch: 1 | Iteration: 419 | Classification loss: 0.41210 | Regression loss: 0.52603 | Running loss: 1.01275\n",
      "Epoch: 1 | Iteration: 420 | Classification loss: 0.39644 | Regression loss: 0.64616 | Running loss: 1.01274\n",
      "Epoch: 1 | Iteration: 421 | Classification loss: 0.48438 | Regression loss: 0.56190 | Running loss: 1.01271\n",
      "Epoch: 1 | Iteration: 422 | Classification loss: 0.46355 | Regression loss: 0.71335 | Running loss: 1.01297\n",
      "Epoch: 1 | Iteration: 423 | Classification loss: 0.54023 | Regression loss: 0.77214 | Running loss: 1.01376\n",
      "Epoch: 1 | Iteration: 424 | Classification loss: 0.40607 | Regression loss: 0.55754 | Running loss: 1.01354\n",
      "Epoch: 1 | Iteration: 425 | Classification loss: 0.17066 | Regression loss: 0.37299 | Running loss: 1.01291\n",
      "Epoch: 1 | Iteration: 426 | Classification loss: 0.47513 | Regression loss: 0.66356 | Running loss: 1.01159\n",
      "Epoch: 1 | Iteration: 427 | Classification loss: 0.47951 | Regression loss: 0.66783 | Running loss: 1.01172\n",
      "Epoch: 1 | Iteration: 428 | Classification loss: 0.53637 | Regression loss: 0.89641 | Running loss: 1.01218\n",
      "Epoch: 1 | Iteration: 429 | Classification loss: 0.37912 | Regression loss: 0.27324 | Running loss: 1.01182\n",
      "Epoch: 1 | Iteration: 430 | Classification loss: 0.39307 | Regression loss: 0.54420 | Running loss: 1.01200\n",
      "Epoch: 1 | Iteration: 431 | Classification loss: 0.48953 | Regression loss: 0.70147 | Running loss: 1.01251\n",
      "Epoch: 1 | Iteration: 432 | Classification loss: 0.28598 | Regression loss: 0.45955 | Running loss: 1.01259\n",
      "Epoch: 1 | Iteration: 433 | Classification loss: 0.36949 | Regression loss: 0.50020 | Running loss: 1.01200\n",
      "Epoch: 1 | Iteration: 434 | Classification loss: 0.23531 | Regression loss: 0.28982 | Running loss: 1.01065\n",
      "Epoch: 1 | Iteration: 435 | Classification loss: 0.36614 | Regression loss: 0.55884 | Running loss: 1.00930\n",
      "Epoch: 1 | Iteration: 436 | Classification loss: 0.40077 | Regression loss: 0.36439 | Running loss: 1.00936\n",
      "Epoch: 1 | Iteration: 437 | Classification loss: 0.56441 | Regression loss: 0.70824 | Running loss: 1.00948\n",
      "Epoch: 1 | Iteration: 438 | Classification loss: 0.46352 | Regression loss: 0.74581 | Running loss: 1.00994\n",
      "Epoch: 1 | Iteration: 439 | Classification loss: 0.36877 | Regression loss: 0.66844 | Running loss: 1.00957\n",
      "Epoch: 1 | Iteration: 440 | Classification loss: 0.29005 | Regression loss: 0.41098 | Running loss: 1.00808\n",
      "Epoch: 1 | Iteration: 441 | Classification loss: 0.38994 | Regression loss: 0.60996 | Running loss: 1.00822\n",
      "Epoch: 1 | Iteration: 442 | Classification loss: 0.37551 | Regression loss: 0.47983 | Running loss: 1.00798\n",
      "Epoch: 1 | Iteration: 443 | Classification loss: 0.39949 | Regression loss: 0.36142 | Running loss: 1.00822\n",
      "Epoch: 1 | Iteration: 444 | Classification loss: 0.34899 | Regression loss: 0.50612 | Running loss: 1.00848\n",
      "Epoch: 1 | Iteration: 445 | Classification loss: 0.67534 | Regression loss: 0.78698 | Running loss: 1.00987\n",
      "Epoch: 1 | Iteration: 446 | Classification loss: 0.38404 | Regression loss: 0.47442 | Running loss: 1.00977\n",
      "Epoch: 1 | Iteration: 447 | Classification loss: 0.39691 | Regression loss: 0.44189 | Running loss: 1.00855\n",
      "Epoch: 1 | Iteration: 448 | Classification loss: 0.45980 | Regression loss: 0.67979 | Running loss: 1.00946\n",
      "Epoch: 1 | Iteration: 449 | Classification loss: 0.43550 | Regression loss: 0.46296 | Running loss: 1.00911\n",
      "Epoch: 1 | Iteration: 450 | Classification loss: 0.23437 | Regression loss: 0.65805 | Running loss: 1.00848\n",
      "Epoch: 1 | Iteration: 451 | Classification loss: 0.45275 | Regression loss: 0.68882 | Running loss: 1.00781\n",
      "Epoch: 1 | Iteration: 452 | Classification loss: 0.37415 | Regression loss: 0.62220 | Running loss: 1.00775\n",
      "Epoch: 1 | Iteration: 453 | Classification loss: 0.49260 | Regression loss: 0.47284 | Running loss: 1.00765\n",
      "Epoch: 1 | Iteration: 454 | Classification loss: 0.57960 | Regression loss: 0.76262 | Running loss: 1.00882\n",
      "Epoch: 1 | Iteration: 455 | Classification loss: 0.32096 | Regression loss: 0.31638 | Running loss: 1.00823\n",
      "Epoch: 1 | Iteration: 456 | Classification loss: 0.52720 | Regression loss: 0.60203 | Running loss: 1.00809\n",
      "Epoch: 1 | Iteration: 457 | Classification loss: 1.52215 | Regression loss: 0.36635 | Running loss: 1.00995\n",
      "Epoch: 1 | Iteration: 458 | Classification loss: 0.47011 | Regression loss: 0.46538 | Running loss: 1.00943\n",
      "Epoch: 1 | Iteration: 459 | Classification loss: 0.38818 | Regression loss: 0.28159 | Running loss: 1.00889\n",
      "Epoch: 1 | Iteration: 460 | Classification loss: 0.45782 | Regression loss: 0.54422 | Running loss: 1.00765\n",
      "Epoch: 1 | Iteration: 461 | Classification loss: 0.44986 | Regression loss: 0.50332 | Running loss: 1.00719\n",
      "Epoch: 1 | Iteration: 462 | Classification loss: 0.31199 | Regression loss: 0.55160 | Running loss: 1.00687\n",
      "Epoch: 1 | Iteration: 463 | Classification loss: 0.38270 | Regression loss: 0.53843 | Running loss: 1.00601\n",
      "Epoch: 1 | Iteration: 464 | Classification loss: 0.33281 | Regression loss: 0.46931 | Running loss: 1.00524\n",
      "Epoch: 1 | Iteration: 465 | Classification loss: 0.56647 | Regression loss: 0.71718 | Running loss: 1.00477\n",
      "Epoch: 1 | Iteration: 466 | Classification loss: 0.29839 | Regression loss: 0.55790 | Running loss: 1.00423\n",
      "Epoch: 1 | Iteration: 467 | Classification loss: 0.32714 | Regression loss: 0.56376 | Running loss: 1.00286\n",
      "Epoch: 1 | Iteration: 468 | Classification loss: 0.38592 | Regression loss: 0.60300 | Running loss: 1.00315\n",
      "Epoch: 1 | Iteration: 469 | Classification loss: 0.50997 | Regression loss: 0.67519 | Running loss: 1.00336\n",
      "Epoch: 1 | Iteration: 470 | Classification loss: 0.44249 | Regression loss: 0.54325 | Running loss: 1.00328\n",
      "Epoch: 1 | Iteration: 471 | Classification loss: 0.75898 | Regression loss: 0.83240 | Running loss: 1.00388\n",
      "Epoch: 1 | Iteration: 472 | Classification loss: 0.56127 | Regression loss: 0.33147 | Running loss: 1.00274\n",
      "Epoch: 1 | Iteration: 473 | Classification loss: 0.25402 | Regression loss: 0.35066 | Running loss: 1.00208\n",
      "Epoch: 1 | Iteration: 474 | Classification loss: 0.50364 | Regression loss: 0.74578 | Running loss: 1.00277\n",
      "Epoch: 1 | Iteration: 475 | Classification loss: 0.49522 | Regression loss: 0.73860 | Running loss: 1.00325\n",
      "Epoch: 1 | Iteration: 476 | Classification loss: 0.38054 | Regression loss: 0.43968 | Running loss: 1.00305\n",
      "Epoch: 1 | Iteration: 477 | Classification loss: 0.70234 | Regression loss: 0.82547 | Running loss: 1.00311\n",
      "Epoch: 1 | Iteration: 478 | Classification loss: 0.36840 | Regression loss: 0.43560 | Running loss: 1.00268\n",
      "Epoch: 1 | Iteration: 479 | Classification loss: 0.41103 | Regression loss: 0.54558 | Running loss: 1.00285\n",
      "Epoch: 1 | Iteration: 480 | Classification loss: 0.29070 | Regression loss: 0.35946 | Running loss: 1.00104\n",
      "Epoch: 1 | Iteration: 481 | Classification loss: 0.37051 | Regression loss: 0.49172 | Running loss: 1.00044\n",
      "Epoch: 1 | Iteration: 482 | Classification loss: 0.37730 | Regression loss: 0.87475 | Running loss: 1.00013\n",
      "Epoch: 1 | Iteration: 483 | Classification loss: 0.38682 | Regression loss: 0.54540 | Running loss: 0.99993\n",
      "Epoch: 1 | Iteration: 484 | Classification loss: 0.30590 | Regression loss: 0.25299 | Running loss: 0.99926\n",
      "Epoch: 1 | Iteration: 485 | Classification loss: 0.41786 | Regression loss: 0.26293 | Running loss: 0.99900\n",
      "Epoch: 1 | Iteration: 486 | Classification loss: 0.41706 | Regression loss: 0.59608 | Running loss: 0.99937\n",
      "Epoch: 1 | Iteration: 487 | Classification loss: 0.36691 | Regression loss: 0.58358 | Running loss: 0.99898\n",
      "Epoch: 1 | Iteration: 488 | Classification loss: 0.48845 | Regression loss: 0.64663 | Running loss: 0.99887\n",
      "Epoch: 1 | Iteration: 489 | Classification loss: 0.40457 | Regression loss: 0.20587 | Running loss: 0.99880\n",
      "Epoch: 1 | Iteration: 490 | Classification loss: 0.47070 | Regression loss: 0.84546 | Running loss: 0.99989\n",
      "Epoch: 1 | Iteration: 491 | Classification loss: 0.37780 | Regression loss: 0.65758 | Running loss: 0.99990\n",
      "Epoch: 1 | Iteration: 492 | Classification loss: 0.34186 | Regression loss: 0.77684 | Running loss: 0.99979\n",
      "Epoch: 1 | Iteration: 493 | Classification loss: 0.45503 | Regression loss: 0.57515 | Running loss: 0.99924\n",
      "Epoch: 1 | Iteration: 494 | Classification loss: 0.51560 | Regression loss: 0.78822 | Running loss: 0.99898\n",
      "Epoch: 1 | Iteration: 495 | Classification loss: 0.46923 | Regression loss: 0.29473 | Running loss: 0.99723\n",
      "Epoch: 1 | Iteration: 496 | Classification loss: 0.79288 | Regression loss: 0.32002 | Running loss: 0.99736\n",
      "Epoch: 1 | Iteration: 497 | Classification loss: 0.47967 | Regression loss: 0.43678 | Running loss: 0.99640\n",
      "Epoch: 1 | Iteration: 498 | Classification loss: 0.39613 | Regression loss: 0.51841 | Running loss: 0.99656\n",
      "Epoch: 1 | Iteration: 499 | Classification loss: 0.38631 | Regression loss: 0.20547 | Running loss: 0.99512\n",
      "Epoch: 1 | Iteration: 500 | Classification loss: 0.34044 | Regression loss: 0.64609 | Running loss: 0.99455\n",
      "Epoch: 1 | Iteration: 501 | Classification loss: 0.43040 | Regression loss: 0.60793 | Running loss: 0.99626\n",
      "Epoch: 1 | Iteration: 502 | Classification loss: 0.62041 | Regression loss: 0.78937 | Running loss: 0.99713\n",
      "Epoch: 1 | Iteration: 503 | Classification loss: 0.34215 | Regression loss: 0.38897 | Running loss: 0.99641\n",
      "Epoch: 1 | Iteration: 504 | Classification loss: 0.43621 | Regression loss: 0.48877 | Running loss: 0.99553\n",
      "Epoch: 1 | Iteration: 505 | Classification loss: 0.30077 | Regression loss: 0.39668 | Running loss: 0.99473\n",
      "Epoch: 1 | Iteration: 506 | Classification loss: 0.78899 | Regression loss: 0.77134 | Running loss: 0.99574\n",
      "Epoch: 1 | Iteration: 507 | Classification loss: 0.64185 | Regression loss: 0.84678 | Running loss: 0.99593\n",
      "Epoch: 1 | Iteration: 508 | Classification loss: 0.46027 | Regression loss: 0.85801 | Running loss: 0.99662\n",
      "Epoch: 1 | Iteration: 509 | Classification loss: 0.73939 | Regression loss: 0.68983 | Running loss: 0.99732\n",
      "Epoch: 1 | Iteration: 510 | Classification loss: 0.41442 | Regression loss: 0.60547 | Running loss: 0.99731\n",
      "Epoch: 1 | Iteration: 511 | Classification loss: 0.33820 | Regression loss: 0.52650 | Running loss: 0.99760\n",
      "Epoch: 1 | Iteration: 512 | Classification loss: 0.34152 | Regression loss: 0.57915 | Running loss: 0.99676\n",
      "Epoch: 1 | Iteration: 513 | Classification loss: 0.53133 | Regression loss: 0.88758 | Running loss: 0.99693\n",
      "Epoch: 1 | Iteration: 514 | Classification loss: 0.51469 | Regression loss: 0.79002 | Running loss: 0.99759\n",
      "Epoch: 1 | Iteration: 515 | Classification loss: 0.39366 | Regression loss: 0.71447 | Running loss: 0.99776\n",
      "Epoch: 1 | Iteration: 516 | Classification loss: 0.40104 | Regression loss: 0.52691 | Running loss: 0.99717\n",
      "Epoch: 1 | Iteration: 517 | Classification loss: 0.57231 | Regression loss: 0.77370 | Running loss: 0.99796\n",
      "Epoch: 1 | Iteration: 518 | Classification loss: 0.56630 | Regression loss: 0.72873 | Running loss: 0.99863\n",
      "Epoch: 1 | Iteration: 519 | Classification loss: 0.44211 | Regression loss: 0.60378 | Running loss: 0.99908\n",
      "Epoch: 1 | Iteration: 520 | Classification loss: 0.38615 | Regression loss: 0.46252 | Running loss: 0.99917\n",
      "Epoch: 1 | Iteration: 521 | Classification loss: 0.43653 | Regression loss: 0.54227 | Running loss: 0.99996\n",
      "Epoch: 1 | Iteration: 522 | Classification loss: 0.41503 | Regression loss: 0.24669 | Running loss: 0.99985\n",
      "Epoch: 1 | Iteration: 523 | Classification loss: 0.52227 | Regression loss: 0.44048 | Running loss: 0.99920\n",
      "Epoch: 1 | Iteration: 524 | Classification loss: 0.28330 | Regression loss: 0.44921 | Running loss: 0.99963\n",
      "Epoch: 1 | Iteration: 525 | Classification loss: 0.26080 | Regression loss: 0.46955 | Running loss: 0.99896\n",
      "Epoch: 1 | Iteration: 526 | Classification loss: 0.34308 | Regression loss: 0.40239 | Running loss: 0.99717\n",
      "Epoch: 1 | Iteration: 527 | Classification loss: 0.42529 | Regression loss: 0.31155 | Running loss: 0.99564\n",
      "Epoch: 1 | Iteration: 528 | Classification loss: 0.38847 | Regression loss: 0.44821 | Running loss: 0.99550\n",
      "Epoch: 1 | Iteration: 529 | Classification loss: 0.54827 | Regression loss: 0.93465 | Running loss: 0.99680\n",
      "Epoch: 1 | Iteration: 530 | Classification loss: 0.47244 | Regression loss: 0.60522 | Running loss: 0.99665\n",
      "Epoch: 1 | Iteration: 531 | Classification loss: 0.27109 | Regression loss: 0.46843 | Running loss: 0.99692\n",
      "Epoch: 1 | Iteration: 532 | Classification loss: 0.41810 | Regression loss: 0.93589 | Running loss: 0.99759\n",
      "Epoch: 1 | Iteration: 533 | Classification loss: 0.37725 | Regression loss: 0.36472 | Running loss: 0.99630\n",
      "Epoch: 1 | Iteration: 534 | Classification loss: 0.65440 | Regression loss: 0.71544 | Running loss: 0.99671\n",
      "Epoch: 1 | Iteration: 535 | Classification loss: 0.26768 | Regression loss: 0.50363 | Running loss: 0.99580\n",
      "Epoch: 1 | Iteration: 536 | Classification loss: 0.76624 | Regression loss: 1.39725 | Running loss: 0.99770\n",
      "Epoch: 1 | Iteration: 537 | Classification loss: 0.34439 | Regression loss: 0.40677 | Running loss: 0.99803\n",
      "Epoch: 1 | Iteration: 538 | Classification loss: 0.43248 | Regression loss: 0.60416 | Running loss: 0.99867\n",
      "Epoch: 1 | Iteration: 539 | Classification loss: 0.54033 | Regression loss: 0.67125 | Running loss: 0.99835\n",
      "Epoch: 1 | Iteration: 540 | Classification loss: 0.41946 | Regression loss: 0.45273 | Running loss: 0.99810\n",
      "Epoch: 1 | Iteration: 541 | Classification loss: 0.61390 | Regression loss: 0.78025 | Running loss: 0.99944\n",
      "Epoch: 1 | Iteration: 542 | Classification loss: 0.37931 | Regression loss: 0.66987 | Running loss: 0.99916\n",
      "Epoch: 1 | Iteration: 543 | Classification loss: 0.36872 | Regression loss: 0.52293 | Running loss: 0.99835\n",
      "Epoch: 1 | Iteration: 544 | Classification loss: 0.34742 | Regression loss: 0.51969 | Running loss: 0.99767\n",
      "Epoch: 1 | Iteration: 545 | Classification loss: 0.74876 | Regression loss: 1.17334 | Running loss: 0.99930\n",
      "Epoch: 1 | Iteration: 546 | Classification loss: 0.46058 | Regression loss: 0.61855 | Running loss: 0.99934\n",
      "Epoch: 1 | Iteration: 547 | Classification loss: 0.41814 | Regression loss: 0.74210 | Running loss: 0.99873\n",
      "Epoch: 1 | Iteration: 548 | Classification loss: 0.36072 | Regression loss: 0.42500 | Running loss: 0.99846\n",
      "Epoch: 1 | Iteration: 549 | Classification loss: 0.31358 | Regression loss: 0.46687 | Running loss: 0.99836\n",
      "Epoch: 1 | Iteration: 550 | Classification loss: 0.35935 | Regression loss: 0.42149 | Running loss: 0.99834\n",
      "Epoch: 1 | Iteration: 551 | Classification loss: 0.51882 | Regression loss: 0.87254 | Running loss: 0.99931\n",
      "Epoch: 1 | Iteration: 552 | Classification loss: 0.43985 | Regression loss: 0.77702 | Running loss: 1.00015\n",
      "Epoch: 1 | Iteration: 553 | Classification loss: 0.51364 | Regression loss: 0.60245 | Running loss: 1.00035\n",
      "Epoch: 1 | Iteration: 554 | Classification loss: 0.39797 | Regression loss: 0.43019 | Running loss: 1.00063\n",
      "Epoch: 1 | Iteration: 555 | Classification loss: 0.23789 | Regression loss: 0.58687 | Running loss: 1.00063\n",
      "Epoch: 1 | Iteration: 556 | Classification loss: 0.42321 | Regression loss: 0.58672 | Running loss: 0.99956\n",
      "Epoch: 1 | Iteration: 557 | Classification loss: 0.46506 | Regression loss: 0.64835 | Running loss: 0.99998\n",
      "Epoch: 1 | Iteration: 558 | Classification loss: 0.46205 | Regression loss: 0.58059 | Running loss: 1.00055\n",
      "Epoch: 1 | Iteration: 559 | Classification loss: 0.42203 | Regression loss: 0.58784 | Running loss: 1.00046\n",
      "Epoch: 1 | Iteration: 560 | Classification loss: 0.48941 | Regression loss: 0.43183 | Running loss: 1.00072\n",
      "Epoch: 1 | Iteration: 561 | Classification loss: 0.29296 | Regression loss: 0.58680 | Running loss: 1.00092\n",
      "Epoch: 1 | Iteration: 562 | Classification loss: 0.37264 | Regression loss: 0.62275 | Running loss: 1.00141\n",
      "Epoch: 1 | Iteration: 563 | Classification loss: 0.44580 | Regression loss: 0.64573 | Running loss: 1.00166\n",
      "Epoch: 1 | Iteration: 564 | Classification loss: 0.47288 | Regression loss: 0.39214 | Running loss: 1.00056\n",
      "Epoch: 1 | Iteration: 565 | Classification loss: 0.20832 | Regression loss: 0.52767 | Running loss: 0.99949\n",
      "Epoch: 1 | Iteration: 566 | Classification loss: 0.45813 | Regression loss: 0.70629 | Running loss: 0.99955\n",
      "Epoch: 1 | Iteration: 567 | Classification loss: 0.31956 | Regression loss: 0.41803 | Running loss: 0.99864\n",
      "Epoch: 1 | Iteration: 568 | Classification loss: 0.42507 | Regression loss: 0.49455 | Running loss: 0.99888\n",
      "Epoch: 1 | Iteration: 569 | Classification loss: 0.41308 | Regression loss: 0.72148 | Running loss: 0.99956\n",
      "Epoch: 1 | Iteration: 570 | Classification loss: 0.30206 | Regression loss: 0.43975 | Running loss: 0.99839\n",
      "Epoch: 1 | Iteration: 571 | Classification loss: 0.73909 | Regression loss: 0.85781 | Running loss: 0.99928\n",
      "Epoch: 1 | Iteration: 572 | Classification loss: 0.51099 | Regression loss: 0.53373 | Running loss: 0.99937\n",
      "Epoch: 1 | Iteration: 573 | Classification loss: 0.34101 | Regression loss: 0.52823 | Running loss: 0.99906\n",
      "Epoch: 1 | Iteration: 574 | Classification loss: 0.31908 | Regression loss: 0.47023 | Running loss: 0.99847\n",
      "Epoch: 1 | Iteration: 575 | Classification loss: 0.30143 | Regression loss: 0.38595 | Running loss: 0.99757\n",
      "Epoch: 1 | Iteration: 576 | Classification loss: 0.38088 | Regression loss: 0.73690 | Running loss: 0.99731\n",
      "Epoch: 1 | Iteration: 577 | Classification loss: 0.25167 | Regression loss: 0.39427 | Running loss: 0.99628\n",
      "Epoch: 1 | Iteration: 578 | Classification loss: 0.21974 | Regression loss: 0.26800 | Running loss: 0.99477\n",
      "Epoch: 1 | Iteration: 579 | Classification loss: 0.35957 | Regression loss: 0.46343 | Running loss: 0.99294\n",
      "Epoch: 1 | Iteration: 580 | Classification loss: 0.51910 | Regression loss: 0.61119 | Running loss: 0.99281\n",
      "Epoch: 1 | Iteration: 581 | Classification loss: 0.27233 | Regression loss: 0.36926 | Running loss: 0.99221\n",
      "Epoch: 1 | Iteration: 582 | Classification loss: 0.33890 | Regression loss: 0.20990 | Running loss: 0.99158\n",
      "Epoch: 1 | Iteration: 583 | Classification loss: 0.20964 | Regression loss: 0.39699 | Running loss: 0.99098\n",
      "Epoch: 1 | Iteration: 584 | Classification loss: 0.37404 | Regression loss: 0.54635 | Running loss: 0.99120\n",
      "Epoch: 1 | Iteration: 585 | Classification loss: 0.36670 | Regression loss: 0.46211 | Running loss: 0.99066\n",
      "Epoch: 1 | Iteration: 586 | Classification loss: 0.19771 | Regression loss: 0.42656 | Running loss: 0.99063\n",
      "Epoch: 1 | Iteration: 587 | Classification loss: 0.43437 | Regression loss: 0.76389 | Running loss: 0.99150\n",
      "Epoch: 1 | Iteration: 588 | Classification loss: 0.36958 | Regression loss: 0.59857 | Running loss: 0.99135\n",
      "Epoch: 1 | Iteration: 589 | Classification loss: 0.35517 | Regression loss: 0.39350 | Running loss: 0.99073\n",
      "Epoch: 1 | Iteration: 590 | Classification loss: 0.34511 | Regression loss: 0.49556 | Running loss: 0.99013\n",
      "Epoch: 1 | Iteration: 591 | Classification loss: 0.37463 | Regression loss: 0.24699 | Running loss: 0.98943\n",
      "Epoch: 1 | Iteration: 592 | Classification loss: 0.35099 | Regression loss: 0.35449 | Running loss: 0.98919\n",
      "Epoch: 1 | Iteration: 593 | Classification loss: 0.33169 | Regression loss: 0.54985 | Running loss: 0.98760\n",
      "Epoch: 1 | Iteration: 594 | Classification loss: 0.28456 | Regression loss: 0.29547 | Running loss: 0.98628\n",
      "Epoch: 1 | Iteration: 595 | Classification loss: 0.41149 | Regression loss: 0.75668 | Running loss: 0.98671\n",
      "Epoch: 1 | Iteration: 596 | Classification loss: 0.41713 | Regression loss: 0.73861 | Running loss: 0.98715\n",
      "Epoch: 1 | Iteration: 597 | Classification loss: 0.27992 | Regression loss: 0.43609 | Running loss: 0.98647\n",
      "Epoch: 1 | Iteration: 598 | Classification loss: 0.40931 | Regression loss: 0.63756 | Running loss: 0.98641\n",
      "Epoch: 1 | Iteration: 599 | Classification loss: 0.55451 | Regression loss: 0.62985 | Running loss: 0.98759\n",
      "Epoch: 1 | Iteration: 600 | Classification loss: 0.50963 | Regression loss: 0.49089 | Running loss: 0.98757\n",
      "Epoch: 1 | Iteration: 601 | Classification loss: 0.58647 | Regression loss: 0.55987 | Running loss: 0.98660\n",
      "Epoch: 1 | Iteration: 602 | Classification loss: 0.40140 | Regression loss: 0.47482 | Running loss: 0.98633\n",
      "Epoch: 1 | Iteration: 603 | Classification loss: 0.25310 | Regression loss: 0.22220 | Running loss: 0.98582\n",
      "Epoch: 1 | Iteration: 604 | Classification loss: 0.42075 | Regression loss: 0.50067 | Running loss: 0.98454\n",
      "Epoch: 1 | Iteration: 605 | Classification loss: 0.23354 | Regression loss: 0.45467 | Running loss: 0.98258\n",
      "Epoch: 1 | Iteration: 606 | Classification loss: 0.36684 | Regression loss: 0.56534 | Running loss: 0.98238\n",
      "Epoch: 1 | Iteration: 607 | Classification loss: 0.39274 | Regression loss: 0.42058 | Running loss: 0.98234\n",
      "Epoch: 1 | Iteration: 608 | Classification loss: 0.72152 | Regression loss: 0.99828 | Running loss: 0.98341\n",
      "Epoch: 1 | Iteration: 609 | Classification loss: 0.56113 | Regression loss: 0.72518 | Running loss: 0.98406\n",
      "Epoch: 1 | Iteration: 610 | Classification loss: 0.40036 | Regression loss: 0.73164 | Running loss: 0.98444\n",
      "Epoch: 1 | Iteration: 611 | Classification loss: 0.34748 | Regression loss: 0.53404 | Running loss: 0.98426\n",
      "Epoch: 1 | Iteration: 612 | Classification loss: 0.38497 | Regression loss: 0.51514 | Running loss: 0.98368\n",
      "Epoch: 1 | Iteration: 613 | Classification loss: 0.36926 | Regression loss: 0.72516 | Running loss: 0.98415\n",
      "Epoch: 1 | Iteration: 614 | Classification loss: 0.51493 | Regression loss: 0.37878 | Running loss: 0.98365\n",
      "Epoch: 1 | Iteration: 615 | Classification loss: 0.36628 | Regression loss: 0.33307 | Running loss: 0.98251\n",
      "Epoch: 1 | Iteration: 616 | Classification loss: 0.50934 | Regression loss: 0.40200 | Running loss: 0.98293\n",
      "Epoch: 1 | Iteration: 617 | Classification loss: 0.37156 | Regression loss: 0.64765 | Running loss: 0.98307\n",
      "Epoch: 1 | Iteration: 618 | Classification loss: 0.61155 | Regression loss: 0.69868 | Running loss: 0.98388\n",
      "Epoch: 1 | Iteration: 619 | Classification loss: 0.21384 | Regression loss: 0.35475 | Running loss: 0.98323\n",
      "Epoch: 1 | Iteration: 620 | Classification loss: 0.56681 | Regression loss: 0.93933 | Running loss: 0.98431\n",
      "Epoch: 1 | Iteration: 621 | Classification loss: 0.62456 | Regression loss: 0.71425 | Running loss: 0.98503\n",
      "Epoch: 1 | Iteration: 622 | Classification loss: 0.38670 | Regression loss: 0.50225 | Running loss: 0.98593\n",
      "Epoch: 1 | Iteration: 623 | Classification loss: 0.24769 | Regression loss: 0.34541 | Running loss: 0.98287\n",
      "Epoch: 1 | Iteration: 624 | Classification loss: 0.36819 | Regression loss: 0.37424 | Running loss: 0.98190\n",
      "Epoch: 1 | Iteration: 625 | Classification loss: 0.47897 | Regression loss: 0.47014 | Running loss: 0.98214\n",
      "Epoch: 1 | Iteration: 626 | Classification loss: 0.31007 | Regression loss: 0.36490 | Running loss: 0.98209\n",
      "Epoch: 1 | Iteration: 627 | Classification loss: 0.29181 | Regression loss: 0.29765 | Running loss: 0.98107\n",
      "Epoch: 1 | Iteration: 628 | Classification loss: 0.24680 | Regression loss: 0.65900 | Running loss: 0.98200\n",
      "Epoch: 1 | Iteration: 629 | Classification loss: 0.50047 | Regression loss: 0.72201 | Running loss: 0.98237\n",
      "Epoch: 1 | Iteration: 630 | Classification loss: 0.27215 | Regression loss: 0.29565 | Running loss: 0.98093\n",
      "Epoch: 1 | Iteration: 631 | Classification loss: 0.42943 | Regression loss: 0.64205 | Running loss: 0.98061\n",
      "Epoch: 1 | Iteration: 632 | Classification loss: 0.31526 | Regression loss: 0.57347 | Running loss: 0.98066\n",
      "Epoch: 1 | Iteration: 633 | Classification loss: 0.28131 | Regression loss: 0.48603 | Running loss: 0.98100\n",
      "Epoch: 1 | Iteration: 634 | Classification loss: 0.88577 | Regression loss: 1.05960 | Running loss: 0.98364\n",
      "Epoch: 1 | Iteration: 635 | Classification loss: 0.31570 | Regression loss: 0.41677 | Running loss: 0.98332\n",
      "Epoch: 1 | Iteration: 636 | Classification loss: 0.31307 | Regression loss: 0.49070 | Running loss: 0.98285\n",
      "Epoch: 1 | Iteration: 637 | Classification loss: 0.44348 | Regression loss: 0.71494 | Running loss: 0.98306\n",
      "Epoch: 1 | Iteration: 638 | Classification loss: 0.45878 | Regression loss: 0.62973 | Running loss: 0.98366\n",
      "Epoch: 1 | Iteration: 639 | Classification loss: 0.26540 | Regression loss: 0.45326 | Running loss: 0.98297\n",
      "Epoch: 1 | Iteration: 640 | Classification loss: 0.41088 | Regression loss: 0.54502 | Running loss: 0.98351\n",
      "Epoch: 1 | Iteration: 641 | Classification loss: 0.51935 | Regression loss: 0.53430 | Running loss: 0.98417\n",
      "Epoch: 1 | Iteration: 642 | Classification loss: 0.46575 | Regression loss: 0.40205 | Running loss: 0.98456\n",
      "Epoch: 1 | Iteration: 643 | Classification loss: 0.18975 | Regression loss: 0.36445 | Running loss: 0.98379\n",
      "Epoch: 1 | Iteration: 644 | Classification loss: 0.36148 | Regression loss: 0.65530 | Running loss: 0.98341\n",
      "Epoch: 1 | Iteration: 645 | Classification loss: 0.56662 | Regression loss: 0.42762 | Running loss: 0.98351\n",
      "Epoch: 1 | Iteration: 646 | Classification loss: 0.49536 | Regression loss: 0.77870 | Running loss: 0.98413\n",
      "Epoch: 1 | Iteration: 647 | Classification loss: 0.36052 | Regression loss: 0.58014 | Running loss: 0.98500\n",
      "Epoch: 1 | Iteration: 648 | Classification loss: 0.50687 | Regression loss: 0.27321 | Running loss: 0.98433\n",
      "Epoch: 1 | Iteration: 649 | Classification loss: 0.46705 | Regression loss: 0.57143 | Running loss: 0.98446\n",
      "Epoch: 1 | Iteration: 650 | Classification loss: 0.45506 | Regression loss: 0.48853 | Running loss: 0.98375\n",
      "Epoch: 1 | Iteration: 651 | Classification loss: 0.27343 | Regression loss: 0.57442 | Running loss: 0.98395\n",
      "Epoch: 1 | Iteration: 652 | Classification loss: 0.37614 | Regression loss: 0.59254 | Running loss: 0.98438\n",
      "Epoch: 1 | Iteration: 653 | Classification loss: 0.50593 | Regression loss: 0.53028 | Running loss: 0.98433\n",
      "Epoch: 1 | Iteration: 654 | Classification loss: 0.57599 | Regression loss: 0.55336 | Running loss: 0.98524\n",
      "Epoch: 1 | Iteration: 655 | Classification loss: 0.34124 | Regression loss: 0.66520 | Running loss: 0.98565\n",
      "Epoch: 1 | Iteration: 656 | Classification loss: 0.46205 | Regression loss: 0.72181 | Running loss: 0.98646\n",
      "Epoch: 1 | Iteration: 657 | Classification loss: 0.43865 | Regression loss: 0.43791 | Running loss: 0.98580\n",
      "Epoch: 1 | Iteration: 658 | Classification loss: 0.59221 | Regression loss: 0.72290 | Running loss: 0.98610\n",
      "Epoch: 1 | Iteration: 659 | Classification loss: 0.50349 | Regression loss: 0.56057 | Running loss: 0.98639\n",
      "Epoch: 1 | Iteration: 660 | Classification loss: 0.48338 | Regression loss: 0.58248 | Running loss: 0.98667\n",
      "Epoch: 1 | Iteration: 661 | Classification loss: 0.67507 | Regression loss: 0.74410 | Running loss: 0.98674\n",
      "Epoch: 1 | Iteration: 662 | Classification loss: 0.39325 | Regression loss: 0.54414 | Running loss: 0.98741\n",
      "Epoch: 1 | Iteration: 663 | Classification loss: 0.23140 | Regression loss: 0.48135 | Running loss: 0.98596\n",
      "Epoch: 1 | Iteration: 664 | Classification loss: 0.39932 | Regression loss: 0.55094 | Running loss: 0.98615\n",
      "Epoch: 1 | Iteration: 665 | Classification loss: 0.26040 | Regression loss: 0.63195 | Running loss: 0.98605\n",
      "Epoch: 1 | Iteration: 666 | Classification loss: 0.50711 | Regression loss: 0.72763 | Running loss: 0.98692\n",
      "Epoch: 1 | Iteration: 667 | Classification loss: 0.27870 | Regression loss: 0.52674 | Running loss: 0.98701\n",
      "Epoch: 1 | Iteration: 668 | Classification loss: 0.43737 | Regression loss: 0.52133 | Running loss: 0.98633\n",
      "Epoch: 1 | Iteration: 669 | Classification loss: 0.65919 | Regression loss: 1.01370 | Running loss: 0.98751\n",
      "Epoch: 1 | Iteration: 670 | Classification loss: 0.29735 | Regression loss: 0.60121 | Running loss: 0.98736\n",
      "Epoch: 1 | Iteration: 671 | Classification loss: 0.37545 | Regression loss: 0.55263 | Running loss: 0.98797\n",
      "Epoch: 1 | Iteration: 672 | Classification loss: 0.32633 | Regression loss: 0.49221 | Running loss: 0.98797\n",
      "Epoch: 1 | Iteration: 673 | Classification loss: 0.49782 | Regression loss: 0.57282 | Running loss: 0.98817\n",
      "Epoch: 1 | Iteration: 674 | Classification loss: 0.29748 | Regression loss: 0.40977 | Running loss: 0.98838\n",
      "Epoch: 1 | Iteration: 675 | Classification loss: 0.24634 | Regression loss: 0.39667 | Running loss: 0.98834\n",
      "Epoch: 1 | Iteration: 676 | Classification loss: 0.39195 | Regression loss: 0.43789 | Running loss: 0.98738\n",
      "Epoch: 1 | Iteration: 677 | Classification loss: 0.42390 | Regression loss: 0.34016 | Running loss: 0.98681\n",
      "Epoch: 1 | Iteration: 678 | Classification loss: 0.48997 | Regression loss: 0.46633 | Running loss: 0.98709\n",
      "Epoch: 1 | Iteration: 679 | Classification loss: 0.57958 | Regression loss: 0.71817 | Running loss: 0.98824\n",
      "Epoch: 1 | Iteration: 680 | Classification loss: 0.56464 | Regression loss: 0.63993 | Running loss: 0.98864\n",
      "Epoch: 1 | Iteration: 681 | Classification loss: 0.27887 | Regression loss: 0.38513 | Running loss: 0.98834\n",
      "Epoch: 1 | Iteration: 682 | Classification loss: 0.42748 | Regression loss: 0.73843 | Running loss: 0.98848\n",
      "Epoch: 1 | Iteration: 683 | Classification loss: 0.32232 | Regression loss: 0.54386 | Running loss: 0.98721\n",
      "Epoch: 1 | Iteration: 684 | Classification loss: 0.39742 | Regression loss: 0.63287 | Running loss: 0.98761\n",
      "Epoch: 1 | Iteration: 685 | Classification loss: 0.27437 | Regression loss: 0.29441 | Running loss: 0.98630\n",
      "Epoch: 1 | Iteration: 686 | Classification loss: 0.40156 | Regression loss: 0.22217 | Running loss: 0.98494\n",
      "Epoch: 1 | Iteration: 687 | Classification loss: 0.27310 | Regression loss: 0.62734 | Running loss: 0.98385\n",
      "Epoch: 1 | Iteration: 688 | Classification loss: 0.56273 | Regression loss: 0.71678 | Running loss: 0.98452\n",
      "Epoch: 1 | Iteration: 689 | Classification loss: 0.63215 | Regression loss: 1.02856 | Running loss: 0.98676\n",
      "Epoch: 1 | Iteration: 690 | Classification loss: 0.46380 | Regression loss: 0.42956 | Running loss: 0.98582\n",
      "Epoch: 1 | Iteration: 691 | Classification loss: 0.49976 | Regression loss: 0.49297 | Running loss: 0.98560\n",
      "Epoch: 1 | Iteration: 692 | Classification loss: 0.36221 | Regression loss: 0.41556 | Running loss: 0.98453\n",
      "Epoch: 1 | Iteration: 693 | Classification loss: 0.57231 | Regression loss: 0.77976 | Running loss: 0.98564\n",
      "Epoch: 1 | Iteration: 694 | Classification loss: 0.45644 | Regression loss: 0.61434 | Running loss: 0.98609\n",
      "Epoch: 1 | Iteration: 695 | Classification loss: 0.50749 | Regression loss: 0.52273 | Running loss: 0.98502\n",
      "Epoch: 1 | Iteration: 696 | Classification loss: 0.36296 | Regression loss: 0.48548 | Running loss: 0.98453\n",
      "Epoch: 1 | Iteration: 697 | Classification loss: 0.23256 | Regression loss: 0.32551 | Running loss: 0.98301\n",
      "Epoch: 1 | Iteration: 698 | Classification loss: 0.38342 | Regression loss: 0.77402 | Running loss: 0.98288\n",
      "Epoch: 1 | Iteration: 699 | Classification loss: 0.38842 | Regression loss: 0.62469 | Running loss: 0.98270\n",
      "Epoch: 1 | Iteration: 700 | Classification loss: 0.60311 | Regression loss: 0.58975 | Running loss: 0.98259\n",
      "Epoch: 1 | Iteration: 701 | Classification loss: 0.72026 | Regression loss: 0.63354 | Running loss: 0.98336\n",
      "Epoch: 1 | Iteration: 702 | Classification loss: 0.50494 | Regression loss: 0.71309 | Running loss: 0.98286\n",
      "Epoch: 1 | Iteration: 703 | Classification loss: 0.42946 | Regression loss: 0.54296 | Running loss: 0.98280\n",
      "Epoch: 1 | Iteration: 704 | Classification loss: 0.37881 | Regression loss: 0.73348 | Running loss: 0.98242\n",
      "Epoch: 1 | Iteration: 705 | Classification loss: 0.60095 | Regression loss: 1.32357 | Running loss: 0.98374\n",
      "Epoch: 1 | Iteration: 706 | Classification loss: 0.39480 | Regression loss: 0.56665 | Running loss: 0.98368\n",
      "Epoch: 1 | Iteration: 707 | Classification loss: 0.41713 | Regression loss: 0.58378 | Running loss: 0.98407\n",
      "Epoch: 1 | Iteration: 708 | Classification loss: 0.29697 | Regression loss: 0.51956 | Running loss: 0.98341\n",
      "Epoch: 1 | Iteration: 709 | Classification loss: 0.40288 | Regression loss: 0.75730 | Running loss: 0.98393\n",
      "Epoch: 1 | Iteration: 710 | Classification loss: 0.57072 | Regression loss: 0.81778 | Running loss: 0.98538\n",
      "Epoch: 1 | Iteration: 711 | Classification loss: 0.26935 | Regression loss: 0.57510 | Running loss: 0.98462\n",
      "Epoch: 1 | Iteration: 712 | Classification loss: 0.52159 | Regression loss: 0.84082 | Running loss: 0.98616\n",
      "Epoch: 1 | Iteration: 713 | Classification loss: 0.37961 | Regression loss: 0.54428 | Running loss: 0.98604\n",
      "Epoch: 1 | Iteration: 714 | Classification loss: 0.32748 | Regression loss: 0.43564 | Running loss: 0.98487\n",
      "Epoch: 1 | Iteration: 715 | Classification loss: 0.30725 | Regression loss: 0.36762 | Running loss: 0.98377\n",
      "Epoch: 1 | Iteration: 716 | Classification loss: 0.38363 | Regression loss: 0.58582 | Running loss: 0.98409\n",
      "Epoch: 1 | Iteration: 717 | Classification loss: 0.28944 | Regression loss: 0.38114 | Running loss: 0.98411\n",
      "Epoch: 1 | Iteration: 718 | Classification loss: 0.40082 | Regression loss: 0.38080 | Running loss: 0.98375\n",
      "Epoch: 1 | Iteration: 719 | Classification loss: 0.55359 | Regression loss: 0.74321 | Running loss: 0.98458\n",
      "Epoch: 1 | Iteration: 720 | Classification loss: 0.44369 | Regression loss: 0.41671 | Running loss: 0.98466\n",
      "Epoch: 1 | Iteration: 721 | Classification loss: 0.33186 | Regression loss: 0.57795 | Running loss: 0.98415\n",
      "Epoch: 1 | Iteration: 722 | Classification loss: 0.33252 | Regression loss: 0.56736 | Running loss: 0.98362\n",
      "Epoch: 1 | Iteration: 723 | Classification loss: 0.53485 | Regression loss: 0.73304 | Running loss: 0.98480\n",
      "Epoch: 1 | Iteration: 724 | Classification loss: 0.44774 | Regression loss: 0.97027 | Running loss: 0.98552\n",
      "Epoch: 1 | Iteration: 725 | Classification loss: 0.30105 | Regression loss: 0.44463 | Running loss: 0.98602\n",
      "Epoch: 1 | Iteration: 726 | Classification loss: 0.19558 | Regression loss: 0.42146 | Running loss: 0.98525\n",
      "Epoch: 1 | Iteration: 727 | Classification loss: 0.48771 | Regression loss: 0.63611 | Running loss: 0.98650\n",
      "Epoch: 1 | Iteration: 728 | Classification loss: 0.17895 | Regression loss: 0.36635 | Running loss: 0.98576\n",
      "Epoch: 1 | Iteration: 729 | Classification loss: 0.40988 | Regression loss: 0.22969 | Running loss: 0.98548\n",
      "Epoch: 1 | Iteration: 730 | Classification loss: 0.46644 | Regression loss: 0.56196 | Running loss: 0.98519\n",
      "Epoch: 1 | Iteration: 731 | Classification loss: 0.38903 | Regression loss: 0.57719 | Running loss: 0.98591\n",
      "Epoch: 1 | Iteration: 732 | Classification loss: 0.35878 | Regression loss: 0.44772 | Running loss: 0.98601\n",
      "Epoch: 1 | Iteration: 733 | Classification loss: 0.51516 | Regression loss: 0.65206 | Running loss: 0.98665\n",
      "Epoch: 1 | Iteration: 734 | Classification loss: 0.41160 | Regression loss: 0.59814 | Running loss: 0.98659\n",
      "Epoch: 1 | Iteration: 735 | Classification loss: 0.59855 | Regression loss: 0.38422 | Running loss: 0.98715\n",
      "Epoch: 1 | Iteration: 736 | Classification loss: 0.39925 | Regression loss: 0.33280 | Running loss: 0.98674\n",
      "Epoch: 1 | Iteration: 737 | Classification loss: 0.23631 | Regression loss: 0.42584 | Running loss: 0.98610\n",
      "Epoch: 1 | Iteration: 738 | Classification loss: 0.31902 | Regression loss: 0.44728 | Running loss: 0.98571\n",
      "Epoch: 1 | Iteration: 739 | Classification loss: 0.36444 | Regression loss: 0.38423 | Running loss: 0.98486\n",
      "Epoch: 1 | Iteration: 740 | Classification loss: 0.56483 | Regression loss: 0.70215 | Running loss: 0.98538\n",
      "Epoch: 1 | Iteration: 741 | Classification loss: 0.53913 | Regression loss: 0.80959 | Running loss: 0.98490\n",
      "Epoch: 1 | Iteration: 742 | Classification loss: 0.25919 | Regression loss: 0.47164 | Running loss: 0.98442\n",
      "Epoch: 1 | Iteration: 743 | Classification loss: 0.43238 | Regression loss: 0.50808 | Running loss: 0.98362\n",
      "Epoch: 1 | Iteration: 744 | Classification loss: 0.71023 | Regression loss: 0.63101 | Running loss: 0.98370\n",
      "Epoch: 1 | Iteration: 745 | Classification loss: 0.61437 | Regression loss: 0.50256 | Running loss: 0.98428\n",
      "Epoch: 1 | Iteration: 746 | Classification loss: 0.40819 | Regression loss: 0.56514 | Running loss: 0.98399\n",
      "Epoch: 1 | Iteration: 747 | Classification loss: 0.43042 | Regression loss: 0.37672 | Running loss: 0.98374\n",
      "Epoch: 1 | Iteration: 748 | Classification loss: 0.33301 | Regression loss: 0.55016 | Running loss: 0.98411\n",
      "Epoch: 1 | Iteration: 749 | Classification loss: 0.33362 | Regression loss: 0.19357 | Running loss: 0.98317\n",
      "Epoch: 1 | Iteration: 750 | Classification loss: 0.72307 | Regression loss: 1.04233 | Running loss: 0.98507\n",
      "Epoch: 1 | Iteration: 751 | Classification loss: 0.40043 | Regression loss: 0.63619 | Running loss: 0.98574\n",
      "Epoch: 1 | Iteration: 752 | Classification loss: 0.24485 | Regression loss: 0.44988 | Running loss: 0.98538\n",
      "Epoch: 1 | Iteration: 753 | Classification loss: 0.60566 | Regression loss: 0.66888 | Running loss: 0.98526\n",
      "Epoch: 1 | Iteration: 754 | Classification loss: 0.34218 | Regression loss: 0.33848 | Running loss: 0.98464\n",
      "Epoch: 1 | Iteration: 755 | Classification loss: 0.44096 | Regression loss: 0.55279 | Running loss: 0.98445\n",
      "Epoch: 1 | Iteration: 756 | Classification loss: 0.37359 | Regression loss: 0.22294 | Running loss: 0.98383\n",
      "Epoch: 1 | Iteration: 757 | Classification loss: 0.32905 | Regression loss: 0.48293 | Running loss: 0.98379\n",
      "Epoch: 1 | Iteration: 758 | Classification loss: 1.00687 | Regression loss: 0.43624 | Running loss: 0.98439\n",
      "Epoch: 1 | Iteration: 759 | Classification loss: 0.30132 | Regression loss: 0.52001 | Running loss: 0.98374\n",
      "Epoch: 1 | Iteration: 760 | Classification loss: 0.29720 | Regression loss: 0.29155 | Running loss: 0.98332\n",
      "Epoch: 1 | Iteration: 761 | Classification loss: 0.46986 | Regression loss: 0.58853 | Running loss: 0.98282\n",
      "Epoch: 1 | Iteration: 762 | Classification loss: 0.26990 | Regression loss: 0.42620 | Running loss: 0.98220\n",
      "Epoch: 1 | Iteration: 763 | Classification loss: 0.53564 | Regression loss: 0.84739 | Running loss: 0.98318\n",
      "Epoch: 1 | Iteration: 764 | Classification loss: 0.40559 | Regression loss: 0.40981 | Running loss: 0.98319\n",
      "Epoch: 1 | Iteration: 765 | Classification loss: 0.59877 | Regression loss: 0.86460 | Running loss: 0.98504\n",
      "Epoch: 1 | Iteration: 766 | Classification loss: 0.49664 | Regression loss: 0.60066 | Running loss: 0.98577\n",
      "Epoch: 1 | Iteration: 767 | Classification loss: 0.49869 | Regression loss: 0.73445 | Running loss: 0.98555\n",
      "Epoch: 1 | Iteration: 768 | Classification loss: 0.20138 | Regression loss: 0.42629 | Running loss: 0.98506\n",
      "Epoch: 1 | Iteration: 769 | Classification loss: 0.31108 | Regression loss: 0.24728 | Running loss: 0.98376\n",
      "Epoch: 1 | Iteration: 770 | Classification loss: 0.54799 | Regression loss: 0.26226 | Running loss: 0.98249\n",
      "Epoch: 1 | Iteration: 771 | Classification loss: 0.72368 | Regression loss: 0.59083 | Running loss: 0.98268\n",
      "Epoch: 1 | Iteration: 772 | Classification loss: 0.67897 | Regression loss: 0.49595 | Running loss: 0.98260\n",
      "Epoch: 1 | Iteration: 773 | Classification loss: 0.22545 | Regression loss: 0.51639 | Running loss: 0.98237\n",
      "Epoch: 1 | Iteration: 774 | Classification loss: 0.36263 | Regression loss: 0.27461 | Running loss: 0.98195\n",
      "Epoch: 1 | Iteration: 775 | Classification loss: 0.35935 | Regression loss: 0.29531 | Running loss: 0.98114\n",
      "Epoch: 1 | Iteration: 776 | Classification loss: 0.59268 | Regression loss: 0.83278 | Running loss: 0.98160\n",
      "Epoch: 1 | Iteration: 777 | Classification loss: 0.23486 | Regression loss: 0.52247 | Running loss: 0.98095\n",
      "Epoch: 1 | Iteration: 778 | Classification loss: 0.24132 | Regression loss: 0.53087 | Running loss: 0.98102\n",
      "Epoch: 1 | Iteration: 779 | Classification loss: 0.73712 | Regression loss: 0.88601 | Running loss: 0.98209\n",
      "Epoch: 1 | Iteration: 780 | Classification loss: 0.44855 | Regression loss: 0.80015 | Running loss: 0.98210\n",
      "Epoch: 1 | Iteration: 781 | Classification loss: 0.26838 | Regression loss: 0.12273 | Running loss: 0.98187\n",
      "Epoch: 1 | Iteration: 782 | Classification loss: 0.64329 | Regression loss: 0.61542 | Running loss: 0.98202\n",
      "Epoch: 1 | Iteration: 783 | Classification loss: 0.24096 | Regression loss: 0.49808 | Running loss: 0.98190\n",
      "Epoch: 1 | Iteration: 784 | Classification loss: 0.42545 | Regression loss: 0.33231 | Running loss: 0.98055\n",
      "Epoch: 1 | Iteration: 785 | Classification loss: 0.43343 | Regression loss: 0.57425 | Running loss: 0.98082\n",
      "Epoch: 1 | Iteration: 786 | Classification loss: 0.57347 | Regression loss: 0.43130 | Running loss: 0.98057\n",
      "Epoch: 1 | Iteration: 787 | Classification loss: 0.36316 | Regression loss: 0.53771 | Running loss: 0.98083\n",
      "Epoch: 1 | Iteration: 788 | Classification loss: 0.22181 | Regression loss: 0.44251 | Running loss: 0.97918\n",
      "Epoch: 1 | Iteration: 789 | Classification loss: 0.44244 | Regression loss: 0.41906 | Running loss: 0.97863\n",
      "Epoch: 1 | Iteration: 790 | Classification loss: 0.51403 | Regression loss: 0.61870 | Running loss: 0.97872\n",
      "Epoch: 1 | Iteration: 791 | Classification loss: 0.38938 | Regression loss: 0.53757 | Running loss: 0.97880\n",
      "Epoch: 1 | Iteration: 792 | Classification loss: 0.40972 | Regression loss: 0.36679 | Running loss: 0.97851\n",
      "Epoch: 1 | Iteration: 793 | Classification loss: 0.21230 | Regression loss: 0.43647 | Running loss: 0.97773\n",
      "Epoch: 1 | Iteration: 794 | Classification loss: 0.37846 | Regression loss: 0.31194 | Running loss: 0.97744\n",
      "Epoch: 1 | Iteration: 795 | Classification loss: 0.47686 | Regression loss: 0.58879 | Running loss: 0.97685\n",
      "Epoch: 1 | Iteration: 796 | Classification loss: 0.45174 | Regression loss: 0.45887 | Running loss: 0.97718\n",
      "Epoch: 1 | Iteration: 797 | Classification loss: 0.49535 | Regression loss: 0.79707 | Running loss: 0.97780\n",
      "Epoch: 1 | Iteration: 798 | Classification loss: 0.45508 | Regression loss: 0.56921 | Running loss: 0.97775\n",
      "Epoch: 1 | Iteration: 799 | Classification loss: 0.43090 | Regression loss: 0.34071 | Running loss: 0.97765\n",
      "Epoch: 1 | Iteration: 800 | Classification loss: 0.41256 | Regression loss: 0.60187 | Running loss: 0.97767\n",
      "Epoch: 1 | Iteration: 801 | Classification loss: 0.40567 | Regression loss: 0.38584 | Running loss: 0.97683\n",
      "Epoch: 1 | Iteration: 802 | Classification loss: 0.45534 | Regression loss: 0.61548 | Running loss: 0.97693\n",
      "Epoch: 1 | Iteration: 803 | Classification loss: 0.37748 | Regression loss: 0.60755 | Running loss: 0.97616\n",
      "Epoch: 1 | Iteration: 804 | Classification loss: 0.37297 | Regression loss: 0.40379 | Running loss: 0.97624\n",
      "Epoch: 1 | Iteration: 805 | Classification loss: 0.34749 | Regression loss: 0.44662 | Running loss: 0.97601\n",
      "Epoch: 1 | Iteration: 806 | Classification loss: 0.30846 | Regression loss: 0.50676 | Running loss: 0.97502\n",
      "Epoch: 1 | Iteration: 807 | Classification loss: 0.32464 | Regression loss: 0.49575 | Running loss: 0.97485\n",
      "Epoch: 1 | Iteration: 808 | Classification loss: 0.46425 | Regression loss: 0.55125 | Running loss: 0.97330\n",
      "Epoch: 1 | Iteration: 809 | Classification loss: 0.38837 | Regression loss: 0.81266 | Running loss: 0.97406\n",
      "Epoch: 1 | Iteration: 810 | Classification loss: 0.32213 | Regression loss: 0.32288 | Running loss: 0.97296\n",
      "Epoch: 1 | Iteration: 811 | Classification loss: 0.73775 | Regression loss: 0.82736 | Running loss: 0.97443\n",
      "Epoch: 1 | Iteration: 812 | Classification loss: 0.43992 | Regression loss: 0.39664 | Running loss: 0.97481\n",
      "Epoch: 1 | Iteration: 813 | Classification loss: 0.32796 | Regression loss: 0.59128 | Running loss: 0.97519\n",
      "Epoch: 1 | Iteration: 814 | Classification loss: 0.36859 | Regression loss: 0.60085 | Running loss: 0.97534\n",
      "Epoch: 1 | Iteration: 815 | Classification loss: 0.38744 | Regression loss: 0.44135 | Running loss: 0.97470\n",
      "Epoch: 1 | Iteration: 816 | Classification loss: 0.40649 | Regression loss: 0.75977 | Running loss: 0.97545\n",
      "Epoch: 1 | Iteration: 817 | Classification loss: 0.35877 | Regression loss: 0.51114 | Running loss: 0.97399\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.65s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 2 | Iteration: 0 | Classification loss: 0.44115 | Regression loss: 0.40074 | Running loss: 0.97420\n",
      "Epoch: 2 | Iteration: 1 | Classification loss: 0.51057 | Regression loss: 0.47306 | Running loss: 0.97373\n",
      "Epoch: 2 | Iteration: 2 | Classification loss: 0.36160 | Regression loss: 0.38999 | Running loss: 0.97422\n",
      "Epoch: 2 | Iteration: 3 | Classification loss: 0.36905 | Regression loss: 0.47600 | Running loss: 0.97338\n",
      "Epoch: 2 | Iteration: 4 | Classification loss: 0.30815 | Regression loss: 0.32743 | Running loss: 0.97279\n",
      "Epoch: 2 | Iteration: 5 | Classification loss: 0.52176 | Regression loss: 0.25319 | Running loss: 0.97225\n",
      "Epoch: 2 | Iteration: 6 | Classification loss: 0.40672 | Regression loss: 0.52392 | Running loss: 0.97260\n",
      "Epoch: 2 | Iteration: 7 | Classification loss: 0.39671 | Regression loss: 0.43466 | Running loss: 0.97208\n",
      "Epoch: 2 | Iteration: 8 | Classification loss: 0.59538 | Regression loss: 0.97947 | Running loss: 0.97323\n",
      "Epoch: 2 | Iteration: 9 | Classification loss: 0.32809 | Regression loss: 0.41585 | Running loss: 0.97345\n",
      "Epoch: 2 | Iteration: 10 | Classification loss: 0.26735 | Regression loss: 0.39447 | Running loss: 0.97157\n",
      "Epoch: 2 | Iteration: 11 | Classification loss: 0.52233 | Regression loss: 0.74838 | Running loss: 0.97274\n",
      "Epoch: 2 | Iteration: 12 | Classification loss: 0.41223 | Regression loss: 0.65893 | Running loss: 0.97395\n",
      "Epoch: 2 | Iteration: 13 | Classification loss: 0.45514 | Regression loss: 0.61551 | Running loss: 0.97411\n",
      "Epoch: 2 | Iteration: 14 | Classification loss: 0.46408 | Regression loss: 0.47211 | Running loss: 0.97452\n",
      "Epoch: 2 | Iteration: 15 | Classification loss: 0.96665 | Regression loss: 0.71982 | Running loss: 0.97656\n",
      "Epoch: 2 | Iteration: 16 | Classification loss: 0.51164 | Regression loss: 0.70310 | Running loss: 0.97680\n",
      "Epoch: 2 | Iteration: 17 | Classification loss: 0.25163 | Regression loss: 0.55949 | Running loss: 0.97638\n",
      "Epoch: 2 | Iteration: 18 | Classification loss: 0.28230 | Regression loss: 0.40535 | Running loss: 0.97564\n",
      "Epoch: 2 | Iteration: 19 | Classification loss: 0.39680 | Regression loss: 0.57271 | Running loss: 0.97609\n",
      "Epoch: 2 | Iteration: 20 | Classification loss: 0.20479 | Regression loss: 0.45599 | Running loss: 0.97551\n",
      "Epoch: 2 | Iteration: 21 | Classification loss: 0.15671 | Regression loss: 0.35497 | Running loss: 0.97474\n",
      "Epoch: 2 | Iteration: 22 | Classification loss: 0.22842 | Regression loss: 0.39098 | Running loss: 0.97449\n",
      "Epoch: 2 | Iteration: 23 | Classification loss: 0.28345 | Regression loss: 0.37270 | Running loss: 0.97412\n",
      "Epoch: 2 | Iteration: 24 | Classification loss: 0.17966 | Regression loss: 0.52628 | Running loss: 0.97353\n",
      "Epoch: 2 | Iteration: 25 | Classification loss: 0.31143 | Regression loss: 0.30246 | Running loss: 0.97242\n",
      "Epoch: 2 | Iteration: 26 | Classification loss: 0.33335 | Regression loss: 0.19522 | Running loss: 0.97202\n",
      "Epoch: 2 | Iteration: 27 | Classification loss: 0.59620 | Regression loss: 0.71150 | Running loss: 0.97247\n",
      "Epoch: 2 | Iteration: 28 | Classification loss: 0.51045 | Regression loss: 0.78013 | Running loss: 0.97320\n",
      "Epoch: 2 | Iteration: 29 | Classification loss: 0.38356 | Regression loss: 0.47711 | Running loss: 0.97360\n",
      "Epoch: 2 | Iteration: 30 | Classification loss: 0.54250 | Regression loss: 0.49872 | Running loss: 0.97419\n",
      "Epoch: 2 | Iteration: 31 | Classification loss: 0.33244 | Regression loss: 0.30252 | Running loss: 0.97335\n",
      "Epoch: 2 | Iteration: 32 | Classification loss: 0.34701 | Regression loss: 0.88508 | Running loss: 0.97489\n",
      "Epoch: 2 | Iteration: 33 | Classification loss: 0.50424 | Regression loss: 0.83272 | Running loss: 0.97489\n",
      "Epoch: 2 | Iteration: 34 | Classification loss: 0.51531 | Regression loss: 0.42155 | Running loss: 0.97512\n",
      "Epoch: 2 | Iteration: 35 | Classification loss: 0.25974 | Regression loss: 0.30326 | Running loss: 0.97472\n",
      "Epoch: 2 | Iteration: 36 | Classification loss: 0.53639 | Regression loss: 0.64174 | Running loss: 0.97536\n",
      "Epoch: 2 | Iteration: 37 | Classification loss: 0.52963 | Regression loss: 0.65588 | Running loss: 0.97652\n",
      "Epoch: 2 | Iteration: 38 | Classification loss: 0.14585 | Regression loss: 0.31656 | Running loss: 0.97562\n",
      "Epoch: 2 | Iteration: 39 | Classification loss: 0.68685 | Regression loss: 0.23609 | Running loss: 0.97540\n",
      "Epoch: 2 | Iteration: 40 | Classification loss: 0.27620 | Regression loss: 0.63173 | Running loss: 0.97424\n",
      "Epoch: 2 | Iteration: 41 | Classification loss: 0.36122 | Regression loss: 0.55090 | Running loss: 0.97426\n",
      "Epoch: 2 | Iteration: 42 | Classification loss: 0.39673 | Regression loss: 0.47402 | Running loss: 0.97295\n",
      "Epoch: 2 | Iteration: 43 | Classification loss: 0.42955 | Regression loss: 0.40737 | Running loss: 0.97247\n",
      "Epoch: 2 | Iteration: 44 | Classification loss: 0.29126 | Regression loss: 0.25775 | Running loss: 0.97131\n",
      "Epoch: 2 | Iteration: 45 | Classification loss: 0.40961 | Regression loss: 0.69057 | Running loss: 0.97196\n",
      "Epoch: 2 | Iteration: 46 | Classification loss: 0.31635 | Regression loss: 0.41452 | Running loss: 0.97106\n",
      "Epoch: 2 | Iteration: 47 | Classification loss: 0.28954 | Regression loss: 0.52829 | Running loss: 0.97125\n",
      "Epoch: 2 | Iteration: 48 | Classification loss: 0.27953 | Regression loss: 0.58456 | Running loss: 0.97112\n",
      "Epoch: 2 | Iteration: 49 | Classification loss: 0.32713 | Regression loss: 0.56990 | Running loss: 0.97196\n",
      "Epoch: 2 | Iteration: 50 | Classification loss: 0.48367 | Regression loss: 0.47796 | Running loss: 0.97287\n",
      "Epoch: 2 | Iteration: 51 | Classification loss: 0.34107 | Regression loss: 0.47833 | Running loss: 0.97260\n",
      "Epoch: 2 | Iteration: 52 | Classification loss: 0.30506 | Regression loss: 0.51907 | Running loss: 0.97264\n",
      "Epoch: 2 | Iteration: 53 | Classification loss: 0.42871 | Regression loss: 0.38108 | Running loss: 0.97214\n",
      "Epoch: 2 | Iteration: 54 | Classification loss: 0.36775 | Regression loss: 0.73093 | Running loss: 0.97311\n",
      "Epoch: 2 | Iteration: 55 | Classification loss: 0.24303 | Regression loss: 0.66352 | Running loss: 0.97276\n",
      "Epoch: 2 | Iteration: 56 | Classification loss: 0.48973 | Regression loss: 0.78310 | Running loss: 0.97347\n",
      "Epoch: 2 | Iteration: 57 | Classification loss: 0.31686 | Regression loss: 0.33450 | Running loss: 0.97287\n",
      "Epoch: 2 | Iteration: 58 | Classification loss: 0.40541 | Regression loss: 0.64756 | Running loss: 0.97426\n",
      "Epoch: 2 | Iteration: 59 | Classification loss: 0.27550 | Regression loss: 0.28916 | Running loss: 0.97297\n",
      "Epoch: 2 | Iteration: 60 | Classification loss: 0.42727 | Regression loss: 0.40737 | Running loss: 0.97261\n",
      "Epoch: 2 | Iteration: 61 | Classification loss: 0.56942 | Regression loss: 0.51122 | Running loss: 0.97313\n",
      "Epoch: 2 | Iteration: 62 | Classification loss: 0.48823 | Regression loss: 0.33163 | Running loss: 0.97171\n",
      "Epoch: 2 | Iteration: 63 | Classification loss: 0.28253 | Regression loss: 0.34229 | Running loss: 0.97094\n",
      "Epoch: 2 | Iteration: 64 | Classification loss: 0.57497 | Regression loss: 0.56454 | Running loss: 0.97109\n",
      "Epoch: 2 | Iteration: 65 | Classification loss: 0.53779 | Regression loss: 0.67237 | Running loss: 0.97184\n",
      "Epoch: 2 | Iteration: 66 | Classification loss: 0.64277 | Regression loss: 0.55715 | Running loss: 0.97194\n",
      "Epoch: 2 | Iteration: 67 | Classification loss: 0.39373 | Regression loss: 0.33646 | Running loss: 0.97171\n",
      "Epoch: 2 | Iteration: 68 | Classification loss: 0.34368 | Regression loss: 0.68875 | Running loss: 0.97216\n",
      "Epoch: 2 | Iteration: 69 | Classification loss: 0.37251 | Regression loss: 0.25592 | Running loss: 0.97150\n",
      "Epoch: 2 | Iteration: 70 | Classification loss: 0.21815 | Regression loss: 0.46568 | Running loss: 0.96997\n",
      "Epoch: 2 | Iteration: 71 | Classification loss: 0.54170 | Regression loss: 0.60573 | Running loss: 0.97008\n",
      "Epoch: 2 | Iteration: 72 | Classification loss: 0.42480 | Regression loss: 0.61990 | Running loss: 0.97017\n",
      "Epoch: 2 | Iteration: 73 | Classification loss: 0.30283 | Regression loss: 0.46352 | Running loss: 0.96940\n",
      "Epoch: 2 | Iteration: 74 | Classification loss: 0.30569 | Regression loss: 0.36135 | Running loss: 0.96862\n",
      "Epoch: 2 | Iteration: 75 | Classification loss: 0.52461 | Regression loss: 0.51028 | Running loss: 0.96896\n",
      "Epoch: 2 | Iteration: 76 | Classification loss: 0.38828 | Regression loss: 0.59523 | Running loss: 0.96874\n",
      "Epoch: 2 | Iteration: 77 | Classification loss: 0.46568 | Regression loss: 0.55693 | Running loss: 0.96862\n",
      "Epoch: 2 | Iteration: 78 | Classification loss: 0.33276 | Regression loss: 0.38345 | Running loss: 0.96854\n",
      "Epoch: 2 | Iteration: 79 | Classification loss: 0.36995 | Regression loss: 0.73440 | Running loss: 0.96874\n",
      "Epoch: 2 | Iteration: 80 | Classification loss: 0.28315 | Regression loss: 0.20904 | Running loss: 0.96809\n",
      "Epoch: 2 | Iteration: 81 | Classification loss: 0.59692 | Regression loss: 0.64385 | Running loss: 0.96862\n",
      "Epoch: 2 | Iteration: 82 | Classification loss: 0.45474 | Regression loss: 0.60260 | Running loss: 0.96928\n",
      "Epoch: 2 | Iteration: 83 | Classification loss: 0.34635 | Regression loss: 0.59028 | Running loss: 0.96904\n",
      "Epoch: 2 | Iteration: 84 | Classification loss: 0.43468 | Regression loss: 0.68265 | Running loss: 0.96938\n",
      "Epoch: 2 | Iteration: 85 | Classification loss: 0.46989 | Regression loss: 0.37739 | Running loss: 0.96790\n",
      "Epoch: 2 | Iteration: 86 | Classification loss: 0.37391 | Regression loss: 0.41783 | Running loss: 0.96778\n",
      "Epoch: 2 | Iteration: 87 | Classification loss: 0.26005 | Regression loss: 0.41459 | Running loss: 0.96662\n",
      "Epoch: 2 | Iteration: 88 | Classification loss: 0.60390 | Regression loss: 0.96213 | Running loss: 0.96677\n",
      "Epoch: 2 | Iteration: 89 | Classification loss: 0.36945 | Regression loss: 0.48782 | Running loss: 0.96729\n",
      "Epoch: 2 | Iteration: 90 | Classification loss: 0.40491 | Regression loss: 0.41627 | Running loss: 0.96740\n",
      "Epoch: 2 | Iteration: 91 | Classification loss: 0.33071 | Regression loss: 0.49930 | Running loss: 0.96680\n",
      "Epoch: 2 | Iteration: 92 | Classification loss: 0.25264 | Regression loss: 0.33018 | Running loss: 0.96583\n",
      "Epoch: 2 | Iteration: 93 | Classification loss: 0.61144 | Regression loss: 0.84769 | Running loss: 0.96681\n",
      "Epoch: 2 | Iteration: 94 | Classification loss: 0.73772 | Regression loss: 0.86702 | Running loss: 0.96808\n",
      "Epoch: 2 | Iteration: 95 | Classification loss: 0.25171 | Regression loss: 0.31425 | Running loss: 0.96784\n",
      "Epoch: 2 | Iteration: 96 | Classification loss: 0.36827 | Regression loss: 0.41937 | Running loss: 0.96675\n",
      "Epoch: 2 | Iteration: 97 | Classification loss: 0.50570 | Regression loss: 0.68928 | Running loss: 0.96642\n",
      "Epoch: 2 | Iteration: 98 | Classification loss: 0.38060 | Regression loss: 0.54980 | Running loss: 0.96698\n",
      "Epoch: 2 | Iteration: 99 | Classification loss: 0.46958 | Regression loss: 0.70524 | Running loss: 0.96761\n",
      "Epoch: 2 | Iteration: 100 | Classification loss: 0.39439 | Regression loss: 0.48327 | Running loss: 0.96715\n",
      "Epoch: 2 | Iteration: 101 | Classification loss: 0.40722 | Regression loss: 0.24494 | Running loss: 0.96658\n",
      "Epoch: 2 | Iteration: 102 | Classification loss: 0.40415 | Regression loss: 0.43371 | Running loss: 0.96617\n",
      "Epoch: 2 | Iteration: 103 | Classification loss: 0.36037 | Regression loss: 0.48790 | Running loss: 0.96577\n",
      "Epoch: 2 | Iteration: 104 | Classification loss: 0.17485 | Regression loss: 0.41989 | Running loss: 0.96461\n",
      "Epoch: 2 | Iteration: 105 | Classification loss: 0.41111 | Regression loss: 0.62267 | Running loss: 0.96405\n",
      "Epoch: 2 | Iteration: 106 | Classification loss: 0.72681 | Regression loss: 0.59988 | Running loss: 0.96478\n",
      "Epoch: 2 | Iteration: 107 | Classification loss: 0.28267 | Regression loss: 0.29778 | Running loss: 0.96485\n",
      "Epoch: 2 | Iteration: 108 | Classification loss: 0.26417 | Regression loss: 0.53469 | Running loss: 0.96417\n",
      "Epoch: 2 | Iteration: 109 | Classification loss: 0.30199 | Regression loss: 0.52388 | Running loss: 0.96353\n",
      "Epoch: 2 | Iteration: 110 | Classification loss: 0.42658 | Regression loss: 0.61723 | Running loss: 0.96275\n",
      "Epoch: 2 | Iteration: 111 | Classification loss: 0.39161 | Regression loss: 0.48231 | Running loss: 0.96319\n",
      "Epoch: 2 | Iteration: 112 | Classification loss: 0.38770 | Regression loss: 0.56131 | Running loss: 0.96322\n",
      "Epoch: 2 | Iteration: 113 | Classification loss: 0.46861 | Regression loss: 0.60275 | Running loss: 0.96298\n",
      "Epoch: 2 | Iteration: 114 | Classification loss: 0.43806 | Regression loss: 0.49904 | Running loss: 0.96336\n",
      "Epoch: 2 | Iteration: 115 | Classification loss: 0.32679 | Regression loss: 0.41917 | Running loss: 0.96311\n",
      "Epoch: 2 | Iteration: 116 | Classification loss: 0.44507 | Regression loss: 0.33160 | Running loss: 0.96362\n",
      "Epoch: 2 | Iteration: 117 | Classification loss: 0.44342 | Regression loss: 0.50675 | Running loss: 0.96367\n",
      "Epoch: 2 | Iteration: 118 | Classification loss: 0.54719 | Regression loss: 0.65915 | Running loss: 0.96455\n",
      "Epoch: 2 | Iteration: 119 | Classification loss: 0.30797 | Regression loss: 0.48879 | Running loss: 0.96360\n",
      "Epoch: 2 | Iteration: 120 | Classification loss: 0.23264 | Regression loss: 0.21104 | Running loss: 0.96207\n",
      "Epoch: 2 | Iteration: 121 | Classification loss: 0.29708 | Regression loss: 0.57540 | Running loss: 0.96174\n",
      "Epoch: 2 | Iteration: 122 | Classification loss: 0.16159 | Regression loss: 0.35353 | Running loss: 0.96137\n",
      "Epoch: 2 | Iteration: 123 | Classification loss: 0.32997 | Regression loss: 0.53544 | Running loss: 0.96110\n",
      "Epoch: 2 | Iteration: 124 | Classification loss: 0.48394 | Regression loss: 0.72875 | Running loss: 0.96181\n",
      "Epoch: 2 | Iteration: 125 | Classification loss: 0.44394 | Regression loss: 0.77009 | Running loss: 0.96272\n",
      "Epoch: 2 | Iteration: 126 | Classification loss: 0.36251 | Regression loss: 0.30400 | Running loss: 0.96234\n",
      "Epoch: 2 | Iteration: 127 | Classification loss: 0.30309 | Regression loss: 0.40945 | Running loss: 0.96084\n",
      "Epoch: 2 | Iteration: 128 | Classification loss: 0.38386 | Regression loss: 0.68243 | Running loss: 0.96126\n",
      "Epoch: 2 | Iteration: 129 | Classification loss: 0.19084 | Regression loss: 0.48124 | Running loss: 0.96092\n",
      "Epoch: 2 | Iteration: 130 | Classification loss: 0.53971 | Regression loss: 0.43143 | Running loss: 0.96059\n",
      "Epoch: 2 | Iteration: 131 | Classification loss: 0.41424 | Regression loss: 0.48858 | Running loss: 0.96059\n",
      "Epoch: 2 | Iteration: 132 | Classification loss: 0.50538 | Regression loss: 0.50165 | Running loss: 0.96082\n",
      "Epoch: 2 | Iteration: 133 | Classification loss: 0.19745 | Regression loss: 0.30785 | Running loss: 0.95955\n",
      "Epoch: 2 | Iteration: 134 | Classification loss: 0.40255 | Regression loss: 0.42719 | Running loss: 0.95922\n",
      "Epoch: 2 | Iteration: 135 | Classification loss: 0.20871 | Regression loss: 0.34181 | Running loss: 0.95839\n",
      "Epoch: 2 | Iteration: 136 | Classification loss: 0.51783 | Regression loss: 0.43991 | Running loss: 0.95762\n",
      "Epoch: 2 | Iteration: 137 | Classification loss: 0.49772 | Regression loss: 0.67336 | Running loss: 0.95869\n",
      "Epoch: 2 | Iteration: 138 | Classification loss: 0.27381 | Regression loss: 0.35790 | Running loss: 0.95769\n",
      "Epoch: 2 | Iteration: 139 | Classification loss: 0.33698 | Regression loss: 0.37065 | Running loss: 0.95533\n",
      "Epoch: 2 | Iteration: 140 | Classification loss: 0.33437 | Regression loss: 0.43188 | Running loss: 0.95499\n",
      "Epoch: 2 | Iteration: 141 | Classification loss: 0.56175 | Regression loss: 0.76585 | Running loss: 0.95631\n",
      "Epoch: 2 | Iteration: 142 | Classification loss: 0.31549 | Regression loss: 0.53133 | Running loss: 0.95600\n",
      "Epoch: 2 | Iteration: 143 | Classification loss: 0.41331 | Regression loss: 0.57786 | Running loss: 0.95607\n",
      "Epoch: 2 | Iteration: 144 | Classification loss: 0.43604 | Regression loss: 0.66087 | Running loss: 0.95654\n",
      "Epoch: 2 | Iteration: 145 | Classification loss: 0.35342 | Regression loss: 0.37268 | Running loss: 0.95615\n",
      "Epoch: 2 | Iteration: 146 | Classification loss: 0.41833 | Regression loss: 0.18847 | Running loss: 0.95576\n",
      "Epoch: 2 | Iteration: 147 | Classification loss: 0.33865 | Regression loss: 0.73930 | Running loss: 0.95535\n",
      "Epoch: 2 | Iteration: 148 | Classification loss: 0.53922 | Regression loss: 0.44332 | Running loss: 0.95560\n",
      "Epoch: 2 | Iteration: 149 | Classification loss: 0.39063 | Regression loss: 0.74324 | Running loss: 0.95609\n",
      "Epoch: 2 | Iteration: 150 | Classification loss: 0.38133 | Regression loss: 0.63068 | Running loss: 0.95613\n",
      "Epoch: 2 | Iteration: 151 | Classification loss: 0.23525 | Regression loss: 0.35894 | Running loss: 0.95495\n",
      "Epoch: 2 | Iteration: 152 | Classification loss: 0.36058 | Regression loss: 0.44367 | Running loss: 0.95459\n",
      "Epoch: 2 | Iteration: 153 | Classification loss: 0.50192 | Regression loss: 0.35159 | Running loss: 0.95311\n",
      "Epoch: 2 | Iteration: 154 | Classification loss: 0.32400 | Regression loss: 0.39019 | Running loss: 0.95275\n",
      "Epoch: 2 | Iteration: 155 | Classification loss: 0.30539 | Regression loss: 0.42468 | Running loss: 0.95301\n",
      "Epoch: 2 | Iteration: 156 | Classification loss: 0.37909 | Regression loss: 0.50534 | Running loss: 0.95228\n",
      "Epoch: 2 | Iteration: 157 | Classification loss: 0.27732 | Regression loss: 0.51801 | Running loss: 0.95140\n",
      "Epoch: 2 | Iteration: 158 | Classification loss: 0.76547 | Regression loss: 0.76265 | Running loss: 0.95281\n",
      "Epoch: 2 | Iteration: 159 | Classification loss: 0.37189 | Regression loss: 0.28428 | Running loss: 0.95107\n",
      "Epoch: 2 | Iteration: 160 | Classification loss: 0.18847 | Regression loss: 0.30740 | Running loss: 0.95045\n",
      "Epoch: 2 | Iteration: 161 | Classification loss: 0.42872 | Regression loss: 0.60928 | Running loss: 0.95062\n",
      "Epoch: 2 | Iteration: 162 | Classification loss: 0.29547 | Regression loss: 0.45824 | Running loss: 0.95082\n",
      "Epoch: 2 | Iteration: 163 | Classification loss: 0.55957 | Regression loss: 0.44171 | Running loss: 0.95110\n",
      "Epoch: 2 | Iteration: 164 | Classification loss: 0.36731 | Regression loss: 0.50633 | Running loss: 0.95035\n",
      "Epoch: 2 | Iteration: 165 | Classification loss: 0.31010 | Regression loss: 0.28404 | Running loss: 0.94967\n",
      "Epoch: 2 | Iteration: 166 | Classification loss: 0.17263 | Regression loss: 0.35390 | Running loss: 0.94960\n",
      "Epoch: 2 | Iteration: 167 | Classification loss: 0.29919 | Regression loss: 0.34570 | Running loss: 0.94953\n",
      "Epoch: 2 | Iteration: 168 | Classification loss: 0.37951 | Regression loss: 0.22837 | Running loss: 0.94872\n",
      "Epoch: 2 | Iteration: 169 | Classification loss: 0.86223 | Regression loss: 1.36307 | Running loss: 0.95127\n",
      "Epoch: 2 | Iteration: 170 | Classification loss: 0.40168 | Regression loss: 0.73192 | Running loss: 0.95127\n",
      "Epoch: 2 | Iteration: 171 | Classification loss: 0.48671 | Regression loss: 0.78246 | Running loss: 0.95259\n",
      "Epoch: 2 | Iteration: 172 | Classification loss: 0.29281 | Regression loss: 0.19983 | Running loss: 0.95094\n",
      "Epoch: 2 | Iteration: 173 | Classification loss: 0.44878 | Regression loss: 0.48604 | Running loss: 0.95074\n",
      "Epoch: 2 | Iteration: 174 | Classification loss: 0.37405 | Regression loss: 0.66928 | Running loss: 0.95059\n",
      "Epoch: 2 | Iteration: 175 | Classification loss: 0.55302 | Regression loss: 0.43623 | Running loss: 0.95051\n",
      "Epoch: 2 | Iteration: 176 | Classification loss: 0.38985 | Regression loss: 0.39105 | Running loss: 0.94946\n",
      "Epoch: 2 | Iteration: 177 | Classification loss: 0.71337 | Regression loss: 0.78689 | Running loss: 0.95093\n",
      "Epoch: 2 | Iteration: 178 | Classification loss: 0.64041 | Regression loss: 0.64300 | Running loss: 0.95127\n",
      "Epoch: 2 | Iteration: 179 | Classification loss: 0.15955 | Regression loss: 0.54042 | Running loss: 0.95084\n",
      "Epoch: 2 | Iteration: 180 | Classification loss: 0.46491 | Regression loss: 0.32367 | Running loss: 0.95059\n",
      "Epoch: 2 | Iteration: 181 | Classification loss: 0.43309 | Regression loss: 0.96879 | Running loss: 0.95221\n",
      "Epoch: 2 | Iteration: 182 | Classification loss: 0.21105 | Regression loss: 0.38602 | Running loss: 0.95143\n",
      "Epoch: 2 | Iteration: 183 | Classification loss: 0.26265 | Regression loss: 0.19256 | Running loss: 0.95026\n",
      "Epoch: 2 | Iteration: 184 | Classification loss: 0.48453 | Regression loss: 0.42709 | Running loss: 0.94927\n",
      "Epoch: 2 | Iteration: 185 | Classification loss: 0.20891 | Regression loss: 0.29189 | Running loss: 0.94881\n",
      "Epoch: 2 | Iteration: 186 | Classification loss: 0.33339 | Regression loss: 0.76419 | Running loss: 0.94915\n",
      "Epoch: 2 | Iteration: 187 | Classification loss: 0.46934 | Regression loss: 0.46469 | Running loss: 0.94963\n",
      "Epoch: 2 | Iteration: 188 | Classification loss: 0.46114 | Regression loss: 0.40050 | Running loss: 0.94823\n",
      "Epoch: 2 | Iteration: 189 | Classification loss: 0.25212 | Regression loss: 0.67200 | Running loss: 0.94710\n",
      "Epoch: 2 | Iteration: 190 | Classification loss: 0.51097 | Regression loss: 0.64791 | Running loss: 0.94678\n",
      "Epoch: 2 | Iteration: 191 | Classification loss: 0.39432 | Regression loss: 0.55357 | Running loss: 0.94582\n",
      "Epoch: 2 | Iteration: 192 | Classification loss: 0.25940 | Regression loss: 0.74994 | Running loss: 0.94580\n",
      "Epoch: 2 | Iteration: 193 | Classification loss: 0.66958 | Regression loss: 0.70979 | Running loss: 0.94683\n",
      "Epoch: 2 | Iteration: 194 | Classification loss: 0.14054 | Regression loss: 0.33325 | Running loss: 0.94593\n",
      "Epoch: 2 | Iteration: 195 | Classification loss: 0.52828 | Regression loss: 0.70944 | Running loss: 0.94557\n",
      "Epoch: 2 | Iteration: 196 | Classification loss: 0.42537 | Regression loss: 0.48264 | Running loss: 0.94478\n",
      "Epoch: 2 | Iteration: 197 | Classification loss: 0.18880 | Regression loss: 0.46879 | Running loss: 0.94387\n",
      "Epoch: 2 | Iteration: 198 | Classification loss: 0.26835 | Regression loss: 0.64734 | Running loss: 0.94385\n",
      "Epoch: 2 | Iteration: 199 | Classification loss: 0.33447 | Regression loss: 0.41769 | Running loss: 0.94266\n",
      "Epoch: 2 | Iteration: 200 | Classification loss: 0.34118 | Regression loss: 0.59710 | Running loss: 0.94195\n",
      "Epoch: 2 | Iteration: 201 | Classification loss: 0.20071 | Regression loss: 0.28410 | Running loss: 0.94083\n",
      "Epoch: 2 | Iteration: 202 | Classification loss: 0.33923 | Regression loss: 0.28220 | Running loss: 0.94037\n",
      "Epoch: 2 | Iteration: 203 | Classification loss: 0.34777 | Regression loss: 0.51805 | Running loss: 0.94015\n",
      "Epoch: 2 | Iteration: 204 | Classification loss: 0.46569 | Regression loss: 0.76931 | Running loss: 0.94129\n",
      "Epoch: 2 | Iteration: 205 | Classification loss: 0.25988 | Regression loss: 0.41379 | Running loss: 0.94072\n",
      "Epoch: 2 | Iteration: 206 | Classification loss: 0.36554 | Regression loss: 0.49789 | Running loss: 0.94098\n",
      "Epoch: 2 | Iteration: 207 | Classification loss: 0.53280 | Regression loss: 0.63692 | Running loss: 0.94186\n",
      "Epoch: 2 | Iteration: 208 | Classification loss: 0.51098 | Regression loss: 0.92518 | Running loss: 0.94324\n",
      "Epoch: 2 | Iteration: 209 | Classification loss: 0.36456 | Regression loss: 0.45175 | Running loss: 0.94340\n",
      "Epoch: 2 | Iteration: 210 | Classification loss: 0.35110 | Regression loss: 0.46444 | Running loss: 0.94335\n",
      "Epoch: 2 | Iteration: 211 | Classification loss: 0.24828 | Regression loss: 0.31848 | Running loss: 0.94152\n",
      "Epoch: 2 | Iteration: 212 | Classification loss: 0.36338 | Regression loss: 0.78683 | Running loss: 0.94167\n",
      "Epoch: 2 | Iteration: 213 | Classification loss: 0.28652 | Regression loss: 0.42962 | Running loss: 0.94162\n",
      "Epoch: 2 | Iteration: 214 | Classification loss: 0.51037 | Regression loss: 0.46589 | Running loss: 0.94086\n",
      "Epoch: 2 | Iteration: 215 | Classification loss: 0.30950 | Regression loss: 0.51522 | Running loss: 0.94103\n",
      "Epoch: 2 | Iteration: 216 | Classification loss: 0.69779 | Regression loss: 0.45420 | Running loss: 0.94059\n",
      "Epoch: 2 | Iteration: 217 | Classification loss: 0.40235 | Regression loss: 0.44231 | Running loss: 0.94074\n",
      "Epoch: 2 | Iteration: 218 | Classification loss: 0.27812 | Regression loss: 0.51938 | Running loss: 0.93801\n",
      "Epoch: 2 | Iteration: 219 | Classification loss: 0.32651 | Regression loss: 0.65974 | Running loss: 0.93848\n",
      "Epoch: 2 | Iteration: 220 | Classification loss: 0.24975 | Regression loss: 0.41977 | Running loss: 0.93774\n",
      "Epoch: 2 | Iteration: 221 | Classification loss: 0.36361 | Regression loss: 0.61720 | Running loss: 0.93728\n",
      "Epoch: 2 | Iteration: 222 | Classification loss: 0.37383 | Regression loss: 0.47365 | Running loss: 0.93723\n",
      "Epoch: 2 | Iteration: 223 | Classification loss: 0.29547 | Regression loss: 0.50990 | Running loss: 0.93606\n",
      "Epoch: 2 | Iteration: 224 | Classification loss: 0.18866 | Regression loss: 0.31101 | Running loss: 0.93496\n",
      "Epoch: 2 | Iteration: 225 | Classification loss: 0.73348 | Regression loss: 0.14240 | Running loss: 0.93493\n",
      "Epoch: 2 | Iteration: 226 | Classification loss: 0.52120 | Regression loss: 0.89692 | Running loss: 0.93603\n",
      "Epoch: 2 | Iteration: 227 | Classification loss: 0.36318 | Regression loss: 0.51006 | Running loss: 0.93393\n",
      "Epoch: 2 | Iteration: 228 | Classification loss: 0.45124 | Regression loss: 0.68507 | Running loss: 0.93404\n",
      "Epoch: 2 | Iteration: 229 | Classification loss: 0.11084 | Regression loss: 0.41307 | Running loss: 0.93277\n",
      "Epoch: 2 | Iteration: 230 | Classification loss: 0.50725 | Regression loss: 0.67273 | Running loss: 0.93356\n",
      "Epoch: 2 | Iteration: 231 | Classification loss: 0.47537 | Regression loss: 0.47190 | Running loss: 0.93389\n",
      "Epoch: 2 | Iteration: 232 | Classification loss: 0.28986 | Regression loss: 0.61555 | Running loss: 0.93414\n",
      "Epoch: 2 | Iteration: 233 | Classification loss: 0.42821 | Regression loss: 0.54011 | Running loss: 0.93330\n",
      "Epoch: 2 | Iteration: 234 | Classification loss: 0.50407 | Regression loss: 0.90368 | Running loss: 0.93368\n",
      "Epoch: 2 | Iteration: 235 | Classification loss: 0.45527 | Regression loss: 0.45478 | Running loss: 0.93327\n",
      "Epoch: 2 | Iteration: 236 | Classification loss: 0.46969 | Regression loss: 0.65088 | Running loss: 0.93385\n",
      "Epoch: 2 | Iteration: 237 | Classification loss: 0.36069 | Regression loss: 0.35362 | Running loss: 0.93363\n",
      "Epoch: 2 | Iteration: 238 | Classification loss: 0.43166 | Regression loss: 0.34590 | Running loss: 0.93317\n",
      "Epoch: 2 | Iteration: 239 | Classification loss: 0.17388 | Regression loss: 0.25651 | Running loss: 0.93180\n",
      "Epoch: 2 | Iteration: 240 | Classification loss: 0.44136 | Regression loss: 0.71470 | Running loss: 0.93203\n",
      "Epoch: 2 | Iteration: 241 | Classification loss: 0.37279 | Regression loss: 0.70226 | Running loss: 0.93216\n",
      "Epoch: 2 | Iteration: 242 | Classification loss: 0.17335 | Regression loss: 0.22026 | Running loss: 0.93110\n",
      "Epoch: 2 | Iteration: 243 | Classification loss: 0.12362 | Regression loss: 0.34207 | Running loss: 0.93027\n",
      "Epoch: 2 | Iteration: 244 | Classification loss: 0.64505 | Regression loss: 0.78903 | Running loss: 0.93115\n",
      "Epoch: 2 | Iteration: 245 | Classification loss: 0.32217 | Regression loss: 0.69579 | Running loss: 0.93100\n",
      "Epoch: 2 | Iteration: 246 | Classification loss: 0.38839 | Regression loss: 0.39127 | Running loss: 0.93083\n",
      "Epoch: 2 | Iteration: 247 | Classification loss: 0.32051 | Regression loss: 0.24366 | Running loss: 0.93049\n",
      "Epoch: 2 | Iteration: 248 | Classification loss: 0.48500 | Regression loss: 0.16292 | Running loss: 0.92946\n",
      "Epoch: 2 | Iteration: 249 | Classification loss: 0.14459 | Regression loss: 0.34599 | Running loss: 0.92896\n",
      "Epoch: 2 | Iteration: 250 | Classification loss: 0.56726 | Regression loss: 0.61732 | Running loss: 0.92949\n",
      "Epoch: 2 | Iteration: 251 | Classification loss: 0.25701 | Regression loss: 0.36307 | Running loss: 0.92846\n",
      "Epoch: 2 | Iteration: 252 | Classification loss: 0.45662 | Regression loss: 0.72204 | Running loss: 0.92934\n",
      "Epoch: 2 | Iteration: 253 | Classification loss: 0.38122 | Regression loss: 0.47950 | Running loss: 0.92786\n",
      "Epoch: 2 | Iteration: 254 | Classification loss: 0.40715 | Regression loss: 0.41438 | Running loss: 0.92742\n",
      "Epoch: 2 | Iteration: 255 | Classification loss: 0.27313 | Regression loss: 0.47378 | Running loss: 0.92717\n",
      "Epoch: 2 | Iteration: 256 | Classification loss: 0.69162 | Regression loss: 0.86493 | Running loss: 0.92871\n",
      "Epoch: 2 | Iteration: 257 | Classification loss: 0.52715 | Regression loss: 0.59782 | Running loss: 0.92958\n",
      "Epoch: 2 | Iteration: 258 | Classification loss: 0.38035 | Regression loss: 0.65760 | Running loss: 0.92942\n",
      "Epoch: 2 | Iteration: 259 | Classification loss: 0.17572 | Regression loss: 0.53254 | Running loss: 0.92955\n",
      "Epoch: 2 | Iteration: 260 | Classification loss: 0.52132 | Regression loss: 0.47371 | Running loss: 0.93056\n",
      "Epoch: 2 | Iteration: 261 | Classification loss: 0.36486 | Regression loss: 0.33836 | Running loss: 0.93032\n",
      "Epoch: 2 | Iteration: 262 | Classification loss: 0.34260 | Regression loss: 0.34343 | Running loss: 0.92943\n",
      "Epoch: 2 | Iteration: 263 | Classification loss: 0.35713 | Regression loss: 0.58020 | Running loss: 0.93003\n",
      "Epoch: 2 | Iteration: 264 | Classification loss: 0.34631 | Regression loss: 0.49195 | Running loss: 0.93061\n",
      "Epoch: 2 | Iteration: 265 | Classification loss: 0.34478 | Regression loss: 0.53866 | Running loss: 0.93116\n",
      "Epoch: 2 | Iteration: 266 | Classification loss: 0.33858 | Regression loss: 0.38835 | Running loss: 0.93077\n",
      "Epoch: 2 | Iteration: 267 | Classification loss: 0.30152 | Regression loss: 0.16869 | Running loss: 0.93005\n",
      "Epoch: 2 | Iteration: 268 | Classification loss: 0.43775 | Regression loss: 0.58332 | Running loss: 0.93085\n",
      "Epoch: 2 | Iteration: 269 | Classification loss: 0.22698 | Regression loss: 0.49501 | Running loss: 0.92990\n",
      "Epoch: 2 | Iteration: 270 | Classification loss: 0.45982 | Regression loss: 0.73461 | Running loss: 0.93035\n",
      "Epoch: 2 | Iteration: 271 | Classification loss: 0.39022 | Regression loss: 0.43082 | Running loss: 0.93049\n",
      "Epoch: 2 | Iteration: 272 | Classification loss: 0.47348 | Regression loss: 0.58788 | Running loss: 0.93093\n",
      "Epoch: 2 | Iteration: 273 | Classification loss: 0.47366 | Regression loss: 0.39205 | Running loss: 0.93142\n",
      "Epoch: 2 | Iteration: 274 | Classification loss: 0.53407 | Regression loss: 0.73317 | Running loss: 0.93255\n",
      "Epoch: 2 | Iteration: 275 | Classification loss: 0.30576 | Regression loss: 0.35924 | Running loss: 0.93211\n",
      "Epoch: 2 | Iteration: 276 | Classification loss: 0.46160 | Regression loss: 0.84167 | Running loss: 0.93356\n",
      "Epoch: 2 | Iteration: 277 | Classification loss: 0.28482 | Regression loss: 0.32643 | Running loss: 0.93245\n",
      "Epoch: 2 | Iteration: 278 | Classification loss: 0.27448 | Regression loss: 0.55148 | Running loss: 0.93179\n",
      "Epoch: 2 | Iteration: 279 | Classification loss: 0.33060 | Regression loss: 0.76048 | Running loss: 0.93254\n",
      "Epoch: 2 | Iteration: 280 | Classification loss: 0.35574 | Regression loss: 0.43234 | Running loss: 0.93202\n",
      "Epoch: 2 | Iteration: 281 | Classification loss: 0.32373 | Regression loss: 0.59560 | Running loss: 0.93149\n",
      "Epoch: 2 | Iteration: 282 | Classification loss: 0.35745 | Regression loss: 0.40425 | Running loss: 0.93101\n",
      "Epoch: 2 | Iteration: 283 | Classification loss: 0.27497 | Regression loss: 0.43940 | Running loss: 0.93015\n",
      "Epoch: 2 | Iteration: 284 | Classification loss: 0.32142 | Regression loss: 0.50013 | Running loss: 0.93004\n",
      "Epoch: 2 | Iteration: 285 | Classification loss: 0.20508 | Regression loss: 0.32695 | Running loss: 0.93015\n",
      "Epoch: 2 | Iteration: 286 | Classification loss: 0.35245 | Regression loss: 0.51922 | Running loss: 0.93005\n",
      "Epoch: 2 | Iteration: 287 | Classification loss: 0.30301 | Regression loss: 0.46735 | Running loss: 0.93022\n",
      "Epoch: 2 | Iteration: 288 | Classification loss: 0.28103 | Regression loss: 0.38897 | Running loss: 0.92969\n",
      "Epoch: 2 | Iteration: 289 | Classification loss: 0.33254 | Regression loss: 0.46972 | Running loss: 0.92967\n",
      "Epoch: 2 | Iteration: 290 | Classification loss: 0.19071 | Regression loss: 0.28293 | Running loss: 0.92718\n",
      "Epoch: 2 | Iteration: 291 | Classification loss: 0.35293 | Regression loss: 0.73517 | Running loss: 0.92678\n",
      "Epoch: 2 | Iteration: 292 | Classification loss: 0.31616 | Regression loss: 0.25858 | Running loss: 0.92567\n",
      "Epoch: 2 | Iteration: 293 | Classification loss: 0.34731 | Regression loss: 0.51286 | Running loss: 0.92562\n",
      "Epoch: 2 | Iteration: 294 | Classification loss: 0.27835 | Regression loss: 0.23712 | Running loss: 0.92485\n",
      "Epoch: 2 | Iteration: 295 | Classification loss: 0.42313 | Regression loss: 0.41472 | Running loss: 0.92434\n",
      "Epoch: 2 | Iteration: 296 | Classification loss: 0.43752 | Regression loss: 0.57113 | Running loss: 0.92457\n",
      "Epoch: 2 | Iteration: 297 | Classification loss: 0.35266 | Regression loss: 0.35907 | Running loss: 0.92460\n",
      "Epoch: 2 | Iteration: 298 | Classification loss: 0.31177 | Regression loss: 0.33414 | Running loss: 0.92406\n",
      "Epoch: 2 | Iteration: 299 | Classification loss: 0.48403 | Regression loss: 0.48449 | Running loss: 0.92396\n",
      "Epoch: 2 | Iteration: 300 | Classification loss: 0.35302 | Regression loss: 0.71151 | Running loss: 0.92347\n",
      "Epoch: 2 | Iteration: 301 | Classification loss: 0.29056 | Regression loss: 0.43056 | Running loss: 0.92378\n",
      "Epoch: 2 | Iteration: 302 | Classification loss: 0.54456 | Regression loss: 0.68165 | Running loss: 0.92322\n",
      "Epoch: 2 | Iteration: 303 | Classification loss: 0.57929 | Regression loss: 0.39808 | Running loss: 0.92249\n",
      "Epoch: 2 | Iteration: 304 | Classification loss: 0.44406 | Regression loss: 0.57187 | Running loss: 0.92275\n",
      "Epoch: 2 | Iteration: 305 | Classification loss: 0.38352 | Regression loss: 0.27178 | Running loss: 0.92287\n",
      "Epoch: 2 | Iteration: 306 | Classification loss: 0.41682 | Regression loss: 0.36487 | Running loss: 0.92295\n",
      "Epoch: 2 | Iteration: 307 | Classification loss: 0.35488 | Regression loss: 0.65502 | Running loss: 0.92307\n",
      "Epoch: 2 | Iteration: 308 | Classification loss: 0.34601 | Regression loss: 0.42333 | Running loss: 0.92326\n",
      "Epoch: 2 | Iteration: 309 | Classification loss: 0.27929 | Regression loss: 0.26583 | Running loss: 0.92317\n",
      "Epoch: 2 | Iteration: 310 | Classification loss: 0.49382 | Regression loss: 0.69628 | Running loss: 0.92374\n",
      "Epoch: 2 | Iteration: 311 | Classification loss: 0.24619 | Regression loss: 0.24107 | Running loss: 0.92227\n",
      "Epoch: 2 | Iteration: 312 | Classification loss: 0.25919 | Regression loss: 0.40993 | Running loss: 0.92247\n",
      "Epoch: 2 | Iteration: 313 | Classification loss: 0.40252 | Regression loss: 0.47682 | Running loss: 0.92209\n",
      "Epoch: 2 | Iteration: 314 | Classification loss: 0.30148 | Regression loss: 0.32927 | Running loss: 0.92157\n",
      "Epoch: 2 | Iteration: 315 | Classification loss: 0.09817 | Regression loss: 0.25554 | Running loss: 0.92075\n",
      "Epoch: 2 | Iteration: 316 | Classification loss: 0.10928 | Regression loss: 0.16346 | Running loss: 0.91740\n",
      "Epoch: 2 | Iteration: 317 | Classification loss: 0.35723 | Regression loss: 0.37126 | Running loss: 0.91739\n",
      "Epoch: 2 | Iteration: 318 | Classification loss: 0.13468 | Regression loss: 0.32857 | Running loss: 0.91671\n",
      "Epoch: 2 | Iteration: 319 | Classification loss: 0.53973 | Regression loss: 0.62903 | Running loss: 0.91673\n",
      "Epoch: 2 | Iteration: 320 | Classification loss: 0.14809 | Regression loss: 0.27971 | Running loss: 0.91541\n",
      "Epoch: 2 | Iteration: 321 | Classification loss: 0.54972 | Regression loss: 0.46100 | Running loss: 0.91600\n",
      "Epoch: 2 | Iteration: 322 | Classification loss: 0.55972 | Regression loss: 0.27873 | Running loss: 0.91576\n",
      "Epoch: 2 | Iteration: 323 | Classification loss: 0.38201 | Regression loss: 0.66582 | Running loss: 0.91575\n",
      "Epoch: 2 | Iteration: 324 | Classification loss: 0.35296 | Regression loss: 0.61152 | Running loss: 0.91594\n",
      "Epoch: 2 | Iteration: 325 | Classification loss: 0.29139 | Regression loss: 0.54270 | Running loss: 0.91650\n",
      "Epoch: 2 | Iteration: 326 | Classification loss: 0.45181 | Regression loss: 0.26361 | Running loss: 0.91590\n",
      "Epoch: 2 | Iteration: 327 | Classification loss: 0.75563 | Regression loss: 0.94528 | Running loss: 0.91731\n",
      "Epoch: 2 | Iteration: 328 | Classification loss: 0.34974 | Regression loss: 0.45584 | Running loss: 0.91638\n",
      "Epoch: 2 | Iteration: 329 | Classification loss: 0.22192 | Regression loss: 0.39436 | Running loss: 0.91573\n",
      "Epoch: 2 | Iteration: 330 | Classification loss: 0.31942 | Regression loss: 0.42634 | Running loss: 0.91566\n",
      "Epoch: 2 | Iteration: 331 | Classification loss: 0.51039 | Regression loss: 0.85149 | Running loss: 0.91631\n",
      "Epoch: 2 | Iteration: 332 | Classification loss: 0.43275 | Regression loss: 0.38416 | Running loss: 0.91605\n",
      "Epoch: 2 | Iteration: 333 | Classification loss: 0.34326 | Regression loss: 0.44052 | Running loss: 0.91592\n",
      "Epoch: 2 | Iteration: 334 | Classification loss: 0.24755 | Regression loss: 0.50979 | Running loss: 0.91550\n",
      "Epoch: 2 | Iteration: 335 | Classification loss: 0.11690 | Regression loss: 0.27493 | Running loss: 0.91421\n",
      "Epoch: 2 | Iteration: 336 | Classification loss: 0.60170 | Regression loss: 0.99197 | Running loss: 0.91514\n",
      "Epoch: 2 | Iteration: 337 | Classification loss: 0.26978 | Regression loss: 0.27354 | Running loss: 0.91421\n",
      "Epoch: 2 | Iteration: 338 | Classification loss: 0.19082 | Regression loss: 0.33162 | Running loss: 0.91289\n",
      "Epoch: 2 | Iteration: 339 | Classification loss: 0.50693 | Regression loss: 0.58628 | Running loss: 0.91333\n",
      "Epoch: 2 | Iteration: 340 | Classification loss: 0.57544 | Regression loss: 0.68359 | Running loss: 0.91321\n",
      "Epoch: 2 | Iteration: 341 | Classification loss: 0.26877 | Regression loss: 0.57873 | Running loss: 0.91278\n",
      "Epoch: 2 | Iteration: 342 | Classification loss: 0.51888 | Regression loss: 0.61529 | Running loss: 0.91292\n",
      "Epoch: 2 | Iteration: 343 | Classification loss: 0.40695 | Regression loss: 0.48250 | Running loss: 0.91186\n",
      "Epoch: 2 | Iteration: 344 | Classification loss: 0.26680 | Regression loss: 0.31829 | Running loss: 0.91115\n",
      "Epoch: 2 | Iteration: 345 | Classification loss: 0.43147 | Regression loss: 0.31050 | Running loss: 0.91121\n",
      "Epoch: 2 | Iteration: 346 | Classification loss: 0.30001 | Regression loss: 0.32082 | Running loss: 0.91055\n",
      "Epoch: 2 | Iteration: 347 | Classification loss: 0.30644 | Regression loss: 0.43256 | Running loss: 0.91025\n",
      "Epoch: 2 | Iteration: 348 | Classification loss: 0.23904 | Regression loss: 0.31052 | Running loss: 0.90887\n",
      "Epoch: 2 | Iteration: 349 | Classification loss: 0.34352 | Regression loss: 0.45003 | Running loss: 0.90885\n",
      "Epoch: 2 | Iteration: 350 | Classification loss: 0.33805 | Regression loss: 0.44648 | Running loss: 0.90850\n",
      "Epoch: 2 | Iteration: 351 | Classification loss: 0.45332 | Regression loss: 0.24236 | Running loss: 0.90655\n",
      "Epoch: 2 | Iteration: 352 | Classification loss: 0.42577 | Regression loss: 0.48320 | Running loss: 0.90657\n",
      "Epoch: 2 | Iteration: 353 | Classification loss: 0.38950 | Regression loss: 0.79957 | Running loss: 0.90709\n",
      "Epoch: 2 | Iteration: 354 | Classification loss: 0.30762 | Regression loss: 0.28626 | Running loss: 0.90664\n",
      "Epoch: 2 | Iteration: 355 | Classification loss: 0.56817 | Regression loss: 0.22255 | Running loss: 0.90608\n",
      "Epoch: 2 | Iteration: 356 | Classification loss: 0.37830 | Regression loss: 0.36827 | Running loss: 0.90616\n",
      "Epoch: 2 | Iteration: 357 | Classification loss: 0.31423 | Regression loss: 0.46883 | Running loss: 0.90644\n",
      "Epoch: 2 | Iteration: 358 | Classification loss: 0.51820 | Regression loss: 0.21662 | Running loss: 0.90625\n",
      "Epoch: 2 | Iteration: 359 | Classification loss: 0.23261 | Regression loss: 0.18053 | Running loss: 0.90555\n",
      "Epoch: 2 | Iteration: 360 | Classification loss: 0.36195 | Regression loss: 0.59077 | Running loss: 0.90554\n",
      "Epoch: 2 | Iteration: 361 | Classification loss: 0.33674 | Regression loss: 0.27630 | Running loss: 0.90417\n",
      "Epoch: 2 | Iteration: 362 | Classification loss: 0.38144 | Regression loss: 0.28617 | Running loss: 0.90310\n",
      "Epoch: 2 | Iteration: 363 | Classification loss: 0.42988 | Regression loss: 0.56814 | Running loss: 0.90377\n",
      "Epoch: 2 | Iteration: 364 | Classification loss: 0.34011 | Regression loss: 0.42336 | Running loss: 0.90296\n",
      "Epoch: 2 | Iteration: 365 | Classification loss: 0.38883 | Regression loss: 0.62209 | Running loss: 0.90325\n",
      "Epoch: 2 | Iteration: 366 | Classification loss: 0.32223 | Regression loss: 0.55585 | Running loss: 0.90295\n",
      "Epoch: 2 | Iteration: 367 | Classification loss: 0.54463 | Regression loss: 0.83372 | Running loss: 0.90457\n",
      "Epoch: 2 | Iteration: 368 | Classification loss: 0.29097 | Regression loss: 0.49064 | Running loss: 0.90488\n",
      "Epoch: 2 | Iteration: 369 | Classification loss: 0.36333 | Regression loss: 0.41156 | Running loss: 0.90463\n",
      "Epoch: 2 | Iteration: 370 | Classification loss: 0.26805 | Regression loss: 0.55374 | Running loss: 0.90372\n",
      "Epoch: 2 | Iteration: 371 | Classification loss: 0.55190 | Regression loss: 0.69274 | Running loss: 0.90288\n",
      "Epoch: 2 | Iteration: 372 | Classification loss: 0.45793 | Regression loss: 0.71331 | Running loss: 0.90344\n",
      "Epoch: 2 | Iteration: 373 | Classification loss: 0.38169 | Regression loss: 0.38686 | Running loss: 0.90299\n",
      "Epoch: 2 | Iteration: 374 | Classification loss: 0.36159 | Regression loss: 0.31567 | Running loss: 0.90279\n",
      "Epoch: 2 | Iteration: 375 | Classification loss: 0.20217 | Regression loss: 0.86422 | Running loss: 0.90222\n",
      "Epoch: 2 | Iteration: 376 | Classification loss: 0.55030 | Regression loss: 0.60094 | Running loss: 0.90238\n",
      "Epoch: 2 | Iteration: 377 | Classification loss: 0.31205 | Regression loss: 0.61409 | Running loss: 0.90217\n",
      "Epoch: 2 | Iteration: 378 | Classification loss: 0.32125 | Regression loss: 0.29114 | Running loss: 0.90170\n",
      "Epoch: 2 | Iteration: 379 | Classification loss: 0.35872 | Regression loss: 0.50724 | Running loss: 0.90231\n",
      "Epoch: 2 | Iteration: 380 | Classification loss: 0.31807 | Regression loss: 0.43189 | Running loss: 0.90150\n",
      "Epoch: 2 | Iteration: 381 | Classification loss: 0.28995 | Regression loss: 0.66160 | Running loss: 0.90138\n",
      "Epoch: 2 | Iteration: 382 | Classification loss: 0.33109 | Regression loss: 0.45615 | Running loss: 0.90057\n",
      "Epoch: 2 | Iteration: 383 | Classification loss: 0.27597 | Regression loss: 0.39383 | Running loss: 0.89920\n",
      "Epoch: 2 | Iteration: 384 | Classification loss: 0.27192 | Regression loss: 0.35386 | Running loss: 0.89801\n",
      "Epoch: 2 | Iteration: 385 | Classification loss: 0.30661 | Regression loss: 0.36365 | Running loss: 0.89741\n",
      "Epoch: 2 | Iteration: 386 | Classification loss: 0.37346 | Regression loss: 0.67731 | Running loss: 0.89729\n",
      "Epoch: 2 | Iteration: 387 | Classification loss: 0.22352 | Regression loss: 0.39413 | Running loss: 0.89467\n",
      "Epoch: 2 | Iteration: 388 | Classification loss: 0.41671 | Regression loss: 0.52693 | Running loss: 0.89464\n",
      "Epoch: 2 | Iteration: 389 | Classification loss: 0.18827 | Regression loss: 0.51982 | Running loss: 0.89405\n",
      "Epoch: 2 | Iteration: 390 | Classification loss: 0.45913 | Regression loss: 0.53710 | Running loss: 0.89441\n",
      "Epoch: 2 | Iteration: 391 | Classification loss: 0.59659 | Regression loss: 0.81955 | Running loss: 0.89492\n",
      "Epoch: 2 | Iteration: 392 | Classification loss: 0.28902 | Regression loss: 0.32804 | Running loss: 0.89338\n",
      "Epoch: 2 | Iteration: 393 | Classification loss: 0.50199 | Regression loss: 0.55402 | Running loss: 0.89380\n",
      "Epoch: 2 | Iteration: 394 | Classification loss: 0.33677 | Regression loss: 0.58819 | Running loss: 0.89293\n",
      "Epoch: 2 | Iteration: 395 | Classification loss: 0.38560 | Regression loss: 0.35566 | Running loss: 0.89256\n",
      "Epoch: 2 | Iteration: 396 | Classification loss: 0.39831 | Regression loss: 0.34204 | Running loss: 0.89252\n",
      "Epoch: 2 | Iteration: 397 | Classification loss: 0.33324 | Regression loss: 0.35532 | Running loss: 0.89254\n",
      "Epoch: 2 | Iteration: 398 | Classification loss: 0.45731 | Regression loss: 0.46182 | Running loss: 0.89244\n",
      "Epoch: 2 | Iteration: 399 | Classification loss: 0.18560 | Regression loss: 0.42855 | Running loss: 0.89233\n",
      "Epoch: 2 | Iteration: 400 | Classification loss: 0.41598 | Regression loss: 0.61667 | Running loss: 0.89283\n",
      "Epoch: 2 | Iteration: 401 | Classification loss: 0.38894 | Regression loss: 0.39111 | Running loss: 0.89180\n",
      "Epoch: 2 | Iteration: 402 | Classification loss: 0.40272 | Regression loss: 0.36753 | Running loss: 0.89162\n",
      "Epoch: 2 | Iteration: 403 | Classification loss: 0.40134 | Regression loss: 0.43454 | Running loss: 0.89147\n",
      "Epoch: 2 | Iteration: 404 | Classification loss: 0.28656 | Regression loss: 0.49083 | Running loss: 0.89123\n",
      "Epoch: 2 | Iteration: 405 | Classification loss: 0.34004 | Regression loss: 0.52530 | Running loss: 0.89042\n",
      "Epoch: 2 | Iteration: 406 | Classification loss: 0.17885 | Regression loss: 0.17197 | Running loss: 0.88829\n",
      "Epoch: 2 | Iteration: 407 | Classification loss: 0.57307 | Regression loss: 0.37339 | Running loss: 0.88869\n",
      "Epoch: 2 | Iteration: 408 | Classification loss: 0.24071 | Regression loss: 0.33628 | Running loss: 0.88861\n",
      "Epoch: 2 | Iteration: 409 | Classification loss: 0.18768 | Regression loss: 0.39917 | Running loss: 0.88753\n",
      "Epoch: 2 | Iteration: 410 | Classification loss: 0.21782 | Regression loss: 0.32877 | Running loss: 0.88754\n",
      "Epoch: 2 | Iteration: 411 | Classification loss: 0.15212 | Regression loss: 0.23193 | Running loss: 0.88703\n",
      "Epoch: 2 | Iteration: 412 | Classification loss: 0.57103 | Regression loss: 0.54826 | Running loss: 0.88721\n",
      "Epoch: 2 | Iteration: 413 | Classification loss: 0.40238 | Regression loss: 0.35786 | Running loss: 0.88679\n",
      "Epoch: 2 | Iteration: 414 | Classification loss: 0.33148 | Regression loss: 0.36333 | Running loss: 0.88657\n",
      "Epoch: 2 | Iteration: 415 | Classification loss: 0.28917 | Regression loss: 0.66014 | Running loss: 0.88614\n",
      "Epoch: 2 | Iteration: 416 | Classification loss: 0.32014 | Regression loss: 0.32076 | Running loss: 0.88540\n",
      "Epoch: 2 | Iteration: 417 | Classification loss: 0.20221 | Regression loss: 0.32225 | Running loss: 0.88448\n",
      "Epoch: 2 | Iteration: 418 | Classification loss: 0.44914 | Regression loss: 0.45548 | Running loss: 0.88483\n",
      "Epoch: 2 | Iteration: 419 | Classification loss: 0.20720 | Regression loss: 0.61052 | Running loss: 0.88514\n",
      "Epoch: 2 | Iteration: 420 | Classification loss: 0.18656 | Regression loss: 0.44878 | Running loss: 0.88488\n",
      "Epoch: 2 | Iteration: 421 | Classification loss: 0.46258 | Regression loss: 0.59454 | Running loss: 0.88549\n",
      "Epoch: 2 | Iteration: 422 | Classification loss: 0.28276 | Regression loss: 0.55482 | Running loss: 0.88463\n",
      "Epoch: 2 | Iteration: 423 | Classification loss: 0.29899 | Regression loss: 0.48671 | Running loss: 0.88351\n",
      "Epoch: 2 | Iteration: 424 | Classification loss: 0.47004 | Regression loss: 0.67403 | Running loss: 0.88433\n",
      "Epoch: 2 | Iteration: 425 | Classification loss: 0.43261 | Regression loss: 0.21519 | Running loss: 0.88375\n",
      "Epoch: 2 | Iteration: 426 | Classification loss: 0.15995 | Regression loss: 0.25046 | Running loss: 0.88189\n",
      "Epoch: 2 | Iteration: 427 | Classification loss: 0.18677 | Regression loss: 0.32424 | Running loss: 0.88068\n",
      "Epoch: 2 | Iteration: 428 | Classification loss: 0.43776 | Regression loss: 0.45592 | Running loss: 0.88052\n",
      "Epoch: 2 | Iteration: 429 | Classification loss: 0.41686 | Regression loss: 0.44559 | Running loss: 0.88063\n",
      "Epoch: 2 | Iteration: 430 | Classification loss: 0.30713 | Regression loss: 0.38143 | Running loss: 0.88024\n",
      "Epoch: 2 | Iteration: 431 | Classification loss: 0.30908 | Regression loss: 0.27364 | Running loss: 0.88035\n",
      "Epoch: 2 | Iteration: 432 | Classification loss: 0.51702 | Regression loss: 0.64208 | Running loss: 0.87914\n",
      "Epoch: 2 | Iteration: 433 | Classification loss: 0.34635 | Regression loss: 0.38946 | Running loss: 0.87853\n",
      "Epoch: 2 | Iteration: 434 | Classification loss: 0.24670 | Regression loss: 0.28174 | Running loss: 0.87820\n",
      "Epoch: 2 | Iteration: 435 | Classification loss: 0.41811 | Regression loss: 0.30940 | Running loss: 0.87711\n",
      "Epoch: 2 | Iteration: 436 | Classification loss: 0.36882 | Regression loss: 0.36479 | Running loss: 0.87721\n",
      "Epoch: 2 | Iteration: 437 | Classification loss: 0.41117 | Regression loss: 0.30303 | Running loss: 0.87665\n",
      "Epoch: 2 | Iteration: 438 | Classification loss: 0.34877 | Regression loss: 0.24384 | Running loss: 0.87665\n",
      "Epoch: 2 | Iteration: 439 | Classification loss: 0.44641 | Regression loss: 0.24692 | Running loss: 0.87641\n",
      "Epoch: 2 | Iteration: 440 | Classification loss: 0.46276 | Regression loss: 0.51877 | Running loss: 0.87549\n",
      "Epoch: 2 | Iteration: 441 | Classification loss: 0.46114 | Regression loss: 0.70510 | Running loss: 0.87618\n",
      "Epoch: 2 | Iteration: 442 | Classification loss: 0.33481 | Regression loss: 0.38894 | Running loss: 0.87645\n",
      "Epoch: 2 | Iteration: 443 | Classification loss: 0.41367 | Regression loss: 0.36009 | Running loss: 0.87588\n",
      "Epoch: 2 | Iteration: 444 | Classification loss: 0.36961 | Regression loss: 0.52452 | Running loss: 0.87627\n",
      "Epoch: 2 | Iteration: 445 | Classification loss: 0.43511 | Regression loss: 0.58861 | Running loss: 0.87555\n",
      "Epoch: 2 | Iteration: 446 | Classification loss: 0.03002 | Regression loss: 0.00000 | Running loss: 0.87398\n",
      "Epoch: 2 | Iteration: 447 | Classification loss: 0.37742 | Regression loss: 0.34137 | Running loss: 0.87249\n",
      "Epoch: 2 | Iteration: 448 | Classification loss: 0.57358 | Regression loss: 0.67412 | Running loss: 0.87279\n",
      "Epoch: 2 | Iteration: 449 | Classification loss: 0.59012 | Regression loss: 0.54907 | Running loss: 0.87261\n",
      "Epoch: 2 | Iteration: 450 | Classification loss: 0.27850 | Regression loss: 0.22959 | Running loss: 0.87237\n",
      "Epoch: 2 | Iteration: 451 | Classification loss: 0.38400 | Regression loss: 0.39177 | Running loss: 0.87280\n",
      "Epoch: 2 | Iteration: 452 | Classification loss: 0.21056 | Regression loss: 0.29146 | Running loss: 0.87219\n",
      "Epoch: 2 | Iteration: 453 | Classification loss: 0.32735 | Regression loss: 0.65218 | Running loss: 0.87152\n",
      "Epoch: 2 | Iteration: 454 | Classification loss: 0.33533 | Regression loss: 0.51158 | Running loss: 0.87086\n",
      "Epoch: 2 | Iteration: 455 | Classification loss: 0.34511 | Regression loss: 0.33571 | Running loss: 0.87074\n",
      "Epoch: 2 | Iteration: 456 | Classification loss: 0.35549 | Regression loss: 0.34422 | Running loss: 0.87086\n",
      "Epoch: 2 | Iteration: 457 | Classification loss: 0.38293 | Regression loss: 0.31103 | Running loss: 0.87094\n",
      "Epoch: 2 | Iteration: 458 | Classification loss: 0.29863 | Regression loss: 0.41560 | Running loss: 0.86952\n",
      "Epoch: 2 | Iteration: 459 | Classification loss: 0.32990 | Regression loss: 0.49185 | Running loss: 0.86965\n",
      "Epoch: 2 | Iteration: 460 | Classification loss: 0.59640 | Regression loss: 0.22117 | Running loss: 0.86974\n",
      "Epoch: 2 | Iteration: 461 | Classification loss: 0.25488 | Regression loss: 0.57996 | Running loss: 0.86816\n",
      "Epoch: 2 | Iteration: 462 | Classification loss: 0.37149 | Regression loss: 0.49510 | Running loss: 0.86740\n",
      "Epoch: 2 | Iteration: 463 | Classification loss: 0.28679 | Regression loss: 0.57507 | Running loss: 0.86834\n",
      "Epoch: 2 | Iteration: 464 | Classification loss: 0.47821 | Regression loss: 0.70204 | Running loss: 0.86818\n",
      "Epoch: 2 | Iteration: 465 | Classification loss: 0.40251 | Regression loss: 0.35419 | Running loss: 0.86822\n",
      "Epoch: 2 | Iteration: 466 | Classification loss: 0.40632 | Regression loss: 0.59617 | Running loss: 0.86871\n",
      "Epoch: 2 | Iteration: 467 | Classification loss: 0.50600 | Regression loss: 0.65285 | Running loss: 0.86901\n",
      "Epoch: 2 | Iteration: 468 | Classification loss: 0.48925 | Regression loss: 0.50405 | Running loss: 0.86899\n",
      "Epoch: 2 | Iteration: 469 | Classification loss: 0.15810 | Regression loss: 0.28496 | Running loss: 0.86807\n",
      "Epoch: 2 | Iteration: 470 | Classification loss: 0.32009 | Regression loss: 0.27172 | Running loss: 0.86793\n",
      "Epoch: 2 | Iteration: 471 | Classification loss: 0.22966 | Regression loss: 0.21442 | Running loss: 0.86709\n",
      "Epoch: 2 | Iteration: 472 | Classification loss: 0.25560 | Regression loss: 0.37620 | Running loss: 0.86609\n",
      "Epoch: 2 | Iteration: 473 | Classification loss: 0.43967 | Regression loss: 0.40839 | Running loss: 0.86593\n",
      "Epoch: 2 | Iteration: 474 | Classification loss: 0.29084 | Regression loss: 0.41032 | Running loss: 0.86578\n",
      "Epoch: 2 | Iteration: 475 | Classification loss: 0.62831 | Regression loss: 0.80418 | Running loss: 0.86735\n",
      "Epoch: 2 | Iteration: 476 | Classification loss: 0.33628 | Regression loss: 0.34203 | Running loss: 0.86732\n",
      "Epoch: 2 | Iteration: 477 | Classification loss: 0.62284 | Regression loss: 0.72396 | Running loss: 0.86789\n",
      "Epoch: 2 | Iteration: 478 | Classification loss: 0.25294 | Regression loss: 0.46908 | Running loss: 0.86751\n",
      "Epoch: 2 | Iteration: 479 | Classification loss: 0.29750 | Regression loss: 0.48066 | Running loss: 0.86648\n",
      "Epoch: 2 | Iteration: 480 | Classification loss: 0.74498 | Regression loss: 0.58664 | Running loss: 0.86710\n",
      "Epoch: 2 | Iteration: 481 | Classification loss: 0.38315 | Regression loss: 0.64394 | Running loss: 0.86761\n",
      "Epoch: 2 | Iteration: 482 | Classification loss: 0.40223 | Regression loss: 0.32815 | Running loss: 0.86704\n",
      "Epoch: 2 | Iteration: 483 | Classification loss: 0.46109 | Regression loss: 0.60520 | Running loss: 0.86759\n",
      "Epoch: 2 | Iteration: 484 | Classification loss: 0.26382 | Regression loss: 0.36838 | Running loss: 0.86671\n",
      "Epoch: 2 | Iteration: 485 | Classification loss: 0.51188 | Regression loss: 0.74022 | Running loss: 0.86724\n",
      "Epoch: 2 | Iteration: 486 | Classification loss: 0.32913 | Regression loss: 0.41422 | Running loss: 0.86718\n",
      "Epoch: 2 | Iteration: 487 | Classification loss: 0.32334 | Regression loss: 0.32790 | Running loss: 0.86689\n",
      "Epoch: 2 | Iteration: 488 | Classification loss: 0.31091 | Regression loss: 0.34806 | Running loss: 0.86658\n",
      "Epoch: 2 | Iteration: 489 | Classification loss: 0.34371 | Regression loss: 0.33317 | Running loss: 0.86629\n",
      "Epoch: 2 | Iteration: 490 | Classification loss: 0.28238 | Regression loss: 0.76357 | Running loss: 0.86635\n",
      "Epoch: 2 | Iteration: 491 | Classification loss: 0.33998 | Regression loss: 0.64954 | Running loss: 0.86593\n",
      "Epoch: 2 | Iteration: 492 | Classification loss: 0.37007 | Regression loss: 0.41351 | Running loss: 0.86621\n",
      "Epoch: 2 | Iteration: 493 | Classification loss: 0.31941 | Regression loss: 0.36353 | Running loss: 0.86444\n",
      "Epoch: 2 | Iteration: 494 | Classification loss: 0.33445 | Regression loss: 0.41950 | Running loss: 0.86428\n",
      "Epoch: 2 | Iteration: 495 | Classification loss: 0.23145 | Regression loss: 0.25294 | Running loss: 0.86341\n",
      "Epoch: 2 | Iteration: 496 | Classification loss: 0.30996 | Regression loss: 0.48075 | Running loss: 0.86305\n",
      "Epoch: 2 | Iteration: 497 | Classification loss: 0.42328 | Regression loss: 0.57879 | Running loss: 0.86340\n",
      "Epoch: 2 | Iteration: 498 | Classification loss: 0.43160 | Regression loss: 0.69765 | Running loss: 0.86332\n",
      "Epoch: 2 | Iteration: 499 | Classification loss: 0.28479 | Regression loss: 0.44401 | Running loss: 0.86304\n",
      "Epoch: 2 | Iteration: 500 | Classification loss: 0.36487 | Regression loss: 0.54744 | Running loss: 0.86318\n",
      "Epoch: 2 | Iteration: 501 | Classification loss: 0.45883 | Regression loss: 0.63960 | Running loss: 0.86341\n",
      "Epoch: 2 | Iteration: 502 | Classification loss: 0.31794 | Regression loss: 0.34541 | Running loss: 0.86324\n",
      "Epoch: 2 | Iteration: 503 | Classification loss: 0.40777 | Regression loss: 0.47087 | Running loss: 0.86330\n",
      "Epoch: 2 | Iteration: 504 | Classification loss: 0.37368 | Regression loss: 0.53606 | Running loss: 0.86385\n",
      "Epoch: 2 | Iteration: 505 | Classification loss: 0.26730 | Regression loss: 0.24940 | Running loss: 0.86333\n",
      "Epoch: 2 | Iteration: 506 | Classification loss: 0.23135 | Regression loss: 0.40577 | Running loss: 0.86275\n",
      "Epoch: 2 | Iteration: 507 | Classification loss: 0.35298 | Regression loss: 0.39220 | Running loss: 0.86258\n",
      "Epoch: 2 | Iteration: 508 | Classification loss: 0.52142 | Regression loss: 0.54399 | Running loss: 0.86156\n",
      "Epoch: 2 | Iteration: 509 | Classification loss: 0.40552 | Regression loss: 0.52247 | Running loss: 0.86192\n",
      "Epoch: 2 | Iteration: 510 | Classification loss: 0.38871 | Regression loss: 0.46671 | Running loss: 0.86231\n",
      "Epoch: 2 | Iteration: 511 | Classification loss: 0.21548 | Regression loss: 0.41374 | Running loss: 0.86103\n",
      "Epoch: 2 | Iteration: 512 | Classification loss: 0.26968 | Regression loss: 0.47995 | Running loss: 0.86039\n",
      "Epoch: 2 | Iteration: 513 | Classification loss: 0.20024 | Regression loss: 0.45945 | Running loss: 0.85956\n",
      "Epoch: 2 | Iteration: 514 | Classification loss: 0.56523 | Regression loss: 0.60700 | Running loss: 0.86004\n",
      "Epoch: 2 | Iteration: 515 | Classification loss: 0.40236 | Regression loss: 0.81406 | Running loss: 0.85910\n",
      "Epoch: 2 | Iteration: 516 | Classification loss: 0.36348 | Regression loss: 0.55048 | Running loss: 0.85849\n",
      "Epoch: 2 | Iteration: 517 | Classification loss: 0.31439 | Regression loss: 0.37176 | Running loss: 0.85824\n",
      "Epoch: 2 | Iteration: 518 | Classification loss: 0.71767 | Regression loss: 0.37958 | Running loss: 0.85906\n",
      "Epoch: 2 | Iteration: 519 | Classification loss: 0.23641 | Regression loss: 0.59326 | Running loss: 0.85878\n",
      "Epoch: 2 | Iteration: 520 | Classification loss: 0.28932 | Regression loss: 0.39064 | Running loss: 0.85882\n",
      "Epoch: 2 | Iteration: 521 | Classification loss: 0.15088 | Regression loss: 0.31885 | Running loss: 0.85874\n",
      "Epoch: 2 | Iteration: 522 | Classification loss: 0.36814 | Regression loss: 0.38729 | Running loss: 0.85901\n",
      "Epoch: 2 | Iteration: 523 | Classification loss: 0.14095 | Regression loss: 0.30007 | Running loss: 0.85858\n",
      "Epoch: 2 | Iteration: 524 | Classification loss: 0.53214 | Regression loss: 0.70837 | Running loss: 0.85965\n",
      "Epoch: 2 | Iteration: 525 | Classification loss: 0.34126 | Regression loss: 0.50053 | Running loss: 0.86010\n",
      "Epoch: 2 | Iteration: 526 | Classification loss: 0.33264 | Regression loss: 0.59903 | Running loss: 0.86091\n",
      "Epoch: 2 | Iteration: 527 | Classification loss: 0.38674 | Regression loss: 0.56385 | Running loss: 0.86020\n",
      "Epoch: 2 | Iteration: 528 | Classification loss: 0.44905 | Regression loss: 0.48396 | Running loss: 0.85948\n",
      "Epoch: 2 | Iteration: 529 | Classification loss: 0.17082 | Regression loss: 0.28849 | Running loss: 0.85868\n",
      "Epoch: 2 | Iteration: 530 | Classification loss: 0.35276 | Regression loss: 0.35958 | Running loss: 0.85802\n",
      "Epoch: 2 | Iteration: 531 | Classification loss: 0.31386 | Regression loss: 0.47078 | Running loss: 0.85832\n",
      "Epoch: 2 | Iteration: 532 | Classification loss: 0.33024 | Regression loss: 0.41322 | Running loss: 0.85734\n",
      "Epoch: 2 | Iteration: 533 | Classification loss: 0.25518 | Regression loss: 0.61827 | Running loss: 0.85642\n",
      "Epoch: 2 | Iteration: 534 | Classification loss: 0.27822 | Regression loss: 0.46806 | Running loss: 0.85603\n",
      "Epoch: 2 | Iteration: 535 | Classification loss: 0.34514 | Regression loss: 0.33707 | Running loss: 0.85627\n",
      "Epoch: 2 | Iteration: 536 | Classification loss: 0.37144 | Regression loss: 0.47110 | Running loss: 0.85560\n",
      "Epoch: 2 | Iteration: 537 | Classification loss: 0.43801 | Regression loss: 0.34575 | Running loss: 0.85480\n",
      "Epoch: 2 | Iteration: 538 | Classification loss: 0.45487 | Regression loss: 0.63411 | Running loss: 0.85605\n",
      "Epoch: 2 | Iteration: 539 | Classification loss: 0.40153 | Regression loss: 0.42754 | Running loss: 0.85586\n",
      "Epoch: 2 | Iteration: 540 | Classification loss: 0.28185 | Regression loss: 0.40707 | Running loss: 0.85543\n",
      "Epoch: 2 | Iteration: 541 | Classification loss: 0.27490 | Regression loss: 0.29996 | Running loss: 0.85475\n",
      "Epoch: 2 | Iteration: 542 | Classification loss: 0.53599 | Regression loss: 0.86116 | Running loss: 0.85580\n",
      "Epoch: 2 | Iteration: 543 | Classification loss: 0.50288 | Regression loss: 0.78268 | Running loss: 0.85670\n",
      "Epoch: 2 | Iteration: 544 | Classification loss: 0.43449 | Regression loss: 0.44946 | Running loss: 0.85737\n",
      "Epoch: 2 | Iteration: 545 | Classification loss: 0.25097 | Regression loss: 0.58066 | Running loss: 0.85683\n",
      "Epoch: 2 | Iteration: 546 | Classification loss: 0.37383 | Regression loss: 0.64794 | Running loss: 0.85742\n",
      "Epoch: 2 | Iteration: 547 | Classification loss: 0.39464 | Regression loss: 0.74719 | Running loss: 0.85806\n",
      "Epoch: 2 | Iteration: 548 | Classification loss: 0.29179 | Regression loss: 0.37211 | Running loss: 0.85766\n",
      "Epoch: 2 | Iteration: 549 | Classification loss: 0.18703 | Regression loss: 0.46555 | Running loss: 0.85717\n",
      "Epoch: 2 | Iteration: 550 | Classification loss: 0.19647 | Regression loss: 0.26499 | Running loss: 0.85617\n",
      "Epoch: 2 | Iteration: 551 | Classification loss: 0.26561 | Regression loss: 0.59543 | Running loss: 0.85626\n",
      "Epoch: 2 | Iteration: 552 | Classification loss: 0.39171 | Regression loss: 0.45549 | Running loss: 0.85630\n",
      "Epoch: 2 | Iteration: 553 | Classification loss: 0.47381 | Regression loss: 0.62477 | Running loss: 0.85688\n",
      "Epoch: 2 | Iteration: 554 | Classification loss: 0.24725 | Regression loss: 0.69182 | Running loss: 0.85656\n",
      "Epoch: 2 | Iteration: 555 | Classification loss: 0.32205 | Regression loss: 0.36107 | Running loss: 0.85612\n",
      "Epoch: 2 | Iteration: 556 | Classification loss: 0.42984 | Regression loss: 0.32369 | Running loss: 0.85508\n",
      "Epoch: 2 | Iteration: 557 | Classification loss: 0.35176 | Regression loss: 0.71925 | Running loss: 0.85592\n",
      "Epoch: 2 | Iteration: 558 | Classification loss: 0.46088 | Regression loss: 0.35528 | Running loss: 0.85544\n",
      "Epoch: 2 | Iteration: 559 | Classification loss: 0.27806 | Regression loss: 0.39666 | Running loss: 0.85566\n",
      "Epoch: 2 | Iteration: 560 | Classification loss: 0.51847 | Regression loss: 0.52914 | Running loss: 0.85609\n",
      "Epoch: 2 | Iteration: 561 | Classification loss: 0.40379 | Regression loss: 0.45213 | Running loss: 0.85564\n",
      "Epoch: 2 | Iteration: 562 | Classification loss: 0.25745 | Regression loss: 0.43477 | Running loss: 0.85538\n",
      "Epoch: 2 | Iteration: 563 | Classification loss: 0.45565 | Regression loss: 0.52499 | Running loss: 0.85610\n",
      "Epoch: 2 | Iteration: 564 | Classification loss: 0.25645 | Regression loss: 0.46273 | Running loss: 0.85525\n",
      "Epoch: 2 | Iteration: 565 | Classification loss: 0.25106 | Regression loss: 0.34465 | Running loss: 0.85403\n",
      "Epoch: 2 | Iteration: 566 | Classification loss: 0.39452 | Regression loss: 0.73636 | Running loss: 0.85389\n",
      "Epoch: 2 | Iteration: 567 | Classification loss: 0.24633 | Regression loss: 0.47211 | Running loss: 0.85386\n",
      "Epoch: 2 | Iteration: 568 | Classification loss: 0.37829 | Regression loss: 0.51145 | Running loss: 0.85358\n",
      "Epoch: 2 | Iteration: 569 | Classification loss: 0.37067 | Regression loss: 0.76746 | Running loss: 0.85460\n",
      "Epoch: 2 | Iteration: 570 | Classification loss: 0.35513 | Regression loss: 0.37706 | Running loss: 0.85469\n",
      "Epoch: 2 | Iteration: 571 | Classification loss: 0.36832 | Regression loss: 0.38468 | Running loss: 0.85391\n",
      "Epoch: 2 | Iteration: 572 | Classification loss: 0.28201 | Regression loss: 0.36699 | Running loss: 0.85311\n",
      "Epoch: 2 | Iteration: 573 | Classification loss: 0.27966 | Regression loss: 0.41707 | Running loss: 0.85298\n",
      "Epoch: 2 | Iteration: 574 | Classification loss: 0.50737 | Regression loss: 0.47284 | Running loss: 0.85360\n",
      "Epoch: 2 | Iteration: 575 | Classification loss: 0.27881 | Regression loss: 0.39780 | Running loss: 0.85289\n",
      "Epoch: 2 | Iteration: 576 | Classification loss: 0.40801 | Regression loss: 0.45273 | Running loss: 0.85264\n",
      "Epoch: 2 | Iteration: 577 | Classification loss: 0.30594 | Regression loss: 0.43063 | Running loss: 0.85207\n",
      "Epoch: 2 | Iteration: 578 | Classification loss: 0.54875 | Regression loss: 0.53478 | Running loss: 0.85280\n",
      "Epoch: 2 | Iteration: 579 | Classification loss: 0.41727 | Regression loss: 0.82577 | Running loss: 0.85308\n",
      "Epoch: 2 | Iteration: 580 | Classification loss: 0.44355 | Regression loss: 0.59025 | Running loss: 0.85416\n",
      "Epoch: 2 | Iteration: 581 | Classification loss: 0.33302 | Regression loss: 0.32651 | Running loss: 0.85300\n",
      "Epoch: 2 | Iteration: 582 | Classification loss: 0.41992 | Regression loss: 0.65765 | Running loss: 0.85304\n",
      "Epoch: 2 | Iteration: 583 | Classification loss: 0.21509 | Regression loss: 0.30415 | Running loss: 0.85221\n",
      "Epoch: 2 | Iteration: 584 | Classification loss: 0.26587 | Regression loss: 0.51621 | Running loss: 0.85154\n",
      "Epoch: 2 | Iteration: 585 | Classification loss: 0.25108 | Regression loss: 0.31982 | Running loss: 0.85098\n",
      "Epoch: 2 | Iteration: 586 | Classification loss: 0.25261 | Regression loss: 0.58382 | Running loss: 0.85107\n",
      "Epoch: 2 | Iteration: 587 | Classification loss: 0.39514 | Regression loss: 0.36226 | Running loss: 0.85124\n",
      "Epoch: 2 | Iteration: 588 | Classification loss: 0.31741 | Regression loss: 0.48331 | Running loss: 0.84971\n",
      "Epoch: 2 | Iteration: 589 | Classification loss: 0.32963 | Regression loss: 0.35958 | Running loss: 0.84937\n",
      "Epoch: 2 | Iteration: 590 | Classification loss: 0.57797 | Regression loss: 0.74576 | Running loss: 0.85038\n",
      "Epoch: 2 | Iteration: 591 | Classification loss: 0.30262 | Regression loss: 0.37980 | Running loss: 0.85008\n",
      "Epoch: 2 | Iteration: 592 | Classification loss: 0.40194 | Regression loss: 0.48446 | Running loss: 0.85069\n",
      "Epoch: 2 | Iteration: 593 | Classification loss: 0.40349 | Regression loss: 0.45187 | Running loss: 0.84948\n",
      "Epoch: 2 | Iteration: 594 | Classification loss: 0.38041 | Regression loss: 0.57027 | Running loss: 0.84817\n",
      "Epoch: 2 | Iteration: 595 | Classification loss: 0.36604 | Regression loss: 0.28330 | Running loss: 0.84834\n",
      "Epoch: 2 | Iteration: 596 | Classification loss: 0.40568 | Regression loss: 0.41531 | Running loss: 0.84841\n",
      "Epoch: 2 | Iteration: 597 | Classification loss: 0.49914 | Regression loss: 0.56238 | Running loss: 0.84814\n",
      "Epoch: 2 | Iteration: 598 | Classification loss: 0.32454 | Regression loss: 0.53610 | Running loss: 0.84800\n",
      "Epoch: 2 | Iteration: 599 | Classification loss: 0.31900 | Regression loss: 0.44313 | Running loss: 0.84717\n",
      "Epoch: 2 | Iteration: 600 | Classification loss: 0.43528 | Regression loss: 0.56541 | Running loss: 0.84742\n",
      "Epoch: 2 | Iteration: 601 | Classification loss: 0.47412 | Regression loss: 0.68021 | Running loss: 0.84842\n",
      "Epoch: 2 | Iteration: 602 | Classification loss: 0.22956 | Regression loss: 0.40571 | Running loss: 0.84802\n",
      "Epoch: 2 | Iteration: 603 | Classification loss: 0.36184 | Regression loss: 0.35620 | Running loss: 0.84776\n",
      "Epoch: 2 | Iteration: 604 | Classification loss: 0.33203 | Regression loss: 0.59201 | Running loss: 0.84842\n",
      "Epoch: 2 | Iteration: 605 | Classification loss: 0.27680 | Regression loss: 0.60077 | Running loss: 0.84810\n",
      "Epoch: 2 | Iteration: 606 | Classification loss: 0.53939 | Regression loss: 0.56179 | Running loss: 0.84765\n",
      "Epoch: 2 | Iteration: 607 | Classification loss: 0.32917 | Regression loss: 0.57642 | Running loss: 0.84830\n",
      "Epoch: 2 | Iteration: 608 | Classification loss: 0.29617 | Regression loss: 0.39122 | Running loss: 0.84808\n",
      "Epoch: 2 | Iteration: 609 | Classification loss: 0.78067 | Regression loss: 0.77886 | Running loss: 0.84955\n",
      "Epoch: 2 | Iteration: 610 | Classification loss: 0.36168 | Regression loss: 0.24193 | Running loss: 0.84867\n",
      "Epoch: 2 | Iteration: 611 | Classification loss: 0.34285 | Regression loss: 0.40047 | Running loss: 0.84841\n",
      "Epoch: 2 | Iteration: 612 | Classification loss: 0.42951 | Regression loss: 0.82885 | Running loss: 0.84903\n",
      "Epoch: 2 | Iteration: 613 | Classification loss: 0.49003 | Regression loss: 0.74989 | Running loss: 0.84936\n",
      "Epoch: 2 | Iteration: 614 | Classification loss: 0.51564 | Regression loss: 0.51312 | Running loss: 0.84955\n",
      "Epoch: 2 | Iteration: 615 | Classification loss: 0.33970 | Regression loss: 0.50407 | Running loss: 0.84974\n",
      "Epoch: 2 | Iteration: 616 | Classification loss: 0.38813 | Regression loss: 0.45325 | Running loss: 0.84987\n",
      "Epoch: 2 | Iteration: 617 | Classification loss: 0.43574 | Regression loss: 0.55640 | Running loss: 0.84995\n",
      "Epoch: 2 | Iteration: 618 | Classification loss: 0.26087 | Regression loss: 0.49329 | Running loss: 0.84905\n",
      "Epoch: 2 | Iteration: 619 | Classification loss: 0.30098 | Regression loss: 0.30560 | Running loss: 0.84867\n",
      "Epoch: 2 | Iteration: 620 | Classification loss: 0.22857 | Regression loss: 0.31582 | Running loss: 0.84887\n",
      "Epoch: 2 | Iteration: 621 | Classification loss: 0.28773 | Regression loss: 0.45431 | Running loss: 0.84861\n",
      "Epoch: 2 | Iteration: 622 | Classification loss: 0.34308 | Regression loss: 0.40161 | Running loss: 0.84907\n",
      "Epoch: 2 | Iteration: 623 | Classification loss: 0.25211 | Regression loss: 0.31248 | Running loss: 0.84847\n",
      "Epoch: 2 | Iteration: 624 | Classification loss: 0.33634 | Regression loss: 0.46635 | Running loss: 0.84765\n",
      "Epoch: 2 | Iteration: 625 | Classification loss: 0.54424 | Regression loss: 0.77104 | Running loss: 0.84785\n",
      "Epoch: 2 | Iteration: 626 | Classification loss: 0.27103 | Regression loss: 0.51205 | Running loss: 0.84808\n",
      "Epoch: 2 | Iteration: 627 | Classification loss: 0.29881 | Regression loss: 0.39933 | Running loss: 0.84806\n",
      "Epoch: 2 | Iteration: 628 | Classification loss: 0.31603 | Regression loss: 0.29247 | Running loss: 0.84714\n",
      "Epoch: 2 | Iteration: 629 | Classification loss: 0.34937 | Regression loss: 0.29971 | Running loss: 0.84709\n",
      "Epoch: 2 | Iteration: 630 | Classification loss: 0.20397 | Regression loss: 0.34244 | Running loss: 0.84624\n",
      "Epoch: 2 | Iteration: 631 | Classification loss: 0.35946 | Regression loss: 0.43758 | Running loss: 0.84603\n",
      "Epoch: 2 | Iteration: 632 | Classification loss: 0.38859 | Regression loss: 0.39294 | Running loss: 0.84558\n",
      "Epoch: 2 | Iteration: 633 | Classification loss: 0.62587 | Regression loss: 0.42985 | Running loss: 0.84668\n",
      "Epoch: 2 | Iteration: 634 | Classification loss: 0.20583 | Regression loss: 0.37278 | Running loss: 0.84618\n",
      "Epoch: 2 | Iteration: 635 | Classification loss: 0.32264 | Regression loss: 0.25889 | Running loss: 0.84624\n",
      "Epoch: 2 | Iteration: 636 | Classification loss: 0.28960 | Regression loss: 0.38047 | Running loss: 0.84567\n",
      "Epoch: 2 | Iteration: 637 | Classification loss: 0.22882 | Regression loss: 0.29780 | Running loss: 0.84438\n",
      "Epoch: 2 | Iteration: 638 | Classification loss: 0.25282 | Regression loss: 0.34022 | Running loss: 0.84430\n",
      "Epoch: 2 | Iteration: 639 | Classification loss: 0.30167 | Regression loss: 0.43693 | Running loss: 0.84436\n",
      "Epoch: 2 | Iteration: 640 | Classification loss: 0.22994 | Regression loss: 0.35096 | Running loss: 0.84399\n",
      "Epoch: 2 | Iteration: 641 | Classification loss: 0.42501 | Regression loss: 0.31407 | Running loss: 0.84281\n",
      "Epoch: 2 | Iteration: 642 | Classification loss: 0.25657 | Regression loss: 0.59493 | Running loss: 0.84282\n",
      "Epoch: 2 | Iteration: 643 | Classification loss: 0.26466 | Regression loss: 0.37130 | Running loss: 0.84211\n",
      "Epoch: 2 | Iteration: 644 | Classification loss: 0.29560 | Regression loss: 0.51945 | Running loss: 0.84155\n",
      "Epoch: 2 | Iteration: 645 | Classification loss: 0.37526 | Regression loss: 0.28002 | Running loss: 0.84141\n",
      "Epoch: 2 | Iteration: 646 | Classification loss: 0.30247 | Regression loss: 0.20077 | Running loss: 0.84120\n",
      "Epoch: 2 | Iteration: 647 | Classification loss: 0.42637 | Regression loss: 0.77545 | Running loss: 0.84145\n",
      "Epoch: 2 | Iteration: 648 | Classification loss: 0.30892 | Regression loss: 0.50113 | Running loss: 0.84110\n",
      "Epoch: 2 | Iteration: 649 | Classification loss: 0.19454 | Regression loss: 0.21548 | Running loss: 0.83966\n",
      "Epoch: 2 | Iteration: 650 | Classification loss: 0.34426 | Regression loss: 0.51476 | Running loss: 0.83935\n",
      "Epoch: 2 | Iteration: 651 | Classification loss: 0.34432 | Regression loss: 0.51162 | Running loss: 0.83987\n",
      "Epoch: 2 | Iteration: 652 | Classification loss: 0.49916 | Regression loss: 0.59113 | Running loss: 0.84045\n",
      "Epoch: 2 | Iteration: 653 | Classification loss: 0.36672 | Regression loss: 0.32271 | Running loss: 0.84012\n",
      "Epoch: 2 | Iteration: 654 | Classification loss: 0.67058 | Regression loss: 0.80289 | Running loss: 0.84164\n",
      "Epoch: 2 | Iteration: 655 | Classification loss: 0.48444 | Regression loss: 0.54209 | Running loss: 0.84223\n",
      "Epoch: 2 | Iteration: 656 | Classification loss: 0.39601 | Regression loss: 0.44137 | Running loss: 0.84214\n",
      "Epoch: 2 | Iteration: 657 | Classification loss: 2.46580 | Regression loss: 0.00000 | Running loss: 0.84548\n",
      "Epoch: 2 | Iteration: 658 | Classification loss: 0.38898 | Regression loss: 0.23115 | Running loss: 0.84366\n",
      "Epoch: 2 | Iteration: 659 | Classification loss: 0.43707 | Regression loss: 0.59389 | Running loss: 0.84441\n",
      "Epoch: 2 | Iteration: 660 | Classification loss: 0.25400 | Regression loss: 0.39413 | Running loss: 0.84471\n",
      "Epoch: 2 | Iteration: 661 | Classification loss: 0.19127 | Regression loss: 0.35050 | Running loss: 0.84372\n",
      "Epoch: 2 | Iteration: 662 | Classification loss: 0.31839 | Regression loss: 0.43115 | Running loss: 0.84371\n",
      "Epoch: 2 | Iteration: 663 | Classification loss: 0.57422 | Regression loss: 0.66949 | Running loss: 0.84420\n",
      "Epoch: 2 | Iteration: 664 | Classification loss: 0.51363 | Regression loss: 0.76935 | Running loss: 0.84502\n",
      "Epoch: 2 | Iteration: 665 | Classification loss: 0.53630 | Regression loss: 0.49633 | Running loss: 0.84589\n",
      "Epoch: 2 | Iteration: 666 | Classification loss: 0.32531 | Regression loss: 0.45534 | Running loss: 0.84640\n",
      "Epoch: 2 | Iteration: 667 | Classification loss: 0.50781 | Regression loss: 0.77683 | Running loss: 0.84768\n",
      "Epoch: 2 | Iteration: 668 | Classification loss: 0.41693 | Regression loss: 0.54643 | Running loss: 0.84839\n",
      "Epoch: 2 | Iteration: 669 | Classification loss: 0.32841 | Regression loss: 0.56652 | Running loss: 0.84573\n",
      "Epoch: 2 | Iteration: 670 | Classification loss: 0.26550 | Regression loss: 0.56285 | Running loss: 0.84512\n",
      "Epoch: 2 | Iteration: 671 | Classification loss: 0.13738 | Regression loss: 0.36329 | Running loss: 0.84358\n",
      "Epoch: 2 | Iteration: 672 | Classification loss: 0.46719 | Regression loss: 0.38570 | Running loss: 0.84430\n",
      "Epoch: 2 | Iteration: 673 | Classification loss: 0.35181 | Regression loss: 0.47936 | Running loss: 0.84410\n",
      "Epoch: 2 | Iteration: 674 | Classification loss: 0.30158 | Regression loss: 0.67677 | Running loss: 0.84397\n",
      "Epoch: 2 | Iteration: 675 | Classification loss: 0.44310 | Regression loss: 0.59239 | Running loss: 0.84406\n",
      "Epoch: 2 | Iteration: 676 | Classification loss: 0.39703 | Regression loss: 0.56794 | Running loss: 0.84443\n",
      "Epoch: 2 | Iteration: 677 | Classification loss: 0.14122 | Regression loss: 0.44672 | Running loss: 0.84260\n",
      "Epoch: 2 | Iteration: 678 | Classification loss: 0.24697 | Regression loss: 0.51240 | Running loss: 0.84156\n",
      "Epoch: 2 | Iteration: 679 | Classification loss: 0.15203 | Regression loss: 0.44133 | Running loss: 0.84134\n",
      "Epoch: 2 | Iteration: 680 | Classification loss: 0.44484 | Regression loss: 0.60195 | Running loss: 0.84186\n",
      "Epoch: 2 | Iteration: 681 | Classification loss: 0.42636 | Regression loss: 1.07882 | Running loss: 0.84207\n",
      "Epoch: 2 | Iteration: 682 | Classification loss: 0.35131 | Regression loss: 0.47822 | Running loss: 0.84253\n",
      "Epoch: 2 | Iteration: 683 | Classification loss: 0.21499 | Regression loss: 0.45456 | Running loss: 0.84296\n",
      "Epoch: 2 | Iteration: 684 | Classification loss: 0.45968 | Regression loss: 0.34330 | Running loss: 0.84274\n",
      "Epoch: 2 | Iteration: 685 | Classification loss: 0.39209 | Regression loss: 0.26835 | Running loss: 0.84306\n",
      "Epoch: 2 | Iteration: 686 | Classification loss: 0.25743 | Regression loss: 0.32026 | Running loss: 0.84202\n",
      "Epoch: 2 | Iteration: 687 | Classification loss: 0.51860 | Regression loss: 0.49589 | Running loss: 0.84218\n",
      "Epoch: 2 | Iteration: 688 | Classification loss: 0.29000 | Regression loss: 0.31872 | Running loss: 0.84168\n",
      "Epoch: 2 | Iteration: 689 | Classification loss: 0.72155 | Regression loss: 0.73188 | Running loss: 0.84273\n",
      "Epoch: 2 | Iteration: 690 | Classification loss: 0.24972 | Regression loss: 0.35724 | Running loss: 0.84163\n",
      "Epoch: 2 | Iteration: 691 | Classification loss: 0.27905 | Regression loss: 0.43874 | Running loss: 0.84117\n",
      "Epoch: 2 | Iteration: 692 | Classification loss: 0.18412 | Regression loss: 0.42588 | Running loss: 0.84037\n",
      "Epoch: 2 | Iteration: 693 | Classification loss: 0.17875 | Regression loss: 0.27340 | Running loss: 0.83852\n",
      "Epoch: 2 | Iteration: 694 | Classification loss: 0.25802 | Regression loss: 0.42014 | Running loss: 0.83893\n",
      "Epoch: 2 | Iteration: 695 | Classification loss: 0.27178 | Regression loss: 0.48420 | Running loss: 0.83796\n",
      "Epoch: 2 | Iteration: 696 | Classification loss: 0.58078 | Regression loss: 0.94624 | Running loss: 0.83920\n",
      "Epoch: 2 | Iteration: 697 | Classification loss: 0.53408 | Regression loss: 0.65509 | Running loss: 0.84026\n",
      "Epoch: 2 | Iteration: 698 | Classification loss: 0.51703 | Regression loss: 0.60799 | Running loss: 0.84068\n",
      "Epoch: 2 | Iteration: 699 | Classification loss: 0.36053 | Regression loss: 0.24522 | Running loss: 0.84039\n",
      "Epoch: 2 | Iteration: 700 | Classification loss: 0.29411 | Regression loss: 0.31813 | Running loss: 0.83974\n",
      "Epoch: 2 | Iteration: 701 | Classification loss: 0.33428 | Regression loss: 0.45253 | Running loss: 0.84034\n",
      "Epoch: 2 | Iteration: 702 | Classification loss: 0.27624 | Regression loss: 0.55608 | Running loss: 0.84076\n",
      "Epoch: 2 | Iteration: 703 | Classification loss: 0.39960 | Regression loss: 0.53966 | Running loss: 0.84091\n",
      "Epoch: 2 | Iteration: 704 | Classification loss: 0.48566 | Regression loss: 0.43261 | Running loss: 0.84028\n",
      "Epoch: 2 | Iteration: 705 | Classification loss: 0.29448 | Regression loss: 0.44265 | Running loss: 0.84040\n",
      "Epoch: 2 | Iteration: 706 | Classification loss: 0.36575 | Regression loss: 0.40395 | Running loss: 0.84022\n",
      "Epoch: 2 | Iteration: 707 | Classification loss: 0.28344 | Regression loss: 0.42563 | Running loss: 0.83930\n",
      "Epoch: 2 | Iteration: 708 | Classification loss: 0.42016 | Regression loss: 0.39266 | Running loss: 0.83805\n",
      "Epoch: 2 | Iteration: 709 | Classification loss: 0.31039 | Regression loss: 0.27798 | Running loss: 0.83759\n",
      "Epoch: 2 | Iteration: 710 | Classification loss: 0.15390 | Regression loss: 0.45755 | Running loss: 0.83718\n",
      "Epoch: 2 | Iteration: 711 | Classification loss: 0.34773 | Regression loss: 0.39176 | Running loss: 0.83753\n",
      "Epoch: 2 | Iteration: 712 | Classification loss: 0.22736 | Regression loss: 0.31075 | Running loss: 0.83631\n",
      "Epoch: 2 | Iteration: 713 | Classification loss: 0.66783 | Regression loss: 0.53753 | Running loss: 0.83728\n",
      "Epoch: 2 | Iteration: 714 | Classification loss: 0.37851 | Regression loss: 0.46590 | Running loss: 0.83702\n",
      "Epoch: 2 | Iteration: 715 | Classification loss: 0.20456 | Regression loss: 0.35936 | Running loss: 0.83650\n",
      "Epoch: 2 | Iteration: 716 | Classification loss: 0.31025 | Regression loss: 0.52762 | Running loss: 0.83587\n",
      "Epoch: 2 | Iteration: 717 | Classification loss: 0.35451 | Regression loss: 0.44484 | Running loss: 0.83578\n",
      "Epoch: 2 | Iteration: 718 | Classification loss: 0.24685 | Regression loss: 0.46552 | Running loss: 0.83561\n",
      "Epoch: 2 | Iteration: 719 | Classification loss: 0.19076 | Regression loss: 0.28283 | Running loss: 0.83458\n",
      "Epoch: 2 | Iteration: 720 | Classification loss: 0.47088 | Regression loss: 0.24504 | Running loss: 0.83468\n",
      "Epoch: 2 | Iteration: 721 | Classification loss: 0.13274 | Regression loss: 0.33130 | Running loss: 0.83364\n",
      "Epoch: 2 | Iteration: 722 | Classification loss: 0.32387 | Regression loss: 0.57072 | Running loss: 0.83374\n",
      "Epoch: 2 | Iteration: 723 | Classification loss: 0.28809 | Regression loss: 0.36836 | Running loss: 0.83344\n",
      "Epoch: 2 | Iteration: 724 | Classification loss: 0.35717 | Regression loss: 0.17240 | Running loss: 0.83350\n",
      "Epoch: 2 | Iteration: 725 | Classification loss: 0.40401 | Regression loss: 0.67428 | Running loss: 0.83390\n",
      "Epoch: 2 | Iteration: 726 | Classification loss: 0.47803 | Regression loss: 0.68094 | Running loss: 0.83339\n",
      "Epoch: 2 | Iteration: 727 | Classification loss: 0.25059 | Regression loss: 0.41468 | Running loss: 0.83297\n",
      "Epoch: 2 | Iteration: 728 | Classification loss: 0.19534 | Regression loss: 0.18101 | Running loss: 0.83145\n",
      "Epoch: 2 | Iteration: 729 | Classification loss: 0.36139 | Regression loss: 0.32460 | Running loss: 0.83177\n",
      "Epoch: 2 | Iteration: 730 | Classification loss: 0.23281 | Regression loss: 0.21490 | Running loss: 0.83031\n",
      "Epoch: 2 | Iteration: 731 | Classification loss: 0.36962 | Regression loss: 0.43136 | Running loss: 0.83002\n",
      "Epoch: 2 | Iteration: 732 | Classification loss: 0.33109 | Regression loss: 0.71966 | Running loss: 0.83031\n",
      "Epoch: 2 | Iteration: 733 | Classification loss: 0.60544 | Regression loss: 0.71491 | Running loss: 0.83101\n",
      "Epoch: 2 | Iteration: 734 | Classification loss: 0.40854 | Regression loss: 0.44429 | Running loss: 0.82990\n",
      "Epoch: 2 | Iteration: 735 | Classification loss: 0.40855 | Regression loss: 0.23175 | Running loss: 0.82936\n",
      "Epoch: 2 | Iteration: 736 | Classification loss: 0.37672 | Regression loss: 0.44180 | Running loss: 0.82876\n",
      "Epoch: 2 | Iteration: 737 | Classification loss: 0.16358 | Regression loss: 0.40203 | Running loss: 0.82846\n",
      "Epoch: 2 | Iteration: 738 | Classification loss: 0.21506 | Regression loss: 0.43706 | Running loss: 0.82821\n",
      "Epoch: 2 | Iteration: 739 | Classification loss: 0.47056 | Regression loss: 0.61168 | Running loss: 0.82951\n",
      "Epoch: 2 | Iteration: 740 | Classification loss: 0.39478 | Regression loss: 0.55862 | Running loss: 0.82911\n",
      "Epoch: 2 | Iteration: 741 | Classification loss: 0.18603 | Regression loss: 0.36851 | Running loss: 0.82807\n",
      "Epoch: 2 | Iteration: 742 | Classification loss: 0.44901 | Regression loss: 0.60344 | Running loss: 0.82939\n",
      "Epoch: 2 | Iteration: 743 | Classification loss: 0.16352 | Regression loss: 0.41161 | Running loss: 0.82960\n",
      "Epoch: 2 | Iteration: 744 | Classification loss: 0.34454 | Regression loss: 0.25801 | Running loss: 0.82794\n",
      "Epoch: 2 | Iteration: 745 | Classification loss: 0.38833 | Regression loss: 0.46313 | Running loss: 0.82761\n",
      "Epoch: 2 | Iteration: 746 | Classification loss: 0.27937 | Regression loss: 0.42226 | Running loss: 0.82745\n",
      "Epoch: 2 | Iteration: 747 | Classification loss: 0.38041 | Regression loss: 0.48884 | Running loss: 0.82806\n",
      "Epoch: 2 | Iteration: 748 | Classification loss: 0.36218 | Regression loss: 0.36266 | Running loss: 0.82822\n",
      "Epoch: 2 | Iteration: 749 | Classification loss: 0.35324 | Regression loss: 0.36128 | Running loss: 0.82866\n",
      "Epoch: 2 | Iteration: 750 | Classification loss: 0.40605 | Regression loss: 0.71428 | Running loss: 0.82854\n",
      "Epoch: 2 | Iteration: 751 | Classification loss: 0.26813 | Regression loss: 0.30648 | Running loss: 0.82844\n",
      "Epoch: 2 | Iteration: 752 | Classification loss: 0.55189 | Regression loss: 0.86737 | Running loss: 0.82893\n",
      "Epoch: 2 | Iteration: 753 | Classification loss: 0.33159 | Regression loss: 0.37620 | Running loss: 0.82862\n",
      "Epoch: 2 | Iteration: 754 | Classification loss: 0.32862 | Regression loss: 0.80820 | Running loss: 0.82925\n",
      "Epoch: 2 | Iteration: 755 | Classification loss: 0.30090 | Regression loss: 0.32646 | Running loss: 0.82901\n",
      "Epoch: 2 | Iteration: 756 | Classification loss: 0.53336 | Regression loss: 0.19977 | Running loss: 0.82736\n",
      "Epoch: 2 | Iteration: 757 | Classification loss: 0.57567 | Regression loss: 0.70813 | Running loss: 0.82768\n",
      "Epoch: 2 | Iteration: 758 | Classification loss: 0.31092 | Regression loss: 0.54545 | Running loss: 0.82732\n",
      "Epoch: 2 | Iteration: 759 | Classification loss: 0.39409 | Regression loss: 0.41520 | Running loss: 0.82752\n",
      "Epoch: 2 | Iteration: 760 | Classification loss: 0.42891 | Regression loss: 0.48158 | Running loss: 0.82735\n",
      "Epoch: 2 | Iteration: 761 | Classification loss: 0.24492 | Regression loss: 0.43880 | Running loss: 0.82731\n",
      "Epoch: 2 | Iteration: 762 | Classification loss: 0.28153 | Regression loss: 0.49881 | Running loss: 0.82750\n",
      "Epoch: 2 | Iteration: 763 | Classification loss: 0.49639 | Regression loss: 1.27678 | Running loss: 0.82917\n",
      "Epoch: 2 | Iteration: 764 | Classification loss: 0.31231 | Regression loss: 0.27422 | Running loss: 0.82867\n",
      "Epoch: 2 | Iteration: 765 | Classification loss: 0.30915 | Regression loss: 0.43011 | Running loss: 0.82838\n",
      "Epoch: 2 | Iteration: 766 | Classification loss: 0.31768 | Regression loss: 0.39822 | Running loss: 0.82836\n",
      "Epoch: 2 | Iteration: 767 | Classification loss: 0.24807 | Regression loss: 0.48312 | Running loss: 0.82888\n",
      "Epoch: 2 | Iteration: 768 | Classification loss: 0.23336 | Regression loss: 0.37369 | Running loss: 0.82805\n",
      "Epoch: 2 | Iteration: 769 | Classification loss: 0.34496 | Regression loss: 0.60067 | Running loss: 0.82850\n",
      "Epoch: 2 | Iteration: 770 | Classification loss: 0.42425 | Regression loss: 0.89447 | Running loss: 0.82875\n",
      "Epoch: 2 | Iteration: 771 | Classification loss: 0.20328 | Regression loss: 0.39871 | Running loss: 0.82831\n",
      "Epoch: 2 | Iteration: 772 | Classification loss: 0.24681 | Regression loss: 0.33803 | Running loss: 0.82736\n",
      "Epoch: 2 | Iteration: 773 | Classification loss: 0.45535 | Regression loss: 0.55706 | Running loss: 0.82765\n",
      "Epoch: 2 | Iteration: 774 | Classification loss: 0.25341 | Regression loss: 0.55456 | Running loss: 0.82673\n",
      "Epoch: 2 | Iteration: 775 | Classification loss: 0.49446 | Regression loss: 0.84952 | Running loss: 0.82809\n",
      "Epoch: 2 | Iteration: 776 | Classification loss: 0.48703 | Regression loss: 0.71352 | Running loss: 0.82789\n",
      "Epoch: 2 | Iteration: 777 | Classification loss: 0.20162 | Regression loss: 0.63540 | Running loss: 0.82834\n",
      "Epoch: 2 | Iteration: 778 | Classification loss: 0.20349 | Regression loss: 0.38443 | Running loss: 0.82786\n",
      "Epoch: 2 | Iteration: 779 | Classification loss: 0.23585 | Regression loss: 0.42632 | Running loss: 0.82700\n",
      "Epoch: 2 | Iteration: 780 | Classification loss: 0.34365 | Regression loss: 0.25124 | Running loss: 0.82662\n",
      "Epoch: 2 | Iteration: 781 | Classification loss: 0.40319 | Regression loss: 0.31107 | Running loss: 0.82621\n",
      "Epoch: 2 | Iteration: 782 | Classification loss: 0.34529 | Regression loss: 0.36532 | Running loss: 0.82610\n",
      "Epoch: 2 | Iteration: 783 | Classification loss: 0.33809 | Regression loss: 0.36290 | Running loss: 0.82608\n",
      "Epoch: 2 | Iteration: 784 | Classification loss: 0.26876 | Regression loss: 0.59598 | Running loss: 0.82616\n",
      "Epoch: 2 | Iteration: 785 | Classification loss: 0.30906 | Regression loss: 0.71415 | Running loss: 0.82715\n",
      "Epoch: 2 | Iteration: 786 | Classification loss: 0.35136 | Regression loss: 0.50069 | Running loss: 0.82711\n",
      "Epoch: 2 | Iteration: 787 | Classification loss: 0.22986 | Regression loss: 0.29239 | Running loss: 0.82661\n",
      "Epoch: 2 | Iteration: 788 | Classification loss: 0.36175 | Regression loss: 0.44844 | Running loss: 0.82689\n",
      "Epoch: 2 | Iteration: 789 | Classification loss: 0.42867 | Regression loss: 0.66350 | Running loss: 0.82747\n",
      "Epoch: 2 | Iteration: 790 | Classification loss: 0.53492 | Regression loss: 0.77513 | Running loss: 0.82914\n",
      "Epoch: 2 | Iteration: 791 | Classification loss: 0.31404 | Regression loss: 0.66204 | Running loss: 0.82892\n",
      "Epoch: 2 | Iteration: 792 | Classification loss: 0.19009 | Regression loss: 0.18711 | Running loss: 0.82852\n",
      "Epoch: 2 | Iteration: 793 | Classification loss: 0.29509 | Regression loss: 0.51607 | Running loss: 0.82843\n",
      "Epoch: 2 | Iteration: 794 | Classification loss: 0.21000 | Regression loss: 0.27961 | Running loss: 0.82838\n",
      "Epoch: 2 | Iteration: 795 | Classification loss: 0.41157 | Regression loss: 0.79025 | Running loss: 0.82910\n",
      "Epoch: 2 | Iteration: 796 | Classification loss: 0.38083 | Regression loss: 0.35356 | Running loss: 0.82855\n",
      "Epoch: 2 | Iteration: 797 | Classification loss: 0.13910 | Regression loss: 0.25541 | Running loss: 0.82792\n",
      "Epoch: 2 | Iteration: 798 | Classification loss: 0.29693 | Regression loss: 0.76726 | Running loss: 0.82876\n",
      "Epoch: 2 | Iteration: 799 | Classification loss: 0.25874 | Regression loss: 0.29163 | Running loss: 0.82792\n",
      "Epoch: 2 | Iteration: 800 | Classification loss: 0.24950 | Regression loss: 0.43150 | Running loss: 0.82715\n",
      "Epoch: 2 | Iteration: 801 | Classification loss: 0.26732 | Regression loss: 0.37739 | Running loss: 0.82700\n",
      "Epoch: 2 | Iteration: 802 | Classification loss: 0.42545 | Regression loss: 0.49446 | Running loss: 0.82639\n",
      "Epoch: 2 | Iteration: 803 | Classification loss: 0.36390 | Regression loss: 0.28635 | Running loss: 0.82573\n",
      "Epoch: 2 | Iteration: 804 | Classification loss: 0.16871 | Regression loss: 0.39850 | Running loss: 0.82484\n",
      "Epoch: 2 | Iteration: 805 | Classification loss: 0.63957 | Regression loss: 0.83638 | Running loss: 0.82648\n",
      "Epoch: 2 | Iteration: 806 | Classification loss: 0.17717 | Regression loss: 0.37110 | Running loss: 0.82601\n",
      "Epoch: 2 | Iteration: 807 | Classification loss: 0.32318 | Regression loss: 0.56731 | Running loss: 0.82577\n",
      "Epoch: 2 | Iteration: 808 | Classification loss: 0.68880 | Regression loss: 1.16419 | Running loss: 0.82794\n",
      "Epoch: 2 | Iteration: 809 | Classification loss: 0.13152 | Regression loss: 0.23508 | Running loss: 0.82758\n",
      "Epoch: 2 | Iteration: 810 | Classification loss: 0.27961 | Regression loss: 0.38104 | Running loss: 0.82652\n",
      "Epoch: 2 | Iteration: 811 | Classification loss: 0.61881 | Regression loss: 0.42569 | Running loss: 0.82764\n",
      "Epoch: 2 | Iteration: 812 | Classification loss: 0.33122 | Regression loss: 0.29672 | Running loss: 0.82756\n",
      "Epoch: 2 | Iteration: 813 | Classification loss: 0.21232 | Regression loss: 0.45074 | Running loss: 0.82712\n",
      "Epoch: 2 | Iteration: 814 | Classification loss: 0.38136 | Regression loss: 0.54269 | Running loss: 0.82771\n",
      "Epoch: 2 | Iteration: 815 | Classification loss: 0.35613 | Regression loss: 0.36188 | Running loss: 0.82844\n",
      "Epoch: 2 | Iteration: 816 | Classification loss: 0.32682 | Regression loss: 0.62510 | Running loss: 0.82980\n",
      "Epoch: 2 | Iteration: 817 | Classification loss: 0.41170 | Regression loss: 0.71355 | Running loss: 0.83059\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.30s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.68s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 3 | Iteration: 0 | Classification loss: 0.39876 | Regression loss: 0.46661 | Running loss: 0.83139\n",
      "Epoch: 3 | Iteration: 1 | Classification loss: 0.31223 | Regression loss: 0.30979 | Running loss: 0.83030\n",
      "Epoch: 3 | Iteration: 2 | Classification loss: 0.24621 | Regression loss: 0.32825 | Running loss: 0.83059\n",
      "Epoch: 3 | Iteration: 3 | Classification loss: 0.33418 | Regression loss: 0.43426 | Running loss: 0.83011\n",
      "Epoch: 3 | Iteration: 4 | Classification loss: 0.30695 | Regression loss: 0.26020 | Running loss: 0.82957\n",
      "Epoch: 3 | Iteration: 5 | Classification loss: 0.15851 | Regression loss: 0.49827 | Running loss: 0.82878\n",
      "Epoch: 3 | Iteration: 6 | Classification loss: 0.26163 | Regression loss: 0.41049 | Running loss: 0.82820\n",
      "Epoch: 3 | Iteration: 7 | Classification loss: 0.40521 | Regression loss: 0.36834 | Running loss: 0.82808\n",
      "Epoch: 3 | Iteration: 8 | Classification loss: 0.42907 | Regression loss: 0.56022 | Running loss: 0.82863\n",
      "Epoch: 3 | Iteration: 9 | Classification loss: 0.55569 | Regression loss: 0.77274 | Running loss: 0.82788\n",
      "Epoch: 3 | Iteration: 10 | Classification loss: 0.33390 | Regression loss: 0.45969 | Running loss: 0.82786\n",
      "Epoch: 3 | Iteration: 11 | Classification loss: 0.43706 | Regression loss: 0.66536 | Running loss: 0.82883\n",
      "Epoch: 3 | Iteration: 12 | Classification loss: 0.49199 | Regression loss: 0.57223 | Running loss: 0.82947\n",
      "Epoch: 3 | Iteration: 13 | Classification loss: 0.36150 | Regression loss: 0.43059 | Running loss: 0.82833\n",
      "Epoch: 3 | Iteration: 14 | Classification loss: 0.61294 | Regression loss: 0.49273 | Running loss: 0.82890\n",
      "Epoch: 3 | Iteration: 15 | Classification loss: 0.42757 | Regression loss: 0.35109 | Running loss: 0.82889\n",
      "Epoch: 3 | Iteration: 16 | Classification loss: 0.14314 | Regression loss: 0.30066 | Running loss: 0.82827\n",
      "Epoch: 3 | Iteration: 17 | Classification loss: 0.25351 | Regression loss: 0.46266 | Running loss: 0.82892\n",
      "Epoch: 3 | Iteration: 18 | Classification loss: 0.15416 | Regression loss: 0.50083 | Running loss: 0.82704\n",
      "Epoch: 3 | Iteration: 19 | Classification loss: 0.53235 | Regression loss: 0.67740 | Running loss: 0.82837\n",
      "Epoch: 3 | Iteration: 20 | Classification loss: 0.39311 | Regression loss: 0.53719 | Running loss: 0.82919\n",
      "Epoch: 3 | Iteration: 21 | Classification loss: 0.37606 | Regression loss: 0.37483 | Running loss: 0.82850\n",
      "Epoch: 3 | Iteration: 22 | Classification loss: 0.28628 | Regression loss: 0.49916 | Running loss: 0.82756\n",
      "Epoch: 3 | Iteration: 23 | Classification loss: 0.13851 | Regression loss: 0.32568 | Running loss: 0.82679\n",
      "Epoch: 3 | Iteration: 24 | Classification loss: 0.44475 | Regression loss: 0.58657 | Running loss: 0.82658\n",
      "Epoch: 3 | Iteration: 25 | Classification loss: 0.22913 | Regression loss: 0.36657 | Running loss: 0.82600\n",
      "Epoch: 3 | Iteration: 26 | Classification loss: 0.38173 | Regression loss: 0.35504 | Running loss: 0.82630\n",
      "Epoch: 3 | Iteration: 27 | Classification loss: 0.22473 | Regression loss: 0.31813 | Running loss: 0.82590\n",
      "Epoch: 3 | Iteration: 28 | Classification loss: 0.29184 | Regression loss: 0.54565 | Running loss: 0.82633\n",
      "Epoch: 3 | Iteration: 29 | Classification loss: 0.61149 | Regression loss: 0.71273 | Running loss: 0.82750\n",
      "Epoch: 3 | Iteration: 30 | Classification loss: 0.29420 | Regression loss: 0.40027 | Running loss: 0.82779\n",
      "Epoch: 3 | Iteration: 31 | Classification loss: 0.17663 | Regression loss: 0.41484 | Running loss: 0.82739\n",
      "Epoch: 3 | Iteration: 32 | Classification loss: 0.33753 | Regression loss: 0.49199 | Running loss: 0.82748\n",
      "Epoch: 3 | Iteration: 33 | Classification loss: 0.44379 | Regression loss: 0.68085 | Running loss: 0.82834\n",
      "Epoch: 3 | Iteration: 34 | Classification loss: 0.53627 | Regression loss: 0.43699 | Running loss: 0.82847\n",
      "Epoch: 3 | Iteration: 35 | Classification loss: 0.48522 | Regression loss: 0.56316 | Running loss: 0.82819\n",
      "Epoch: 3 | Iteration: 36 | Classification loss: 0.12278 | Regression loss: 0.27134 | Running loss: 0.82779\n",
      "Epoch: 3 | Iteration: 37 | Classification loss: 0.22150 | Regression loss: 0.27997 | Running loss: 0.82721\n",
      "Epoch: 3 | Iteration: 38 | Classification loss: 0.50270 | Regression loss: 0.55532 | Running loss: 0.82783\n",
      "Epoch: 3 | Iteration: 39 | Classification loss: 0.39760 | Regression loss: 0.57624 | Running loss: 0.82821\n",
      "Epoch: 3 | Iteration: 40 | Classification loss: 0.15631 | Regression loss: 0.27013 | Running loss: 0.82760\n",
      "Epoch: 3 | Iteration: 41 | Classification loss: 0.29880 | Regression loss: 0.43804 | Running loss: 0.82824\n",
      "Epoch: 3 | Iteration: 42 | Classification loss: 0.36911 | Regression loss: 0.43524 | Running loss: 0.82795\n",
      "Epoch: 3 | Iteration: 43 | Classification loss: 0.22223 | Regression loss: 0.32594 | Running loss: 0.82782\n",
      "Epoch: 3 | Iteration: 44 | Classification loss: 0.30642 | Regression loss: 0.56709 | Running loss: 0.82823\n",
      "Epoch: 3 | Iteration: 45 | Classification loss: 0.24639 | Regression loss: 0.33144 | Running loss: 0.82739\n",
      "Epoch: 3 | Iteration: 46 | Classification loss: 0.21866 | Regression loss: 0.30707 | Running loss: 0.82691\n",
      "Epoch: 3 | Iteration: 47 | Classification loss: 0.22992 | Regression loss: 0.35209 | Running loss: 0.82605\n",
      "Epoch: 3 | Iteration: 48 | Classification loss: 0.26901 | Regression loss: 0.44354 | Running loss: 0.82572\n",
      "Epoch: 3 | Iteration: 49 | Classification loss: 0.24112 | Regression loss: 0.67755 | Running loss: 0.82480\n",
      "Epoch: 3 | Iteration: 50 | Classification loss: 0.32974 | Regression loss: 0.39082 | Running loss: 0.82468\n",
      "Epoch: 3 | Iteration: 51 | Classification loss: 0.52596 | Regression loss: 0.50109 | Running loss: 0.82519\n",
      "Epoch: 3 | Iteration: 52 | Classification loss: 0.27548 | Regression loss: 0.33311 | Running loss: 0.82476\n",
      "Epoch: 3 | Iteration: 53 | Classification loss: 0.37617 | Regression loss: 0.44666 | Running loss: 0.82392\n",
      "Epoch: 3 | Iteration: 54 | Classification loss: 0.24144 | Regression loss: 0.45985 | Running loss: 0.82298\n",
      "Epoch: 3 | Iteration: 55 | Classification loss: 0.12866 | Regression loss: 0.34261 | Running loss: 0.82238\n",
      "Epoch: 3 | Iteration: 56 | Classification loss: 0.36303 | Regression loss: 0.37807 | Running loss: 0.82251\n",
      "Epoch: 3 | Iteration: 57 | Classification loss: 0.23560 | Regression loss: 0.90047 | Running loss: 0.82265\n",
      "Epoch: 3 | Iteration: 58 | Classification loss: 0.32684 | Regression loss: 0.39889 | Running loss: 0.82180\n",
      "Epoch: 3 | Iteration: 59 | Classification loss: 0.18328 | Regression loss: 0.43840 | Running loss: 0.82119\n",
      "Epoch: 3 | Iteration: 60 | Classification loss: 0.37079 | Regression loss: 0.43475 | Running loss: 0.82157\n",
      "Epoch: 3 | Iteration: 61 | Classification loss: 0.33801 | Regression loss: 0.47325 | Running loss: 0.82147\n",
      "Epoch: 3 | Iteration: 62 | Classification loss: 0.59656 | Regression loss: 0.30733 | Running loss: 0.82177\n",
      "Epoch: 3 | Iteration: 63 | Classification loss: 0.47872 | Regression loss: 0.37191 | Running loss: 0.82157\n",
      "Epoch: 3 | Iteration: 64 | Classification loss: 0.19204 | Regression loss: 0.44537 | Running loss: 0.82127\n",
      "Epoch: 3 | Iteration: 65 | Classification loss: 0.11761 | Regression loss: 0.28145 | Running loss: 0.82073\n",
      "Epoch: 3 | Iteration: 66 | Classification loss: 0.28382 | Regression loss: 0.38096 | Running loss: 0.82081\n",
      "Epoch: 3 | Iteration: 67 | Classification loss: 0.30403 | Regression loss: 0.51166 | Running loss: 0.82110\n",
      "Epoch: 3 | Iteration: 68 | Classification loss: 0.21727 | Regression loss: 0.42109 | Running loss: 0.82027\n",
      "Epoch: 3 | Iteration: 69 | Classification loss: 0.26064 | Regression loss: 0.34778 | Running loss: 0.82026\n",
      "Epoch: 3 | Iteration: 70 | Classification loss: 0.21430 | Regression loss: 0.42712 | Running loss: 0.81965\n",
      "Epoch: 3 | Iteration: 71 | Classification loss: 0.23895 | Regression loss: 0.33207 | Running loss: 0.81938\n",
      "Epoch: 3 | Iteration: 72 | Classification loss: 0.26295 | Regression loss: 0.28743 | Running loss: 0.81849\n",
      "Epoch: 3 | Iteration: 73 | Classification loss: 0.33988 | Regression loss: 0.52621 | Running loss: 0.81739\n",
      "Epoch: 3 | Iteration: 74 | Classification loss: 0.38483 | Regression loss: 0.68726 | Running loss: 0.81830\n",
      "Epoch: 3 | Iteration: 75 | Classification loss: 0.32515 | Regression loss: 0.23489 | Running loss: 0.81730\n",
      "Epoch: 3 | Iteration: 76 | Classification loss: 0.30411 | Regression loss: 0.35814 | Running loss: 0.81678\n",
      "Epoch: 3 | Iteration: 77 | Classification loss: 0.34318 | Regression loss: 0.52977 | Running loss: 0.81704\n",
      "Epoch: 3 | Iteration: 78 | Classification loss: 0.27226 | Regression loss: 0.32365 | Running loss: 0.81675\n",
      "Epoch: 3 | Iteration: 79 | Classification loss: 0.10769 | Regression loss: 0.23546 | Running loss: 0.81606\n",
      "Epoch: 3 | Iteration: 80 | Classification loss: 0.37544 | Regression loss: 0.48893 | Running loss: 0.81595\n",
      "Epoch: 3 | Iteration: 81 | Classification loss: 0.27258 | Regression loss: 0.29885 | Running loss: 0.81587\n",
      "Epoch: 3 | Iteration: 82 | Classification loss: 0.19461 | Regression loss: 0.46410 | Running loss: 0.81512\n",
      "Epoch: 3 | Iteration: 83 | Classification loss: 0.45754 | Regression loss: 0.37789 | Running loss: 0.81523\n",
      "Epoch: 3 | Iteration: 84 | Classification loss: 0.25558 | Regression loss: 0.48431 | Running loss: 0.81517\n",
      "Epoch: 3 | Iteration: 85 | Classification loss: 0.43410 | Regression loss: 0.67552 | Running loss: 0.81572\n",
      "Epoch: 3 | Iteration: 86 | Classification loss: 0.30130 | Regression loss: 0.55668 | Running loss: 0.81588\n",
      "Epoch: 3 | Iteration: 87 | Classification loss: 0.24922 | Regression loss: 0.49461 | Running loss: 0.81563\n",
      "Epoch: 3 | Iteration: 88 | Classification loss: 0.28755 | Regression loss: 0.43945 | Running loss: 0.81639\n",
      "Epoch: 3 | Iteration: 89 | Classification loss: 0.37853 | Regression loss: 0.32573 | Running loss: 0.81590\n",
      "Epoch: 3 | Iteration: 90 | Classification loss: 0.28456 | Regression loss: 0.36796 | Running loss: 0.81605\n",
      "Epoch: 3 | Iteration: 91 | Classification loss: 0.27122 | Regression loss: 0.32415 | Running loss: 0.81607\n",
      "Epoch: 3 | Iteration: 92 | Classification loss: 0.26240 | Regression loss: 0.43179 | Running loss: 0.81637\n",
      "Epoch: 3 | Iteration: 93 | Classification loss: 0.45331 | Regression loss: 0.28449 | Running loss: 0.81707\n",
      "Epoch: 3 | Iteration: 94 | Classification loss: 0.36113 | Regression loss: 0.32129 | Running loss: 0.81620\n",
      "Epoch: 3 | Iteration: 95 | Classification loss: 0.22303 | Regression loss: 0.36372 | Running loss: 0.81585\n",
      "Epoch: 3 | Iteration: 96 | Classification loss: 0.28895 | Regression loss: 0.51456 | Running loss: 0.81607\n",
      "Epoch: 3 | Iteration: 97 | Classification loss: 0.32887 | Regression loss: 0.28682 | Running loss: 0.81540\n",
      "Epoch: 3 | Iteration: 98 | Classification loss: 0.39613 | Regression loss: 0.28082 | Running loss: 0.81547\n",
      "Epoch: 3 | Iteration: 99 | Classification loss: 0.51497 | Regression loss: 0.75487 | Running loss: 0.81697\n",
      "Epoch: 3 | Iteration: 100 | Classification loss: 0.38463 | Regression loss: 0.50973 | Running loss: 0.81695\n",
      "Epoch: 3 | Iteration: 101 | Classification loss: 0.44139 | Regression loss: 0.37348 | Running loss: 0.81694\n",
      "Epoch: 3 | Iteration: 102 | Classification loss: 0.14539 | Regression loss: 0.24789 | Running loss: 0.81646\n",
      "Epoch: 3 | Iteration: 103 | Classification loss: 0.19703 | Regression loss: 0.17955 | Running loss: 0.81509\n",
      "Epoch: 3 | Iteration: 104 | Classification loss: 0.18298 | Regression loss: 0.34220 | Running loss: 0.81447\n",
      "Epoch: 3 | Iteration: 105 | Classification loss: 0.40406 | Regression loss: 0.54215 | Running loss: 0.81479\n",
      "Epoch: 3 | Iteration: 106 | Classification loss: 0.41422 | Regression loss: 0.56113 | Running loss: 0.81445\n",
      "Epoch: 3 | Iteration: 107 | Classification loss: 0.23698 | Regression loss: 0.39016 | Running loss: 0.81441\n",
      "Epoch: 3 | Iteration: 108 | Classification loss: 0.30020 | Regression loss: 0.46108 | Running loss: 0.81511\n",
      "Epoch: 3 | Iteration: 109 | Classification loss: 0.28634 | Regression loss: 0.37251 | Running loss: 0.81541\n",
      "Epoch: 3 | Iteration: 110 | Classification loss: 0.30823 | Regression loss: 0.37412 | Running loss: 0.81499\n",
      "Epoch: 3 | Iteration: 111 | Classification loss: 0.36961 | Regression loss: 0.36879 | Running loss: 0.81474\n",
      "Epoch: 3 | Iteration: 112 | Classification loss: 0.41020 | Regression loss: 0.68277 | Running loss: 0.81555\n",
      "Epoch: 3 | Iteration: 113 | Classification loss: 0.37814 | Regression loss: 0.56100 | Running loss: 0.81626\n",
      "Epoch: 3 | Iteration: 114 | Classification loss: 0.23076 | Regression loss: 0.58380 | Running loss: 0.81557\n",
      "Epoch: 3 | Iteration: 115 | Classification loss: 0.34183 | Regression loss: 0.39865 | Running loss: 0.81558\n",
      "Epoch: 3 | Iteration: 116 | Classification loss: 0.39244 | Regression loss: 0.39579 | Running loss: 0.81610\n",
      "Epoch: 3 | Iteration: 117 | Classification loss: 0.20482 | Regression loss: 0.40418 | Running loss: 0.81586\n",
      "Epoch: 3 | Iteration: 118 | Classification loss: 0.34068 | Regression loss: 0.40518 | Running loss: 0.81589\n",
      "Epoch: 3 | Iteration: 119 | Classification loss: 0.21482 | Regression loss: 0.26309 | Running loss: 0.81541\n",
      "Epoch: 3 | Iteration: 120 | Classification loss: 0.24232 | Regression loss: 0.33585 | Running loss: 0.81539\n",
      "Epoch: 3 | Iteration: 121 | Classification loss: 0.45662 | Regression loss: 0.41591 | Running loss: 0.81574\n",
      "Epoch: 3 | Iteration: 122 | Classification loss: 0.19960 | Regression loss: 0.43792 | Running loss: 0.81506\n",
      "Epoch: 3 | Iteration: 123 | Classification loss: 0.18950 | Regression loss: 0.27338 | Running loss: 0.81365\n",
      "Epoch: 3 | Iteration: 124 | Classification loss: 0.41560 | Regression loss: 0.36431 | Running loss: 0.81376\n",
      "Epoch: 3 | Iteration: 125 | Classification loss: 0.42540 | Regression loss: 0.45600 | Running loss: 0.81398\n",
      "Epoch: 3 | Iteration: 126 | Classification loss: 0.24317 | Regression loss: 0.20077 | Running loss: 0.81308\n",
      "Epoch: 3 | Iteration: 127 | Classification loss: 0.13612 | Regression loss: 0.40334 | Running loss: 0.81211\n",
      "Epoch: 3 | Iteration: 128 | Classification loss: 0.19874 | Regression loss: 0.50987 | Running loss: 0.81347\n",
      "Epoch: 3 | Iteration: 129 | Classification loss: 0.49394 | Regression loss: 0.61223 | Running loss: 0.81424\n",
      "Epoch: 3 | Iteration: 130 | Classification loss: 0.22559 | Regression loss: 0.34265 | Running loss: 0.81288\n",
      "Epoch: 3 | Iteration: 131 | Classification loss: 0.18443 | Regression loss: 0.18024 | Running loss: 0.81133\n",
      "Epoch: 3 | Iteration: 132 | Classification loss: 0.57491 | Regression loss: 0.73922 | Running loss: 0.81294\n",
      "Epoch: 3 | Iteration: 133 | Classification loss: 0.35295 | Regression loss: 0.41411 | Running loss: 0.81293\n",
      "Epoch: 3 | Iteration: 134 | Classification loss: 0.29154 | Regression loss: 0.27627 | Running loss: 0.81306\n",
      "Epoch: 3 | Iteration: 135 | Classification loss: 0.24863 | Regression loss: 0.31517 | Running loss: 0.81223\n",
      "Epoch: 3 | Iteration: 136 | Classification loss: 0.36427 | Regression loss: 0.59622 | Running loss: 0.81245\n",
      "Epoch: 3 | Iteration: 137 | Classification loss: 0.33279 | Regression loss: 0.73767 | Running loss: 0.81323\n",
      "Epoch: 3 | Iteration: 138 | Classification loss: 0.39951 | Regression loss: 0.49975 | Running loss: 0.81363\n",
      "Epoch: 3 | Iteration: 139 | Classification loss: 0.42979 | Regression loss: 0.79009 | Running loss: 0.81468\n",
      "Epoch: 3 | Iteration: 140 | Classification loss: 0.25015 | Regression loss: 0.27449 | Running loss: 0.81431\n",
      "Epoch: 3 | Iteration: 141 | Classification loss: 0.42898 | Regression loss: 0.46547 | Running loss: 0.81445\n",
      "Epoch: 3 | Iteration: 142 | Classification loss: 0.19275 | Regression loss: 0.36252 | Running loss: 0.81393\n",
      "Epoch: 3 | Iteration: 143 | Classification loss: 0.27255 | Regression loss: 0.58891 | Running loss: 0.81398\n",
      "Epoch: 3 | Iteration: 144 | Classification loss: 0.23703 | Regression loss: 0.36514 | Running loss: 0.81345\n",
      "Epoch: 3 | Iteration: 145 | Classification loss: 0.34703 | Regression loss: 0.53998 | Running loss: 0.81350\n",
      "Epoch: 3 | Iteration: 146 | Classification loss: 0.33300 | Regression loss: 0.46316 | Running loss: 0.81273\n",
      "Epoch: 3 | Iteration: 147 | Classification loss: 0.17278 | Regression loss: 0.35357 | Running loss: 0.81227\n",
      "Epoch: 3 | Iteration: 148 | Classification loss: 0.38312 | Regression loss: 0.61915 | Running loss: 0.81227\n",
      "Epoch: 3 | Iteration: 149 | Classification loss: 0.17460 | Regression loss: 0.42953 | Running loss: 0.81116\n",
      "Epoch: 3 | Iteration: 150 | Classification loss: 0.33383 | Regression loss: 0.34273 | Running loss: 0.81053\n",
      "Epoch: 3 | Iteration: 151 | Classification loss: 0.12794 | Regression loss: 0.39107 | Running loss: 0.81068\n",
      "Epoch: 3 | Iteration: 152 | Classification loss: 0.45079 | Regression loss: 0.52822 | Running loss: 0.81145\n",
      "Epoch: 3 | Iteration: 153 | Classification loss: 0.45533 | Regression loss: 0.36983 | Running loss: 0.81222\n",
      "Epoch: 3 | Iteration: 154 | Classification loss: 0.09492 | Regression loss: 0.16377 | Running loss: 0.81147\n",
      "Epoch: 3 | Iteration: 155 | Classification loss: 0.23550 | Regression loss: 0.42663 | Running loss: 0.81110\n",
      "Epoch: 3 | Iteration: 156 | Classification loss: 0.51450 | Regression loss: 0.18489 | Running loss: 0.81110\n",
      "Epoch: 3 | Iteration: 157 | Classification loss: 0.32396 | Regression loss: 0.26425 | Running loss: 0.80941\n",
      "Epoch: 3 | Iteration: 158 | Classification loss: 0.33901 | Regression loss: 0.35783 | Running loss: 0.80944\n",
      "Epoch: 3 | Iteration: 159 | Classification loss: 0.29725 | Regression loss: 0.26231 | Running loss: 0.80787\n",
      "Epoch: 3 | Iteration: 160 | Classification loss: 0.40770 | Regression loss: 0.80379 | Running loss: 0.80885\n",
      "Epoch: 3 | Iteration: 161 | Classification loss: 0.19837 | Regression loss: 0.23039 | Running loss: 0.80815\n",
      "Epoch: 3 | Iteration: 162 | Classification loss: 0.37015 | Regression loss: 0.38844 | Running loss: 0.80700\n",
      "Epoch: 3 | Iteration: 163 | Classification loss: 0.32623 | Regression loss: 0.37583 | Running loss: 0.80635\n",
      "Epoch: 3 | Iteration: 164 | Classification loss: 0.60083 | Regression loss: 0.68419 | Running loss: 0.80746\n",
      "Epoch: 3 | Iteration: 165 | Classification loss: 0.49205 | Regression loss: 0.62493 | Running loss: 0.80756\n",
      "Epoch: 3 | Iteration: 166 | Classification loss: 0.43796 | Regression loss: 0.35372 | Running loss: 0.80788\n",
      "Epoch: 3 | Iteration: 167 | Classification loss: 0.29992 | Regression loss: 0.51862 | Running loss: 0.80702\n",
      "Epoch: 3 | Iteration: 168 | Classification loss: 0.18331 | Regression loss: 0.26480 | Running loss: 0.80643\n",
      "Epoch: 3 | Iteration: 169 | Classification loss: 0.31207 | Regression loss: 0.61321 | Running loss: 0.80697\n",
      "Epoch: 3 | Iteration: 170 | Classification loss: 0.26433 | Regression loss: 0.25346 | Running loss: 0.80669\n",
      "Epoch: 3 | Iteration: 171 | Classification loss: 0.33069 | Regression loss: 0.34313 | Running loss: 0.80669\n",
      "Epoch: 3 | Iteration: 172 | Classification loss: 0.44501 | Regression loss: 0.72568 | Running loss: 0.80693\n",
      "Epoch: 3 | Iteration: 173 | Classification loss: 0.12328 | Regression loss: 0.25292 | Running loss: 0.80571\n",
      "Epoch: 3 | Iteration: 174 | Classification loss: 0.23671 | Regression loss: 0.16898 | Running loss: 0.80495\n",
      "Epoch: 3 | Iteration: 175 | Classification loss: 0.38784 | Regression loss: 0.17430 | Running loss: 0.80471\n",
      "Epoch: 3 | Iteration: 176 | Classification loss: 0.27830 | Regression loss: 0.42842 | Running loss: 0.80462\n",
      "Epoch: 3 | Iteration: 177 | Classification loss: 0.16307 | Regression loss: 0.38698 | Running loss: 0.80475\n",
      "Epoch: 3 | Iteration: 178 | Classification loss: 0.39278 | Regression loss: 0.60283 | Running loss: 0.80516\n",
      "Epoch: 3 | Iteration: 179 | Classification loss: 0.47907 | Regression loss: 0.67039 | Running loss: 0.80545\n",
      "Epoch: 3 | Iteration: 180 | Classification loss: 0.28507 | Regression loss: 0.42765 | Running loss: 0.80462\n",
      "Epoch: 3 | Iteration: 181 | Classification loss: 0.15100 | Regression loss: 0.48345 | Running loss: 0.80443\n",
      "Epoch: 3 | Iteration: 182 | Classification loss: 0.08937 | Regression loss: 0.29222 | Running loss: 0.80337\n",
      "Epoch: 3 | Iteration: 183 | Classification loss: 0.39737 | Regression loss: 0.34283 | Running loss: 0.80265\n",
      "Epoch: 3 | Iteration: 184 | Classification loss: 0.45685 | Regression loss: 0.33636 | Running loss: 0.80291\n",
      "Epoch: 3 | Iteration: 185 | Classification loss: 0.19481 | Regression loss: 0.47753 | Running loss: 0.80250\n",
      "Epoch: 3 | Iteration: 186 | Classification loss: 0.41131 | Regression loss: 0.52649 | Running loss: 0.80256\n",
      "Epoch: 3 | Iteration: 187 | Classification loss: 0.43597 | Regression loss: 0.56849 | Running loss: 0.80353\n",
      "Epoch: 3 | Iteration: 188 | Classification loss: 0.33934 | Regression loss: 0.57467 | Running loss: 0.80408\n",
      "Epoch: 3 | Iteration: 189 | Classification loss: 0.44414 | Regression loss: 0.58586 | Running loss: 0.80465\n",
      "Epoch: 3 | Iteration: 190 | Classification loss: 0.28469 | Regression loss: 0.27943 | Running loss: 0.80365\n",
      "Epoch: 3 | Iteration: 191 | Classification loss: 0.26216 | Regression loss: 0.74028 | Running loss: 0.80380\n",
      "Epoch: 3 | Iteration: 192 | Classification loss: 0.31259 | Regression loss: 0.51583 | Running loss: 0.80375\n",
      "Epoch: 3 | Iteration: 193 | Classification loss: 0.52803 | Regression loss: 0.51787 | Running loss: 0.80458\n",
      "Epoch: 3 | Iteration: 194 | Classification loss: 0.22909 | Regression loss: 0.29533 | Running loss: 0.80413\n",
      "Epoch: 3 | Iteration: 195 | Classification loss: 0.36801 | Regression loss: 0.50489 | Running loss: 0.80456\n",
      "Epoch: 3 | Iteration: 196 | Classification loss: 0.25229 | Regression loss: 0.39621 | Running loss: 0.80351\n",
      "Epoch: 3 | Iteration: 197 | Classification loss: 0.22902 | Regression loss: 0.34461 | Running loss: 0.80222\n",
      "Epoch: 3 | Iteration: 198 | Classification loss: 0.33581 | Regression loss: 0.22600 | Running loss: 0.80152\n",
      "Epoch: 3 | Iteration: 199 | Classification loss: 0.38715 | Regression loss: 0.39157 | Running loss: 0.80170\n",
      "Epoch: 3 | Iteration: 200 | Classification loss: 0.12288 | Regression loss: 0.42683 | Running loss: 0.80061\n",
      "Epoch: 3 | Iteration: 201 | Classification loss: 0.53650 | Regression loss: 0.39766 | Running loss: 0.80082\n",
      "Epoch: 3 | Iteration: 202 | Classification loss: 0.30833 | Regression loss: 0.25154 | Running loss: 0.80058\n",
      "Epoch: 3 | Iteration: 203 | Classification loss: 0.31858 | Regression loss: 0.79268 | Running loss: 0.80186\n",
      "Epoch: 3 | Iteration: 204 | Classification loss: 0.28663 | Regression loss: 0.33028 | Running loss: 0.80158\n",
      "Epoch: 3 | Iteration: 205 | Classification loss: 0.36166 | Regression loss: 0.38527 | Running loss: 0.80220\n",
      "Epoch: 3 | Iteration: 206 | Classification loss: 0.34339 | Regression loss: 0.29795 | Running loss: 0.80100\n",
      "Epoch: 3 | Iteration: 207 | Classification loss: 0.47223 | Regression loss: 0.62713 | Running loss: 0.80151\n",
      "Epoch: 3 | Iteration: 208 | Classification loss: 0.36269 | Regression loss: 0.34975 | Running loss: 0.80107\n",
      "Epoch: 3 | Iteration: 209 | Classification loss: 0.17798 | Regression loss: 0.41659 | Running loss: 0.80036\n",
      "Epoch: 3 | Iteration: 210 | Classification loss: 0.22842 | Regression loss: 0.35769 | Running loss: 0.79967\n",
      "Epoch: 3 | Iteration: 211 | Classification loss: 0.12502 | Regression loss: 0.41518 | Running loss: 0.79983\n",
      "Epoch: 3 | Iteration: 212 | Classification loss: 0.24229 | Regression loss: 0.24915 | Running loss: 0.79939\n",
      "Epoch: 3 | Iteration: 213 | Classification loss: 0.31867 | Regression loss: 0.56522 | Running loss: 0.79959\n",
      "Epoch: 3 | Iteration: 214 | Classification loss: 0.33952 | Regression loss: 0.32990 | Running loss: 0.79944\n",
      "Epoch: 3 | Iteration: 215 | Classification loss: 0.23483 | Regression loss: 0.36423 | Running loss: 0.79889\n",
      "Epoch: 3 | Iteration: 216 | Classification loss: 0.15543 | Regression loss: 0.36990 | Running loss: 0.79845\n",
      "Epoch: 3 | Iteration: 217 | Classification loss: 0.28676 | Regression loss: 0.41335 | Running loss: 0.79848\n",
      "Epoch: 3 | Iteration: 218 | Classification loss: 0.29056 | Regression loss: 0.36877 | Running loss: 0.79812\n",
      "Epoch: 3 | Iteration: 219 | Classification loss: 0.48488 | Regression loss: 0.35412 | Running loss: 0.79823\n",
      "Epoch: 3 | Iteration: 220 | Classification loss: 0.25542 | Regression loss: 0.25402 | Running loss: 0.79707\n",
      "Epoch: 3 | Iteration: 221 | Classification loss: 0.42365 | Regression loss: 0.52844 | Running loss: 0.79731\n",
      "Epoch: 3 | Iteration: 222 | Classification loss: 0.31707 | Regression loss: 0.33220 | Running loss: 0.79724\n",
      "Epoch: 3 | Iteration: 223 | Classification loss: 0.32057 | Regression loss: 0.50395 | Running loss: 0.79773\n",
      "Epoch: 3 | Iteration: 224 | Classification loss: 0.35303 | Regression loss: 0.41888 | Running loss: 0.79648\n",
      "Epoch: 3 | Iteration: 225 | Classification loss: 0.31723 | Regression loss: 0.49334 | Running loss: 0.79553\n",
      "Epoch: 3 | Iteration: 226 | Classification loss: 0.42170 | Regression loss: 0.64531 | Running loss: 0.79590\n",
      "Epoch: 3 | Iteration: 227 | Classification loss: 0.20615 | Regression loss: 0.27584 | Running loss: 0.79520\n",
      "Epoch: 3 | Iteration: 228 | Classification loss: 0.35295 | Regression loss: 0.45109 | Running loss: 0.79477\n",
      "Epoch: 3 | Iteration: 229 | Classification loss: 0.19139 | Regression loss: 0.48100 | Running loss: 0.79383\n",
      "Epoch: 3 | Iteration: 230 | Classification loss: 0.21302 | Regression loss: 0.38173 | Running loss: 0.79369\n",
      "Epoch: 3 | Iteration: 231 | Classification loss: 0.25064 | Regression loss: 0.45828 | Running loss: 0.79380\n",
      "Epoch: 3 | Iteration: 232 | Classification loss: 0.24887 | Regression loss: 0.38655 | Running loss: 0.79415\n",
      "Epoch: 3 | Iteration: 233 | Classification loss: 0.34656 | Regression loss: 0.33633 | Running loss: 0.79379\n",
      "Epoch: 3 | Iteration: 234 | Classification loss: 0.27009 | Regression loss: 0.31112 | Running loss: 0.79326\n",
      "Epoch: 3 | Iteration: 235 | Classification loss: 0.20212 | Regression loss: 0.44645 | Running loss: 0.79236\n",
      "Epoch: 3 | Iteration: 236 | Classification loss: 0.20469 | Regression loss: 0.17624 | Running loss: 0.79124\n",
      "Epoch: 3 | Iteration: 237 | Classification loss: 0.28619 | Regression loss: 0.31450 | Running loss: 0.79108\n",
      "Epoch: 3 | Iteration: 238 | Classification loss: 0.38283 | Regression loss: 0.51352 | Running loss: 0.79137\n",
      "Epoch: 3 | Iteration: 239 | Classification loss: 0.37490 | Regression loss: 0.48667 | Running loss: 0.79095\n",
      "Epoch: 3 | Iteration: 240 | Classification loss: 0.33611 | Regression loss: 0.34700 | Running loss: 0.79068\n",
      "Epoch: 3 | Iteration: 241 | Classification loss: 0.14573 | Regression loss: 0.34055 | Running loss: 0.79030\n",
      "Epoch: 3 | Iteration: 242 | Classification loss: 0.42235 | Regression loss: 0.46005 | Running loss: 0.78997\n",
      "Epoch: 3 | Iteration: 243 | Classification loss: 0.19449 | Regression loss: 0.30494 | Running loss: 0.78926\n",
      "Epoch: 3 | Iteration: 244 | Classification loss: 0.46627 | Regression loss: 0.64224 | Running loss: 0.79009\n",
      "Epoch: 3 | Iteration: 245 | Classification loss: 0.32473 | Regression loss: 0.44917 | Running loss: 0.78968\n",
      "Epoch: 3 | Iteration: 246 | Classification loss: 0.17966 | Regression loss: 0.21163 | Running loss: 0.78902\n",
      "Epoch: 3 | Iteration: 247 | Classification loss: 0.22858 | Regression loss: 0.43402 | Running loss: 0.78916\n",
      "Epoch: 3 | Iteration: 248 | Classification loss: 0.10475 | Regression loss: 0.42320 | Running loss: 0.78795\n",
      "Epoch: 3 | Iteration: 249 | Classification loss: 0.31885 | Regression loss: 0.20941 | Running loss: 0.78757\n",
      "Epoch: 3 | Iteration: 250 | Classification loss: 0.33126 | Regression loss: 0.52999 | Running loss: 0.78751\n",
      "Epoch: 3 | Iteration: 251 | Classification loss: 0.14325 | Regression loss: 0.44977 | Running loss: 0.78642\n",
      "Epoch: 3 | Iteration: 252 | Classification loss: 0.26492 | Regression loss: 0.26971 | Running loss: 0.78603\n",
      "Epoch: 3 | Iteration: 253 | Classification loss: 0.47653 | Regression loss: 0.21434 | Running loss: 0.78590\n",
      "Epoch: 3 | Iteration: 254 | Classification loss: 0.39401 | Regression loss: 0.59168 | Running loss: 0.78658\n",
      "Epoch: 3 | Iteration: 255 | Classification loss: 0.29722 | Regression loss: 0.30887 | Running loss: 0.78640\n",
      "Epoch: 3 | Iteration: 256 | Classification loss: 0.24988 | Regression loss: 0.40100 | Running loss: 0.78574\n",
      "Epoch: 3 | Iteration: 257 | Classification loss: 0.39120 | Regression loss: 0.40854 | Running loss: 0.78598\n",
      "Epoch: 3 | Iteration: 258 | Classification loss: 0.56904 | Regression loss: 0.92113 | Running loss: 0.78724\n",
      "Epoch: 3 | Iteration: 259 | Classification loss: 0.23685 | Regression loss: 0.37481 | Running loss: 0.78699\n",
      "Epoch: 3 | Iteration: 260 | Classification loss: 0.30038 | Regression loss: 0.53598 | Running loss: 0.78650\n",
      "Epoch: 3 | Iteration: 261 | Classification loss: 0.22575 | Regression loss: 0.36685 | Running loss: 0.78520\n",
      "Epoch: 3 | Iteration: 262 | Classification loss: 0.34888 | Regression loss: 0.37715 | Running loss: 0.78458\n",
      "Epoch: 3 | Iteration: 263 | Classification loss: 0.21387 | Regression loss: 0.53825 | Running loss: 0.78477\n",
      "Epoch: 3 | Iteration: 264 | Classification loss: 0.09811 | Regression loss: 0.21730 | Running loss: 0.78324\n",
      "Epoch: 3 | Iteration: 265 | Classification loss: 0.48048 | Regression loss: 0.66368 | Running loss: 0.78449\n",
      "Epoch: 3 | Iteration: 266 | Classification loss: 0.34771 | Regression loss: 0.36285 | Running loss: 0.78435\n",
      "Epoch: 3 | Iteration: 267 | Classification loss: 0.37952 | Regression loss: 0.64650 | Running loss: 0.78526\n",
      "Epoch: 3 | Iteration: 268 | Classification loss: 0.40242 | Regression loss: 0.55020 | Running loss: 0.78549\n",
      "Epoch: 3 | Iteration: 269 | Classification loss: 0.17093 | Regression loss: 0.47885 | Running loss: 0.78528\n",
      "Epoch: 3 | Iteration: 270 | Classification loss: 0.16898 | Regression loss: 0.28299 | Running loss: 0.78458\n",
      "Epoch: 3 | Iteration: 271 | Classification loss: 0.37338 | Regression loss: 0.26049 | Running loss: 0.78447\n",
      "Epoch: 3 | Iteration: 272 | Classification loss: 0.17161 | Regression loss: 0.30337 | Running loss: 0.78277\n",
      "Epoch: 3 | Iteration: 273 | Classification loss: 0.19230 | Regression loss: 0.31672 | Running loss: 0.78242\n",
      "Epoch: 3 | Iteration: 274 | Classification loss: 0.38427 | Regression loss: 0.54622 | Running loss: 0.78251\n",
      "Epoch: 3 | Iteration: 275 | Classification loss: 0.50824 | Regression loss: 0.57514 | Running loss: 0.78297\n",
      "Epoch: 3 | Iteration: 276 | Classification loss: 0.20085 | Regression loss: 0.39078 | Running loss: 0.78225\n",
      "Epoch: 3 | Iteration: 277 | Classification loss: 0.47145 | Regression loss: 0.37079 | Running loss: 0.78264\n",
      "Epoch: 3 | Iteration: 278 | Classification loss: 0.58452 | Regression loss: 0.65534 | Running loss: 0.78347\n",
      "Epoch: 3 | Iteration: 279 | Classification loss: 0.53288 | Regression loss: 0.61229 | Running loss: 0.78364\n",
      "Epoch: 3 | Iteration: 280 | Classification loss: 0.30961 | Regression loss: 0.56434 | Running loss: 0.78367\n",
      "Epoch: 3 | Iteration: 281 | Classification loss: 0.25871 | Regression loss: 0.46205 | Running loss: 0.78359\n",
      "Epoch: 3 | Iteration: 282 | Classification loss: 0.20099 | Regression loss: 0.47760 | Running loss: 0.78294\n",
      "Epoch: 3 | Iteration: 283 | Classification loss: 0.14264 | Regression loss: 0.12638 | Running loss: 0.78117\n",
      "Epoch: 3 | Iteration: 284 | Classification loss: 0.60519 | Regression loss: 0.51388 | Running loss: 0.78214\n",
      "Epoch: 3 | Iteration: 285 | Classification loss: 0.10744 | Regression loss: 0.34499 | Running loss: 0.78161\n",
      "Epoch: 3 | Iteration: 286 | Classification loss: 0.25432 | Regression loss: 0.54189 | Running loss: 0.78135\n",
      "Epoch: 3 | Iteration: 287 | Classification loss: 0.07864 | Regression loss: 0.19494 | Running loss: 0.78014\n",
      "Epoch: 3 | Iteration: 288 | Classification loss: 0.48842 | Regression loss: 0.52316 | Running loss: 0.77996\n",
      "Epoch: 3 | Iteration: 289 | Classification loss: 0.61859 | Regression loss: 0.78281 | Running loss: 0.78096\n",
      "Epoch: 3 | Iteration: 290 | Classification loss: 0.27360 | Regression loss: 0.61065 | Running loss: 0.78135\n",
      "Epoch: 3 | Iteration: 291 | Classification loss: 0.29010 | Regression loss: 0.52203 | Running loss: 0.77985\n",
      "Epoch: 3 | Iteration: 292 | Classification loss: 0.40562 | Regression loss: 0.28770 | Running loss: 0.78003\n",
      "Epoch: 3 | Iteration: 293 | Classification loss: 0.28505 | Regression loss: 0.27480 | Running loss: 0.77967\n",
      "Epoch: 3 | Iteration: 294 | Classification loss: 0.30900 | Regression loss: 0.44252 | Running loss: 0.77865\n",
      "Epoch: 3 | Iteration: 295 | Classification loss: 0.10317 | Regression loss: 0.30740 | Running loss: 0.77700\n",
      "Epoch: 3 | Iteration: 296 | Classification loss: 0.46347 | Regression loss: 0.54366 | Running loss: 0.77695\n",
      "Epoch: 3 | Iteration: 297 | Classification loss: 0.32147 | Regression loss: 0.62846 | Running loss: 0.77716\n",
      "Epoch: 3 | Iteration: 298 | Classification loss: 0.55203 | Regression loss: 0.80058 | Running loss: 0.77819\n",
      "Epoch: 3 | Iteration: 299 | Classification loss: 0.43586 | Regression loss: 0.24782 | Running loss: 0.77757\n",
      "Epoch: 3 | Iteration: 300 | Classification loss: 0.43687 | Regression loss: 0.57344 | Running loss: 0.77808\n",
      "Epoch: 3 | Iteration: 301 | Classification loss: 0.42154 | Regression loss: 0.75969 | Running loss: 0.77923\n",
      "Epoch: 3 | Iteration: 302 | Classification loss: 0.31031 | Regression loss: 0.66484 | Running loss: 0.78009\n",
      "Epoch: 3 | Iteration: 303 | Classification loss: 0.27546 | Regression loss: 0.50621 | Running loss: 0.78017\n",
      "Epoch: 3 | Iteration: 304 | Classification loss: 0.33778 | Regression loss: 0.39140 | Running loss: 0.78014\n",
      "Epoch: 3 | Iteration: 305 | Classification loss: 0.65613 | Regression loss: 0.52160 | Running loss: 0.78137\n",
      "Epoch: 3 | Iteration: 306 | Classification loss: 0.62875 | Regression loss: 0.49336 | Running loss: 0.78201\n",
      "Epoch: 3 | Iteration: 307 | Classification loss: 0.29257 | Regression loss: 0.50045 | Running loss: 0.78096\n",
      "Epoch: 3 | Iteration: 308 | Classification loss: 0.31520 | Regression loss: 0.43769 | Running loss: 0.78090\n",
      "Epoch: 3 | Iteration: 309 | Classification loss: 0.37062 | Regression loss: 0.50757 | Running loss: 0.78126\n",
      "Epoch: 3 | Iteration: 310 | Classification loss: 0.17935 | Regression loss: 0.26697 | Running loss: 0.78094\n",
      "Epoch: 3 | Iteration: 311 | Classification loss: 0.46772 | Regression loss: 0.48650 | Running loss: 0.78155\n",
      "Epoch: 3 | Iteration: 312 | Classification loss: 0.62522 | Regression loss: 0.71093 | Running loss: 0.78313\n",
      "Epoch: 3 | Iteration: 313 | Classification loss: 0.28577 | Regression loss: 0.46484 | Running loss: 0.78303\n",
      "Epoch: 3 | Iteration: 314 | Classification loss: 0.32860 | Regression loss: 0.49334 | Running loss: 0.78311\n",
      "Epoch: 3 | Iteration: 315 | Classification loss: 0.54744 | Regression loss: 0.80230 | Running loss: 0.78370\n",
      "Epoch: 3 | Iteration: 316 | Classification loss: 0.34440 | Regression loss: 0.54170 | Running loss: 0.78432\n",
      "Epoch: 3 | Iteration: 317 | Classification loss: 0.46432 | Regression loss: 0.57949 | Running loss: 0.78524\n",
      "Epoch: 3 | Iteration: 318 | Classification loss: 0.58152 | Regression loss: 0.89548 | Running loss: 0.78686\n",
      "Epoch: 3 | Iteration: 319 | Classification loss: 0.15607 | Regression loss: 0.25039 | Running loss: 0.78662\n",
      "Epoch: 3 | Iteration: 320 | Classification loss: 0.27096 | Regression loss: 0.47057 | Running loss: 0.78691\n",
      "Epoch: 3 | Iteration: 321 | Classification loss: 0.38176 | Regression loss: 0.48349 | Running loss: 0.78717\n",
      "Epoch: 3 | Iteration: 322 | Classification loss: 0.28615 | Regression loss: 0.34575 | Running loss: 0.78727\n",
      "Epoch: 3 | Iteration: 323 | Classification loss: 0.47138 | Regression loss: 0.70358 | Running loss: 0.78814\n",
      "Epoch: 3 | Iteration: 324 | Classification loss: 0.51880 | Regression loss: 0.16786 | Running loss: 0.78781\n",
      "Epoch: 3 | Iteration: 325 | Classification loss: 0.21355 | Regression loss: 0.42632 | Running loss: 0.78782\n",
      "Epoch: 3 | Iteration: 326 | Classification loss: 0.35830 | Regression loss: 0.60028 | Running loss: 0.78810\n",
      "Epoch: 3 | Iteration: 327 | Classification loss: 0.33677 | Regression loss: 0.42994 | Running loss: 0.78833\n",
      "Epoch: 3 | Iteration: 328 | Classification loss: 0.39064 | Regression loss: 0.44550 | Running loss: 0.78899\n",
      "Epoch: 3 | Iteration: 329 | Classification loss: 0.26702 | Regression loss: 0.32127 | Running loss: 0.78777\n",
      "Epoch: 3 | Iteration: 330 | Classification loss: 0.16003 | Regression loss: 0.11764 | Running loss: 0.78670\n",
      "Epoch: 3 | Iteration: 331 | Classification loss: 0.24338 | Regression loss: 0.29187 | Running loss: 0.78695\n",
      "Epoch: 3 | Iteration: 332 | Classification loss: 0.48660 | Regression loss: 0.56781 | Running loss: 0.78734\n",
      "Epoch: 3 | Iteration: 333 | Classification loss: 0.16339 | Regression loss: 0.27265 | Running loss: 0.78650\n",
      "Epoch: 3 | Iteration: 334 | Classification loss: 0.37993 | Regression loss: 0.37726 | Running loss: 0.78584\n",
      "Epoch: 3 | Iteration: 335 | Classification loss: 0.33341 | Regression loss: 0.50876 | Running loss: 0.78614\n",
      "Epoch: 3 | Iteration: 336 | Classification loss: 0.39976 | Regression loss: 0.40233 | Running loss: 0.78480\n",
      "Epoch: 3 | Iteration: 337 | Classification loss: 0.14188 | Regression loss: 0.48037 | Running loss: 0.78399\n",
      "Epoch: 3 | Iteration: 338 | Classification loss: 0.19401 | Regression loss: 0.26981 | Running loss: 0.78324\n",
      "Epoch: 3 | Iteration: 339 | Classification loss: 0.35193 | Regression loss: 0.57007 | Running loss: 0.78016\n",
      "Epoch: 3 | Iteration: 340 | Classification loss: 0.34446 | Regression loss: 0.31674 | Running loss: 0.78024\n",
      "Epoch: 3 | Iteration: 341 | Classification loss: 0.16354 | Regression loss: 0.42317 | Running loss: 0.77935\n",
      "Epoch: 3 | Iteration: 342 | Classification loss: 0.45215 | Regression loss: 0.41055 | Running loss: 0.77978\n",
      "Epoch: 3 | Iteration: 343 | Classification loss: 0.56338 | Regression loss: 0.45979 | Running loss: 0.78074\n",
      "Epoch: 3 | Iteration: 344 | Classification loss: 0.35843 | Regression loss: 0.38118 | Running loss: 0.78072\n",
      "Epoch: 3 | Iteration: 345 | Classification loss: 0.47928 | Regression loss: 0.66443 | Running loss: 0.78052\n",
      "Epoch: 3 | Iteration: 346 | Classification loss: 0.20392 | Regression loss: 0.61560 | Running loss: 0.77960\n",
      "Epoch: 3 | Iteration: 347 | Classification loss: 0.38839 | Regression loss: 0.64526 | Running loss: 0.77960\n",
      "Epoch: 3 | Iteration: 348 | Classification loss: 0.28800 | Regression loss: 0.44044 | Running loss: 0.77949\n",
      "Epoch: 3 | Iteration: 349 | Classification loss: 0.49199 | Regression loss: 0.45725 | Running loss: 0.77882\n",
      "Epoch: 3 | Iteration: 350 | Classification loss: 0.08357 | Regression loss: 0.23288 | Running loss: 0.77753\n",
      "Epoch: 3 | Iteration: 351 | Classification loss: 0.33762 | Regression loss: 0.31067 | Running loss: 0.77704\n",
      "Epoch: 3 | Iteration: 352 | Classification loss: 0.51490 | Regression loss: 0.35045 | Running loss: 0.77711\n",
      "Epoch: 3 | Iteration: 353 | Classification loss: 0.32504 | Regression loss: 0.29288 | Running loss: 0.77734\n",
      "Epoch: 3 | Iteration: 354 | Classification loss: 0.44513 | Regression loss: 0.28698 | Running loss: 0.77710\n",
      "Epoch: 3 | Iteration: 355 | Classification loss: 0.32507 | Regression loss: 0.42462 | Running loss: 0.77694\n",
      "Epoch: 3 | Iteration: 356 | Classification loss: 0.30572 | Regression loss: 0.28075 | Running loss: 0.77616\n",
      "Epoch: 3 | Iteration: 357 | Classification loss: 0.30391 | Regression loss: 0.29150 | Running loss: 0.77528\n",
      "Epoch: 3 | Iteration: 358 | Classification loss: 0.28719 | Regression loss: 0.42847 | Running loss: 0.77478\n",
      "Epoch: 3 | Iteration: 359 | Classification loss: 0.37530 | Regression loss: 0.49643 | Running loss: 0.77534\n",
      "Epoch: 3 | Iteration: 360 | Classification loss: 0.37141 | Regression loss: 0.49418 | Running loss: 0.77556\n",
      "Epoch: 3 | Iteration: 361 | Classification loss: 0.31924 | Regression loss: 0.47998 | Running loss: 0.77597\n",
      "Epoch: 3 | Iteration: 362 | Classification loss: 0.37748 | Regression loss: 0.55196 | Running loss: 0.77573\n",
      "Epoch: 3 | Iteration: 363 | Classification loss: 0.38809 | Regression loss: 0.47450 | Running loss: 0.77445\n",
      "Epoch: 3 | Iteration: 364 | Classification loss: 0.32811 | Regression loss: 0.33919 | Running loss: 0.77412\n",
      "Epoch: 3 | Iteration: 365 | Classification loss: 0.40725 | Regression loss: 0.34476 | Running loss: 0.77429\n",
      "Epoch: 3 | Iteration: 366 | Classification loss: 0.25040 | Regression loss: 0.49017 | Running loss: 0.77416\n",
      "Epoch: 3 | Iteration: 367 | Classification loss: 0.40410 | Regression loss: 0.33084 | Running loss: 0.77431\n",
      "Epoch: 3 | Iteration: 368 | Classification loss: 0.33757 | Regression loss: 0.40697 | Running loss: 0.77465\n",
      "Epoch: 3 | Iteration: 369 | Classification loss: 0.21755 | Regression loss: 0.33268 | Running loss: 0.77372\n",
      "Epoch: 3 | Iteration: 370 | Classification loss: 0.43938 | Regression loss: 0.39729 | Running loss: 0.77417\n",
      "Epoch: 3 | Iteration: 371 | Classification loss: 0.24407 | Regression loss: 0.26621 | Running loss: 0.77229\n",
      "Epoch: 3 | Iteration: 372 | Classification loss: 0.31733 | Regression loss: 0.30765 | Running loss: 0.77232\n",
      "Epoch: 3 | Iteration: 373 | Classification loss: 0.32398 | Regression loss: 0.20113 | Running loss: 0.77194\n",
      "Epoch: 3 | Iteration: 374 | Classification loss: 0.23534 | Regression loss: 0.46591 | Running loss: 0.77212\n",
      "Epoch: 3 | Iteration: 375 | Classification loss: 0.43202 | Regression loss: 0.63762 | Running loss: 0.77336\n",
      "Epoch: 3 | Iteration: 376 | Classification loss: 0.26330 | Regression loss: 0.36709 | Running loss: 0.77326\n",
      "Epoch: 3 | Iteration: 377 | Classification loss: 0.38074 | Regression loss: 0.51668 | Running loss: 0.77354\n",
      "Epoch: 3 | Iteration: 378 | Classification loss: 0.30453 | Regression loss: 0.37404 | Running loss: 0.77185\n",
      "Epoch: 3 | Iteration: 379 | Classification loss: 0.38816 | Regression loss: 0.81110 | Running loss: 0.77187\n",
      "Epoch: 3 | Iteration: 380 | Classification loss: 0.20564 | Regression loss: 0.26739 | Running loss: 0.77056\n",
      "Epoch: 3 | Iteration: 381 | Classification loss: 0.25474 | Regression loss: 0.50582 | Running loss: 0.77087\n",
      "Epoch: 3 | Iteration: 382 | Classification loss: 0.20385 | Regression loss: 0.52899 | Running loss: 0.77111\n",
      "Epoch: 3 | Iteration: 383 | Classification loss: 0.25675 | Regression loss: 0.46596 | Running loss: 0.77099\n",
      "Epoch: 3 | Iteration: 384 | Classification loss: 0.48916 | Regression loss: 0.75081 | Running loss: 0.77180\n",
      "Epoch: 3 | Iteration: 385 | Classification loss: 0.31448 | Regression loss: 0.53534 | Running loss: 0.77162\n",
      "Epoch: 3 | Iteration: 386 | Classification loss: 0.54315 | Regression loss: 0.72526 | Running loss: 0.77232\n",
      "Epoch: 3 | Iteration: 387 | Classification loss: 0.37644 | Regression loss: 0.23724 | Running loss: 0.77208\n",
      "Epoch: 3 | Iteration: 388 | Classification loss: 0.22749 | Regression loss: 0.49092 | Running loss: 0.77197\n",
      "Epoch: 3 | Iteration: 389 | Classification loss: 0.29630 | Regression loss: 0.52526 | Running loss: 0.77220\n",
      "Epoch: 3 | Iteration: 390 | Classification loss: 0.22821 | Regression loss: 0.27371 | Running loss: 0.77158\n",
      "Epoch: 3 | Iteration: 391 | Classification loss: 0.36245 | Regression loss: 0.30984 | Running loss: 0.77174\n",
      "Epoch: 3 | Iteration: 392 | Classification loss: 0.28402 | Regression loss: 0.45349 | Running loss: 0.77200\n",
      "Epoch: 3 | Iteration: 393 | Classification loss: 0.32352 | Regression loss: 0.33037 | Running loss: 0.77182\n",
      "Epoch: 3 | Iteration: 394 | Classification loss: 0.33654 | Regression loss: 0.27315 | Running loss: 0.77197\n",
      "Epoch: 3 | Iteration: 395 | Classification loss: 0.21282 | Regression loss: 0.33520 | Running loss: 0.77065\n",
      "Epoch: 3 | Iteration: 396 | Classification loss: 0.33254 | Regression loss: 0.59021 | Running loss: 0.77081\n",
      "Epoch: 3 | Iteration: 397 | Classification loss: 0.13822 | Regression loss: 0.24529 | Running loss: 0.77045\n",
      "Epoch: 3 | Iteration: 398 | Classification loss: 0.32972 | Regression loss: 0.48095 | Running loss: 0.77039\n",
      "Epoch: 3 | Iteration: 399 | Classification loss: 0.26909 | Regression loss: 0.32920 | Running loss: 0.76999\n",
      "Epoch: 3 | Iteration: 400 | Classification loss: 0.28152 | Regression loss: 0.30816 | Running loss: 0.76975\n",
      "Epoch: 3 | Iteration: 401 | Classification loss: 0.10637 | Regression loss: 0.32808 | Running loss: 0.76967\n",
      "Epoch: 3 | Iteration: 402 | Classification loss: 0.36253 | Regression loss: 0.40801 | Running loss: 0.76978\n",
      "Epoch: 3 | Iteration: 403 | Classification loss: 0.35164 | Regression loss: 0.79473 | Running loss: 0.77114\n",
      "Epoch: 3 | Iteration: 404 | Classification loss: 0.40090 | Regression loss: 0.56628 | Running loss: 0.77129\n",
      "Epoch: 3 | Iteration: 405 | Classification loss: 0.58914 | Regression loss: 0.39926 | Running loss: 0.77195\n",
      "Epoch: 3 | Iteration: 406 | Classification loss: 0.35619 | Regression loss: 0.59126 | Running loss: 0.77279\n",
      "Epoch: 3 | Iteration: 407 | Classification loss: 0.45415 | Regression loss: 0.77591 | Running loss: 0.77309\n",
      "Epoch: 3 | Iteration: 408 | Classification loss: 0.55639 | Regression loss: 0.76487 | Running loss: 0.77342\n",
      "Epoch: 3 | Iteration: 409 | Classification loss: 0.18167 | Regression loss: 0.37842 | Running loss: 0.77321\n",
      "Epoch: 3 | Iteration: 410 | Classification loss: 0.31290 | Regression loss: 0.46016 | Running loss: 0.77400\n",
      "Epoch: 3 | Iteration: 411 | Classification loss: 0.34719 | Regression loss: 0.28877 | Running loss: 0.77390\n",
      "Epoch: 3 | Iteration: 412 | Classification loss: 0.22909 | Regression loss: 0.42042 | Running loss: 0.77430\n",
      "Epoch: 3 | Iteration: 413 | Classification loss: 0.39779 | Regression loss: 0.54275 | Running loss: 0.77458\n",
      "Epoch: 3 | Iteration: 414 | Classification loss: 0.49352 | Regression loss: 0.39555 | Running loss: 0.77426\n",
      "Epoch: 3 | Iteration: 415 | Classification loss: 0.60326 | Regression loss: 0.62643 | Running loss: 0.77408\n",
      "Epoch: 3 | Iteration: 416 | Classification loss: 0.47349 | Regression loss: 0.47996 | Running loss: 0.77428\n",
      "Epoch: 3 | Iteration: 417 | Classification loss: 0.24398 | Regression loss: 0.30029 | Running loss: 0.77409\n",
      "Epoch: 3 | Iteration: 418 | Classification loss: 0.34480 | Regression loss: 0.46423 | Running loss: 0.77407\n",
      "Epoch: 3 | Iteration: 419 | Classification loss: 0.19404 | Regression loss: 0.50160 | Running loss: 0.77433\n",
      "Epoch: 3 | Iteration: 420 | Classification loss: 0.40919 | Regression loss: 0.72859 | Running loss: 0.77530\n",
      "Epoch: 3 | Iteration: 421 | Classification loss: 0.31737 | Regression loss: 0.32034 | Running loss: 0.77441\n",
      "Epoch: 3 | Iteration: 422 | Classification loss: 0.24538 | Regression loss: 0.21884 | Running loss: 0.77343\n",
      "Epoch: 3 | Iteration: 423 | Classification loss: 0.12757 | Regression loss: 0.42639 | Running loss: 0.77343\n",
      "Epoch: 3 | Iteration: 424 | Classification loss: 0.19787 | Regression loss: 0.49668 | Running loss: 0.77271\n",
      "Epoch: 3 | Iteration: 425 | Classification loss: 0.47443 | Regression loss: 0.60040 | Running loss: 0.77371\n",
      "Epoch: 3 | Iteration: 426 | Classification loss: 0.23768 | Regression loss: 0.37868 | Running loss: 0.77374\n",
      "Epoch: 3 | Iteration: 427 | Classification loss: 0.27545 | Regression loss: 0.48408 | Running loss: 0.77356\n",
      "Epoch: 3 | Iteration: 428 | Classification loss: 0.18795 | Regression loss: 0.27847 | Running loss: 0.77309\n",
      "Epoch: 3 | Iteration: 429 | Classification loss: 0.39239 | Regression loss: 0.61992 | Running loss: 0.77337\n",
      "Epoch: 3 | Iteration: 430 | Classification loss: 0.15391 | Regression loss: 0.19628 | Running loss: 0.77262\n",
      "Epoch: 3 | Iteration: 431 | Classification loss: 0.22242 | Regression loss: 0.38010 | Running loss: 0.77240\n",
      "Epoch: 3 | Iteration: 432 | Classification loss: 0.24032 | Regression loss: 0.45372 | Running loss: 0.77155\n",
      "Epoch: 3 | Iteration: 433 | Classification loss: 0.66393 | Regression loss: 0.18775 | Running loss: 0.77210\n",
      "Epoch: 3 | Iteration: 434 | Classification loss: 0.32118 | Regression loss: 0.47648 | Running loss: 0.77086\n",
      "Epoch: 3 | Iteration: 435 | Classification loss: 0.44169 | Regression loss: 0.41780 | Running loss: 0.77116\n",
      "Epoch: 3 | Iteration: 436 | Classification loss: 0.39733 | Regression loss: 0.70586 | Running loss: 0.77109\n",
      "Epoch: 3 | Iteration: 437 | Classification loss: 0.31010 | Regression loss: 0.22950 | Running loss: 0.77092\n",
      "Epoch: 3 | Iteration: 438 | Classification loss: 0.38330 | Regression loss: 0.69378 | Running loss: 0.77161\n",
      "Epoch: 3 | Iteration: 439 | Classification loss: 0.28167 | Regression loss: 0.37124 | Running loss: 0.77034\n",
      "Epoch: 3 | Iteration: 440 | Classification loss: 0.58271 | Regression loss: 0.77653 | Running loss: 0.77135\n",
      "Epoch: 3 | Iteration: 441 | Classification loss: 0.31525 | Regression loss: 0.38190 | Running loss: 0.77113\n",
      "Epoch: 3 | Iteration: 442 | Classification loss: 0.46812 | Regression loss: 0.52338 | Running loss: 0.77129\n",
      "Epoch: 3 | Iteration: 443 | Classification loss: 0.50402 | Regression loss: 0.45035 | Running loss: 0.77183\n",
      "Epoch: 3 | Iteration: 444 | Classification loss: 0.45329 | Regression loss: 0.58881 | Running loss: 0.77235\n",
      "Epoch: 3 | Iteration: 445 | Classification loss: 0.27215 | Regression loss: 0.46984 | Running loss: 0.77029\n",
      "Epoch: 3 | Iteration: 446 | Classification loss: 0.42267 | Regression loss: 0.76424 | Running loss: 0.77149\n",
      "Epoch: 3 | Iteration: 447 | Classification loss: 0.29295 | Regression loss: 0.39962 | Running loss: 0.77140\n",
      "Epoch: 3 | Iteration: 448 | Classification loss: 0.27931 | Regression loss: 0.51665 | Running loss: 0.77156\n",
      "Epoch: 3 | Iteration: 449 | Classification loss: 0.34730 | Regression loss: 0.38926 | Running loss: 0.77157\n",
      "Epoch: 3 | Iteration: 450 | Classification loss: 0.25886 | Regression loss: 0.26325 | Running loss: 0.77140\n",
      "Epoch: 3 | Iteration: 451 | Classification loss: 0.37875 | Regression loss: 0.56224 | Running loss: 0.77139\n",
      "Epoch: 3 | Iteration: 452 | Classification loss: 0.27794 | Regression loss: 0.42873 | Running loss: 0.77017\n",
      "Epoch: 3 | Iteration: 453 | Classification loss: 0.20280 | Regression loss: 0.35649 | Running loss: 0.77008\n",
      "Epoch: 3 | Iteration: 454 | Classification loss: 0.38910 | Regression loss: 0.67112 | Running loss: 0.77103\n",
      "Epoch: 3 | Iteration: 455 | Classification loss: 0.27751 | Regression loss: 0.48418 | Running loss: 0.77053\n",
      "Epoch: 3 | Iteration: 456 | Classification loss: 0.24888 | Regression loss: 0.42975 | Running loss: 0.77027\n",
      "Epoch: 3 | Iteration: 457 | Classification loss: 0.21953 | Regression loss: 0.44097 | Running loss: 0.76890\n",
      "Epoch: 3 | Iteration: 458 | Classification loss: 0.49457 | Regression loss: 0.79197 | Running loss: 0.76908\n",
      "Epoch: 3 | Iteration: 459 | Classification loss: 0.23595 | Regression loss: 0.39647 | Running loss: 0.76867\n",
      "Epoch: 3 | Iteration: 460 | Classification loss: 0.30376 | Regression loss: 0.22976 | Running loss: 0.76856\n",
      "Epoch: 3 | Iteration: 461 | Classification loss: 0.29351 | Regression loss: 0.31251 | Running loss: 0.76845\n",
      "Epoch: 3 | Iteration: 462 | Classification loss: 0.30352 | Regression loss: 0.31304 | Running loss: 0.76849\n",
      "Epoch: 3 | Iteration: 463 | Classification loss: 0.16418 | Regression loss: 0.19814 | Running loss: 0.76778\n",
      "Epoch: 3 | Iteration: 464 | Classification loss: 0.17100 | Regression loss: 0.32869 | Running loss: 0.76736\n",
      "Epoch: 3 | Iteration: 465 | Classification loss: 0.32538 | Regression loss: 0.44605 | Running loss: 0.76750\n",
      "Epoch: 3 | Iteration: 466 | Classification loss: 0.22541 | Regression loss: 0.44211 | Running loss: 0.76711\n",
      "Epoch: 3 | Iteration: 467 | Classification loss: 0.47308 | Regression loss: 0.81953 | Running loss: 0.76765\n",
      "Epoch: 3 | Iteration: 468 | Classification loss: 0.39233 | Regression loss: 0.21680 | Running loss: 0.76716\n",
      "Epoch: 3 | Iteration: 469 | Classification loss: 0.22820 | Regression loss: 0.44076 | Running loss: 0.76746\n",
      "Epoch: 3 | Iteration: 470 | Classification loss: 0.21664 | Regression loss: 0.25729 | Running loss: 0.76678\n",
      "Epoch: 3 | Iteration: 471 | Classification loss: 0.22710 | Regression loss: 0.10195 | Running loss: 0.76526\n",
      "Epoch: 3 | Iteration: 472 | Classification loss: 0.33849 | Regression loss: 0.51057 | Running loss: 0.76434\n",
      "Epoch: 3 | Iteration: 473 | Classification loss: 0.38251 | Regression loss: 0.32907 | Running loss: 0.76381\n",
      "Epoch: 3 | Iteration: 474 | Classification loss: 0.11966 | Regression loss: 0.23403 | Running loss: 0.76376\n",
      "Epoch: 3 | Iteration: 475 | Classification loss: 0.25547 | Regression loss: 0.22027 | Running loss: 0.76309\n",
      "Epoch: 3 | Iteration: 476 | Classification loss: 0.33811 | Regression loss: 0.68769 | Running loss: 0.76416\n",
      "Epoch: 3 | Iteration: 477 | Classification loss: 0.28399 | Regression loss: 0.27442 | Running loss: 0.76287\n",
      "Epoch: 3 | Iteration: 478 | Classification loss: 0.30324 | Regression loss: 0.55466 | Running loss: 0.76312\n",
      "Epoch: 3 | Iteration: 479 | Classification loss: 0.25823 | Regression loss: 0.40354 | Running loss: 0.76366\n",
      "Epoch: 3 | Iteration: 480 | Classification loss: 0.31042 | Regression loss: 0.30157 | Running loss: 0.76275\n",
      "Epoch: 3 | Iteration: 481 | Classification loss: 0.42399 | Regression loss: 0.57739 | Running loss: 0.76365\n",
      "Epoch: 3 | Iteration: 482 | Classification loss: 0.44516 | Regression loss: 0.75219 | Running loss: 0.76469\n",
      "Epoch: 3 | Iteration: 483 | Classification loss: 0.18436 | Regression loss: 0.49182 | Running loss: 0.76475\n",
      "Epoch: 3 | Iteration: 484 | Classification loss: 0.28618 | Regression loss: 0.49411 | Running loss: 0.76447\n",
      "Epoch: 3 | Iteration: 485 | Classification loss: 0.40628 | Regression loss: 0.55819 | Running loss: 0.76510\n",
      "Epoch: 3 | Iteration: 486 | Classification loss: 0.45709 | Regression loss: 0.60553 | Running loss: 0.76609\n",
      "Epoch: 3 | Iteration: 487 | Classification loss: 0.09096 | Regression loss: 0.31699 | Running loss: 0.76395\n",
      "Epoch: 3 | Iteration: 488 | Classification loss: 0.76707 | Regression loss: 1.23965 | Running loss: 0.76687\n",
      "Epoch: 3 | Iteration: 489 | Classification loss: 0.34808 | Regression loss: 0.53202 | Running loss: 0.76685\n",
      "Epoch: 3 | Iteration: 490 | Classification loss: 0.34827 | Regression loss: 0.23650 | Running loss: 0.76431\n",
      "Epoch: 3 | Iteration: 491 | Classification loss: 0.25496 | Regression loss: 0.42582 | Running loss: 0.76494\n",
      "Epoch: 3 | Iteration: 492 | Classification loss: 0.10870 | Regression loss: 0.18553 | Running loss: 0.76421\n",
      "Epoch: 3 | Iteration: 493 | Classification loss: 0.13844 | Regression loss: 0.19765 | Running loss: 0.76279\n",
      "Epoch: 3 | Iteration: 494 | Classification loss: 0.33215 | Regression loss: 0.61725 | Running loss: 0.76343\n",
      "Epoch: 3 | Iteration: 495 | Classification loss: 0.39444 | Regression loss: 0.74688 | Running loss: 0.76439\n",
      "Epoch: 3 | Iteration: 496 | Classification loss: 0.17055 | Regression loss: 0.43916 | Running loss: 0.76376\n",
      "Epoch: 3 | Iteration: 497 | Classification loss: 0.47717 | Regression loss: 0.24408 | Running loss: 0.76377\n",
      "Epoch: 3 | Iteration: 498 | Classification loss: 0.44962 | Regression loss: 0.28042 | Running loss: 0.76332\n",
      "Epoch: 3 | Iteration: 499 | Classification loss: 0.16665 | Regression loss: 0.23605 | Running loss: 0.76188\n",
      "Epoch: 3 | Iteration: 500 | Classification loss: 0.23389 | Regression loss: 0.52191 | Running loss: 0.76166\n",
      "Epoch: 3 | Iteration: 501 | Classification loss: 0.22316 | Regression loss: 0.26792 | Running loss: 0.76140\n",
      "Epoch: 3 | Iteration: 502 | Classification loss: 0.15316 | Regression loss: 0.23268 | Running loss: 0.76102\n",
      "Epoch: 3 | Iteration: 503 | Classification loss: 0.37030 | Regression loss: 0.49669 | Running loss: 0.76122\n",
      "Epoch: 3 | Iteration: 504 | Classification loss: 0.70728 | Regression loss: 0.43062 | Running loss: 0.76236\n",
      "Epoch: 3 | Iteration: 505 | Classification loss: 0.50443 | Regression loss: 0.71793 | Running loss: 0.76349\n",
      "Epoch: 3 | Iteration: 506 | Classification loss: 0.22424 | Regression loss: 0.43008 | Running loss: 0.76346\n",
      "Epoch: 3 | Iteration: 507 | Classification loss: 0.26453 | Regression loss: 0.41657 | Running loss: 0.76327\n",
      "Epoch: 3 | Iteration: 508 | Classification loss: 0.39835 | Regression loss: 0.55433 | Running loss: 0.76320\n",
      "Epoch: 3 | Iteration: 509 | Classification loss: 0.30757 | Regression loss: 0.34125 | Running loss: 0.76184\n",
      "Epoch: 3 | Iteration: 510 | Classification loss: 0.22153 | Regression loss: 0.39797 | Running loss: 0.76149\n",
      "Epoch: 3 | Iteration: 511 | Classification loss: 0.30491 | Regression loss: 0.54104 | Running loss: 0.76098\n",
      "Epoch: 3 | Iteration: 512 | Classification loss: 0.27638 | Regression loss: 0.21243 | Running loss: 0.75983\n",
      "Epoch: 3 | Iteration: 513 | Classification loss: 0.44598 | Regression loss: 0.27918 | Running loss: 0.75969\n",
      "Epoch: 3 | Iteration: 514 | Classification loss: 0.22272 | Regression loss: 0.30313 | Running loss: 0.75853\n",
      "Epoch: 3 | Iteration: 515 | Classification loss: 0.25996 | Regression loss: 0.18311 | Running loss: 0.75786\n",
      "Epoch: 3 | Iteration: 516 | Classification loss: 0.35621 | Regression loss: 0.61275 | Running loss: 0.75891\n",
      "Epoch: 3 | Iteration: 517 | Classification loss: 0.23836 | Regression loss: 0.41117 | Running loss: 0.75878\n",
      "Epoch: 3 | Iteration: 518 | Classification loss: 0.26326 | Regression loss: 0.19837 | Running loss: 0.75839\n",
      "Epoch: 3 | Iteration: 519 | Classification loss: 0.27688 | Regression loss: 0.32720 | Running loss: 0.75718\n",
      "Epoch: 3 | Iteration: 520 | Classification loss: 0.26178 | Regression loss: 0.16121 | Running loss: 0.75617\n",
      "Epoch: 3 | Iteration: 521 | Classification loss: 0.48650 | Regression loss: 0.63365 | Running loss: 0.75690\n",
      "Epoch: 3 | Iteration: 522 | Classification loss: 0.43869 | Regression loss: 0.36292 | Running loss: 0.75694\n",
      "Epoch: 3 | Iteration: 523 | Classification loss: 0.26308 | Regression loss: 0.31077 | Running loss: 0.75716\n",
      "Epoch: 3 | Iteration: 524 | Classification loss: 0.17676 | Regression loss: 0.33152 | Running loss: 0.75611\n",
      "Epoch: 3 | Iteration: 525 | Classification loss: 0.25421 | Regression loss: 0.27058 | Running loss: 0.75597\n",
      "Epoch: 3 | Iteration: 526 | Classification loss: 0.33361 | Regression loss: 0.35446 | Running loss: 0.75587\n",
      "Epoch: 3 | Iteration: 527 | Classification loss: 0.27168 | Regression loss: 0.41156 | Running loss: 0.75615\n",
      "Epoch: 3 | Iteration: 528 | Classification loss: 0.14871 | Regression loss: 0.31076 | Running loss: 0.75540\n",
      "Epoch: 3 | Iteration: 529 | Classification loss: 0.18923 | Regression loss: 0.52823 | Running loss: 0.75418\n",
      "Epoch: 3 | Iteration: 530 | Classification loss: 0.30242 | Regression loss: 0.50021 | Running loss: 0.75440\n",
      "Epoch: 3 | Iteration: 531 | Classification loss: 0.14988 | Regression loss: 0.31300 | Running loss: 0.75414\n",
      "Epoch: 3 | Iteration: 532 | Classification loss: 0.49340 | Regression loss: 0.39495 | Running loss: 0.75426\n",
      "Epoch: 3 | Iteration: 533 | Classification loss: 0.26536 | Regression loss: 0.67201 | Running loss: 0.75388\n",
      "Epoch: 3 | Iteration: 534 | Classification loss: 0.52083 | Regression loss: 0.26591 | Running loss: 0.75351\n",
      "Epoch: 3 | Iteration: 535 | Classification loss: 0.24574 | Regression loss: 0.29580 | Running loss: 0.75250\n",
      "Epoch: 3 | Iteration: 536 | Classification loss: 0.29579 | Regression loss: 0.58901 | Running loss: 0.75348\n",
      "Epoch: 3 | Iteration: 537 | Classification loss: 0.27808 | Regression loss: 0.41942 | Running loss: 0.75387\n",
      "Epoch: 3 | Iteration: 538 | Classification loss: 0.38609 | Regression loss: 0.44596 | Running loss: 0.75342\n",
      "Epoch: 3 | Iteration: 539 | Classification loss: 0.08046 | Regression loss: 0.21540 | Running loss: 0.75206\n",
      "Epoch: 3 | Iteration: 540 | Classification loss: 0.10710 | Regression loss: 0.27609 | Running loss: 0.75198\n",
      "Epoch: 3 | Iteration: 541 | Classification loss: 0.28886 | Regression loss: 0.51498 | Running loss: 0.75211\n",
      "Epoch: 3 | Iteration: 542 | Classification loss: 0.25796 | Regression loss: 0.48632 | Running loss: 0.75199\n",
      "Epoch: 3 | Iteration: 543 | Classification loss: 0.31965 | Regression loss: 0.49884 | Running loss: 0.75253\n",
      "Epoch: 3 | Iteration: 544 | Classification loss: 0.36113 | Regression loss: 0.22883 | Running loss: 0.75196\n",
      "Epoch: 3 | Iteration: 545 | Classification loss: 0.39418 | Regression loss: 0.33450 | Running loss: 0.75227\n",
      "Epoch: 3 | Iteration: 546 | Classification loss: 0.24647 | Regression loss: 0.16867 | Running loss: 0.75204\n",
      "Epoch: 3 | Iteration: 547 | Classification loss: 0.22976 | Regression loss: 0.47996 | Running loss: 0.75230\n",
      "Epoch: 3 | Iteration: 548 | Classification loss: 0.19936 | Regression loss: 0.34704 | Running loss: 0.75197\n",
      "Epoch: 3 | Iteration: 549 | Classification loss: 0.22831 | Regression loss: 0.34299 | Running loss: 0.75127\n",
      "Epoch: 3 | Iteration: 550 | Classification loss: 0.47408 | Regression loss: 0.37272 | Running loss: 0.75153\n",
      "Epoch: 3 | Iteration: 551 | Classification loss: 0.36002 | Regression loss: 0.37491 | Running loss: 0.75094\n",
      "Epoch: 3 | Iteration: 552 | Classification loss: 0.25034 | Regression loss: 0.33393 | Running loss: 0.75089\n",
      "Epoch: 3 | Iteration: 553 | Classification loss: 0.55379 | Regression loss: 0.71666 | Running loss: 0.75179\n",
      "Epoch: 3 | Iteration: 554 | Classification loss: 0.41271 | Regression loss: 0.34826 | Running loss: 0.75191\n",
      "Epoch: 3 | Iteration: 555 | Classification loss: 0.22239 | Regression loss: 0.44609 | Running loss: 0.75230\n",
      "Epoch: 3 | Iteration: 556 | Classification loss: 0.31095 | Regression loss: 0.26589 | Running loss: 0.75197\n",
      "Epoch: 3 | Iteration: 557 | Classification loss: 0.43878 | Regression loss: 0.75963 | Running loss: 0.75210\n",
      "Epoch: 3 | Iteration: 558 | Classification loss: 0.12247 | Regression loss: 0.41113 | Running loss: 0.75171\n",
      "Epoch: 3 | Iteration: 559 | Classification loss: 0.46719 | Regression loss: 0.37915 | Running loss: 0.75216\n",
      "Epoch: 3 | Iteration: 560 | Classification loss: 0.19541 | Regression loss: 0.30321 | Running loss: 0.75155\n",
      "Epoch: 3 | Iteration: 561 | Classification loss: 0.23625 | Regression loss: 0.20763 | Running loss: 0.75081\n",
      "Epoch: 3 | Iteration: 562 | Classification loss: 0.22297 | Regression loss: 0.26312 | Running loss: 0.74998\n",
      "Epoch: 3 | Iteration: 563 | Classification loss: 0.21453 | Regression loss: 0.25864 | Running loss: 0.74922\n",
      "Epoch: 3 | Iteration: 564 | Classification loss: 0.28041 | Regression loss: 0.24016 | Running loss: 0.74899\n",
      "Epoch: 3 | Iteration: 565 | Classification loss: 0.21421 | Regression loss: 0.32516 | Running loss: 0.74927\n",
      "Epoch: 3 | Iteration: 566 | Classification loss: 0.30069 | Regression loss: 0.55790 | Running loss: 0.74966\n",
      "Epoch: 3 | Iteration: 567 | Classification loss: 0.29245 | Regression loss: 0.30009 | Running loss: 0.74921\n",
      "Epoch: 3 | Iteration: 568 | Classification loss: 0.29966 | Regression loss: 0.46637 | Running loss: 0.74947\n",
      "Epoch: 3 | Iteration: 569 | Classification loss: 0.39188 | Regression loss: 0.35563 | Running loss: 0.74975\n",
      "Epoch: 3 | Iteration: 570 | Classification loss: 0.31746 | Regression loss: 0.46670 | Running loss: 0.75003\n",
      "Epoch: 3 | Iteration: 571 | Classification loss: 0.41799 | Regression loss: 0.56221 | Running loss: 0.75085\n",
      "Epoch: 3 | Iteration: 572 | Classification loss: 0.21507 | Regression loss: 0.32016 | Running loss: 0.75082\n",
      "Epoch: 3 | Iteration: 573 | Classification loss: 0.45421 | Regression loss: 0.72906 | Running loss: 0.75145\n",
      "Epoch: 3 | Iteration: 574 | Classification loss: 0.16641 | Regression loss: 0.26326 | Running loss: 0.75017\n",
      "Epoch: 3 | Iteration: 575 | Classification loss: 0.30990 | Regression loss: 0.45085 | Running loss: 0.75057\n",
      "Epoch: 3 | Iteration: 576 | Classification loss: 0.24354 | Regression loss: 0.27535 | Running loss: 0.75028\n",
      "Epoch: 3 | Iteration: 577 | Classification loss: 0.34471 | Regression loss: 0.65544 | Running loss: 0.75054\n",
      "Epoch: 3 | Iteration: 578 | Classification loss: 0.32929 | Regression loss: 0.31092 | Running loss: 0.75063\n",
      "Epoch: 3 | Iteration: 579 | Classification loss: 0.28103 | Regression loss: 0.67804 | Running loss: 0.75186\n",
      "Epoch: 3 | Iteration: 580 | Classification loss: 0.17544 | Regression loss: 0.28845 | Running loss: 0.75106\n",
      "Epoch: 3 | Iteration: 581 | Classification loss: 0.09988 | Regression loss: 0.28686 | Running loss: 0.75069\n",
      "Epoch: 3 | Iteration: 582 | Classification loss: 0.30052 | Regression loss: 0.44606 | Running loss: 0.75086\n",
      "Epoch: 3 | Iteration: 583 | Classification loss: 0.31057 | Regression loss: 0.36686 | Running loss: 0.75055\n",
      "Epoch: 3 | Iteration: 584 | Classification loss: 0.36537 | Regression loss: 0.47706 | Running loss: 0.75075\n",
      "Epoch: 3 | Iteration: 585 | Classification loss: 0.46210 | Regression loss: 0.62518 | Running loss: 0.75071\n",
      "Epoch: 3 | Iteration: 586 | Classification loss: 0.22668 | Regression loss: 0.45511 | Running loss: 0.75036\n",
      "Epoch: 3 | Iteration: 587 | Classification loss: 0.19941 | Regression loss: 0.39977 | Running loss: 0.75007\n",
      "Epoch: 3 | Iteration: 588 | Classification loss: 0.16356 | Regression loss: 0.27673 | Running loss: 0.74949\n",
      "Epoch: 3 | Iteration: 589 | Classification loss: 0.32810 | Regression loss: 0.34201 | Running loss: 0.74942\n",
      "Epoch: 3 | Iteration: 590 | Classification loss: 0.49235 | Regression loss: 0.62300 | Running loss: 0.75035\n",
      "Epoch: 3 | Iteration: 591 | Classification loss: 0.22072 | Regression loss: 0.71012 | Running loss: 0.75102\n",
      "Epoch: 3 | Iteration: 592 | Classification loss: 0.41968 | Regression loss: 0.44440 | Running loss: 0.75136\n",
      "Epoch: 3 | Iteration: 593 | Classification loss: 0.23210 | Regression loss: 0.50552 | Running loss: 0.75136\n",
      "Epoch: 3 | Iteration: 594 | Classification loss: 0.41778 | Regression loss: 0.42911 | Running loss: 0.75169\n",
      "Epoch: 3 | Iteration: 595 | Classification loss: 0.37682 | Regression loss: 0.26591 | Running loss: 0.75180\n",
      "Epoch: 3 | Iteration: 596 | Classification loss: 0.29454 | Regression loss: 0.32907 | Running loss: 0.75144\n",
      "Epoch: 3 | Iteration: 597 | Classification loss: 0.25662 | Regression loss: 0.41441 | Running loss: 0.75155\n",
      "Epoch: 3 | Iteration: 598 | Classification loss: 0.63511 | Regression loss: 0.67268 | Running loss: 0.75281\n",
      "Epoch: 3 | Iteration: 599 | Classification loss: 0.33260 | Regression loss: 0.42815 | Running loss: 0.75180\n",
      "Epoch: 3 | Iteration: 600 | Classification loss: 0.24128 | Regression loss: 0.62019 | Running loss: 0.75173\n",
      "Epoch: 3 | Iteration: 601 | Classification loss: 0.29956 | Regression loss: 0.37437 | Running loss: 0.75145\n",
      "Epoch: 3 | Iteration: 602 | Classification loss: 0.29822 | Regression loss: 0.31308 | Running loss: 0.75188\n",
      "Epoch: 3 | Iteration: 603 | Classification loss: 0.35492 | Regression loss: 0.62791 | Running loss: 0.75310\n",
      "Epoch: 3 | Iteration: 604 | Classification loss: 0.45459 | Regression loss: 0.66049 | Running loss: 0.75428\n",
      "Epoch: 3 | Iteration: 605 | Classification loss: 0.35136 | Regression loss: 0.63051 | Running loss: 0.75435\n",
      "Epoch: 3 | Iteration: 606 | Classification loss: 0.44796 | Regression loss: 0.65526 | Running loss: 0.75460\n",
      "Epoch: 3 | Iteration: 607 | Classification loss: 0.42989 | Regression loss: 0.39073 | Running loss: 0.75499\n",
      "Epoch: 3 | Iteration: 608 | Classification loss: 0.35442 | Regression loss: 0.28904 | Running loss: 0.75475\n",
      "Epoch: 3 | Iteration: 609 | Classification loss: 0.56137 | Regression loss: 0.46201 | Running loss: 0.75548\n",
      "Epoch: 3 | Iteration: 610 | Classification loss: 0.46798 | Regression loss: 0.70694 | Running loss: 0.75647\n",
      "Epoch: 3 | Iteration: 611 | Classification loss: 0.30358 | Regression loss: 0.38693 | Running loss: 0.75637\n",
      "Epoch: 3 | Iteration: 612 | Classification loss: 0.27381 | Regression loss: 0.39392 | Running loss: 0.75552\n",
      "Epoch: 3 | Iteration: 613 | Classification loss: 0.19500 | Regression loss: 0.30960 | Running loss: 0.75465\n",
      "Epoch: 3 | Iteration: 614 | Classification loss: 0.18922 | Regression loss: 0.39629 | Running loss: 0.75420\n",
      "Epoch: 3 | Iteration: 615 | Classification loss: 0.49290 | Regression loss: 0.51659 | Running loss: 0.75473\n",
      "Epoch: 3 | Iteration: 616 | Classification loss: 0.44959 | Regression loss: 0.28599 | Running loss: 0.75463\n",
      "Epoch: 3 | Iteration: 617 | Classification loss: 0.27561 | Regression loss: 0.49727 | Running loss: 0.75496\n",
      "Epoch: 3 | Iteration: 618 | Classification loss: 0.38251 | Regression loss: 0.55369 | Running loss: 0.75534\n",
      "Epoch: 3 | Iteration: 619 | Classification loss: 0.39554 | Regression loss: 0.39878 | Running loss: 0.75597\n",
      "Epoch: 3 | Iteration: 620 | Classification loss: 0.13106 | Regression loss: 0.22813 | Running loss: 0.75553\n",
      "Epoch: 3 | Iteration: 621 | Classification loss: 0.23255 | Regression loss: 0.27326 | Running loss: 0.75480\n",
      "Epoch: 3 | Iteration: 622 | Classification loss: 0.26818 | Regression loss: 0.43718 | Running loss: 0.75493\n",
      "Epoch: 3 | Iteration: 623 | Classification loss: 0.43099 | Regression loss: 0.60230 | Running loss: 0.75607\n",
      "Epoch: 3 | Iteration: 624 | Classification loss: 0.26831 | Regression loss: 0.41813 | Running loss: 0.75589\n",
      "Epoch: 3 | Iteration: 625 | Classification loss: 0.22116 | Regression loss: 0.57866 | Running loss: 0.75572\n",
      "Epoch: 3 | Iteration: 626 | Classification loss: 0.35125 | Regression loss: 0.25727 | Running loss: 0.75605\n",
      "Epoch: 3 | Iteration: 627 | Classification loss: 0.47215 | Regression loss: 0.58990 | Running loss: 0.75710\n",
      "Epoch: 3 | Iteration: 628 | Classification loss: 0.28939 | Regression loss: 0.46933 | Running loss: 0.75720\n",
      "Epoch: 3 | Iteration: 629 | Classification loss: 0.38351 | Regression loss: 0.25131 | Running loss: 0.75626\n",
      "Epoch: 3 | Iteration: 630 | Classification loss: 0.34345 | Regression loss: 0.38013 | Running loss: 0.75657\n",
      "Epoch: 3 | Iteration: 631 | Classification loss: 0.36446 | Regression loss: 0.75460 | Running loss: 0.75808\n",
      "Epoch: 3 | Iteration: 632 | Classification loss: 0.30374 | Regression loss: 0.63219 | Running loss: 0.75732\n",
      "Epoch: 3 | Iteration: 633 | Classification loss: 0.30852 | Regression loss: 0.26993 | Running loss: 0.75694\n",
      "Epoch: 3 | Iteration: 634 | Classification loss: 0.08012 | Regression loss: 0.18657 | Running loss: 0.75634\n",
      "Epoch: 3 | Iteration: 635 | Classification loss: 0.44024 | Regression loss: 0.52956 | Running loss: 0.75715\n",
      "Epoch: 3 | Iteration: 636 | Classification loss: 0.52616 | Regression loss: 0.24577 | Running loss: 0.75677\n",
      "Epoch: 3 | Iteration: 637 | Classification loss: 0.32365 | Regression loss: 0.39283 | Running loss: 0.75607\n",
      "Epoch: 3 | Iteration: 638 | Classification loss: 0.24400 | Regression loss: 0.31273 | Running loss: 0.75538\n",
      "Epoch: 3 | Iteration: 639 | Classification loss: 0.30126 | Regression loss: 0.26179 | Running loss: 0.75407\n",
      "Epoch: 3 | Iteration: 640 | Classification loss: 0.52233 | Regression loss: 0.69816 | Running loss: 0.75546\n",
      "Epoch: 3 | Iteration: 641 | Classification loss: 0.24515 | Regression loss: 0.30706 | Running loss: 0.75478\n",
      "Epoch: 3 | Iteration: 642 | Classification loss: 0.47179 | Regression loss: 0.74688 | Running loss: 0.75610\n",
      "Epoch: 3 | Iteration: 643 | Classification loss: 0.40306 | Regression loss: 0.47078 | Running loss: 0.75613\n",
      "Epoch: 3 | Iteration: 644 | Classification loss: 0.19654 | Regression loss: 0.23722 | Running loss: 0.75579\n",
      "Epoch: 3 | Iteration: 645 | Classification loss: 0.32932 | Regression loss: 0.44131 | Running loss: 0.75556\n",
      "Epoch: 3 | Iteration: 646 | Classification loss: 0.14355 | Regression loss: 0.23758 | Running loss: 0.75473\n",
      "Epoch: 3 | Iteration: 647 | Classification loss: 0.43990 | Regression loss: 0.35470 | Running loss: 0.75526\n",
      "Epoch: 3 | Iteration: 648 | Classification loss: 0.22617 | Regression loss: 0.33010 | Running loss: 0.75437\n",
      "Epoch: 3 | Iteration: 649 | Classification loss: 0.24298 | Regression loss: 0.39239 | Running loss: 0.75443\n",
      "Epoch: 3 | Iteration: 650 | Classification loss: 0.46753 | Regression loss: 1.06450 | Running loss: 0.75614\n",
      "Epoch: 3 | Iteration: 651 | Classification loss: 0.63600 | Regression loss: 0.74736 | Running loss: 0.75787\n",
      "Epoch: 3 | Iteration: 652 | Classification loss: 0.17455 | Regression loss: 0.28407 | Running loss: 0.75683\n",
      "Epoch: 3 | Iteration: 653 | Classification loss: 0.19397 | Regression loss: 0.19767 | Running loss: 0.75597\n",
      "Epoch: 3 | Iteration: 654 | Classification loss: 0.15782 | Regression loss: 0.14868 | Running loss: 0.75606\n",
      "Epoch: 3 | Iteration: 655 | Classification loss: 0.22084 | Regression loss: 0.46002 | Running loss: 0.75610\n",
      "Epoch: 3 | Iteration: 656 | Classification loss: 0.21574 | Regression loss: 0.47077 | Running loss: 0.75607\n",
      "Epoch: 3 | Iteration: 657 | Classification loss: 0.32802 | Regression loss: 0.17000 | Running loss: 0.75589\n",
      "Epoch: 3 | Iteration: 658 | Classification loss: 0.24300 | Regression loss: 0.26117 | Running loss: 0.75551\n",
      "Epoch: 3 | Iteration: 659 | Classification loss: 0.36244 | Regression loss: 0.62652 | Running loss: 0.75637\n",
      "Epoch: 3 | Iteration: 660 | Classification loss: 0.20743 | Regression loss: 0.54397 | Running loss: 0.75545\n",
      "Epoch: 3 | Iteration: 661 | Classification loss: 0.41312 | Regression loss: 0.52700 | Running loss: 0.75647\n",
      "Epoch: 3 | Iteration: 662 | Classification loss: 0.34626 | Regression loss: 0.45072 | Running loss: 0.75655\n",
      "Epoch: 3 | Iteration: 663 | Classification loss: 0.26545 | Regression loss: 0.29319 | Running loss: 0.75626\n",
      "Epoch: 3 | Iteration: 664 | Classification loss: 0.11787 | Regression loss: 0.14908 | Running loss: 0.75422\n",
      "Epoch: 3 | Iteration: 665 | Classification loss: 0.55296 | Regression loss: 0.28289 | Running loss: 0.75366\n",
      "Epoch: 3 | Iteration: 666 | Classification loss: 0.34692 | Regression loss: 0.49662 | Running loss: 0.75376\n",
      "Epoch: 3 | Iteration: 667 | Classification loss: 0.14606 | Regression loss: 0.40055 | Running loss: 0.75322\n",
      "Epoch: 3 | Iteration: 668 | Classification loss: 0.22903 | Regression loss: 0.30852 | Running loss: 0.75340\n",
      "Epoch: 3 | Iteration: 669 | Classification loss: 0.61107 | Regression loss: 0.81427 | Running loss: 0.75440\n",
      "Epoch: 3 | Iteration: 670 | Classification loss: 0.39111 | Regression loss: 0.70072 | Running loss: 0.75555\n",
      "Epoch: 3 | Iteration: 671 | Classification loss: 0.68688 | Regression loss: 0.00000 | Running loss: 0.75557\n",
      "Epoch: 3 | Iteration: 672 | Classification loss: 0.43111 | Regression loss: 0.28268 | Running loss: 0.75466\n",
      "Epoch: 3 | Iteration: 673 | Classification loss: 0.38239 | Regression loss: 0.51459 | Running loss: 0.75570\n",
      "Epoch: 3 | Iteration: 674 | Classification loss: 0.41116 | Regression loss: 0.22760 | Running loss: 0.75617\n",
      "Epoch: 3 | Iteration: 675 | Classification loss: 0.39627 | Regression loss: 0.27365 | Running loss: 0.75638\n",
      "Epoch: 3 | Iteration: 676 | Classification loss: 0.15563 | Regression loss: 0.35798 | Running loss: 0.75600\n",
      "Epoch: 3 | Iteration: 677 | Classification loss: 0.32650 | Regression loss: 0.42645 | Running loss: 0.75640\n",
      "Epoch: 3 | Iteration: 678 | Classification loss: 0.24782 | Regression loss: 0.53757 | Running loss: 0.75598\n",
      "Epoch: 3 | Iteration: 679 | Classification loss: 0.09687 | Regression loss: 0.20091 | Running loss: 0.75428\n",
      "Epoch: 3 | Iteration: 680 | Classification loss: 0.37034 | Regression loss: 0.49160 | Running loss: 0.75458\n",
      "Epoch: 3 | Iteration: 681 | Classification loss: 0.21359 | Regression loss: 0.37955 | Running loss: 0.75449\n",
      "Epoch: 3 | Iteration: 682 | Classification loss: 0.20505 | Regression loss: 0.42825 | Running loss: 0.75500\n",
      "Epoch: 3 | Iteration: 683 | Classification loss: 0.19810 | Regression loss: 0.34294 | Running loss: 0.75460\n",
      "Epoch: 3 | Iteration: 684 | Classification loss: 0.30218 | Regression loss: 0.42204 | Running loss: 0.75446\n",
      "Epoch: 3 | Iteration: 685 | Classification loss: 0.24345 | Regression loss: 0.24314 | Running loss: 0.75409\n",
      "Epoch: 3 | Iteration: 686 | Classification loss: 0.40986 | Regression loss: 0.50644 | Running loss: 0.75405\n",
      "Epoch: 3 | Iteration: 687 | Classification loss: 0.44099 | Regression loss: 0.58672 | Running loss: 0.75409\n",
      "Epoch: 3 | Iteration: 688 | Classification loss: 0.21510 | Regression loss: 0.52551 | Running loss: 0.75375\n",
      "Epoch: 3 | Iteration: 689 | Classification loss: 0.40548 | Regression loss: 0.49629 | Running loss: 0.75349\n",
      "Epoch: 3 | Iteration: 690 | Classification loss: 0.21310 | Regression loss: 0.15664 | Running loss: 0.75310\n",
      "Epoch: 3 | Iteration: 691 | Classification loss: 0.19338 | Regression loss: 0.20747 | Running loss: 0.75190\n",
      "Epoch: 3 | Iteration: 692 | Classification loss: 0.38342 | Regression loss: 0.42583 | Running loss: 0.75186\n",
      "Epoch: 3 | Iteration: 693 | Classification loss: 0.21757 | Regression loss: 0.46871 | Running loss: 0.75114\n",
      "Epoch: 3 | Iteration: 694 | Classification loss: 0.26539 | Regression loss: 0.41507 | Running loss: 0.75145\n",
      "Epoch: 3 | Iteration: 695 | Classification loss: 0.20144 | Regression loss: 0.14746 | Running loss: 0.75040\n",
      "Epoch: 3 | Iteration: 696 | Classification loss: 0.19972 | Regression loss: 0.48559 | Running loss: 0.75048\n",
      "Epoch: 3 | Iteration: 697 | Classification loss: 0.22700 | Regression loss: 0.24377 | Running loss: 0.75027\n",
      "Epoch: 3 | Iteration: 698 | Classification loss: 0.23882 | Regression loss: 0.36533 | Running loss: 0.75036\n",
      "Epoch: 3 | Iteration: 699 | Classification loss: 0.22987 | Regression loss: 0.00000 | Running loss: 0.74926\n",
      "Epoch: 3 | Iteration: 700 | Classification loss: 0.45109 | Regression loss: 1.07738 | Running loss: 0.75122\n",
      "Epoch: 3 | Iteration: 701 | Classification loss: 0.19080 | Regression loss: 0.13437 | Running loss: 0.75000\n",
      "Epoch: 3 | Iteration: 702 | Classification loss: 0.43591 | Regression loss: 0.78449 | Running loss: 0.75132\n",
      "Epoch: 3 | Iteration: 703 | Classification loss: 0.28972 | Regression loss: 0.50441 | Running loss: 0.75069\n",
      "Epoch: 3 | Iteration: 704 | Classification loss: 0.21952 | Regression loss: 0.33614 | Running loss: 0.75056\n",
      "Epoch: 3 | Iteration: 705 | Classification loss: 0.11544 | Regression loss: 0.30057 | Running loss: 0.74990\n",
      "Epoch: 3 | Iteration: 706 | Classification loss: 0.26869 | Regression loss: 0.34157 | Running loss: 0.74984\n",
      "Epoch: 3 | Iteration: 707 | Classification loss: 0.22332 | Regression loss: 0.20593 | Running loss: 0.74850\n",
      "Epoch: 3 | Iteration: 708 | Classification loss: 0.61151 | Regression loss: 0.76628 | Running loss: 0.74983\n",
      "Epoch: 3 | Iteration: 709 | Classification loss: 0.36767 | Regression loss: 0.70269 | Running loss: 0.75078\n",
      "Epoch: 3 | Iteration: 710 | Classification loss: 0.37195 | Regression loss: 0.56914 | Running loss: 0.75149\n",
      "Epoch: 3 | Iteration: 711 | Classification loss: 0.30159 | Regression loss: 0.31884 | Running loss: 0.75165\n",
      "Epoch: 3 | Iteration: 712 | Classification loss: 0.22376 | Regression loss: 0.28257 | Running loss: 0.75168\n",
      "Epoch: 3 | Iteration: 713 | Classification loss: 0.36963 | Regression loss: 0.62979 | Running loss: 0.75191\n",
      "Epoch: 3 | Iteration: 714 | Classification loss: 0.45435 | Regression loss: 0.53220 | Running loss: 0.75255\n",
      "Epoch: 3 | Iteration: 715 | Classification loss: 0.38902 | Regression loss: 0.51109 | Running loss: 0.75315\n",
      "Epoch: 3 | Iteration: 716 | Classification loss: 0.39523 | Regression loss: 0.20813 | Running loss: 0.75331\n",
      "Epoch: 3 | Iteration: 717 | Classification loss: 0.10168 | Regression loss: 0.26509 | Running loss: 0.75264\n",
      "Epoch: 3 | Iteration: 718 | Classification loss: 0.19339 | Regression loss: 0.39973 | Running loss: 0.75251\n",
      "Epoch: 3 | Iteration: 719 | Classification loss: 0.33557 | Regression loss: 0.38194 | Running loss: 0.75226\n",
      "Epoch: 3 | Iteration: 720 | Classification loss: 0.17509 | Regression loss: 0.21938 | Running loss: 0.75203\n",
      "Epoch: 3 | Iteration: 721 | Classification loss: 0.61982 | Regression loss: 0.69891 | Running loss: 0.75277\n",
      "Epoch: 3 | Iteration: 722 | Classification loss: 0.43448 | Regression loss: 0.48987 | Running loss: 0.75332\n",
      "Epoch: 3 | Iteration: 723 | Classification loss: 0.41394 | Regression loss: 0.25108 | Running loss: 0.75300\n",
      "Epoch: 3 | Iteration: 724 | Classification loss: 0.13428 | Regression loss: 0.26817 | Running loss: 0.75226\n",
      "Epoch: 3 | Iteration: 725 | Classification loss: 0.38714 | Regression loss: 0.53975 | Running loss: 0.75249\n",
      "Epoch: 3 | Iteration: 726 | Classification loss: 0.29815 | Regression loss: 0.65011 | Running loss: 0.75225\n",
      "Epoch: 3 | Iteration: 727 | Classification loss: 0.24796 | Regression loss: 0.23550 | Running loss: 0.75226\n",
      "Epoch: 3 | Iteration: 728 | Classification loss: 0.10753 | Regression loss: 0.19379 | Running loss: 0.75125\n",
      "Epoch: 3 | Iteration: 729 | Classification loss: 0.16813 | Regression loss: 0.52395 | Running loss: 0.75129\n",
      "Epoch: 3 | Iteration: 730 | Classification loss: 0.41996 | Regression loss: 0.64082 | Running loss: 0.75222\n",
      "Epoch: 3 | Iteration: 731 | Classification loss: 0.22575 | Regression loss: 0.26787 | Running loss: 0.75179\n",
      "Epoch: 3 | Iteration: 732 | Classification loss: 0.38717 | Regression loss: 0.30534 | Running loss: 0.75191\n",
      "Epoch: 3 | Iteration: 733 | Classification loss: 0.33672 | Regression loss: 0.21575 | Running loss: 0.75165\n",
      "Epoch: 3 | Iteration: 734 | Classification loss: 0.26609 | Regression loss: 0.25676 | Running loss: 0.75153\n",
      "Epoch: 3 | Iteration: 735 | Classification loss: 0.26333 | Regression loss: 0.33408 | Running loss: 0.75143\n",
      "Epoch: 3 | Iteration: 736 | Classification loss: 0.13311 | Regression loss: 0.24074 | Running loss: 0.75141\n",
      "Epoch: 3 | Iteration: 737 | Classification loss: 0.45315 | Regression loss: 0.44072 | Running loss: 0.75200\n",
      "Epoch: 3 | Iteration: 738 | Classification loss: 0.80730 | Regression loss: 0.76274 | Running loss: 0.75335\n",
      "Epoch: 3 | Iteration: 739 | Classification loss: 0.69722 | Regression loss: 0.07767 | Running loss: 0.75317\n",
      "Epoch: 3 | Iteration: 740 | Classification loss: 0.42797 | Regression loss: 0.15553 | Running loss: 0.75297\n",
      "Epoch: 3 | Iteration: 741 | Classification loss: 0.42540 | Regression loss: 0.58834 | Running loss: 0.75403\n",
      "Epoch: 3 | Iteration: 742 | Classification loss: 0.27553 | Regression loss: 0.54379 | Running loss: 0.75390\n",
      "Epoch: 3 | Iteration: 743 | Classification loss: 0.37493 | Regression loss: 0.61199 | Running loss: 0.75488\n",
      "Epoch: 3 | Iteration: 744 | Classification loss: 0.71285 | Regression loss: 0.70876 | Running loss: 0.75550\n",
      "Epoch: 3 | Iteration: 745 | Classification loss: 0.23666 | Regression loss: 0.61967 | Running loss: 0.75567\n",
      "Epoch: 3 | Iteration: 746 | Classification loss: 0.21178 | Regression loss: 0.71227 | Running loss: 0.75673\n",
      "Epoch: 3 | Iteration: 747 | Classification loss: 0.25823 | Regression loss: 0.45470 | Running loss: 0.75683\n",
      "Epoch: 3 | Iteration: 748 | Classification loss: 0.51598 | Regression loss: 0.45459 | Running loss: 0.75772\n",
      "Epoch: 3 | Iteration: 749 | Classification loss: 0.43254 | Regression loss: 0.29842 | Running loss: 0.75813\n",
      "Epoch: 3 | Iteration: 750 | Classification loss: 0.80744 | Regression loss: 0.57744 | Running loss: 0.75917\n",
      "Epoch: 3 | Iteration: 751 | Classification loss: 0.36598 | Regression loss: 0.69988 | Running loss: 0.76012\n",
      "Epoch: 3 | Iteration: 752 | Classification loss: 0.67816 | Regression loss: 0.21718 | Running loss: 0.76084\n",
      "Epoch: 3 | Iteration: 753 | Classification loss: 0.20925 | Regression loss: 0.52115 | Running loss: 0.76092\n",
      "Epoch: 3 | Iteration: 754 | Classification loss: 0.22530 | Regression loss: 0.67027 | Running loss: 0.76074\n",
      "Epoch: 3 | Iteration: 755 | Classification loss: 0.24938 | Regression loss: 0.22852 | Running loss: 0.76048\n",
      "Epoch: 3 | Iteration: 756 | Classification loss: 0.88325 | Regression loss: 0.43053 | Running loss: 0.76181\n",
      "Epoch: 3 | Iteration: 757 | Classification loss: 0.41787 | Regression loss: 0.47958 | Running loss: 0.76200\n",
      "Epoch: 3 | Iteration: 758 | Classification loss: 0.36741 | Regression loss: 0.36538 | Running loss: 0.76049\n",
      "Epoch: 3 | Iteration: 759 | Classification loss: 0.28468 | Regression loss: 0.44801 | Running loss: 0.76073\n",
      "Epoch: 3 | Iteration: 760 | Classification loss: 0.21315 | Regression loss: 0.23654 | Running loss: 0.75996\n",
      "Epoch: 3 | Iteration: 761 | Classification loss: 0.21529 | Regression loss: 0.35367 | Running loss: 0.75991\n",
      "Epoch: 3 | Iteration: 762 | Classification loss: 0.31509 | Regression loss: 0.24165 | Running loss: 0.75957\n",
      "Epoch: 3 | Iteration: 763 | Classification loss: 0.35668 | Regression loss: 0.36670 | Running loss: 0.75951\n",
      "Epoch: 3 | Iteration: 764 | Classification loss: 0.31508 | Regression loss: 0.48916 | Running loss: 0.76049\n",
      "Epoch: 3 | Iteration: 765 | Classification loss: 0.16937 | Regression loss: 0.25109 | Running loss: 0.75904\n",
      "Epoch: 3 | Iteration: 766 | Classification loss: 0.17633 | Regression loss: 0.44015 | Running loss: 0.75886\n",
      "Epoch: 3 | Iteration: 767 | Classification loss: 0.25354 | Regression loss: 0.16984 | Running loss: 0.75765\n",
      "Epoch: 3 | Iteration: 768 | Classification loss: 0.18376 | Regression loss: 0.66415 | Running loss: 0.75744\n",
      "Epoch: 3 | Iteration: 769 | Classification loss: 0.24320 | Regression loss: 0.41283 | Running loss: 0.75745\n",
      "Epoch: 3 | Iteration: 770 | Classification loss: 0.38862 | Regression loss: 0.20828 | Running loss: 0.75774\n",
      "Epoch: 3 | Iteration: 771 | Classification loss: 0.45975 | Regression loss: 0.26497 | Running loss: 0.75793\n",
      "Epoch: 3 | Iteration: 772 | Classification loss: 0.16713 | Regression loss: 0.38415 | Running loss: 0.75808\n",
      "Epoch: 3 | Iteration: 773 | Classification loss: 0.45063 | Regression loss: 0.41415 | Running loss: 0.75879\n",
      "Epoch: 3 | Iteration: 774 | Classification loss: 0.58864 | Regression loss: 0.77413 | Running loss: 0.75965\n",
      "Epoch: 3 | Iteration: 775 | Classification loss: 0.42524 | Regression loss: 0.47767 | Running loss: 0.75929\n",
      "Epoch: 3 | Iteration: 776 | Classification loss: 0.35666 | Regression loss: 0.35752 | Running loss: 0.75954\n",
      "Epoch: 3 | Iteration: 777 | Classification loss: 0.37765 | Regression loss: 0.31845 | Running loss: 0.75925\n",
      "Epoch: 3 | Iteration: 778 | Classification loss: 0.43547 | Regression loss: 0.53010 | Running loss: 0.75870\n",
      "Epoch: 3 | Iteration: 779 | Classification loss: 0.28948 | Regression loss: 0.29273 | Running loss: 0.75757\n",
      "Epoch: 3 | Iteration: 780 | Classification loss: 0.22283 | Regression loss: 0.55418 | Running loss: 0.75738\n",
      "Epoch: 3 | Iteration: 781 | Classification loss: 0.38567 | Regression loss: 0.28832 | Running loss: 0.75728\n",
      "Epoch: 3 | Iteration: 782 | Classification loss: 0.10018 | Regression loss: 0.31386 | Running loss: 0.75675\n",
      "Epoch: 3 | Iteration: 783 | Classification loss: 0.39561 | Regression loss: 0.23552 | Running loss: 0.75748\n",
      "Epoch: 3 | Iteration: 784 | Classification loss: 0.26282 | Regression loss: 0.42885 | Running loss: 0.75662\n",
      "Epoch: 3 | Iteration: 785 | Classification loss: 0.37540 | Regression loss: 0.45771 | Running loss: 0.75739\n",
      "Epoch: 3 | Iteration: 786 | Classification loss: 0.49074 | Regression loss: 0.67065 | Running loss: 0.75812\n",
      "Epoch: 3 | Iteration: 787 | Classification loss: 0.16428 | Regression loss: 0.29435 | Running loss: 0.75849\n",
      "Epoch: 3 | Iteration: 788 | Classification loss: 0.30919 | Regression loss: 0.37764 | Running loss: 0.75784\n",
      "Epoch: 3 | Iteration: 789 | Classification loss: 0.18402 | Regression loss: 0.19232 | Running loss: 0.75579\n",
      "Epoch: 3 | Iteration: 790 | Classification loss: 0.43508 | Regression loss: 0.35041 | Running loss: 0.75559\n",
      "Epoch: 3 | Iteration: 791 | Classification loss: 0.44941 | Regression loss: 0.78496 | Running loss: 0.75643\n",
      "Epoch: 3 | Iteration: 792 | Classification loss: 0.33392 | Regression loss: 0.22775 | Running loss: 0.75617\n",
      "Epoch: 3 | Iteration: 793 | Classification loss: 0.29230 | Regression loss: 0.21337 | Running loss: 0.75606\n",
      "Epoch: 3 | Iteration: 794 | Classification loss: 0.26672 | Regression loss: 0.33332 | Running loss: 0.75576\n",
      "Epoch: 3 | Iteration: 795 | Classification loss: 0.31019 | Regression loss: 0.55875 | Running loss: 0.75668\n",
      "Epoch: 3 | Iteration: 796 | Classification loss: 0.10410 | Regression loss: 0.26866 | Running loss: 0.75541\n",
      "Epoch: 3 | Iteration: 797 | Classification loss: 0.25456 | Regression loss: 0.48484 | Running loss: 0.75499\n",
      "Epoch: 3 | Iteration: 798 | Classification loss: 0.17648 | Regression loss: 0.40021 | Running loss: 0.75343\n",
      "Epoch: 3 | Iteration: 799 | Classification loss: 0.19853 | Regression loss: 0.24867 | Running loss: 0.75296\n",
      "Epoch: 3 | Iteration: 800 | Classification loss: 0.09926 | Regression loss: 0.18983 | Running loss: 0.75152\n",
      "Epoch: 3 | Iteration: 801 | Classification loss: 0.32085 | Regression loss: 0.57965 | Running loss: 0.75096\n",
      "Epoch: 3 | Iteration: 802 | Classification loss: 0.29903 | Regression loss: 0.36465 | Running loss: 0.75033\n",
      "Epoch: 3 | Iteration: 803 | Classification loss: 0.33048 | Regression loss: 0.24312 | Running loss: 0.74992\n",
      "Epoch: 3 | Iteration: 804 | Classification loss: 0.27392 | Regression loss: 0.50415 | Running loss: 0.75002\n",
      "Epoch: 3 | Iteration: 805 | Classification loss: 0.11793 | Regression loss: 0.40742 | Running loss: 0.74871\n",
      "Epoch: 3 | Iteration: 806 | Classification loss: 0.35592 | Regression loss: 0.35943 | Running loss: 0.74790\n",
      "Epoch: 3 | Iteration: 807 | Classification loss: 0.15407 | Regression loss: 0.30632 | Running loss: 0.74723\n",
      "Epoch: 3 | Iteration: 808 | Classification loss: 0.20456 | Regression loss: 0.38289 | Running loss: 0.74690\n",
      "Epoch: 3 | Iteration: 809 | Classification loss: 0.32261 | Regression loss: 0.36941 | Running loss: 0.74653\n",
      "Epoch: 3 | Iteration: 810 | Classification loss: 0.14413 | Regression loss: 0.51895 | Running loss: 0.74696\n",
      "Epoch: 3 | Iteration: 811 | Classification loss: 0.42546 | Regression loss: 0.56268 | Running loss: 0.74703\n",
      "Epoch: 3 | Iteration: 812 | Classification loss: 0.30675 | Regression loss: 0.24663 | Running loss: 0.74547\n",
      "Epoch: 3 | Iteration: 813 | Classification loss: 0.54049 | Regression loss: 0.55147 | Running loss: 0.74615\n",
      "Epoch: 3 | Iteration: 814 | Classification loss: 0.25945 | Regression loss: 0.25259 | Running loss: 0.74553\n",
      "Epoch: 3 | Iteration: 815 | Classification loss: 0.17946 | Regression loss: 0.50667 | Running loss: 0.74420\n",
      "Epoch: 3 | Iteration: 816 | Classification loss: 0.30320 | Regression loss: 0.43857 | Running loss: 0.74391\n",
      "Epoch: 3 | Iteration: 817 | Classification loss: 0.30747 | Regression loss: 0.41524 | Running loss: 0.74327\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.521\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 4 | Iteration: 0 | Classification loss: 0.23996 | Regression loss: 0.64524 | Running loss: 0.74209\n",
      "Epoch: 4 | Iteration: 1 | Classification loss: 0.32404 | Regression loss: 0.21303 | Running loss: 0.74235\n",
      "Epoch: 4 | Iteration: 2 | Classification loss: 0.07086 | Regression loss: 0.18688 | Running loss: 0.74138\n",
      "Epoch: 4 | Iteration: 3 | Classification loss: 0.37996 | Regression loss: 0.51032 | Running loss: 0.74143\n",
      "Epoch: 4 | Iteration: 4 | Classification loss: 0.29238 | Regression loss: 0.30008 | Running loss: 0.74135\n",
      "Epoch: 4 | Iteration: 5 | Classification loss: 0.34123 | Regression loss: 0.44506 | Running loss: 0.74057\n",
      "Epoch: 4 | Iteration: 6 | Classification loss: 0.25712 | Regression loss: 0.22030 | Running loss: 0.74016\n",
      "Epoch: 4 | Iteration: 7 | Classification loss: 0.34987 | Regression loss: 0.37771 | Running loss: 0.74033\n",
      "Epoch: 4 | Iteration: 8 | Classification loss: 0.17697 | Regression loss: 0.24997 | Running loss: 0.73927\n",
      "Epoch: 4 | Iteration: 9 | Classification loss: 0.11516 | Regression loss: 0.52460 | Running loss: 0.73901\n",
      "Epoch: 4 | Iteration: 10 | Classification loss: 0.33943 | Regression loss: 0.55735 | Running loss: 0.73913\n",
      "Epoch: 4 | Iteration: 11 | Classification loss: 0.14885 | Regression loss: 0.34013 | Running loss: 0.73894\n",
      "Epoch: 4 | Iteration: 12 | Classification loss: 0.47232 | Regression loss: 0.48335 | Running loss: 0.74029\n",
      "Epoch: 4 | Iteration: 13 | Classification loss: 0.21426 | Regression loss: 0.35546 | Running loss: 0.74036\n",
      "Epoch: 4 | Iteration: 14 | Classification loss: 0.41308 | Regression loss: 0.56858 | Running loss: 0.74022\n",
      "Epoch: 4 | Iteration: 15 | Classification loss: 0.32246 | Regression loss: 0.45263 | Running loss: 0.74089\n",
      "Epoch: 4 | Iteration: 16 | Classification loss: 0.26232 | Regression loss: 0.29240 | Running loss: 0.74049\n",
      "Epoch: 4 | Iteration: 17 | Classification loss: 0.27460 | Regression loss: 0.29922 | Running loss: 0.73995\n",
      "Epoch: 4 | Iteration: 18 | Classification loss: 0.16791 | Regression loss: 0.32927 | Running loss: 0.73934\n",
      "Epoch: 4 | Iteration: 19 | Classification loss: 0.23019 | Regression loss: 0.58201 | Running loss: 0.73972\n",
      "Epoch: 4 | Iteration: 20 | Classification loss: 0.25410 | Regression loss: 0.48333 | Running loss: 0.74027\n",
      "Epoch: 4 | Iteration: 21 | Classification loss: 0.39475 | Regression loss: 0.58548 | Running loss: 0.74039\n",
      "Epoch: 4 | Iteration: 22 | Classification loss: 0.25118 | Regression loss: 0.55634 | Running loss: 0.74068\n",
      "Epoch: 4 | Iteration: 23 | Classification loss: 0.22161 | Regression loss: 0.41551 | Running loss: 0.74078\n",
      "Epoch: 4 | Iteration: 24 | Classification loss: 0.39723 | Regression loss: 0.34491 | Running loss: 0.74054\n",
      "Epoch: 4 | Iteration: 25 | Classification loss: 0.27374 | Regression loss: 0.44422 | Running loss: 0.73993\n",
      "Epoch: 4 | Iteration: 26 | Classification loss: 0.16801 | Regression loss: 0.26543 | Running loss: 0.73932\n",
      "Epoch: 4 | Iteration: 27 | Classification loss: 0.49772 | Regression loss: 0.46418 | Running loss: 0.73895\n",
      "Epoch: 4 | Iteration: 28 | Classification loss: 0.34626 | Regression loss: 0.45411 | Running loss: 0.73891\n",
      "Epoch: 4 | Iteration: 29 | Classification loss: 0.08142 | Regression loss: 0.25098 | Running loss: 0.73751\n",
      "Epoch: 4 | Iteration: 30 | Classification loss: 0.44209 | Regression loss: 0.24742 | Running loss: 0.73743\n",
      "Epoch: 4 | Iteration: 31 | Classification loss: 0.23655 | Regression loss: 0.42553 | Running loss: 0.73686\n",
      "Epoch: 4 | Iteration: 32 | Classification loss: 0.32498 | Regression loss: 0.36284 | Running loss: 0.73760\n",
      "Epoch: 4 | Iteration: 33 | Classification loss: 0.42190 | Regression loss: 0.60278 | Running loss: 0.73835\n",
      "Epoch: 4 | Iteration: 34 | Classification loss: 0.35186 | Regression loss: 0.32883 | Running loss: 0.73798\n",
      "Epoch: 4 | Iteration: 35 | Classification loss: 0.22424 | Regression loss: 0.32416 | Running loss: 0.73785\n",
      "Epoch: 4 | Iteration: 36 | Classification loss: 0.14607 | Regression loss: 0.35618 | Running loss: 0.73739\n",
      "Epoch: 4 | Iteration: 37 | Classification loss: 0.27772 | Regression loss: 0.26337 | Running loss: 0.73697\n",
      "Epoch: 4 | Iteration: 38 | Classification loss: 0.26926 | Regression loss: 0.53603 | Running loss: 0.73741\n",
      "Epoch: 4 | Iteration: 39 | Classification loss: 0.26721 | Regression loss: 0.35890 | Running loss: 0.73747\n",
      "Epoch: 4 | Iteration: 40 | Classification loss: 0.40198 | Regression loss: 0.35803 | Running loss: 0.73756\n",
      "Epoch: 4 | Iteration: 41 | Classification loss: 0.18518 | Regression loss: 0.35930 | Running loss: 0.73690\n",
      "Epoch: 4 | Iteration: 42 | Classification loss: 0.38548 | Regression loss: 0.46471 | Running loss: 0.73687\n",
      "Epoch: 4 | Iteration: 43 | Classification loss: 0.30423 | Regression loss: 0.16814 | Running loss: 0.73622\n",
      "Epoch: 4 | Iteration: 44 | Classification loss: 0.30831 | Regression loss: 0.18197 | Running loss: 0.73534\n",
      "Epoch: 4 | Iteration: 45 | Classification loss: 0.42438 | Regression loss: 0.39522 | Running loss: 0.73525\n",
      "Epoch: 4 | Iteration: 46 | Classification loss: 0.22692 | Regression loss: 0.19304 | Running loss: 0.73476\n",
      "Epoch: 4 | Iteration: 47 | Classification loss: 0.25831 | Regression loss: 0.12133 | Running loss: 0.73401\n",
      "Epoch: 4 | Iteration: 48 | Classification loss: 0.22775 | Regression loss: 0.32085 | Running loss: 0.73363\n",
      "Epoch: 4 | Iteration: 49 | Classification loss: 0.17361 | Regression loss: 0.42046 | Running loss: 0.73335\n",
      "Epoch: 4 | Iteration: 50 | Classification loss: 0.21330 | Regression loss: 0.50230 | Running loss: 0.73329\n",
      "Epoch: 4 | Iteration: 51 | Classification loss: 0.33178 | Regression loss: 0.21519 | Running loss: 0.73328\n",
      "Epoch: 4 | Iteration: 52 | Classification loss: 0.51990 | Regression loss: 0.29945 | Running loss: 0.73325\n",
      "Epoch: 4 | Iteration: 53 | Classification loss: 0.31088 | Regression loss: 0.53115 | Running loss: 0.73391\n",
      "Epoch: 4 | Iteration: 54 | Classification loss: 0.13754 | Regression loss: 0.14081 | Running loss: 0.73322\n",
      "Epoch: 4 | Iteration: 55 | Classification loss: 0.25557 | Regression loss: 0.12734 | Running loss: 0.73293\n",
      "Epoch: 4 | Iteration: 56 | Classification loss: 0.14808 | Regression loss: 0.20000 | Running loss: 0.73223\n",
      "Epoch: 4 | Iteration: 57 | Classification loss: 0.26296 | Regression loss: 0.18678 | Running loss: 0.73099\n",
      "Epoch: 4 | Iteration: 58 | Classification loss: 0.11074 | Regression loss: 0.12509 | Running loss: 0.73020\n",
      "Epoch: 4 | Iteration: 59 | Classification loss: 0.21997 | Regression loss: 0.28470 | Running loss: 0.72941\n",
      "Epoch: 4 | Iteration: 60 | Classification loss: 0.24442 | Regression loss: 0.45470 | Running loss: 0.72946\n",
      "Epoch: 4 | Iteration: 61 | Classification loss: 0.44646 | Regression loss: 0.53763 | Running loss: 0.72902\n",
      "Epoch: 4 | Iteration: 62 | Classification loss: 0.49207 | Regression loss: 0.65957 | Running loss: 0.73038\n",
      "Epoch: 4 | Iteration: 63 | Classification loss: 0.42735 | Regression loss: 0.30900 | Running loss: 0.73033\n",
      "Epoch: 4 | Iteration: 64 | Classification loss: 0.28807 | Regression loss: 0.75838 | Running loss: 0.73096\n",
      "Epoch: 4 | Iteration: 65 | Classification loss: 0.30946 | Regression loss: 0.30512 | Running loss: 0.73074\n",
      "Epoch: 4 | Iteration: 66 | Classification loss: 0.39835 | Regression loss: 0.49648 | Running loss: 0.73005\n",
      "Epoch: 4 | Iteration: 67 | Classification loss: 0.25469 | Regression loss: 0.34932 | Running loss: 0.72956\n",
      "Epoch: 4 | Iteration: 68 | Classification loss: 0.18957 | Regression loss: 0.32455 | Running loss: 0.72805\n",
      "Epoch: 4 | Iteration: 69 | Classification loss: 0.12466 | Regression loss: 0.30881 | Running loss: 0.72769\n",
      "Epoch: 4 | Iteration: 70 | Classification loss: 0.20844 | Regression loss: 0.18446 | Running loss: 0.72704\n",
      "Epoch: 4 | Iteration: 71 | Classification loss: 0.19087 | Regression loss: 0.26600 | Running loss: 0.72631\n",
      "Epoch: 4 | Iteration: 72 | Classification loss: 0.34351 | Regression loss: 0.41485 | Running loss: 0.72683\n",
      "Epoch: 4 | Iteration: 73 | Classification loss: 0.22378 | Regression loss: 0.41073 | Running loss: 0.72675\n",
      "Epoch: 4 | Iteration: 74 | Classification loss: 0.34824 | Regression loss: 0.30506 | Running loss: 0.72658\n",
      "Epoch: 4 | Iteration: 75 | Classification loss: 0.26049 | Regression loss: 0.23555 | Running loss: 0.72627\n",
      "Epoch: 4 | Iteration: 76 | Classification loss: 0.23420 | Regression loss: 0.57374 | Running loss: 0.72666\n",
      "Epoch: 4 | Iteration: 77 | Classification loss: 0.19136 | Regression loss: 0.48170 | Running loss: 0.72691\n",
      "Epoch: 4 | Iteration: 78 | Classification loss: 0.15088 | Regression loss: 0.18237 | Running loss: 0.72573\n",
      "Epoch: 4 | Iteration: 79 | Classification loss: 0.20999 | Regression loss: 0.32594 | Running loss: 0.72604\n",
      "Epoch: 4 | Iteration: 80 | Classification loss: 0.16794 | Regression loss: 0.33842 | Running loss: 0.72543\n",
      "Epoch: 4 | Iteration: 81 | Classification loss: 0.42845 | Regression loss: 0.60243 | Running loss: 0.72630\n",
      "Epoch: 4 | Iteration: 82 | Classification loss: 0.19769 | Regression loss: 0.97580 | Running loss: 0.72746\n",
      "Epoch: 4 | Iteration: 83 | Classification loss: 0.21895 | Regression loss: 0.40778 | Running loss: 0.72785\n",
      "Epoch: 4 | Iteration: 84 | Classification loss: 0.42152 | Regression loss: 0.80413 | Running loss: 0.72876\n",
      "Epoch: 4 | Iteration: 85 | Classification loss: 0.42708 | Regression loss: 0.38278 | Running loss: 0.72808\n",
      "Epoch: 4 | Iteration: 86 | Classification loss: 0.52480 | Regression loss: 0.66042 | Running loss: 0.72852\n",
      "Epoch: 4 | Iteration: 87 | Classification loss: 0.35499 | Regression loss: 0.48674 | Running loss: 0.72823\n",
      "Epoch: 4 | Iteration: 88 | Classification loss: 0.18489 | Regression loss: 0.48459 | Running loss: 0.72767\n",
      "Epoch: 4 | Iteration: 89 | Classification loss: 0.16369 | Regression loss: 0.49376 | Running loss: 0.72653\n",
      "Epoch: 4 | Iteration: 90 | Classification loss: 0.62497 | Regression loss: 0.22325 | Running loss: 0.72558\n",
      "Epoch: 4 | Iteration: 91 | Classification loss: 0.07420 | Regression loss: 0.29961 | Running loss: 0.72521\n",
      "Epoch: 4 | Iteration: 92 | Classification loss: 0.29391 | Regression loss: 0.32650 | Running loss: 0.72490\n",
      "Epoch: 4 | Iteration: 93 | Classification loss: 1.20779 | Regression loss: 1.09235 | Running loss: 0.72823\n",
      "Epoch: 4 | Iteration: 94 | Classification loss: 0.58241 | Regression loss: 0.45424 | Running loss: 0.72901\n",
      "Epoch: 4 | Iteration: 95 | Classification loss: 0.16374 | Regression loss: 0.50626 | Running loss: 0.72846\n",
      "Epoch: 4 | Iteration: 96 | Classification loss: 0.10941 | Regression loss: 0.19134 | Running loss: 0.72729\n",
      "Epoch: 4 | Iteration: 97 | Classification loss: 0.21858 | Regression loss: 0.33417 | Running loss: 0.72593\n",
      "Epoch: 4 | Iteration: 98 | Classification loss: 0.51170 | Regression loss: 0.22527 | Running loss: 0.72550\n",
      "Epoch: 4 | Iteration: 99 | Classification loss: 0.14050 | Regression loss: 0.22536 | Running loss: 0.72514\n",
      "Epoch: 4 | Iteration: 100 | Classification loss: 0.49953 | Regression loss: 0.63223 | Running loss: 0.72579\n",
      "Epoch: 4 | Iteration: 101 | Classification loss: 0.43560 | Regression loss: 0.64795 | Running loss: 0.72657\n",
      "Epoch: 4 | Iteration: 102 | Classification loss: 0.11996 | Regression loss: 0.31817 | Running loss: 0.72517\n",
      "Epoch: 4 | Iteration: 103 | Classification loss: 0.32859 | Regression loss: 0.29449 | Running loss: 0.72514\n",
      "Epoch: 4 | Iteration: 104 | Classification loss: 0.36577 | Regression loss: 0.39090 | Running loss: 0.72572\n",
      "Epoch: 4 | Iteration: 105 | Classification loss: 0.25891 | Regression loss: 0.31239 | Running loss: 0.72576\n",
      "Epoch: 4 | Iteration: 106 | Classification loss: 0.26749 | Regression loss: 0.33457 | Running loss: 0.72557\n",
      "Epoch: 4 | Iteration: 107 | Classification loss: 0.15658 | Regression loss: 0.26681 | Running loss: 0.72427\n",
      "Epoch: 4 | Iteration: 108 | Classification loss: 0.15612 | Regression loss: 0.30089 | Running loss: 0.72395\n",
      "Epoch: 4 | Iteration: 109 | Classification loss: 0.43481 | Regression loss: 0.18716 | Running loss: 0.72367\n",
      "Epoch: 4 | Iteration: 110 | Classification loss: 0.23023 | Regression loss: 0.31428 | Running loss: 0.72383\n",
      "Epoch: 4 | Iteration: 111 | Classification loss: 0.24825 | Regression loss: 0.55117 | Running loss: 0.72340\n",
      "Epoch: 4 | Iteration: 112 | Classification loss: 0.26399 | Regression loss: 0.71193 | Running loss: 0.72466\n",
      "Epoch: 4 | Iteration: 113 | Classification loss: 0.23222 | Regression loss: 0.30142 | Running loss: 0.72452\n",
      "Epoch: 4 | Iteration: 114 | Classification loss: 0.10731 | Regression loss: 0.24930 | Running loss: 0.72384\n",
      "Epoch: 4 | Iteration: 115 | Classification loss: 0.27084 | Regression loss: 0.29566 | Running loss: 0.72327\n",
      "Epoch: 4 | Iteration: 116 | Classification loss: 0.19432 | Regression loss: 0.28519 | Running loss: 0.72264\n",
      "Epoch: 4 | Iteration: 117 | Classification loss: 0.51039 | Regression loss: 0.56562 | Running loss: 0.72307\n",
      "Epoch: 4 | Iteration: 118 | Classification loss: 0.43551 | Regression loss: 0.42259 | Running loss: 0.72258\n",
      "Epoch: 4 | Iteration: 119 | Classification loss: 0.25284 | Regression loss: 0.21921 | Running loss: 0.72244\n",
      "Epoch: 4 | Iteration: 120 | Classification loss: 0.26440 | Regression loss: 0.47493 | Running loss: 0.72177\n",
      "Epoch: 4 | Iteration: 121 | Classification loss: 0.52778 | Regression loss: 0.59327 | Running loss: 0.72271\n",
      "Epoch: 4 | Iteration: 122 | Classification loss: 0.33247 | Regression loss: 0.30218 | Running loss: 0.72126\n",
      "Epoch: 4 | Iteration: 123 | Classification loss: 0.18143 | Regression loss: 0.22674 | Running loss: 0.72068\n",
      "Epoch: 4 | Iteration: 124 | Classification loss: 0.32383 | Regression loss: 0.23800 | Running loss: 0.71982\n",
      "Epoch: 4 | Iteration: 125 | Classification loss: 0.13410 | Regression loss: 0.32854 | Running loss: 0.71884\n",
      "Epoch: 4 | Iteration: 126 | Classification loss: 0.18539 | Regression loss: 0.31439 | Running loss: 0.71775\n",
      "Epoch: 4 | Iteration: 127 | Classification loss: 0.22543 | Regression loss: 0.44048 | Running loss: 0.71760\n",
      "Epoch: 4 | Iteration: 128 | Classification loss: 0.21048 | Regression loss: 0.20661 | Running loss: 0.71606\n",
      "Epoch: 4 | Iteration: 129 | Classification loss: 0.43919 | Regression loss: 0.33185 | Running loss: 0.71622\n",
      "Epoch: 4 | Iteration: 130 | Classification loss: 0.29859 | Regression loss: 0.60642 | Running loss: 0.71643\n",
      "Epoch: 4 | Iteration: 131 | Classification loss: 0.69320 | Regression loss: 0.42516 | Running loss: 0.71720\n",
      "Epoch: 4 | Iteration: 132 | Classification loss: 0.12728 | Regression loss: 0.28484 | Running loss: 0.71698\n",
      "Epoch: 4 | Iteration: 133 | Classification loss: 0.28603 | Regression loss: 0.22730 | Running loss: 0.71612\n",
      "Epoch: 4 | Iteration: 134 | Classification loss: 0.23578 | Regression loss: 0.21723 | Running loss: 0.71562\n",
      "Epoch: 4 | Iteration: 135 | Classification loss: 0.28073 | Regression loss: 0.55069 | Running loss: 0.71616\n",
      "Epoch: 4 | Iteration: 136 | Classification loss: 0.31867 | Regression loss: 0.70425 | Running loss: 0.71608\n",
      "Epoch: 4 | Iteration: 137 | Classification loss: 0.20647 | Regression loss: 0.57090 | Running loss: 0.71612\n",
      "Epoch: 4 | Iteration: 138 | Classification loss: 0.33447 | Regression loss: 0.31953 | Running loss: 0.71607\n",
      "Epoch: 4 | Iteration: 139 | Classification loss: 0.24931 | Regression loss: 0.44376 | Running loss: 0.71613\n",
      "Epoch: 4 | Iteration: 140 | Classification loss: 0.22589 | Regression loss: 0.38863 | Running loss: 0.71479\n",
      "Epoch: 4 | Iteration: 141 | Classification loss: 0.45264 | Regression loss: 0.57806 | Running loss: 0.71558\n",
      "Epoch: 4 | Iteration: 142 | Classification loss: 0.18401 | Regression loss: 0.44203 | Running loss: 0.71577\n",
      "Epoch: 4 | Iteration: 143 | Classification loss: 0.25849 | Regression loss: 0.24923 | Running loss: 0.71557\n",
      "Epoch: 4 | Iteration: 144 | Classification loss: 0.60776 | Regression loss: 0.78887 | Running loss: 0.71713\n",
      "Epoch: 4 | Iteration: 145 | Classification loss: 0.31029 | Regression loss: 0.18353 | Running loss: 0.71740\n",
      "Epoch: 4 | Iteration: 146 | Classification loss: 0.24316 | Regression loss: 0.18271 | Running loss: 0.71725\n",
      "Epoch: 4 | Iteration: 147 | Classification loss: 0.49438 | Regression loss: 0.34200 | Running loss: 0.71738\n",
      "Epoch: 4 | Iteration: 148 | Classification loss: 0.15710 | Regression loss: 0.37356 | Running loss: 0.71710\n",
      "Epoch: 4 | Iteration: 149 | Classification loss: 0.42428 | Regression loss: 0.32187 | Running loss: 0.71601\n",
      "Epoch: 4 | Iteration: 150 | Classification loss: 0.45075 | Regression loss: 0.41405 | Running loss: 0.71652\n",
      "Epoch: 4 | Iteration: 151 | Classification loss: 0.26284 | Regression loss: 0.28672 | Running loss: 0.71628\n",
      "Epoch: 4 | Iteration: 152 | Classification loss: 0.30261 | Regression loss: 0.39913 | Running loss: 0.71674\n",
      "Epoch: 4 | Iteration: 153 | Classification loss: 0.25235 | Regression loss: 0.52338 | Running loss: 0.71763\n",
      "Epoch: 4 | Iteration: 154 | Classification loss: 0.42207 | Regression loss: 0.52885 | Running loss: 0.71784\n",
      "Epoch: 4 | Iteration: 155 | Classification loss: 0.12470 | Regression loss: 0.43486 | Running loss: 0.71753\n",
      "Epoch: 4 | Iteration: 156 | Classification loss: 0.39588 | Regression loss: 0.44018 | Running loss: 0.71850\n",
      "Epoch: 4 | Iteration: 157 | Classification loss: 0.21131 | Regression loss: 0.61543 | Running loss: 0.71920\n",
      "Epoch: 4 | Iteration: 158 | Classification loss: 0.26530 | Regression loss: 0.54711 | Running loss: 0.71877\n",
      "Epoch: 4 | Iteration: 159 | Classification loss: 0.39348 | Regression loss: 0.73479 | Running loss: 0.71991\n",
      "Epoch: 4 | Iteration: 160 | Classification loss: 0.33649 | Regression loss: 0.38417 | Running loss: 0.71964\n",
      "Epoch: 4 | Iteration: 161 | Classification loss: 0.16994 | Regression loss: 0.29383 | Running loss: 0.71924\n",
      "Epoch: 4 | Iteration: 162 | Classification loss: 0.29105 | Regression loss: 0.38459 | Running loss: 0.71937\n",
      "Epoch: 4 | Iteration: 163 | Classification loss: 0.25195 | Regression loss: 0.47390 | Running loss: 0.71882\n",
      "Epoch: 4 | Iteration: 164 | Classification loss: 0.37493 | Regression loss: 0.44232 | Running loss: 0.71806\n",
      "Epoch: 4 | Iteration: 165 | Classification loss: 0.25205 | Regression loss: 0.29843 | Running loss: 0.71781\n",
      "Epoch: 4 | Iteration: 166 | Classification loss: 0.39076 | Regression loss: 0.60517 | Running loss: 0.71824\n",
      "Epoch: 4 | Iteration: 167 | Classification loss: 0.41407 | Regression loss: 0.40883 | Running loss: 0.71795\n",
      "Epoch: 4 | Iteration: 168 | Classification loss: 0.17047 | Regression loss: 0.20723 | Running loss: 0.71658\n",
      "Epoch: 4 | Iteration: 169 | Classification loss: 0.17973 | Regression loss: 0.35488 | Running loss: 0.71684\n",
      "Epoch: 4 | Iteration: 170 | Classification loss: 0.10928 | Regression loss: 0.40452 | Running loss: 0.71385\n",
      "Epoch: 4 | Iteration: 171 | Classification loss: 0.25298 | Regression loss: 0.25223 | Running loss: 0.71310\n",
      "Epoch: 4 | Iteration: 172 | Classification loss: 0.28404 | Regression loss: 0.36202 | Running loss: 0.71323\n",
      "Epoch: 4 | Iteration: 173 | Classification loss: 0.35271 | Regression loss: 0.26769 | Running loss: 0.71310\n",
      "Epoch: 4 | Iteration: 174 | Classification loss: 0.32790 | Regression loss: 0.30588 | Running loss: 0.71378\n",
      "Epoch: 4 | Iteration: 175 | Classification loss: 0.18000 | Regression loss: 0.29678 | Running loss: 0.71406\n",
      "Epoch: 4 | Iteration: 176 | Classification loss: 0.13020 | Regression loss: 0.25991 | Running loss: 0.71295\n",
      "Epoch: 4 | Iteration: 177 | Classification loss: 0.14927 | Regression loss: 0.18484 | Running loss: 0.71133\n",
      "Epoch: 4 | Iteration: 178 | Classification loss: 0.20635 | Regression loss: 0.46763 | Running loss: 0.71146\n",
      "Epoch: 4 | Iteration: 179 | Classification loss: 0.22989 | Regression loss: 0.36138 | Running loss: 0.71120\n",
      "Epoch: 4 | Iteration: 180 | Classification loss: 0.34934 | Regression loss: 0.67485 | Running loss: 0.71179\n",
      "Epoch: 4 | Iteration: 181 | Classification loss: 0.49091 | Regression loss: 0.41477 | Running loss: 0.71279\n",
      "Epoch: 4 | Iteration: 182 | Classification loss: 0.57281 | Regression loss: 0.35028 | Running loss: 0.71313\n",
      "Epoch: 4 | Iteration: 183 | Classification loss: 0.24913 | Regression loss: 0.45808 | Running loss: 0.71356\n",
      "Epoch: 4 | Iteration: 184 | Classification loss: 0.26236 | Regression loss: 0.34690 | Running loss: 0.71401\n",
      "Epoch: 4 | Iteration: 185 | Classification loss: 0.20664 | Regression loss: 0.53230 | Running loss: 0.71375\n",
      "Epoch: 4 | Iteration: 186 | Classification loss: 0.28514 | Regression loss: 0.22442 | Running loss: 0.71250\n",
      "Epoch: 4 | Iteration: 187 | Classification loss: 0.39266 | Regression loss: 0.44802 | Running loss: 0.71173\n",
      "Epoch: 4 | Iteration: 188 | Classification loss: 0.41647 | Regression loss: 0.41931 | Running loss: 0.71210\n",
      "Epoch: 4 | Iteration: 189 | Classification loss: 0.35620 | Regression loss: 0.59556 | Running loss: 0.71264\n",
      "Epoch: 4 | Iteration: 190 | Classification loss: 0.37471 | Regression loss: 0.35941 | Running loss: 0.71220\n",
      "Epoch: 4 | Iteration: 191 | Classification loss: 0.19767 | Regression loss: 0.18041 | Running loss: 0.71166\n",
      "Epoch: 4 | Iteration: 192 | Classification loss: 0.22648 | Regression loss: 0.34399 | Running loss: 0.71156\n",
      "Epoch: 4 | Iteration: 193 | Classification loss: 0.31786 | Regression loss: 0.45721 | Running loss: 0.71142\n",
      "Epoch: 4 | Iteration: 194 | Classification loss: 0.21597 | Regression loss: 0.46090 | Running loss: 0.71179\n",
      "Epoch: 4 | Iteration: 195 | Classification loss: 0.20096 | Regression loss: 0.44348 | Running loss: 0.71163\n",
      "Epoch: 4 | Iteration: 196 | Classification loss: 0.20177 | Regression loss: 0.32720 | Running loss: 0.71164\n",
      "Epoch: 4 | Iteration: 197 | Classification loss: 0.32100 | Regression loss: 0.36286 | Running loss: 0.71212\n",
      "Epoch: 4 | Iteration: 198 | Classification loss: 0.21365 | Regression loss: 0.37044 | Running loss: 0.71135\n",
      "Epoch: 4 | Iteration: 199 | Classification loss: 0.17572 | Regression loss: 0.32213 | Running loss: 0.71105\n",
      "Epoch: 4 | Iteration: 200 | Classification loss: 0.30391 | Regression loss: 0.32920 | Running loss: 0.71139\n",
      "Epoch: 4 | Iteration: 201 | Classification loss: 0.25733 | Regression loss: 0.50277 | Running loss: 0.71170\n",
      "Epoch: 4 | Iteration: 202 | Classification loss: 0.19646 | Regression loss: 0.37314 | Running loss: 0.71200\n",
      "Epoch: 4 | Iteration: 203 | Classification loss: 0.38329 | Regression loss: 0.59493 | Running loss: 0.71171\n",
      "Epoch: 4 | Iteration: 204 | Classification loss: 0.15328 | Regression loss: 0.26450 | Running loss: 0.71094\n",
      "Epoch: 4 | Iteration: 205 | Classification loss: 0.11210 | Regression loss: 0.37833 | Running loss: 0.71078\n",
      "Epoch: 4 | Iteration: 206 | Classification loss: 0.23490 | Regression loss: 0.52196 | Running loss: 0.71127\n",
      "Epoch: 4 | Iteration: 207 | Classification loss: 0.22044 | Regression loss: 0.50695 | Running loss: 0.71168\n",
      "Epoch: 4 | Iteration: 208 | Classification loss: 0.16003 | Regression loss: 0.27666 | Running loss: 0.71118\n",
      "Epoch: 4 | Iteration: 209 | Classification loss: 0.26229 | Regression loss: 0.51219 | Running loss: 0.71136\n",
      "Epoch: 4 | Iteration: 210 | Classification loss: 0.34089 | Regression loss: 0.67539 | Running loss: 0.71247\n",
      "Epoch: 4 | Iteration: 211 | Classification loss: 0.22821 | Regression loss: 0.31523 | Running loss: 0.71213\n",
      "Epoch: 4 | Iteration: 212 | Classification loss: 0.11368 | Regression loss: 0.22260 | Running loss: 0.71119\n",
      "Epoch: 4 | Iteration: 213 | Classification loss: 0.23114 | Regression loss: 0.37790 | Running loss: 0.71148\n",
      "Epoch: 4 | Iteration: 214 | Classification loss: 0.59382 | Regression loss: 0.36472 | Running loss: 0.71163\n",
      "Epoch: 4 | Iteration: 215 | Classification loss: 0.17470 | Regression loss: 0.31094 | Running loss: 0.71072\n",
      "Epoch: 4 | Iteration: 216 | Classification loss: 0.33810 | Regression loss: 0.27674 | Running loss: 0.71038\n",
      "Epoch: 4 | Iteration: 217 | Classification loss: 0.16376 | Regression loss: 0.20009 | Running loss: 0.71002\n",
      "Epoch: 4 | Iteration: 218 | Classification loss: 0.11332 | Regression loss: 0.11919 | Running loss: 0.70872\n",
      "Epoch: 4 | Iteration: 219 | Classification loss: 0.42177 | Regression loss: 0.49805 | Running loss: 0.70916\n",
      "Epoch: 4 | Iteration: 220 | Classification loss: 0.37225 | Regression loss: 0.35185 | Running loss: 0.70895\n",
      "Epoch: 4 | Iteration: 221 | Classification loss: 0.43101 | Regression loss: 0.34075 | Running loss: 0.70990\n",
      "Epoch: 4 | Iteration: 222 | Classification loss: 0.41290 | Regression loss: 0.45744 | Running loss: 0.71087\n",
      "Epoch: 4 | Iteration: 223 | Classification loss: 0.20571 | Regression loss: 0.39981 | Running loss: 0.71048\n",
      "Epoch: 4 | Iteration: 224 | Classification loss: 0.12155 | Regression loss: 0.15721 | Running loss: 0.70955\n",
      "Epoch: 4 | Iteration: 225 | Classification loss: 0.31271 | Regression loss: 0.48210 | Running loss: 0.70950\n",
      "Epoch: 4 | Iteration: 226 | Classification loss: 0.17790 | Regression loss: 0.35789 | Running loss: 0.70939\n",
      "Epoch: 4 | Iteration: 227 | Classification loss: 0.30520 | Regression loss: 0.22360 | Running loss: 0.70899\n",
      "Epoch: 4 | Iteration: 228 | Classification loss: 0.36528 | Regression loss: 0.28359 | Running loss: 0.70946\n",
      "Epoch: 4 | Iteration: 229 | Classification loss: 0.36034 | Regression loss: 0.19630 | Running loss: 0.70915\n",
      "Epoch: 4 | Iteration: 230 | Classification loss: 0.14946 | Regression loss: 0.48176 | Running loss: 0.70932\n",
      "Epoch: 4 | Iteration: 231 | Classification loss: 0.21796 | Regression loss: 0.22224 | Running loss: 0.70906\n",
      "Epoch: 4 | Iteration: 232 | Classification loss: 0.09476 | Regression loss: 0.24663 | Running loss: 0.70805\n",
      "Epoch: 4 | Iteration: 233 | Classification loss: 0.07798 | Regression loss: 0.19803 | Running loss: 0.70713\n",
      "Epoch: 4 | Iteration: 234 | Classification loss: 0.28500 | Regression loss: 0.53296 | Running loss: 0.70760\n",
      "Epoch: 4 | Iteration: 235 | Classification loss: 0.08588 | Regression loss: 0.30176 | Running loss: 0.70583\n",
      "Epoch: 4 | Iteration: 236 | Classification loss: 0.16001 | Regression loss: 0.33445 | Running loss: 0.70530\n",
      "Epoch: 4 | Iteration: 237 | Classification loss: 0.20899 | Regression loss: 0.55523 | Running loss: 0.70549\n",
      "Epoch: 4 | Iteration: 238 | Classification loss: 0.36421 | Regression loss: 0.33627 | Running loss: 0.70574\n",
      "Epoch: 4 | Iteration: 239 | Classification loss: 0.27333 | Regression loss: 0.26514 | Running loss: 0.70442\n",
      "Epoch: 4 | Iteration: 240 | Classification loss: 0.17730 | Regression loss: 0.41335 | Running loss: 0.70453\n",
      "Epoch: 4 | Iteration: 241 | Classification loss: 0.26843 | Regression loss: 0.27029 | Running loss: 0.70392\n",
      "Epoch: 4 | Iteration: 242 | Classification loss: 0.52432 | Regression loss: 0.64812 | Running loss: 0.70526\n",
      "Epoch: 4 | Iteration: 243 | Classification loss: 0.45054 | Regression loss: 0.33493 | Running loss: 0.70595\n",
      "Epoch: 4 | Iteration: 244 | Classification loss: 0.27426 | Regression loss: 0.28660 | Running loss: 0.70610\n",
      "Epoch: 4 | Iteration: 245 | Classification loss: 0.26117 | Regression loss: 0.21446 | Running loss: 0.70610\n",
      "Epoch: 4 | Iteration: 246 | Classification loss: 0.15744 | Regression loss: 0.41802 | Running loss: 0.70621\n",
      "Epoch: 4 | Iteration: 247 | Classification loss: 0.18677 | Regression loss: 0.30893 | Running loss: 0.70612\n",
      "Epoch: 4 | Iteration: 248 | Classification loss: 0.24183 | Regression loss: 0.40106 | Running loss: 0.70569\n",
      "Epoch: 4 | Iteration: 249 | Classification loss: 0.21830 | Regression loss: 0.36587 | Running loss: 0.70568\n",
      "Epoch: 4 | Iteration: 250 | Classification loss: 0.27726 | Regression loss: 0.52963 | Running loss: 0.70576\n",
      "Epoch: 4 | Iteration: 251 | Classification loss: 0.24244 | Regression loss: 0.36640 | Running loss: 0.70548\n",
      "Epoch: 4 | Iteration: 252 | Classification loss: 0.55074 | Regression loss: 0.29414 | Running loss: 0.70560\n",
      "Epoch: 4 | Iteration: 253 | Classification loss: 0.38766 | Regression loss: 0.52378 | Running loss: 0.70546\n",
      "Epoch: 4 | Iteration: 254 | Classification loss: 0.39475 | Regression loss: 0.51894 | Running loss: 0.70622\n",
      "Epoch: 4 | Iteration: 255 | Classification loss: 0.18292 | Regression loss: 0.36494 | Running loss: 0.70495\n",
      "Epoch: 4 | Iteration: 256 | Classification loss: 0.33035 | Regression loss: 0.42957 | Running loss: 0.70561\n",
      "Epoch: 4 | Iteration: 257 | Classification loss: 0.34367 | Regression loss: 0.62047 | Running loss: 0.70602\n",
      "Epoch: 4 | Iteration: 258 | Classification loss: 0.29874 | Regression loss: 0.37497 | Running loss: 0.70633\n",
      "Epoch: 4 | Iteration: 259 | Classification loss: 0.31831 | Regression loss: 0.54233 | Running loss: 0.70605\n",
      "Epoch: 4 | Iteration: 260 | Classification loss: 0.34909 | Regression loss: 0.47765 | Running loss: 0.70642\n",
      "Epoch: 4 | Iteration: 261 | Classification loss: 0.32981 | Regression loss: 0.53101 | Running loss: 0.70622\n",
      "Epoch: 4 | Iteration: 262 | Classification loss: 0.36635 | Regression loss: 0.56900 | Running loss: 0.70717\n",
      "Epoch: 4 | Iteration: 263 | Classification loss: 0.40173 | Regression loss: 0.24972 | Running loss: 0.70770\n",
      "Epoch: 4 | Iteration: 264 | Classification loss: 0.10786 | Regression loss: 0.39341 | Running loss: 0.70721\n",
      "Epoch: 4 | Iteration: 265 | Classification loss: 0.21423 | Regression loss: 0.20794 | Running loss: 0.70670\n",
      "Epoch: 4 | Iteration: 266 | Classification loss: 0.19097 | Regression loss: 0.32211 | Running loss: 0.70604\n",
      "Epoch: 4 | Iteration: 267 | Classification loss: 0.32410 | Regression loss: 0.24676 | Running loss: 0.70500\n",
      "Epoch: 4 | Iteration: 268 | Classification loss: 0.22912 | Regression loss: 0.53733 | Running loss: 0.70517\n",
      "Epoch: 4 | Iteration: 269 | Classification loss: 0.40374 | Regression loss: 0.49315 | Running loss: 0.70577\n",
      "Epoch: 4 | Iteration: 270 | Classification loss: 0.25339 | Regression loss: 0.39758 | Running loss: 0.70619\n",
      "Epoch: 4 | Iteration: 271 | Classification loss: 0.49487 | Regression loss: 0.79157 | Running loss: 0.70742\n",
      "Epoch: 4 | Iteration: 272 | Classification loss: 0.19500 | Regression loss: 0.31141 | Running loss: 0.70621\n",
      "Epoch: 4 | Iteration: 273 | Classification loss: 0.32732 | Regression loss: 0.53494 | Running loss: 0.70607\n",
      "Epoch: 4 | Iteration: 274 | Classification loss: 0.31970 | Regression loss: 0.39791 | Running loss: 0.70578\n",
      "Epoch: 4 | Iteration: 275 | Classification loss: 0.12638 | Regression loss: 0.48324 | Running loss: 0.70552\n",
      "Epoch: 4 | Iteration: 276 | Classification loss: 0.48370 | Regression loss: 0.57113 | Running loss: 0.70593\n",
      "Epoch: 4 | Iteration: 277 | Classification loss: 0.26128 | Regression loss: 0.37553 | Running loss: 0.70592\n",
      "Epoch: 4 | Iteration: 278 | Classification loss: 0.16896 | Regression loss: 0.33346 | Running loss: 0.70568\n",
      "Epoch: 4 | Iteration: 279 | Classification loss: 0.34372 | Regression loss: 0.65949 | Running loss: 0.70635\n",
      "Epoch: 4 | Iteration: 280 | Classification loss: 0.24337 | Regression loss: 0.36485 | Running loss: 0.70495\n",
      "Epoch: 4 | Iteration: 281 | Classification loss: 0.20045 | Regression loss: 0.45774 | Running loss: 0.70474\n",
      "Epoch: 4 | Iteration: 282 | Classification loss: 0.08288 | Regression loss: 0.35018 | Running loss: 0.70388\n",
      "Epoch: 4 | Iteration: 283 | Classification loss: 0.24682 | Regression loss: 0.43360 | Running loss: 0.70390\n",
      "Epoch: 4 | Iteration: 284 | Classification loss: 0.43647 | Regression loss: 0.30545 | Running loss: 0.70416\n",
      "Epoch: 4 | Iteration: 285 | Classification loss: 0.18045 | Regression loss: 0.26628 | Running loss: 0.70309\n",
      "Epoch: 4 | Iteration: 286 | Classification loss: 0.09347 | Regression loss: 0.23605 | Running loss: 0.70151\n",
      "Epoch: 4 | Iteration: 287 | Classification loss: 0.16475 | Regression loss: 0.24287 | Running loss: 0.70037\n",
      "Epoch: 4 | Iteration: 288 | Classification loss: 0.08143 | Regression loss: 0.21185 | Running loss: 0.69875\n",
      "Epoch: 4 | Iteration: 289 | Classification loss: 0.19165 | Regression loss: 0.39519 | Running loss: 0.69828\n",
      "Epoch: 4 | Iteration: 290 | Classification loss: 0.36292 | Regression loss: 0.20692 | Running loss: 0.69813\n",
      "Epoch: 4 | Iteration: 291 | Classification loss: 0.42733 | Regression loss: 0.46754 | Running loss: 0.69787\n",
      "Epoch: 4 | Iteration: 292 | Classification loss: 0.31326 | Regression loss: 0.50437 | Running loss: 0.69716\n",
      "Epoch: 4 | Iteration: 293 | Classification loss: 0.37616 | Regression loss: 0.31119 | Running loss: 0.69715\n",
      "Epoch: 4 | Iteration: 294 | Classification loss: 0.39815 | Regression loss: 0.68807 | Running loss: 0.69799\n",
      "Epoch: 4 | Iteration: 295 | Classification loss: 0.28974 | Regression loss: 0.36866 | Running loss: 0.69830\n",
      "Epoch: 4 | Iteration: 296 | Classification loss: 0.21856 | Regression loss: 0.33136 | Running loss: 0.69823\n",
      "Epoch: 4 | Iteration: 297 | Classification loss: 0.16421 | Regression loss: 0.44190 | Running loss: 0.69742\n",
      "Epoch: 4 | Iteration: 298 | Classification loss: 0.24062 | Regression loss: 0.31403 | Running loss: 0.69706\n",
      "Epoch: 4 | Iteration: 299 | Classification loss: 0.36906 | Regression loss: 0.40312 | Running loss: 0.69706\n",
      "Epoch: 4 | Iteration: 300 | Classification loss: 0.15278 | Regression loss: 0.31194 | Running loss: 0.69611\n",
      "Epoch: 4 | Iteration: 301 | Classification loss: 0.34842 | Regression loss: 0.35688 | Running loss: 0.69594\n",
      "Epoch: 4 | Iteration: 302 | Classification loss: 0.49579 | Regression loss: 0.33528 | Running loss: 0.69688\n",
      "Epoch: 4 | Iteration: 303 | Classification loss: 0.52394 | Regression loss: 0.39976 | Running loss: 0.69772\n",
      "Epoch: 4 | Iteration: 304 | Classification loss: 0.34325 | Regression loss: 0.18565 | Running loss: 0.69736\n",
      "Epoch: 4 | Iteration: 305 | Classification loss: 0.33914 | Regression loss: 0.66611 | Running loss: 0.69731\n",
      "Epoch: 4 | Iteration: 306 | Classification loss: 0.14753 | Regression loss: 0.42373 | Running loss: 0.69708\n",
      "Epoch: 4 | Iteration: 307 | Classification loss: 0.29485 | Regression loss: 0.39714 | Running loss: 0.69686\n",
      "Epoch: 4 | Iteration: 308 | Classification loss: 0.19092 | Regression loss: 0.41984 | Running loss: 0.69687\n",
      "Epoch: 4 | Iteration: 309 | Classification loss: 0.25148 | Regression loss: 0.42694 | Running loss: 0.69610\n",
      "Epoch: 4 | Iteration: 310 | Classification loss: 0.32338 | Regression loss: 0.39763 | Running loss: 0.69602\n",
      "Epoch: 4 | Iteration: 311 | Classification loss: 0.38066 | Regression loss: 0.45795 | Running loss: 0.69643\n",
      "Epoch: 4 | Iteration: 312 | Classification loss: 0.38217 | Regression loss: 0.43566 | Running loss: 0.69662\n",
      "Epoch: 4 | Iteration: 313 | Classification loss: 0.27292 | Regression loss: 0.32807 | Running loss: 0.69558\n",
      "Epoch: 4 | Iteration: 314 | Classification loss: 0.52866 | Regression loss: 0.68168 | Running loss: 0.69613\n",
      "Epoch: 4 | Iteration: 315 | Classification loss: 0.08925 | Regression loss: 0.29665 | Running loss: 0.69575\n",
      "Epoch: 4 | Iteration: 316 | Classification loss: 0.31773 | Regression loss: 0.35997 | Running loss: 0.69657\n",
      "Epoch: 4 | Iteration: 317 | Classification loss: 0.08725 | Regression loss: 0.26236 | Running loss: 0.69533\n",
      "Epoch: 4 | Iteration: 318 | Classification loss: 0.17211 | Regression loss: 0.61619 | Running loss: 0.69536\n",
      "Epoch: 4 | Iteration: 319 | Classification loss: 0.30912 | Regression loss: 0.29813 | Running loss: 0.69514\n",
      "Epoch: 4 | Iteration: 320 | Classification loss: 0.38635 | Regression loss: 0.59980 | Running loss: 0.69600\n",
      "Epoch: 4 | Iteration: 321 | Classification loss: 0.30428 | Regression loss: 0.35933 | Running loss: 0.69620\n",
      "Epoch: 4 | Iteration: 322 | Classification loss: 0.37412 | Regression loss: 0.57677 | Running loss: 0.69566\n",
      "Epoch: 4 | Iteration: 323 | Classification loss: 0.15067 | Regression loss: 0.32581 | Running loss: 0.69551\n",
      "Epoch: 4 | Iteration: 324 | Classification loss: 0.14961 | Regression loss: 0.52213 | Running loss: 0.69442\n",
      "Epoch: 4 | Iteration: 325 | Classification loss: 0.41077 | Regression loss: 0.38046 | Running loss: 0.69425\n",
      "Epoch: 4 | Iteration: 326 | Classification loss: 0.51073 | Regression loss: 0.75624 | Running loss: 0.69592\n",
      "Epoch: 4 | Iteration: 327 | Classification loss: 0.15458 | Regression loss: 0.40133 | Running loss: 0.69549\n",
      "Epoch: 4 | Iteration: 328 | Classification loss: 0.45541 | Regression loss: 0.67803 | Running loss: 0.69699\n",
      "Epoch: 4 | Iteration: 329 | Classification loss: 0.17369 | Regression loss: 0.27272 | Running loss: 0.69630\n",
      "Epoch: 4 | Iteration: 330 | Classification loss: 0.27190 | Regression loss: 0.27536 | Running loss: 0.69628\n",
      "Epoch: 4 | Iteration: 331 | Classification loss: 0.31664 | Regression loss: 0.21473 | Running loss: 0.69607\n",
      "Epoch: 4 | Iteration: 332 | Classification loss: 0.36378 | Regression loss: 0.24694 | Running loss: 0.69423\n",
      "Epoch: 4 | Iteration: 333 | Classification loss: 0.53128 | Regression loss: 0.09675 | Running loss: 0.69272\n",
      "Epoch: 4 | Iteration: 334 | Classification loss: 0.34864 | Regression loss: 0.41832 | Running loss: 0.69333\n",
      "Epoch: 4 | Iteration: 335 | Classification loss: 0.26538 | Regression loss: 0.39570 | Running loss: 0.69387\n",
      "Epoch: 4 | Iteration: 336 | Classification loss: 0.24358 | Regression loss: 0.27930 | Running loss: 0.69431\n",
      "Epoch: 4 | Iteration: 337 | Classification loss: 0.10148 | Regression loss: 0.26040 | Running loss: 0.69367\n",
      "Epoch: 4 | Iteration: 338 | Classification loss: 0.33317 | Regression loss: 0.26539 | Running loss: 0.69349\n",
      "Epoch: 4 | Iteration: 339 | Classification loss: 0.24284 | Regression loss: 0.42274 | Running loss: 0.69383\n",
      "Epoch: 4 | Iteration: 340 | Classification loss: 0.24909 | Regression loss: 0.52521 | Running loss: 0.69437\n",
      "Epoch: 4 | Iteration: 341 | Classification loss: 0.31311 | Regression loss: 0.41531 | Running loss: 0.69385\n",
      "Epoch: 4 | Iteration: 342 | Classification loss: 0.29893 | Regression loss: 0.20914 | Running loss: 0.69336\n",
      "Epoch: 4 | Iteration: 343 | Classification loss: 0.42382 | Regression loss: 0.55682 | Running loss: 0.69344\n",
      "Epoch: 4 | Iteration: 344 | Classification loss: 0.36351 | Regression loss: 0.44786 | Running loss: 0.69347\n",
      "Epoch: 4 | Iteration: 345 | Classification loss: 0.18422 | Regression loss: 0.29982 | Running loss: 0.69332\n",
      "Epoch: 4 | Iteration: 346 | Classification loss: 0.19141 | Regression loss: 0.72617 | Running loss: 0.69462\n",
      "Epoch: 4 | Iteration: 347 | Classification loss: 0.19832 | Regression loss: 0.36265 | Running loss: 0.69407\n",
      "Epoch: 4 | Iteration: 348 | Classification loss: 0.33300 | Regression loss: 0.28176 | Running loss: 0.69361\n",
      "Epoch: 4 | Iteration: 349 | Classification loss: 0.18987 | Regression loss: 0.25104 | Running loss: 0.69340\n",
      "Epoch: 4 | Iteration: 350 | Classification loss: 0.34902 | Regression loss: 0.34665 | Running loss: 0.69372\n",
      "Epoch: 4 | Iteration: 351 | Classification loss: 0.35985 | Regression loss: 0.34271 | Running loss: 0.69227\n",
      "Epoch: 4 | Iteration: 352 | Classification loss: 0.17517 | Regression loss: 0.25644 | Running loss: 0.69095\n",
      "Epoch: 4 | Iteration: 353 | Classification loss: 0.38650 | Regression loss: 0.61034 | Running loss: 0.69157\n",
      "Epoch: 4 | Iteration: 354 | Classification loss: 0.47385 | Regression loss: 0.42309 | Running loss: 0.69194\n",
      "Epoch: 4 | Iteration: 355 | Classification loss: 0.37946 | Regression loss: 0.16117 | Running loss: 0.69123\n",
      "Epoch: 4 | Iteration: 356 | Classification loss: 0.19208 | Regression loss: 0.53315 | Running loss: 0.69140\n",
      "Epoch: 4 | Iteration: 357 | Classification loss: 0.19904 | Regression loss: 0.47178 | Running loss: 0.69140\n",
      "Epoch: 4 | Iteration: 358 | Classification loss: 0.29608 | Regression loss: 0.42951 | Running loss: 0.69183\n",
      "Epoch: 4 | Iteration: 359 | Classification loss: 0.30904 | Regression loss: 0.50186 | Running loss: 0.69194\n",
      "Epoch: 4 | Iteration: 360 | Classification loss: 0.41796 | Regression loss: 0.48118 | Running loss: 0.69217\n",
      "Epoch: 4 | Iteration: 361 | Classification loss: 0.39995 | Regression loss: 0.64216 | Running loss: 0.69366\n",
      "Epoch: 4 | Iteration: 362 | Classification loss: 0.18789 | Regression loss: 0.18853 | Running loss: 0.69269\n",
      "Epoch: 4 | Iteration: 363 | Classification loss: 0.28272 | Regression loss: 0.31799 | Running loss: 0.69270\n",
      "Epoch: 4 | Iteration: 364 | Classification loss: 0.22254 | Regression loss: 0.31670 | Running loss: 0.69251\n",
      "Epoch: 4 | Iteration: 365 | Classification loss: 0.47543 | Regression loss: 0.24854 | Running loss: 0.69288\n",
      "Epoch: 4 | Iteration: 366 | Classification loss: 0.19883 | Regression loss: 0.31957 | Running loss: 0.69247\n",
      "Epoch: 4 | Iteration: 367 | Classification loss: 0.21304 | Regression loss: 0.42710 | Running loss: 0.69278\n",
      "Epoch: 4 | Iteration: 368 | Classification loss: 0.20791 | Regression loss: 0.30716 | Running loss: 0.69197\n",
      "Epoch: 4 | Iteration: 369 | Classification loss: 0.26322 | Regression loss: 0.26589 | Running loss: 0.69098\n",
      "Epoch: 4 | Iteration: 370 | Classification loss: 0.38996 | Regression loss: 0.55343 | Running loss: 0.69138\n",
      "Epoch: 4 | Iteration: 371 | Classification loss: 0.26492 | Regression loss: 0.38212 | Running loss: 0.69087\n",
      "Epoch: 4 | Iteration: 372 | Classification loss: 0.15379 | Regression loss: 0.30058 | Running loss: 0.69104\n",
      "Epoch: 4 | Iteration: 373 | Classification loss: 0.24357 | Regression loss: 0.23569 | Running loss: 0.69120\n",
      "Epoch: 4 | Iteration: 374 | Classification loss: 0.76581 | Regression loss: 0.73976 | Running loss: 0.69259\n",
      "Epoch: 4 | Iteration: 375 | Classification loss: 0.34023 | Regression loss: 0.35395 | Running loss: 0.69261\n",
      "Epoch: 4 | Iteration: 376 | Classification loss: 0.54624 | Regression loss: 0.49693 | Running loss: 0.69333\n",
      "Epoch: 4 | Iteration: 377 | Classification loss: 0.23137 | Regression loss: 0.21127 | Running loss: 0.69352\n",
      "Epoch: 4 | Iteration: 378 | Classification loss: 0.22241 | Regression loss: 0.34418 | Running loss: 0.69328\n",
      "Epoch: 4 | Iteration: 379 | Classification loss: 0.40244 | Regression loss: 0.43911 | Running loss: 0.69402\n",
      "Epoch: 4 | Iteration: 380 | Classification loss: 0.33517 | Regression loss: 0.71448 | Running loss: 0.69491\n",
      "Epoch: 4 | Iteration: 381 | Classification loss: 0.10617 | Regression loss: 0.34645 | Running loss: 0.69536\n",
      "Epoch: 4 | Iteration: 382 | Classification loss: 0.50295 | Regression loss: 0.50825 | Running loss: 0.69433\n",
      "Epoch: 4 | Iteration: 383 | Classification loss: 0.21522 | Regression loss: 0.35119 | Running loss: 0.69481\n",
      "Epoch: 4 | Iteration: 384 | Classification loss: 0.24834 | Regression loss: 0.30448 | Running loss: 0.69347\n",
      "Epoch: 4 | Iteration: 385 | Classification loss: 0.37720 | Regression loss: 0.60672 | Running loss: 0.69385\n",
      "Epoch: 4 | Iteration: 386 | Classification loss: 0.43973 | Regression loss: 0.22577 | Running loss: 0.69407\n",
      "Epoch: 4 | Iteration: 387 | Classification loss: 0.13219 | Regression loss: 0.38879 | Running loss: 0.69428\n",
      "Epoch: 4 | Iteration: 388 | Classification loss: 0.28427 | Regression loss: 0.30761 | Running loss: 0.69424\n",
      "Epoch: 4 | Iteration: 389 | Classification loss: 0.21935 | Regression loss: 0.26642 | Running loss: 0.69436\n",
      "Epoch: 4 | Iteration: 390 | Classification loss: 0.47993 | Regression loss: 0.19355 | Running loss: 0.69295\n",
      "Epoch: 4 | Iteration: 391 | Classification loss: 0.16119 | Regression loss: 0.25243 | Running loss: 0.69164\n",
      "Epoch: 4 | Iteration: 392 | Classification loss: 0.38642 | Regression loss: 0.41815 | Running loss: 0.69136\n",
      "Epoch: 4 | Iteration: 393 | Classification loss: 0.42198 | Regression loss: 0.15819 | Running loss: 0.69128\n",
      "Epoch: 4 | Iteration: 394 | Classification loss: 0.35219 | Regression loss: 0.28315 | Running loss: 0.69154\n",
      "Epoch: 4 | Iteration: 395 | Classification loss: 0.34665 | Regression loss: 0.48690 | Running loss: 0.69121\n",
      "Epoch: 4 | Iteration: 396 | Classification loss: 0.24971 | Regression loss: 0.52362 | Running loss: 0.69078\n",
      "Epoch: 4 | Iteration: 397 | Classification loss: 0.11703 | Regression loss: 0.33566 | Running loss: 0.68989\n",
      "Epoch: 4 | Iteration: 398 | Classification loss: 0.17985 | Regression loss: 0.12227 | Running loss: 0.68928\n",
      "Epoch: 4 | Iteration: 399 | Classification loss: 0.40033 | Regression loss: 0.54816 | Running loss: 0.69045\n",
      "Epoch: 4 | Iteration: 400 | Classification loss: 0.21895 | Regression loss: 0.34633 | Running loss: 0.69039\n",
      "Epoch: 4 | Iteration: 401 | Classification loss: 0.28079 | Regression loss: 0.48687 | Running loss: 0.69049\n",
      "Epoch: 4 | Iteration: 402 | Classification loss: 0.34535 | Regression loss: 0.47619 | Running loss: 0.69135\n",
      "Epoch: 4 | Iteration: 403 | Classification loss: 0.17976 | Regression loss: 0.30875 | Running loss: 0.68969\n",
      "Epoch: 4 | Iteration: 404 | Classification loss: 0.13213 | Regression loss: 0.41901 | Running loss: 0.68894\n",
      "Epoch: 4 | Iteration: 405 | Classification loss: 0.25142 | Regression loss: 0.24395 | Running loss: 0.68860\n",
      "Epoch: 4 | Iteration: 406 | Classification loss: 0.32317 | Regression loss: 0.25632 | Running loss: 0.68895\n",
      "Epoch: 4 | Iteration: 407 | Classification loss: 0.23302 | Regression loss: 0.51297 | Running loss: 0.68859\n",
      "Epoch: 4 | Iteration: 408 | Classification loss: 0.18838 | Regression loss: 0.29374 | Running loss: 0.68766\n",
      "Epoch: 4 | Iteration: 409 | Classification loss: 0.29699 | Regression loss: 0.29105 | Running loss: 0.68787\n",
      "Epoch: 4 | Iteration: 410 | Classification loss: 0.28882 | Regression loss: 0.69849 | Running loss: 0.68924\n",
      "Epoch: 4 | Iteration: 411 | Classification loss: 0.38675 | Regression loss: 0.53787 | Running loss: 0.68971\n",
      "Epoch: 4 | Iteration: 412 | Classification loss: 0.20541 | Regression loss: 0.27224 | Running loss: 0.68854\n",
      "Epoch: 4 | Iteration: 413 | Classification loss: 0.12135 | Regression loss: 0.19634 | Running loss: 0.68819\n",
      "Epoch: 4 | Iteration: 414 | Classification loss: 0.25230 | Regression loss: 0.30795 | Running loss: 0.68792\n",
      "Epoch: 4 | Iteration: 415 | Classification loss: 0.27574 | Regression loss: 0.20319 | Running loss: 0.68778\n",
      "Epoch: 4 | Iteration: 416 | Classification loss: 0.26319 | Regression loss: 0.28318 | Running loss: 0.68782\n",
      "Epoch: 4 | Iteration: 417 | Classification loss: 0.25828 | Regression loss: 0.33126 | Running loss: 0.68781\n",
      "Epoch: 4 | Iteration: 418 | Classification loss: 0.31760 | Regression loss: 0.35980 | Running loss: 0.68842\n",
      "Epoch: 4 | Iteration: 419 | Classification loss: 0.32279 | Regression loss: 0.30228 | Running loss: 0.68788\n",
      "Epoch: 4 | Iteration: 420 | Classification loss: 0.28273 | Regression loss: 0.47962 | Running loss: 0.68626\n",
      "Epoch: 4 | Iteration: 421 | Classification loss: 0.44870 | Regression loss: 0.41016 | Running loss: 0.68643\n",
      "Epoch: 4 | Iteration: 422 | Classification loss: 0.18305 | Regression loss: 0.35315 | Running loss: 0.68634\n",
      "Epoch: 4 | Iteration: 423 | Classification loss: 0.37615 | Regression loss: 0.24294 | Running loss: 0.68555\n",
      "Epoch: 4 | Iteration: 424 | Classification loss: 0.30689 | Regression loss: 0.20853 | Running loss: 0.68494\n",
      "Epoch: 4 | Iteration: 425 | Classification loss: 0.21767 | Regression loss: 0.62037 | Running loss: 0.68464\n",
      "Epoch: 4 | Iteration: 426 | Classification loss: 0.14583 | Regression loss: 0.31994 | Running loss: 0.68273\n",
      "Epoch: 4 | Iteration: 427 | Classification loss: 0.14565 | Regression loss: 0.44998 | Running loss: 0.68221\n",
      "Epoch: 4 | Iteration: 428 | Classification loss: 0.44669 | Regression loss: 0.14679 | Running loss: 0.68155\n",
      "Epoch: 4 | Iteration: 429 | Classification loss: 0.23952 | Regression loss: 0.20440 | Running loss: 0.68101\n",
      "Epoch: 4 | Iteration: 430 | Classification loss: 0.26859 | Regression loss: 0.38907 | Running loss: 0.68038\n",
      "Epoch: 4 | Iteration: 431 | Classification loss: 0.39217 | Regression loss: 0.47949 | Running loss: 0.68066\n",
      "Epoch: 4 | Iteration: 432 | Classification loss: 0.17326 | Regression loss: 0.28119 | Running loss: 0.67880\n",
      "Epoch: 4 | Iteration: 433 | Classification loss: 0.13557 | Regression loss: 0.26203 | Running loss: 0.67747\n",
      "Epoch: 4 | Iteration: 434 | Classification loss: 0.10349 | Regression loss: 0.14157 | Running loss: 0.67617\n",
      "Epoch: 4 | Iteration: 435 | Classification loss: 0.23788 | Regression loss: 0.40777 | Running loss: 0.67600\n",
      "Epoch: 4 | Iteration: 436 | Classification loss: 0.33575 | Regression loss: 0.49291 | Running loss: 0.67586\n",
      "Epoch: 4 | Iteration: 437 | Classification loss: 0.11753 | Regression loss: 0.35957 | Running loss: 0.67586\n",
      "Epoch: 4 | Iteration: 438 | Classification loss: 0.10475 | Regression loss: 0.37763 | Running loss: 0.67420\n",
      "Epoch: 4 | Iteration: 439 | Classification loss: 0.20559 | Regression loss: 0.35583 | Running loss: 0.67353\n",
      "Epoch: 4 | Iteration: 440 | Classification loss: 0.10079 | Regression loss: 0.39274 | Running loss: 0.67305\n",
      "Epoch: 4 | Iteration: 441 | Classification loss: 0.42377 | Regression loss: 0.63891 | Running loss: 0.67371\n",
      "Epoch: 4 | Iteration: 442 | Classification loss: 0.17410 | Regression loss: 0.19623 | Running loss: 0.67355\n",
      "Epoch: 4 | Iteration: 443 | Classification loss: 0.51698 | Regression loss: 0.70446 | Running loss: 0.67485\n",
      "Epoch: 4 | Iteration: 444 | Classification loss: 0.46606 | Regression loss: 0.60317 | Running loss: 0.67588\n",
      "Epoch: 4 | Iteration: 445 | Classification loss: 0.27066 | Regression loss: 0.49220 | Running loss: 0.67596\n",
      "Epoch: 4 | Iteration: 446 | Classification loss: 0.31106 | Regression loss: 0.41598 | Running loss: 0.67580\n",
      "Epoch: 4 | Iteration: 447 | Classification loss: 0.16954 | Regression loss: 0.28029 | Running loss: 0.67586\n",
      "Epoch: 4 | Iteration: 448 | Classification loss: 0.20797 | Regression loss: 0.33703 | Running loss: 0.67572\n",
      "Epoch: 4 | Iteration: 449 | Classification loss: 0.24297 | Regression loss: 0.19361 | Running loss: 0.67575\n",
      "Epoch: 4 | Iteration: 450 | Classification loss: 0.22604 | Regression loss: 0.42483 | Running loss: 0.67535\n",
      "Epoch: 4 | Iteration: 451 | Classification loss: 0.31747 | Regression loss: 0.45877 | Running loss: 0.67559\n",
      "Epoch: 4 | Iteration: 452 | Classification loss: 0.24036 | Regression loss: 0.53655 | Running loss: 0.67595\n",
      "Epoch: 4 | Iteration: 453 | Classification loss: 0.11884 | Regression loss: 0.22325 | Running loss: 0.67519\n",
      "Epoch: 4 | Iteration: 454 | Classification loss: 0.23841 | Regression loss: 0.35856 | Running loss: 0.67528\n",
      "Epoch: 4 | Iteration: 455 | Classification loss: 0.60617 | Regression loss: 0.50494 | Running loss: 0.67577\n",
      "Epoch: 4 | Iteration: 456 | Classification loss: 0.36478 | Regression loss: 0.58904 | Running loss: 0.67495\n",
      "Epoch: 4 | Iteration: 457 | Classification loss: 0.20855 | Regression loss: 0.21060 | Running loss: 0.67399\n",
      "Epoch: 4 | Iteration: 458 | Classification loss: 0.22975 | Regression loss: 0.33506 | Running loss: 0.67369\n",
      "Epoch: 4 | Iteration: 459 | Classification loss: 0.21780 | Regression loss: 0.32581 | Running loss: 0.67338\n",
      "Epoch: 4 | Iteration: 460 | Classification loss: 0.31927 | Regression loss: 0.21932 | Running loss: 0.67253\n",
      "Epoch: 4 | Iteration: 461 | Classification loss: 0.17400 | Regression loss: 0.29725 | Running loss: 0.67231\n",
      "Epoch: 4 | Iteration: 462 | Classification loss: 0.40197 | Regression loss: 0.64834 | Running loss: 0.67285\n",
      "Epoch: 4 | Iteration: 463 | Classification loss: 0.09828 | Regression loss: 0.33686 | Running loss: 0.67238\n",
      "Epoch: 4 | Iteration: 464 | Classification loss: 0.22744 | Regression loss: 0.41538 | Running loss: 0.67283\n",
      "Epoch: 4 | Iteration: 465 | Classification loss: 0.30536 | Regression loss: 0.32194 | Running loss: 0.67283\n",
      "Epoch: 4 | Iteration: 466 | Classification loss: 0.11384 | Regression loss: 0.13694 | Running loss: 0.67194\n",
      "Epoch: 4 | Iteration: 467 | Classification loss: 0.13816 | Regression loss: 0.18614 | Running loss: 0.67093\n",
      "Epoch: 4 | Iteration: 468 | Classification loss: 0.23168 | Regression loss: 0.47053 | Running loss: 0.67001\n",
      "Epoch: 4 | Iteration: 469 | Classification loss: 0.58943 | Regression loss: 0.35580 | Running loss: 0.67098\n",
      "Epoch: 4 | Iteration: 470 | Classification loss: 0.63512 | Regression loss: 0.62536 | Running loss: 0.67213\n",
      "Epoch: 4 | Iteration: 471 | Classification loss: 0.23666 | Regression loss: 0.25666 | Running loss: 0.67236\n",
      "Epoch: 4 | Iteration: 472 | Classification loss: 0.26146 | Regression loss: 0.26087 | Running loss: 0.67184\n",
      "Epoch: 4 | Iteration: 473 | Classification loss: 0.28332 | Regression loss: 0.38717 | Running loss: 0.67071\n",
      "Epoch: 4 | Iteration: 474 | Classification loss: 0.23182 | Regression loss: 0.32496 | Running loss: 0.67070\n",
      "Epoch: 4 | Iteration: 475 | Classification loss: 0.22293 | Regression loss: 0.41682 | Running loss: 0.67097\n",
      "Epoch: 4 | Iteration: 476 | Classification loss: 0.46459 | Regression loss: 0.67238 | Running loss: 0.67204\n",
      "Epoch: 4 | Iteration: 477 | Classification loss: 0.35405 | Regression loss: 0.68988 | Running loss: 0.67239\n",
      "Epoch: 4 | Iteration: 478 | Classification loss: 0.33576 | Regression loss: 0.60584 | Running loss: 0.67353\n",
      "Epoch: 4 | Iteration: 479 | Classification loss: 0.29686 | Regression loss: 0.33563 | Running loss: 0.67331\n",
      "Epoch: 4 | Iteration: 480 | Classification loss: 0.31114 | Regression loss: 0.29103 | Running loss: 0.67336\n",
      "Epoch: 4 | Iteration: 481 | Classification loss: 0.25781 | Regression loss: 0.38449 | Running loss: 0.67375\n",
      "Epoch: 4 | Iteration: 482 | Classification loss: 0.44478 | Regression loss: 0.36235 | Running loss: 0.67479\n",
      "Epoch: 4 | Iteration: 483 | Classification loss: 0.46233 | Regression loss: 0.40520 | Running loss: 0.67473\n",
      "Epoch: 4 | Iteration: 484 | Classification loss: 0.35433 | Regression loss: 0.33552 | Running loss: 0.67478\n",
      "Epoch: 4 | Iteration: 485 | Classification loss: 0.39652 | Regression loss: 0.39350 | Running loss: 0.67521\n",
      "Epoch: 4 | Iteration: 486 | Classification loss: 0.11758 | Regression loss: 0.36413 | Running loss: 0.67462\n",
      "Epoch: 4 | Iteration: 487 | Classification loss: 0.19891 | Regression loss: 0.40660 | Running loss: 0.67478\n",
      "Epoch: 4 | Iteration: 488 | Classification loss: 0.22334 | Regression loss: 0.40402 | Running loss: 0.67460\n",
      "Epoch: 4 | Iteration: 489 | Classification loss: 0.29676 | Regression loss: 0.44693 | Running loss: 0.67517\n",
      "Epoch: 4 | Iteration: 490 | Classification loss: 0.45100 | Regression loss: 0.65410 | Running loss: 0.67620\n",
      "Epoch: 4 | Iteration: 491 | Classification loss: 0.29170 | Regression loss: 0.34954 | Running loss: 0.67610\n",
      "Epoch: 4 | Iteration: 492 | Classification loss: 0.39948 | Regression loss: 0.62749 | Running loss: 0.67683\n",
      "Epoch: 4 | Iteration: 493 | Classification loss: 0.47073 | Regression loss: 0.37762 | Running loss: 0.67655\n",
      "Epoch: 4 | Iteration: 494 | Classification loss: 0.11594 | Regression loss: 0.16832 | Running loss: 0.67601\n",
      "Epoch: 4 | Iteration: 495 | Classification loss: 0.27618 | Regression loss: 0.37866 | Running loss: 0.67514\n",
      "Epoch: 4 | Iteration: 496 | Classification loss: 0.22463 | Regression loss: 0.45101 | Running loss: 0.67547\n",
      "Epoch: 4 | Iteration: 497 | Classification loss: 0.33097 | Regression loss: 0.42784 | Running loss: 0.67561\n",
      "Epoch: 4 | Iteration: 498 | Classification loss: 0.20170 | Regression loss: 0.30649 | Running loss: 0.67514\n",
      "Epoch: 4 | Iteration: 499 | Classification loss: 0.59689 | Regression loss: 0.24237 | Running loss: 0.67538\n",
      "Epoch: 4 | Iteration: 500 | Classification loss: 0.61796 | Regression loss: 0.87395 | Running loss: 0.67659\n",
      "Epoch: 4 | Iteration: 501 | Classification loss: 0.02986 | Regression loss: 0.00000 | Running loss: 0.67558\n",
      "Epoch: 4 | Iteration: 502 | Classification loss: 0.30138 | Regression loss: 0.28704 | Running loss: 0.67624\n",
      "Epoch: 4 | Iteration: 503 | Classification loss: 0.10437 | Regression loss: 0.28392 | Running loss: 0.67523\n",
      "Epoch: 4 | Iteration: 504 | Classification loss: 0.07669 | Regression loss: 0.18439 | Running loss: 0.67457\n",
      "Epoch: 4 | Iteration: 505 | Classification loss: 0.30682 | Regression loss: 0.30493 | Running loss: 0.67422\n",
      "Epoch: 4 | Iteration: 506 | Classification loss: 0.11188 | Regression loss: 0.23319 | Running loss: 0.67396\n",
      "Epoch: 4 | Iteration: 507 | Classification loss: 0.09108 | Regression loss: 0.35147 | Running loss: 0.67339\n",
      "Epoch: 4 | Iteration: 508 | Classification loss: 0.49428 | Regression loss: 0.26489 | Running loss: 0.67405\n",
      "Epoch: 4 | Iteration: 509 | Classification loss: 0.47869 | Regression loss: 0.43002 | Running loss: 0.67459\n",
      "Epoch: 4 | Iteration: 510 | Classification loss: 1.93766 | Regression loss: 0.93750 | Running loss: 0.67855\n",
      "Epoch: 4 | Iteration: 511 | Classification loss: 0.10505 | Regression loss: 0.41519 | Running loss: 0.67861\n",
      "Epoch: 4 | Iteration: 512 | Classification loss: 0.30255 | Regression loss: 0.28994 | Running loss: 0.67788\n",
      "Epoch: 4 | Iteration: 513 | Classification loss: 0.50138 | Regression loss: 0.60745 | Running loss: 0.67896\n",
      "Epoch: 4 | Iteration: 514 | Classification loss: 0.36421 | Regression loss: 0.31663 | Running loss: 0.67836\n",
      "Epoch: 4 | Iteration: 515 | Classification loss: 0.20270 | Regression loss: 0.42641 | Running loss: 0.67807\n",
      "Epoch: 4 | Iteration: 516 | Classification loss: 0.32027 | Regression loss: 0.63062 | Running loss: 0.67886\n",
      "Epoch: 4 | Iteration: 517 | Classification loss: 0.26196 | Regression loss: 0.28311 | Running loss: 0.67880\n",
      "Epoch: 4 | Iteration: 518 | Classification loss: 0.29011 | Regression loss: 0.30923 | Running loss: 0.67901\n",
      "Epoch: 4 | Iteration: 519 | Classification loss: 0.33010 | Regression loss: 0.46135 | Running loss: 0.67896\n",
      "Epoch: 4 | Iteration: 520 | Classification loss: 0.39092 | Regression loss: 0.32186 | Running loss: 0.67891\n",
      "Epoch: 4 | Iteration: 521 | Classification loss: 0.35081 | Regression loss: 0.28343 | Running loss: 0.67822\n",
      "Epoch: 4 | Iteration: 522 | Classification loss: 0.16823 | Regression loss: 0.21426 | Running loss: 0.67737\n",
      "Epoch: 4 | Iteration: 523 | Classification loss: 0.20389 | Regression loss: 0.28532 | Running loss: 0.67708\n",
      "Epoch: 4 | Iteration: 524 | Classification loss: 0.24566 | Regression loss: 0.50295 | Running loss: 0.67709\n",
      "Epoch: 4 | Iteration: 525 | Classification loss: 0.17202 | Regression loss: 0.37815 | Running loss: 0.67675\n",
      "Epoch: 4 | Iteration: 526 | Classification loss: 0.46057 | Regression loss: 0.55496 | Running loss: 0.67792\n",
      "Epoch: 4 | Iteration: 527 | Classification loss: 0.31984 | Regression loss: 0.37102 | Running loss: 0.67738\n",
      "Epoch: 4 | Iteration: 528 | Classification loss: 0.30534 | Regression loss: 0.30618 | Running loss: 0.67700\n",
      "Epoch: 4 | Iteration: 529 | Classification loss: 0.29593 | Regression loss: 0.20776 | Running loss: 0.67734\n",
      "Epoch: 4 | Iteration: 530 | Classification loss: 0.26212 | Regression loss: 0.37273 | Running loss: 0.67723\n",
      "Epoch: 4 | Iteration: 531 | Classification loss: 0.25208 | Regression loss: 0.38692 | Running loss: 0.67719\n",
      "Epoch: 4 | Iteration: 532 | Classification loss: 0.18592 | Regression loss: 0.34767 | Running loss: 0.67688\n",
      "Epoch: 4 | Iteration: 533 | Classification loss: 0.24138 | Regression loss: 0.40672 | Running loss: 0.67612\n",
      "Epoch: 4 | Iteration: 534 | Classification loss: 0.47481 | Regression loss: 0.66908 | Running loss: 0.67705\n",
      "Epoch: 4 | Iteration: 535 | Classification loss: 0.34860 | Regression loss: 0.38091 | Running loss: 0.67741\n",
      "Epoch: 4 | Iteration: 536 | Classification loss: 0.24879 | Regression loss: 0.37856 | Running loss: 0.67766\n",
      "Epoch: 4 | Iteration: 537 | Classification loss: 0.21744 | Regression loss: 0.37817 | Running loss: 0.67777\n",
      "Epoch: 4 | Iteration: 538 | Classification loss: 0.41700 | Regression loss: 0.57897 | Running loss: 0.67815\n",
      "Epoch: 4 | Iteration: 539 | Classification loss: 0.32316 | Regression loss: 0.30805 | Running loss: 0.67816\n",
      "Epoch: 4 | Iteration: 540 | Classification loss: 0.27307 | Regression loss: 0.28344 | Running loss: 0.67776\n",
      "Epoch: 4 | Iteration: 541 | Classification loss: 0.14595 | Regression loss: 0.23666 | Running loss: 0.67743\n",
      "Epoch: 4 | Iteration: 542 | Classification loss: 0.24602 | Regression loss: 0.33324 | Running loss: 0.67689\n",
      "Epoch: 4 | Iteration: 543 | Classification loss: 0.11293 | Regression loss: 0.20805 | Running loss: 0.67659\n",
      "Epoch: 4 | Iteration: 544 | Classification loss: 0.41786 | Regression loss: 0.49859 | Running loss: 0.67744\n",
      "Epoch: 4 | Iteration: 545 | Classification loss: 0.38622 | Regression loss: 0.28694 | Running loss: 0.67715\n",
      "Epoch: 4 | Iteration: 546 | Classification loss: 0.26495 | Regression loss: 0.27753 | Running loss: 0.67739\n",
      "Epoch: 4 | Iteration: 547 | Classification loss: 0.34950 | Regression loss: 0.62089 | Running loss: 0.67857\n",
      "Epoch: 4 | Iteration: 548 | Classification loss: 0.19846 | Regression loss: 0.37776 | Running loss: 0.67863\n",
      "Epoch: 4 | Iteration: 549 | Classification loss: 0.40717 | Regression loss: 0.36330 | Running loss: 0.67898\n",
      "Epoch: 4 | Iteration: 550 | Classification loss: 0.23250 | Regression loss: 0.28654 | Running loss: 0.67859\n",
      "Epoch: 4 | Iteration: 551 | Classification loss: 0.27450 | Regression loss: 0.28081 | Running loss: 0.67861\n",
      "Epoch: 4 | Iteration: 552 | Classification loss: 0.12584 | Regression loss: 0.26526 | Running loss: 0.67775\n",
      "Epoch: 4 | Iteration: 553 | Classification loss: 0.34232 | Regression loss: 0.36022 | Running loss: 0.67747\n",
      "Epoch: 4 | Iteration: 554 | Classification loss: 0.10373 | Regression loss: 0.19316 | Running loss: 0.67751\n",
      "Epoch: 4 | Iteration: 555 | Classification loss: 0.16304 | Regression loss: 0.28905 | Running loss: 0.67765\n",
      "Epoch: 4 | Iteration: 556 | Classification loss: 0.24316 | Regression loss: 0.36293 | Running loss: 0.67816\n",
      "Epoch: 4 | Iteration: 557 | Classification loss: 0.25442 | Regression loss: 0.37135 | Running loss: 0.67851\n",
      "Epoch: 4 | Iteration: 558 | Classification loss: 0.31358 | Regression loss: 0.26046 | Running loss: 0.67919\n",
      "Epoch: 4 | Iteration: 559 | Classification loss: 0.23791 | Regression loss: 0.26602 | Running loss: 0.67919\n",
      "Epoch: 4 | Iteration: 560 | Classification loss: 0.09921 | Regression loss: 0.39817 | Running loss: 0.67878\n",
      "Epoch: 4 | Iteration: 561 | Classification loss: 0.35923 | Regression loss: 0.35668 | Running loss: 0.67825\n",
      "Epoch: 4 | Iteration: 562 | Classification loss: 0.24206 | Regression loss: 0.39894 | Running loss: 0.67723\n",
      "Epoch: 4 | Iteration: 563 | Classification loss: 0.24302 | Regression loss: 0.32904 | Running loss: 0.67690\n",
      "Epoch: 4 | Iteration: 564 | Classification loss: 0.22942 | Regression loss: 0.36466 | Running loss: 0.67599\n",
      "Epoch: 4 | Iteration: 565 | Classification loss: 0.34296 | Regression loss: 0.92403 | Running loss: 0.67730\n",
      "Epoch: 4 | Iteration: 566 | Classification loss: 0.27731 | Regression loss: 0.31512 | Running loss: 0.67669\n",
      "Epoch: 4 | Iteration: 567 | Classification loss: 0.27442 | Regression loss: 0.46617 | Running loss: 0.67697\n",
      "Epoch: 4 | Iteration: 568 | Classification loss: 0.08640 | Regression loss: 0.25990 | Running loss: 0.67663\n",
      "Epoch: 4 | Iteration: 569 | Classification loss: 0.11027 | Regression loss: 0.21464 | Running loss: 0.67641\n",
      "Epoch: 4 | Iteration: 570 | Classification loss: 0.42881 | Regression loss: 0.43925 | Running loss: 0.67736\n",
      "Epoch: 4 | Iteration: 571 | Classification loss: 0.40616 | Regression loss: 0.18866 | Running loss: 0.67764\n",
      "Epoch: 4 | Iteration: 572 | Classification loss: 0.61969 | Regression loss: 0.50865 | Running loss: 0.67838\n",
      "Epoch: 4 | Iteration: 573 | Classification loss: 0.49529 | Regression loss: 0.63468 | Running loss: 0.67937\n",
      "Epoch: 4 | Iteration: 574 | Classification loss: 0.14363 | Regression loss: 0.36914 | Running loss: 0.67909\n",
      "Epoch: 4 | Iteration: 575 | Classification loss: 0.22066 | Regression loss: 0.37473 | Running loss: 0.67929\n",
      "Epoch: 4 | Iteration: 576 | Classification loss: 0.36048 | Regression loss: 0.27951 | Running loss: 0.67895\n",
      "Epoch: 4 | Iteration: 577 | Classification loss: 0.21053 | Regression loss: 0.33067 | Running loss: 0.67869\n",
      "Epoch: 4 | Iteration: 578 | Classification loss: 0.17370 | Regression loss: 0.45737 | Running loss: 0.67929\n",
      "Epoch: 4 | Iteration: 579 | Classification loss: 0.11908 | Regression loss: 0.27794 | Running loss: 0.67901\n",
      "Epoch: 4 | Iteration: 580 | Classification loss: 0.40030 | Regression loss: 0.36851 | Running loss: 0.67953\n",
      "Epoch: 4 | Iteration: 581 | Classification loss: 0.43177 | Regression loss: 0.51875 | Running loss: 0.67937\n",
      "Epoch: 4 | Iteration: 582 | Classification loss: 0.22607 | Regression loss: 0.46042 | Running loss: 0.67840\n",
      "Epoch: 4 | Iteration: 583 | Classification loss: 0.44617 | Regression loss: 0.42452 | Running loss: 0.67889\n",
      "Epoch: 4 | Iteration: 584 | Classification loss: 0.29248 | Regression loss: 0.20505 | Running loss: 0.67743\n",
      "Epoch: 4 | Iteration: 585 | Classification loss: 0.38264 | Regression loss: 0.97111 | Running loss: 0.67852\n",
      "Epoch: 4 | Iteration: 586 | Classification loss: 0.28504 | Regression loss: 0.24495 | Running loss: 0.67721\n",
      "Epoch: 4 | Iteration: 587 | Classification loss: 0.27739 | Regression loss: 0.34091 | Running loss: 0.67676\n",
      "Epoch: 4 | Iteration: 588 | Classification loss: 0.22696 | Regression loss: 0.22029 | Running loss: 0.67632\n",
      "Epoch: 4 | Iteration: 589 | Classification loss: 0.12667 | Regression loss: 0.37256 | Running loss: 0.67600\n",
      "Epoch: 4 | Iteration: 590 | Classification loss: 0.33848 | Regression loss: 0.38294 | Running loss: 0.67575\n",
      "Epoch: 4 | Iteration: 591 | Classification loss: 0.26718 | Regression loss: 0.39880 | Running loss: 0.67633\n",
      "Epoch: 4 | Iteration: 592 | Classification loss: 0.42040 | Regression loss: 0.71399 | Running loss: 0.67736\n",
      "Epoch: 4 | Iteration: 593 | Classification loss: 0.22162 | Regression loss: 0.43186 | Running loss: 0.67406\n",
      "Epoch: 4 | Iteration: 594 | Classification loss: 0.30678 | Regression loss: 0.58905 | Running loss: 0.67378\n",
      "Epoch: 4 | Iteration: 595 | Classification loss: 0.25084 | Regression loss: 0.20656 | Running loss: 0.67336\n",
      "Epoch: 4 | Iteration: 596 | Classification loss: 0.17028 | Regression loss: 0.15287 | Running loss: 0.67340\n",
      "Epoch: 4 | Iteration: 597 | Classification loss: 0.36466 | Regression loss: 0.40567 | Running loss: 0.67384\n",
      "Epoch: 4 | Iteration: 598 | Classification loss: 0.19122 | Regression loss: 0.23480 | Running loss: 0.67322\n",
      "Epoch: 4 | Iteration: 599 | Classification loss: 0.30099 | Regression loss: 0.28615 | Running loss: 0.67366\n",
      "Epoch: 4 | Iteration: 600 | Classification loss: 0.13432 | Regression loss: 0.23156 | Running loss: 0.67213\n",
      "Epoch: 4 | Iteration: 601 | Classification loss: 0.14221 | Regression loss: 0.30794 | Running loss: 0.67086\n",
      "Epoch: 4 | Iteration: 602 | Classification loss: 0.40027 | Regression loss: 0.36859 | Running loss: 0.67152\n",
      "Epoch: 4 | Iteration: 603 | Classification loss: 0.24757 | Regression loss: 0.28166 | Running loss: 0.67133\n",
      "Epoch: 4 | Iteration: 604 | Classification loss: 0.29604 | Regression loss: 0.25968 | Running loss: 0.67093\n",
      "Epoch: 4 | Iteration: 605 | Classification loss: 0.25343 | Regression loss: 0.43218 | Running loss: 0.67116\n",
      "Epoch: 4 | Iteration: 606 | Classification loss: 0.23779 | Regression loss: 0.54526 | Running loss: 0.67152\n",
      "Epoch: 4 | Iteration: 607 | Classification loss: 0.39528 | Regression loss: 0.39702 | Running loss: 0.67226\n",
      "Epoch: 4 | Iteration: 608 | Classification loss: 0.41563 | Regression loss: 0.59950 | Running loss: 0.67338\n",
      "Epoch: 4 | Iteration: 609 | Classification loss: 0.26392 | Regression loss: 0.30297 | Running loss: 0.67327\n",
      "Epoch: 4 | Iteration: 610 | Classification loss: 0.30999 | Regression loss: 0.62303 | Running loss: 0.67404\n",
      "Epoch: 4 | Iteration: 611 | Classification loss: 0.45312 | Regression loss: 0.33193 | Running loss: 0.67401\n",
      "Epoch: 4 | Iteration: 612 | Classification loss: 0.23444 | Regression loss: 0.32692 | Running loss: 0.67318\n",
      "Epoch: 4 | Iteration: 613 | Classification loss: 0.28716 | Regression loss: 0.15989 | Running loss: 0.67301\n",
      "Epoch: 4 | Iteration: 614 | Classification loss: 0.20948 | Regression loss: 0.34957 | Running loss: 0.67342\n",
      "Epoch: 4 | Iteration: 615 | Classification loss: 0.07604 | Regression loss: 0.16170 | Running loss: 0.67276\n",
      "Epoch: 4 | Iteration: 616 | Classification loss: 0.22352 | Regression loss: 0.30302 | Running loss: 0.67285\n",
      "Epoch: 4 | Iteration: 617 | Classification loss: 0.38734 | Regression loss: 0.49491 | Running loss: 0.67247\n",
      "Epoch: 4 | Iteration: 618 | Classification loss: 0.19586 | Regression loss: 0.43224 | Running loss: 0.67201\n",
      "Epoch: 4 | Iteration: 619 | Classification loss: 0.22516 | Regression loss: 0.32325 | Running loss: 0.67216\n",
      "Epoch: 4 | Iteration: 620 | Classification loss: 0.16363 | Regression loss: 0.28280 | Running loss: 0.67157\n",
      "Epoch: 4 | Iteration: 621 | Classification loss: 0.51366 | Regression loss: 0.18360 | Running loss: 0.67072\n",
      "Epoch: 4 | Iteration: 622 | Classification loss: 0.36534 | Regression loss: 0.28755 | Running loss: 0.67076\n",
      "Epoch: 4 | Iteration: 623 | Classification loss: 0.40733 | Regression loss: 0.29698 | Running loss: 0.67135\n",
      "Epoch: 4 | Iteration: 624 | Classification loss: 0.27214 | Regression loss: 0.44836 | Running loss: 0.67167\n",
      "Epoch: 4 | Iteration: 625 | Classification loss: 0.26193 | Regression loss: 0.14777 | Running loss: 0.67157\n",
      "Epoch: 4 | Iteration: 626 | Classification loss: 0.37180 | Regression loss: 0.50814 | Running loss: 0.67233\n",
      "Epoch: 4 | Iteration: 627 | Classification loss: 0.47449 | Regression loss: 0.58225 | Running loss: 0.67311\n",
      "Epoch: 4 | Iteration: 628 | Classification loss: 0.15790 | Regression loss: 0.42723 | Running loss: 0.67344\n",
      "Epoch: 4 | Iteration: 629 | Classification loss: 0.38204 | Regression loss: 0.44398 | Running loss: 0.67355\n",
      "Epoch: 4 | Iteration: 630 | Classification loss: 0.41660 | Regression loss: 0.37726 | Running loss: 0.67333\n",
      "Epoch: 4 | Iteration: 631 | Classification loss: 0.16302 | Regression loss: 0.35260 | Running loss: 0.67213\n",
      "Epoch: 4 | Iteration: 632 | Classification loss: 0.40210 | Regression loss: 0.41733 | Running loss: 0.67294\n",
      "Epoch: 4 | Iteration: 633 | Classification loss: 0.33620 | Regression loss: 0.44973 | Running loss: 0.67349\n",
      "Epoch: 4 | Iteration: 634 | Classification loss: 0.24663 | Regression loss: 0.37022 | Running loss: 0.67381\n",
      "Epoch: 4 | Iteration: 635 | Classification loss: 0.40470 | Regression loss: 0.18883 | Running loss: 0.67334\n",
      "Epoch: 4 | Iteration: 636 | Classification loss: 0.32142 | Regression loss: 0.42265 | Running loss: 0.67278\n",
      "Epoch: 4 | Iteration: 637 | Classification loss: 0.24381 | Regression loss: 0.16111 | Running loss: 0.67203\n",
      "Epoch: 4 | Iteration: 638 | Classification loss: 0.35130 | Regression loss: 0.47587 | Running loss: 0.67238\n",
      "Epoch: 4 | Iteration: 639 | Classification loss: 0.17981 | Regression loss: 0.29535 | Running loss: 0.67195\n",
      "Epoch: 4 | Iteration: 640 | Classification loss: 0.09351 | Regression loss: 0.34466 | Running loss: 0.67159\n",
      "Epoch: 4 | Iteration: 641 | Classification loss: 0.26015 | Regression loss: 0.31474 | Running loss: 0.67068\n",
      "Epoch: 4 | Iteration: 642 | Classification loss: 0.37002 | Regression loss: 0.68980 | Running loss: 0.67155\n",
      "Epoch: 4 | Iteration: 643 | Classification loss: 0.22914 | Regression loss: 0.21870 | Running loss: 0.67143\n",
      "Epoch: 4 | Iteration: 644 | Classification loss: 0.28758 | Regression loss: 0.54390 | Running loss: 0.67030\n",
      "Epoch: 4 | Iteration: 645 | Classification loss: 0.36022 | Regression loss: 0.59756 | Running loss: 0.67123\n",
      "Epoch: 4 | Iteration: 646 | Classification loss: 0.21394 | Regression loss: 0.31919 | Running loss: 0.67144\n",
      "Epoch: 4 | Iteration: 647 | Classification loss: 0.31975 | Regression loss: 0.15903 | Running loss: 0.67073\n",
      "Epoch: 4 | Iteration: 648 | Classification loss: 0.11208 | Regression loss: 0.42447 | Running loss: 0.67074\n",
      "Epoch: 4 | Iteration: 649 | Classification loss: 0.14072 | Regression loss: 0.26429 | Running loss: 0.67006\n",
      "Epoch: 4 | Iteration: 650 | Classification loss: 0.44867 | Regression loss: 0.71942 | Running loss: 0.67066\n",
      "Epoch: 4 | Iteration: 651 | Classification loss: 0.23547 | Regression loss: 0.38549 | Running loss: 0.67080\n",
      "Epoch: 4 | Iteration: 652 | Classification loss: 0.17423 | Regression loss: 0.39965 | Running loss: 0.67055\n",
      "Epoch: 4 | Iteration: 653 | Classification loss: 0.44943 | Regression loss: 0.68668 | Running loss: 0.67127\n",
      "Epoch: 4 | Iteration: 654 | Classification loss: 0.23553 | Regression loss: 0.46409 | Running loss: 0.67077\n",
      "Epoch: 4 | Iteration: 655 | Classification loss: 0.26712 | Regression loss: 0.56002 | Running loss: 0.67130\n",
      "Epoch: 4 | Iteration: 656 | Classification loss: 0.19049 | Regression loss: 0.46344 | Running loss: 0.67094\n",
      "Epoch: 4 | Iteration: 657 | Classification loss: 0.25545 | Regression loss: 0.55949 | Running loss: 0.67091\n",
      "Epoch: 4 | Iteration: 658 | Classification loss: 0.26003 | Regression loss: 0.40469 | Running loss: 0.67062\n",
      "Epoch: 4 | Iteration: 659 | Classification loss: 0.33681 | Regression loss: 0.22176 | Running loss: 0.66948\n",
      "Epoch: 4 | Iteration: 660 | Classification loss: 0.31660 | Regression loss: 0.42479 | Running loss: 0.66952\n",
      "Epoch: 4 | Iteration: 661 | Classification loss: 0.29180 | Regression loss: 0.22590 | Running loss: 0.66963\n",
      "Epoch: 4 | Iteration: 662 | Classification loss: 0.24777 | Regression loss: 0.22213 | Running loss: 0.66922\n",
      "Epoch: 4 | Iteration: 663 | Classification loss: 0.34893 | Regression loss: 0.47865 | Running loss: 0.66942\n",
      "Epoch: 4 | Iteration: 664 | Classification loss: 0.36468 | Regression loss: 0.63003 | Running loss: 0.66978\n",
      "Epoch: 4 | Iteration: 665 | Classification loss: 0.10597 | Regression loss: 0.26437 | Running loss: 0.66942\n",
      "Epoch: 4 | Iteration: 666 | Classification loss: 0.44211 | Regression loss: 0.27012 | Running loss: 0.66885\n",
      "Epoch: 4 | Iteration: 667 | Classification loss: 0.23713 | Regression loss: 0.56932 | Running loss: 0.66882\n",
      "Epoch: 4 | Iteration: 668 | Classification loss: 0.39972 | Regression loss: 0.59899 | Running loss: 0.67006\n",
      "Epoch: 4 | Iteration: 669 | Classification loss: 0.29848 | Regression loss: 0.30265 | Running loss: 0.67019\n",
      "Epoch: 4 | Iteration: 670 | Classification loss: 0.16889 | Regression loss: 0.43794 | Running loss: 0.67038\n",
      "Epoch: 4 | Iteration: 671 | Classification loss: 0.28085 | Regression loss: 0.44944 | Running loss: 0.67083\n",
      "Epoch: 4 | Iteration: 672 | Classification loss: 0.21759 | Regression loss: 0.40278 | Running loss: 0.67077\n",
      "Epoch: 4 | Iteration: 673 | Classification loss: 0.26607 | Regression loss: 0.42326 | Running loss: 0.67091\n",
      "Epoch: 4 | Iteration: 674 | Classification loss: 0.37525 | Regression loss: 0.45408 | Running loss: 0.67130\n",
      "Epoch: 4 | Iteration: 675 | Classification loss: 0.40443 | Regression loss: 0.42505 | Running loss: 0.67201\n",
      "Epoch: 4 | Iteration: 676 | Classification loss: 0.20963 | Regression loss: 0.34285 | Running loss: 0.67233\n",
      "Epoch: 4 | Iteration: 677 | Classification loss: 0.28684 | Regression loss: 0.23098 | Running loss: 0.67270\n",
      "Epoch: 4 | Iteration: 678 | Classification loss: 0.27304 | Regression loss: 0.50277 | Running loss: 0.67291\n",
      "Epoch: 4 | Iteration: 679 | Classification loss: 0.14829 | Regression loss: 0.25021 | Running loss: 0.67252\n",
      "Epoch: 4 | Iteration: 680 | Classification loss: 0.34601 | Regression loss: 0.39865 | Running loss: 0.67196\n",
      "Epoch: 4 | Iteration: 681 | Classification loss: 0.18340 | Regression loss: 0.52671 | Running loss: 0.67157\n",
      "Epoch: 4 | Iteration: 682 | Classification loss: 0.30466 | Regression loss: 0.28665 | Running loss: 0.67091\n",
      "Epoch: 4 | Iteration: 683 | Classification loss: 0.41299 | Regression loss: 0.55667 | Running loss: 0.67143\n",
      "Epoch: 4 | Iteration: 684 | Classification loss: 0.28186 | Regression loss: 0.56519 | Running loss: 0.67191\n",
      "Epoch: 4 | Iteration: 685 | Classification loss: 0.26525 | Regression loss: 0.49436 | Running loss: 0.67195\n",
      "Epoch: 4 | Iteration: 686 | Classification loss: 0.25603 | Regression loss: 0.41784 | Running loss: 0.67228\n",
      "Epoch: 4 | Iteration: 687 | Classification loss: 0.33764 | Regression loss: 0.30556 | Running loss: 0.67188\n",
      "Epoch: 4 | Iteration: 688 | Classification loss: 0.21279 | Regression loss: 0.46163 | Running loss: 0.67156\n",
      "Epoch: 4 | Iteration: 689 | Classification loss: 0.36165 | Regression loss: 0.66948 | Running loss: 0.67172\n",
      "Epoch: 4 | Iteration: 690 | Classification loss: 0.31886 | Regression loss: 0.63855 | Running loss: 0.67216\n",
      "Epoch: 4 | Iteration: 691 | Classification loss: 0.33942 | Regression loss: 0.42524 | Running loss: 0.67294\n",
      "Epoch: 4 | Iteration: 692 | Classification loss: 0.32238 | Regression loss: 0.41211 | Running loss: 0.67327\n",
      "Epoch: 4 | Iteration: 693 | Classification loss: 0.27206 | Regression loss: 0.25703 | Running loss: 0.67277\n",
      "Epoch: 4 | Iteration: 694 | Classification loss: 0.26939 | Regression loss: 0.11802 | Running loss: 0.67219\n",
      "Epoch: 4 | Iteration: 695 | Classification loss: 0.51933 | Regression loss: 0.50146 | Running loss: 0.67295\n",
      "Epoch: 4 | Iteration: 696 | Classification loss: 0.19850 | Regression loss: 0.34728 | Running loss: 0.67298\n",
      "Epoch: 4 | Iteration: 697 | Classification loss: 0.27304 | Regression loss: 0.20066 | Running loss: 0.67256\n",
      "Epoch: 4 | Iteration: 698 | Classification loss: 0.30595 | Regression loss: 0.32463 | Running loss: 0.67265\n",
      "Epoch: 4 | Iteration: 699 | Classification loss: 0.20006 | Regression loss: 0.50477 | Running loss: 0.67307\n",
      "Epoch: 4 | Iteration: 700 | Classification loss: 0.35721 | Regression loss: 0.55380 | Running loss: 0.67362\n",
      "Epoch: 4 | Iteration: 701 | Classification loss: 0.32206 | Regression loss: 0.47801 | Running loss: 0.67370\n",
      "Epoch: 4 | Iteration: 702 | Classification loss: 0.20179 | Regression loss: 0.33288 | Running loss: 0.67363\n",
      "Epoch: 4 | Iteration: 703 | Classification loss: 0.32336 | Regression loss: 0.40774 | Running loss: 0.67314\n",
      "Epoch: 4 | Iteration: 704 | Classification loss: 0.33644 | Regression loss: 0.64276 | Running loss: 0.67426\n",
      "Epoch: 4 | Iteration: 705 | Classification loss: 0.28130 | Regression loss: 0.57309 | Running loss: 0.67499\n",
      "Epoch: 4 | Iteration: 706 | Classification loss: 0.11824 | Regression loss: 0.25203 | Running loss: 0.67422\n",
      "Epoch: 4 | Iteration: 707 | Classification loss: 0.21361 | Regression loss: 0.37224 | Running loss: 0.67393\n",
      "Epoch: 4 | Iteration: 708 | Classification loss: 0.49474 | Regression loss: 0.71541 | Running loss: 0.67548\n",
      "Epoch: 4 | Iteration: 709 | Classification loss: 0.11681 | Regression loss: 0.27654 | Running loss: 0.67472\n",
      "Epoch: 4 | Iteration: 710 | Classification loss: 0.10201 | Regression loss: 0.27676 | Running loss: 0.67344\n",
      "Epoch: 4 | Iteration: 711 | Classification loss: 0.21714 | Regression loss: 0.26193 | Running loss: 0.67331\n",
      "Epoch: 4 | Iteration: 712 | Classification loss: 0.34224 | Regression loss: 0.49360 | Running loss: 0.67431\n",
      "Epoch: 4 | Iteration: 713 | Classification loss: 0.35278 | Regression loss: 0.28093 | Running loss: 0.67436\n",
      "Epoch: 4 | Iteration: 714 | Classification loss: 0.20792 | Regression loss: 0.36439 | Running loss: 0.67359\n",
      "Epoch: 4 | Iteration: 715 | Classification loss: 0.38006 | Regression loss: 0.24175 | Running loss: 0.67386\n",
      "Epoch: 4 | Iteration: 716 | Classification loss: 0.31135 | Regression loss: 0.40094 | Running loss: 0.67406\n",
      "Epoch: 4 | Iteration: 717 | Classification loss: 0.33597 | Regression loss: 0.06233 | Running loss: 0.67413\n",
      "Epoch: 4 | Iteration: 718 | Classification loss: 0.19915 | Regression loss: 0.36576 | Running loss: 0.67479\n",
      "Epoch: 4 | Iteration: 719 | Classification loss: 0.35124 | Regression loss: 0.58387 | Running loss: 0.67482\n",
      "Epoch: 4 | Iteration: 720 | Classification loss: 0.48837 | Regression loss: 0.55515 | Running loss: 0.67546\n",
      "Epoch: 4 | Iteration: 721 | Classification loss: 0.30692 | Regression loss: 0.29794 | Running loss: 0.67513\n",
      "Epoch: 4 | Iteration: 722 | Classification loss: 0.17546 | Regression loss: 0.26959 | Running loss: 0.67428\n",
      "Epoch: 4 | Iteration: 723 | Classification loss: 0.10483 | Regression loss: 0.19525 | Running loss: 0.67367\n",
      "Epoch: 4 | Iteration: 724 | Classification loss: 0.14437 | Regression loss: 0.56092 | Running loss: 0.67452\n",
      "Epoch: 4 | Iteration: 725 | Classification loss: 0.30958 | Regression loss: 0.41319 | Running loss: 0.67437\n",
      "Epoch: 4 | Iteration: 726 | Classification loss: 0.30466 | Regression loss: 0.63315 | Running loss: 0.67518\n",
      "Epoch: 4 | Iteration: 727 | Classification loss: 0.23133 | Regression loss: 0.26199 | Running loss: 0.67511\n",
      "Epoch: 4 | Iteration: 728 | Classification loss: 0.18832 | Regression loss: 0.40181 | Running loss: 0.67499\n",
      "Epoch: 4 | Iteration: 729 | Classification loss: 0.28073 | Regression loss: 0.43617 | Running loss: 0.67531\n",
      "Epoch: 4 | Iteration: 730 | Classification loss: 0.17011 | Regression loss: 0.23191 | Running loss: 0.67485\n",
      "Epoch: 4 | Iteration: 731 | Classification loss: 0.80709 | Regression loss: 0.72328 | Running loss: 0.67703\n",
      "Epoch: 4 | Iteration: 732 | Classification loss: 0.25527 | Regression loss: 0.39396 | Running loss: 0.67765\n",
      "Epoch: 4 | Iteration: 733 | Classification loss: 0.19790 | Regression loss: 0.21972 | Running loss: 0.67793\n",
      "Epoch: 4 | Iteration: 734 | Classification loss: 0.20757 | Regression loss: 0.31182 | Running loss: 0.67733\n",
      "Epoch: 4 | Iteration: 735 | Classification loss: 0.06179 | Regression loss: 0.18983 | Running loss: 0.67706\n",
      "Epoch: 4 | Iteration: 736 | Classification loss: 0.28817 | Regression loss: 0.28751 | Running loss: 0.67722\n",
      "Epoch: 4 | Iteration: 737 | Classification loss: 0.11041 | Regression loss: 0.32469 | Running loss: 0.67657\n",
      "Epoch: 4 | Iteration: 738 | Classification loss: 0.28853 | Regression loss: 0.23909 | Running loss: 0.67622\n",
      "Epoch: 4 | Iteration: 739 | Classification loss: 0.45859 | Regression loss: 0.43646 | Running loss: 0.67693\n",
      "Epoch: 4 | Iteration: 740 | Classification loss: 0.16178 | Regression loss: 0.47655 | Running loss: 0.67703\n",
      "Epoch: 4 | Iteration: 741 | Classification loss: 0.45572 | Regression loss: 0.89537 | Running loss: 0.67865\n",
      "Epoch: 4 | Iteration: 742 | Classification loss: 0.18596 | Regression loss: 0.52099 | Running loss: 0.67772\n",
      "Epoch: 4 | Iteration: 743 | Classification loss: 0.18548 | Regression loss: 0.28861 | Running loss: 0.67710\n",
      "Epoch: 4 | Iteration: 744 | Classification loss: 0.11710 | Regression loss: 0.20553 | Running loss: 0.67662\n",
      "Epoch: 4 | Iteration: 745 | Classification loss: 0.28056 | Regression loss: 0.31650 | Running loss: 0.67687\n",
      "Epoch: 4 | Iteration: 746 | Classification loss: 0.19417 | Regression loss: 0.34247 | Running loss: 0.67679\n",
      "Epoch: 4 | Iteration: 747 | Classification loss: 0.22278 | Regression loss: 0.38052 | Running loss: 0.67700\n",
      "Epoch: 4 | Iteration: 748 | Classification loss: 0.20981 | Regression loss: 0.27184 | Running loss: 0.67668\n",
      "Epoch: 4 | Iteration: 749 | Classification loss: 0.28297 | Regression loss: 0.46629 | Running loss: 0.67701\n",
      "Epoch: 4 | Iteration: 750 | Classification loss: 0.42157 | Regression loss: 0.76472 | Running loss: 0.67777\n",
      "Epoch: 4 | Iteration: 751 | Classification loss: 0.33559 | Regression loss: 0.23062 | Running loss: 0.67769\n",
      "Epoch: 4 | Iteration: 752 | Classification loss: 0.10444 | Regression loss: 0.35551 | Running loss: 0.67692\n",
      "Epoch: 4 | Iteration: 753 | Classification loss: 0.32882 | Regression loss: 0.62471 | Running loss: 0.67700\n",
      "Epoch: 4 | Iteration: 754 | Classification loss: 0.47693 | Regression loss: 0.81557 | Running loss: 0.67776\n",
      "Epoch: 4 | Iteration: 755 | Classification loss: 0.09164 | Regression loss: 0.20235 | Running loss: 0.67725\n",
      "Epoch: 4 | Iteration: 756 | Classification loss: 0.53739 | Regression loss: 0.69598 | Running loss: 0.67820\n",
      "Epoch: 4 | Iteration: 757 | Classification loss: 0.23955 | Regression loss: 0.50309 | Running loss: 0.67775\n",
      "Epoch: 4 | Iteration: 758 | Classification loss: 0.07465 | Regression loss: 0.20526 | Running loss: 0.67697\n",
      "Epoch: 4 | Iteration: 759 | Classification loss: 0.19928 | Regression loss: 0.36666 | Running loss: 0.67638\n",
      "Epoch: 4 | Iteration: 760 | Classification loss: 0.25302 | Regression loss: 0.59881 | Running loss: 0.67643\n",
      "Epoch: 4 | Iteration: 761 | Classification loss: 0.58028 | Regression loss: 0.47894 | Running loss: 0.67682\n",
      "Epoch: 4 | Iteration: 762 | Classification loss: 0.19550 | Regression loss: 0.54459 | Running loss: 0.67643\n",
      "Epoch: 4 | Iteration: 763 | Classification loss: 0.27276 | Regression loss: 0.56136 | Running loss: 0.67680\n",
      "Epoch: 4 | Iteration: 764 | Classification loss: 0.20363 | Regression loss: 0.32533 | Running loss: 0.67685\n",
      "Epoch: 4 | Iteration: 765 | Classification loss: 0.17011 | Regression loss: 0.28363 | Running loss: 0.67692\n",
      "Epoch: 4 | Iteration: 766 | Classification loss: 0.26970 | Regression loss: 0.44240 | Running loss: 0.67731\n",
      "Epoch: 4 | Iteration: 767 | Classification loss: 0.50979 | Regression loss: 0.27759 | Running loss: 0.67775\n",
      "Epoch: 4 | Iteration: 768 | Classification loss: 0.25876 | Regression loss: 0.52659 | Running loss: 0.67779\n",
      "Epoch: 4 | Iteration: 769 | Classification loss: 0.31698 | Regression loss: 0.39299 | Running loss: 0.67741\n",
      "Epoch: 4 | Iteration: 770 | Classification loss: 0.32750 | Regression loss: 0.30621 | Running loss: 0.67738\n",
      "Epoch: 4 | Iteration: 771 | Classification loss: 0.35941 | Regression loss: 0.46997 | Running loss: 0.67646\n",
      "Epoch: 4 | Iteration: 772 | Classification loss: 0.32027 | Regression loss: 0.64863 | Running loss: 0.67739\n",
      "Epoch: 4 | Iteration: 773 | Classification loss: 0.41478 | Regression loss: 0.25452 | Running loss: 0.67700\n",
      "Epoch: 4 | Iteration: 774 | Classification loss: 0.06722 | Regression loss: 0.21275 | Running loss: 0.67613\n",
      "Epoch: 4 | Iteration: 775 | Classification loss: 0.49069 | Regression loss: 0.69236 | Running loss: 0.67727\n",
      "Epoch: 4 | Iteration: 776 | Classification loss: 0.29022 | Regression loss: 0.29453 | Running loss: 0.67633\n",
      "Epoch: 4 | Iteration: 777 | Classification loss: 0.17636 | Regression loss: 0.18262 | Running loss: 0.67578\n",
      "Epoch: 4 | Iteration: 778 | Classification loss: 0.14424 | Regression loss: 0.25177 | Running loss: 0.67557\n",
      "Epoch: 4 | Iteration: 779 | Classification loss: 0.17215 | Regression loss: 0.26247 | Running loss: 0.67443\n",
      "Epoch: 4 | Iteration: 780 | Classification loss: 0.30667 | Regression loss: 0.18887 | Running loss: 0.67420\n",
      "Epoch: 4 | Iteration: 781 | Classification loss: 0.16777 | Regression loss: 0.39418 | Running loss: 0.67401\n",
      "Epoch: 4 | Iteration: 782 | Classification loss: 0.44542 | Regression loss: 0.35040 | Running loss: 0.67474\n",
      "Epoch: 4 | Iteration: 783 | Classification loss: 0.14416 | Regression loss: 0.28864 | Running loss: 0.67424\n",
      "Epoch: 4 | Iteration: 784 | Classification loss: 0.19031 | Regression loss: 0.36436 | Running loss: 0.67387\n",
      "Epoch: 4 | Iteration: 785 | Classification loss: 0.38858 | Regression loss: 0.60409 | Running loss: 0.67496\n",
      "Epoch: 4 | Iteration: 786 | Classification loss: 0.34706 | Regression loss: 0.35665 | Running loss: 0.67571\n",
      "Epoch: 4 | Iteration: 787 | Classification loss: 0.32532 | Regression loss: 0.69547 | Running loss: 0.67693\n",
      "Epoch: 4 | Iteration: 788 | Classification loss: 0.11637 | Regression loss: 0.43545 | Running loss: 0.67745\n",
      "Epoch: 4 | Iteration: 789 | Classification loss: 0.31195 | Regression loss: 0.31721 | Running loss: 0.67753\n",
      "Epoch: 4 | Iteration: 790 | Classification loss: 0.12708 | Regression loss: 0.36176 | Running loss: 0.67737\n",
      "Epoch: 4 | Iteration: 791 | Classification loss: 0.35376 | Regression loss: 0.49512 | Running loss: 0.67728\n",
      "Epoch: 4 | Iteration: 792 | Classification loss: 0.28538 | Regression loss: 0.29822 | Running loss: 0.67681\n",
      "Epoch: 4 | Iteration: 793 | Classification loss: 0.46521 | Regression loss: 0.71530 | Running loss: 0.67780\n",
      "Epoch: 4 | Iteration: 794 | Classification loss: 0.17563 | Regression loss: 0.44466 | Running loss: 0.67687\n",
      "Epoch: 4 | Iteration: 795 | Classification loss: 0.17504 | Regression loss: 0.36214 | Running loss: 0.67662\n",
      "Epoch: 4 | Iteration: 796 | Classification loss: 0.20050 | Regression loss: 0.17160 | Running loss: 0.67627\n",
      "Epoch: 4 | Iteration: 797 | Classification loss: 0.21691 | Regression loss: 0.26950 | Running loss: 0.67603\n",
      "Epoch: 4 | Iteration: 798 | Classification loss: 0.39462 | Regression loss: 0.40302 | Running loss: 0.67652\n",
      "Epoch: 4 | Iteration: 799 | Classification loss: 0.18050 | Regression loss: 0.19146 | Running loss: 0.67571\n",
      "Epoch: 4 | Iteration: 800 | Classification loss: 0.32264 | Regression loss: 0.40855 | Running loss: 0.67625\n",
      "Epoch: 4 | Iteration: 801 | Classification loss: 0.20526 | Regression loss: 0.73989 | Running loss: 0.67673\n",
      "Epoch: 4 | Iteration: 802 | Classification loss: 0.12798 | Regression loss: 0.39174 | Running loss: 0.67610\n",
      "Epoch: 4 | Iteration: 803 | Classification loss: 0.38982 | Regression loss: 0.22715 | Running loss: 0.67549\n",
      "Epoch: 4 | Iteration: 804 | Classification loss: 0.54443 | Regression loss: 0.63330 | Running loss: 0.67679\n",
      "Epoch: 4 | Iteration: 805 | Classification loss: 0.12567 | Regression loss: 0.51944 | Running loss: 0.67607\n",
      "Epoch: 4 | Iteration: 806 | Classification loss: 0.14276 | Regression loss: 0.19150 | Running loss: 0.67559\n",
      "Epoch: 4 | Iteration: 807 | Classification loss: 0.18647 | Regression loss: 0.40028 | Running loss: 0.67538\n",
      "Epoch: 4 | Iteration: 808 | Classification loss: 0.29390 | Regression loss: 0.29717 | Running loss: 0.67534\n",
      "Epoch: 4 | Iteration: 809 | Classification loss: 0.68644 | Regression loss: 0.46624 | Running loss: 0.67629\n",
      "Epoch: 4 | Iteration: 810 | Classification loss: 0.01330 | Regression loss: 0.00000 | Running loss: 0.67488\n",
      "Epoch: 4 | Iteration: 811 | Classification loss: 0.43248 | Regression loss: 0.32734 | Running loss: 0.67472\n",
      "Epoch: 4 | Iteration: 812 | Classification loss: 0.45193 | Regression loss: 0.51406 | Running loss: 0.67502\n",
      "Epoch: 4 | Iteration: 813 | Classification loss: 0.46609 | Regression loss: 0.42449 | Running loss: 0.67560\n",
      "Epoch: 4 | Iteration: 814 | Classification loss: 0.31533 | Regression loss: 0.50501 | Running loss: 0.67482\n",
      "Epoch: 4 | Iteration: 815 | Classification loss: 0.23880 | Regression loss: 0.40063 | Running loss: 0.67532\n",
      "Epoch: 4 | Iteration: 816 | Classification loss: 0.13743 | Regression loss: 0.46991 | Running loss: 0.67518\n",
      "Epoch: 4 | Iteration: 817 | Classification loss: 0.17170 | Regression loss: 0.62363 | Running loss: 0.67607\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 5 | Iteration: 0 | Classification loss: 0.24907 | Regression loss: 0.40462 | Running loss: 0.67580\n",
      "Epoch: 5 | Iteration: 1 | Classification loss: 0.36970 | Regression loss: 0.53739 | Running loss: 0.67640\n",
      "Epoch: 5 | Iteration: 2 | Classification loss: 0.35304 | Regression loss: 0.62924 | Running loss: 0.67640\n",
      "Epoch: 5 | Iteration: 3 | Classification loss: 0.28709 | Regression loss: 0.29691 | Running loss: 0.67624\n",
      "Epoch: 5 | Iteration: 4 | Classification loss: 0.33417 | Regression loss: 0.53479 | Running loss: 0.67607\n",
      "Epoch: 5 | Iteration: 5 | Classification loss: 0.21125 | Regression loss: 0.25302 | Running loss: 0.67605\n",
      "Epoch: 5 | Iteration: 6 | Classification loss: 0.38667 | Regression loss: 0.49027 | Running loss: 0.67646\n",
      "Epoch: 5 | Iteration: 7 | Classification loss: 0.20438 | Regression loss: 0.39513 | Running loss: 0.67608\n",
      "Epoch: 5 | Iteration: 8 | Classification loss: 0.21580 | Regression loss: 0.43068 | Running loss: 0.67483\n",
      "Epoch: 5 | Iteration: 9 | Classification loss: 0.16533 | Regression loss: 0.24574 | Running loss: 0.67454\n",
      "Epoch: 5 | Iteration: 10 | Classification loss: 0.11889 | Regression loss: 0.25836 | Running loss: 0.67303\n",
      "Epoch: 5 | Iteration: 11 | Classification loss: 0.31270 | Regression loss: 0.31817 | Running loss: 0.67340\n",
      "Epoch: 5 | Iteration: 12 | Classification loss: 0.24686 | Regression loss: 0.26841 | Running loss: 0.67334\n",
      "Epoch: 5 | Iteration: 13 | Classification loss: 0.36862 | Regression loss: 0.38790 | Running loss: 0.67379\n",
      "Epoch: 5 | Iteration: 14 | Classification loss: 0.60099 | Regression loss: 0.67921 | Running loss: 0.67513\n",
      "Epoch: 5 | Iteration: 15 | Classification loss: 0.10879 | Regression loss: 0.26470 | Running loss: 0.67462\n",
      "Epoch: 5 | Iteration: 16 | Classification loss: 0.06966 | Regression loss: 0.29562 | Running loss: 0.67381\n",
      "Epoch: 5 | Iteration: 17 | Classification loss: 0.39588 | Regression loss: 0.41173 | Running loss: 0.67411\n",
      "Epoch: 5 | Iteration: 18 | Classification loss: 0.23096 | Regression loss: 0.34088 | Running loss: 0.67421\n",
      "Epoch: 5 | Iteration: 19 | Classification loss: 0.26198 | Regression loss: 0.65459 | Running loss: 0.67531\n",
      "Epoch: 5 | Iteration: 20 | Classification loss: 0.29927 | Regression loss: 0.44746 | Running loss: 0.67561\n",
      "Epoch: 5 | Iteration: 21 | Classification loss: 0.23979 | Regression loss: 0.27671 | Running loss: 0.67531\n",
      "Epoch: 5 | Iteration: 22 | Classification loss: 0.11332 | Regression loss: 0.32825 | Running loss: 0.67465\n",
      "Epoch: 5 | Iteration: 23 | Classification loss: 0.38272 | Regression loss: 0.48247 | Running loss: 0.67492\n",
      "Epoch: 5 | Iteration: 24 | Classification loss: 0.28655 | Regression loss: 0.55658 | Running loss: 0.67559\n",
      "Epoch: 5 | Iteration: 25 | Classification loss: 0.36645 | Regression loss: 0.48117 | Running loss: 0.67532\n",
      "Epoch: 5 | Iteration: 26 | Classification loss: 0.42513 | Regression loss: 0.44354 | Running loss: 0.67544\n",
      "Epoch: 5 | Iteration: 27 | Classification loss: 0.24863 | Regression loss: 0.30443 | Running loss: 0.67558\n",
      "Epoch: 5 | Iteration: 28 | Classification loss: 0.41940 | Regression loss: 0.44782 | Running loss: 0.67548\n",
      "Epoch: 5 | Iteration: 29 | Classification loss: 0.24447 | Regression loss: 0.41070 | Running loss: 0.67567\n",
      "Epoch: 5 | Iteration: 30 | Classification loss: 0.32222 | Regression loss: 0.27897 | Running loss: 0.67564\n",
      "Epoch: 5 | Iteration: 31 | Classification loss: 0.24495 | Regression loss: 0.41848 | Running loss: 0.67608\n",
      "Epoch: 5 | Iteration: 32 | Classification loss: 0.39072 | Regression loss: 0.22026 | Running loss: 0.67591\n",
      "Epoch: 5 | Iteration: 33 | Classification loss: 0.23754 | Regression loss: 0.31788 | Running loss: 0.67562\n",
      "Epoch: 5 | Iteration: 34 | Classification loss: 0.22512 | Regression loss: 0.50874 | Running loss: 0.67622\n",
      "Epoch: 5 | Iteration: 35 | Classification loss: 0.29537 | Regression loss: 0.55151 | Running loss: 0.67592\n",
      "Epoch: 5 | Iteration: 36 | Classification loss: 0.17493 | Regression loss: 0.41228 | Running loss: 0.67530\n",
      "Epoch: 5 | Iteration: 37 | Classification loss: 0.26321 | Regression loss: 0.41528 | Running loss: 0.67558\n",
      "Epoch: 5 | Iteration: 38 | Classification loss: 0.11649 | Regression loss: 0.39601 | Running loss: 0.67515\n",
      "Epoch: 5 | Iteration: 39 | Classification loss: 0.23313 | Regression loss: 0.46341 | Running loss: 0.67521\n",
      "Epoch: 5 | Iteration: 40 | Classification loss: 0.18767 | Regression loss: 0.29652 | Running loss: 0.67472\n",
      "Epoch: 5 | Iteration: 41 | Classification loss: 0.51516 | Regression loss: 0.37425 | Running loss: 0.67488\n",
      "Epoch: 5 | Iteration: 42 | Classification loss: 0.29911 | Regression loss: 0.35292 | Running loss: 0.67439\n",
      "Epoch: 5 | Iteration: 43 | Classification loss: 0.09825 | Regression loss: 0.25025 | Running loss: 0.67300\n",
      "Epoch: 5 | Iteration: 44 | Classification loss: 0.26717 | Regression loss: 0.54250 | Running loss: 0.67387\n",
      "Epoch: 5 | Iteration: 45 | Classification loss: 0.23340 | Regression loss: 0.50089 | Running loss: 0.67413\n",
      "Epoch: 5 | Iteration: 46 | Classification loss: 0.32568 | Regression loss: 0.50978 | Running loss: 0.67473\n",
      "Epoch: 5 | Iteration: 47 | Classification loss: 0.18781 | Regression loss: 0.26759 | Running loss: 0.67419\n",
      "Epoch: 5 | Iteration: 48 | Classification loss: 0.37109 | Regression loss: 0.65813 | Running loss: 0.67521\n",
      "Epoch: 5 | Iteration: 49 | Classification loss: 0.13877 | Regression loss: 0.27394 | Running loss: 0.67475\n",
      "Epoch: 5 | Iteration: 50 | Classification loss: 0.12437 | Regression loss: 0.37587 | Running loss: 0.67473\n",
      "Epoch: 5 | Iteration: 51 | Classification loss: 0.32868 | Regression loss: 0.62395 | Running loss: 0.67557\n",
      "Epoch: 5 | Iteration: 52 | Classification loss: 0.16292 | Regression loss: 0.41846 | Running loss: 0.67485\n",
      "Epoch: 5 | Iteration: 53 | Classification loss: 0.18257 | Regression loss: 0.18108 | Running loss: 0.67428\n",
      "Epoch: 5 | Iteration: 54 | Classification loss: 0.21868 | Regression loss: 0.39332 | Running loss: 0.67460\n",
      "Epoch: 5 | Iteration: 55 | Classification loss: 0.14003 | Regression loss: 0.33547 | Running loss: 0.67459\n",
      "Epoch: 5 | Iteration: 56 | Classification loss: 0.32117 | Regression loss: 0.36890 | Running loss: 0.67296\n",
      "Epoch: 5 | Iteration: 57 | Classification loss: 0.16133 | Regression loss: 0.33542 | Running loss: 0.67256\n",
      "Epoch: 5 | Iteration: 58 | Classification loss: 0.17301 | Regression loss: 0.28215 | Running loss: 0.67139\n",
      "Epoch: 5 | Iteration: 59 | Classification loss: 0.19637 | Regression loss: 0.36494 | Running loss: 0.67162\n",
      "Epoch: 5 | Iteration: 60 | Classification loss: 0.23408 | Regression loss: 0.25265 | Running loss: 0.67146\n",
      "Epoch: 5 | Iteration: 61 | Classification loss: 0.15016 | Regression loss: 0.30486 | Running loss: 0.67069\n",
      "Epoch: 5 | Iteration: 62 | Classification loss: 0.38104 | Regression loss: 0.32564 | Running loss: 0.67001\n",
      "Epoch: 5 | Iteration: 63 | Classification loss: 0.20376 | Regression loss: 0.30334 | Running loss: 0.67011\n",
      "Epoch: 5 | Iteration: 64 | Classification loss: 0.17260 | Regression loss: 0.33238 | Running loss: 0.66910\n",
      "Epoch: 5 | Iteration: 65 | Classification loss: 0.09490 | Regression loss: 0.19298 | Running loss: 0.66855\n",
      "Epoch: 5 | Iteration: 66 | Classification loss: 0.10855 | Regression loss: 0.26046 | Running loss: 0.66818\n",
      "Epoch: 5 | Iteration: 67 | Classification loss: 0.42436 | Regression loss: 0.37719 | Running loss: 0.66781\n",
      "Epoch: 5 | Iteration: 68 | Classification loss: 0.45963 | Regression loss: 0.22873 | Running loss: 0.66786\n",
      "Epoch: 5 | Iteration: 69 | Classification loss: 0.20432 | Regression loss: 0.30976 | Running loss: 0.66784\n",
      "Epoch: 5 | Iteration: 70 | Classification loss: 0.29143 | Regression loss: 0.37734 | Running loss: 0.66800\n",
      "Epoch: 5 | Iteration: 71 | Classification loss: 0.30574 | Regression loss: 0.49521 | Running loss: 0.66863\n",
      "Epoch: 5 | Iteration: 72 | Classification loss: 0.42379 | Regression loss: 0.64578 | Running loss: 0.66942\n",
      "Epoch: 5 | Iteration: 73 | Classification loss: 0.13800 | Regression loss: 0.29463 | Running loss: 0.66946\n",
      "Epoch: 5 | Iteration: 74 | Classification loss: 0.07728 | Regression loss: 0.24285 | Running loss: 0.66849\n",
      "Epoch: 5 | Iteration: 75 | Classification loss: 0.28747 | Regression loss: 0.17648 | Running loss: 0.66826\n",
      "Epoch: 5 | Iteration: 76 | Classification loss: 0.26810 | Regression loss: 0.48110 | Running loss: 0.66849\n",
      "Epoch: 5 | Iteration: 77 | Classification loss: 0.44755 | Regression loss: 0.56529 | Running loss: 0.66884\n",
      "Epoch: 5 | Iteration: 78 | Classification loss: 0.17621 | Regression loss: 0.29810 | Running loss: 0.66825\n",
      "Epoch: 5 | Iteration: 79 | Classification loss: 0.21169 | Regression loss: 0.36325 | Running loss: 0.66849\n",
      "Epoch: 5 | Iteration: 80 | Classification loss: 0.37478 | Regression loss: 0.59885 | Running loss: 0.66983\n",
      "Epoch: 5 | Iteration: 81 | Classification loss: 0.46200 | Regression loss: 0.38644 | Running loss: 0.66963\n",
      "Epoch: 5 | Iteration: 82 | Classification loss: 0.32086 | Regression loss: 0.55518 | Running loss: 0.67026\n",
      "Epoch: 5 | Iteration: 83 | Classification loss: 0.21389 | Regression loss: 0.35347 | Running loss: 0.66985\n",
      "Epoch: 5 | Iteration: 84 | Classification loss: 0.27913 | Regression loss: 0.32215 | Running loss: 0.66941\n",
      "Epoch: 5 | Iteration: 85 | Classification loss: 0.18149 | Regression loss: 0.29266 | Running loss: 0.66939\n",
      "Epoch: 5 | Iteration: 86 | Classification loss: 0.27172 | Regression loss: 0.61190 | Running loss: 0.67005\n",
      "Epoch: 5 | Iteration: 87 | Classification loss: 0.19006 | Regression loss: 0.38133 | Running loss: 0.67020\n",
      "Epoch: 5 | Iteration: 88 | Classification loss: 0.48811 | Regression loss: 0.27255 | Running loss: 0.67056\n",
      "Epoch: 5 | Iteration: 89 | Classification loss: 0.14289 | Regression loss: 0.43819 | Running loss: 0.67023\n",
      "Epoch: 5 | Iteration: 90 | Classification loss: 0.19193 | Regression loss: 0.25419 | Running loss: 0.67016\n",
      "Epoch: 5 | Iteration: 91 | Classification loss: 0.09002 | Regression loss: 0.25089 | Running loss: 0.66967\n",
      "Epoch: 5 | Iteration: 92 | Classification loss: 0.46426 | Regression loss: 0.74088 | Running loss: 0.67010\n",
      "Epoch: 5 | Iteration: 93 | Classification loss: 0.06303 | Regression loss: 0.26977 | Running loss: 0.66892\n",
      "Epoch: 5 | Iteration: 94 | Classification loss: 0.38433 | Regression loss: 0.53336 | Running loss: 0.66980\n",
      "Epoch: 5 | Iteration: 95 | Classification loss: 0.09086 | Regression loss: 0.23272 | Running loss: 0.66981\n",
      "Epoch: 5 | Iteration: 96 | Classification loss: 0.13886 | Regression loss: 0.13175 | Running loss: 0.66923\n",
      "Epoch: 5 | Iteration: 97 | Classification loss: 0.19043 | Regression loss: 0.41078 | Running loss: 0.66948\n",
      "Epoch: 5 | Iteration: 98 | Classification loss: 0.20536 | Regression loss: 0.32894 | Running loss: 0.66945\n",
      "Epoch: 5 | Iteration: 99 | Classification loss: 0.30684 | Regression loss: 0.44588 | Running loss: 0.66978\n",
      "Epoch: 5 | Iteration: 100 | Classification loss: 0.34179 | Regression loss: 0.52762 | Running loss: 0.67016\n",
      "Epoch: 5 | Iteration: 101 | Classification loss: 0.23852 | Regression loss: 0.32818 | Running loss: 0.67005\n",
      "Epoch: 5 | Iteration: 102 | Classification loss: 0.16713 | Regression loss: 0.18104 | Running loss: 0.66922\n",
      "Epoch: 5 | Iteration: 103 | Classification loss: 0.30387 | Regression loss: 0.46587 | Running loss: 0.66904\n",
      "Epoch: 5 | Iteration: 104 | Classification loss: 0.47063 | Regression loss: 0.47390 | Running loss: 0.66986\n",
      "Epoch: 5 | Iteration: 105 | Classification loss: 0.30337 | Regression loss: 0.37162 | Running loss: 0.66997\n",
      "Epoch: 5 | Iteration: 106 | Classification loss: 0.23729 | Regression loss: 0.34984 | Running loss: 0.67011\n",
      "Epoch: 5 | Iteration: 107 | Classification loss: 0.06412 | Regression loss: 0.16386 | Running loss: 0.66889\n",
      "Epoch: 5 | Iteration: 108 | Classification loss: 0.33280 | Regression loss: 0.45258 | Running loss: 0.66953\n",
      "Epoch: 5 | Iteration: 109 | Classification loss: 0.43961 | Regression loss: 0.51029 | Running loss: 0.67024\n",
      "Epoch: 5 | Iteration: 110 | Classification loss: 0.14104 | Regression loss: 0.23285 | Running loss: 0.66980\n",
      "Epoch: 5 | Iteration: 111 | Classification loss: 0.23516 | Regression loss: 0.34774 | Running loss: 0.67008\n",
      "Epoch: 5 | Iteration: 112 | Classification loss: 0.50027 | Regression loss: 0.60218 | Running loss: 0.67097\n",
      "Epoch: 5 | Iteration: 113 | Classification loss: 0.11551 | Regression loss: 0.43253 | Running loss: 0.67032\n",
      "Epoch: 5 | Iteration: 114 | Classification loss: 0.28285 | Regression loss: 0.26516 | Running loss: 0.67051\n",
      "Epoch: 5 | Iteration: 115 | Classification loss: 0.07359 | Regression loss: 0.23595 | Running loss: 0.67033\n",
      "Epoch: 5 | Iteration: 116 | Classification loss: 0.22976 | Regression loss: 0.31990 | Running loss: 0.67094\n",
      "Epoch: 5 | Iteration: 117 | Classification loss: 0.22188 | Regression loss: 0.26518 | Running loss: 0.67062\n",
      "Epoch: 5 | Iteration: 118 | Classification loss: 0.27114 | Regression loss: 0.38384 | Running loss: 0.67028\n",
      "Epoch: 5 | Iteration: 119 | Classification loss: 0.28461 | Regression loss: 0.34132 | Running loss: 0.67057\n",
      "Epoch: 5 | Iteration: 120 | Classification loss: 0.13955 | Regression loss: 0.22754 | Running loss: 0.67034\n",
      "Epoch: 5 | Iteration: 121 | Classification loss: 0.17833 | Regression loss: 0.25103 | Running loss: 0.67008\n",
      "Epoch: 5 | Iteration: 122 | Classification loss: 0.36968 | Regression loss: 0.51921 | Running loss: 0.67087\n",
      "Epoch: 5 | Iteration: 123 | Classification loss: 0.09322 | Regression loss: 0.33476 | Running loss: 0.66960\n",
      "Epoch: 5 | Iteration: 124 | Classification loss: 0.23570 | Regression loss: 0.26159 | Running loss: 0.66986\n",
      "Epoch: 5 | Iteration: 125 | Classification loss: 0.15692 | Regression loss: 0.55143 | Running loss: 0.66883\n",
      "Epoch: 5 | Iteration: 126 | Classification loss: 0.26263 | Regression loss: 0.41317 | Running loss: 0.66804\n",
      "Epoch: 5 | Iteration: 127 | Classification loss: 0.30954 | Regression loss: 0.35895 | Running loss: 0.66785\n",
      "Epoch: 5 | Iteration: 128 | Classification loss: 0.37784 | Regression loss: 0.46571 | Running loss: 0.66809\n",
      "Epoch: 5 | Iteration: 129 | Classification loss: 0.11654 | Regression loss: 0.20813 | Running loss: 0.66784\n",
      "Epoch: 5 | Iteration: 130 | Classification loss: 0.11156 | Regression loss: 0.20046 | Running loss: 0.66737\n",
      "Epoch: 5 | Iteration: 131 | Classification loss: 0.10922 | Regression loss: 0.44206 | Running loss: 0.66760\n",
      "Epoch: 5 | Iteration: 132 | Classification loss: 0.16542 | Regression loss: 0.32559 | Running loss: 0.66728\n",
      "Epoch: 5 | Iteration: 133 | Classification loss: 0.16769 | Regression loss: 0.32494 | Running loss: 0.66671\n",
      "Epoch: 5 | Iteration: 134 | Classification loss: 0.22601 | Regression loss: 0.47741 | Running loss: 0.66657\n",
      "Epoch: 5 | Iteration: 135 | Classification loss: 0.13260 | Regression loss: 0.25257 | Running loss: 0.66665\n",
      "Epoch: 5 | Iteration: 136 | Classification loss: 0.17054 | Regression loss: 0.27095 | Running loss: 0.66634\n",
      "Epoch: 5 | Iteration: 137 | Classification loss: 0.20554 | Regression loss: 0.34726 | Running loss: 0.66522\n",
      "Epoch: 5 | Iteration: 138 | Classification loss: 0.18174 | Regression loss: 0.29330 | Running loss: 0.66427\n",
      "Epoch: 5 | Iteration: 139 | Classification loss: 0.06197 | Regression loss: 0.23899 | Running loss: 0.66403\n",
      "Epoch: 5 | Iteration: 140 | Classification loss: 0.14883 | Regression loss: 0.24028 | Running loss: 0.66368\n",
      "Epoch: 5 | Iteration: 141 | Classification loss: 0.15795 | Regression loss: 0.35544 | Running loss: 0.66362\n",
      "Epoch: 5 | Iteration: 142 | Classification loss: 0.30595 | Regression loss: 0.36513 | Running loss: 0.66388\n",
      "Epoch: 5 | Iteration: 143 | Classification loss: 0.13622 | Regression loss: 0.41801 | Running loss: 0.66405\n",
      "Epoch: 5 | Iteration: 144 | Classification loss: 0.29617 | Regression loss: 0.42024 | Running loss: 0.66338\n",
      "Epoch: 5 | Iteration: 145 | Classification loss: 0.44537 | Regression loss: 0.61251 | Running loss: 0.66463\n",
      "Epoch: 5 | Iteration: 146 | Classification loss: 0.33500 | Regression loss: 0.79502 | Running loss: 0.66560\n",
      "Epoch: 5 | Iteration: 147 | Classification loss: 0.24674 | Regression loss: 0.50131 | Running loss: 0.66584\n",
      "Epoch: 5 | Iteration: 148 | Classification loss: 0.23624 | Regression loss: 0.27757 | Running loss: 0.66637\n",
      "Epoch: 5 | Iteration: 149 | Classification loss: 0.13413 | Regression loss: 0.20065 | Running loss: 0.66639\n",
      "Epoch: 5 | Iteration: 150 | Classification loss: 0.26978 | Regression loss: 0.43473 | Running loss: 0.66639\n",
      "Epoch: 5 | Iteration: 151 | Classification loss: 0.15944 | Regression loss: 0.23422 | Running loss: 0.66529\n",
      "Epoch: 5 | Iteration: 152 | Classification loss: 0.23874 | Regression loss: 0.25218 | Running loss: 0.66375\n",
      "Epoch: 5 | Iteration: 153 | Classification loss: 0.18821 | Regression loss: 0.33999 | Running loss: 0.66382\n",
      "Epoch: 5 | Iteration: 154 | Classification loss: 0.26206 | Regression loss: 0.41386 | Running loss: 0.66413\n",
      "Epoch: 5 | Iteration: 155 | Classification loss: 0.25544 | Regression loss: 0.35914 | Running loss: 0.66402\n",
      "Epoch: 5 | Iteration: 156 | Classification loss: 0.39631 | Regression loss: 0.46995 | Running loss: 0.66464\n",
      "Epoch: 5 | Iteration: 157 | Classification loss: 0.46889 | Regression loss: 0.23831 | Running loss: 0.66477\n",
      "Epoch: 5 | Iteration: 158 | Classification loss: 0.33186 | Regression loss: 0.56768 | Running loss: 0.66430\n",
      "Epoch: 5 | Iteration: 159 | Classification loss: 0.24067 | Regression loss: 0.36322 | Running loss: 0.66342\n",
      "Epoch: 5 | Iteration: 160 | Classification loss: 0.22779 | Regression loss: 0.42198 | Running loss: 0.66283\n",
      "Epoch: 5 | Iteration: 161 | Classification loss: 0.20803 | Regression loss: 0.46356 | Running loss: 0.66291\n",
      "Epoch: 5 | Iteration: 162 | Classification loss: 0.19487 | Regression loss: 0.08058 | Running loss: 0.66226\n",
      "Epoch: 5 | Iteration: 163 | Classification loss: 0.18368 | Regression loss: 0.15470 | Running loss: 0.66165\n",
      "Epoch: 5 | Iteration: 164 | Classification loss: 0.00048 | Regression loss: 0.00000 | Running loss: 0.66004\n",
      "Epoch: 5 | Iteration: 165 | Classification loss: 0.47256 | Regression loss: 0.24883 | Running loss: 0.65974\n",
      "Epoch: 5 | Iteration: 166 | Classification loss: 0.21824 | Regression loss: 0.40142 | Running loss: 0.65960\n",
      "Epoch: 5 | Iteration: 167 | Classification loss: 0.41825 | Regression loss: 0.69198 | Running loss: 0.66024\n",
      "Epoch: 5 | Iteration: 168 | Classification loss: 0.37520 | Regression loss: 0.37114 | Running loss: 0.66077\n",
      "Epoch: 5 | Iteration: 169 | Classification loss: 0.09991 | Regression loss: 0.21413 | Running loss: 0.66019\n",
      "Epoch: 5 | Iteration: 170 | Classification loss: 0.32481 | Regression loss: 0.22834 | Running loss: 0.66004\n",
      "Epoch: 5 | Iteration: 171 | Classification loss: 0.22815 | Regression loss: 0.35133 | Running loss: 0.65971\n",
      "Epoch: 5 | Iteration: 172 | Classification loss: 0.23285 | Regression loss: 0.41819 | Running loss: 0.65881\n",
      "Epoch: 5 | Iteration: 173 | Classification loss: 0.18449 | Regression loss: 0.38074 | Running loss: 0.65865\n",
      "Epoch: 5 | Iteration: 174 | Classification loss: 0.11354 | Regression loss: 0.25976 | Running loss: 0.65735\n",
      "Epoch: 5 | Iteration: 175 | Classification loss: 0.14927 | Regression loss: 0.48309 | Running loss: 0.65691\n",
      "Epoch: 5 | Iteration: 176 | Classification loss: 0.79650 | Regression loss: 0.45649 | Running loss: 0.65885\n",
      "Epoch: 5 | Iteration: 177 | Classification loss: 0.11441 | Regression loss: 0.26361 | Running loss: 0.65830\n",
      "Epoch: 5 | Iteration: 178 | Classification loss: 0.33002 | Regression loss: 0.33369 | Running loss: 0.65827\n",
      "Epoch: 5 | Iteration: 179 | Classification loss: 0.12561 | Regression loss: 0.30274 | Running loss: 0.65761\n",
      "Epoch: 5 | Iteration: 180 | Classification loss: 0.17879 | Regression loss: 0.22241 | Running loss: 0.65740\n",
      "Epoch: 5 | Iteration: 181 | Classification loss: 0.17746 | Regression loss: 0.34370 | Running loss: 0.65676\n",
      "Epoch: 5 | Iteration: 182 | Classification loss: 0.12807 | Regression loss: 0.21446 | Running loss: 0.65446\n",
      "Epoch: 5 | Iteration: 183 | Classification loss: 0.17376 | Regression loss: 0.46050 | Running loss: 0.65567\n",
      "Epoch: 5 | Iteration: 184 | Classification loss: 0.55271 | Regression loss: 0.14737 | Running loss: 0.65590\n",
      "Epoch: 5 | Iteration: 185 | Classification loss: 0.16992 | Regression loss: 0.30865 | Running loss: 0.65608\n",
      "Epoch: 5 | Iteration: 186 | Classification loss: 0.34462 | Regression loss: 0.47211 | Running loss: 0.65719\n",
      "Epoch: 5 | Iteration: 187 | Classification loss: 0.33933 | Regression loss: 0.43315 | Running loss: 0.65751\n",
      "Epoch: 5 | Iteration: 188 | Classification loss: 0.23163 | Regression loss: 0.60752 | Running loss: 0.65850\n",
      "Epoch: 5 | Iteration: 189 | Classification loss: 0.53515 | Regression loss: 0.64028 | Running loss: 0.65996\n",
      "Epoch: 5 | Iteration: 190 | Classification loss: 0.17359 | Regression loss: 0.26457 | Running loss: 0.65932\n",
      "Epoch: 5 | Iteration: 191 | Classification loss: 0.17356 | Regression loss: 0.28434 | Running loss: 0.65842\n",
      "Epoch: 5 | Iteration: 192 | Classification loss: 0.06885 | Regression loss: 0.27915 | Running loss: 0.65337\n",
      "Epoch: 5 | Iteration: 193 | Classification loss: 0.17395 | Regression loss: 0.35080 | Running loss: 0.65337\n",
      "Epoch: 5 | Iteration: 194 | Classification loss: 0.56222 | Regression loss: 0.60425 | Running loss: 0.65452\n",
      "Epoch: 5 | Iteration: 195 | Classification loss: 0.36752 | Regression loss: 0.24528 | Running loss: 0.65353\n",
      "Epoch: 5 | Iteration: 196 | Classification loss: 0.29010 | Regression loss: 0.19823 | Running loss: 0.65315\n",
      "Epoch: 5 | Iteration: 197 | Classification loss: 0.18941 | Regression loss: 0.23917 | Running loss: 0.65274\n",
      "Epoch: 5 | Iteration: 198 | Classification loss: 0.30207 | Regression loss: 0.54216 | Running loss: 0.65253\n",
      "Epoch: 5 | Iteration: 199 | Classification loss: 0.12452 | Regression loss: 0.33613 | Running loss: 0.65236\n",
      "Epoch: 5 | Iteration: 200 | Classification loss: 0.15261 | Regression loss: 0.30608 | Running loss: 0.65208\n",
      "Epoch: 5 | Iteration: 201 | Classification loss: 0.08412 | Regression loss: 0.24707 | Running loss: 0.65116\n",
      "Epoch: 5 | Iteration: 202 | Classification loss: 0.25021 | Regression loss: 0.33493 | Running loss: 0.65091\n",
      "Epoch: 5 | Iteration: 203 | Classification loss: 0.05224 | Regression loss: 0.21424 | Running loss: 0.65017\n",
      "Epoch: 5 | Iteration: 204 | Classification loss: 0.13702 | Regression loss: 0.23238 | Running loss: 0.65014\n",
      "Epoch: 5 | Iteration: 205 | Classification loss: 0.28234 | Regression loss: 0.21947 | Running loss: 0.65017\n",
      "Epoch: 5 | Iteration: 206 | Classification loss: 0.09337 | Regression loss: 0.31959 | Running loss: 0.64950\n",
      "Epoch: 5 | Iteration: 207 | Classification loss: 0.07777 | Regression loss: 0.36356 | Running loss: 0.64928\n",
      "Epoch: 5 | Iteration: 208 | Classification loss: 0.16330 | Regression loss: 0.22372 | Running loss: 0.64802\n",
      "Epoch: 5 | Iteration: 209 | Classification loss: 0.17533 | Regression loss: 0.32867 | Running loss: 0.64765\n",
      "Epoch: 5 | Iteration: 210 | Classification loss: 0.07759 | Regression loss: 0.22541 | Running loss: 0.64703\n",
      "Epoch: 5 | Iteration: 211 | Classification loss: 0.14424 | Regression loss: 0.41101 | Running loss: 0.64714\n",
      "Epoch: 5 | Iteration: 212 | Classification loss: 0.72175 | Regression loss: 0.13771 | Running loss: 0.64758\n",
      "Epoch: 5 | Iteration: 213 | Classification loss: 0.23747 | Regression loss: 0.69530 | Running loss: 0.64817\n",
      "Epoch: 5 | Iteration: 214 | Classification loss: 0.35046 | Regression loss: 0.23461 | Running loss: 0.64827\n",
      "Epoch: 5 | Iteration: 215 | Classification loss: 0.16916 | Regression loss: 0.26941 | Running loss: 0.64786\n",
      "Epoch: 5 | Iteration: 216 | Classification loss: 0.32044 | Regression loss: 0.33686 | Running loss: 0.64688\n",
      "Epoch: 5 | Iteration: 217 | Classification loss: 0.12754 | Regression loss: 0.18554 | Running loss: 0.64605\n",
      "Epoch: 5 | Iteration: 218 | Classification loss: 0.33660 | Regression loss: 0.30473 | Running loss: 0.64608\n",
      "Epoch: 5 | Iteration: 219 | Classification loss: 0.34649 | Regression loss: 0.47719 | Running loss: 0.64653\n",
      "Epoch: 5 | Iteration: 220 | Classification loss: 0.40959 | Regression loss: 0.22224 | Running loss: 0.64581\n",
      "Epoch: 5 | Iteration: 221 | Classification loss: 0.21613 | Regression loss: 0.52964 | Running loss: 0.64603\n",
      "Epoch: 5 | Iteration: 222 | Classification loss: 0.13602 | Regression loss: 0.30535 | Running loss: 0.64580\n",
      "Epoch: 5 | Iteration: 223 | Classification loss: 0.29837 | Regression loss: 0.30882 | Running loss: 0.64625\n",
      "Epoch: 5 | Iteration: 224 | Classification loss: 0.14152 | Regression loss: 0.61283 | Running loss: 0.64660\n",
      "Epoch: 5 | Iteration: 225 | Classification loss: 0.09348 | Regression loss: 0.25744 | Running loss: 0.64666\n",
      "Epoch: 5 | Iteration: 226 | Classification loss: 0.10446 | Regression loss: 0.29457 | Running loss: 0.64563\n",
      "Epoch: 5 | Iteration: 227 | Classification loss: 0.13116 | Regression loss: 0.54150 | Running loss: 0.64563\n",
      "Epoch: 5 | Iteration: 228 | Classification loss: 0.12987 | Regression loss: 0.34031 | Running loss: 0.64548\n",
      "Epoch: 5 | Iteration: 229 | Classification loss: 0.08209 | Regression loss: 0.32112 | Running loss: 0.64435\n",
      "Epoch: 5 | Iteration: 230 | Classification loss: 0.07088 | Regression loss: 0.20470 | Running loss: 0.64375\n",
      "Epoch: 5 | Iteration: 231 | Classification loss: 0.29479 | Regression loss: 0.47101 | Running loss: 0.64374\n",
      "Epoch: 5 | Iteration: 232 | Classification loss: 0.40289 | Regression loss: 0.36337 | Running loss: 0.64423\n",
      "Epoch: 5 | Iteration: 233 | Classification loss: 0.12019 | Regression loss: 0.19645 | Running loss: 0.64376\n",
      "Epoch: 5 | Iteration: 234 | Classification loss: 0.37712 | Regression loss: 0.29807 | Running loss: 0.64432\n",
      "Epoch: 5 | Iteration: 235 | Classification loss: 0.17005 | Regression loss: 0.41048 | Running loss: 0.64408\n",
      "Epoch: 5 | Iteration: 236 | Classification loss: 0.21746 | Regression loss: 0.41582 | Running loss: 0.64475\n",
      "Epoch: 5 | Iteration: 237 | Classification loss: 0.20433 | Regression loss: 0.30693 | Running loss: 0.64487\n",
      "Epoch: 5 | Iteration: 238 | Classification loss: 0.36842 | Regression loss: 0.74569 | Running loss: 0.64589\n",
      "Epoch: 5 | Iteration: 239 | Classification loss: 0.18243 | Regression loss: 0.39194 | Running loss: 0.64578\n",
      "Epoch: 5 | Iteration: 240 | Classification loss: 0.14316 | Regression loss: 0.35779 | Running loss: 0.64564\n",
      "Epoch: 5 | Iteration: 241 | Classification loss: 0.32337 | Regression loss: 0.28501 | Running loss: 0.64585\n",
      "Epoch: 5 | Iteration: 242 | Classification loss: 0.18606 | Regression loss: 0.39127 | Running loss: 0.64601\n",
      "Epoch: 5 | Iteration: 243 | Classification loss: 0.39436 | Regression loss: 0.46976 | Running loss: 0.64630\n",
      "Epoch: 5 | Iteration: 244 | Classification loss: 0.22800 | Regression loss: 0.37286 | Running loss: 0.64622\n",
      "Epoch: 5 | Iteration: 245 | Classification loss: 0.25308 | Regression loss: 0.40995 | Running loss: 0.64640\n",
      "Epoch: 5 | Iteration: 246 | Classification loss: 0.16967 | Regression loss: 0.31783 | Running loss: 0.64619\n",
      "Epoch: 5 | Iteration: 247 | Classification loss: 0.16969 | Regression loss: 0.29877 | Running loss: 0.64459\n",
      "Epoch: 5 | Iteration: 248 | Classification loss: 0.48110 | Regression loss: 0.60539 | Running loss: 0.64558\n",
      "Epoch: 5 | Iteration: 249 | Classification loss: 0.26615 | Regression loss: 0.39057 | Running loss: 0.64541\n",
      "Epoch: 5 | Iteration: 250 | Classification loss: 0.13407 | Regression loss: 0.21792 | Running loss: 0.64543\n",
      "Epoch: 5 | Iteration: 251 | Classification loss: 0.42224 | Regression loss: 0.33635 | Running loss: 0.64629\n",
      "Epoch: 5 | Iteration: 252 | Classification loss: 0.30438 | Regression loss: 0.25394 | Running loss: 0.64567\n",
      "Epoch: 5 | Iteration: 253 | Classification loss: 0.18146 | Regression loss: 0.31631 | Running loss: 0.64548\n",
      "Epoch: 5 | Iteration: 254 | Classification loss: 0.15799 | Regression loss: 0.43277 | Running loss: 0.64440\n",
      "Epoch: 5 | Iteration: 255 | Classification loss: 0.43489 | Regression loss: 0.48597 | Running loss: 0.64399\n",
      "Epoch: 5 | Iteration: 256 | Classification loss: 0.13712 | Regression loss: 0.23078 | Running loss: 0.64370\n",
      "Epoch: 5 | Iteration: 257 | Classification loss: 0.13507 | Regression loss: 0.27475 | Running loss: 0.64333\n",
      "Epoch: 5 | Iteration: 258 | Classification loss: 0.60554 | Regression loss: 0.25391 | Running loss: 0.64376\n",
      "Epoch: 5 | Iteration: 259 | Classification loss: 0.40393 | Regression loss: 0.48405 | Running loss: 0.64446\n",
      "Epoch: 5 | Iteration: 260 | Classification loss: 0.26039 | Regression loss: 0.14075 | Running loss: 0.64400\n",
      "Epoch: 5 | Iteration: 261 | Classification loss: 0.30544 | Regression loss: 0.39239 | Running loss: 0.64460\n",
      "Epoch: 5 | Iteration: 262 | Classification loss: 0.15609 | Regression loss: 0.20542 | Running loss: 0.64379\n",
      "Epoch: 5 | Iteration: 263 | Classification loss: 0.33885 | Regression loss: 0.29095 | Running loss: 0.64314\n",
      "Epoch: 5 | Iteration: 264 | Classification loss: 0.24513 | Regression loss: 0.57953 | Running loss: 0.64342\n",
      "Epoch: 5 | Iteration: 265 | Classification loss: 0.21418 | Regression loss: 0.26130 | Running loss: 0.64263\n",
      "Epoch: 5 | Iteration: 266 | Classification loss: 0.20618 | Regression loss: 0.33072 | Running loss: 0.64271\n",
      "Epoch: 5 | Iteration: 267 | Classification loss: 0.14510 | Regression loss: 0.28793 | Running loss: 0.64087\n",
      "Epoch: 5 | Iteration: 268 | Classification loss: 0.09401 | Regression loss: 0.22733 | Running loss: 0.64045\n",
      "Epoch: 5 | Iteration: 269 | Classification loss: 0.13358 | Regression loss: 0.21051 | Running loss: 0.63990\n",
      "Epoch: 5 | Iteration: 270 | Classification loss: 0.42626 | Regression loss: 0.35771 | Running loss: 0.64057\n",
      "Epoch: 5 | Iteration: 271 | Classification loss: 0.33652 | Regression loss: 0.20506 | Running loss: 0.64066\n",
      "Epoch: 5 | Iteration: 272 | Classification loss: 0.17663 | Regression loss: 0.21098 | Running loss: 0.63999\n",
      "Epoch: 5 | Iteration: 273 | Classification loss: 0.40369 | Regression loss: 0.48880 | Running loss: 0.64044\n",
      "Epoch: 5 | Iteration: 274 | Classification loss: 0.21206 | Regression loss: 0.31335 | Running loss: 0.63923\n",
      "Epoch: 5 | Iteration: 275 | Classification loss: 0.21365 | Regression loss: 0.29042 | Running loss: 0.63893\n",
      "Epoch: 5 | Iteration: 276 | Classification loss: 0.18043 | Regression loss: 0.25346 | Running loss: 0.63800\n",
      "Epoch: 5 | Iteration: 277 | Classification loss: 0.12208 | Regression loss: 0.28140 | Running loss: 0.63790\n",
      "Epoch: 5 | Iteration: 278 | Classification loss: 0.26810 | Regression loss: 0.32599 | Running loss: 0.63844\n",
      "Epoch: 5 | Iteration: 279 | Classification loss: 0.12338 | Regression loss: 0.28345 | Running loss: 0.63771\n",
      "Epoch: 5 | Iteration: 280 | Classification loss: 0.40579 | Regression loss: 0.61598 | Running loss: 0.63890\n",
      "Epoch: 5 | Iteration: 281 | Classification loss: 0.42635 | Regression loss: 0.61102 | Running loss: 0.63980\n",
      "Epoch: 5 | Iteration: 282 | Classification loss: 0.14315 | Regression loss: 0.41797 | Running loss: 0.64019\n",
      "Epoch: 5 | Iteration: 283 | Classification loss: 0.30695 | Regression loss: 0.35706 | Running loss: 0.64062\n",
      "Epoch: 5 | Iteration: 284 | Classification loss: 0.44772 | Regression loss: 0.14200 | Running loss: 0.64026\n",
      "Epoch: 5 | Iteration: 285 | Classification loss: 0.23121 | Regression loss: 0.18878 | Running loss: 0.64004\n",
      "Epoch: 5 | Iteration: 286 | Classification loss: 0.17186 | Regression loss: 0.31470 | Running loss: 0.63991\n",
      "Epoch: 5 | Iteration: 287 | Classification loss: 0.11888 | Regression loss: 0.30963 | Running loss: 0.63939\n",
      "Epoch: 5 | Iteration: 288 | Classification loss: 0.13940 | Regression loss: 0.20848 | Running loss: 0.63852\n",
      "Epoch: 5 | Iteration: 289 | Classification loss: 0.17690 | Regression loss: 0.15170 | Running loss: 0.63759\n",
      "Epoch: 5 | Iteration: 290 | Classification loss: 0.20847 | Regression loss: 0.46525 | Running loss: 0.63691\n",
      "Epoch: 5 | Iteration: 291 | Classification loss: 0.35207 | Regression loss: 0.23212 | Running loss: 0.63695\n",
      "Epoch: 5 | Iteration: 292 | Classification loss: 0.07348 | Regression loss: 0.13816 | Running loss: 0.63550\n",
      "Epoch: 5 | Iteration: 293 | Classification loss: 0.33578 | Regression loss: 0.14204 | Running loss: 0.63489\n",
      "Epoch: 5 | Iteration: 294 | Classification loss: 0.13707 | Regression loss: 0.35855 | Running loss: 0.63476\n",
      "Epoch: 5 | Iteration: 295 | Classification loss: 0.45735 | Regression loss: 0.54565 | Running loss: 0.63587\n",
      "Epoch: 5 | Iteration: 296 | Classification loss: 0.23906 | Regression loss: 0.28811 | Running loss: 0.63581\n",
      "Epoch: 5 | Iteration: 297 | Classification loss: 0.32041 | Regression loss: 0.51497 | Running loss: 0.63700\n",
      "Epoch: 5 | Iteration: 298 | Classification loss: 0.24378 | Regression loss: 0.25073 | Running loss: 0.63694\n",
      "Epoch: 5 | Iteration: 299 | Classification loss: 0.24509 | Regression loss: 0.36251 | Running loss: 0.63639\n",
      "Epoch: 5 | Iteration: 300 | Classification loss: 0.15376 | Regression loss: 0.36513 | Running loss: 0.63617\n",
      "Epoch: 5 | Iteration: 301 | Classification loss: 0.44301 | Regression loss: 0.82482 | Running loss: 0.63761\n",
      "Epoch: 5 | Iteration: 302 | Classification loss: 0.29606 | Regression loss: 0.43294 | Running loss: 0.63817\n",
      "Epoch: 5 | Iteration: 303 | Classification loss: 0.20140 | Regression loss: 0.27220 | Running loss: 0.63773\n",
      "Epoch: 5 | Iteration: 304 | Classification loss: 0.54609 | Regression loss: 0.30989 | Running loss: 0.63813\n",
      "Epoch: 5 | Iteration: 305 | Classification loss: 0.28854 | Regression loss: 0.28147 | Running loss: 0.63786\n",
      "Epoch: 5 | Iteration: 306 | Classification loss: 0.25634 | Regression loss: 0.48242 | Running loss: 0.63790\n",
      "Epoch: 5 | Iteration: 307 | Classification loss: 0.14368 | Regression loss: 0.27586 | Running loss: 0.63792\n",
      "Epoch: 5 | Iteration: 308 | Classification loss: 0.17044 | Regression loss: 0.34157 | Running loss: 0.63718\n",
      "Epoch: 5 | Iteration: 309 | Classification loss: 0.19457 | Regression loss: 0.28970 | Running loss: 0.63604\n",
      "Epoch: 5 | Iteration: 310 | Classification loss: 0.21902 | Regression loss: 0.29392 | Running loss: 0.63589\n",
      "Epoch: 5 | Iteration: 311 | Classification loss: 0.34767 | Regression loss: 0.55578 | Running loss: 0.63605\n",
      "Epoch: 5 | Iteration: 312 | Classification loss: 0.19360 | Regression loss: 0.16588 | Running loss: 0.63518\n",
      "Epoch: 5 | Iteration: 313 | Classification loss: 0.09828 | Regression loss: 0.14040 | Running loss: 0.63463\n",
      "Epoch: 5 | Iteration: 314 | Classification loss: 0.18266 | Regression loss: 0.43542 | Running loss: 0.63422\n",
      "Epoch: 5 | Iteration: 315 | Classification loss: 0.21987 | Regression loss: 0.37666 | Running loss: 0.63385\n",
      "Epoch: 5 | Iteration: 316 | Classification loss: 0.11003 | Regression loss: 0.22557 | Running loss: 0.63328\n",
      "Epoch: 5 | Iteration: 317 | Classification loss: 0.53178 | Regression loss: 0.43157 | Running loss: 0.63402\n",
      "Epoch: 5 | Iteration: 318 | Classification loss: 0.20824 | Regression loss: 0.33838 | Running loss: 0.63363\n",
      "Epoch: 5 | Iteration: 319 | Classification loss: 0.14904 | Regression loss: 0.28290 | Running loss: 0.63368\n",
      "Epoch: 5 | Iteration: 320 | Classification loss: 0.30946 | Regression loss: 0.24708 | Running loss: 0.63314\n",
      "Epoch: 5 | Iteration: 321 | Classification loss: 0.21424 | Regression loss: 0.22788 | Running loss: 0.63307\n",
      "Epoch: 5 | Iteration: 322 | Classification loss: 0.27793 | Regression loss: 0.18186 | Running loss: 0.63312\n",
      "Epoch: 5 | Iteration: 323 | Classification loss: 0.07978 | Regression loss: 0.27747 | Running loss: 0.63268\n",
      "Epoch: 5 | Iteration: 324 | Classification loss: 0.18283 | Regression loss: 0.26739 | Running loss: 0.63146\n",
      "Epoch: 5 | Iteration: 325 | Classification loss: 0.25505 | Regression loss: 0.27194 | Running loss: 0.63162\n",
      "Epoch: 5 | Iteration: 326 | Classification loss: 0.29423 | Regression loss: 0.53614 | Running loss: 0.63162\n",
      "Epoch: 5 | Iteration: 327 | Classification loss: 0.51177 | Regression loss: 0.31548 | Running loss: 0.63136\n",
      "Epoch: 5 | Iteration: 328 | Classification loss: 0.38247 | Regression loss: 0.57896 | Running loss: 0.63221\n",
      "Epoch: 5 | Iteration: 329 | Classification loss: 0.26654 | Regression loss: 0.36826 | Running loss: 0.63253\n",
      "Epoch: 5 | Iteration: 330 | Classification loss: 0.16798 | Regression loss: 0.22878 | Running loss: 0.63225\n",
      "Epoch: 5 | Iteration: 331 | Classification loss: 0.07651 | Regression loss: 0.20287 | Running loss: 0.63200\n",
      "Epoch: 5 | Iteration: 332 | Classification loss: 0.17132 | Regression loss: 0.41266 | Running loss: 0.63083\n",
      "Epoch: 5 | Iteration: 333 | Classification loss: 0.14137 | Regression loss: 0.51073 | Running loss: 0.63089\n",
      "Epoch: 5 | Iteration: 334 | Classification loss: 0.18106 | Regression loss: 0.53971 | Running loss: 0.63118\n",
      "Epoch: 5 | Iteration: 335 | Classification loss: 0.42594 | Regression loss: 0.29833 | Running loss: 0.63036\n",
      "Epoch: 5 | Iteration: 336 | Classification loss: 0.20451 | Regression loss: 0.47923 | Running loss: 0.63033\n",
      "Epoch: 5 | Iteration: 337 | Classification loss: 0.12925 | Regression loss: 0.34351 | Running loss: 0.62962\n",
      "Epoch: 5 | Iteration: 338 | Classification loss: 0.24295 | Regression loss: 0.28556 | Running loss: 0.62937\n",
      "Epoch: 5 | Iteration: 339 | Classification loss: 0.17869 | Regression loss: 0.12703 | Running loss: 0.62835\n",
      "Epoch: 5 | Iteration: 340 | Classification loss: 0.25634 | Regression loss: 0.34161 | Running loss: 0.62822\n",
      "Epoch: 5 | Iteration: 341 | Classification loss: 0.14018 | Regression loss: 0.33977 | Running loss: 0.62806\n",
      "Epoch: 5 | Iteration: 342 | Classification loss: 0.26558 | Regression loss: 0.29633 | Running loss: 0.62770\n",
      "Epoch: 5 | Iteration: 343 | Classification loss: 0.54123 | Regression loss: 0.59550 | Running loss: 0.62894\n",
      "Epoch: 5 | Iteration: 344 | Classification loss: 0.15279 | Regression loss: 0.21947 | Running loss: 0.62874\n",
      "Epoch: 5 | Iteration: 345 | Classification loss: 0.27902 | Regression loss: 0.29129 | Running loss: 0.62823\n",
      "Epoch: 5 | Iteration: 346 | Classification loss: 0.28614 | Regression loss: 0.34824 | Running loss: 0.62751\n",
      "Epoch: 5 | Iteration: 347 | Classification loss: 0.32395 | Regression loss: 0.38623 | Running loss: 0.62819\n",
      "Epoch: 5 | Iteration: 348 | Classification loss: 0.13004 | Regression loss: 0.34679 | Running loss: 0.62772\n",
      "Epoch: 5 | Iteration: 349 | Classification loss: 0.27307 | Regression loss: 0.30680 | Running loss: 0.62726\n",
      "Epoch: 5 | Iteration: 350 | Classification loss: 0.14725 | Regression loss: 0.31436 | Running loss: 0.62619\n",
      "Epoch: 5 | Iteration: 351 | Classification loss: 0.19109 | Regression loss: 0.22024 | Running loss: 0.62581\n",
      "Epoch: 5 | Iteration: 352 | Classification loss: 0.45142 | Regression loss: 0.47559 | Running loss: 0.62645\n",
      "Epoch: 5 | Iteration: 353 | Classification loss: 0.52517 | Regression loss: 0.79120 | Running loss: 0.62762\n",
      "Epoch: 5 | Iteration: 354 | Classification loss: 0.14956 | Regression loss: 0.32541 | Running loss: 0.62733\n",
      "Epoch: 5 | Iteration: 355 | Classification loss: 0.21788 | Regression loss: 0.38655 | Running loss: 0.62716\n",
      "Epoch: 5 | Iteration: 356 | Classification loss: 0.11522 | Regression loss: 0.19638 | Running loss: 0.62613\n",
      "Epoch: 5 | Iteration: 357 | Classification loss: 0.14261 | Regression loss: 0.34337 | Running loss: 0.62544\n",
      "Epoch: 5 | Iteration: 358 | Classification loss: 0.09119 | Regression loss: 0.30400 | Running loss: 0.62512\n",
      "Epoch: 5 | Iteration: 359 | Classification loss: 0.18630 | Regression loss: 0.22666 | Running loss: 0.62491\n",
      "Epoch: 5 | Iteration: 360 | Classification loss: 0.19265 | Regression loss: 0.27744 | Running loss: 0.62430\n",
      "Epoch: 5 | Iteration: 361 | Classification loss: 0.32921 | Regression loss: 0.54863 | Running loss: 0.62526\n",
      "Epoch: 5 | Iteration: 362 | Classification loss: 0.10976 | Regression loss: 0.27686 | Running loss: 0.62455\n",
      "Epoch: 5 | Iteration: 363 | Classification loss: 0.23488 | Regression loss: 0.29814 | Running loss: 0.62419\n",
      "Epoch: 5 | Iteration: 364 | Classification loss: 0.22369 | Regression loss: 0.36477 | Running loss: 0.62419\n",
      "Epoch: 5 | Iteration: 365 | Classification loss: 0.15031 | Regression loss: 0.28125 | Running loss: 0.62311\n",
      "Epoch: 5 | Iteration: 366 | Classification loss: 0.19276 | Regression loss: 0.27258 | Running loss: 0.62235\n",
      "Epoch: 5 | Iteration: 367 | Classification loss: 0.25439 | Regression loss: 0.20544 | Running loss: 0.62175\n",
      "Epoch: 5 | Iteration: 368 | Classification loss: 0.21052 | Regression loss: 0.47832 | Running loss: 0.62178\n",
      "Epoch: 5 | Iteration: 369 | Classification loss: 0.29107 | Regression loss: 0.48547 | Running loss: 0.62204\n",
      "Epoch: 5 | Iteration: 370 | Classification loss: 0.28244 | Regression loss: 0.55485 | Running loss: 0.62237\n",
      "Epoch: 5 | Iteration: 371 | Classification loss: 0.27744 | Regression loss: 0.39705 | Running loss: 0.62166\n",
      "Epoch: 5 | Iteration: 372 | Classification loss: 0.51387 | Regression loss: 0.25427 | Running loss: 0.62128\n",
      "Epoch: 5 | Iteration: 373 | Classification loss: 0.11592 | Regression loss: 0.19280 | Running loss: 0.62037\n",
      "Epoch: 5 | Iteration: 374 | Classification loss: 0.42902 | Regression loss: 0.31212 | Running loss: 0.62038\n",
      "Epoch: 5 | Iteration: 375 | Classification loss: 0.16690 | Regression loss: 0.42413 | Running loss: 0.62050\n",
      "Epoch: 5 | Iteration: 376 | Classification loss: 0.26026 | Regression loss: 0.35937 | Running loss: 0.62097\n",
      "Epoch: 5 | Iteration: 377 | Classification loss: 0.26099 | Regression loss: 0.23764 | Running loss: 0.61992\n",
      "Epoch: 5 | Iteration: 378 | Classification loss: 0.25379 | Regression loss: 0.40316 | Running loss: 0.62015\n",
      "Epoch: 5 | Iteration: 379 | Classification loss: 0.15591 | Regression loss: 0.26501 | Running loss: 0.62004\n",
      "Epoch: 5 | Iteration: 380 | Classification loss: 0.06174 | Regression loss: 0.17721 | Running loss: 0.61926\n",
      "Epoch: 5 | Iteration: 381 | Classification loss: 0.08412 | Regression loss: 0.28488 | Running loss: 0.61858\n",
      "Epoch: 5 | Iteration: 382 | Classification loss: 0.22332 | Regression loss: 0.32017 | Running loss: 0.61785\n",
      "Epoch: 5 | Iteration: 383 | Classification loss: 0.21336 | Regression loss: 0.25384 | Running loss: 0.61718\n",
      "Epoch: 5 | Iteration: 384 | Classification loss: 0.19724 | Regression loss: 0.46534 | Running loss: 0.61744\n",
      "Epoch: 5 | Iteration: 385 | Classification loss: 0.27598 | Regression loss: 0.19858 | Running loss: 0.61693\n",
      "Epoch: 5 | Iteration: 386 | Classification loss: 0.22270 | Regression loss: 0.25390 | Running loss: 0.61592\n",
      "Epoch: 5 | Iteration: 387 | Classification loss: 0.20019 | Regression loss: 0.22328 | Running loss: 0.61506\n",
      "Epoch: 5 | Iteration: 388 | Classification loss: 0.14919 | Regression loss: 0.23815 | Running loss: 0.61509\n",
      "Epoch: 5 | Iteration: 389 | Classification loss: 0.20759 | Regression loss: 0.29472 | Running loss: 0.61493\n",
      "Epoch: 5 | Iteration: 390 | Classification loss: 0.39793 | Regression loss: 0.22167 | Running loss: 0.61375\n",
      "Epoch: 5 | Iteration: 391 | Classification loss: 0.38166 | Regression loss: 0.73202 | Running loss: 0.61519\n",
      "Epoch: 5 | Iteration: 392 | Classification loss: 0.12099 | Regression loss: 0.45611 | Running loss: 0.61558\n",
      "Epoch: 5 | Iteration: 393 | Classification loss: 0.19152 | Regression loss: 0.40936 | Running loss: 0.61583\n",
      "Epoch: 5 | Iteration: 394 | Classification loss: 0.18797 | Regression loss: 0.16719 | Running loss: 0.61487\n",
      "Epoch: 5 | Iteration: 395 | Classification loss: 0.20404 | Regression loss: 0.27905 | Running loss: 0.61456\n",
      "Epoch: 5 | Iteration: 396 | Classification loss: 0.28370 | Regression loss: 0.15743 | Running loss: 0.61430\n",
      "Epoch: 5 | Iteration: 397 | Classification loss: 0.09123 | Regression loss: 0.22500 | Running loss: 0.61369\n",
      "Epoch: 5 | Iteration: 398 | Classification loss: 0.25913 | Regression loss: 0.39974 | Running loss: 0.61358\n",
      "Epoch: 5 | Iteration: 399 | Classification loss: 0.31044 | Regression loss: 0.43200 | Running loss: 0.61427\n",
      "Epoch: 5 | Iteration: 400 | Classification loss: 0.39800 | Regression loss: 0.43360 | Running loss: 0.61481\n",
      "Epoch: 5 | Iteration: 401 | Classification loss: 0.15406 | Regression loss: 0.45709 | Running loss: 0.61416\n",
      "Epoch: 5 | Iteration: 402 | Classification loss: 0.33015 | Regression loss: 0.33168 | Running loss: 0.61339\n",
      "Epoch: 5 | Iteration: 403 | Classification loss: 0.10248 | Regression loss: 0.39759 | Running loss: 0.61318\n",
      "Epoch: 5 | Iteration: 404 | Classification loss: 0.06297 | Regression loss: 0.16432 | Running loss: 0.61275\n",
      "Epoch: 5 | Iteration: 405 | Classification loss: 0.16068 | Regression loss: 0.21506 | Running loss: 0.61290\n",
      "Epoch: 5 | Iteration: 406 | Classification loss: 0.21214 | Regression loss: 0.21023 | Running loss: 0.61233\n",
      "Epoch: 5 | Iteration: 407 | Classification loss: 0.12541 | Regression loss: 0.08165 | Running loss: 0.61130\n",
      "Epoch: 5 | Iteration: 408 | Classification loss: 0.27521 | Regression loss: 0.52202 | Running loss: 0.61102\n",
      "Epoch: 5 | Iteration: 409 | Classification loss: 0.34895 | Regression loss: 0.30531 | Running loss: 0.61134\n",
      "Epoch: 5 | Iteration: 410 | Classification loss: 0.17818 | Regression loss: 0.31691 | Running loss: 0.61115\n",
      "Epoch: 5 | Iteration: 411 | Classification loss: 0.49640 | Regression loss: 0.17491 | Running loss: 0.61106\n",
      "Epoch: 5 | Iteration: 412 | Classification loss: 0.23979 | Regression loss: 0.16798 | Running loss: 0.61107\n",
      "Epoch: 5 | Iteration: 413 | Classification loss: 0.41705 | Regression loss: 0.51409 | Running loss: 0.60988\n",
      "Epoch: 5 | Iteration: 414 | Classification loss: 0.31876 | Regression loss: 0.46361 | Running loss: 0.61014\n",
      "Epoch: 5 | Iteration: 415 | Classification loss: 0.11901 | Regression loss: 0.30045 | Running loss: 0.61015\n",
      "Epoch: 5 | Iteration: 416 | Classification loss: 0.36282 | Regression loss: 0.32578 | Running loss: 0.61048\n",
      "Epoch: 5 | Iteration: 417 | Classification loss: 0.08532 | Regression loss: 0.13832 | Running loss: 0.61043\n",
      "Epoch: 5 | Iteration: 418 | Classification loss: 0.05208 | Regression loss: 0.17404 | Running loss: 0.60973\n",
      "Epoch: 5 | Iteration: 419 | Classification loss: 0.46689 | Regression loss: 0.40368 | Running loss: 0.61060\n",
      "Epoch: 5 | Iteration: 420 | Classification loss: 0.08072 | Regression loss: 0.34420 | Running loss: 0.61039\n",
      "Epoch: 5 | Iteration: 421 | Classification loss: 0.22200 | Regression loss: 0.37984 | Running loss: 0.60981\n",
      "Epoch: 5 | Iteration: 422 | Classification loss: 0.53215 | Regression loss: 0.70389 | Running loss: 0.61100\n",
      "Epoch: 5 | Iteration: 423 | Classification loss: 0.09652 | Regression loss: 0.37761 | Running loss: 0.60925\n",
      "Epoch: 5 | Iteration: 424 | Classification loss: 0.31639 | Regression loss: 0.34549 | Running loss: 0.60916\n",
      "Epoch: 5 | Iteration: 425 | Classification loss: 0.19748 | Regression loss: 0.52557 | Running loss: 0.60966\n",
      "Epoch: 5 | Iteration: 426 | Classification loss: 0.31332 | Regression loss: 0.26254 | Running loss: 0.61016\n",
      "Epoch: 5 | Iteration: 427 | Classification loss: 0.06009 | Regression loss: 0.25851 | Running loss: 0.60961\n",
      "Epoch: 5 | Iteration: 428 | Classification loss: 0.30571 | Regression loss: 0.13697 | Running loss: 0.60942\n",
      "Epoch: 5 | Iteration: 429 | Classification loss: 0.35465 | Regression loss: 0.43909 | Running loss: 0.60980\n",
      "Epoch: 5 | Iteration: 430 | Classification loss: 0.16572 | Regression loss: 0.23875 | Running loss: 0.60965\n",
      "Epoch: 5 | Iteration: 431 | Classification loss: 0.20163 | Regression loss: 0.29832 | Running loss: 0.60915\n",
      "Epoch: 5 | Iteration: 432 | Classification loss: 0.12197 | Regression loss: 0.34697 | Running loss: 0.60771\n",
      "Epoch: 5 | Iteration: 433 | Classification loss: 0.08184 | Regression loss: 0.25715 | Running loss: 0.60726\n",
      "Epoch: 5 | Iteration: 434 | Classification loss: 0.38700 | Regression loss: 0.22142 | Running loss: 0.60755\n",
      "Epoch: 5 | Iteration: 435 | Classification loss: 0.24292 | Regression loss: 0.47435 | Running loss: 0.60708\n",
      "Epoch: 5 | Iteration: 436 | Classification loss: 0.32214 | Regression loss: 0.30204 | Running loss: 0.60575\n",
      "Epoch: 5 | Iteration: 437 | Classification loss: 0.35654 | Regression loss: 0.47362 | Running loss: 0.60682\n",
      "Epoch: 5 | Iteration: 438 | Classification loss: 0.26335 | Regression loss: 0.18370 | Running loss: 0.60525\n",
      "Epoch: 5 | Iteration: 439 | Classification loss: 0.41061 | Regression loss: 0.28546 | Running loss: 0.60515\n",
      "Epoch: 5 | Iteration: 440 | Classification loss: 0.37186 | Regression loss: 0.45778 | Running loss: 0.60625\n",
      "Epoch: 5 | Iteration: 441 | Classification loss: 0.07497 | Regression loss: 0.26254 | Running loss: 0.60579\n",
      "Epoch: 5 | Iteration: 442 | Classification loss: 0.28280 | Regression loss: 0.54901 | Running loss: 0.60575\n",
      "Epoch: 5 | Iteration: 443 | Classification loss: 0.27068 | Regression loss: 0.46880 | Running loss: 0.60511\n",
      "Epoch: 5 | Iteration: 444 | Classification loss: 0.27906 | Regression loss: 0.51184 | Running loss: 0.60522\n",
      "Epoch: 5 | Iteration: 445 | Classification loss: 0.29607 | Regression loss: 0.40074 | Running loss: 0.60494\n",
      "Epoch: 5 | Iteration: 446 | Classification loss: 0.33913 | Regression loss: 0.47168 | Running loss: 0.60551\n",
      "Epoch: 5 | Iteration: 447 | Classification loss: 0.32273 | Regression loss: 0.32809 | Running loss: 0.60590\n",
      "Epoch: 5 | Iteration: 448 | Classification loss: 0.13332 | Regression loss: 0.16931 | Running loss: 0.60508\n",
      "Epoch: 5 | Iteration: 449 | Classification loss: 0.35315 | Regression loss: 0.38584 | Running loss: 0.60498\n",
      "Epoch: 5 | Iteration: 450 | Classification loss: 0.39843 | Regression loss: 0.32302 | Running loss: 0.60486\n",
      "Epoch: 5 | Iteration: 451 | Classification loss: 0.08855 | Regression loss: 0.25649 | Running loss: 0.60413\n",
      "Epoch: 5 | Iteration: 452 | Classification loss: 0.32827 | Regression loss: 0.48452 | Running loss: 0.60448\n",
      "Epoch: 5 | Iteration: 453 | Classification loss: 0.37086 | Regression loss: 0.72880 | Running loss: 0.60503\n",
      "Epoch: 5 | Iteration: 454 | Classification loss: 0.22355 | Regression loss: 0.41628 | Running loss: 0.60437\n",
      "Epoch: 5 | Iteration: 455 | Classification loss: 0.08485 | Regression loss: 0.18041 | Running loss: 0.60356\n",
      "Epoch: 5 | Iteration: 456 | Classification loss: 0.39977 | Regression loss: 0.33984 | Running loss: 0.60448\n",
      "Epoch: 5 | Iteration: 457 | Classification loss: 0.12825 | Regression loss: 0.27818 | Running loss: 0.60292\n",
      "Epoch: 5 | Iteration: 458 | Classification loss: 0.29730 | Regression loss: 0.34276 | Running loss: 0.60304\n",
      "Epoch: 5 | Iteration: 459 | Classification loss: 0.21617 | Regression loss: 0.19523 | Running loss: 0.60314\n",
      "Epoch: 5 | Iteration: 460 | Classification loss: 0.34355 | Regression loss: 0.30234 | Running loss: 0.60364\n",
      "Epoch: 5 | Iteration: 461 | Classification loss: 0.19878 | Regression loss: 0.38296 | Running loss: 0.60393\n",
      "Epoch: 5 | Iteration: 462 | Classification loss: 0.18748 | Regression loss: 0.23486 | Running loss: 0.60379\n",
      "Epoch: 5 | Iteration: 463 | Classification loss: 0.22970 | Regression loss: 0.39114 | Running loss: 0.60391\n",
      "Epoch: 5 | Iteration: 464 | Classification loss: 0.18432 | Regression loss: 0.14604 | Running loss: 0.60297\n",
      "Epoch: 5 | Iteration: 465 | Classification loss: 0.15826 | Regression loss: 0.28721 | Running loss: 0.60300\n",
      "Epoch: 5 | Iteration: 466 | Classification loss: 0.23136 | Regression loss: 0.44214 | Running loss: 0.60324\n",
      "Epoch: 5 | Iteration: 467 | Classification loss: 0.35517 | Regression loss: 0.34610 | Running loss: 0.60266\n",
      "Epoch: 5 | Iteration: 468 | Classification loss: 0.16435 | Regression loss: 0.21319 | Running loss: 0.60200\n",
      "Epoch: 5 | Iteration: 469 | Classification loss: 0.13191 | Regression loss: 0.29091 | Running loss: 0.60081\n",
      "Epoch: 5 | Iteration: 470 | Classification loss: 0.22134 | Regression loss: 0.13434 | Running loss: 0.60041\n",
      "Epoch: 5 | Iteration: 471 | Classification loss: 0.20836 | Regression loss: 0.30917 | Running loss: 0.60019\n",
      "Epoch: 5 | Iteration: 472 | Classification loss: 0.32657 | Regression loss: 0.70238 | Running loss: 0.60127\n",
      "Epoch: 5 | Iteration: 473 | Classification loss: 0.18103 | Regression loss: 0.32548 | Running loss: 0.60059\n",
      "Epoch: 5 | Iteration: 474 | Classification loss: 0.14112 | Regression loss: 0.21317 | Running loss: 0.60013\n",
      "Epoch: 5 | Iteration: 475 | Classification loss: 0.10891 | Regression loss: 0.32904 | Running loss: 0.59864\n",
      "Epoch: 5 | Iteration: 476 | Classification loss: 0.49305 | Regression loss: 0.50440 | Running loss: 0.59940\n",
      "Epoch: 5 | Iteration: 477 | Classification loss: 0.52033 | Regression loss: 0.62155 | Running loss: 0.60061\n",
      "Epoch: 5 | Iteration: 478 | Classification loss: 0.41352 | Regression loss: 0.38637 | Running loss: 0.60146\n",
      "Epoch: 5 | Iteration: 479 | Classification loss: 0.11670 | Regression loss: 0.37868 | Running loss: 0.60148\n",
      "Epoch: 5 | Iteration: 480 | Classification loss: 0.20296 | Regression loss: 0.28545 | Running loss: 0.60086\n",
      "Epoch: 5 | Iteration: 481 | Classification loss: 0.28304 | Regression loss: 0.13316 | Running loss: 0.60095\n",
      "Epoch: 5 | Iteration: 482 | Classification loss: 0.13992 | Regression loss: 0.37921 | Running loss: 0.60053\n",
      "Epoch: 5 | Iteration: 483 | Classification loss: 0.16727 | Regression loss: 0.28204 | Running loss: 0.59953\n",
      "Epoch: 5 | Iteration: 484 | Classification loss: 0.05241 | Regression loss: 0.26716 | Running loss: 0.59913\n",
      "Epoch: 5 | Iteration: 485 | Classification loss: 0.50744 | Regression loss: 0.55204 | Running loss: 0.60002\n",
      "Epoch: 5 | Iteration: 486 | Classification loss: 0.14198 | Regression loss: 0.18775 | Running loss: 0.59832\n",
      "Epoch: 5 | Iteration: 487 | Classification loss: 0.60013 | Regression loss: 0.59236 | Running loss: 0.59942\n",
      "Epoch: 5 | Iteration: 488 | Classification loss: 0.11802 | Regression loss: 0.48021 | Running loss: 0.59995\n",
      "Epoch: 5 | Iteration: 489 | Classification loss: 0.50743 | Regression loss: 0.45994 | Running loss: 0.60071\n",
      "Epoch: 5 | Iteration: 490 | Classification loss: 0.14886 | Regression loss: 0.28970 | Running loss: 0.60040\n",
      "Epoch: 5 | Iteration: 491 | Classification loss: 0.19202 | Regression loss: 0.33133 | Running loss: 0.59914\n",
      "Epoch: 5 | Iteration: 492 | Classification loss: 0.32447 | Regression loss: 0.40174 | Running loss: 0.60057\n",
      "Epoch: 5 | Iteration: 493 | Classification loss: 0.37737 | Regression loss: 0.36192 | Running loss: 0.60053\n",
      "Epoch: 5 | Iteration: 494 | Classification loss: 0.07024 | Regression loss: 0.29485 | Running loss: 0.59933\n",
      "Epoch: 5 | Iteration: 495 | Classification loss: 0.18165 | Regression loss: 0.34071 | Running loss: 0.59859\n",
      "Epoch: 5 | Iteration: 496 | Classification loss: 0.16665 | Regression loss: 0.26819 | Running loss: 0.59782\n",
      "Epoch: 5 | Iteration: 497 | Classification loss: 0.43443 | Regression loss: 0.52795 | Running loss: 0.59846\n",
      "Epoch: 5 | Iteration: 498 | Classification loss: 0.20485 | Regression loss: 0.33818 | Running loss: 0.59834\n",
      "Epoch: 5 | Iteration: 499 | Classification loss: 0.33145 | Regression loss: 0.23790 | Running loss: 0.59788\n",
      "Epoch: 5 | Iteration: 500 | Classification loss: 0.34741 | Regression loss: 0.35615 | Running loss: 0.59798\n",
      "Epoch: 5 | Iteration: 501 | Classification loss: 0.28143 | Regression loss: 0.40939 | Running loss: 0.59755\n",
      "Epoch: 5 | Iteration: 502 | Classification loss: 0.43335 | Regression loss: 0.30859 | Running loss: 0.59707\n",
      "Epoch: 5 | Iteration: 503 | Classification loss: 0.33257 | Regression loss: 0.47357 | Running loss: 0.59752\n",
      "Epoch: 5 | Iteration: 504 | Classification loss: 0.37244 | Regression loss: 0.53591 | Running loss: 0.59759\n",
      "Epoch: 5 | Iteration: 505 | Classification loss: 0.13178 | Regression loss: 0.31988 | Running loss: 0.59757\n",
      "Epoch: 5 | Iteration: 506 | Classification loss: 0.24165 | Regression loss: 0.26949 | Running loss: 0.59684\n",
      "Epoch: 5 | Iteration: 507 | Classification loss: 0.31932 | Regression loss: 0.21993 | Running loss: 0.59672\n",
      "Epoch: 5 | Iteration: 508 | Classification loss: 0.23064 | Regression loss: 0.82005 | Running loss: 0.59753\n",
      "Epoch: 5 | Iteration: 509 | Classification loss: 0.15690 | Regression loss: 0.33450 | Running loss: 0.59769\n",
      "Epoch: 5 | Iteration: 510 | Classification loss: 0.32897 | Regression loss: 0.33571 | Running loss: 0.59826\n",
      "Epoch: 5 | Iteration: 511 | Classification loss: 0.20545 | Regression loss: 0.26244 | Running loss: 0.59793\n",
      "Epoch: 5 | Iteration: 512 | Classification loss: 0.25304 | Regression loss: 0.31420 | Running loss: 0.59804\n",
      "Epoch: 5 | Iteration: 513 | Classification loss: 0.12830 | Regression loss: 0.29972 | Running loss: 0.59738\n",
      "Epoch: 5 | Iteration: 514 | Classification loss: 0.40148 | Regression loss: 0.29377 | Running loss: 0.59621\n",
      "Epoch: 5 | Iteration: 515 | Classification loss: 0.13485 | Regression loss: 0.38799 | Running loss: 0.59651\n",
      "Epoch: 5 | Iteration: 516 | Classification loss: 0.36810 | Regression loss: 0.34256 | Running loss: 0.59720\n",
      "Epoch: 5 | Iteration: 517 | Classification loss: 0.08596 | Regression loss: 0.21582 | Running loss: 0.59619\n",
      "Epoch: 5 | Iteration: 518 | Classification loss: 0.23015 | Regression loss: 0.61879 | Running loss: 0.59674\n",
      "Epoch: 5 | Iteration: 519 | Classification loss: 0.03995 | Regression loss: 0.16669 | Running loss: 0.59532\n",
      "Epoch: 5 | Iteration: 520 | Classification loss: 0.28657 | Regression loss: 0.16827 | Running loss: 0.59474\n",
      "Epoch: 5 | Iteration: 521 | Classification loss: 0.08707 | Regression loss: 0.28491 | Running loss: 0.59445\n",
      "Epoch: 5 | Iteration: 522 | Classification loss: 0.34670 | Regression loss: 0.36234 | Running loss: 0.59499\n",
      "Epoch: 5 | Iteration: 523 | Classification loss: 0.26615 | Regression loss: 0.32313 | Running loss: 0.59443\n",
      "Epoch: 5 | Iteration: 524 | Classification loss: 0.13495 | Regression loss: 0.21609 | Running loss: 0.59345\n",
      "Epoch: 5 | Iteration: 525 | Classification loss: 0.45314 | Regression loss: 0.70361 | Running loss: 0.59407\n",
      "Epoch: 5 | Iteration: 526 | Classification loss: 0.27085 | Regression loss: 0.26766 | Running loss: 0.59341\n",
      "Epoch: 5 | Iteration: 527 | Classification loss: 0.25098 | Regression loss: 0.39493 | Running loss: 0.59359\n",
      "Epoch: 5 | Iteration: 528 | Classification loss: 0.23050 | Regression loss: 0.26496 | Running loss: 0.59285\n",
      "Epoch: 5 | Iteration: 529 | Classification loss: 0.18497 | Regression loss: 0.46189 | Running loss: 0.59283\n",
      "Epoch: 5 | Iteration: 530 | Classification loss: 0.26702 | Regression loss: 0.24887 | Running loss: 0.59266\n",
      "Epoch: 5 | Iteration: 531 | Classification loss: 0.10222 | Regression loss: 0.31080 | Running loss: 0.59216\n",
      "Epoch: 5 | Iteration: 532 | Classification loss: 0.37341 | Regression loss: 0.27690 | Running loss: 0.59224\n",
      "Epoch: 5 | Iteration: 533 | Classification loss: 0.22058 | Regression loss: 0.27885 | Running loss: 0.59213\n",
      "Epoch: 5 | Iteration: 534 | Classification loss: 0.26973 | Regression loss: 0.27735 | Running loss: 0.59176\n",
      "Epoch: 5 | Iteration: 535 | Classification loss: 0.67910 | Regression loss: 0.46848 | Running loss: 0.59236\n",
      "Epoch: 5 | Iteration: 536 | Classification loss: 0.44485 | Regression loss: 0.29725 | Running loss: 0.59267\n",
      "Epoch: 5 | Iteration: 537 | Classification loss: 0.17895 | Regression loss: 0.25022 | Running loss: 0.59217\n",
      "Epoch: 5 | Iteration: 538 | Classification loss: 0.26247 | Regression loss: 0.51128 | Running loss: 0.59269\n",
      "Epoch: 5 | Iteration: 539 | Classification loss: 0.30875 | Regression loss: 0.45774 | Running loss: 0.59283\n",
      "Epoch: 5 | Iteration: 540 | Classification loss: 0.26940 | Regression loss: 0.76765 | Running loss: 0.59394\n",
      "Epoch: 5 | Iteration: 541 | Classification loss: 0.31573 | Regression loss: 0.55048 | Running loss: 0.59389\n",
      "Epoch: 5 | Iteration: 542 | Classification loss: 0.13649 | Regression loss: 0.43221 | Running loss: 0.59372\n",
      "Epoch: 5 | Iteration: 543 | Classification loss: 0.45671 | Regression loss: 0.34604 | Running loss: 0.59463\n",
      "Epoch: 5 | Iteration: 544 | Classification loss: 0.04978 | Regression loss: 0.26378 | Running loss: 0.59364\n",
      "Epoch: 5 | Iteration: 545 | Classification loss: 0.17384 | Regression loss: 0.36708 | Running loss: 0.59325\n",
      "Epoch: 5 | Iteration: 546 | Classification loss: 0.36151 | Regression loss: 0.44371 | Running loss: 0.59319\n",
      "Epoch: 5 | Iteration: 547 | Classification loss: 0.29474 | Regression loss: 0.12956 | Running loss: 0.59313\n",
      "Epoch: 5 | Iteration: 548 | Classification loss: 0.48813 | Regression loss: 0.47269 | Running loss: 0.59299\n",
      "Epoch: 5 | Iteration: 549 | Classification loss: 0.21171 | Regression loss: 0.27987 | Running loss: 0.59315\n",
      "Epoch: 5 | Iteration: 550 | Classification loss: 0.18047 | Regression loss: 0.29229 | Running loss: 0.59310\n",
      "Epoch: 5 | Iteration: 551 | Classification loss: 0.18202 | Regression loss: 0.30253 | Running loss: 0.59216\n",
      "Epoch: 5 | Iteration: 552 | Classification loss: 0.12198 | Regression loss: 0.18005 | Running loss: 0.59160\n",
      "Epoch: 5 | Iteration: 553 | Classification loss: 0.57600 | Regression loss: 0.50917 | Running loss: 0.59304\n",
      "Epoch: 5 | Iteration: 554 | Classification loss: 0.49173 | Regression loss: 0.30681 | Running loss: 0.59342\n",
      "Epoch: 5 | Iteration: 555 | Classification loss: 0.44036 | Regression loss: 0.44124 | Running loss: 0.59423\n",
      "Epoch: 5 | Iteration: 556 | Classification loss: 0.33778 | Regression loss: 0.29189 | Running loss: 0.59411\n",
      "Epoch: 5 | Iteration: 557 | Classification loss: 0.23169 | Regression loss: 0.41214 | Running loss: 0.59440\n",
      "Epoch: 5 | Iteration: 558 | Classification loss: 0.24743 | Regression loss: 0.33462 | Running loss: 0.59466\n",
      "Epoch: 5 | Iteration: 559 | Classification loss: 0.27633 | Regression loss: 0.32796 | Running loss: 0.59474\n",
      "Epoch: 5 | Iteration: 560 | Classification loss: 0.25628 | Regression loss: 0.34846 | Running loss: 0.59498\n",
      "Epoch: 5 | Iteration: 561 | Classification loss: 0.27590 | Regression loss: 0.15049 | Running loss: 0.59492\n",
      "Epoch: 5 | Iteration: 562 | Classification loss: 0.24665 | Regression loss: 0.43789 | Running loss: 0.59488\n",
      "Epoch: 5 | Iteration: 563 | Classification loss: 0.29835 | Regression loss: 0.31160 | Running loss: 0.59508\n",
      "Epoch: 5 | Iteration: 564 | Classification loss: 0.43702 | Regression loss: 0.72405 | Running loss: 0.59639\n",
      "Epoch: 5 | Iteration: 565 | Classification loss: 0.17645 | Regression loss: 0.39348 | Running loss: 0.59696\n",
      "Epoch: 5 | Iteration: 566 | Classification loss: 0.30428 | Regression loss: 0.42527 | Running loss: 0.59768\n",
      "Epoch: 5 | Iteration: 567 | Classification loss: 0.30035 | Regression loss: 0.35456 | Running loss: 0.59739\n",
      "Epoch: 5 | Iteration: 568 | Classification loss: 0.15914 | Regression loss: 0.27522 | Running loss: 0.59688\n",
      "Epoch: 5 | Iteration: 569 | Classification loss: 0.20873 | Regression loss: 0.55703 | Running loss: 0.59738\n",
      "Epoch: 5 | Iteration: 570 | Classification loss: 0.22491 | Regression loss: 0.46482 | Running loss: 0.59742\n",
      "Epoch: 5 | Iteration: 571 | Classification loss: 0.15771 | Regression loss: 0.18677 | Running loss: 0.59651\n",
      "Epoch: 5 | Iteration: 572 | Classification loss: 0.35214 | Regression loss: 0.34227 | Running loss: 0.59576\n",
      "Epoch: 5 | Iteration: 573 | Classification loss: 0.28836 | Regression loss: 0.46143 | Running loss: 0.59639\n",
      "Epoch: 5 | Iteration: 574 | Classification loss: 0.64805 | Regression loss: 0.77941 | Running loss: 0.59861\n",
      "Epoch: 5 | Iteration: 575 | Classification loss: 0.18948 | Regression loss: 0.28143 | Running loss: 0.59862\n",
      "Epoch: 5 | Iteration: 576 | Classification loss: 0.32938 | Regression loss: 0.37275 | Running loss: 0.59853\n",
      "Epoch: 5 | Iteration: 577 | Classification loss: 0.23539 | Regression loss: 0.20084 | Running loss: 0.59738\n",
      "Epoch: 5 | Iteration: 578 | Classification loss: 0.38896 | Regression loss: 0.56634 | Running loss: 0.59834\n",
      "Epoch: 5 | Iteration: 579 | Classification loss: 0.10999 | Regression loss: 0.29633 | Running loss: 0.59800\n",
      "Epoch: 5 | Iteration: 580 | Classification loss: 0.19499 | Regression loss: 0.40323 | Running loss: 0.59725\n",
      "Epoch: 5 | Iteration: 581 | Classification loss: 0.16158 | Regression loss: 0.08422 | Running loss: 0.59604\n",
      "Epoch: 5 | Iteration: 582 | Classification loss: 0.24589 | Regression loss: 0.38691 | Running loss: 0.59556\n",
      "Epoch: 5 | Iteration: 583 | Classification loss: 0.17039 | Regression loss: 0.35375 | Running loss: 0.59547\n",
      "Epoch: 5 | Iteration: 584 | Classification loss: 0.51362 | Regression loss: 0.76562 | Running loss: 0.59683\n",
      "Epoch: 5 | Iteration: 585 | Classification loss: 0.22078 | Regression loss: 0.28556 | Running loss: 0.59689\n",
      "Epoch: 5 | Iteration: 586 | Classification loss: 0.27150 | Regression loss: 0.47740 | Running loss: 0.59662\n",
      "Epoch: 5 | Iteration: 587 | Classification loss: 0.15700 | Regression loss: 0.17314 | Running loss: 0.59614\n",
      "Epoch: 5 | Iteration: 588 | Classification loss: 0.25296 | Regression loss: 0.29675 | Running loss: 0.59572\n",
      "Epoch: 5 | Iteration: 589 | Classification loss: 0.26289 | Regression loss: 0.31215 | Running loss: 0.59571\n",
      "Epoch: 5 | Iteration: 590 | Classification loss: 0.19521 | Regression loss: 0.42234 | Running loss: 0.59605\n",
      "Epoch: 5 | Iteration: 591 | Classification loss: 0.36246 | Regression loss: 0.31581 | Running loss: 0.59672\n",
      "Epoch: 5 | Iteration: 592 | Classification loss: 0.25953 | Regression loss: 0.43134 | Running loss: 0.59570\n",
      "Epoch: 5 | Iteration: 593 | Classification loss: 0.61107 | Regression loss: 0.31610 | Running loss: 0.59688\n",
      "Epoch: 5 | Iteration: 594 | Classification loss: 0.11629 | Regression loss: 0.28461 | Running loss: 0.59585\n",
      "Epoch: 5 | Iteration: 595 | Classification loss: 0.37342 | Regression loss: 0.58777 | Running loss: 0.59713\n",
      "Epoch: 5 | Iteration: 596 | Classification loss: 0.28739 | Regression loss: 0.44502 | Running loss: 0.59805\n",
      "Epoch: 5 | Iteration: 597 | Classification loss: 0.32925 | Regression loss: 0.31992 | Running loss: 0.59815\n",
      "Epoch: 5 | Iteration: 598 | Classification loss: 0.35843 | Regression loss: 0.15610 | Running loss: 0.59811\n",
      "Epoch: 5 | Iteration: 599 | Classification loss: 0.28226 | Regression loss: 0.19760 | Running loss: 0.59756\n",
      "Epoch: 5 | Iteration: 600 | Classification loss: 0.23947 | Regression loss: 0.52511 | Running loss: 0.59735\n",
      "Epoch: 5 | Iteration: 601 | Classification loss: 0.11594 | Regression loss: 0.25229 | Running loss: 0.59695\n",
      "Epoch: 5 | Iteration: 602 | Classification loss: 0.12734 | Regression loss: 0.24120 | Running loss: 0.59699\n",
      "Epoch: 5 | Iteration: 603 | Classification loss: 0.36412 | Regression loss: 0.10762 | Running loss: 0.59640\n",
      "Epoch: 5 | Iteration: 604 | Classification loss: 0.18628 | Regression loss: 0.36589 | Running loss: 0.59561\n",
      "Epoch: 5 | Iteration: 605 | Classification loss: 0.07503 | Regression loss: 0.21810 | Running loss: 0.59485\n",
      "Epoch: 5 | Iteration: 606 | Classification loss: 0.07155 | Regression loss: 0.17244 | Running loss: 0.59416\n",
      "Epoch: 5 | Iteration: 607 | Classification loss: 0.13040 | Regression loss: 0.20783 | Running loss: 0.59438\n",
      "Epoch: 5 | Iteration: 608 | Classification loss: 0.50393 | Regression loss: 0.72158 | Running loss: 0.59526\n",
      "Epoch: 5 | Iteration: 609 | Classification loss: 0.21120 | Regression loss: 0.50762 | Running loss: 0.59480\n",
      "Epoch: 5 | Iteration: 610 | Classification loss: 0.38797 | Regression loss: 0.44525 | Running loss: 0.59572\n",
      "Epoch: 5 | Iteration: 611 | Classification loss: 0.11106 | Regression loss: 0.13377 | Running loss: 0.59504\n",
      "Epoch: 5 | Iteration: 612 | Classification loss: 0.13452 | Regression loss: 0.42238 | Running loss: 0.59395\n",
      "Epoch: 5 | Iteration: 613 | Classification loss: 0.17978 | Regression loss: 0.49621 | Running loss: 0.59421\n",
      "Epoch: 5 | Iteration: 614 | Classification loss: 0.12063 | Regression loss: 0.26535 | Running loss: 0.59389\n",
      "Epoch: 5 | Iteration: 615 | Classification loss: 1.18740 | Regression loss: 0.32847 | Running loss: 0.59630\n",
      "Epoch: 5 | Iteration: 616 | Classification loss: 0.15817 | Regression loss: 0.19104 | Running loss: 0.59590\n",
      "Epoch: 5 | Iteration: 617 | Classification loss: 0.05281 | Regression loss: 0.18193 | Running loss: 0.59539\n",
      "Epoch: 5 | Iteration: 618 | Classification loss: 0.09988 | Regression loss: 0.16222 | Running loss: 0.59461\n",
      "Epoch: 5 | Iteration: 619 | Classification loss: 0.39051 | Regression loss: 0.32152 | Running loss: 0.59478\n",
      "Epoch: 5 | Iteration: 620 | Classification loss: 0.24947 | Regression loss: 0.29691 | Running loss: 0.59514\n",
      "Epoch: 5 | Iteration: 621 | Classification loss: 0.23123 | Regression loss: 0.41497 | Running loss: 0.59557\n",
      "Epoch: 5 | Iteration: 622 | Classification loss: 0.18910 | Regression loss: 0.37615 | Running loss: 0.59492\n",
      "Epoch: 5 | Iteration: 623 | Classification loss: 0.25658 | Regression loss: 0.52923 | Running loss: 0.59564\n",
      "Epoch: 5 | Iteration: 624 | Classification loss: 0.11026 | Regression loss: 0.40741 | Running loss: 0.59568\n",
      "Epoch: 5 | Iteration: 625 | Classification loss: 0.13272 | Regression loss: 0.19600 | Running loss: 0.59492\n",
      "Epoch: 5 | Iteration: 626 | Classification loss: 0.29519 | Regression loss: 0.39537 | Running loss: 0.59495\n",
      "Epoch: 5 | Iteration: 627 | Classification loss: 0.25527 | Regression loss: 0.36570 | Running loss: 0.59486\n",
      "Epoch: 5 | Iteration: 628 | Classification loss: 0.16577 | Regression loss: 0.38055 | Running loss: 0.59426\n",
      "Epoch: 5 | Iteration: 629 | Classification loss: 0.74204 | Regression loss: 0.69835 | Running loss: 0.59649\n",
      "Epoch: 5 | Iteration: 630 | Classification loss: 0.16651 | Regression loss: 0.37554 | Running loss: 0.59695\n",
      "Epoch: 5 | Iteration: 631 | Classification loss: 0.27696 | Regression loss: 0.59011 | Running loss: 0.59758\n",
      "Epoch: 5 | Iteration: 632 | Classification loss: 0.17233 | Regression loss: 0.46742 | Running loss: 0.59788\n",
      "Epoch: 5 | Iteration: 633 | Classification loss: 0.46673 | Regression loss: 0.16705 | Running loss: 0.59816\n",
      "Epoch: 5 | Iteration: 634 | Classification loss: 0.39054 | Regression loss: 0.52427 | Running loss: 0.59859\n",
      "Epoch: 5 | Iteration: 635 | Classification loss: 0.19727 | Regression loss: 0.34206 | Running loss: 0.59889\n",
      "Epoch: 5 | Iteration: 636 | Classification loss: 0.30861 | Regression loss: 0.50839 | Running loss: 0.59965\n",
      "Epoch: 5 | Iteration: 637 | Classification loss: 0.22527 | Regression loss: 0.35319 | Running loss: 0.59970\n",
      "Epoch: 5 | Iteration: 638 | Classification loss: 0.44017 | Regression loss: 0.62488 | Running loss: 0.60088\n",
      "Epoch: 5 | Iteration: 639 | Classification loss: 0.12223 | Regression loss: 0.41451 | Running loss: 0.60135\n",
      "Epoch: 5 | Iteration: 640 | Classification loss: 0.24145 | Regression loss: 0.37807 | Running loss: 0.60181\n",
      "Epoch: 5 | Iteration: 641 | Classification loss: 0.39924 | Regression loss: 0.42961 | Running loss: 0.60244\n",
      "Epoch: 5 | Iteration: 642 | Classification loss: 0.24760 | Regression loss: 0.40609 | Running loss: 0.60241\n",
      "Epoch: 5 | Iteration: 643 | Classification loss: 0.18716 | Regression loss: 0.42171 | Running loss: 0.60252\n",
      "Epoch: 5 | Iteration: 644 | Classification loss: 0.25533 | Regression loss: 0.39967 | Running loss: 0.60239\n",
      "Epoch: 5 | Iteration: 645 | Classification loss: 0.28632 | Regression loss: 0.39168 | Running loss: 0.60163\n",
      "Epoch: 5 | Iteration: 646 | Classification loss: 0.42214 | Regression loss: 0.29196 | Running loss: 0.60080\n",
      "Epoch: 5 | Iteration: 647 | Classification loss: 0.12571 | Regression loss: 0.42044 | Running loss: 0.60040\n",
      "Epoch: 5 | Iteration: 648 | Classification loss: 0.39408 | Regression loss: 0.54879 | Running loss: 0.60125\n",
      "Epoch: 5 | Iteration: 649 | Classification loss: 0.22097 | Regression loss: 0.22675 | Running loss: 0.60148\n",
      "Epoch: 5 | Iteration: 650 | Classification loss: 0.30465 | Regression loss: 0.63906 | Running loss: 0.60196\n",
      "Epoch: 5 | Iteration: 651 | Classification loss: 0.21242 | Regression loss: 0.26775 | Running loss: 0.60213\n",
      "Epoch: 5 | Iteration: 652 | Classification loss: 0.24906 | Regression loss: 0.47984 | Running loss: 0.60261\n",
      "Epoch: 5 | Iteration: 653 | Classification loss: 0.09613 | Regression loss: 0.23699 | Running loss: 0.60222\n",
      "Epoch: 5 | Iteration: 654 | Classification loss: 0.23983 | Regression loss: 0.19637 | Running loss: 0.60174\n",
      "Epoch: 5 | Iteration: 655 | Classification loss: 0.52317 | Regression loss: 0.49432 | Running loss: 0.60254\n",
      "Epoch: 5 | Iteration: 656 | Classification loss: 0.22325 | Regression loss: 0.29626 | Running loss: 0.60185\n",
      "Epoch: 5 | Iteration: 657 | Classification loss: 0.12609 | Regression loss: 0.18816 | Running loss: 0.60106\n",
      "Epoch: 5 | Iteration: 658 | Classification loss: 0.12353 | Regression loss: 0.31306 | Running loss: 0.60014\n",
      "Epoch: 5 | Iteration: 659 | Classification loss: 0.21056 | Regression loss: 0.22163 | Running loss: 0.59980\n",
      "Epoch: 5 | Iteration: 660 | Classification loss: 0.25278 | Regression loss: 0.15182 | Running loss: 0.59931\n",
      "Epoch: 5 | Iteration: 661 | Classification loss: 0.30779 | Regression loss: 0.35946 | Running loss: 0.59930\n",
      "Epoch: 5 | Iteration: 662 | Classification loss: 0.25216 | Regression loss: 0.45719 | Running loss: 0.60016\n",
      "Epoch: 5 | Iteration: 663 | Classification loss: 0.13462 | Regression loss: 0.68019 | Running loss: 0.60112\n",
      "Epoch: 5 | Iteration: 664 | Classification loss: 0.23822 | Regression loss: 0.14068 | Running loss: 0.60187\n",
      "Epoch: 5 | Iteration: 665 | Classification loss: 0.17370 | Regression loss: 0.16628 | Running loss: 0.60111\n",
      "Epoch: 5 | Iteration: 666 | Classification loss: 0.12719 | Regression loss: 0.16685 | Running loss: 0.60046\n",
      "Epoch: 5 | Iteration: 667 | Classification loss: 0.16887 | Regression loss: 0.37672 | Running loss: 0.59933\n",
      "Epoch: 5 | Iteration: 668 | Classification loss: 0.09724 | Regression loss: 0.29680 | Running loss: 0.59863\n",
      "Epoch: 5 | Iteration: 669 | Classification loss: 0.15608 | Regression loss: 0.40780 | Running loss: 0.59913\n",
      "Epoch: 5 | Iteration: 670 | Classification loss: 0.28240 | Regression loss: 0.60222 | Running loss: 0.59979\n",
      "Epoch: 5 | Iteration: 671 | Classification loss: 0.41063 | Regression loss: 0.41832 | Running loss: 0.60029\n",
      "Epoch: 5 | Iteration: 672 | Classification loss: 0.19002 | Regression loss: 0.50064 | Running loss: 0.60037\n",
      "Epoch: 5 | Iteration: 673 | Classification loss: 0.21615 | Regression loss: 0.17235 | Running loss: 0.60001\n",
      "Epoch: 5 | Iteration: 674 | Classification loss: 0.15528 | Regression loss: 0.62403 | Running loss: 0.60083\n",
      "Epoch: 5 | Iteration: 675 | Classification loss: 0.19399 | Regression loss: 0.16001 | Running loss: 0.60027\n",
      "Epoch: 5 | Iteration: 676 | Classification loss: 0.18070 | Regression loss: 0.36047 | Running loss: 0.59885\n",
      "Epoch: 5 | Iteration: 677 | Classification loss: 0.35178 | Regression loss: 0.69756 | Running loss: 0.60019\n",
      "Epoch: 5 | Iteration: 678 | Classification loss: 0.26722 | Regression loss: 0.21473 | Running loss: 0.59982\n",
      "Epoch: 5 | Iteration: 679 | Classification loss: 0.45970 | Regression loss: 0.64221 | Running loss: 0.60117\n",
      "Epoch: 5 | Iteration: 680 | Classification loss: 0.11722 | Regression loss: 0.22129 | Running loss: 0.60105\n",
      "Epoch: 5 | Iteration: 681 | Classification loss: 0.32247 | Regression loss: 0.18634 | Running loss: 0.60102\n",
      "Epoch: 5 | Iteration: 682 | Classification loss: 0.46304 | Regression loss: 0.55133 | Running loss: 0.60236\n",
      "Epoch: 5 | Iteration: 683 | Classification loss: 0.26300 | Regression loss: 0.51087 | Running loss: 0.60264\n",
      "Epoch: 5 | Iteration: 684 | Classification loss: 0.30700 | Regression loss: 0.31297 | Running loss: 0.60248\n",
      "Epoch: 5 | Iteration: 685 | Classification loss: 0.23509 | Regression loss: 0.27760 | Running loss: 0.60255\n",
      "Epoch: 5 | Iteration: 686 | Classification loss: 0.25640 | Regression loss: 0.33529 | Running loss: 0.60210\n",
      "Epoch: 5 | Iteration: 687 | Classification loss: 0.23962 | Regression loss: 0.22530 | Running loss: 0.60149\n",
      "Epoch: 5 | Iteration: 688 | Classification loss: 0.44061 | Regression loss: 0.33969 | Running loss: 0.60137\n",
      "Epoch: 5 | Iteration: 689 | Classification loss: 0.18902 | Regression loss: 0.33457 | Running loss: 0.60007\n",
      "Epoch: 5 | Iteration: 690 | Classification loss: 0.14630 | Regression loss: 0.25610 | Running loss: 0.59999\n",
      "Epoch: 5 | Iteration: 691 | Classification loss: 0.38531 | Regression loss: 0.62388 | Running loss: 0.60110\n",
      "Epoch: 5 | Iteration: 692 | Classification loss: 0.27981 | Regression loss: 0.30447 | Running loss: 0.60157\n",
      "Epoch: 5 | Iteration: 693 | Classification loss: 0.29282 | Regression loss: 0.29224 | Running loss: 0.60169\n",
      "Epoch: 5 | Iteration: 694 | Classification loss: 0.19077 | Regression loss: 0.36107 | Running loss: 0.60046\n",
      "Epoch: 5 | Iteration: 695 | Classification loss: 0.32986 | Regression loss: 0.36551 | Running loss: 0.60063\n",
      "Epoch: 5 | Iteration: 696 | Classification loss: 0.24604 | Regression loss: 0.28298 | Running loss: 0.60071\n",
      "Epoch: 5 | Iteration: 697 | Classification loss: 0.35393 | Regression loss: 0.25612 | Running loss: 0.60107\n",
      "Epoch: 5 | Iteration: 698 | Classification loss: 0.15051 | Regression loss: 0.17045 | Running loss: 0.60002\n",
      "Epoch: 5 | Iteration: 699 | Classification loss: 0.26522 | Regression loss: 0.47241 | Running loss: 0.60058\n",
      "Epoch: 5 | Iteration: 700 | Classification loss: 0.32395 | Regression loss: 0.26456 | Running loss: 0.60084\n",
      "Epoch: 5 | Iteration: 701 | Classification loss: 0.84519 | Regression loss: 1.12268 | Running loss: 0.60411\n",
      "Epoch: 5 | Iteration: 702 | Classification loss: 0.23230 | Regression loss: 0.24606 | Running loss: 0.60390\n",
      "Epoch: 5 | Iteration: 703 | Classification loss: 0.26102 | Regression loss: 0.21853 | Running loss: 0.60432\n",
      "Epoch: 5 | Iteration: 704 | Classification loss: 0.23961 | Regression loss: 0.29780 | Running loss: 0.60466\n",
      "Epoch: 5 | Iteration: 705 | Classification loss: 0.21104 | Regression loss: 0.21391 | Running loss: 0.60451\n",
      "Epoch: 5 | Iteration: 706 | Classification loss: 0.11807 | Regression loss: 0.33221 | Running loss: 0.60458\n",
      "Epoch: 5 | Iteration: 707 | Classification loss: 0.09980 | Regression loss: 0.28446 | Running loss: 0.60447\n",
      "Epoch: 5 | Iteration: 708 | Classification loss: 0.21344 | Regression loss: 0.28778 | Running loss: 0.60469\n",
      "Epoch: 5 | Iteration: 709 | Classification loss: 0.23042 | Regression loss: 0.29056 | Running loss: 0.60473\n",
      "Epoch: 5 | Iteration: 710 | Classification loss: 0.04992 | Regression loss: 0.13204 | Running loss: 0.60449\n",
      "Epoch: 5 | Iteration: 711 | Classification loss: 0.12799 | Regression loss: 0.21596 | Running loss: 0.60406\n",
      "Epoch: 5 | Iteration: 712 | Classification loss: 0.08714 | Regression loss: 0.29792 | Running loss: 0.60311\n",
      "Epoch: 5 | Iteration: 713 | Classification loss: 0.29045 | Regression loss: 0.46511 | Running loss: 0.60276\n",
      "Epoch: 5 | Iteration: 714 | Classification loss: 0.11151 | Regression loss: 0.31697 | Running loss: 0.60245\n",
      "Epoch: 5 | Iteration: 715 | Classification loss: 0.32156 | Regression loss: 0.25202 | Running loss: 0.60272\n",
      "Epoch: 5 | Iteration: 716 | Classification loss: 0.14229 | Regression loss: 0.25397 | Running loss: 0.60220\n",
      "Epoch: 5 | Iteration: 717 | Classification loss: 0.12996 | Regression loss: 0.44868 | Running loss: 0.60273\n",
      "Epoch: 5 | Iteration: 718 | Classification loss: 0.16072 | Regression loss: 0.42309 | Running loss: 0.60261\n",
      "Epoch: 5 | Iteration: 719 | Classification loss: 0.19851 | Regression loss: 0.48359 | Running loss: 0.60233\n",
      "Epoch: 5 | Iteration: 720 | Classification loss: 0.33030 | Regression loss: 0.37841 | Running loss: 0.60248\n",
      "Epoch: 5 | Iteration: 721 | Classification loss: 0.22504 | Regression loss: 0.28412 | Running loss: 0.60201\n",
      "Epoch: 5 | Iteration: 722 | Classification loss: 0.21069 | Regression loss: 0.57081 | Running loss: 0.60269\n",
      "Epoch: 5 | Iteration: 723 | Classification loss: 0.20125 | Regression loss: 0.19469 | Running loss: 0.60227\n",
      "Epoch: 5 | Iteration: 724 | Classification loss: 0.06088 | Regression loss: 0.17912 | Running loss: 0.60124\n",
      "Epoch: 5 | Iteration: 725 | Classification loss: 0.11031 | Regression loss: 0.31619 | Running loss: 0.60139\n",
      "Epoch: 5 | Iteration: 726 | Classification loss: 0.25809 | Regression loss: 0.22986 | Running loss: 0.60157\n",
      "Epoch: 5 | Iteration: 727 | Classification loss: 0.13370 | Regression loss: 0.29775 | Running loss: 0.60108\n",
      "Epoch: 5 | Iteration: 728 | Classification loss: 0.14197 | Regression loss: 0.30022 | Running loss: 0.60103\n",
      "Epoch: 5 | Iteration: 729 | Classification loss: 0.15580 | Regression loss: 0.33466 | Running loss: 0.60120\n",
      "Epoch: 5 | Iteration: 730 | Classification loss: 0.26530 | Regression loss: 0.31898 | Running loss: 0.60182\n",
      "Epoch: 5 | Iteration: 731 | Classification loss: 0.22912 | Regression loss: 0.43609 | Running loss: 0.60162\n",
      "Epoch: 5 | Iteration: 732 | Classification loss: 0.53939 | Regression loss: 0.29628 | Running loss: 0.60176\n",
      "Epoch: 5 | Iteration: 733 | Classification loss: 0.47966 | Regression loss: 0.12277 | Running loss: 0.60233\n",
      "Epoch: 5 | Iteration: 734 | Classification loss: 0.17328 | Regression loss: 0.52235 | Running loss: 0.60237\n",
      "Epoch: 5 | Iteration: 735 | Classification loss: 0.42254 | Regression loss: 0.26261 | Running loss: 0.60258\n",
      "Epoch: 5 | Iteration: 736 | Classification loss: 0.11849 | Regression loss: 0.09399 | Running loss: 0.60174\n",
      "Epoch: 5 | Iteration: 737 | Classification loss: 0.40757 | Regression loss: 0.40798 | Running loss: 0.60235\n",
      "Epoch: 5 | Iteration: 738 | Classification loss: 0.22394 | Regression loss: 0.44225 | Running loss: 0.60145\n",
      "Epoch: 5 | Iteration: 739 | Classification loss: 0.39567 | Regression loss: 0.34560 | Running loss: 0.60178\n",
      "Epoch: 5 | Iteration: 740 | Classification loss: 0.16591 | Regression loss: 0.32853 | Running loss: 0.60177\n",
      "Epoch: 5 | Iteration: 741 | Classification loss: 0.20167 | Regression loss: 0.16732 | Running loss: 0.60129\n",
      "Epoch: 5 | Iteration: 742 | Classification loss: 0.19566 | Regression loss: 0.20463 | Running loss: 0.60094\n",
      "Epoch: 5 | Iteration: 743 | Classification loss: 0.24030 | Regression loss: 0.42750 | Running loss: 0.60055\n",
      "Epoch: 5 | Iteration: 744 | Classification loss: 0.11263 | Regression loss: 0.46176 | Running loss: 0.60049\n",
      "Epoch: 5 | Iteration: 745 | Classification loss: 0.51346 | Regression loss: 0.34269 | Running loss: 0.60088\n",
      "Epoch: 5 | Iteration: 746 | Classification loss: 0.29850 | Regression loss: 0.28634 | Running loss: 0.60107\n",
      "Epoch: 5 | Iteration: 747 | Classification loss: 0.36021 | Regression loss: 0.36088 | Running loss: 0.60158\n",
      "Epoch: 5 | Iteration: 748 | Classification loss: 0.10843 | Regression loss: 0.28920 | Running loss: 0.60020\n",
      "Epoch: 5 | Iteration: 749 | Classification loss: 0.30986 | Regression loss: 0.21246 | Running loss: 0.59993\n",
      "Epoch: 5 | Iteration: 750 | Classification loss: 0.40943 | Regression loss: 0.30580 | Running loss: 0.60066\n",
      "Epoch: 5 | Iteration: 751 | Classification loss: 0.21815 | Regression loss: 0.47734 | Running loss: 0.60053\n",
      "Epoch: 5 | Iteration: 752 | Classification loss: 0.09722 | Regression loss: 0.26021 | Running loss: 0.60013\n",
      "Epoch: 5 | Iteration: 753 | Classification loss: 0.26063 | Regression loss: 0.35947 | Running loss: 0.60038\n",
      "Epoch: 5 | Iteration: 754 | Classification loss: 0.19786 | Regression loss: 0.16630 | Running loss: 0.59992\n",
      "Epoch: 5 | Iteration: 755 | Classification loss: 0.23887 | Regression loss: 0.41013 | Running loss: 0.59938\n",
      "Epoch: 5 | Iteration: 756 | Classification loss: 0.25718 | Regression loss: 0.19018 | Running loss: 0.59954\n",
      "Epoch: 5 | Iteration: 757 | Classification loss: 0.17761 | Regression loss: 0.30689 | Running loss: 0.59969\n",
      "Epoch: 5 | Iteration: 758 | Classification loss: 0.12008 | Regression loss: 0.20256 | Running loss: 0.59861\n",
      "Epoch: 5 | Iteration: 759 | Classification loss: 0.42300 | Regression loss: 0.56627 | Running loss: 0.59882\n",
      "Epoch: 5 | Iteration: 760 | Classification loss: 0.18751 | Regression loss: 0.27212 | Running loss: 0.59893\n",
      "Epoch: 5 | Iteration: 761 | Classification loss: 0.20604 | Regression loss: 0.42654 | Running loss: 0.59880\n",
      "Epoch: 5 | Iteration: 762 | Classification loss: 0.35185 | Regression loss: 0.49952 | Running loss: 0.59978\n",
      "Epoch: 5 | Iteration: 763 | Classification loss: 0.30087 | Regression loss: 0.30690 | Running loss: 0.59974\n",
      "Epoch: 5 | Iteration: 764 | Classification loss: 0.19106 | Regression loss: 0.23070 | Running loss: 0.59893\n",
      "Epoch: 5 | Iteration: 765 | Classification loss: 0.22313 | Regression loss: 0.26992 | Running loss: 0.59897\n",
      "Epoch: 5 | Iteration: 766 | Classification loss: 0.48144 | Regression loss: 0.67773 | Running loss: 0.60021\n",
      "Epoch: 5 | Iteration: 767 | Classification loss: 0.28034 | Regression loss: 0.34300 | Running loss: 0.60059\n",
      "Epoch: 5 | Iteration: 768 | Classification loss: 0.23226 | Regression loss: 0.32679 | Running loss: 0.60107\n",
      "Epoch: 5 | Iteration: 769 | Classification loss: 0.15666 | Regression loss: 0.20503 | Running loss: 0.60110\n",
      "Epoch: 5 | Iteration: 770 | Classification loss: 0.36323 | Regression loss: 0.26791 | Running loss: 0.60080\n",
      "Epoch: 5 | Iteration: 771 | Classification loss: 0.16953 | Regression loss: 0.32447 | Running loss: 0.60070\n",
      "Epoch: 5 | Iteration: 772 | Classification loss: 0.26198 | Regression loss: 0.46304 | Running loss: 0.60138\n",
      "Epoch: 5 | Iteration: 773 | Classification loss: 0.25211 | Regression loss: 0.35614 | Running loss: 0.60081\n",
      "Epoch: 5 | Iteration: 774 | Classification loss: 0.45438 | Regression loss: 0.39879 | Running loss: 0.60146\n",
      "Epoch: 5 | Iteration: 775 | Classification loss: 0.33996 | Regression loss: 0.77348 | Running loss: 0.60268\n",
      "Epoch: 5 | Iteration: 776 | Classification loss: 0.17876 | Regression loss: 0.35178 | Running loss: 0.60288\n",
      "Epoch: 5 | Iteration: 777 | Classification loss: 0.18561 | Regression loss: 0.16083 | Running loss: 0.60276\n",
      "Epoch: 5 | Iteration: 778 | Classification loss: 0.23909 | Regression loss: 0.22796 | Running loss: 0.60251\n",
      "Epoch: 5 | Iteration: 779 | Classification loss: 0.27735 | Regression loss: 0.45574 | Running loss: 0.60316\n",
      "Epoch: 5 | Iteration: 780 | Classification loss: 0.16783 | Regression loss: 0.42536 | Running loss: 0.60230\n",
      "Epoch: 5 | Iteration: 781 | Classification loss: 0.24576 | Regression loss: 0.54089 | Running loss: 0.60180\n",
      "Epoch: 5 | Iteration: 782 | Classification loss: 0.21122 | Regression loss: 0.40520 | Running loss: 0.60191\n",
      "Epoch: 5 | Iteration: 783 | Classification loss: 0.34536 | Regression loss: 0.61362 | Running loss: 0.60250\n",
      "Epoch: 5 | Iteration: 784 | Classification loss: 0.14051 | Regression loss: 0.33026 | Running loss: 0.60226\n",
      "Epoch: 5 | Iteration: 785 | Classification loss: 0.30816 | Regression loss: 0.46188 | Running loss: 0.60297\n",
      "Epoch: 5 | Iteration: 786 | Classification loss: 0.51575 | Regression loss: 0.18698 | Running loss: 0.60340\n",
      "Epoch: 5 | Iteration: 787 | Classification loss: 0.16549 | Regression loss: 0.24995 | Running loss: 0.60337\n",
      "Epoch: 5 | Iteration: 788 | Classification loss: 0.37369 | Regression loss: 0.25603 | Running loss: 0.60393\n",
      "Epoch: 5 | Iteration: 789 | Classification loss: 0.16082 | Regression loss: 0.28532 | Running loss: 0.60417\n",
      "Epoch: 5 | Iteration: 790 | Classification loss: 0.31378 | Regression loss: 0.49764 | Running loss: 0.60445\n",
      "Epoch: 5 | Iteration: 791 | Classification loss: 0.34907 | Regression loss: 0.59303 | Running loss: 0.60516\n",
      "Epoch: 5 | Iteration: 792 | Classification loss: 0.10314 | Regression loss: 0.15603 | Running loss: 0.60526\n",
      "Epoch: 5 | Iteration: 793 | Classification loss: 0.16865 | Regression loss: 0.23296 | Running loss: 0.60510\n",
      "Epoch: 5 | Iteration: 794 | Classification loss: 0.12636 | Regression loss: 0.32957 | Running loss: 0.60502\n",
      "Epoch: 5 | Iteration: 795 | Classification loss: 0.17715 | Regression loss: 0.26727 | Running loss: 0.60391\n",
      "Epoch: 5 | Iteration: 796 | Classification loss: 0.00123 | Regression loss: 0.00000 | Running loss: 0.60286\n",
      "Epoch: 5 | Iteration: 797 | Classification loss: 0.30205 | Regression loss: 0.19731 | Running loss: 0.60218\n",
      "Epoch: 5 | Iteration: 798 | Classification loss: 0.21089 | Regression loss: 0.31029 | Running loss: 0.60224\n",
      "Epoch: 5 | Iteration: 799 | Classification loss: 0.20151 | Regression loss: 0.43085 | Running loss: 0.60229\n",
      "Epoch: 5 | Iteration: 800 | Classification loss: 0.10050 | Regression loss: 0.25551 | Running loss: 0.60196\n",
      "Epoch: 5 | Iteration: 801 | Classification loss: 0.26848 | Regression loss: 0.41348 | Running loss: 0.60079\n",
      "Epoch: 5 | Iteration: 802 | Classification loss: 0.47488 | Regression loss: 0.43764 | Running loss: 0.60116\n",
      "Epoch: 5 | Iteration: 803 | Classification loss: 0.05035 | Regression loss: 0.15534 | Running loss: 0.60062\n",
      "Epoch: 5 | Iteration: 804 | Classification loss: 0.48786 | Regression loss: 0.54243 | Running loss: 0.60097\n",
      "Epoch: 5 | Iteration: 805 | Classification loss: 0.19374 | Regression loss: 0.36288 | Running loss: 0.60094\n",
      "Epoch: 5 | Iteration: 806 | Classification loss: 0.37422 | Regression loss: 0.42865 | Running loss: 0.60107\n",
      "Epoch: 5 | Iteration: 807 | Classification loss: 0.17024 | Regression loss: 0.21474 | Running loss: 0.60100\n",
      "Epoch: 5 | Iteration: 808 | Classification loss: 0.19822 | Regression loss: 0.32037 | Running loss: 0.60101\n",
      "Epoch: 5 | Iteration: 809 | Classification loss: 0.30734 | Regression loss: 0.35296 | Running loss: 0.60137\n",
      "Epoch: 5 | Iteration: 810 | Classification loss: 0.49341 | Regression loss: 0.20299 | Running loss: 0.60173\n",
      "Epoch: 5 | Iteration: 811 | Classification loss: 0.35474 | Regression loss: 0.38925 | Running loss: 0.60141\n",
      "Epoch: 5 | Iteration: 812 | Classification loss: 0.21764 | Regression loss: 0.13294 | Running loss: 0.60140\n",
      "Epoch: 5 | Iteration: 813 | Classification loss: 0.14737 | Regression loss: 0.30794 | Running loss: 0.60183\n",
      "Epoch: 5 | Iteration: 814 | Classification loss: 0.20018 | Regression loss: 0.21114 | Running loss: 0.60142\n",
      "Epoch: 5 | Iteration: 815 | Classification loss: 0.06577 | Regression loss: 0.21719 | Running loss: 0.60079\n",
      "Epoch: 5 | Iteration: 816 | Classification loss: 0.11448 | Regression loss: 0.35881 | Running loss: 0.60106\n",
      "Epoch: 5 | Iteration: 817 | Classification loss: 0.37824 | Regression loss: 0.23700 | Running loss: 0.60037\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.415\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 6 | Iteration: 0 | Classification loss: 0.13701 | Regression loss: 0.25557 | Running loss: 0.60006\n",
      "Epoch: 6 | Iteration: 1 | Classification loss: 0.06631 | Regression loss: 0.09262 | Running loss: 0.59951\n",
      "Epoch: 6 | Iteration: 2 | Classification loss: 0.32776 | Regression loss: 0.34693 | Running loss: 0.59975\n",
      "Epoch: 6 | Iteration: 3 | Classification loss: 0.64271 | Regression loss: 0.98411 | Running loss: 0.60212\n",
      "Epoch: 6 | Iteration: 4 | Classification loss: 0.07379 | Regression loss: 0.19546 | Running loss: 0.60174\n",
      "Epoch: 6 | Iteration: 5 | Classification loss: 0.07817 | Regression loss: 0.32817 | Running loss: 0.60184\n",
      "Epoch: 6 | Iteration: 6 | Classification loss: 0.09625 | Regression loss: 0.30503 | Running loss: 0.60174\n",
      "Epoch: 6 | Iteration: 7 | Classification loss: 0.28532 | Regression loss: 0.35300 | Running loss: 0.60196\n",
      "Epoch: 6 | Iteration: 8 | Classification loss: 0.28458 | Regression loss: 0.52278 | Running loss: 0.60192\n",
      "Epoch: 6 | Iteration: 9 | Classification loss: 0.20893 | Regression loss: 0.21199 | Running loss: 0.60110\n",
      "Epoch: 6 | Iteration: 10 | Classification loss: 0.19380 | Regression loss: 0.21450 | Running loss: 0.60000\n",
      "Epoch: 6 | Iteration: 11 | Classification loss: 0.33361 | Regression loss: 0.30770 | Running loss: 0.60001\n",
      "Epoch: 6 | Iteration: 12 | Classification loss: 0.10270 | Regression loss: 0.41487 | Running loss: 0.60025\n",
      "Epoch: 6 | Iteration: 13 | Classification loss: 0.26978 | Regression loss: 0.23739 | Running loss: 0.60071\n",
      "Epoch: 6 | Iteration: 14 | Classification loss: 0.58889 | Regression loss: 0.42421 | Running loss: 0.60157\n",
      "Epoch: 6 | Iteration: 15 | Classification loss: 0.20636 | Regression loss: 0.37310 | Running loss: 0.60142\n",
      "Epoch: 6 | Iteration: 16 | Classification loss: 0.34062 | Regression loss: 0.41463 | Running loss: 0.60149\n",
      "Epoch: 6 | Iteration: 17 | Classification loss: 0.43701 | Regression loss: 0.50910 | Running loss: 0.60193\n",
      "Epoch: 6 | Iteration: 18 | Classification loss: 0.17378 | Regression loss: 0.13892 | Running loss: 0.60119\n",
      "Epoch: 6 | Iteration: 19 | Classification loss: 0.51154 | Regression loss: 0.45846 | Running loss: 0.60218\n",
      "Epoch: 6 | Iteration: 20 | Classification loss: 0.20367 | Regression loss: 0.28148 | Running loss: 0.60210\n",
      "Epoch: 6 | Iteration: 21 | Classification loss: 0.18476 | Regression loss: 0.34713 | Running loss: 0.60255\n",
      "Epoch: 6 | Iteration: 22 | Classification loss: 0.25916 | Regression loss: 0.21708 | Running loss: 0.60231\n",
      "Epoch: 6 | Iteration: 23 | Classification loss: 0.23182 | Regression loss: 0.26410 | Running loss: 0.60234\n",
      "Epoch: 6 | Iteration: 24 | Classification loss: 0.45567 | Regression loss: 0.30992 | Running loss: 0.60275\n",
      "Epoch: 6 | Iteration: 25 | Classification loss: 0.12598 | Regression loss: 0.22470 | Running loss: 0.60117\n",
      "Epoch: 6 | Iteration: 26 | Classification loss: 0.08839 | Regression loss: 0.20477 | Running loss: 0.60102\n",
      "Epoch: 6 | Iteration: 27 | Classification loss: 0.13820 | Regression loss: 0.21915 | Running loss: 0.60059\n",
      "Epoch: 6 | Iteration: 28 | Classification loss: 0.19850 | Regression loss: 0.45901 | Running loss: 0.60064\n",
      "Epoch: 6 | Iteration: 29 | Classification loss: 0.25048 | Regression loss: 0.27866 | Running loss: 0.60027\n",
      "Epoch: 6 | Iteration: 30 | Classification loss: 0.09309 | Regression loss: 0.19668 | Running loss: 0.59990\n",
      "Epoch: 6 | Iteration: 31 | Classification loss: 0.16287 | Regression loss: 0.29160 | Running loss: 0.59965\n",
      "Epoch: 6 | Iteration: 32 | Classification loss: 0.17819 | Regression loss: 0.20612 | Running loss: 0.59949\n",
      "Epoch: 6 | Iteration: 33 | Classification loss: 0.19083 | Regression loss: 0.15737 | Running loss: 0.59937\n",
      "Epoch: 6 | Iteration: 34 | Classification loss: 0.11017 | Regression loss: 0.19381 | Running loss: 0.59812\n",
      "Epoch: 6 | Iteration: 35 | Classification loss: 0.28147 | Regression loss: 0.24559 | Running loss: 0.59654\n",
      "Epoch: 6 | Iteration: 36 | Classification loss: 0.21151 | Regression loss: 0.26650 | Running loss: 0.59655\n",
      "Epoch: 6 | Iteration: 37 | Classification loss: 0.60156 | Regression loss: 0.94529 | Running loss: 0.59843\n",
      "Epoch: 6 | Iteration: 38 | Classification loss: 0.10409 | Regression loss: 0.18833 | Running loss: 0.59840\n",
      "Epoch: 6 | Iteration: 39 | Classification loss: 0.16884 | Regression loss: 0.40336 | Running loss: 0.59857\n",
      "Epoch: 6 | Iteration: 40 | Classification loss: 0.06273 | Regression loss: 0.22149 | Running loss: 0.59835\n",
      "Epoch: 6 | Iteration: 41 | Classification loss: 0.19268 | Regression loss: 0.27736 | Running loss: 0.59846\n",
      "Epoch: 6 | Iteration: 42 | Classification loss: 0.23733 | Regression loss: 0.32577 | Running loss: 0.59865\n",
      "Epoch: 6 | Iteration: 43 | Classification loss: 0.18722 | Regression loss: 0.32390 | Running loss: 0.59791\n",
      "Epoch: 6 | Iteration: 44 | Classification loss: 0.42111 | Regression loss: 0.54383 | Running loss: 0.59907\n",
      "Epoch: 6 | Iteration: 45 | Classification loss: 0.25171 | Regression loss: 0.49042 | Running loss: 0.59949\n",
      "Epoch: 6 | Iteration: 46 | Classification loss: 0.35233 | Regression loss: 0.28621 | Running loss: 0.59959\n",
      "Epoch: 6 | Iteration: 47 | Classification loss: 0.31201 | Regression loss: 0.20887 | Running loss: 0.59977\n",
      "Epoch: 6 | Iteration: 48 | Classification loss: 0.23741 | Regression loss: 0.48328 | Running loss: 0.60028\n",
      "Epoch: 6 | Iteration: 49 | Classification loss: 0.33955 | Regression loss: 0.37474 | Running loss: 0.60079\n",
      "Epoch: 6 | Iteration: 50 | Classification loss: 0.09988 | Regression loss: 0.19887 | Running loss: 0.60001\n",
      "Epoch: 6 | Iteration: 51 | Classification loss: 0.15047 | Regression loss: 0.20102 | Running loss: 0.59916\n",
      "Epoch: 6 | Iteration: 52 | Classification loss: 0.40314 | Regression loss: 0.25504 | Running loss: 0.59880\n",
      "Epoch: 6 | Iteration: 53 | Classification loss: 0.14023 | Regression loss: 0.30655 | Running loss: 0.59834\n",
      "Epoch: 6 | Iteration: 54 | Classification loss: 0.17688 | Regression loss: 0.35310 | Running loss: 0.59787\n",
      "Epoch: 6 | Iteration: 55 | Classification loss: 0.17452 | Regression loss: 0.43137 | Running loss: 0.59846\n",
      "Epoch: 6 | Iteration: 56 | Classification loss: 0.36508 | Regression loss: 0.77923 | Running loss: 0.59927\n",
      "Epoch: 6 | Iteration: 57 | Classification loss: 0.29165 | Regression loss: 0.32765 | Running loss: 0.59932\n",
      "Epoch: 6 | Iteration: 58 | Classification loss: 0.18301 | Regression loss: 0.40261 | Running loss: 0.59926\n",
      "Epoch: 6 | Iteration: 59 | Classification loss: 0.23567 | Regression loss: 0.25529 | Running loss: 0.59924\n",
      "Epoch: 6 | Iteration: 60 | Classification loss: 0.17089 | Regression loss: 0.23590 | Running loss: 0.59874\n",
      "Epoch: 6 | Iteration: 61 | Classification loss: 0.13423 | Regression loss: 0.45833 | Running loss: 0.59908\n",
      "Epoch: 6 | Iteration: 62 | Classification loss: 0.10505 | Regression loss: 0.35532 | Running loss: 0.59953\n",
      "Epoch: 6 | Iteration: 63 | Classification loss: 0.08548 | Regression loss: 0.23749 | Running loss: 0.59943\n",
      "Epoch: 6 | Iteration: 64 | Classification loss: 0.12763 | Regression loss: 0.22049 | Running loss: 0.59904\n",
      "Epoch: 6 | Iteration: 65 | Classification loss: 0.17907 | Regression loss: 0.29330 | Running loss: 0.59905\n",
      "Epoch: 6 | Iteration: 66 | Classification loss: 0.21103 | Regression loss: 0.67772 | Running loss: 0.59951\n",
      "Epoch: 6 | Iteration: 67 | Classification loss: 0.14615 | Regression loss: 0.26408 | Running loss: 0.59938\n",
      "Epoch: 6 | Iteration: 68 | Classification loss: 0.31232 | Regression loss: 0.33612 | Running loss: 0.59972\n",
      "Epoch: 6 | Iteration: 69 | Classification loss: 0.15485 | Regression loss: 0.33060 | Running loss: 0.59985\n",
      "Epoch: 6 | Iteration: 70 | Classification loss: 0.06093 | Regression loss: 0.15179 | Running loss: 0.59950\n",
      "Epoch: 6 | Iteration: 71 | Classification loss: 0.20548 | Regression loss: 0.33369 | Running loss: 0.59957\n",
      "Epoch: 6 | Iteration: 72 | Classification loss: 0.18424 | Regression loss: 0.30178 | Running loss: 0.59930\n",
      "Epoch: 6 | Iteration: 73 | Classification loss: 0.17218 | Regression loss: 0.36111 | Running loss: 0.59814\n",
      "Epoch: 6 | Iteration: 74 | Classification loss: 0.17500 | Regression loss: 0.35954 | Running loss: 0.59806\n",
      "Epoch: 6 | Iteration: 75 | Classification loss: 0.27957 | Regression loss: 0.56655 | Running loss: 0.59855\n",
      "Epoch: 6 | Iteration: 76 | Classification loss: 0.09957 | Regression loss: 0.19335 | Running loss: 0.59842\n",
      "Epoch: 6 | Iteration: 77 | Classification loss: 0.56219 | Regression loss: 0.89161 | Running loss: 0.60036\n",
      "Epoch: 6 | Iteration: 78 | Classification loss: 0.13876 | Regression loss: 0.33384 | Running loss: 0.60043\n",
      "Epoch: 6 | Iteration: 79 | Classification loss: 0.06375 | Regression loss: 0.20984 | Running loss: 0.60034\n",
      "Epoch: 6 | Iteration: 80 | Classification loss: 0.10993 | Regression loss: 0.25472 | Running loss: 0.59975\n",
      "Epoch: 6 | Iteration: 81 | Classification loss: 0.45124 | Regression loss: 0.27243 | Running loss: 0.59972\n",
      "Epoch: 6 | Iteration: 82 | Classification loss: 0.17730 | Regression loss: 0.18101 | Running loss: 0.59877\n",
      "Epoch: 6 | Iteration: 83 | Classification loss: 0.10254 | Regression loss: 0.20147 | Running loss: 0.59815\n",
      "Epoch: 6 | Iteration: 84 | Classification loss: 0.12337 | Regression loss: 0.31826 | Running loss: 0.59771\n",
      "Epoch: 6 | Iteration: 85 | Classification loss: 0.19670 | Regression loss: 0.59423 | Running loss: 0.59830\n",
      "Epoch: 6 | Iteration: 86 | Classification loss: 0.13711 | Regression loss: 0.31945 | Running loss: 0.59875\n",
      "Epoch: 6 | Iteration: 87 | Classification loss: 0.25938 | Regression loss: 0.30884 | Running loss: 0.59914\n",
      "Epoch: 6 | Iteration: 88 | Classification loss: 0.27404 | Regression loss: 0.59919 | Running loss: 0.60004\n",
      "Epoch: 6 | Iteration: 89 | Classification loss: 0.14743 | Regression loss: 0.23401 | Running loss: 0.60039\n",
      "Epoch: 6 | Iteration: 90 | Classification loss: 0.11831 | Regression loss: 0.22910 | Running loss: 0.59949\n",
      "Epoch: 6 | Iteration: 91 | Classification loss: 0.29673 | Regression loss: 0.43278 | Running loss: 0.59964\n",
      "Epoch: 6 | Iteration: 92 | Classification loss: 0.51914 | Regression loss: 0.70503 | Running loss: 0.60110\n",
      "Epoch: 6 | Iteration: 93 | Classification loss: 0.24503 | Regression loss: 0.32316 | Running loss: 0.60089\n",
      "Epoch: 6 | Iteration: 94 | Classification loss: 0.25796 | Regression loss: 0.29620 | Running loss: 0.60119\n",
      "Epoch: 6 | Iteration: 95 | Classification loss: 0.21248 | Regression loss: 0.31642 | Running loss: 0.60038\n",
      "Epoch: 6 | Iteration: 96 | Classification loss: 0.20137 | Regression loss: 0.32859 | Running loss: 0.59988\n",
      "Epoch: 6 | Iteration: 97 | Classification loss: 0.35064 | Regression loss: 0.38547 | Running loss: 0.60051\n",
      "Epoch: 6 | Iteration: 98 | Classification loss: 0.25201 | Regression loss: 0.25327 | Running loss: 0.60014\n",
      "Epoch: 6 | Iteration: 99 | Classification loss: 0.16226 | Regression loss: 0.37921 | Running loss: 0.60078\n",
      "Epoch: 6 | Iteration: 100 | Classification loss: 0.18365 | Regression loss: 0.19127 | Running loss: 0.60108\n",
      "Epoch: 6 | Iteration: 101 | Classification loss: 0.33587 | Regression loss: 0.92627 | Running loss: 0.60186\n",
      "Epoch: 6 | Iteration: 102 | Classification loss: 0.26178 | Regression loss: 0.23035 | Running loss: 0.60199\n",
      "Epoch: 6 | Iteration: 103 | Classification loss: 0.08659 | Regression loss: 0.23771 | Running loss: 0.60144\n",
      "Epoch: 6 | Iteration: 104 | Classification loss: 0.06891 | Regression loss: 0.22430 | Running loss: 0.59955\n",
      "Epoch: 6 | Iteration: 105 | Classification loss: 0.08117 | Regression loss: 0.14890 | Running loss: 0.59907\n",
      "Epoch: 6 | Iteration: 106 | Classification loss: 0.05725 | Regression loss: 0.24240 | Running loss: 0.59834\n",
      "Epoch: 6 | Iteration: 107 | Classification loss: 0.18834 | Regression loss: 0.39703 | Running loss: 0.59807\n",
      "Epoch: 6 | Iteration: 108 | Classification loss: 0.41060 | Regression loss: 0.23462 | Running loss: 0.59820\n",
      "Epoch: 6 | Iteration: 109 | Classification loss: 0.14046 | Regression loss: 0.31731 | Running loss: 0.59848\n",
      "Epoch: 6 | Iteration: 110 | Classification loss: 0.22885 | Regression loss: 0.27324 | Running loss: 0.59860\n",
      "Epoch: 6 | Iteration: 111 | Classification loss: 0.17710 | Regression loss: 0.19517 | Running loss: 0.59776\n",
      "Epoch: 6 | Iteration: 112 | Classification loss: 0.07489 | Regression loss: 0.23760 | Running loss: 0.59757\n",
      "Epoch: 6 | Iteration: 113 | Classification loss: 0.21987 | Regression loss: 0.30355 | Running loss: 0.59762\n",
      "Epoch: 6 | Iteration: 114 | Classification loss: 0.04299 | Regression loss: 0.19915 | Running loss: 0.59717\n",
      "Epoch: 6 | Iteration: 115 | Classification loss: 0.13088 | Regression loss: 0.35557 | Running loss: 0.59746\n",
      "Epoch: 6 | Iteration: 116 | Classification loss: 0.05859 | Regression loss: 0.31535 | Running loss: 0.59699\n",
      "Epoch: 6 | Iteration: 117 | Classification loss: 0.20556 | Regression loss: 0.29369 | Running loss: 0.59656\n",
      "Epoch: 6 | Iteration: 118 | Classification loss: 0.13411 | Regression loss: 0.32706 | Running loss: 0.59623\n",
      "Epoch: 6 | Iteration: 119 | Classification loss: 0.19827 | Regression loss: 0.28710 | Running loss: 0.59554\n",
      "Epoch: 6 | Iteration: 120 | Classification loss: 0.15017 | Regression loss: 0.22403 | Running loss: 0.59540\n",
      "Epoch: 6 | Iteration: 121 | Classification loss: 0.32276 | Regression loss: 0.26595 | Running loss: 0.59518\n",
      "Epoch: 6 | Iteration: 122 | Classification loss: 0.07539 | Regression loss: 0.27269 | Running loss: 0.59422\n",
      "Epoch: 6 | Iteration: 123 | Classification loss: 0.22369 | Regression loss: 0.26574 | Running loss: 0.59452\n",
      "Epoch: 6 | Iteration: 124 | Classification loss: 0.07797 | Regression loss: 0.20277 | Running loss: 0.59342\n",
      "Epoch: 6 | Iteration: 125 | Classification loss: 0.24608 | Regression loss: 0.20853 | Running loss: 0.59285\n",
      "Epoch: 6 | Iteration: 126 | Classification loss: 0.28293 | Regression loss: 0.34561 | Running loss: 0.59253\n",
      "Epoch: 6 | Iteration: 127 | Classification loss: 0.36591 | Regression loss: 0.40808 | Running loss: 0.59268\n",
      "Epoch: 6 | Iteration: 128 | Classification loss: 0.06796 | Regression loss: 0.25312 | Running loss: 0.59170\n",
      "Epoch: 6 | Iteration: 129 | Classification loss: 0.64183 | Regression loss: 0.57242 | Running loss: 0.59283\n",
      "Epoch: 6 | Iteration: 130 | Classification loss: 0.29447 | Regression loss: 0.17183 | Running loss: 0.59315\n",
      "Epoch: 6 | Iteration: 131 | Classification loss: 0.24860 | Regression loss: 0.65495 | Running loss: 0.59348\n",
      "Epoch: 6 | Iteration: 132 | Classification loss: 0.20092 | Regression loss: 0.25641 | Running loss: 0.59296\n",
      "Epoch: 6 | Iteration: 133 | Classification loss: 0.07509 | Regression loss: 0.33069 | Running loss: 0.59308\n",
      "Epoch: 6 | Iteration: 134 | Classification loss: 0.37232 | Regression loss: 0.60690 | Running loss: 0.59341\n",
      "Epoch: 6 | Iteration: 135 | Classification loss: 0.15900 | Regression loss: 0.27879 | Running loss: 0.59209\n",
      "Epoch: 6 | Iteration: 136 | Classification loss: 0.10150 | Regression loss: 0.36740 | Running loss: 0.59174\n",
      "Epoch: 6 | Iteration: 137 | Classification loss: 0.17763 | Regression loss: 0.38121 | Running loss: 0.59233\n",
      "Epoch: 6 | Iteration: 138 | Classification loss: 0.29021 | Regression loss: 0.49872 | Running loss: 0.59243\n",
      "Epoch: 6 | Iteration: 139 | Classification loss: 0.14671 | Regression loss: 0.46779 | Running loss: 0.59285\n",
      "Epoch: 6 | Iteration: 140 | Classification loss: 0.18482 | Regression loss: 0.43425 | Running loss: 0.59280\n",
      "Epoch: 6 | Iteration: 141 | Classification loss: 0.22087 | Regression loss: 0.50041 | Running loss: 0.59342\n",
      "Epoch: 6 | Iteration: 142 | Classification loss: 0.15568 | Regression loss: 0.34629 | Running loss: 0.59314\n",
      "Epoch: 6 | Iteration: 143 | Classification loss: 0.68252 | Regression loss: 0.32458 | Running loss: 0.59399\n",
      "Epoch: 6 | Iteration: 144 | Classification loss: 0.17166 | Regression loss: 0.31570 | Running loss: 0.59412\n",
      "Epoch: 6 | Iteration: 145 | Classification loss: 0.41894 | Regression loss: 0.24350 | Running loss: 0.59420\n",
      "Epoch: 6 | Iteration: 146 | Classification loss: 0.14595 | Regression loss: 0.28049 | Running loss: 0.59439\n",
      "Epoch: 6 | Iteration: 147 | Classification loss: 0.19007 | Regression loss: 0.47579 | Running loss: 0.59483\n",
      "Epoch: 6 | Iteration: 148 | Classification loss: 0.13862 | Regression loss: 0.26074 | Running loss: 0.59428\n",
      "Epoch: 6 | Iteration: 149 | Classification loss: 0.21733 | Regression loss: 0.82131 | Running loss: 0.59496\n",
      "Epoch: 6 | Iteration: 150 | Classification loss: 0.27165 | Regression loss: 0.28450 | Running loss: 0.59532\n",
      "Epoch: 6 | Iteration: 151 | Classification loss: 0.21535 | Regression loss: 0.47636 | Running loss: 0.59585\n",
      "Epoch: 6 | Iteration: 152 | Classification loss: 0.35545 | Regression loss: 0.28008 | Running loss: 0.59641\n",
      "Epoch: 6 | Iteration: 153 | Classification loss: 0.33233 | Regression loss: 0.56279 | Running loss: 0.59717\n",
      "Epoch: 6 | Iteration: 154 | Classification loss: 0.29845 | Regression loss: 0.35752 | Running loss: 0.59642\n",
      "Epoch: 6 | Iteration: 155 | Classification loss: 0.12798 | Regression loss: 0.37467 | Running loss: 0.59642\n",
      "Epoch: 6 | Iteration: 156 | Classification loss: 0.42046 | Regression loss: 0.35073 | Running loss: 0.59725\n",
      "Epoch: 6 | Iteration: 157 | Classification loss: 0.20484 | Regression loss: 0.28901 | Running loss: 0.59736\n",
      "Epoch: 6 | Iteration: 158 | Classification loss: 0.30802 | Regression loss: 0.42576 | Running loss: 0.59683\n",
      "Epoch: 6 | Iteration: 159 | Classification loss: 0.28133 | Regression loss: 0.54832 | Running loss: 0.59621\n",
      "Epoch: 6 | Iteration: 160 | Classification loss: 0.14685 | Regression loss: 0.38983 | Running loss: 0.59568\n",
      "Epoch: 6 | Iteration: 161 | Classification loss: 0.25682 | Regression loss: 0.20766 | Running loss: 0.59562\n",
      "Epoch: 6 | Iteration: 162 | Classification loss: 0.17111 | Regression loss: 0.28881 | Running loss: 0.59556\n",
      "Epoch: 6 | Iteration: 163 | Classification loss: 0.12108 | Regression loss: 0.21653 | Running loss: 0.59541\n",
      "Epoch: 6 | Iteration: 164 | Classification loss: 0.12903 | Regression loss: 0.22070 | Running loss: 0.59507\n",
      "Epoch: 6 | Iteration: 165 | Classification loss: 0.20514 | Regression loss: 0.27808 | Running loss: 0.59514\n",
      "Epoch: 6 | Iteration: 166 | Classification loss: 0.45971 | Regression loss: 0.56565 | Running loss: 0.59655\n",
      "Epoch: 6 | Iteration: 167 | Classification loss: 0.17996 | Regression loss: 0.22101 | Running loss: 0.59523\n",
      "Epoch: 6 | Iteration: 168 | Classification loss: 0.32999 | Regression loss: 0.30738 | Running loss: 0.59585\n",
      "Epoch: 6 | Iteration: 169 | Classification loss: 0.25255 | Regression loss: 0.26999 | Running loss: 0.59451\n",
      "Epoch: 6 | Iteration: 170 | Classification loss: 0.29928 | Regression loss: 0.47256 | Running loss: 0.59485\n",
      "Epoch: 6 | Iteration: 171 | Classification loss: 0.31920 | Regression loss: 0.45906 | Running loss: 0.59448\n",
      "Epoch: 6 | Iteration: 172 | Classification loss: 0.28410 | Regression loss: 0.29359 | Running loss: 0.59475\n",
      "Epoch: 6 | Iteration: 173 | Classification loss: 0.08688 | Regression loss: 0.31209 | Running loss: 0.59450\n",
      "Epoch: 6 | Iteration: 174 | Classification loss: 0.27202 | Regression loss: 0.44072 | Running loss: 0.59448\n",
      "Epoch: 6 | Iteration: 175 | Classification loss: 0.31498 | Regression loss: 0.37852 | Running loss: 0.59439\n",
      "Epoch: 6 | Iteration: 176 | Classification loss: 0.23857 | Regression loss: 0.28161 | Running loss: 0.59470\n",
      "Epoch: 6 | Iteration: 177 | Classification loss: 0.19948 | Regression loss: 0.36960 | Running loss: 0.59479\n",
      "Epoch: 6 | Iteration: 178 | Classification loss: 0.11817 | Regression loss: 0.49004 | Running loss: 0.59514\n",
      "Epoch: 6 | Iteration: 179 | Classification loss: 0.21278 | Regression loss: 0.29695 | Running loss: 0.59423\n",
      "Epoch: 6 | Iteration: 180 | Classification loss: 0.30593 | Regression loss: 0.59160 | Running loss: 0.59494\n",
      "Epoch: 6 | Iteration: 181 | Classification loss: 0.31094 | Regression loss: 0.41141 | Running loss: 0.59525\n",
      "Epoch: 6 | Iteration: 182 | Classification loss: 0.23742 | Regression loss: 0.56006 | Running loss: 0.59543\n",
      "Epoch: 6 | Iteration: 183 | Classification loss: 0.50192 | Regression loss: 0.30163 | Running loss: 0.59566\n",
      "Epoch: 6 | Iteration: 184 | Classification loss: 0.17436 | Regression loss: 0.16408 | Running loss: 0.59485\n",
      "Epoch: 6 | Iteration: 185 | Classification loss: 0.31833 | Regression loss: 0.13350 | Running loss: 0.59414\n",
      "Epoch: 6 | Iteration: 186 | Classification loss: 0.18369 | Regression loss: 0.41078 | Running loss: 0.59352\n",
      "Epoch: 6 | Iteration: 187 | Classification loss: 0.12093 | Regression loss: 0.28513 | Running loss: 0.59342\n",
      "Epoch: 6 | Iteration: 188 | Classification loss: 0.18721 | Regression loss: 0.24927 | Running loss: 0.59328\n",
      "Epoch: 6 | Iteration: 189 | Classification loss: 0.30526 | Regression loss: 0.42913 | Running loss: 0.59367\n",
      "Epoch: 6 | Iteration: 190 | Classification loss: 0.16932 | Regression loss: 0.42941 | Running loss: 0.59276\n",
      "Epoch: 6 | Iteration: 191 | Classification loss: 0.26817 | Regression loss: 0.39267 | Running loss: 0.59310\n",
      "Epoch: 6 | Iteration: 192 | Classification loss: 0.20576 | Regression loss: 0.53780 | Running loss: 0.59326\n",
      "Epoch: 6 | Iteration: 193 | Classification loss: 0.19792 | Regression loss: 0.25571 | Running loss: 0.59323\n",
      "Epoch: 6 | Iteration: 194 | Classification loss: 0.37326 | Regression loss: 0.13253 | Running loss: 0.59311\n",
      "Epoch: 6 | Iteration: 195 | Classification loss: 0.16772 | Regression loss: 0.35244 | Running loss: 0.59329\n",
      "Epoch: 6 | Iteration: 196 | Classification loss: 0.09786 | Regression loss: 0.22246 | Running loss: 0.59254\n",
      "Epoch: 6 | Iteration: 197 | Classification loss: 0.32237 | Regression loss: 0.56207 | Running loss: 0.59326\n",
      "Epoch: 6 | Iteration: 198 | Classification loss: 0.33046 | Regression loss: 0.36336 | Running loss: 0.59323\n",
      "Epoch: 6 | Iteration: 199 | Classification loss: 0.22767 | Regression loss: 0.37964 | Running loss: 0.59384\n",
      "Epoch: 6 | Iteration: 200 | Classification loss: 0.07532 | Regression loss: 0.16909 | Running loss: 0.59263\n",
      "Epoch: 6 | Iteration: 201 | Classification loss: 0.31217 | Regression loss: 0.27024 | Running loss: 0.59338\n",
      "Epoch: 6 | Iteration: 202 | Classification loss: 0.35277 | Regression loss: 0.60842 | Running loss: 0.59440\n",
      "Epoch: 6 | Iteration: 203 | Classification loss: 0.30691 | Regression loss: 0.31930 | Running loss: 0.59491\n",
      "Epoch: 6 | Iteration: 204 | Classification loss: 0.34801 | Regression loss: 0.18312 | Running loss: 0.59455\n",
      "Epoch: 6 | Iteration: 205 | Classification loss: 0.23522 | Regression loss: 0.18131 | Running loss: 0.59420\n",
      "Epoch: 6 | Iteration: 206 | Classification loss: 0.22109 | Regression loss: 0.56654 | Running loss: 0.59508\n",
      "Epoch: 6 | Iteration: 207 | Classification loss: 0.19593 | Regression loss: 0.28141 | Running loss: 0.59372\n",
      "Epoch: 6 | Iteration: 208 | Classification loss: 0.33279 | Regression loss: 0.34015 | Running loss: 0.59399\n",
      "Epoch: 6 | Iteration: 209 | Classification loss: 0.23920 | Regression loss: 0.43007 | Running loss: 0.59403\n",
      "Epoch: 6 | Iteration: 210 | Classification loss: 0.05227 | Regression loss: 0.20893 | Running loss: 0.59357\n",
      "Epoch: 6 | Iteration: 211 | Classification loss: 0.24752 | Regression loss: 0.26856 | Running loss: 0.59330\n",
      "Epoch: 6 | Iteration: 212 | Classification loss: 0.24427 | Regression loss: 0.18358 | Running loss: 0.59313\n",
      "Epoch: 6 | Iteration: 213 | Classification loss: 0.24113 | Regression loss: 0.37243 | Running loss: 0.59353\n",
      "Epoch: 6 | Iteration: 214 | Classification loss: 0.23692 | Regression loss: 0.38658 | Running loss: 0.59348\n",
      "Epoch: 6 | Iteration: 215 | Classification loss: 0.10530 | Regression loss: 0.14353 | Running loss: 0.59297\n",
      "Epoch: 6 | Iteration: 216 | Classification loss: 0.14104 | Regression loss: 0.23856 | Running loss: 0.59264\n",
      "Epoch: 6 | Iteration: 217 | Classification loss: 0.21815 | Regression loss: 0.28465 | Running loss: 0.59135\n",
      "Epoch: 6 | Iteration: 218 | Classification loss: 0.17331 | Regression loss: 0.19442 | Running loss: 0.59060\n",
      "Epoch: 6 | Iteration: 219 | Classification loss: 0.22613 | Regression loss: 0.22093 | Running loss: 0.59064\n",
      "Epoch: 6 | Iteration: 220 | Classification loss: 0.10278 | Regression loss: 0.16500 | Running loss: 0.58963\n",
      "Epoch: 6 | Iteration: 221 | Classification loss: 0.17716 | Regression loss: 0.33949 | Running loss: 0.58913\n",
      "Epoch: 6 | Iteration: 222 | Classification loss: 0.39490 | Regression loss: 0.54407 | Running loss: 0.58893\n",
      "Epoch: 6 | Iteration: 223 | Classification loss: 0.26221 | Regression loss: 0.38917 | Running loss: 0.58850\n",
      "Epoch: 6 | Iteration: 224 | Classification loss: 0.28089 | Regression loss: 0.26773 | Running loss: 0.58846\n",
      "Epoch: 6 | Iteration: 225 | Classification loss: 0.24300 | Regression loss: 0.28417 | Running loss: 0.58791\n",
      "Epoch: 6 | Iteration: 226 | Classification loss: 0.11546 | Regression loss: 0.24910 | Running loss: 0.58801\n",
      "Epoch: 6 | Iteration: 227 | Classification loss: 0.33924 | Regression loss: 0.15298 | Running loss: 0.58791\n",
      "Epoch: 6 | Iteration: 228 | Classification loss: 0.32419 | Regression loss: 0.47554 | Running loss: 0.58790\n",
      "Epoch: 6 | Iteration: 229 | Classification loss: 0.17304 | Regression loss: 0.41718 | Running loss: 0.58823\n",
      "Epoch: 6 | Iteration: 230 | Classification loss: 0.10874 | Regression loss: 0.36052 | Running loss: 0.58725\n",
      "Epoch: 6 | Iteration: 231 | Classification loss: 0.49201 | Regression loss: 0.63893 | Running loss: 0.58853\n",
      "Epoch: 6 | Iteration: 232 | Classification loss: 0.39037 | Regression loss: 0.53740 | Running loss: 0.58944\n",
      "Epoch: 6 | Iteration: 233 | Classification loss: 0.04661 | Regression loss: 0.21511 | Running loss: 0.58899\n",
      "Epoch: 6 | Iteration: 234 | Classification loss: 0.36897 | Regression loss: 0.37768 | Running loss: 0.58988\n",
      "Epoch: 6 | Iteration: 235 | Classification loss: 0.34364 | Regression loss: 0.30987 | Running loss: 0.58902\n",
      "Epoch: 6 | Iteration: 236 | Classification loss: 0.06488 | Regression loss: 0.19956 | Running loss: 0.58795\n",
      "Epoch: 6 | Iteration: 237 | Classification loss: 0.11279 | Regression loss: 0.15763 | Running loss: 0.58673\n",
      "Epoch: 6 | Iteration: 238 | Classification loss: 0.19934 | Regression loss: 0.24128 | Running loss: 0.58635\n",
      "Epoch: 6 | Iteration: 239 | Classification loss: 0.26664 | Regression loss: 0.28226 | Running loss: 0.58616\n",
      "Epoch: 6 | Iteration: 240 | Classification loss: 0.22696 | Regression loss: 0.30653 | Running loss: 0.58606\n",
      "Epoch: 6 | Iteration: 241 | Classification loss: 0.11057 | Regression loss: 0.29112 | Running loss: 0.58566\n",
      "Epoch: 6 | Iteration: 242 | Classification loss: 0.40375 | Regression loss: 0.17289 | Running loss: 0.58560\n",
      "Epoch: 6 | Iteration: 243 | Classification loss: 0.24219 | Regression loss: 0.55757 | Running loss: 0.58635\n",
      "Epoch: 6 | Iteration: 244 | Classification loss: 0.26387 | Regression loss: 0.16097 | Running loss: 0.58583\n",
      "Epoch: 6 | Iteration: 245 | Classification loss: 0.24214 | Regression loss: 0.18986 | Running loss: 0.58547\n",
      "Epoch: 6 | Iteration: 246 | Classification loss: 0.14382 | Regression loss: 0.59127 | Running loss: 0.58462\n",
      "Epoch: 6 | Iteration: 247 | Classification loss: 0.21111 | Regression loss: 0.20606 | Running loss: 0.58432\n",
      "Epoch: 6 | Iteration: 248 | Classification loss: 0.29870 | Regression loss: 0.21622 | Running loss: 0.58389\n",
      "Epoch: 6 | Iteration: 249 | Classification loss: 0.17957 | Regression loss: 0.33821 | Running loss: 0.58361\n",
      "Epoch: 6 | Iteration: 250 | Classification loss: 0.47274 | Regression loss: 0.73367 | Running loss: 0.58516\n",
      "Epoch: 6 | Iteration: 251 | Classification loss: 0.04477 | Regression loss: 0.22334 | Running loss: 0.58416\n",
      "Epoch: 6 | Iteration: 252 | Classification loss: 0.19197 | Regression loss: 0.36651 | Running loss: 0.58390\n",
      "Epoch: 6 | Iteration: 253 | Classification loss: 0.15189 | Regression loss: 0.25640 | Running loss: 0.58403\n",
      "Epoch: 6 | Iteration: 254 | Classification loss: 0.29702 | Regression loss: 0.15318 | Running loss: 0.58354\n",
      "Epoch: 6 | Iteration: 255 | Classification loss: 0.58062 | Regression loss: 0.42578 | Running loss: 0.58405\n",
      "Epoch: 6 | Iteration: 256 | Classification loss: 0.11272 | Regression loss: 0.27371 | Running loss: 0.58197\n",
      "Epoch: 6 | Iteration: 257 | Classification loss: 0.17511 | Regression loss: 0.50033 | Running loss: 0.58238\n",
      "Epoch: 6 | Iteration: 258 | Classification loss: 0.24533 | Regression loss: 0.45804 | Running loss: 0.58238\n",
      "Epoch: 6 | Iteration: 259 | Classification loss: 0.25548 | Regression loss: 0.36560 | Running loss: 0.58275\n",
      "Epoch: 6 | Iteration: 260 | Classification loss: 0.13241 | Regression loss: 0.17919 | Running loss: 0.58146\n",
      "Epoch: 6 | Iteration: 261 | Classification loss: 0.19372 | Regression loss: 0.31289 | Running loss: 0.58166\n",
      "Epoch: 6 | Iteration: 262 | Classification loss: 0.18547 | Regression loss: 0.18278 | Running loss: 0.58120\n",
      "Epoch: 6 | Iteration: 263 | Classification loss: 0.10209 | Regression loss: 0.30713 | Running loss: 0.58153\n",
      "Epoch: 6 | Iteration: 264 | Classification loss: 0.23750 | Regression loss: 0.14544 | Running loss: 0.58103\n",
      "Epoch: 6 | Iteration: 265 | Classification loss: 0.28944 | Regression loss: 0.20960 | Running loss: 0.58098\n",
      "Epoch: 6 | Iteration: 266 | Classification loss: 0.20858 | Regression loss: 0.15494 | Running loss: 0.57915\n",
      "Epoch: 6 | Iteration: 267 | Classification loss: 0.15949 | Regression loss: 0.34751 | Running loss: 0.57915\n",
      "Epoch: 6 | Iteration: 268 | Classification loss: 0.10604 | Regression loss: 0.15675 | Running loss: 0.57818\n",
      "Epoch: 6 | Iteration: 269 | Classification loss: 0.21749 | Regression loss: 0.46266 | Running loss: 0.57888\n",
      "Epoch: 6 | Iteration: 270 | Classification loss: 0.19138 | Regression loss: 0.35935 | Running loss: 0.57888\n",
      "Epoch: 6 | Iteration: 271 | Classification loss: 0.56398 | Regression loss: 0.16583 | Running loss: 0.57919\n",
      "Epoch: 6 | Iteration: 272 | Classification loss: 0.29388 | Regression loss: 0.26559 | Running loss: 0.57907\n",
      "Epoch: 6 | Iteration: 273 | Classification loss: 0.16109 | Regression loss: 0.12674 | Running loss: 0.57829\n",
      "Epoch: 6 | Iteration: 274 | Classification loss: 0.11792 | Regression loss: 0.24445 | Running loss: 0.57764\n",
      "Epoch: 6 | Iteration: 275 | Classification loss: 0.53420 | Regression loss: 0.32731 | Running loss: 0.57751\n",
      "Epoch: 6 | Iteration: 276 | Classification loss: 0.16262 | Regression loss: 0.32190 | Running loss: 0.57767\n",
      "Epoch: 6 | Iteration: 277 | Classification loss: 0.06840 | Regression loss: 0.11492 | Running loss: 0.57612\n",
      "Epoch: 6 | Iteration: 278 | Classification loss: 0.22118 | Regression loss: 0.48026 | Running loss: 0.57605\n",
      "Epoch: 6 | Iteration: 279 | Classification loss: 0.22521 | Regression loss: 0.22828 | Running loss: 0.57566\n",
      "Epoch: 6 | Iteration: 280 | Classification loss: 0.10800 | Regression loss: 0.25456 | Running loss: 0.57536\n",
      "Epoch: 6 | Iteration: 281 | Classification loss: 0.12402 | Regression loss: 0.36872 | Running loss: 0.57539\n",
      "Epoch: 6 | Iteration: 282 | Classification loss: 0.31792 | Regression loss: 0.44834 | Running loss: 0.57539\n",
      "Epoch: 6 | Iteration: 283 | Classification loss: 0.11734 | Regression loss: 0.25890 | Running loss: 0.57540\n",
      "Epoch: 6 | Iteration: 284 | Classification loss: 0.11816 | Regression loss: 0.39485 | Running loss: 0.57569\n",
      "Epoch: 6 | Iteration: 285 | Classification loss: 0.09860 | Regression loss: 0.37320 | Running loss: 0.57569\n",
      "Epoch: 6 | Iteration: 286 | Classification loss: 0.14271 | Regression loss: 0.23615 | Running loss: 0.57535\n",
      "Epoch: 6 | Iteration: 287 | Classification loss: 0.10734 | Regression loss: 0.28261 | Running loss: 0.57554\n",
      "Epoch: 6 | Iteration: 288 | Classification loss: 0.27001 | Regression loss: 0.65317 | Running loss: 0.57690\n",
      "Epoch: 6 | Iteration: 289 | Classification loss: 0.11597 | Regression loss: 0.31292 | Running loss: 0.57708\n",
      "Epoch: 6 | Iteration: 290 | Classification loss: 0.25481 | Regression loss: 0.49051 | Running loss: 0.57612\n",
      "Epoch: 6 | Iteration: 291 | Classification loss: 0.24809 | Regression loss: 0.26280 | Running loss: 0.57570\n",
      "Epoch: 6 | Iteration: 292 | Classification loss: 0.21463 | Regression loss: 0.20348 | Running loss: 0.57487\n",
      "Epoch: 6 | Iteration: 293 | Classification loss: 0.14647 | Regression loss: 0.28588 | Running loss: 0.57525\n",
      "Epoch: 6 | Iteration: 294 | Classification loss: 0.20026 | Regression loss: 0.27241 | Running loss: 0.57508\n",
      "Epoch: 6 | Iteration: 295 | Classification loss: 0.15440 | Regression loss: 0.25443 | Running loss: 0.57455\n",
      "Epoch: 6 | Iteration: 296 | Classification loss: 0.21553 | Regression loss: 0.38074 | Running loss: 0.57497\n",
      "Epoch: 6 | Iteration: 297 | Classification loss: 0.26788 | Regression loss: 0.27147 | Running loss: 0.57301\n",
      "Epoch: 6 | Iteration: 298 | Classification loss: 0.21778 | Regression loss: 0.43184 | Running loss: 0.57361\n",
      "Epoch: 6 | Iteration: 299 | Classification loss: 0.12686 | Regression loss: 0.44301 | Running loss: 0.57428\n",
      "Epoch: 6 | Iteration: 300 | Classification loss: 0.25159 | Regression loss: 0.24656 | Running loss: 0.57476\n",
      "Epoch: 6 | Iteration: 301 | Classification loss: 0.37601 | Regression loss: 0.35328 | Running loss: 0.57479\n",
      "Epoch: 6 | Iteration: 302 | Classification loss: 0.22254 | Regression loss: 0.22984 | Running loss: 0.57460\n",
      "Epoch: 6 | Iteration: 303 | Classification loss: 0.18113 | Regression loss: 0.36892 | Running loss: 0.57441\n",
      "Epoch: 6 | Iteration: 304 | Classification loss: 0.16719 | Regression loss: 0.30967 | Running loss: 0.57423\n",
      "Epoch: 6 | Iteration: 305 | Classification loss: 0.32078 | Regression loss: 0.24502 | Running loss: 0.57379\n",
      "Epoch: 6 | Iteration: 306 | Classification loss: 0.39857 | Regression loss: 0.34598 | Running loss: 0.57425\n",
      "Epoch: 6 | Iteration: 307 | Classification loss: 0.27176 | Regression loss: 0.37604 | Running loss: 0.57489\n",
      "Epoch: 6 | Iteration: 308 | Classification loss: 0.10000 | Regression loss: 0.22623 | Running loss: 0.57416\n",
      "Epoch: 6 | Iteration: 309 | Classification loss: 0.20259 | Regression loss: 0.25020 | Running loss: 0.57382\n",
      "Epoch: 6 | Iteration: 310 | Classification loss: 0.17429 | Regression loss: 0.31427 | Running loss: 0.57371\n",
      "Epoch: 6 | Iteration: 311 | Classification loss: 0.29536 | Regression loss: 0.46615 | Running loss: 0.57235\n",
      "Epoch: 6 | Iteration: 312 | Classification loss: 0.11780 | Regression loss: 0.33361 | Running loss: 0.57217\n",
      "Epoch: 6 | Iteration: 313 | Classification loss: 0.07316 | Regression loss: 0.44065 | Running loss: 0.57146\n",
      "Epoch: 6 | Iteration: 314 | Classification loss: 0.29467 | Regression loss: 0.21329 | Running loss: 0.57120\n",
      "Epoch: 6 | Iteration: 315 | Classification loss: 0.17774 | Regression loss: 0.31149 | Running loss: 0.57091\n",
      "Epoch: 6 | Iteration: 316 | Classification loss: 0.17082 | Regression loss: 0.26992 | Running loss: 0.56996\n",
      "Epoch: 6 | Iteration: 317 | Classification loss: 0.23059 | Regression loss: 0.35514 | Running loss: 0.57005\n",
      "Epoch: 6 | Iteration: 318 | Classification loss: 0.10397 | Regression loss: 0.37898 | Running loss: 0.56938\n",
      "Epoch: 6 | Iteration: 319 | Classification loss: 0.12266 | Regression loss: 0.23523 | Running loss: 0.56894\n",
      "Epoch: 6 | Iteration: 320 | Classification loss: 0.22802 | Regression loss: 0.26412 | Running loss: 0.56780\n",
      "Epoch: 6 | Iteration: 321 | Classification loss: 0.43747 | Regression loss: 0.14978 | Running loss: 0.56790\n",
      "Epoch: 6 | Iteration: 322 | Classification loss: 0.36892 | Regression loss: 0.56850 | Running loss: 0.56853\n",
      "Epoch: 6 | Iteration: 323 | Classification loss: 0.15156 | Regression loss: 0.22380 | Running loss: 0.56763\n",
      "Epoch: 6 | Iteration: 324 | Classification loss: 0.13056 | Regression loss: 0.29309 | Running loss: 0.56717\n",
      "Epoch: 6 | Iteration: 325 | Classification loss: 0.50167 | Regression loss: 0.44419 | Running loss: 0.56784\n",
      "Epoch: 6 | Iteration: 326 | Classification loss: 0.35227 | Regression loss: 0.25945 | Running loss: 0.56775\n",
      "Epoch: 6 | Iteration: 327 | Classification loss: 0.10373 | Regression loss: 0.27200 | Running loss: 0.56715\n",
      "Epoch: 6 | Iteration: 328 | Classification loss: 0.15049 | Regression loss: 0.28204 | Running loss: 0.56659\n",
      "Epoch: 6 | Iteration: 329 | Classification loss: 0.16754 | Regression loss: 0.17139 | Running loss: 0.56617\n",
      "Epoch: 6 | Iteration: 330 | Classification loss: 0.13488 | Regression loss: 0.22048 | Running loss: 0.56500\n",
      "Epoch: 6 | Iteration: 331 | Classification loss: 0.27793 | Regression loss: 0.11283 | Running loss: 0.56488\n",
      "Epoch: 6 | Iteration: 332 | Classification loss: 0.33140 | Regression loss: 0.19234 | Running loss: 0.56404\n",
      "Epoch: 6 | Iteration: 333 | Classification loss: 0.17628 | Regression loss: 0.22370 | Running loss: 0.56388\n",
      "Epoch: 6 | Iteration: 334 | Classification loss: 0.26914 | Regression loss: 0.14877 | Running loss: 0.56326\n",
      "Epoch: 6 | Iteration: 335 | Classification loss: 0.10314 | Regression loss: 0.26756 | Running loss: 0.56334\n",
      "Epoch: 6 | Iteration: 336 | Classification loss: 0.32758 | Regression loss: 0.64141 | Running loss: 0.56440\n",
      "Epoch: 6 | Iteration: 337 | Classification loss: 0.33659 | Regression loss: 0.62650 | Running loss: 0.56429\n",
      "Epoch: 6 | Iteration: 338 | Classification loss: 0.35615 | Regression loss: 0.25239 | Running loss: 0.56447\n",
      "Epoch: 6 | Iteration: 339 | Classification loss: 0.15245 | Regression loss: 0.30381 | Running loss: 0.56475\n",
      "Epoch: 6 | Iteration: 340 | Classification loss: 0.24564 | Regression loss: 0.25758 | Running loss: 0.56489\n",
      "Epoch: 6 | Iteration: 341 | Classification loss: 0.32276 | Regression loss: 0.37201 | Running loss: 0.56541\n",
      "Epoch: 6 | Iteration: 342 | Classification loss: 0.11355 | Regression loss: 0.32382 | Running loss: 0.56548\n",
      "Epoch: 6 | Iteration: 343 | Classification loss: 0.10239 | Regression loss: 0.44904 | Running loss: 0.56525\n",
      "Epoch: 6 | Iteration: 344 | Classification loss: 0.15975 | Regression loss: 0.55302 | Running loss: 0.56525\n",
      "Epoch: 6 | Iteration: 345 | Classification loss: 0.20379 | Regression loss: 0.29327 | Running loss: 0.56462\n",
      "Epoch: 6 | Iteration: 346 | Classification loss: 0.36477 | Regression loss: 0.59655 | Running loss: 0.56578\n",
      "Epoch: 6 | Iteration: 347 | Classification loss: 0.11630 | Regression loss: 0.39298 | Running loss: 0.56612\n",
      "Epoch: 6 | Iteration: 348 | Classification loss: 0.33118 | Regression loss: 0.55171 | Running loss: 0.56730\n",
      "Epoch: 6 | Iteration: 349 | Classification loss: 0.43263 | Regression loss: 0.32661 | Running loss: 0.56773\n",
      "Epoch: 6 | Iteration: 350 | Classification loss: 0.14879 | Regression loss: 0.29775 | Running loss: 0.56783\n",
      "Epoch: 6 | Iteration: 351 | Classification loss: 0.27276 | Regression loss: 0.48435 | Running loss: 0.56822\n",
      "Epoch: 6 | Iteration: 352 | Classification loss: 0.25287 | Regression loss: 0.28223 | Running loss: 0.56752\n",
      "Epoch: 6 | Iteration: 353 | Classification loss: 0.07179 | Regression loss: 0.18955 | Running loss: 0.56638\n",
      "Epoch: 6 | Iteration: 354 | Classification loss: 0.27883 | Regression loss: 0.42194 | Running loss: 0.56640\n",
      "Epoch: 6 | Iteration: 355 | Classification loss: 0.24197 | Regression loss: 0.33123 | Running loss: 0.56677\n",
      "Epoch: 6 | Iteration: 356 | Classification loss: 0.11012 | Regression loss: 0.11566 | Running loss: 0.56567\n",
      "Epoch: 6 | Iteration: 357 | Classification loss: 0.22687 | Regression loss: 0.37600 | Running loss: 0.56616\n",
      "Epoch: 6 | Iteration: 358 | Classification loss: 0.40389 | Regression loss: 0.37267 | Running loss: 0.56664\n",
      "Epoch: 6 | Iteration: 359 | Classification loss: 0.10505 | Regression loss: 0.27345 | Running loss: 0.56529\n",
      "Epoch: 6 | Iteration: 360 | Classification loss: 0.30244 | Regression loss: 0.48917 | Running loss: 0.56591\n",
      "Epoch: 6 | Iteration: 361 | Classification loss: 0.04413 | Regression loss: 0.11941 | Running loss: 0.56404\n",
      "Epoch: 6 | Iteration: 362 | Classification loss: 0.12972 | Regression loss: 0.34853 | Running loss: 0.56432\n",
      "Epoch: 6 | Iteration: 363 | Classification loss: 0.15083 | Regression loss: 0.28209 | Running loss: 0.56416\n",
      "Epoch: 6 | Iteration: 364 | Classification loss: 0.44999 | Regression loss: 0.52730 | Running loss: 0.56409\n",
      "Epoch: 6 | Iteration: 365 | Classification loss: 0.25229 | Regression loss: 0.62185 | Running loss: 0.56429\n",
      "Epoch: 6 | Iteration: 366 | Classification loss: 0.15856 | Regression loss: 0.33550 | Running loss: 0.56404\n",
      "Epoch: 6 | Iteration: 367 | Classification loss: 0.30542 | Regression loss: 0.37568 | Running loss: 0.56438\n",
      "Epoch: 6 | Iteration: 368 | Classification loss: 0.10354 | Regression loss: 0.09334 | Running loss: 0.56359\n",
      "Epoch: 6 | Iteration: 369 | Classification loss: 0.35558 | Regression loss: 0.17321 | Running loss: 0.56371\n",
      "Epoch: 6 | Iteration: 370 | Classification loss: 0.10081 | Regression loss: 0.20572 | Running loss: 0.56277\n",
      "Epoch: 6 | Iteration: 371 | Classification loss: 0.15005 | Regression loss: 0.27776 | Running loss: 0.56257\n",
      "Epoch: 6 | Iteration: 372 | Classification loss: 0.32337 | Regression loss: 0.27513 | Running loss: 0.56297\n",
      "Epoch: 6 | Iteration: 373 | Classification loss: 0.56692 | Regression loss: 0.19949 | Running loss: 0.56248\n",
      "Epoch: 6 | Iteration: 374 | Classification loss: 0.22074 | Regression loss: 0.22182 | Running loss: 0.56220\n",
      "Epoch: 6 | Iteration: 375 | Classification loss: 0.16944 | Regression loss: 0.33995 | Running loss: 0.56205\n",
      "Epoch: 6 | Iteration: 376 | Classification loss: 0.11925 | Regression loss: 0.26855 | Running loss: 0.56172\n",
      "Epoch: 6 | Iteration: 377 | Classification loss: 0.32416 | Regression loss: 0.19378 | Running loss: 0.56136\n",
      "Epoch: 6 | Iteration: 378 | Classification loss: 0.43858 | Regression loss: 0.41520 | Running loss: 0.56201\n",
      "Epoch: 6 | Iteration: 379 | Classification loss: 0.19433 | Regression loss: 0.31394 | Running loss: 0.56181\n",
      "Epoch: 6 | Iteration: 380 | Classification loss: 0.25954 | Regression loss: 0.47643 | Running loss: 0.56264\n",
      "Epoch: 6 | Iteration: 381 | Classification loss: 0.09462 | Regression loss: 0.28895 | Running loss: 0.56193\n",
      "Epoch: 6 | Iteration: 382 | Classification loss: 0.33927 | Regression loss: 0.34761 | Running loss: 0.56213\n",
      "Epoch: 6 | Iteration: 383 | Classification loss: 0.09551 | Regression loss: 0.29494 | Running loss: 0.55897\n",
      "Epoch: 6 | Iteration: 384 | Classification loss: 0.13336 | Regression loss: 0.44529 | Running loss: 0.55917\n",
      "Epoch: 6 | Iteration: 385 | Classification loss: 0.07374 | Regression loss: 0.39780 | Running loss: 0.55916\n",
      "Epoch: 6 | Iteration: 386 | Classification loss: 0.34289 | Regression loss: 0.45369 | Running loss: 0.55968\n",
      "Epoch: 6 | Iteration: 387 | Classification loss: 0.07654 | Regression loss: 0.27128 | Running loss: 0.55952\n",
      "Epoch: 6 | Iteration: 388 | Classification loss: 0.24884 | Regression loss: 0.26679 | Running loss: 0.55965\n",
      "Epoch: 6 | Iteration: 389 | Classification loss: 0.15925 | Regression loss: 0.34662 | Running loss: 0.55990\n",
      "Epoch: 6 | Iteration: 390 | Classification loss: 0.45099 | Regression loss: 0.56684 | Running loss: 0.56093\n",
      "Epoch: 6 | Iteration: 391 | Classification loss: 0.21371 | Regression loss: 0.32675 | Running loss: 0.56097\n",
      "Epoch: 6 | Iteration: 392 | Classification loss: 0.22282 | Regression loss: 0.43574 | Running loss: 0.56192\n",
      "Epoch: 6 | Iteration: 393 | Classification loss: 0.39569 | Regression loss: 0.39577 | Running loss: 0.56282\n",
      "Epoch: 6 | Iteration: 394 | Classification loss: 0.12760 | Regression loss: 0.27819 | Running loss: 0.56286\n",
      "Epoch: 6 | Iteration: 395 | Classification loss: 0.12191 | Regression loss: 0.28852 | Running loss: 0.56217\n",
      "Epoch: 6 | Iteration: 396 | Classification loss: 0.14915 | Regression loss: 0.20284 | Running loss: 0.56201\n",
      "Epoch: 6 | Iteration: 397 | Classification loss: 0.12617 | Regression loss: 0.27181 | Running loss: 0.56166\n",
      "Epoch: 6 | Iteration: 398 | Classification loss: 0.25418 | Regression loss: 0.33867 | Running loss: 0.56206\n",
      "Epoch: 6 | Iteration: 399 | Classification loss: 0.08734 | Regression loss: 0.17527 | Running loss: 0.56142\n",
      "Epoch: 6 | Iteration: 400 | Classification loss: 0.07555 | Regression loss: 0.20252 | Running loss: 0.56081\n",
      "Epoch: 6 | Iteration: 401 | Classification loss: 0.22050 | Regression loss: 0.21974 | Running loss: 0.56033\n",
      "Epoch: 6 | Iteration: 402 | Classification loss: 0.42237 | Regression loss: 0.18146 | Running loss: 0.56012\n",
      "Epoch: 6 | Iteration: 403 | Classification loss: 0.05790 | Regression loss: 0.27382 | Running loss: 0.55976\n",
      "Epoch: 6 | Iteration: 404 | Classification loss: 0.16289 | Regression loss: 0.37662 | Running loss: 0.55928\n",
      "Epoch: 6 | Iteration: 405 | Classification loss: 0.08155 | Regression loss: 0.30042 | Running loss: 0.55925\n",
      "Epoch: 6 | Iteration: 406 | Classification loss: 0.17589 | Regression loss: 0.30929 | Running loss: 0.55974\n",
      "Epoch: 6 | Iteration: 407 | Classification loss: 0.37494 | Regression loss: 0.48664 | Running loss: 0.56061\n",
      "Epoch: 6 | Iteration: 408 | Classification loss: 0.22445 | Regression loss: 0.34811 | Running loss: 0.56078\n",
      "Epoch: 6 | Iteration: 409 | Classification loss: 0.08049 | Regression loss: 0.24139 | Running loss: 0.56056\n",
      "Epoch: 6 | Iteration: 410 | Classification loss: 0.26798 | Regression loss: 0.50984 | Running loss: 0.56123\n",
      "Epoch: 6 | Iteration: 411 | Classification loss: 0.36261 | Regression loss: 0.41891 | Running loss: 0.56182\n",
      "Epoch: 6 | Iteration: 412 | Classification loss: 0.23005 | Regression loss: 0.36824 | Running loss: 0.56184\n",
      "Epoch: 6 | Iteration: 413 | Classification loss: 0.34850 | Regression loss: 0.16550 | Running loss: 0.56154\n",
      "Epoch: 6 | Iteration: 414 | Classification loss: 0.13980 | Regression loss: 0.49313 | Running loss: 0.56114\n",
      "Epoch: 6 | Iteration: 415 | Classification loss: 0.19452 | Regression loss: 0.42142 | Running loss: 0.56116\n",
      "Epoch: 6 | Iteration: 416 | Classification loss: 0.16613 | Regression loss: 0.24132 | Running loss: 0.56059\n",
      "Epoch: 6 | Iteration: 417 | Classification loss: 0.25337 | Regression loss: 0.61275 | Running loss: 0.56095\n",
      "Epoch: 6 | Iteration: 418 | Classification loss: 0.05016 | Regression loss: 0.28116 | Running loss: 0.56119\n",
      "Epoch: 6 | Iteration: 419 | Classification loss: 0.10448 | Regression loss: 0.27364 | Running loss: 0.56031\n",
      "Epoch: 6 | Iteration: 420 | Classification loss: 0.20657 | Regression loss: 0.34153 | Running loss: 0.56008\n",
      "Epoch: 6 | Iteration: 421 | Classification loss: 0.22797 | Regression loss: 0.40377 | Running loss: 0.55986\n",
      "Epoch: 6 | Iteration: 422 | Classification loss: 0.13994 | Regression loss: 0.39612 | Running loss: 0.55994\n",
      "Epoch: 6 | Iteration: 423 | Classification loss: 0.11357 | Regression loss: 0.20712 | Running loss: 0.55984\n",
      "Epoch: 6 | Iteration: 424 | Classification loss: 0.24162 | Regression loss: 0.22632 | Running loss: 0.55998\n",
      "Epoch: 6 | Iteration: 425 | Classification loss: 0.27664 | Regression loss: 0.33827 | Running loss: 0.55987\n",
      "Epoch: 6 | Iteration: 426 | Classification loss: 0.22821 | Regression loss: 0.25554 | Running loss: 0.55969\n",
      "Epoch: 6 | Iteration: 427 | Classification loss: 0.17263 | Regression loss: 0.29866 | Running loss: 0.55892\n",
      "Epoch: 6 | Iteration: 428 | Classification loss: 0.23911 | Regression loss: 0.41433 | Running loss: 0.55906\n",
      "Epoch: 6 | Iteration: 429 | Classification loss: 0.14059 | Regression loss: 0.32107 | Running loss: 0.55854\n",
      "Epoch: 6 | Iteration: 430 | Classification loss: 0.16598 | Regression loss: 0.15411 | Running loss: 0.55838\n",
      "Epoch: 6 | Iteration: 431 | Classification loss: 0.18214 | Regression loss: 0.50252 | Running loss: 0.55871\n",
      "Epoch: 6 | Iteration: 432 | Classification loss: 0.29998 | Regression loss: 0.50208 | Running loss: 0.55888\n",
      "Epoch: 6 | Iteration: 433 | Classification loss: 0.11827 | Regression loss: 0.24803 | Running loss: 0.55822\n",
      "Epoch: 6 | Iteration: 434 | Classification loss: 0.25944 | Regression loss: 0.29882 | Running loss: 0.55863\n",
      "Epoch: 6 | Iteration: 435 | Classification loss: 0.09795 | Regression loss: 0.28466 | Running loss: 0.55815\n",
      "Epoch: 6 | Iteration: 436 | Classification loss: 0.13630 | Regression loss: 0.27371 | Running loss: 0.55824\n",
      "Epoch: 6 | Iteration: 437 | Classification loss: 0.30288 | Regression loss: 0.19075 | Running loss: 0.55793\n",
      "Epoch: 6 | Iteration: 438 | Classification loss: 0.11600 | Regression loss: 0.38919 | Running loss: 0.55805\n",
      "Epoch: 6 | Iteration: 439 | Classification loss: 0.14966 | Regression loss: 0.21327 | Running loss: 0.55780\n",
      "Epoch: 6 | Iteration: 440 | Classification loss: 0.18690 | Regression loss: 0.27577 | Running loss: 0.55808\n",
      "Epoch: 6 | Iteration: 441 | Classification loss: 0.33696 | Regression loss: 0.38888 | Running loss: 0.55756\n",
      "Epoch: 6 | Iteration: 442 | Classification loss: 0.41233 | Regression loss: 0.61567 | Running loss: 0.55869\n",
      "Epoch: 6 | Iteration: 443 | Classification loss: 0.08013 | Regression loss: 0.28177 | Running loss: 0.55815\n",
      "Epoch: 6 | Iteration: 444 | Classification loss: 0.16719 | Regression loss: 0.21881 | Running loss: 0.55722\n",
      "Epoch: 6 | Iteration: 445 | Classification loss: 0.22540 | Regression loss: 0.48320 | Running loss: 0.55742\n",
      "Epoch: 6 | Iteration: 446 | Classification loss: 0.31093 | Regression loss: 0.54141 | Running loss: 0.55829\n",
      "Epoch: 6 | Iteration: 447 | Classification loss: 0.16533 | Regression loss: 0.35736 | Running loss: 0.55834\n",
      "Epoch: 6 | Iteration: 448 | Classification loss: 0.15529 | Regression loss: 0.32734 | Running loss: 0.55699\n",
      "Epoch: 6 | Iteration: 449 | Classification loss: 0.29987 | Regression loss: 0.25770 | Running loss: 0.55686\n",
      "Epoch: 6 | Iteration: 450 | Classification loss: 0.18746 | Regression loss: 0.26405 | Running loss: 0.55665\n",
      "Epoch: 6 | Iteration: 451 | Classification loss: 0.15720 | Regression loss: 0.10874 | Running loss: 0.55645\n",
      "Epoch: 6 | Iteration: 452 | Classification loss: 0.32548 | Regression loss: 0.30228 | Running loss: 0.55645\n",
      "Epoch: 6 | Iteration: 453 | Classification loss: 0.16951 | Regression loss: 0.21073 | Running loss: 0.55622\n",
      "Epoch: 6 | Iteration: 454 | Classification loss: 0.06298 | Regression loss: 0.25513 | Running loss: 0.55541\n",
      "Epoch: 6 | Iteration: 455 | Classification loss: 0.11041 | Regression loss: 0.39530 | Running loss: 0.55520\n",
      "Epoch: 6 | Iteration: 456 | Classification loss: 0.08407 | Regression loss: 0.34718 | Running loss: 0.55436\n",
      "Epoch: 6 | Iteration: 457 | Classification loss: 0.26622 | Regression loss: 0.30613 | Running loss: 0.55327\n",
      "Epoch: 6 | Iteration: 458 | Classification loss: 0.19647 | Regression loss: 0.13996 | Running loss: 0.55289\n",
      "Epoch: 6 | Iteration: 459 | Classification loss: 0.27201 | Regression loss: 0.37932 | Running loss: 0.55350\n",
      "Epoch: 6 | Iteration: 460 | Classification loss: 0.41938 | Regression loss: 0.25117 | Running loss: 0.55390\n",
      "Epoch: 6 | Iteration: 461 | Classification loss: 0.25026 | Regression loss: 0.30456 | Running loss: 0.55355\n",
      "Epoch: 6 | Iteration: 462 | Classification loss: 0.16334 | Regression loss: 0.33459 | Running loss: 0.55336\n",
      "Epoch: 6 | Iteration: 463 | Classification loss: 0.25381 | Regression loss: 0.58882 | Running loss: 0.55347\n",
      "Epoch: 6 | Iteration: 464 | Classification loss: 0.32621 | Regression loss: 0.38661 | Running loss: 0.55366\n",
      "Epoch: 6 | Iteration: 465 | Classification loss: 0.21714 | Regression loss: 0.31637 | Running loss: 0.55281\n",
      "Epoch: 6 | Iteration: 466 | Classification loss: 0.24186 | Regression loss: 0.53144 | Running loss: 0.55341\n",
      "Epoch: 6 | Iteration: 467 | Classification loss: 0.20097 | Regression loss: 0.26573 | Running loss: 0.55281\n",
      "Epoch: 6 | Iteration: 468 | Classification loss: 0.12115 | Regression loss: 0.25225 | Running loss: 0.55215\n",
      "Epoch: 6 | Iteration: 469 | Classification loss: 0.20483 | Regression loss: 0.24498 | Running loss: 0.55222\n",
      "Epoch: 6 | Iteration: 470 | Classification loss: 0.36794 | Regression loss: 0.11763 | Running loss: 0.55193\n",
      "Epoch: 6 | Iteration: 471 | Classification loss: 0.23040 | Regression loss: 0.34901 | Running loss: 0.55220\n",
      "Epoch: 6 | Iteration: 472 | Classification loss: 0.08411 | Regression loss: 0.41003 | Running loss: 0.55156\n",
      "Epoch: 6 | Iteration: 473 | Classification loss: 0.24158 | Regression loss: 0.19971 | Running loss: 0.55056\n",
      "Epoch: 6 | Iteration: 474 | Classification loss: 0.59895 | Regression loss: 0.51803 | Running loss: 0.55228\n",
      "Epoch: 6 | Iteration: 475 | Classification loss: 0.12178 | Regression loss: 0.24437 | Running loss: 0.55220\n",
      "Epoch: 6 | Iteration: 476 | Classification loss: 0.10658 | Regression loss: 0.31672 | Running loss: 0.55214\n",
      "Epoch: 6 | Iteration: 477 | Classification loss: 0.13252 | Regression loss: 0.25792 | Running loss: 0.55203\n",
      "Epoch: 6 | Iteration: 478 | Classification loss: 0.33269 | Regression loss: 0.31741 | Running loss: 0.55333\n",
      "Epoch: 6 | Iteration: 479 | Classification loss: 0.28635 | Regression loss: 0.58415 | Running loss: 0.55407\n",
      "Epoch: 6 | Iteration: 480 | Classification loss: 0.22751 | Regression loss: 0.21833 | Running loss: 0.55392\n",
      "Epoch: 6 | Iteration: 481 | Classification loss: 0.25292 | Regression loss: 0.39653 | Running loss: 0.55396\n",
      "Epoch: 6 | Iteration: 482 | Classification loss: 0.19728 | Regression loss: 0.37506 | Running loss: 0.55439\n",
      "Epoch: 6 | Iteration: 483 | Classification loss: 0.21636 | Regression loss: 0.45676 | Running loss: 0.55437\n",
      "Epoch: 6 | Iteration: 484 | Classification loss: 0.58117 | Regression loss: 0.36045 | Running loss: 0.55443\n",
      "Epoch: 6 | Iteration: 485 | Classification loss: 0.19479 | Regression loss: 0.22472 | Running loss: 0.55486\n",
      "Epoch: 6 | Iteration: 486 | Classification loss: 0.15297 | Regression loss: 0.21233 | Running loss: 0.55353\n",
      "Epoch: 6 | Iteration: 487 | Classification loss: 0.19789 | Regression loss: 0.29111 | Running loss: 0.55339\n",
      "Epoch: 6 | Iteration: 488 | Classification loss: 0.18996 | Regression loss: 0.29560 | Running loss: 0.55276\n",
      "Epoch: 6 | Iteration: 489 | Classification loss: 0.17235 | Regression loss: 0.30547 | Running loss: 0.55294\n",
      "Epoch: 6 | Iteration: 490 | Classification loss: 0.07090 | Regression loss: 0.26936 | Running loss: 0.55259\n",
      "Epoch: 6 | Iteration: 491 | Classification loss: 0.27373 | Regression loss: 0.23612 | Running loss: 0.55228\n",
      "Epoch: 6 | Iteration: 492 | Classification loss: 0.15668 | Regression loss: 0.39722 | Running loss: 0.55200\n",
      "Epoch: 6 | Iteration: 493 | Classification loss: 0.00242 | Regression loss: 0.00000 | Running loss: 0.55052\n",
      "Epoch: 6 | Iteration: 494 | Classification loss: 0.30670 | Regression loss: 0.21803 | Running loss: 0.55086\n",
      "Epoch: 6 | Iteration: 495 | Classification loss: 0.16228 | Regression loss: 0.28133 | Running loss: 0.55084\n",
      "Epoch: 6 | Iteration: 496 | Classification loss: 0.38343 | Regression loss: 0.54114 | Running loss: 0.55187\n",
      "Epoch: 6 | Iteration: 497 | Classification loss: 0.05228 | Regression loss: 0.24805 | Running loss: 0.55190\n",
      "Epoch: 6 | Iteration: 498 | Classification loss: 0.23664 | Regression loss: 0.39572 | Running loss: 0.55222\n",
      "Epoch: 6 | Iteration: 499 | Classification loss: 0.10763 | Regression loss: 0.21810 | Running loss: 0.55164\n",
      "Epoch: 6 | Iteration: 500 | Classification loss: 0.06128 | Regression loss: 0.22243 | Running loss: 0.55142\n",
      "Epoch: 6 | Iteration: 501 | Classification loss: 0.26345 | Regression loss: 0.36428 | Running loss: 0.55236\n",
      "Epoch: 6 | Iteration: 502 | Classification loss: 0.04553 | Regression loss: 0.22937 | Running loss: 0.55156\n",
      "Epoch: 6 | Iteration: 503 | Classification loss: 0.06722 | Regression loss: 0.24696 | Running loss: 0.54894\n",
      "Epoch: 6 | Iteration: 504 | Classification loss: 0.08985 | Regression loss: 0.45356 | Running loss: 0.54948\n",
      "Epoch: 6 | Iteration: 505 | Classification loss: 0.38925 | Regression loss: 0.46569 | Running loss: 0.55038\n",
      "Epoch: 6 | Iteration: 506 | Classification loss: 0.20373 | Regression loss: 0.39729 | Running loss: 0.55078\n",
      "Epoch: 6 | Iteration: 507 | Classification loss: 0.09133 | Regression loss: 0.26837 | Running loss: 0.55022\n",
      "Epoch: 6 | Iteration: 508 | Classification loss: 0.44389 | Regression loss: 0.37678 | Running loss: 0.55025\n",
      "Epoch: 6 | Iteration: 509 | Classification loss: 0.14487 | Regression loss: 0.35364 | Running loss: 0.55041\n",
      "Epoch: 6 | Iteration: 510 | Classification loss: 0.28949 | Regression loss: 0.47225 | Running loss: 0.55111\n",
      "Epoch: 6 | Iteration: 511 | Classification loss: 0.06475 | Regression loss: 0.29375 | Running loss: 0.55055\n",
      "Epoch: 6 | Iteration: 512 | Classification loss: 0.13930 | Regression loss: 0.20740 | Running loss: 0.55021\n",
      "Epoch: 6 | Iteration: 513 | Classification loss: 0.45618 | Regression loss: 0.47547 | Running loss: 0.55105\n",
      "Epoch: 6 | Iteration: 514 | Classification loss: 0.24152 | Regression loss: 0.27650 | Running loss: 0.55006\n",
      "Epoch: 6 | Iteration: 515 | Classification loss: 0.44719 | Regression loss: 0.30573 | Running loss: 0.55041\n",
      "Epoch: 6 | Iteration: 516 | Classification loss: 0.21611 | Regression loss: 0.38595 | Running loss: 0.55010\n",
      "Epoch: 6 | Iteration: 517 | Classification loss: 0.45764 | Regression loss: 0.65898 | Running loss: 0.55045\n",
      "Epoch: 6 | Iteration: 518 | Classification loss: 0.08156 | Regression loss: 0.17456 | Running loss: 0.55033\n",
      "Epoch: 6 | Iteration: 519 | Classification loss: 0.61638 | Regression loss: 0.25027 | Running loss: 0.55013\n",
      "Epoch: 6 | Iteration: 520 | Classification loss: 0.13100 | Regression loss: 0.26913 | Running loss: 0.54996\n",
      "Epoch: 6 | Iteration: 521 | Classification loss: 0.18580 | Regression loss: 0.25142 | Running loss: 0.54977\n",
      "Epoch: 6 | Iteration: 522 | Classification loss: 0.24136 | Regression loss: 0.33033 | Running loss: 0.54996\n",
      "Epoch: 6 | Iteration: 523 | Classification loss: 0.13774 | Regression loss: 0.30617 | Running loss: 0.54985\n",
      "Epoch: 6 | Iteration: 524 | Classification loss: 0.21507 | Regression loss: 0.29660 | Running loss: 0.54935\n",
      "Epoch: 6 | Iteration: 525 | Classification loss: 0.46535 | Regression loss: 0.61799 | Running loss: 0.55081\n",
      "Epoch: 6 | Iteration: 526 | Classification loss: 0.06121 | Regression loss: 0.34073 | Running loss: 0.55103\n",
      "Epoch: 6 | Iteration: 527 | Classification loss: 0.33798 | Regression loss: 0.53744 | Running loss: 0.55206\n",
      "Epoch: 6 | Iteration: 528 | Classification loss: 0.32751 | Regression loss: 0.31787 | Running loss: 0.55204\n",
      "Epoch: 6 | Iteration: 529 | Classification loss: 0.07144 | Regression loss: 0.30152 | Running loss: 0.55173\n",
      "Epoch: 6 | Iteration: 530 | Classification loss: 0.27430 | Regression loss: 0.25957 | Running loss: 0.55222\n",
      "Epoch: 6 | Iteration: 531 | Classification loss: 0.07272 | Regression loss: 0.23848 | Running loss: 0.55193\n",
      "Epoch: 6 | Iteration: 532 | Classification loss: 0.11485 | Regression loss: 0.34610 | Running loss: 0.55208\n",
      "Epoch: 6 | Iteration: 533 | Classification loss: 0.52853 | Regression loss: 0.45171 | Running loss: 0.55335\n",
      "Epoch: 6 | Iteration: 534 | Classification loss: 0.24938 | Regression loss: 0.40359 | Running loss: 0.55405\n",
      "Epoch: 6 | Iteration: 535 | Classification loss: 0.15499 | Regression loss: 0.22182 | Running loss: 0.55374\n",
      "Epoch: 6 | Iteration: 536 | Classification loss: 0.27687 | Regression loss: 0.33268 | Running loss: 0.55401\n",
      "Epoch: 6 | Iteration: 537 | Classification loss: 0.21571 | Regression loss: 0.41553 | Running loss: 0.55218\n",
      "Epoch: 6 | Iteration: 538 | Classification loss: 0.20667 | Regression loss: 0.07178 | Running loss: 0.55215\n",
      "Epoch: 6 | Iteration: 539 | Classification loss: 0.13554 | Regression loss: 0.48267 | Running loss: 0.55224\n",
      "Epoch: 6 | Iteration: 540 | Classification loss: 0.27254 | Regression loss: 0.24222 | Running loss: 0.55270\n",
      "Epoch: 6 | Iteration: 541 | Classification loss: 0.41047 | Regression loss: 0.24211 | Running loss: 0.55307\n",
      "Epoch: 6 | Iteration: 542 | Classification loss: 0.22741 | Regression loss: 0.43358 | Running loss: 0.55326\n",
      "Epoch: 6 | Iteration: 543 | Classification loss: 0.43790 | Regression loss: 0.39104 | Running loss: 0.55390\n",
      "Epoch: 6 | Iteration: 544 | Classification loss: 0.40657 | Regression loss: 0.30705 | Running loss: 0.55340\n",
      "Epoch: 6 | Iteration: 545 | Classification loss: 0.12817 | Regression loss: 0.16652 | Running loss: 0.55250\n",
      "Epoch: 6 | Iteration: 546 | Classification loss: 0.11074 | Regression loss: 0.25259 | Running loss: 0.55195\n",
      "Epoch: 6 | Iteration: 547 | Classification loss: 0.23307 | Regression loss: 0.20861 | Running loss: 0.55179\n",
      "Epoch: 6 | Iteration: 548 | Classification loss: 0.04962 | Regression loss: 0.20642 | Running loss: 0.55086\n",
      "Epoch: 6 | Iteration: 549 | Classification loss: 0.17449 | Regression loss: 0.27742 | Running loss: 0.55034\n",
      "Epoch: 6 | Iteration: 550 | Classification loss: 0.14879 | Regression loss: 0.30783 | Running loss: 0.55065\n",
      "Epoch: 6 | Iteration: 551 | Classification loss: 0.24624 | Regression loss: 0.35913 | Running loss: 0.55116\n",
      "Epoch: 6 | Iteration: 552 | Classification loss: 0.22452 | Regression loss: 0.56441 | Running loss: 0.55142\n",
      "Epoch: 6 | Iteration: 553 | Classification loss: 0.29626 | Regression loss: 0.40199 | Running loss: 0.55193\n",
      "Epoch: 6 | Iteration: 554 | Classification loss: 0.49555 | Regression loss: 0.27996 | Running loss: 0.55242\n",
      "Epoch: 6 | Iteration: 555 | Classification loss: 0.21103 | Regression loss: 0.35475 | Running loss: 0.55234\n",
      "Epoch: 6 | Iteration: 556 | Classification loss: 0.17143 | Regression loss: 0.12842 | Running loss: 0.55065\n",
      "Epoch: 6 | Iteration: 557 | Classification loss: 0.25045 | Regression loss: 0.34576 | Running loss: 0.55060\n",
      "Epoch: 6 | Iteration: 558 | Classification loss: 0.06403 | Regression loss: 0.20136 | Running loss: 0.54996\n",
      "Epoch: 6 | Iteration: 559 | Classification loss: 0.31676 | Regression loss: 0.45031 | Running loss: 0.55051\n",
      "Epoch: 6 | Iteration: 560 | Classification loss: 0.38781 | Regression loss: 0.32719 | Running loss: 0.55113\n",
      "Epoch: 6 | Iteration: 561 | Classification loss: 0.04819 | Regression loss: 0.16944 | Running loss: 0.55038\n",
      "Epoch: 6 | Iteration: 562 | Classification loss: 0.32522 | Regression loss: 0.48781 | Running loss: 0.55109\n",
      "Epoch: 6 | Iteration: 563 | Classification loss: 0.10734 | Regression loss: 0.28109 | Running loss: 0.55122\n",
      "Epoch: 6 | Iteration: 564 | Classification loss: 0.06749 | Regression loss: 0.12335 | Running loss: 0.55090\n",
      "Epoch: 6 | Iteration: 565 | Classification loss: 0.45473 | Regression loss: 0.14483 | Running loss: 0.55116\n",
      "Epoch: 6 | Iteration: 566 | Classification loss: 0.09138 | Regression loss: 0.24960 | Running loss: 0.55006\n",
      "Epoch: 6 | Iteration: 567 | Classification loss: 0.26120 | Regression loss: 0.22280 | Running loss: 0.55021\n",
      "Epoch: 6 | Iteration: 568 | Classification loss: 0.28616 | Regression loss: 0.13545 | Running loss: 0.54975\n",
      "Epoch: 6 | Iteration: 569 | Classification loss: 0.12671 | Regression loss: 0.20258 | Running loss: 0.54944\n",
      "Epoch: 6 | Iteration: 570 | Classification loss: 0.08916 | Regression loss: 0.25327 | Running loss: 0.54970\n",
      "Epoch: 6 | Iteration: 571 | Classification loss: 0.21149 | Regression loss: 0.32362 | Running loss: 0.54969\n",
      "Epoch: 6 | Iteration: 572 | Classification loss: 0.19528 | Regression loss: 0.18532 | Running loss: 0.54948\n",
      "Epoch: 6 | Iteration: 573 | Classification loss: 0.13197 | Regression loss: 0.14497 | Running loss: 0.54897\n",
      "Epoch: 6 | Iteration: 574 | Classification loss: 0.03843 | Regression loss: 0.19594 | Running loss: 0.54837\n",
      "Epoch: 6 | Iteration: 575 | Classification loss: 0.43053 | Regression loss: 0.49155 | Running loss: 0.54852\n",
      "Epoch: 6 | Iteration: 576 | Classification loss: 0.64599 | Regression loss: 0.43506 | Running loss: 0.55010\n",
      "Epoch: 6 | Iteration: 577 | Classification loss: 0.27348 | Regression loss: 0.23184 | Running loss: 0.54820\n",
      "Epoch: 6 | Iteration: 578 | Classification loss: 0.12415 | Regression loss: 0.21146 | Running loss: 0.54793\n",
      "Epoch: 6 | Iteration: 579 | Classification loss: 0.27573 | Regression loss: 0.50749 | Running loss: 0.54895\n",
      "Epoch: 6 | Iteration: 580 | Classification loss: 0.52316 | Regression loss: 0.49742 | Running loss: 0.55026\n",
      "Epoch: 6 | Iteration: 581 | Classification loss: 0.45422 | Regression loss: 0.29493 | Running loss: 0.55031\n",
      "Epoch: 6 | Iteration: 582 | Classification loss: 0.53309 | Regression loss: 0.13737 | Running loss: 0.55093\n",
      "Epoch: 6 | Iteration: 583 | Classification loss: 0.25800 | Regression loss: 0.19267 | Running loss: 0.55123\n",
      "Epoch: 6 | Iteration: 584 | Classification loss: 0.28265 | Regression loss: 0.56035 | Running loss: 0.55203\n",
      "Epoch: 6 | Iteration: 585 | Classification loss: 0.33230 | Regression loss: 0.23391 | Running loss: 0.55158\n",
      "Epoch: 6 | Iteration: 586 | Classification loss: 0.30132 | Regression loss: 0.55277 | Running loss: 0.55237\n",
      "Epoch: 6 | Iteration: 587 | Classification loss: 0.38097 | Regression loss: 0.49219 | Running loss: 0.55298\n",
      "Epoch: 6 | Iteration: 588 | Classification loss: 0.04747 | Regression loss: 0.18763 | Running loss: 0.55171\n",
      "Epoch: 6 | Iteration: 589 | Classification loss: 0.19339 | Regression loss: 0.50147 | Running loss: 0.55234\n",
      "Epoch: 6 | Iteration: 590 | Classification loss: 0.23339 | Regression loss: 0.32197 | Running loss: 0.55275\n",
      "Epoch: 6 | Iteration: 591 | Classification loss: 0.37227 | Regression loss: 0.54871 | Running loss: 0.55313\n",
      "Epoch: 6 | Iteration: 592 | Classification loss: 0.14835 | Regression loss: 0.39289 | Running loss: 0.55177\n",
      "Epoch: 6 | Iteration: 593 | Classification loss: 0.27441 | Regression loss: 0.58078 | Running loss: 0.55234\n",
      "Epoch: 6 | Iteration: 594 | Classification loss: 0.21373 | Regression loss: 0.13803 | Running loss: 0.55194\n",
      "Epoch: 6 | Iteration: 595 | Classification loss: 0.34943 | Regression loss: 0.41534 | Running loss: 0.55241\n",
      "Epoch: 6 | Iteration: 596 | Classification loss: 0.23660 | Regression loss: 0.51195 | Running loss: 0.55285\n",
      "Epoch: 6 | Iteration: 597 | Classification loss: 0.08493 | Regression loss: 0.08441 | Running loss: 0.55171\n",
      "Epoch: 6 | Iteration: 598 | Classification loss: 0.16752 | Regression loss: 0.27227 | Running loss: 0.55158\n",
      "Epoch: 6 | Iteration: 599 | Classification loss: 0.46229 | Regression loss: 0.59170 | Running loss: 0.55261\n",
      "Epoch: 6 | Iteration: 600 | Classification loss: 0.54808 | Regression loss: 0.33719 | Running loss: 0.55363\n",
      "Epoch: 6 | Iteration: 601 | Classification loss: 0.21016 | Regression loss: 0.50843 | Running loss: 0.55254\n",
      "Epoch: 6 | Iteration: 602 | Classification loss: 0.24503 | Regression loss: 0.44745 | Running loss: 0.55294\n",
      "Epoch: 6 | Iteration: 603 | Classification loss: 0.15158 | Regression loss: 0.53379 | Running loss: 0.55366\n",
      "Epoch: 6 | Iteration: 604 | Classification loss: 0.23294 | Regression loss: 0.27130 | Running loss: 0.55409\n",
      "Epoch: 6 | Iteration: 605 | Classification loss: 0.23325 | Regression loss: 0.22568 | Running loss: 0.55454\n",
      "Epoch: 6 | Iteration: 606 | Classification loss: 0.18335 | Regression loss: 0.49316 | Running loss: 0.55530\n",
      "Epoch: 6 | Iteration: 607 | Classification loss: 0.06893 | Regression loss: 0.14408 | Running loss: 0.55455\n",
      "Epoch: 6 | Iteration: 608 | Classification loss: 0.13178 | Regression loss: 0.27965 | Running loss: 0.55408\n",
      "Epoch: 6 | Iteration: 609 | Classification loss: 0.18623 | Regression loss: 0.32642 | Running loss: 0.55419\n",
      "Epoch: 6 | Iteration: 610 | Classification loss: 0.23156 | Regression loss: 0.44685 | Running loss: 0.55455\n",
      "Epoch: 6 | Iteration: 611 | Classification loss: 0.13375 | Regression loss: 0.51336 | Running loss: 0.55510\n",
      "Epoch: 6 | Iteration: 612 | Classification loss: 0.08937 | Regression loss: 0.32579 | Running loss: 0.55530\n",
      "Epoch: 6 | Iteration: 613 | Classification loss: 0.32706 | Regression loss: 0.22396 | Running loss: 0.55536\n",
      "Epoch: 6 | Iteration: 614 | Classification loss: 0.14852 | Regression loss: 0.25564 | Running loss: 0.55568\n",
      "Epoch: 6 | Iteration: 615 | Classification loss: 0.28058 | Regression loss: 0.30732 | Running loss: 0.55588\n",
      "Epoch: 6 | Iteration: 616 | Classification loss: 0.13517 | Regression loss: 0.33181 | Running loss: 0.55607\n",
      "Epoch: 6 | Iteration: 617 | Classification loss: 0.33843 | Regression loss: 0.58927 | Running loss: 0.55693\n",
      "Epoch: 6 | Iteration: 618 | Classification loss: 0.10431 | Regression loss: 0.30965 | Running loss: 0.55683\n",
      "Epoch: 6 | Iteration: 619 | Classification loss: 0.38786 | Regression loss: 0.34137 | Running loss: 0.55732\n",
      "Epoch: 6 | Iteration: 620 | Classification loss: 0.21018 | Regression loss: 0.38558 | Running loss: 0.55776\n",
      "Epoch: 6 | Iteration: 621 | Classification loss: 0.21517 | Regression loss: 0.64435 | Running loss: 0.55830\n",
      "Epoch: 6 | Iteration: 622 | Classification loss: 0.20593 | Regression loss: 0.47663 | Running loss: 0.55897\n",
      "Epoch: 6 | Iteration: 623 | Classification loss: 0.15353 | Regression loss: 0.45407 | Running loss: 0.55921\n",
      "Epoch: 6 | Iteration: 624 | Classification loss: 0.09148 | Regression loss: 0.24296 | Running loss: 0.55932\n",
      "Epoch: 6 | Iteration: 625 | Classification loss: 0.46594 | Regression loss: 0.51584 | Running loss: 0.56037\n",
      "Epoch: 6 | Iteration: 626 | Classification loss: 0.34704 | Regression loss: 0.59430 | Running loss: 0.56100\n",
      "Epoch: 6 | Iteration: 627 | Classification loss: 0.34196 | Regression loss: 0.51840 | Running loss: 0.56117\n",
      "Epoch: 6 | Iteration: 628 | Classification loss: 0.28572 | Regression loss: 0.25336 | Running loss: 0.56161\n",
      "Epoch: 6 | Iteration: 629 | Classification loss: 0.08460 | Regression loss: 0.34530 | Running loss: 0.56004\n",
      "Epoch: 6 | Iteration: 630 | Classification loss: 0.07962 | Regression loss: 0.21830 | Running loss: 0.55970\n",
      "Epoch: 6 | Iteration: 631 | Classification loss: 0.27221 | Regression loss: 0.49782 | Running loss: 0.55943\n",
      "Epoch: 6 | Iteration: 632 | Classification loss: 0.23953 | Regression loss: 0.30963 | Running loss: 0.55962\n",
      "Epoch: 6 | Iteration: 633 | Classification loss: 0.25067 | Regression loss: 0.23652 | Running loss: 0.55978\n",
      "Epoch: 6 | Iteration: 634 | Classification loss: 0.25063 | Regression loss: 0.25116 | Running loss: 0.55883\n",
      "Epoch: 6 | Iteration: 635 | Classification loss: 0.25238 | Regression loss: 0.14787 | Running loss: 0.55875\n",
      "Epoch: 6 | Iteration: 636 | Classification loss: 0.14796 | Regression loss: 0.28777 | Running loss: 0.55868\n",
      "Epoch: 6 | Iteration: 637 | Classification loss: 0.18788 | Regression loss: 0.27252 | Running loss: 0.55849\n",
      "Epoch: 6 | Iteration: 638 | Classification loss: 0.24381 | Regression loss: 0.27778 | Running loss: 0.55795\n",
      "Epoch: 6 | Iteration: 639 | Classification loss: 0.05894 | Regression loss: 0.21737 | Running loss: 0.55728\n",
      "Epoch: 6 | Iteration: 640 | Classification loss: 0.24782 | Regression loss: 0.35779 | Running loss: 0.55725\n",
      "Epoch: 6 | Iteration: 641 | Classification loss: 0.30116 | Regression loss: 0.65454 | Running loss: 0.55772\n",
      "Epoch: 6 | Iteration: 642 | Classification loss: 0.43383 | Regression loss: 0.62242 | Running loss: 0.55883\n",
      "Epoch: 6 | Iteration: 643 | Classification loss: 0.14578 | Regression loss: 0.37715 | Running loss: 0.55786\n",
      "Epoch: 6 | Iteration: 644 | Classification loss: 0.11905 | Regression loss: 0.24137 | Running loss: 0.55760\n",
      "Epoch: 6 | Iteration: 645 | Classification loss: 0.14960 | Regression loss: 0.30153 | Running loss: 0.55718\n",
      "Epoch: 6 | Iteration: 646 | Classification loss: 0.09400 | Regression loss: 0.20470 | Running loss: 0.55693\n",
      "Epoch: 6 | Iteration: 647 | Classification loss: 0.15295 | Regression loss: 0.36159 | Running loss: 0.55662\n",
      "Epoch: 6 | Iteration: 648 | Classification loss: 0.19660 | Regression loss: 0.37490 | Running loss: 0.55697\n",
      "Epoch: 6 | Iteration: 649 | Classification loss: 0.23428 | Regression loss: 0.30622 | Running loss: 0.55597\n",
      "Epoch: 6 | Iteration: 650 | Classification loss: 0.27697 | Regression loss: 0.33088 | Running loss: 0.55607\n",
      "Epoch: 6 | Iteration: 651 | Classification loss: 0.36386 | Regression loss: 0.31759 | Running loss: 0.55605\n",
      "Epoch: 6 | Iteration: 652 | Classification loss: 0.36443 | Regression loss: 0.16554 | Running loss: 0.55584\n",
      "Epoch: 6 | Iteration: 653 | Classification loss: 0.37478 | Regression loss: 0.49982 | Running loss: 0.55580\n",
      "Epoch: 6 | Iteration: 654 | Classification loss: 0.17411 | Regression loss: 0.43278 | Running loss: 0.55570\n",
      "Epoch: 6 | Iteration: 655 | Classification loss: 0.24967 | Regression loss: 0.51123 | Running loss: 0.55622\n",
      "Epoch: 6 | Iteration: 656 | Classification loss: 0.11553 | Regression loss: 0.20941 | Running loss: 0.55533\n",
      "Epoch: 6 | Iteration: 657 | Classification loss: 0.15540 | Regression loss: 0.36006 | Running loss: 0.55537\n",
      "Epoch: 6 | Iteration: 658 | Classification loss: 0.17431 | Regression loss: 0.15853 | Running loss: 0.55457\n",
      "Epoch: 6 | Iteration: 659 | Classification loss: 0.24610 | Regression loss: 0.25815 | Running loss: 0.55392\n",
      "Epoch: 6 | Iteration: 660 | Classification loss: 0.17243 | Regression loss: 0.42934 | Running loss: 0.55405\n",
      "Epoch: 6 | Iteration: 661 | Classification loss: 0.17892 | Regression loss: 0.29126 | Running loss: 0.55406\n",
      "Epoch: 6 | Iteration: 662 | Classification loss: 0.17977 | Regression loss: 0.24184 | Running loss: 0.55398\n",
      "Epoch: 6 | Iteration: 663 | Classification loss: 0.20865 | Regression loss: 0.27673 | Running loss: 0.55428\n",
      "Epoch: 6 | Iteration: 664 | Classification loss: 0.12287 | Regression loss: 0.21262 | Running loss: 0.55425\n",
      "Epoch: 6 | Iteration: 665 | Classification loss: 0.41959 | Regression loss: 0.46740 | Running loss: 0.55506\n",
      "Epoch: 6 | Iteration: 666 | Classification loss: 0.20949 | Regression loss: 0.27087 | Running loss: 0.55397\n",
      "Epoch: 6 | Iteration: 667 | Classification loss: 0.24515 | Regression loss: 0.11731 | Running loss: 0.55389\n",
      "Epoch: 6 | Iteration: 668 | Classification loss: 0.10329 | Regression loss: 0.30267 | Running loss: 0.55343\n",
      "Epoch: 6 | Iteration: 669 | Classification loss: 0.43592 | Regression loss: 0.59157 | Running loss: 0.55444\n",
      "Epoch: 6 | Iteration: 670 | Classification loss: 0.23871 | Regression loss: 0.23863 | Running loss: 0.55385\n",
      "Epoch: 6 | Iteration: 671 | Classification loss: 0.32919 | Regression loss: 0.35837 | Running loss: 0.55367\n",
      "Epoch: 6 | Iteration: 672 | Classification loss: 0.11754 | Regression loss: 0.30421 | Running loss: 0.55336\n",
      "Epoch: 6 | Iteration: 673 | Classification loss: 0.06768 | Regression loss: 0.36655 | Running loss: 0.55343\n",
      "Epoch: 6 | Iteration: 674 | Classification loss: 0.10639 | Regression loss: 0.27932 | Running loss: 0.55277\n",
      "Epoch: 6 | Iteration: 675 | Classification loss: 0.16701 | Regression loss: 0.25084 | Running loss: 0.55222\n",
      "Epoch: 6 | Iteration: 676 | Classification loss: 0.21518 | Regression loss: 0.26731 | Running loss: 0.55215\n",
      "Epoch: 6 | Iteration: 677 | Classification loss: 0.19263 | Regression loss: 0.31745 | Running loss: 0.55203\n",
      "Epoch: 6 | Iteration: 678 | Classification loss: 0.32923 | Regression loss: 0.49150 | Running loss: 0.55245\n",
      "Epoch: 6 | Iteration: 679 | Classification loss: 0.37294 | Regression loss: 0.48243 | Running loss: 0.55314\n",
      "Epoch: 6 | Iteration: 680 | Classification loss: 0.30127 | Regression loss: 0.37426 | Running loss: 0.55270\n",
      "Epoch: 6 | Iteration: 681 | Classification loss: 0.14629 | Regression loss: 0.19205 | Running loss: 0.55193\n",
      "Epoch: 6 | Iteration: 682 | Classification loss: 0.33420 | Regression loss: 0.39045 | Running loss: 0.55179\n",
      "Epoch: 6 | Iteration: 683 | Classification loss: 0.34859 | Regression loss: 0.38025 | Running loss: 0.55164\n",
      "Epoch: 6 | Iteration: 684 | Classification loss: 0.35960 | Regression loss: 0.29071 | Running loss: 0.55226\n",
      "Epoch: 6 | Iteration: 685 | Classification loss: 0.13605 | Regression loss: 0.30569 | Running loss: 0.55224\n",
      "Epoch: 6 | Iteration: 686 | Classification loss: 0.51448 | Regression loss: 0.74766 | Running loss: 0.55358\n",
      "Epoch: 6 | Iteration: 687 | Classification loss: 0.36574 | Regression loss: 0.20779 | Running loss: 0.55391\n",
      "Epoch: 6 | Iteration: 688 | Classification loss: 0.10928 | Regression loss: 0.31474 | Running loss: 0.55389\n",
      "Epoch: 6 | Iteration: 689 | Classification loss: 0.21670 | Regression loss: 0.35525 | Running loss: 0.55356\n",
      "Epoch: 6 | Iteration: 690 | Classification loss: 0.35147 | Regression loss: 0.28536 | Running loss: 0.55364\n",
      "Epoch: 6 | Iteration: 691 | Classification loss: 0.16674 | Regression loss: 0.33241 | Running loss: 0.55331\n",
      "Epoch: 6 | Iteration: 692 | Classification loss: 0.13026 | Regression loss: 0.31197 | Running loss: 0.55271\n",
      "Epoch: 6 | Iteration: 693 | Classification loss: 0.15909 | Regression loss: 0.24738 | Running loss: 0.55262\n",
      "Epoch: 6 | Iteration: 694 | Classification loss: 0.12799 | Regression loss: 0.31347 | Running loss: 0.55249\n",
      "Epoch: 6 | Iteration: 695 | Classification loss: 0.15608 | Regression loss: 0.23298 | Running loss: 0.55223\n",
      "Epoch: 6 | Iteration: 696 | Classification loss: 0.14833 | Regression loss: 0.23221 | Running loss: 0.55235\n",
      "Epoch: 6 | Iteration: 697 | Classification loss: 0.12069 | Regression loss: 0.30660 | Running loss: 0.55143\n",
      "Epoch: 6 | Iteration: 698 | Classification loss: 0.26860 | Regression loss: 0.16511 | Running loss: 0.55091\n",
      "Epoch: 6 | Iteration: 699 | Classification loss: 0.28037 | Regression loss: 0.33217 | Running loss: 0.55092\n",
      "Epoch: 6 | Iteration: 700 | Classification loss: 0.13678 | Regression loss: 0.23062 | Running loss: 0.55117\n",
      "Epoch: 6 | Iteration: 701 | Classification loss: 0.18806 | Regression loss: 0.35972 | Running loss: 0.55110\n",
      "Epoch: 6 | Iteration: 702 | Classification loss: 0.09960 | Regression loss: 0.29625 | Running loss: 0.54997\n",
      "Epoch: 6 | Iteration: 703 | Classification loss: 0.24171 | Regression loss: 0.24199 | Running loss: 0.54968\n",
      "Epoch: 6 | Iteration: 704 | Classification loss: 0.13045 | Regression loss: 0.43629 | Running loss: 0.54975\n",
      "Epoch: 6 | Iteration: 705 | Classification loss: 0.13202 | Regression loss: 0.31481 | Running loss: 0.54982\n",
      "Epoch: 6 | Iteration: 706 | Classification loss: 0.13277 | Regression loss: 0.25213 | Running loss: 0.54901\n",
      "Epoch: 6 | Iteration: 707 | Classification loss: 0.24330 | Regression loss: 0.50946 | Running loss: 0.54956\n",
      "Epoch: 6 | Iteration: 708 | Classification loss: 0.25779 | Regression loss: 0.29980 | Running loss: 0.54933\n",
      "Epoch: 6 | Iteration: 709 | Classification loss: 0.15116 | Regression loss: 0.36379 | Running loss: 0.54902\n",
      "Epoch: 6 | Iteration: 710 | Classification loss: 0.29987 | Regression loss: 0.37560 | Running loss: 0.54985\n",
      "Epoch: 6 | Iteration: 711 | Classification loss: 0.58284 | Regression loss: 0.17397 | Running loss: 0.55033\n",
      "Epoch: 6 | Iteration: 712 | Classification loss: 0.23922 | Regression loss: 0.36022 | Running loss: 0.55067\n",
      "Epoch: 6 | Iteration: 713 | Classification loss: 0.30203 | Regression loss: 0.38675 | Running loss: 0.55082\n",
      "Epoch: 6 | Iteration: 714 | Classification loss: 0.27770 | Regression loss: 0.58478 | Running loss: 0.55130\n",
      "Epoch: 6 | Iteration: 715 | Classification loss: 0.19182 | Regression loss: 0.36545 | Running loss: 0.55192\n",
      "Epoch: 6 | Iteration: 716 | Classification loss: 0.25405 | Regression loss: 0.41999 | Running loss: 0.55251\n",
      "Epoch: 6 | Iteration: 717 | Classification loss: 0.15966 | Regression loss: 0.22571 | Running loss: 0.55227\n",
      "Epoch: 6 | Iteration: 718 | Classification loss: 0.14647 | Regression loss: 0.24157 | Running loss: 0.55231\n",
      "Epoch: 6 | Iteration: 719 | Classification loss: 0.26550 | Regression loss: 0.48039 | Running loss: 0.55291\n",
      "Epoch: 6 | Iteration: 720 | Classification loss: 0.18245 | Regression loss: 0.28876 | Running loss: 0.55332\n",
      "Epoch: 6 | Iteration: 721 | Classification loss: 0.21245 | Regression loss: 0.42551 | Running loss: 0.55356\n",
      "Epoch: 6 | Iteration: 722 | Classification loss: 0.21040 | Regression loss: 0.47909 | Running loss: 0.55306\n",
      "Epoch: 6 | Iteration: 723 | Classification loss: 0.07173 | Regression loss: 0.23876 | Running loss: 0.55238\n",
      "Epoch: 6 | Iteration: 724 | Classification loss: 0.22931 | Regression loss: 0.52873 | Running loss: 0.55280\n",
      "Epoch: 6 | Iteration: 725 | Classification loss: 0.14247 | Regression loss: 0.31647 | Running loss: 0.55266\n",
      "Epoch: 6 | Iteration: 726 | Classification loss: 0.26686 | Regression loss: 0.24560 | Running loss: 0.55296\n",
      "Epoch: 6 | Iteration: 727 | Classification loss: 0.31957 | Regression loss: 0.38690 | Running loss: 0.55339\n",
      "Epoch: 6 | Iteration: 728 | Classification loss: 0.25347 | Regression loss: 0.53574 | Running loss: 0.55337\n",
      "Epoch: 6 | Iteration: 729 | Classification loss: 0.24014 | Regression loss: 0.31760 | Running loss: 0.55330\n",
      "Epoch: 6 | Iteration: 730 | Classification loss: 0.15330 | Regression loss: 0.25743 | Running loss: 0.55318\n",
      "Epoch: 6 | Iteration: 731 | Classification loss: 0.11335 | Regression loss: 0.28769 | Running loss: 0.55172\n",
      "Epoch: 6 | Iteration: 732 | Classification loss: 0.07469 | Regression loss: 0.21218 | Running loss: 0.55044\n",
      "Epoch: 6 | Iteration: 733 | Classification loss: 0.12813 | Regression loss: 0.35609 | Running loss: 0.55089\n",
      "Epoch: 6 | Iteration: 734 | Classification loss: 0.20170 | Regression loss: 0.48105 | Running loss: 0.55076\n",
      "Epoch: 6 | Iteration: 735 | Classification loss: 0.30897 | Regression loss: 0.29764 | Running loss: 0.55067\n",
      "Epoch: 6 | Iteration: 736 | Classification loss: 0.06337 | Regression loss: 0.09784 | Running loss: 0.55046\n",
      "Epoch: 6 | Iteration: 737 | Classification loss: 0.35850 | Regression loss: 0.25773 | Running loss: 0.55115\n",
      "Epoch: 6 | Iteration: 738 | Classification loss: 0.21898 | Regression loss: 0.31246 | Running loss: 0.55133\n",
      "Epoch: 6 | Iteration: 739 | Classification loss: 0.18394 | Regression loss: 0.18876 | Running loss: 0.55098\n",
      "Epoch: 6 | Iteration: 740 | Classification loss: 0.07775 | Regression loss: 0.31567 | Running loss: 0.55070\n",
      "Epoch: 6 | Iteration: 741 | Classification loss: 0.26558 | Regression loss: 0.59782 | Running loss: 0.55162\n",
      "Epoch: 6 | Iteration: 742 | Classification loss: 0.37544 | Regression loss: 0.37921 | Running loss: 0.55198\n",
      "Epoch: 6 | Iteration: 743 | Classification loss: 0.08846 | Regression loss: 0.10929 | Running loss: 0.55078\n",
      "Epoch: 6 | Iteration: 744 | Classification loss: 0.33629 | Regression loss: 0.38918 | Running loss: 0.55138\n",
      "Epoch: 6 | Iteration: 745 | Classification loss: 0.10349 | Regression loss: 0.36773 | Running loss: 0.55146\n",
      "Epoch: 6 | Iteration: 746 | Classification loss: 0.08403 | Regression loss: 0.18897 | Running loss: 0.55053\n",
      "Epoch: 6 | Iteration: 747 | Classification loss: 0.33376 | Regression loss: 0.38096 | Running loss: 0.55113\n",
      "Epoch: 6 | Iteration: 748 | Classification loss: 0.00028 | Regression loss: 0.00000 | Running loss: 0.55010\n",
      "Epoch: 6 | Iteration: 749 | Classification loss: 0.31921 | Regression loss: 0.53378 | Running loss: 0.55077\n",
      "Epoch: 6 | Iteration: 750 | Classification loss: 0.20947 | Regression loss: 0.52088 | Running loss: 0.54982\n",
      "Epoch: 6 | Iteration: 751 | Classification loss: 0.23545 | Regression loss: 0.35214 | Running loss: 0.55045\n",
      "Epoch: 6 | Iteration: 752 | Classification loss: 0.07968 | Regression loss: 0.32500 | Running loss: 0.55015\n",
      "Epoch: 6 | Iteration: 753 | Classification loss: 0.19438 | Regression loss: 0.35673 | Running loss: 0.55043\n",
      "Epoch: 6 | Iteration: 754 | Classification loss: 0.15385 | Regression loss: 0.38272 | Running loss: 0.55061\n",
      "Epoch: 6 | Iteration: 755 | Classification loss: 0.23123 | Regression loss: 0.27239 | Running loss: 0.54960\n",
      "Epoch: 6 | Iteration: 756 | Classification loss: 0.21170 | Regression loss: 0.24056 | Running loss: 0.54973\n",
      "Epoch: 6 | Iteration: 757 | Classification loss: 0.24613 | Regression loss: 0.46012 | Running loss: 0.54979\n",
      "Epoch: 6 | Iteration: 758 | Classification loss: 0.17737 | Regression loss: 0.47295 | Running loss: 0.54969\n",
      "Epoch: 6 | Iteration: 759 | Classification loss: 0.23627 | Regression loss: 0.45229 | Running loss: 0.54982\n",
      "Epoch: 6 | Iteration: 760 | Classification loss: 0.24531 | Regression loss: 0.28166 | Running loss: 0.55025\n",
      "Epoch: 6 | Iteration: 761 | Classification loss: 0.08160 | Regression loss: 0.23280 | Running loss: 0.54987\n",
      "Epoch: 6 | Iteration: 762 | Classification loss: 0.21881 | Regression loss: 0.24960 | Running loss: 0.55007\n",
      "Epoch: 6 | Iteration: 763 | Classification loss: 0.04542 | Regression loss: 0.18830 | Running loss: 0.54972\n",
      "Epoch: 6 | Iteration: 764 | Classification loss: 0.25637 | Regression loss: 0.38186 | Running loss: 0.55023\n",
      "Epoch: 6 | Iteration: 765 | Classification loss: 0.12277 | Regression loss: 0.29592 | Running loss: 0.55007\n",
      "Epoch: 6 | Iteration: 766 | Classification loss: 0.04330 | Regression loss: 0.12281 | Running loss: 0.54967\n",
      "Epoch: 6 | Iteration: 767 | Classification loss: 0.09574 | Regression loss: 0.23333 | Running loss: 0.54932\n",
      "Epoch: 6 | Iteration: 768 | Classification loss: 0.06547 | Regression loss: 0.33366 | Running loss: 0.54959\n",
      "Epoch: 6 | Iteration: 769 | Classification loss: 0.34572 | Regression loss: 0.30160 | Running loss: 0.54952\n",
      "Epoch: 6 | Iteration: 770 | Classification loss: 0.21541 | Regression loss: 0.40181 | Running loss: 0.54966\n",
      "Epoch: 6 | Iteration: 771 | Classification loss: 0.09223 | Regression loss: 0.17013 | Running loss: 0.54872\n",
      "Epoch: 6 | Iteration: 772 | Classification loss: 0.28531 | Regression loss: 0.83979 | Running loss: 0.54985\n",
      "Epoch: 6 | Iteration: 773 | Classification loss: 0.10959 | Regression loss: 0.27570 | Running loss: 0.55005\n",
      "Epoch: 6 | Iteration: 774 | Classification loss: 0.34234 | Regression loss: 0.42150 | Running loss: 0.55085\n",
      "Epoch: 6 | Iteration: 775 | Classification loss: 0.26372 | Regression loss: 0.12759 | Running loss: 0.54991\n",
      "Epoch: 6 | Iteration: 776 | Classification loss: 0.29230 | Regression loss: 0.26044 | Running loss: 0.55005\n",
      "Epoch: 6 | Iteration: 777 | Classification loss: 0.11857 | Regression loss: 0.30086 | Running loss: 0.55052\n",
      "Epoch: 6 | Iteration: 778 | Classification loss: 0.10035 | Regression loss: 0.28725 | Running loss: 0.54989\n",
      "Epoch: 6 | Iteration: 779 | Classification loss: 0.28830 | Regression loss: 0.70159 | Running loss: 0.55096\n",
      "Epoch: 6 | Iteration: 780 | Classification loss: 0.06893 | Regression loss: 0.23578 | Running loss: 0.55085\n",
      "Epoch: 6 | Iteration: 781 | Classification loss: 0.30309 | Regression loss: 0.31579 | Running loss: 0.55110\n",
      "Epoch: 6 | Iteration: 782 | Classification loss: 0.45002 | Regression loss: 0.42974 | Running loss: 0.55133\n",
      "Epoch: 6 | Iteration: 783 | Classification loss: 0.32573 | Regression loss: 0.47358 | Running loss: 0.55217\n",
      "Epoch: 6 | Iteration: 784 | Classification loss: 0.12500 | Regression loss: 0.21600 | Running loss: 0.55183\n",
      "Epoch: 6 | Iteration: 785 | Classification loss: 0.21990 | Regression loss: 0.52271 | Running loss: 0.55237\n",
      "Epoch: 6 | Iteration: 786 | Classification loss: 0.19045 | Regression loss: 0.44561 | Running loss: 0.55289\n",
      "Epoch: 6 | Iteration: 787 | Classification loss: 0.29085 | Regression loss: 0.50848 | Running loss: 0.55370\n",
      "Epoch: 6 | Iteration: 788 | Classification loss: 0.17541 | Regression loss: 0.26582 | Running loss: 0.55274\n",
      "Epoch: 6 | Iteration: 789 | Classification loss: 0.19124 | Regression loss: 0.20564 | Running loss: 0.55268\n",
      "Epoch: 6 | Iteration: 790 | Classification loss: 0.23619 | Regression loss: 0.48309 | Running loss: 0.55262\n",
      "Epoch: 6 | Iteration: 791 | Classification loss: 0.06590 | Regression loss: 0.20922 | Running loss: 0.55215\n",
      "Epoch: 6 | Iteration: 792 | Classification loss: 0.29753 | Regression loss: 0.26093 | Running loss: 0.55243\n",
      "Epoch: 6 | Iteration: 793 | Classification loss: 0.10390 | Regression loss: 0.30278 | Running loss: 0.55238\n",
      "Epoch: 6 | Iteration: 794 | Classification loss: 0.07876 | Regression loss: 0.07490 | Running loss: 0.55174\n",
      "Epoch: 6 | Iteration: 795 | Classification loss: 0.12160 | Regression loss: 0.27342 | Running loss: 0.55172\n",
      "Epoch: 6 | Iteration: 796 | Classification loss: 0.11066 | Regression loss: 0.09478 | Running loss: 0.55094\n",
      "Epoch: 6 | Iteration: 797 | Classification loss: 0.12176 | Regression loss: 0.26771 | Running loss: 0.55064\n",
      "Epoch: 6 | Iteration: 798 | Classification loss: 0.12938 | Regression loss: 0.20870 | Running loss: 0.55001\n",
      "Epoch: 6 | Iteration: 799 | Classification loss: 0.25320 | Regression loss: 0.62307 | Running loss: 0.55063\n",
      "Epoch: 6 | Iteration: 800 | Classification loss: 0.22544 | Regression loss: 0.33623 | Running loss: 0.55075\n",
      "Epoch: 6 | Iteration: 801 | Classification loss: 0.20287 | Regression loss: 0.43409 | Running loss: 0.55057\n",
      "Epoch: 6 | Iteration: 802 | Classification loss: 0.11909 | Regression loss: 0.37296 | Running loss: 0.55065\n",
      "Epoch: 6 | Iteration: 803 | Classification loss: 0.36510 | Regression loss: 0.21535 | Running loss: 0.55071\n",
      "Epoch: 6 | Iteration: 804 | Classification loss: 0.14668 | Regression loss: 0.43186 | Running loss: 0.55091\n",
      "Epoch: 6 | Iteration: 805 | Classification loss: 0.37788 | Regression loss: 0.24750 | Running loss: 0.55103\n",
      "Epoch: 6 | Iteration: 806 | Classification loss: 0.16194 | Regression loss: 0.32625 | Running loss: 0.55052\n",
      "Epoch: 6 | Iteration: 807 | Classification loss: 0.37764 | Regression loss: 0.77033 | Running loss: 0.55152\n",
      "Epoch: 6 | Iteration: 808 | Classification loss: 0.15129 | Regression loss: 0.46618 | Running loss: 0.55210\n",
      "Epoch: 6 | Iteration: 809 | Classification loss: 0.33514 | Regression loss: 0.43400 | Running loss: 0.55273\n",
      "Epoch: 6 | Iteration: 810 | Classification loss: 0.10666 | Regression loss: 0.32943 | Running loss: 0.55263\n",
      "Epoch: 6 | Iteration: 811 | Classification loss: 0.12810 | Regression loss: 0.35078 | Running loss: 0.55206\n",
      "Epoch: 6 | Iteration: 812 | Classification loss: 0.33650 | Regression loss: 0.52688 | Running loss: 0.55289\n",
      "Epoch: 6 | Iteration: 813 | Classification loss: 0.29192 | Regression loss: 0.55287 | Running loss: 0.55355\n",
      "Epoch: 6 | Iteration: 814 | Classification loss: 0.05642 | Regression loss: 0.26161 | Running loss: 0.55317\n",
      "Epoch: 6 | Iteration: 815 | Classification loss: 0.10891 | Regression loss: 0.27414 | Running loss: 0.55296\n",
      "Epoch: 6 | Iteration: 816 | Classification loss: 0.11375 | Regression loss: 0.35368 | Running loss: 0.55301\n",
      "Epoch: 6 | Iteration: 817 | Classification loss: 0.18493 | Regression loss: 0.48509 | Running loss: 0.55318\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.482\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.503\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 7 | Iteration: 0 | Classification loss: 0.37151 | Regression loss: 0.41266 | Running loss: 0.55378\n",
      "Epoch: 7 | Iteration: 1 | Classification loss: 0.20440 | Regression loss: 0.33889 | Running loss: 0.55415\n",
      "Epoch: 7 | Iteration: 2 | Classification loss: 0.17865 | Regression loss: 0.46659 | Running loss: 0.55446\n",
      "Epoch: 7 | Iteration: 3 | Classification loss: 0.24443 | Regression loss: 0.41266 | Running loss: 0.55460\n",
      "Epoch: 7 | Iteration: 4 | Classification loss: 0.14087 | Regression loss: 0.48209 | Running loss: 0.55397\n",
      "Epoch: 7 | Iteration: 5 | Classification loss: 0.13616 | Regression loss: 0.24243 | Running loss: 0.55398\n",
      "Epoch: 7 | Iteration: 6 | Classification loss: 0.18361 | Regression loss: 0.26789 | Running loss: 0.55403\n",
      "Epoch: 7 | Iteration: 7 | Classification loss: 0.19323 | Regression loss: 0.28764 | Running loss: 0.55310\n",
      "Epoch: 7 | Iteration: 8 | Classification loss: 0.28903 | Regression loss: 0.45814 | Running loss: 0.55337\n",
      "Epoch: 7 | Iteration: 9 | Classification loss: 0.27472 | Regression loss: 0.27077 | Running loss: 0.55371\n",
      "Epoch: 7 | Iteration: 10 | Classification loss: 0.27399 | Regression loss: 0.50029 | Running loss: 0.55439\n",
      "Epoch: 7 | Iteration: 11 | Classification loss: 0.15624 | Regression loss: 0.29448 | Running loss: 0.55462\n",
      "Epoch: 7 | Iteration: 12 | Classification loss: 0.14651 | Regression loss: 0.22632 | Running loss: 0.55465\n",
      "Epoch: 7 | Iteration: 13 | Classification loss: 0.26271 | Regression loss: 0.51573 | Running loss: 0.55543\n",
      "Epoch: 7 | Iteration: 14 | Classification loss: 0.08023 | Regression loss: 0.14475 | Running loss: 0.55483\n",
      "Epoch: 7 | Iteration: 15 | Classification loss: 0.31305 | Regression loss: 0.15546 | Running loss: 0.55497\n",
      "Epoch: 7 | Iteration: 16 | Classification loss: 0.04593 | Regression loss: 0.19019 | Running loss: 0.55460\n",
      "Epoch: 7 | Iteration: 17 | Classification loss: 0.22039 | Regression loss: 0.21245 | Running loss: 0.55473\n",
      "Epoch: 7 | Iteration: 18 | Classification loss: 0.17174 | Regression loss: 0.33121 | Running loss: 0.55380\n",
      "Epoch: 7 | Iteration: 19 | Classification loss: 0.17619 | Regression loss: 0.23576 | Running loss: 0.55269\n",
      "Epoch: 7 | Iteration: 20 | Classification loss: 0.20909 | Regression loss: 0.32614 | Running loss: 0.55255\n",
      "Epoch: 7 | Iteration: 21 | Classification loss: 0.09582 | Regression loss: 0.36654 | Running loss: 0.55256\n",
      "Epoch: 7 | Iteration: 22 | Classification loss: 0.36495 | Regression loss: 0.50208 | Running loss: 0.55329\n",
      "Epoch: 7 | Iteration: 23 | Classification loss: 0.18252 | Regression loss: 0.28743 | Running loss: 0.55284\n",
      "Epoch: 7 | Iteration: 24 | Classification loss: 0.12225 | Regression loss: 0.24228 | Running loss: 0.55269\n",
      "Epoch: 7 | Iteration: 25 | Classification loss: 0.11389 | Regression loss: 0.16626 | Running loss: 0.55215\n",
      "Epoch: 7 | Iteration: 26 | Classification loss: 0.07963 | Regression loss: 0.12614 | Running loss: 0.55114\n",
      "Epoch: 7 | Iteration: 27 | Classification loss: 0.10065 | Regression loss: 0.21221 | Running loss: 0.55077\n",
      "Epoch: 7 | Iteration: 28 | Classification loss: 0.25942 | Regression loss: 0.33626 | Running loss: 0.55004\n",
      "Epoch: 7 | Iteration: 29 | Classification loss: 0.08155 | Regression loss: 0.20588 | Running loss: 0.54959\n",
      "Epoch: 7 | Iteration: 30 | Classification loss: 0.22835 | Regression loss: 0.52193 | Running loss: 0.54933\n",
      "Epoch: 7 | Iteration: 31 | Classification loss: 0.15130 | Regression loss: 0.44580 | Running loss: 0.54900\n",
      "Epoch: 7 | Iteration: 32 | Classification loss: 0.15090 | Regression loss: 0.25749 | Running loss: 0.54893\n",
      "Epoch: 7 | Iteration: 33 | Classification loss: 0.21986 | Regression loss: 0.28475 | Running loss: 0.54842\n",
      "Epoch: 7 | Iteration: 34 | Classification loss: 0.06151 | Regression loss: 0.28251 | Running loss: 0.54804\n",
      "Epoch: 7 | Iteration: 35 | Classification loss: 0.21165 | Regression loss: 0.46221 | Running loss: 0.54886\n",
      "Epoch: 7 | Iteration: 36 | Classification loss: 0.24953 | Regression loss: 0.42249 | Running loss: 0.54881\n",
      "Epoch: 7 | Iteration: 37 | Classification loss: 0.28762 | Regression loss: 0.27122 | Running loss: 0.54878\n",
      "Epoch: 7 | Iteration: 38 | Classification loss: 0.11277 | Regression loss: 0.32315 | Running loss: 0.54920\n",
      "Epoch: 7 | Iteration: 39 | Classification loss: 0.34267 | Regression loss: 0.41286 | Running loss: 0.54950\n",
      "Epoch: 7 | Iteration: 40 | Classification loss: 0.18175 | Regression loss: 0.39579 | Running loss: 0.54911\n",
      "Epoch: 7 | Iteration: 41 | Classification loss: 0.12879 | Regression loss: 0.29119 | Running loss: 0.54919\n",
      "Epoch: 7 | Iteration: 42 | Classification loss: 0.16558 | Regression loss: 0.22116 | Running loss: 0.54838\n",
      "Epoch: 7 | Iteration: 43 | Classification loss: 0.13553 | Regression loss: 0.27351 | Running loss: 0.54887\n",
      "Epoch: 7 | Iteration: 44 | Classification loss: 0.26476 | Regression loss: 0.34219 | Running loss: 0.54913\n",
      "Epoch: 7 | Iteration: 45 | Classification loss: 0.35613 | Regression loss: 0.42947 | Running loss: 0.54983\n",
      "Epoch: 7 | Iteration: 46 | Classification loss: 0.19112 | Regression loss: 0.67157 | Running loss: 0.54960\n",
      "Epoch: 7 | Iteration: 47 | Classification loss: 0.22329 | Regression loss: 0.22781 | Running loss: 0.54876\n",
      "Epoch: 7 | Iteration: 48 | Classification loss: 0.10714 | Regression loss: 0.26163 | Running loss: 0.54851\n",
      "Epoch: 7 | Iteration: 49 | Classification loss: 0.33015 | Regression loss: 0.16975 | Running loss: 0.54814\n",
      "Epoch: 7 | Iteration: 50 | Classification loss: 0.13903 | Regression loss: 0.17197 | Running loss: 0.54837\n",
      "Epoch: 7 | Iteration: 51 | Classification loss: 0.12437 | Regression loss: 0.25276 | Running loss: 0.54807\n",
      "Epoch: 7 | Iteration: 52 | Classification loss: 0.05494 | Regression loss: 0.18397 | Running loss: 0.54793\n",
      "Epoch: 7 | Iteration: 53 | Classification loss: 0.17330 | Regression loss: 0.39699 | Running loss: 0.54822\n",
      "Epoch: 7 | Iteration: 54 | Classification loss: 0.08642 | Regression loss: 0.42459 | Running loss: 0.54804\n",
      "Epoch: 7 | Iteration: 55 | Classification loss: 0.18138 | Regression loss: 0.36940 | Running loss: 0.54761\n",
      "Epoch: 7 | Iteration: 56 | Classification loss: 0.06492 | Regression loss: 0.19170 | Running loss: 0.54724\n",
      "Epoch: 7 | Iteration: 57 | Classification loss: 0.08181 | Regression loss: 0.13626 | Running loss: 0.54666\n",
      "Epoch: 7 | Iteration: 58 | Classification loss: 0.07006 | Regression loss: 0.18412 | Running loss: 0.54639\n",
      "Epoch: 7 | Iteration: 59 | Classification loss: 0.15611 | Regression loss: 0.23352 | Running loss: 0.54613\n",
      "Epoch: 7 | Iteration: 60 | Classification loss: 0.18775 | Regression loss: 0.14645 | Running loss: 0.54510\n",
      "Epoch: 7 | Iteration: 61 | Classification loss: 0.11604 | Regression loss: 0.24577 | Running loss: 0.54480\n",
      "Epoch: 7 | Iteration: 62 | Classification loss: 0.05816 | Regression loss: 0.17352 | Running loss: 0.54379\n",
      "Epoch: 7 | Iteration: 63 | Classification loss: 0.07131 | Regression loss: 0.14524 | Running loss: 0.54346\n",
      "Epoch: 7 | Iteration: 64 | Classification loss: 0.38973 | Regression loss: 0.28288 | Running loss: 0.54343\n",
      "Epoch: 7 | Iteration: 65 | Classification loss: 0.11887 | Regression loss: 0.17906 | Running loss: 0.54325\n",
      "Epoch: 7 | Iteration: 66 | Classification loss: 0.09325 | Regression loss: 0.24799 | Running loss: 0.54277\n",
      "Epoch: 7 | Iteration: 67 | Classification loss: 0.11221 | Regression loss: 0.16176 | Running loss: 0.54238\n",
      "Epoch: 7 | Iteration: 68 | Classification loss: 0.14060 | Regression loss: 0.37084 | Running loss: 0.54181\n",
      "Epoch: 7 | Iteration: 69 | Classification loss: 0.34779 | Regression loss: 0.42546 | Running loss: 0.54266\n",
      "Epoch: 7 | Iteration: 70 | Classification loss: 0.11495 | Regression loss: 0.25343 | Running loss: 0.54236\n",
      "Epoch: 7 | Iteration: 71 | Classification loss: 0.21963 | Regression loss: 0.23693 | Running loss: 0.54226\n",
      "Epoch: 7 | Iteration: 72 | Classification loss: 0.25391 | Regression loss: 0.27973 | Running loss: 0.54130\n",
      "Epoch: 7 | Iteration: 73 | Classification loss: 0.07373 | Regression loss: 0.22679 | Running loss: 0.54082\n",
      "Epoch: 7 | Iteration: 74 | Classification loss: 0.04999 | Regression loss: 0.23351 | Running loss: 0.54007\n",
      "Epoch: 7 | Iteration: 75 | Classification loss: 0.14775 | Regression loss: 0.22743 | Running loss: 0.53923\n",
      "Epoch: 7 | Iteration: 76 | Classification loss: 0.17933 | Regression loss: 0.47041 | Running loss: 0.53972\n",
      "Epoch: 7 | Iteration: 77 | Classification loss: 0.08310 | Regression loss: 0.17670 | Running loss: 0.53942\n",
      "Epoch: 7 | Iteration: 78 | Classification loss: 0.17778 | Regression loss: 0.24426 | Running loss: 0.53956\n",
      "Epoch: 7 | Iteration: 79 | Classification loss: 0.12731 | Regression loss: 0.27750 | Running loss: 0.53957\n",
      "Epoch: 7 | Iteration: 80 | Classification loss: 0.08832 | Regression loss: 0.23513 | Running loss: 0.53903\n",
      "Epoch: 7 | Iteration: 81 | Classification loss: 0.06840 | Regression loss: 0.27212 | Running loss: 0.53919\n",
      "Epoch: 7 | Iteration: 82 | Classification loss: 0.14326 | Regression loss: 0.25754 | Running loss: 0.53944\n",
      "Epoch: 7 | Iteration: 83 | Classification loss: 0.08600 | Regression loss: 0.16961 | Running loss: 0.53907\n",
      "Epoch: 7 | Iteration: 84 | Classification loss: 0.28711 | Regression loss: 0.41854 | Running loss: 0.53927\n",
      "Epoch: 7 | Iteration: 85 | Classification loss: 0.32784 | Regression loss: 0.56094 | Running loss: 0.54038\n",
      "Epoch: 7 | Iteration: 86 | Classification loss: 0.17605 | Regression loss: 0.21854 | Running loss: 0.54009\n",
      "Epoch: 7 | Iteration: 87 | Classification loss: 0.20547 | Regression loss: 0.37196 | Running loss: 0.54049\n",
      "Epoch: 7 | Iteration: 88 | Classification loss: 0.14577 | Regression loss: 0.16546 | Running loss: 0.54014\n",
      "Epoch: 7 | Iteration: 89 | Classification loss: 0.21534 | Regression loss: 0.56062 | Running loss: 0.53997\n",
      "Epoch: 7 | Iteration: 90 | Classification loss: 0.28399 | Regression loss: 0.28892 | Running loss: 0.53997\n",
      "Epoch: 7 | Iteration: 91 | Classification loss: 0.13833 | Regression loss: 0.26658 | Running loss: 0.54013\n",
      "Epoch: 7 | Iteration: 92 | Classification loss: 0.05967 | Regression loss: 0.39425 | Running loss: 0.53949\n",
      "Epoch: 7 | Iteration: 93 | Classification loss: 0.32937 | Regression loss: 0.51162 | Running loss: 0.53960\n",
      "Epoch: 7 | Iteration: 94 | Classification loss: 0.12083 | Regression loss: 0.46385 | Running loss: 0.53958\n",
      "Epoch: 7 | Iteration: 95 | Classification loss: 0.19977 | Regression loss: 0.38388 | Running loss: 0.53972\n",
      "Epoch: 7 | Iteration: 96 | Classification loss: 0.18381 | Regression loss: 0.40589 | Running loss: 0.53963\n",
      "Epoch: 7 | Iteration: 97 | Classification loss: 0.27971 | Regression loss: 0.46412 | Running loss: 0.53989\n",
      "Epoch: 7 | Iteration: 98 | Classification loss: 0.40846 | Regression loss: 0.52028 | Running loss: 0.54093\n",
      "Epoch: 7 | Iteration: 99 | Classification loss: 0.19583 | Regression loss: 0.30513 | Running loss: 0.54020\n",
      "Epoch: 7 | Iteration: 100 | Classification loss: 0.44748 | Regression loss: 0.13050 | Running loss: 0.54069\n",
      "Epoch: 7 | Iteration: 101 | Classification loss: 0.33153 | Regression loss: 0.48709 | Running loss: 0.54157\n",
      "Epoch: 7 | Iteration: 102 | Classification loss: 0.08990 | Regression loss: 0.10821 | Running loss: 0.54087\n",
      "Epoch: 7 | Iteration: 103 | Classification loss: 0.12431 | Regression loss: 0.36352 | Running loss: 0.54058\n",
      "Epoch: 7 | Iteration: 104 | Classification loss: 0.33348 | Regression loss: 0.29795 | Running loss: 0.54077\n",
      "Epoch: 7 | Iteration: 105 | Classification loss: 0.21515 | Regression loss: 0.41033 | Running loss: 0.54138\n",
      "Epoch: 7 | Iteration: 106 | Classification loss: 0.05726 | Regression loss: 0.23779 | Running loss: 0.54104\n",
      "Epoch: 7 | Iteration: 107 | Classification loss: 0.17468 | Regression loss: 0.22766 | Running loss: 0.54061\n",
      "Epoch: 7 | Iteration: 108 | Classification loss: 0.08255 | Regression loss: 0.21230 | Running loss: 0.54024\n",
      "Epoch: 7 | Iteration: 109 | Classification loss: 0.08104 | Regression loss: 0.31284 | Running loss: 0.54008\n",
      "Epoch: 7 | Iteration: 110 | Classification loss: 0.11679 | Regression loss: 0.37363 | Running loss: 0.53975\n",
      "Epoch: 7 | Iteration: 111 | Classification loss: 0.19532 | Regression loss: 0.25653 | Running loss: 0.53974\n",
      "Epoch: 7 | Iteration: 112 | Classification loss: 0.17431 | Regression loss: 0.32942 | Running loss: 0.54010\n",
      "Epoch: 7 | Iteration: 113 | Classification loss: 0.07479 | Regression loss: 0.24547 | Running loss: 0.53937\n",
      "Epoch: 7 | Iteration: 114 | Classification loss: 0.14355 | Regression loss: 0.14439 | Running loss: 0.53835\n",
      "Epoch: 7 | Iteration: 115 | Classification loss: 0.10528 | Regression loss: 0.29201 | Running loss: 0.53841\n",
      "Epoch: 7 | Iteration: 116 | Classification loss: 0.28883 | Regression loss: 0.20702 | Running loss: 0.53828\n",
      "Epoch: 7 | Iteration: 117 | Classification loss: 0.10816 | Regression loss: 0.32199 | Running loss: 0.53838\n",
      "Epoch: 7 | Iteration: 118 | Classification loss: 0.06088 | Regression loss: 0.16754 | Running loss: 0.53801\n",
      "Epoch: 7 | Iteration: 119 | Classification loss: 0.35552 | Regression loss: 0.31511 | Running loss: 0.53837\n",
      "Epoch: 7 | Iteration: 120 | Classification loss: 0.22961 | Regression loss: 0.24080 | Running loss: 0.53830\n",
      "Epoch: 7 | Iteration: 121 | Classification loss: 0.23534 | Regression loss: 0.28535 | Running loss: 0.53861\n",
      "Epoch: 7 | Iteration: 122 | Classification loss: 0.30484 | Regression loss: 0.41474 | Running loss: 0.53913\n",
      "Epoch: 7 | Iteration: 123 | Classification loss: 0.27272 | Regression loss: 0.34251 | Running loss: 0.53891\n",
      "Epoch: 7 | Iteration: 124 | Classification loss: 0.06887 | Regression loss: 0.19480 | Running loss: 0.53738\n",
      "Epoch: 7 | Iteration: 125 | Classification loss: 0.37642 | Regression loss: 0.40122 | Running loss: 0.53821\n",
      "Epoch: 7 | Iteration: 126 | Classification loss: 0.14639 | Regression loss: 0.31474 | Running loss: 0.53836\n",
      "Epoch: 7 | Iteration: 127 | Classification loss: 0.26742 | Regression loss: 0.47785 | Running loss: 0.53843\n",
      "Epoch: 7 | Iteration: 128 | Classification loss: 0.34440 | Regression loss: 0.39753 | Running loss: 0.53821\n",
      "Epoch: 7 | Iteration: 129 | Classification loss: 0.26637 | Regression loss: 0.47242 | Running loss: 0.53865\n",
      "Epoch: 7 | Iteration: 130 | Classification loss: 0.18907 | Regression loss: 0.26751 | Running loss: 0.53859\n",
      "Epoch: 7 | Iteration: 131 | Classification loss: 0.12421 | Regression loss: 0.20309 | Running loss: 0.53813\n",
      "Epoch: 7 | Iteration: 132 | Classification loss: 0.09933 | Regression loss: 0.10276 | Running loss: 0.53763\n",
      "Epoch: 7 | Iteration: 133 | Classification loss: 0.24959 | Regression loss: 0.33165 | Running loss: 0.53826\n",
      "Epoch: 7 | Iteration: 134 | Classification loss: 0.11114 | Regression loss: 0.35794 | Running loss: 0.53795\n",
      "Epoch: 7 | Iteration: 135 | Classification loss: 0.06741 | Regression loss: 0.12785 | Running loss: 0.53758\n",
      "Epoch: 7 | Iteration: 136 | Classification loss: 0.08197 | Regression loss: 0.28664 | Running loss: 0.53768\n",
      "Epoch: 7 | Iteration: 137 | Classification loss: 0.21018 | Regression loss: 0.35161 | Running loss: 0.53779\n",
      "Epoch: 7 | Iteration: 138 | Classification loss: 0.13741 | Regression loss: 0.21435 | Running loss: 0.53763\n",
      "Epoch: 7 | Iteration: 139 | Classification loss: 0.26902 | Regression loss: 0.58392 | Running loss: 0.53819\n",
      "Epoch: 7 | Iteration: 140 | Classification loss: 0.25511 | Regression loss: 0.49471 | Running loss: 0.53902\n",
      "Epoch: 7 | Iteration: 141 | Classification loss: 0.49358 | Regression loss: 0.16537 | Running loss: 0.53903\n",
      "Epoch: 7 | Iteration: 142 | Classification loss: 0.15911 | Regression loss: 0.27752 | Running loss: 0.53857\n",
      "Epoch: 7 | Iteration: 143 | Classification loss: 0.28383 | Regression loss: 0.23206 | Running loss: 0.53849\n",
      "Epoch: 7 | Iteration: 144 | Classification loss: 0.25627 | Regression loss: 0.37344 | Running loss: 0.53875\n",
      "Epoch: 7 | Iteration: 145 | Classification loss: 0.12297 | Regression loss: 0.46105 | Running loss: 0.53823\n",
      "Epoch: 7 | Iteration: 146 | Classification loss: 0.18118 | Regression loss: 0.40610 | Running loss: 0.53798\n",
      "Epoch: 7 | Iteration: 147 | Classification loss: 0.27038 | Regression loss: 0.57898 | Running loss: 0.53862\n",
      "Epoch: 7 | Iteration: 148 | Classification loss: 0.04631 | Regression loss: 0.18998 | Running loss: 0.53754\n",
      "Epoch: 7 | Iteration: 149 | Classification loss: 0.10674 | Regression loss: 0.32205 | Running loss: 0.53747\n",
      "Epoch: 7 | Iteration: 150 | Classification loss: 0.33021 | Regression loss: 0.29520 | Running loss: 0.53797\n",
      "Epoch: 7 | Iteration: 151 | Classification loss: 0.05977 | Regression loss: 0.15278 | Running loss: 0.53750\n",
      "Epoch: 7 | Iteration: 152 | Classification loss: 0.08554 | Regression loss: 0.30855 | Running loss: 0.53731\n",
      "Epoch: 7 | Iteration: 153 | Classification loss: 0.20748 | Regression loss: 0.43714 | Running loss: 0.53744\n",
      "Epoch: 7 | Iteration: 154 | Classification loss: 0.09203 | Regression loss: 0.32026 | Running loss: 0.53728\n",
      "Epoch: 7 | Iteration: 155 | Classification loss: 0.08118 | Regression loss: 0.18085 | Running loss: 0.53692\n",
      "Epoch: 7 | Iteration: 156 | Classification loss: 0.13684 | Regression loss: 0.45092 | Running loss: 0.53586\n",
      "Epoch: 7 | Iteration: 157 | Classification loss: 0.11108 | Regression loss: 0.26632 | Running loss: 0.53588\n",
      "Epoch: 7 | Iteration: 158 | Classification loss: 0.14238 | Regression loss: 0.27380 | Running loss: 0.53587\n",
      "Epoch: 7 | Iteration: 159 | Classification loss: 0.20030 | Regression loss: 0.43644 | Running loss: 0.53636\n",
      "Epoch: 7 | Iteration: 160 | Classification loss: 0.27830 | Regression loss: 0.21601 | Running loss: 0.53605\n",
      "Epoch: 7 | Iteration: 161 | Classification loss: 0.29262 | Regression loss: 0.28725 | Running loss: 0.53547\n",
      "Epoch: 7 | Iteration: 162 | Classification loss: 0.04303 | Regression loss: 0.17370 | Running loss: 0.53501\n",
      "Epoch: 7 | Iteration: 163 | Classification loss: 0.12808 | Regression loss: 0.35493 | Running loss: 0.53468\n",
      "Epoch: 7 | Iteration: 164 | Classification loss: 0.06542 | Regression loss: 0.23067 | Running loss: 0.53413\n",
      "Epoch: 7 | Iteration: 165 | Classification loss: 0.12400 | Regression loss: 0.19760 | Running loss: 0.53342\n",
      "Epoch: 7 | Iteration: 166 | Classification loss: 0.06481 | Regression loss: 0.30621 | Running loss: 0.53228\n",
      "Epoch: 7 | Iteration: 167 | Classification loss: 0.13064 | Regression loss: 0.34496 | Running loss: 0.53239\n",
      "Epoch: 7 | Iteration: 168 | Classification loss: 0.11558 | Regression loss: 0.21315 | Running loss: 0.53232\n",
      "Epoch: 7 | Iteration: 169 | Classification loss: 0.07631 | Regression loss: 0.31299 | Running loss: 0.53212\n",
      "Epoch: 7 | Iteration: 170 | Classification loss: 0.21311 | Regression loss: 0.50661 | Running loss: 0.53259\n",
      "Epoch: 7 | Iteration: 171 | Classification loss: 0.28283 | Regression loss: 0.56769 | Running loss: 0.53334\n",
      "Epoch: 7 | Iteration: 172 | Classification loss: 0.19448 | Regression loss: 0.31220 | Running loss: 0.53367\n",
      "Epoch: 7 | Iteration: 173 | Classification loss: 0.10379 | Regression loss: 0.17280 | Running loss: 0.53320\n",
      "Epoch: 7 | Iteration: 174 | Classification loss: 0.19803 | Regression loss: 0.20847 | Running loss: 0.53291\n",
      "Epoch: 7 | Iteration: 175 | Classification loss: 0.50491 | Regression loss: 0.60112 | Running loss: 0.53511\n",
      "Epoch: 7 | Iteration: 176 | Classification loss: 0.16909 | Regression loss: 0.37503 | Running loss: 0.53515\n",
      "Epoch: 7 | Iteration: 177 | Classification loss: 0.12885 | Regression loss: 0.19009 | Running loss: 0.53490\n",
      "Epoch: 7 | Iteration: 178 | Classification loss: 0.20296 | Regression loss: 0.21466 | Running loss: 0.53389\n",
      "Epoch: 7 | Iteration: 179 | Classification loss: 0.29039 | Regression loss: 0.33662 | Running loss: 0.53454\n",
      "Epoch: 7 | Iteration: 180 | Classification loss: 0.07520 | Regression loss: 0.29533 | Running loss: 0.53402\n",
      "Epoch: 7 | Iteration: 181 | Classification loss: 0.10359 | Regression loss: 0.33196 | Running loss: 0.53424\n",
      "Epoch: 7 | Iteration: 182 | Classification loss: 0.04551 | Regression loss: 0.26159 | Running loss: 0.53429\n",
      "Epoch: 7 | Iteration: 183 | Classification loss: 0.05663 | Regression loss: 0.17613 | Running loss: 0.53350\n",
      "Epoch: 7 | Iteration: 184 | Classification loss: 0.22911 | Regression loss: 0.35997 | Running loss: 0.53412\n",
      "Epoch: 7 | Iteration: 185 | Classification loss: 0.06134 | Regression loss: 0.18828 | Running loss: 0.53400\n",
      "Epoch: 7 | Iteration: 186 | Classification loss: 0.25789 | Regression loss: 0.40045 | Running loss: 0.53423\n",
      "Epoch: 7 | Iteration: 187 | Classification loss: 0.10594 | Regression loss: 0.26286 | Running loss: 0.53325\n",
      "Epoch: 7 | Iteration: 188 | Classification loss: 0.09703 | Regression loss: 0.34317 | Running loss: 0.53293\n",
      "Epoch: 7 | Iteration: 189 | Classification loss: 0.09867 | Regression loss: 0.34371 | Running loss: 0.53310\n",
      "Epoch: 7 | Iteration: 190 | Classification loss: 0.20568 | Regression loss: 0.47906 | Running loss: 0.53282\n",
      "Epoch: 7 | Iteration: 191 | Classification loss: 0.12279 | Regression loss: 0.32759 | Running loss: 0.53273\n",
      "Epoch: 7 | Iteration: 192 | Classification loss: 0.38209 | Regression loss: 0.36878 | Running loss: 0.53271\n",
      "Epoch: 7 | Iteration: 193 | Classification loss: 0.63788 | Regression loss: 0.60632 | Running loss: 0.53448\n",
      "Epoch: 7 | Iteration: 194 | Classification loss: 0.36202 | Regression loss: 0.60045 | Running loss: 0.53571\n",
      "Epoch: 7 | Iteration: 195 | Classification loss: 0.07704 | Regression loss: 0.42356 | Running loss: 0.53485\n",
      "Epoch: 7 | Iteration: 196 | Classification loss: 0.17695 | Regression loss: 0.23224 | Running loss: 0.53463\n",
      "Epoch: 7 | Iteration: 197 | Classification loss: 0.13552 | Regression loss: 0.27228 | Running loss: 0.53394\n",
      "Epoch: 7 | Iteration: 198 | Classification loss: 0.40995 | Regression loss: 0.25699 | Running loss: 0.53407\n",
      "Epoch: 7 | Iteration: 199 | Classification loss: 0.28086 | Regression loss: 0.47081 | Running loss: 0.53334\n",
      "Epoch: 7 | Iteration: 200 | Classification loss: 0.26218 | Regression loss: 0.19801 | Running loss: 0.53375\n",
      "Epoch: 7 | Iteration: 201 | Classification loss: 0.09156 | Regression loss: 0.13663 | Running loss: 0.53247\n",
      "Epoch: 7 | Iteration: 202 | Classification loss: 0.14278 | Regression loss: 0.22059 | Running loss: 0.53240\n",
      "Epoch: 7 | Iteration: 203 | Classification loss: 0.25722 | Regression loss: 0.28729 | Running loss: 0.53261\n",
      "Epoch: 7 | Iteration: 204 | Classification loss: 0.18332 | Regression loss: 0.31017 | Running loss: 0.53246\n",
      "Epoch: 7 | Iteration: 205 | Classification loss: 0.06893 | Regression loss: 0.23505 | Running loss: 0.53218\n",
      "Epoch: 7 | Iteration: 206 | Classification loss: 0.14649 | Regression loss: 0.16768 | Running loss: 0.53178\n",
      "Epoch: 7 | Iteration: 207 | Classification loss: 0.17468 | Regression loss: 0.33994 | Running loss: 0.53064\n",
      "Epoch: 7 | Iteration: 208 | Classification loss: 0.27560 | Regression loss: 0.44922 | Running loss: 0.53129\n",
      "Epoch: 7 | Iteration: 209 | Classification loss: 0.19924 | Regression loss: 0.29569 | Running loss: 0.53053\n",
      "Epoch: 7 | Iteration: 210 | Classification loss: 0.16290 | Regression loss: 0.23371 | Running loss: 0.53003\n",
      "Epoch: 7 | Iteration: 211 | Classification loss: 0.18641 | Regression loss: 0.38265 | Running loss: 0.53042\n",
      "Epoch: 7 | Iteration: 212 | Classification loss: 0.13282 | Regression loss: 0.16961 | Running loss: 0.52996\n",
      "Epoch: 7 | Iteration: 213 | Classification loss: 0.08954 | Regression loss: 0.16202 | Running loss: 0.52984\n",
      "Epoch: 7 | Iteration: 214 | Classification loss: 0.11196 | Regression loss: 0.30627 | Running loss: 0.52975\n",
      "Epoch: 7 | Iteration: 215 | Classification loss: 0.14883 | Regression loss: 0.23524 | Running loss: 0.52856\n",
      "Epoch: 7 | Iteration: 216 | Classification loss: 0.13035 | Regression loss: 0.18921 | Running loss: 0.52790\n",
      "Epoch: 7 | Iteration: 217 | Classification loss: 0.37059 | Regression loss: 0.32419 | Running loss: 0.52853\n",
      "Epoch: 7 | Iteration: 218 | Classification loss: 0.16922 | Regression loss: 0.13422 | Running loss: 0.52792\n",
      "Epoch: 7 | Iteration: 219 | Classification loss: 0.40287 | Regression loss: 0.18671 | Running loss: 0.52784\n",
      "Epoch: 7 | Iteration: 220 | Classification loss: 0.12582 | Regression loss: 0.19037 | Running loss: 0.52791\n",
      "Epoch: 7 | Iteration: 221 | Classification loss: 0.14527 | Regression loss: 0.33700 | Running loss: 0.52764\n",
      "Epoch: 7 | Iteration: 222 | Classification loss: 0.16284 | Regression loss: 0.31395 | Running loss: 0.52756\n",
      "Epoch: 7 | Iteration: 223 | Classification loss: 0.14984 | Regression loss: 0.14074 | Running loss: 0.52684\n",
      "Epoch: 7 | Iteration: 224 | Classification loss: 0.31621 | Regression loss: 0.38083 | Running loss: 0.52691\n",
      "Epoch: 7 | Iteration: 225 | Classification loss: 0.21640 | Regression loss: 0.12773 | Running loss: 0.52594\n",
      "Epoch: 7 | Iteration: 226 | Classification loss: 0.07339 | Regression loss: 0.21690 | Running loss: 0.52510\n",
      "Epoch: 7 | Iteration: 227 | Classification loss: 0.22758 | Regression loss: 0.24645 | Running loss: 0.52545\n",
      "Epoch: 7 | Iteration: 228 | Classification loss: 0.19548 | Regression loss: 0.32442 | Running loss: 0.52577\n",
      "Epoch: 7 | Iteration: 229 | Classification loss: 0.17035 | Regression loss: 0.47852 | Running loss: 0.52618\n",
      "Epoch: 7 | Iteration: 230 | Classification loss: 0.19326 | Regression loss: 0.23565 | Running loss: 0.52653\n",
      "Epoch: 7 | Iteration: 231 | Classification loss: 0.10763 | Regression loss: 0.15308 | Running loss: 0.52615\n",
      "Epoch: 7 | Iteration: 232 | Classification loss: 0.19822 | Regression loss: 0.36826 | Running loss: 0.52636\n",
      "Epoch: 7 | Iteration: 233 | Classification loss: 0.30789 | Regression loss: 0.13861 | Running loss: 0.52605\n",
      "Epoch: 7 | Iteration: 234 | Classification loss: 0.22478 | Regression loss: 0.61084 | Running loss: 0.52614\n",
      "Epoch: 7 | Iteration: 235 | Classification loss: 0.13731 | Regression loss: 0.43523 | Running loss: 0.52589\n",
      "Epoch: 7 | Iteration: 236 | Classification loss: 0.08742 | Regression loss: 0.18666 | Running loss: 0.52489\n",
      "Epoch: 7 | Iteration: 237 | Classification loss: 0.20136 | Regression loss: 0.35045 | Running loss: 0.52486\n",
      "Epoch: 7 | Iteration: 238 | Classification loss: 0.28272 | Regression loss: 0.28400 | Running loss: 0.52539\n",
      "Epoch: 7 | Iteration: 239 | Classification loss: 0.22618 | Regression loss: 0.24941 | Running loss: 0.52515\n",
      "Epoch: 7 | Iteration: 240 | Classification loss: 0.21417 | Regression loss: 0.53649 | Running loss: 0.52612\n",
      "Epoch: 7 | Iteration: 241 | Classification loss: 0.10122 | Regression loss: 0.31405 | Running loss: 0.52542\n",
      "Epoch: 7 | Iteration: 242 | Classification loss: 0.13682 | Regression loss: 0.27949 | Running loss: 0.52482\n",
      "Epoch: 7 | Iteration: 243 | Classification loss: 0.06685 | Regression loss: 0.26247 | Running loss: 0.52504\n",
      "Epoch: 7 | Iteration: 244 | Classification loss: 0.10845 | Regression loss: 0.26757 | Running loss: 0.52417\n",
      "Epoch: 7 | Iteration: 245 | Classification loss: 0.11525 | Regression loss: 0.23372 | Running loss: 0.52409\n",
      "Epoch: 7 | Iteration: 246 | Classification loss: 0.24110 | Regression loss: 0.41319 | Running loss: 0.52502\n",
      "Epoch: 7 | Iteration: 247 | Classification loss: 0.12443 | Regression loss: 0.31397 | Running loss: 0.52470\n",
      "Epoch: 7 | Iteration: 248 | Classification loss: 0.16502 | Regression loss: 0.54723 | Running loss: 0.52544\n",
      "Epoch: 7 | Iteration: 249 | Classification loss: 0.13803 | Regression loss: 0.27571 | Running loss: 0.52530\n",
      "Epoch: 7 | Iteration: 250 | Classification loss: 0.18012 | Regression loss: 0.46769 | Running loss: 0.52575\n",
      "Epoch: 7 | Iteration: 251 | Classification loss: 0.54767 | Regression loss: 0.18812 | Running loss: 0.52656\n",
      "Epoch: 7 | Iteration: 252 | Classification loss: 0.48070 | Regression loss: 0.29011 | Running loss: 0.52742\n",
      "Epoch: 7 | Iteration: 253 | Classification loss: 0.54482 | Regression loss: 0.45791 | Running loss: 0.52835\n",
      "Epoch: 7 | Iteration: 254 | Classification loss: 0.08565 | Regression loss: 0.32928 | Running loss: 0.52842\n",
      "Epoch: 7 | Iteration: 255 | Classification loss: 0.51359 | Regression loss: 0.77998 | Running loss: 0.53046\n",
      "Epoch: 7 | Iteration: 256 | Classification loss: 0.13726 | Regression loss: 0.31714 | Running loss: 0.53090\n",
      "Epoch: 7 | Iteration: 257 | Classification loss: 0.17261 | Regression loss: 0.33865 | Running loss: 0.53008\n",
      "Epoch: 7 | Iteration: 258 | Classification loss: 0.12566 | Regression loss: 0.22217 | Running loss: 0.52861\n",
      "Epoch: 7 | Iteration: 259 | Classification loss: 0.09330 | Regression loss: 0.20430 | Running loss: 0.52819\n",
      "Epoch: 7 | Iteration: 260 | Classification loss: 0.17131 | Regression loss: 0.43276 | Running loss: 0.52873\n",
      "Epoch: 7 | Iteration: 261 | Classification loss: 0.25145 | Regression loss: 0.54414 | Running loss: 0.52875\n",
      "Epoch: 7 | Iteration: 262 | Classification loss: 0.24765 | Regression loss: 0.28526 | Running loss: 0.52778\n",
      "Epoch: 7 | Iteration: 263 | Classification loss: 0.17469 | Regression loss: 0.32571 | Running loss: 0.52728\n",
      "Epoch: 7 | Iteration: 264 | Classification loss: 0.28340 | Regression loss: 0.21486 | Running loss: 0.52694\n",
      "Epoch: 7 | Iteration: 265 | Classification loss: 0.33558 | Regression loss: 0.27513 | Running loss: 0.52726\n",
      "Epoch: 7 | Iteration: 266 | Classification loss: 0.09464 | Regression loss: 0.29375 | Running loss: 0.52635\n",
      "Epoch: 7 | Iteration: 267 | Classification loss: 0.07616 | Regression loss: 0.25293 | Running loss: 0.52587\n",
      "Epoch: 7 | Iteration: 268 | Classification loss: 0.27579 | Regression loss: 0.44089 | Running loss: 0.52560\n",
      "Epoch: 7 | Iteration: 269 | Classification loss: 0.16005 | Regression loss: 0.28116 | Running loss: 0.52474\n",
      "Epoch: 7 | Iteration: 270 | Classification loss: 0.15005 | Regression loss: 0.15378 | Running loss: 0.52487\n",
      "Epoch: 7 | Iteration: 271 | Classification loss: 0.24439 | Regression loss: 0.31337 | Running loss: 0.52460\n",
      "Epoch: 7 | Iteration: 272 | Classification loss: 0.36621 | Regression loss: 0.33480 | Running loss: 0.52489\n",
      "Epoch: 7 | Iteration: 273 | Classification loss: 0.44633 | Regression loss: 0.50769 | Running loss: 0.52496\n",
      "Epoch: 7 | Iteration: 274 | Classification loss: 0.50524 | Regression loss: 0.17255 | Running loss: 0.52523\n",
      "Epoch: 7 | Iteration: 275 | Classification loss: 0.10293 | Regression loss: 0.31419 | Running loss: 0.52435\n",
      "Epoch: 7 | Iteration: 276 | Classification loss: 0.17603 | Regression loss: 0.23418 | Running loss: 0.52447\n",
      "Epoch: 7 | Iteration: 277 | Classification loss: 0.08794 | Regression loss: 0.08240 | Running loss: 0.52328\n",
      "Epoch: 7 | Iteration: 278 | Classification loss: 0.25014 | Regression loss: 0.31180 | Running loss: 0.52291\n",
      "Epoch: 7 | Iteration: 279 | Classification loss: 0.40789 | Regression loss: 0.62511 | Running loss: 0.52464\n",
      "Epoch: 7 | Iteration: 280 | Classification loss: 0.07510 | Regression loss: 0.25085 | Running loss: 0.52441\n",
      "Epoch: 7 | Iteration: 281 | Classification loss: 0.23817 | Regression loss: 0.31430 | Running loss: 0.52340\n",
      "Epoch: 7 | Iteration: 282 | Classification loss: 0.05832 | Regression loss: 0.30675 | Running loss: 0.52236\n",
      "Epoch: 7 | Iteration: 283 | Classification loss: 0.20377 | Regression loss: 0.41327 | Running loss: 0.52216\n",
      "Epoch: 7 | Iteration: 284 | Classification loss: 0.14561 | Regression loss: 0.39979 | Running loss: 0.52187\n",
      "Epoch: 7 | Iteration: 285 | Classification loss: 0.15258 | Regression loss: 0.07512 | Running loss: 0.52095\n",
      "Epoch: 7 | Iteration: 286 | Classification loss: 0.29753 | Regression loss: 0.34245 | Running loss: 0.52122\n",
      "Epoch: 7 | Iteration: 287 | Classification loss: 0.10396 | Regression loss: 0.17565 | Running loss: 0.52086\n",
      "Epoch: 7 | Iteration: 288 | Classification loss: 0.14846 | Regression loss: 0.31924 | Running loss: 0.52045\n",
      "Epoch: 7 | Iteration: 289 | Classification loss: 0.04586 | Regression loss: 0.26636 | Running loss: 0.52065\n",
      "Epoch: 7 | Iteration: 290 | Classification loss: 0.33334 | Regression loss: 0.22348 | Running loss: 0.52094\n",
      "Epoch: 7 | Iteration: 291 | Classification loss: 0.23573 | Regression loss: 0.25511 | Running loss: 0.52089\n",
      "Epoch: 7 | Iteration: 292 | Classification loss: 0.13203 | Regression loss: 0.15444 | Running loss: 0.52011\n",
      "Epoch: 7 | Iteration: 293 | Classification loss: 0.44395 | Regression loss: 0.70632 | Running loss: 0.52111\n",
      "Epoch: 7 | Iteration: 294 | Classification loss: 0.43447 | Regression loss: 0.44842 | Running loss: 0.52205\n",
      "Epoch: 7 | Iteration: 295 | Classification loss: 0.35549 | Regression loss: 0.24330 | Running loss: 0.52215\n",
      "Epoch: 7 | Iteration: 296 | Classification loss: 0.11773 | Regression loss: 0.19988 | Running loss: 0.52197\n",
      "Epoch: 7 | Iteration: 297 | Classification loss: 0.24120 | Regression loss: 0.29273 | Running loss: 0.52186\n",
      "Epoch: 7 | Iteration: 298 | Classification loss: 0.18894 | Regression loss: 0.21488 | Running loss: 0.52174\n",
      "Epoch: 7 | Iteration: 299 | Classification loss: 0.34506 | Regression loss: 0.52905 | Running loss: 0.52163\n",
      "Epoch: 7 | Iteration: 300 | Classification loss: 0.04101 | Regression loss: 0.11901 | Running loss: 0.52112\n",
      "Epoch: 7 | Iteration: 301 | Classification loss: 0.11726 | Regression loss: 0.19398 | Running loss: 0.52029\n",
      "Epoch: 7 | Iteration: 302 | Classification loss: 0.17254 | Regression loss: 0.17889 | Running loss: 0.51980\n",
      "Epoch: 7 | Iteration: 303 | Classification loss: 0.23938 | Regression loss: 0.30318 | Running loss: 0.51916\n",
      "Epoch: 7 | Iteration: 304 | Classification loss: 0.11162 | Regression loss: 0.32677 | Running loss: 0.51868\n",
      "Epoch: 7 | Iteration: 305 | Classification loss: 0.11048 | Regression loss: 0.29729 | Running loss: 0.51828\n",
      "Epoch: 7 | Iteration: 306 | Classification loss: 0.08514 | Regression loss: 0.24416 | Running loss: 0.51827\n",
      "Epoch: 7 | Iteration: 307 | Classification loss: 0.07286 | Regression loss: 0.30227 | Running loss: 0.51705\n",
      "Epoch: 7 | Iteration: 308 | Classification loss: 0.12680 | Regression loss: 0.34594 | Running loss: 0.51612\n",
      "Epoch: 7 | Iteration: 309 | Classification loss: 0.30053 | Regression loss: 0.16997 | Running loss: 0.51534\n",
      "Epoch: 7 | Iteration: 310 | Classification loss: 0.17179 | Regression loss: 0.23646 | Running loss: 0.51507\n",
      "Epoch: 7 | Iteration: 311 | Classification loss: 0.06924 | Regression loss: 0.21941 | Running loss: 0.51479\n",
      "Epoch: 7 | Iteration: 312 | Classification loss: 0.10154 | Regression loss: 0.22554 | Running loss: 0.51485\n",
      "Epoch: 7 | Iteration: 313 | Classification loss: 0.18883 | Regression loss: 0.48579 | Running loss: 0.51466\n",
      "Epoch: 7 | Iteration: 314 | Classification loss: 0.12800 | Regression loss: 0.26958 | Running loss: 0.51436\n",
      "Epoch: 7 | Iteration: 315 | Classification loss: 0.08774 | Regression loss: 0.29379 | Running loss: 0.51415\n",
      "Epoch: 7 | Iteration: 316 | Classification loss: 0.04654 | Regression loss: 0.17301 | Running loss: 0.51358\n",
      "Epoch: 7 | Iteration: 317 | Classification loss: 0.24960 | Regression loss: 0.17803 | Running loss: 0.51364\n",
      "Epoch: 7 | Iteration: 318 | Classification loss: 0.30718 | Regression loss: 0.52468 | Running loss: 0.51443\n",
      "Epoch: 7 | Iteration: 319 | Classification loss: 0.09529 | Regression loss: 0.27356 | Running loss: 0.51424\n",
      "Epoch: 7 | Iteration: 320 | Classification loss: 0.06014 | Regression loss: 0.18924 | Running loss: 0.51370\n",
      "Epoch: 7 | Iteration: 321 | Classification loss: 0.27254 | Regression loss: 0.48180 | Running loss: 0.51466\n",
      "Epoch: 7 | Iteration: 322 | Classification loss: 0.15551 | Regression loss: 0.50833 | Running loss: 0.51477\n",
      "Epoch: 7 | Iteration: 323 | Classification loss: 0.14074 | Regression loss: 0.23631 | Running loss: 0.51362\n",
      "Epoch: 7 | Iteration: 324 | Classification loss: 0.05011 | Regression loss: 0.21594 | Running loss: 0.51204\n",
      "Epoch: 7 | Iteration: 325 | Classification loss: 0.37359 | Regression loss: 0.31091 | Running loss: 0.51236\n",
      "Epoch: 7 | Iteration: 326 | Classification loss: 0.10126 | Regression loss: 0.25982 | Running loss: 0.51236\n",
      "Epoch: 7 | Iteration: 327 | Classification loss: 0.20978 | Regression loss: 0.24510 | Running loss: 0.51237\n",
      "Epoch: 7 | Iteration: 328 | Classification loss: 0.19986 | Regression loss: 0.42026 | Running loss: 0.51301\n",
      "Epoch: 7 | Iteration: 329 | Classification loss: 0.19785 | Regression loss: 0.49451 | Running loss: 0.51337\n",
      "Epoch: 7 | Iteration: 330 | Classification loss: 0.20142 | Regression loss: 0.36976 | Running loss: 0.51336\n",
      "Epoch: 7 | Iteration: 331 | Classification loss: 0.25469 | Regression loss: 0.33138 | Running loss: 0.51346\n",
      "Epoch: 7 | Iteration: 332 | Classification loss: 0.29653 | Regression loss: 0.35282 | Running loss: 0.51354\n",
      "Epoch: 7 | Iteration: 333 | Classification loss: 0.37785 | Regression loss: 0.17470 | Running loss: 0.51328\n",
      "Epoch: 7 | Iteration: 334 | Classification loss: 0.07864 | Regression loss: 0.22191 | Running loss: 0.51282\n",
      "Epoch: 7 | Iteration: 335 | Classification loss: 0.23627 | Regression loss: 0.35650 | Running loss: 0.51226\n",
      "Epoch: 7 | Iteration: 336 | Classification loss: 0.23367 | Regression loss: 0.21467 | Running loss: 0.51194\n",
      "Epoch: 7 | Iteration: 337 | Classification loss: 0.13185 | Regression loss: 0.32721 | Running loss: 0.51134\n",
      "Epoch: 7 | Iteration: 338 | Classification loss: 0.30706 | Regression loss: 0.16026 | Running loss: 0.51162\n",
      "Epoch: 7 | Iteration: 339 | Classification loss: 0.09804 | Regression loss: 0.25100 | Running loss: 0.51129\n",
      "Epoch: 7 | Iteration: 340 | Classification loss: 0.11086 | Regression loss: 0.12573 | Running loss: 0.51110\n",
      "Epoch: 7 | Iteration: 341 | Classification loss: 0.07270 | Regression loss: 0.24948 | Running loss: 0.51073\n",
      "Epoch: 7 | Iteration: 342 | Classification loss: 0.09548 | Regression loss: 0.39668 | Running loss: 0.51051\n",
      "Epoch: 7 | Iteration: 343 | Classification loss: 0.13615 | Regression loss: 0.31012 | Running loss: 0.51047\n",
      "Epoch: 7 | Iteration: 344 | Classification loss: 0.25686 | Regression loss: 0.15824 | Running loss: 0.51045\n",
      "Epoch: 7 | Iteration: 345 | Classification loss: 0.17150 | Regression loss: 0.07701 | Running loss: 0.50998\n",
      "Epoch: 7 | Iteration: 346 | Classification loss: 0.14338 | Regression loss: 0.41484 | Running loss: 0.51043\n",
      "Epoch: 7 | Iteration: 347 | Classification loss: 0.18255 | Regression loss: 0.27234 | Running loss: 0.50956\n",
      "Epoch: 7 | Iteration: 348 | Classification loss: 0.13208 | Regression loss: 0.19696 | Running loss: 0.50926\n",
      "Epoch: 7 | Iteration: 349 | Classification loss: 0.29578 | Regression loss: 0.46993 | Running loss: 0.51006\n",
      "Epoch: 7 | Iteration: 350 | Classification loss: 0.25780 | Regression loss: 0.17337 | Running loss: 0.51012\n",
      "Epoch: 7 | Iteration: 351 | Classification loss: 0.10771 | Regression loss: 0.41565 | Running loss: 0.50911\n",
      "Epoch: 7 | Iteration: 352 | Classification loss: 0.18215 | Regression loss: 0.31666 | Running loss: 0.50915\n",
      "Epoch: 7 | Iteration: 353 | Classification loss: 0.39377 | Regression loss: 0.51328 | Running loss: 0.50959\n",
      "Epoch: 7 | Iteration: 354 | Classification loss: 0.31229 | Regression loss: 0.17544 | Running loss: 0.50972\n",
      "Epoch: 7 | Iteration: 355 | Classification loss: 0.26932 | Regression loss: 0.48584 | Running loss: 0.51036\n",
      "Epoch: 7 | Iteration: 356 | Classification loss: 0.41710 | Regression loss: 0.31230 | Running loss: 0.51105\n",
      "Epoch: 7 | Iteration: 357 | Classification loss: 0.62515 | Regression loss: 0.20965 | Running loss: 0.51188\n",
      "Epoch: 7 | Iteration: 358 | Classification loss: 0.16246 | Regression loss: 0.38012 | Running loss: 0.51200\n",
      "Epoch: 7 | Iteration: 359 | Classification loss: 0.14929 | Regression loss: 0.24850 | Running loss: 0.51178\n",
      "Epoch: 7 | Iteration: 360 | Classification loss: 0.10718 | Regression loss: 0.29512 | Running loss: 0.51094\n",
      "Epoch: 7 | Iteration: 361 | Classification loss: 0.22596 | Regression loss: 0.26086 | Running loss: 0.51021\n",
      "Epoch: 7 | Iteration: 362 | Classification loss: 0.00006 | Regression loss: 0.00000 | Running loss: 0.50885\n",
      "Epoch: 7 | Iteration: 363 | Classification loss: 0.29739 | Regression loss: 0.36342 | Running loss: 0.50950\n",
      "Epoch: 7 | Iteration: 364 | Classification loss: 0.44805 | Regression loss: 0.16447 | Running loss: 0.50928\n",
      "Epoch: 7 | Iteration: 365 | Classification loss: 0.33600 | Regression loss: 0.26496 | Running loss: 0.50902\n",
      "Epoch: 7 | Iteration: 366 | Classification loss: 0.21672 | Regression loss: 0.22347 | Running loss: 0.50860\n",
      "Epoch: 7 | Iteration: 367 | Classification loss: 0.24134 | Regression loss: 0.18913 | Running loss: 0.50858\n",
      "Epoch: 7 | Iteration: 368 | Classification loss: 0.20765 | Regression loss: 0.12980 | Running loss: 0.50673\n",
      "Epoch: 7 | Iteration: 369 | Classification loss: 0.31987 | Regression loss: 0.35333 | Running loss: 0.50693\n",
      "Epoch: 7 | Iteration: 370 | Classification loss: 0.12940 | Regression loss: 0.13233 | Running loss: 0.50660\n",
      "Epoch: 7 | Iteration: 371 | Classification loss: 0.39511 | Regression loss: 0.51126 | Running loss: 0.50727\n",
      "Epoch: 7 | Iteration: 372 | Classification loss: 0.23451 | Regression loss: 0.36177 | Running loss: 0.50719\n",
      "Epoch: 7 | Iteration: 373 | Classification loss: 0.32982 | Regression loss: 0.44960 | Running loss: 0.50775\n",
      "Epoch: 7 | Iteration: 374 | Classification loss: 0.15639 | Regression loss: 0.37091 | Running loss: 0.50792\n",
      "Epoch: 7 | Iteration: 375 | Classification loss: 0.16251 | Regression loss: 0.27422 | Running loss: 0.50798\n",
      "Epoch: 7 | Iteration: 376 | Classification loss: 0.07279 | Regression loss: 0.31865 | Running loss: 0.50788\n",
      "Epoch: 7 | Iteration: 377 | Classification loss: 0.08450 | Regression loss: 0.15260 | Running loss: 0.50758\n",
      "Epoch: 7 | Iteration: 378 | Classification loss: 0.30989 | Regression loss: 0.32025 | Running loss: 0.50808\n",
      "Epoch: 7 | Iteration: 379 | Classification loss: 0.14667 | Regression loss: 0.15539 | Running loss: 0.50783\n",
      "Epoch: 7 | Iteration: 380 | Classification loss: 0.15540 | Regression loss: 0.19238 | Running loss: 0.50765\n",
      "Epoch: 7 | Iteration: 381 | Classification loss: 0.26618 | Regression loss: 0.52576 | Running loss: 0.50801\n",
      "Epoch: 7 | Iteration: 382 | Classification loss: 0.22930 | Regression loss: 0.47994 | Running loss: 0.50870\n",
      "Epoch: 7 | Iteration: 383 | Classification loss: 0.13443 | Regression loss: 0.26176 | Running loss: 0.50839\n",
      "Epoch: 7 | Iteration: 384 | Classification loss: 0.22892 | Regression loss: 0.35986 | Running loss: 0.50878\n",
      "Epoch: 7 | Iteration: 385 | Classification loss: 0.25611 | Regression loss: 0.34861 | Running loss: 0.50902\n",
      "Epoch: 7 | Iteration: 386 | Classification loss: 0.29661 | Regression loss: 0.13922 | Running loss: 0.50876\n",
      "Epoch: 7 | Iteration: 387 | Classification loss: 0.17459 | Regression loss: 0.24511 | Running loss: 0.50871\n",
      "Epoch: 7 | Iteration: 388 | Classification loss: 0.14974 | Regression loss: 0.27586 | Running loss: 0.50879\n",
      "Epoch: 7 | Iteration: 389 | Classification loss: 0.14364 | Regression loss: 0.33337 | Running loss: 0.50824\n",
      "Epoch: 7 | Iteration: 390 | Classification loss: 0.24464 | Regression loss: 0.30790 | Running loss: 0.50822\n",
      "Epoch: 7 | Iteration: 391 | Classification loss: 0.30826 | Regression loss: 0.33272 | Running loss: 0.50848\n",
      "Epoch: 7 | Iteration: 392 | Classification loss: 0.11122 | Regression loss: 0.15849 | Running loss: 0.50767\n",
      "Epoch: 7 | Iteration: 393 | Classification loss: 0.28999 | Regression loss: 0.45323 | Running loss: 0.50764\n",
      "Epoch: 7 | Iteration: 394 | Classification loss: 0.11578 | Regression loss: 0.23859 | Running loss: 0.50715\n",
      "Epoch: 7 | Iteration: 395 | Classification loss: 0.28390 | Regression loss: 0.60520 | Running loss: 0.50755\n",
      "Epoch: 7 | Iteration: 396 | Classification loss: 0.23262 | Regression loss: 0.44271 | Running loss: 0.50717\n",
      "Epoch: 7 | Iteration: 397 | Classification loss: 0.22945 | Regression loss: 0.41408 | Running loss: 0.50735\n",
      "Epoch: 7 | Iteration: 398 | Classification loss: 0.17139 | Regression loss: 0.38535 | Running loss: 0.50711\n",
      "Epoch: 7 | Iteration: 399 | Classification loss: 0.19955 | Regression loss: 0.20668 | Running loss: 0.50715\n",
      "Epoch: 7 | Iteration: 400 | Classification loss: 0.13966 | Regression loss: 0.19477 | Running loss: 0.50705\n",
      "Epoch: 7 | Iteration: 401 | Classification loss: 0.23632 | Regression loss: 0.51106 | Running loss: 0.50705\n",
      "Epoch: 7 | Iteration: 402 | Classification loss: 0.15603 | Regression loss: 0.21961 | Running loss: 0.50686\n",
      "Epoch: 7 | Iteration: 403 | Classification loss: 0.15592 | Regression loss: 0.15809 | Running loss: 0.50621\n",
      "Epoch: 7 | Iteration: 404 | Classification loss: 0.17720 | Regression loss: 0.22834 | Running loss: 0.50564\n",
      "Epoch: 7 | Iteration: 405 | Classification loss: 0.29993 | Regression loss: 0.22662 | Running loss: 0.50608\n",
      "Epoch: 7 | Iteration: 406 | Classification loss: 0.09182 | Regression loss: 0.34127 | Running loss: 0.50543\n",
      "Epoch: 7 | Iteration: 407 | Classification loss: 0.04797 | Regression loss: 0.16269 | Running loss: 0.50493\n",
      "Epoch: 7 | Iteration: 408 | Classification loss: 0.22296 | Regression loss: 0.65208 | Running loss: 0.50565\n",
      "Epoch: 7 | Iteration: 409 | Classification loss: 0.05886 | Regression loss: 0.10278 | Running loss: 0.50456\n",
      "Epoch: 7 | Iteration: 410 | Classification loss: 0.37171 | Regression loss: 0.54535 | Running loss: 0.50482\n",
      "Epoch: 7 | Iteration: 411 | Classification loss: 0.20005 | Regression loss: 0.30643 | Running loss: 0.50472\n",
      "Epoch: 7 | Iteration: 412 | Classification loss: 0.06976 | Regression loss: 0.22983 | Running loss: 0.50450\n",
      "Epoch: 7 | Iteration: 413 | Classification loss: 0.20032 | Regression loss: 0.36285 | Running loss: 0.50482\n",
      "Epoch: 7 | Iteration: 414 | Classification loss: 0.16203 | Regression loss: 0.22436 | Running loss: 0.50502\n",
      "Epoch: 7 | Iteration: 415 | Classification loss: 0.22090 | Regression loss: 0.26373 | Running loss: 0.50502\n",
      "Epoch: 7 | Iteration: 416 | Classification loss: 0.11884 | Regression loss: 0.16781 | Running loss: 0.50423\n",
      "Epoch: 7 | Iteration: 417 | Classification loss: 0.48395 | Regression loss: 0.52464 | Running loss: 0.50503\n",
      "Epoch: 7 | Iteration: 418 | Classification loss: 0.11600 | Regression loss: 0.27398 | Running loss: 0.50549\n",
      "Epoch: 7 | Iteration: 419 | Classification loss: 0.25509 | Regression loss: 0.49844 | Running loss: 0.50576\n",
      "Epoch: 7 | Iteration: 420 | Classification loss: 0.16057 | Regression loss: 0.36940 | Running loss: 0.50576\n",
      "Epoch: 7 | Iteration: 421 | Classification loss: 0.15136 | Regression loss: 0.33828 | Running loss: 0.50599\n",
      "Epoch: 7 | Iteration: 422 | Classification loss: 0.22082 | Regression loss: 0.22472 | Running loss: 0.50610\n",
      "Epoch: 7 | Iteration: 423 | Classification loss: 0.17500 | Regression loss: 0.24750 | Running loss: 0.50522\n",
      "Epoch: 7 | Iteration: 424 | Classification loss: 0.29797 | Regression loss: 0.62269 | Running loss: 0.50555\n",
      "Epoch: 7 | Iteration: 425 | Classification loss: 0.18175 | Regression loss: 0.27446 | Running loss: 0.50607\n",
      "Epoch: 7 | Iteration: 426 | Classification loss: 0.13942 | Regression loss: 0.30113 | Running loss: 0.50550\n",
      "Epoch: 7 | Iteration: 427 | Classification loss: 0.07347 | Regression loss: 0.23350 | Running loss: 0.50517\n",
      "Epoch: 7 | Iteration: 428 | Classification loss: 0.32657 | Regression loss: 0.34052 | Running loss: 0.50596\n",
      "Epoch: 7 | Iteration: 429 | Classification loss: 0.29507 | Regression loss: 0.41010 | Running loss: 0.50594\n",
      "Epoch: 7 | Iteration: 430 | Classification loss: 0.24860 | Regression loss: 0.29534 | Running loss: 0.50702\n",
      "Epoch: 7 | Iteration: 431 | Classification loss: 0.29216 | Regression loss: 0.42063 | Running loss: 0.50674\n",
      "Epoch: 7 | Iteration: 432 | Classification loss: 0.06320 | Regression loss: 0.30243 | Running loss: 0.50601\n",
      "Epoch: 7 | Iteration: 433 | Classification loss: 0.22863 | Regression loss: 0.21908 | Running loss: 0.50573\n",
      "Epoch: 7 | Iteration: 434 | Classification loss: 0.04782 | Regression loss: 0.27184 | Running loss: 0.50556\n",
      "Epoch: 7 | Iteration: 435 | Classification loss: 0.34651 | Regression loss: 0.25755 | Running loss: 0.50567\n",
      "Epoch: 7 | Iteration: 436 | Classification loss: 0.06923 | Regression loss: 0.25331 | Running loss: 0.50524\n",
      "Epoch: 7 | Iteration: 437 | Classification loss: 0.14023 | Regression loss: 0.43576 | Running loss: 0.50539\n",
      "Epoch: 7 | Iteration: 438 | Classification loss: 0.36706 | Regression loss: 0.37703 | Running loss: 0.50597\n",
      "Epoch: 7 | Iteration: 439 | Classification loss: 0.17971 | Regression loss: 0.20619 | Running loss: 0.50533\n",
      "Epoch: 7 | Iteration: 440 | Classification loss: 0.17834 | Regression loss: 0.27050 | Running loss: 0.50493\n",
      "Epoch: 7 | Iteration: 441 | Classification loss: 0.24652 | Regression loss: 0.24744 | Running loss: 0.50454\n",
      "Epoch: 7 | Iteration: 442 | Classification loss: 0.14797 | Regression loss: 0.19140 | Running loss: 0.50416\n",
      "Epoch: 7 | Iteration: 443 | Classification loss: 0.07333 | Regression loss: 0.14992 | Running loss: 0.50398\n",
      "Epoch: 7 | Iteration: 444 | Classification loss: 0.30914 | Regression loss: 0.70868 | Running loss: 0.50508\n",
      "Epoch: 7 | Iteration: 445 | Classification loss: 0.23211 | Regression loss: 0.32784 | Running loss: 0.50573\n",
      "Epoch: 7 | Iteration: 446 | Classification loss: 0.17262 | Regression loss: 0.36901 | Running loss: 0.50554\n",
      "Epoch: 7 | Iteration: 447 | Classification loss: 0.28005 | Regression loss: 0.35998 | Running loss: 0.50598\n",
      "Epoch: 7 | Iteration: 448 | Classification loss: 0.12678 | Regression loss: 0.27510 | Running loss: 0.50645\n",
      "Epoch: 7 | Iteration: 449 | Classification loss: 0.12227 | Regression loss: 0.15278 | Running loss: 0.50634\n",
      "Epoch: 7 | Iteration: 450 | Classification loss: 0.37218 | Regression loss: 0.25372 | Running loss: 0.50680\n",
      "Epoch: 7 | Iteration: 451 | Classification loss: 0.10092 | Regression loss: 0.31028 | Running loss: 0.50633\n",
      "Epoch: 7 | Iteration: 452 | Classification loss: 0.36973 | Regression loss: 0.54751 | Running loss: 0.50693\n",
      "Epoch: 7 | Iteration: 453 | Classification loss: 0.21496 | Regression loss: 0.15567 | Running loss: 0.50714\n",
      "Epoch: 7 | Iteration: 454 | Classification loss: 0.24707 | Regression loss: 0.32478 | Running loss: 0.50604\n",
      "Epoch: 7 | Iteration: 455 | Classification loss: 0.33799 | Regression loss: 0.64542 | Running loss: 0.50723\n",
      "Epoch: 7 | Iteration: 456 | Classification loss: 0.11189 | Regression loss: 0.36327 | Running loss: 0.50665\n",
      "Epoch: 7 | Iteration: 457 | Classification loss: 0.43300 | Regression loss: 0.18339 | Running loss: 0.50710\n",
      "Epoch: 7 | Iteration: 458 | Classification loss: 0.31256 | Regression loss: 0.27941 | Running loss: 0.50718\n",
      "Epoch: 7 | Iteration: 459 | Classification loss: 0.05349 | Regression loss: 0.12740 | Running loss: 0.50671\n",
      "Epoch: 7 | Iteration: 460 | Classification loss: 0.30636 | Regression loss: 0.47655 | Running loss: 0.50750\n",
      "Epoch: 7 | Iteration: 461 | Classification loss: 0.13988 | Regression loss: 0.24535 | Running loss: 0.50629\n",
      "Epoch: 7 | Iteration: 462 | Classification loss: 0.10364 | Regression loss: 0.25928 | Running loss: 0.50640\n",
      "Epoch: 7 | Iteration: 463 | Classification loss: 0.14127 | Regression loss: 0.23732 | Running loss: 0.50592\n",
      "Epoch: 7 | Iteration: 464 | Classification loss: 0.07225 | Regression loss: 0.33562 | Running loss: 0.50498\n",
      "Epoch: 7 | Iteration: 465 | Classification loss: 0.52411 | Regression loss: 0.66041 | Running loss: 0.50575\n",
      "Epoch: 7 | Iteration: 466 | Classification loss: 0.05726 | Regression loss: 0.18699 | Running loss: 0.50556\n",
      "Epoch: 7 | Iteration: 467 | Classification loss: 0.15771 | Regression loss: 0.19653 | Running loss: 0.50478\n",
      "Epoch: 7 | Iteration: 468 | Classification loss: 0.34673 | Regression loss: 0.28090 | Running loss: 0.50476\n",
      "Epoch: 7 | Iteration: 469 | Classification loss: 0.08602 | Regression loss: 0.31826 | Running loss: 0.50397\n",
      "Epoch: 7 | Iteration: 470 | Classification loss: 0.16763 | Regression loss: 0.32019 | Running loss: 0.50407\n",
      "Epoch: 7 | Iteration: 471 | Classification loss: 0.05765 | Regression loss: 0.27096 | Running loss: 0.50393\n",
      "Epoch: 7 | Iteration: 472 | Classification loss: 0.27150 | Regression loss: 0.49442 | Running loss: 0.50402\n",
      "Epoch: 7 | Iteration: 473 | Classification loss: 0.06868 | Regression loss: 0.34757 | Running loss: 0.50430\n",
      "Epoch: 7 | Iteration: 474 | Classification loss: 0.07918 | Regression loss: 0.14781 | Running loss: 0.50364\n",
      "Epoch: 7 | Iteration: 475 | Classification loss: 0.08853 | Regression loss: 0.16690 | Running loss: 0.50334\n",
      "Epoch: 7 | Iteration: 476 | Classification loss: 0.32712 | Regression loss: 0.53725 | Running loss: 0.50476\n",
      "Epoch: 7 | Iteration: 477 | Classification loss: 0.10680 | Regression loss: 0.39904 | Running loss: 0.50498\n",
      "Epoch: 7 | Iteration: 478 | Classification loss: 0.19120 | Regression loss: 0.18649 | Running loss: 0.50533\n",
      "Epoch: 7 | Iteration: 479 | Classification loss: 0.15541 | Regression loss: 0.26160 | Running loss: 0.50538\n",
      "Epoch: 7 | Iteration: 480 | Classification loss: 0.20104 | Regression loss: 0.30127 | Running loss: 0.50571\n",
      "Epoch: 7 | Iteration: 481 | Classification loss: 0.22312 | Regression loss: 0.71940 | Running loss: 0.50584\n",
      "Epoch: 7 | Iteration: 482 | Classification loss: 0.52009 | Regression loss: 0.26832 | Running loss: 0.50630\n",
      "Epoch: 7 | Iteration: 483 | Classification loss: 0.07895 | Regression loss: 0.17581 | Running loss: 0.50553\n",
      "Epoch: 7 | Iteration: 484 | Classification loss: 0.10534 | Regression loss: 0.23920 | Running loss: 0.50524\n",
      "Epoch: 7 | Iteration: 485 | Classification loss: 0.23869 | Regression loss: 0.25278 | Running loss: 0.50506\n",
      "Epoch: 7 | Iteration: 486 | Classification loss: 0.32645 | Regression loss: 0.37693 | Running loss: 0.50531\n",
      "Epoch: 7 | Iteration: 487 | Classification loss: 0.33003 | Regression loss: 0.20150 | Running loss: 0.50512\n",
      "Epoch: 7 | Iteration: 488 | Classification loss: 0.42546 | Regression loss: 0.68982 | Running loss: 0.50637\n",
      "Epoch: 7 | Iteration: 489 | Classification loss: 0.15826 | Regression loss: 0.43810 | Running loss: 0.50527\n",
      "Epoch: 7 | Iteration: 490 | Classification loss: 0.18396 | Regression loss: 0.37432 | Running loss: 0.50515\n",
      "Epoch: 7 | Iteration: 491 | Classification loss: 0.40805 | Regression loss: 0.27876 | Running loss: 0.50499\n",
      "Epoch: 7 | Iteration: 492 | Classification loss: 0.17196 | Regression loss: 0.24997 | Running loss: 0.50496\n",
      "Epoch: 7 | Iteration: 493 | Classification loss: 0.09798 | Regression loss: 0.15395 | Running loss: 0.50451\n",
      "Epoch: 7 | Iteration: 494 | Classification loss: 0.07247 | Regression loss: 0.30469 | Running loss: 0.50353\n",
      "Epoch: 7 | Iteration: 495 | Classification loss: 0.08654 | Regression loss: 0.25305 | Running loss: 0.50252\n",
      "Epoch: 7 | Iteration: 496 | Classification loss: 0.20288 | Regression loss: 0.55286 | Running loss: 0.50340\n",
      "Epoch: 7 | Iteration: 497 | Classification loss: 0.71636 | Regression loss: 0.29731 | Running loss: 0.50466\n",
      "Epoch: 7 | Iteration: 498 | Classification loss: 0.37447 | Regression loss: 0.29653 | Running loss: 0.50507\n",
      "Epoch: 7 | Iteration: 499 | Classification loss: 0.39730 | Regression loss: 0.29076 | Running loss: 0.50510\n",
      "Epoch: 7 | Iteration: 500 | Classification loss: 0.09312 | Regression loss: 0.24831 | Running loss: 0.50422\n",
      "Epoch: 7 | Iteration: 501 | Classification loss: 0.40064 | Regression loss: 0.14582 | Running loss: 0.50422\n",
      "Epoch: 7 | Iteration: 502 | Classification loss: 0.25191 | Regression loss: 0.41356 | Running loss: 0.50426\n",
      "Epoch: 7 | Iteration: 503 | Classification loss: 0.08632 | Regression loss: 0.23232 | Running loss: 0.50359\n",
      "Epoch: 7 | Iteration: 504 | Classification loss: 0.13496 | Regression loss: 0.26727 | Running loss: 0.50315\n",
      "Epoch: 7 | Iteration: 505 | Classification loss: 0.12086 | Regression loss: 0.53799 | Running loss: 0.50371\n",
      "Epoch: 7 | Iteration: 506 | Classification loss: 0.15062 | Regression loss: 0.24158 | Running loss: 0.50359\n",
      "Epoch: 7 | Iteration: 507 | Classification loss: 0.23063 | Regression loss: 0.48540 | Running loss: 0.50406\n",
      "Epoch: 7 | Iteration: 508 | Classification loss: 0.14739 | Regression loss: 0.21376 | Running loss: 0.50329\n",
      "Epoch: 7 | Iteration: 509 | Classification loss: 0.18702 | Regression loss: 0.26334 | Running loss: 0.50310\n",
      "Epoch: 7 | Iteration: 510 | Classification loss: 0.06308 | Regression loss: 0.20967 | Running loss: 0.50209\n",
      "Epoch: 7 | Iteration: 511 | Classification loss: 0.36161 | Regression loss: 0.39468 | Running loss: 0.50270\n",
      "Epoch: 7 | Iteration: 512 | Classification loss: 0.35949 | Regression loss: 0.28184 | Running loss: 0.50324\n",
      "Epoch: 7 | Iteration: 513 | Classification loss: 0.15219 | Regression loss: 0.25959 | Running loss: 0.50251\n",
      "Epoch: 7 | Iteration: 514 | Classification loss: 0.06239 | Regression loss: 0.29572 | Running loss: 0.50277\n",
      "Epoch: 7 | Iteration: 515 | Classification loss: 0.55126 | Regression loss: 0.62101 | Running loss: 0.50418\n",
      "Epoch: 7 | Iteration: 516 | Classification loss: 0.12492 | Regression loss: 0.22142 | Running loss: 0.50440\n",
      "Epoch: 7 | Iteration: 517 | Classification loss: 0.36436 | Regression loss: 0.55443 | Running loss: 0.50537\n",
      "Epoch: 7 | Iteration: 518 | Classification loss: 0.15975 | Regression loss: 0.39960 | Running loss: 0.50549\n",
      "Epoch: 7 | Iteration: 519 | Classification loss: 0.06109 | Regression loss: 0.27455 | Running loss: 0.50533\n",
      "Epoch: 7 | Iteration: 520 | Classification loss: 0.07826 | Regression loss: 0.14753 | Running loss: 0.50472\n",
      "Epoch: 7 | Iteration: 521 | Classification loss: 0.10651 | Regression loss: 0.18486 | Running loss: 0.50437\n",
      "Epoch: 7 | Iteration: 522 | Classification loss: 0.09245 | Regression loss: 0.39771 | Running loss: 0.50362\n",
      "Epoch: 7 | Iteration: 523 | Classification loss: 0.12900 | Regression loss: 0.27302 | Running loss: 0.50348\n",
      "Epoch: 7 | Iteration: 524 | Classification loss: 0.08853 | Regression loss: 0.13748 | Running loss: 0.50321\n",
      "Epoch: 7 | Iteration: 525 | Classification loss: 0.19621 | Regression loss: 0.27847 | Running loss: 0.50360\n",
      "Epoch: 7 | Iteration: 526 | Classification loss: 0.13575 | Regression loss: 0.30948 | Running loss: 0.50407\n",
      "Epoch: 7 | Iteration: 527 | Classification loss: 0.11215 | Regression loss: 0.22968 | Running loss: 0.50413\n",
      "Epoch: 7 | Iteration: 528 | Classification loss: 0.18397 | Regression loss: 0.24627 | Running loss: 0.50380\n",
      "Epoch: 7 | Iteration: 529 | Classification loss: 0.08582 | Regression loss: 0.14857 | Running loss: 0.50370\n",
      "Epoch: 7 | Iteration: 530 | Classification loss: 0.26277 | Regression loss: 0.59706 | Running loss: 0.50391\n",
      "Epoch: 7 | Iteration: 531 | Classification loss: 0.26072 | Regression loss: 0.29862 | Running loss: 0.50384\n",
      "Epoch: 7 | Iteration: 532 | Classification loss: 0.52801 | Regression loss: 0.35133 | Running loss: 0.50478\n",
      "Epoch: 7 | Iteration: 533 | Classification loss: 0.17796 | Regression loss: 0.20731 | Running loss: 0.50454\n",
      "Epoch: 7 | Iteration: 534 | Classification loss: 0.24198 | Regression loss: 0.48440 | Running loss: 0.50531\n",
      "Epoch: 7 | Iteration: 535 | Classification loss: 0.33806 | Regression loss: 0.23873 | Running loss: 0.50511\n",
      "Epoch: 7 | Iteration: 536 | Classification loss: 0.18310 | Regression loss: 0.43858 | Running loss: 0.50501\n",
      "Epoch: 7 | Iteration: 537 | Classification loss: 0.17176 | Regression loss: 0.24456 | Running loss: 0.50473\n",
      "Epoch: 7 | Iteration: 538 | Classification loss: 0.14571 | Regression loss: 0.22024 | Running loss: 0.50459\n",
      "Epoch: 7 | Iteration: 539 | Classification loss: 0.10324 | Regression loss: 0.20015 | Running loss: 0.50368\n",
      "Epoch: 7 | Iteration: 540 | Classification loss: 0.07742 | Regression loss: 0.32384 | Running loss: 0.50333\n",
      "Epoch: 7 | Iteration: 541 | Classification loss: 0.23150 | Regression loss: 0.22213 | Running loss: 0.50340\n",
      "Epoch: 7 | Iteration: 542 | Classification loss: 0.05102 | Regression loss: 0.25404 | Running loss: 0.50323\n",
      "Epoch: 7 | Iteration: 543 | Classification loss: 0.16763 | Regression loss: 0.17168 | Running loss: 0.50310\n",
      "Epoch: 7 | Iteration: 544 | Classification loss: 0.22354 | Regression loss: 0.30891 | Running loss: 0.50295\n",
      "Epoch: 7 | Iteration: 545 | Classification loss: 0.16763 | Regression loss: 0.31374 | Running loss: 0.50234\n",
      "Epoch: 7 | Iteration: 546 | Classification loss: 0.08579 | Regression loss: 0.14368 | Running loss: 0.50107\n",
      "Epoch: 7 | Iteration: 547 | Classification loss: 0.10412 | Regression loss: 0.47366 | Running loss: 0.50132\n",
      "Epoch: 7 | Iteration: 548 | Classification loss: 0.00124 | Regression loss: 0.00000 | Running loss: 0.50059\n",
      "Epoch: 7 | Iteration: 549 | Classification loss: 0.11751 | Regression loss: 0.32626 | Running loss: 0.50048\n",
      "Epoch: 7 | Iteration: 550 | Classification loss: 0.05881 | Regression loss: 0.17612 | Running loss: 0.50033\n",
      "Epoch: 7 | Iteration: 551 | Classification loss: 0.14459 | Regression loss: 0.43410 | Running loss: 0.50073\n",
      "Epoch: 7 | Iteration: 552 | Classification loss: 0.19271 | Regression loss: 0.33749 | Running loss: 0.50131\n",
      "Epoch: 7 | Iteration: 553 | Classification loss: 0.32986 | Regression loss: 0.44945 | Running loss: 0.50173\n",
      "Epoch: 7 | Iteration: 554 | Classification loss: 0.55418 | Regression loss: 0.23554 | Running loss: 0.50229\n",
      "Epoch: 7 | Iteration: 555 | Classification loss: 0.15398 | Regression loss: 0.44023 | Running loss: 0.50237\n",
      "Epoch: 7 | Iteration: 556 | Classification loss: 0.23787 | Regression loss: 0.44644 | Running loss: 0.50323\n",
      "Epoch: 7 | Iteration: 557 | Classification loss: 0.27653 | Regression loss: 0.27008 | Running loss: 0.50389\n",
      "Epoch: 7 | Iteration: 558 | Classification loss: 0.26754 | Regression loss: 0.38078 | Running loss: 0.50467\n",
      "Epoch: 7 | Iteration: 559 | Classification loss: 0.27939 | Regression loss: 0.23855 | Running loss: 0.50493\n",
      "Epoch: 7 | Iteration: 560 | Classification loss: 0.11466 | Regression loss: 0.24249 | Running loss: 0.50498\n",
      "Epoch: 7 | Iteration: 561 | Classification loss: 0.09741 | Regression loss: 0.13391 | Running loss: 0.50472\n",
      "Epoch: 7 | Iteration: 562 | Classification loss: 0.03922 | Regression loss: 0.14521 | Running loss: 0.50462\n",
      "Epoch: 7 | Iteration: 563 | Classification loss: 0.29558 | Regression loss: 0.26123 | Running loss: 0.50530\n",
      "Epoch: 7 | Iteration: 564 | Classification loss: 0.28499 | Regression loss: 0.38949 | Running loss: 0.50531\n",
      "Epoch: 7 | Iteration: 565 | Classification loss: 0.13913 | Regression loss: 0.32683 | Running loss: 0.50564\n",
      "Epoch: 7 | Iteration: 566 | Classification loss: 0.07078 | Regression loss: 0.11245 | Running loss: 0.50533\n",
      "Epoch: 7 | Iteration: 567 | Classification loss: 0.21249 | Regression loss: 0.32600 | Running loss: 0.50585\n",
      "Epoch: 7 | Iteration: 568 | Classification loss: 0.27147 | Regression loss: 0.23270 | Running loss: 0.50584\n",
      "Epoch: 7 | Iteration: 569 | Classification loss: 0.37490 | Regression loss: 0.64620 | Running loss: 0.50634\n",
      "Epoch: 7 | Iteration: 570 | Classification loss: 0.46600 | Regression loss: 0.79635 | Running loss: 0.50812\n",
      "Epoch: 7 | Iteration: 571 | Classification loss: 0.10421 | Regression loss: 0.22725 | Running loss: 0.50787\n",
      "Epoch: 7 | Iteration: 572 | Classification loss: 0.07270 | Regression loss: 0.18230 | Running loss: 0.50732\n",
      "Epoch: 7 | Iteration: 573 | Classification loss: 0.19526 | Regression loss: 0.28372 | Running loss: 0.50767\n",
      "Epoch: 7 | Iteration: 574 | Classification loss: 0.12195 | Regression loss: 0.30390 | Running loss: 0.50796\n",
      "Epoch: 7 | Iteration: 575 | Classification loss: 0.22201 | Regression loss: 0.49060 | Running loss: 0.50863\n",
      "Epoch: 7 | Iteration: 576 | Classification loss: 0.07416 | Regression loss: 0.18511 | Running loss: 0.50785\n",
      "Epoch: 7 | Iteration: 577 | Classification loss: 0.24389 | Regression loss: 0.32134 | Running loss: 0.50846\n",
      "Epoch: 7 | Iteration: 578 | Classification loss: 0.06957 | Regression loss: 0.16207 | Running loss: 0.50808\n",
      "Epoch: 7 | Iteration: 579 | Classification loss: 0.18397 | Regression loss: 0.33627 | Running loss: 0.50831\n",
      "Epoch: 7 | Iteration: 580 | Classification loss: 0.29048 | Regression loss: 0.44963 | Running loss: 0.50915\n",
      "Epoch: 7 | Iteration: 581 | Classification loss: 0.08844 | Regression loss: 0.19163 | Running loss: 0.50902\n",
      "Epoch: 7 | Iteration: 582 | Classification loss: 0.12734 | Regression loss: 0.26881 | Running loss: 0.50902\n",
      "Epoch: 7 | Iteration: 583 | Classification loss: 0.05317 | Regression loss: 0.12594 | Running loss: 0.50886\n",
      "Epoch: 7 | Iteration: 584 | Classification loss: 0.35636 | Regression loss: 0.33706 | Running loss: 0.50884\n",
      "Epoch: 7 | Iteration: 585 | Classification loss: 0.04820 | Regression loss: 0.13348 | Running loss: 0.50742\n",
      "Epoch: 7 | Iteration: 586 | Classification loss: 0.22450 | Regression loss: 0.13413 | Running loss: 0.50735\n",
      "Epoch: 7 | Iteration: 587 | Classification loss: 0.07255 | Regression loss: 0.17341 | Running loss: 0.50669\n",
      "Epoch: 7 | Iteration: 588 | Classification loss: 0.27380 | Regression loss: 0.60651 | Running loss: 0.50783\n",
      "Epoch: 7 | Iteration: 589 | Classification loss: 0.12608 | Regression loss: 0.27729 | Running loss: 0.50708\n",
      "Epoch: 7 | Iteration: 590 | Classification loss: 0.14323 | Regression loss: 0.41489 | Running loss: 0.50705\n",
      "Epoch: 7 | Iteration: 591 | Classification loss: 0.24182 | Regression loss: 0.30460 | Running loss: 0.50734\n",
      "Epoch: 7 | Iteration: 592 | Classification loss: 0.20542 | Regression loss: 0.28339 | Running loss: 0.50741\n",
      "Epoch: 7 | Iteration: 593 | Classification loss: 0.13965 | Regression loss: 0.27645 | Running loss: 0.50656\n",
      "Epoch: 7 | Iteration: 594 | Classification loss: 0.38908 | Regression loss: 0.12646 | Running loss: 0.50642\n",
      "Epoch: 7 | Iteration: 595 | Classification loss: 0.21552 | Regression loss: 0.45173 | Running loss: 0.50658\n",
      "Epoch: 7 | Iteration: 596 | Classification loss: 0.26956 | Regression loss: 0.32055 | Running loss: 0.50659\n",
      "Epoch: 7 | Iteration: 597 | Classification loss: 0.42639 | Regression loss: 0.34255 | Running loss: 0.50664\n",
      "Epoch: 7 | Iteration: 598 | Classification loss: 0.09802 | Regression loss: 0.30776 | Running loss: 0.50559\n",
      "Epoch: 7 | Iteration: 599 | Classification loss: 0.04701 | Regression loss: 0.25505 | Running loss: 0.50519\n",
      "Epoch: 7 | Iteration: 600 | Classification loss: 0.14932 | Regression loss: 0.28637 | Running loss: 0.50491\n",
      "Epoch: 7 | Iteration: 601 | Classification loss: 0.19205 | Regression loss: 0.21095 | Running loss: 0.50408\n",
      "Epoch: 7 | Iteration: 602 | Classification loss: 0.09393 | Regression loss: 0.26582 | Running loss: 0.50440\n",
      "Epoch: 7 | Iteration: 603 | Classification loss: 0.04833 | Regression loss: 0.17929 | Running loss: 0.50388\n",
      "Epoch: 7 | Iteration: 604 | Classification loss: 0.09756 | Regression loss: 0.22150 | Running loss: 0.50325\n",
      "Epoch: 7 | Iteration: 605 | Classification loss: 0.03694 | Regression loss: 0.14356 | Running loss: 0.50236\n",
      "Epoch: 7 | Iteration: 606 | Classification loss: 0.06275 | Regression loss: 0.16350 | Running loss: 0.50223\n",
      "Epoch: 7 | Iteration: 607 | Classification loss: 0.02909 | Regression loss: 0.06223 | Running loss: 0.50160\n",
      "Epoch: 7 | Iteration: 608 | Classification loss: 0.12230 | Regression loss: 0.45815 | Running loss: 0.50218\n",
      "Epoch: 7 | Iteration: 609 | Classification loss: 0.05914 | Regression loss: 0.29736 | Running loss: 0.50210\n",
      "Epoch: 7 | Iteration: 610 | Classification loss: 0.42720 | Regression loss: 0.29357 | Running loss: 0.50256\n",
      "Epoch: 7 | Iteration: 611 | Classification loss: 0.30676 | Regression loss: 0.42579 | Running loss: 0.50312\n",
      "Epoch: 7 | Iteration: 612 | Classification loss: 0.28970 | Regression loss: 0.24926 | Running loss: 0.50319\n",
      "Epoch: 7 | Iteration: 613 | Classification loss: 0.61161 | Regression loss: 0.26121 | Running loss: 0.50430\n",
      "Epoch: 7 | Iteration: 614 | Classification loss: 0.10645 | Regression loss: 0.19742 | Running loss: 0.50433\n",
      "Epoch: 7 | Iteration: 615 | Classification loss: 0.14768 | Regression loss: 0.16160 | Running loss: 0.50415\n",
      "Epoch: 7 | Iteration: 616 | Classification loss: 0.09328 | Regression loss: 0.22506 | Running loss: 0.50380\n",
      "Epoch: 7 | Iteration: 617 | Classification loss: 0.14674 | Regression loss: 0.20101 | Running loss: 0.50363\n",
      "Epoch: 7 | Iteration: 618 | Classification loss: 0.04280 | Regression loss: 0.32097 | Running loss: 0.50391\n",
      "Epoch: 7 | Iteration: 619 | Classification loss: 0.17211 | Regression loss: 0.39645 | Running loss: 0.50370\n",
      "Epoch: 7 | Iteration: 620 | Classification loss: 0.50980 | Regression loss: 0.68877 | Running loss: 0.50516\n",
      "Epoch: 7 | Iteration: 621 | Classification loss: 0.13039 | Regression loss: 0.23245 | Running loss: 0.50484\n",
      "Epoch: 7 | Iteration: 622 | Classification loss: 0.19796 | Regression loss: 0.44194 | Running loss: 0.50468\n",
      "Epoch: 7 | Iteration: 623 | Classification loss: 0.24638 | Regression loss: 0.28172 | Running loss: 0.50451\n",
      "Epoch: 7 | Iteration: 624 | Classification loss: 0.14612 | Regression loss: 0.30643 | Running loss: 0.50489\n",
      "Epoch: 7 | Iteration: 625 | Classification loss: 0.24105 | Regression loss: 0.20450 | Running loss: 0.50422\n",
      "Epoch: 7 | Iteration: 626 | Classification loss: 0.25064 | Regression loss: 0.37822 | Running loss: 0.50456\n",
      "Epoch: 7 | Iteration: 627 | Classification loss: 0.10870 | Regression loss: 0.21765 | Running loss: 0.50372\n",
      "Epoch: 7 | Iteration: 628 | Classification loss: 0.19432 | Regression loss: 0.27176 | Running loss: 0.50317\n",
      "Epoch: 7 | Iteration: 629 | Classification loss: 0.37233 | Regression loss: 0.26910 | Running loss: 0.50297\n",
      "Epoch: 7 | Iteration: 630 | Classification loss: 0.17148 | Regression loss: 0.27649 | Running loss: 0.50296\n",
      "Epoch: 7 | Iteration: 631 | Classification loss: 0.07638 | Regression loss: 0.18149 | Running loss: 0.50282\n",
      "Epoch: 7 | Iteration: 632 | Classification loss: 0.09560 | Regression loss: 0.34278 | Running loss: 0.50329\n",
      "Epoch: 7 | Iteration: 633 | Classification loss: 0.69719 | Regression loss: 0.43207 | Running loss: 0.50439\n",
      "Epoch: 7 | Iteration: 634 | Classification loss: 0.15721 | Regression loss: 0.30802 | Running loss: 0.50438\n",
      "Epoch: 7 | Iteration: 635 | Classification loss: 0.07512 | Regression loss: 0.33208 | Running loss: 0.50480\n",
      "Epoch: 7 | Iteration: 636 | Classification loss: 0.25685 | Regression loss: 0.50207 | Running loss: 0.50558\n",
      "Epoch: 7 | Iteration: 637 | Classification loss: 0.12577 | Regression loss: 0.29697 | Running loss: 0.50530\n",
      "Epoch: 7 | Iteration: 638 | Classification loss: 0.07028 | Regression loss: 0.22607 | Running loss: 0.50519\n",
      "Epoch: 7 | Iteration: 639 | Classification loss: 0.35723 | Regression loss: 0.59746 | Running loss: 0.50540\n",
      "Epoch: 7 | Iteration: 640 | Classification loss: 0.12596 | Regression loss: 0.22973 | Running loss: 0.50461\n",
      "Epoch: 7 | Iteration: 641 | Classification loss: 0.14276 | Regression loss: 0.46487 | Running loss: 0.50451\n",
      "Epoch: 7 | Iteration: 642 | Classification loss: 0.27577 | Regression loss: 0.34275 | Running loss: 0.50487\n",
      "Epoch: 7 | Iteration: 643 | Classification loss: 0.17503 | Regression loss: 0.30135 | Running loss: 0.50479\n",
      "Epoch: 7 | Iteration: 644 | Classification loss: 0.35069 | Regression loss: 0.26504 | Running loss: 0.50476\n",
      "Epoch: 7 | Iteration: 645 | Classification loss: 0.44094 | Regression loss: 0.11397 | Running loss: 0.50470\n",
      "Epoch: 7 | Iteration: 646 | Classification loss: 0.08102 | Regression loss: 0.30994 | Running loss: 0.50431\n",
      "Epoch: 7 | Iteration: 647 | Classification loss: 0.09643 | Regression loss: 0.24339 | Running loss: 0.50329\n",
      "Epoch: 7 | Iteration: 648 | Classification loss: 0.23226 | Regression loss: 0.28763 | Running loss: 0.50386\n",
      "Epoch: 7 | Iteration: 649 | Classification loss: 0.16871 | Regression loss: 0.30696 | Running loss: 0.50395\n",
      "Epoch: 7 | Iteration: 650 | Classification loss: 0.40098 | Regression loss: 0.53074 | Running loss: 0.50457\n",
      "Epoch: 7 | Iteration: 651 | Classification loss: 0.13756 | Regression loss: 0.47630 | Running loss: 0.50537\n",
      "Epoch: 7 | Iteration: 652 | Classification loss: 0.11548 | Regression loss: 0.24521 | Running loss: 0.50530\n",
      "Epoch: 7 | Iteration: 653 | Classification loss: 0.36013 | Regression loss: 0.17247 | Running loss: 0.50508\n",
      "Epoch: 7 | Iteration: 654 | Classification loss: 0.17002 | Regression loss: 0.41695 | Running loss: 0.50543\n",
      "Epoch: 7 | Iteration: 655 | Classification loss: 0.17559 | Regression loss: 0.37630 | Running loss: 0.50601\n",
      "Epoch: 7 | Iteration: 656 | Classification loss: 0.13785 | Regression loss: 0.29277 | Running loss: 0.50569\n",
      "Epoch: 7 | Iteration: 657 | Classification loss: 0.18899 | Regression loss: 0.20911 | Running loss: 0.50573\n",
      "Epoch: 7 | Iteration: 658 | Classification loss: 0.32527 | Regression loss: 0.40649 | Running loss: 0.50637\n",
      "Epoch: 7 | Iteration: 659 | Classification loss: 0.13894 | Regression loss: 0.20265 | Running loss: 0.50577\n",
      "Epoch: 7 | Iteration: 660 | Classification loss: 0.41515 | Regression loss: 0.43707 | Running loss: 0.50649\n",
      "Epoch: 7 | Iteration: 661 | Classification loss: 0.07896 | Regression loss: 0.25629 | Running loss: 0.50600\n",
      "Epoch: 7 | Iteration: 662 | Classification loss: 0.42966 | Regression loss: 0.42462 | Running loss: 0.50728\n",
      "Epoch: 7 | Iteration: 663 | Classification loss: 0.07182 | Regression loss: 0.29366 | Running loss: 0.50704\n",
      "Epoch: 7 | Iteration: 664 | Classification loss: 0.38166 | Regression loss: 0.28808 | Running loss: 0.50779\n",
      "Epoch: 7 | Iteration: 665 | Classification loss: 0.10238 | Regression loss: 0.18775 | Running loss: 0.50773\n",
      "Epoch: 7 | Iteration: 666 | Classification loss: 0.10190 | Regression loss: 0.43766 | Running loss: 0.50806\n",
      "Epoch: 7 | Iteration: 667 | Classification loss: 0.17518 | Regression loss: 0.24162 | Running loss: 0.50795\n",
      "Epoch: 7 | Iteration: 668 | Classification loss: 0.27558 | Regression loss: 0.44859 | Running loss: 0.50874\n",
      "Epoch: 7 | Iteration: 669 | Classification loss: 0.17433 | Regression loss: 0.20882 | Running loss: 0.50872\n",
      "Epoch: 7 | Iteration: 670 | Classification loss: 0.10119 | Regression loss: 0.13896 | Running loss: 0.50776\n",
      "Epoch: 7 | Iteration: 671 | Classification loss: 0.26709 | Regression loss: 0.34670 | Running loss: 0.50729\n",
      "Epoch: 7 | Iteration: 672 | Classification loss: 0.21951 | Regression loss: 0.33983 | Running loss: 0.50740\n",
      "Epoch: 7 | Iteration: 673 | Classification loss: 0.12009 | Regression loss: 0.33646 | Running loss: 0.50776\n",
      "Epoch: 7 | Iteration: 674 | Classification loss: 0.24324 | Regression loss: 0.54238 | Running loss: 0.50851\n",
      "Epoch: 7 | Iteration: 675 | Classification loss: 0.07305 | Regression loss: 0.35770 | Running loss: 0.50716\n",
      "Epoch: 7 | Iteration: 676 | Classification loss: 0.07543 | Regression loss: 0.33228 | Running loss: 0.50689\n",
      "Epoch: 7 | Iteration: 677 | Classification loss: 0.03262 | Regression loss: 0.20128 | Running loss: 0.50672\n",
      "Epoch: 7 | Iteration: 678 | Classification loss: 0.09635 | Regression loss: 0.25872 | Running loss: 0.50660\n",
      "Epoch: 7 | Iteration: 679 | Classification loss: 0.06368 | Regression loss: 0.27220 | Running loss: 0.50601\n",
      "Epoch: 7 | Iteration: 680 | Classification loss: 0.51953 | Regression loss: 0.75800 | Running loss: 0.50783\n",
      "Epoch: 7 | Iteration: 681 | Classification loss: 0.13089 | Regression loss: 0.26829 | Running loss: 0.50776\n",
      "Epoch: 7 | Iteration: 682 | Classification loss: 0.12582 | Regression loss: 0.35394 | Running loss: 0.50810\n",
      "Epoch: 7 | Iteration: 683 | Classification loss: 0.06940 | Regression loss: 0.30416 | Running loss: 0.50838\n",
      "Epoch: 7 | Iteration: 684 | Classification loss: 0.18932 | Regression loss: 0.31054 | Running loss: 0.50820\n",
      "Epoch: 7 | Iteration: 685 | Classification loss: 0.13413 | Regression loss: 0.39891 | Running loss: 0.50877\n",
      "Epoch: 7 | Iteration: 686 | Classification loss: 0.44530 | Regression loss: 0.56176 | Running loss: 0.50947\n",
      "Epoch: 7 | Iteration: 687 | Classification loss: 0.20429 | Regression loss: 0.44168 | Running loss: 0.51002\n",
      "Epoch: 7 | Iteration: 688 | Classification loss: 0.13218 | Regression loss: 0.20625 | Running loss: 0.50982\n",
      "Epoch: 7 | Iteration: 689 | Classification loss: 0.09984 | Regression loss: 0.13124 | Running loss: 0.50940\n",
      "Epoch: 7 | Iteration: 690 | Classification loss: 0.21385 | Regression loss: 0.31921 | Running loss: 0.50909\n",
      "Epoch: 7 | Iteration: 691 | Classification loss: 0.12386 | Regression loss: 0.24207 | Running loss: 0.50892\n",
      "Epoch: 7 | Iteration: 692 | Classification loss: 0.24465 | Regression loss: 0.19654 | Running loss: 0.50830\n",
      "Epoch: 7 | Iteration: 693 | Classification loss: 0.34915 | Regression loss: 0.26484 | Running loss: 0.50704\n",
      "Epoch: 7 | Iteration: 694 | Classification loss: 0.28274 | Regression loss: 0.36458 | Running loss: 0.50641\n",
      "Epoch: 7 | Iteration: 695 | Classification loss: 0.07323 | Regression loss: 0.29841 | Running loss: 0.50616\n",
      "Epoch: 7 | Iteration: 696 | Classification loss: 0.10225 | Regression loss: 0.32612 | Running loss: 0.50619\n",
      "Epoch: 7 | Iteration: 697 | Classification loss: 0.25389 | Regression loss: 0.34165 | Running loss: 0.50657\n",
      "Epoch: 7 | Iteration: 698 | Classification loss: 0.10583 | Regression loss: 0.27382 | Running loss: 0.50600\n",
      "Epoch: 7 | Iteration: 699 | Classification loss: 0.09748 | Regression loss: 0.13573 | Running loss: 0.50496\n",
      "Epoch: 7 | Iteration: 700 | Classification loss: 0.28386 | Regression loss: 0.63656 | Running loss: 0.50588\n",
      "Epoch: 7 | Iteration: 701 | Classification loss: 0.11856 | Regression loss: 0.19529 | Running loss: 0.50605\n",
      "Epoch: 7 | Iteration: 702 | Classification loss: 0.08533 | Regression loss: 0.17088 | Running loss: 0.50584\n",
      "Epoch: 7 | Iteration: 703 | Classification loss: 0.23105 | Regression loss: 0.36615 | Running loss: 0.50594\n",
      "Epoch: 7 | Iteration: 704 | Classification loss: 0.09864 | Regression loss: 0.42674 | Running loss: 0.50600\n",
      "Epoch: 7 | Iteration: 705 | Classification loss: 0.11629 | Regression loss: 0.29245 | Running loss: 0.50621\n",
      "Epoch: 7 | Iteration: 706 | Classification loss: 0.19541 | Regression loss: 0.14644 | Running loss: 0.50627\n",
      "Epoch: 7 | Iteration: 707 | Classification loss: 0.15663 | Regression loss: 0.43265 | Running loss: 0.50642\n",
      "Epoch: 7 | Iteration: 708 | Classification loss: 0.22374 | Regression loss: 0.72871 | Running loss: 0.50687\n",
      "Epoch: 7 | Iteration: 709 | Classification loss: 0.14741 | Regression loss: 0.20492 | Running loss: 0.50659\n",
      "Epoch: 7 | Iteration: 710 | Classification loss: 0.29251 | Regression loss: 0.21822 | Running loss: 0.50682\n",
      "Epoch: 7 | Iteration: 711 | Classification loss: 0.37203 | Regression loss: 0.39988 | Running loss: 0.50722\n",
      "Epoch: 7 | Iteration: 712 | Classification loss: 0.27042 | Regression loss: 0.47163 | Running loss: 0.50810\n",
      "Epoch: 7 | Iteration: 713 | Classification loss: 0.10548 | Regression loss: 0.43156 | Running loss: 0.50867\n",
      "Epoch: 7 | Iteration: 714 | Classification loss: 0.10333 | Regression loss: 0.26758 | Running loss: 0.50858\n",
      "Epoch: 7 | Iteration: 715 | Classification loss: 0.16422 | Regression loss: 0.27090 | Running loss: 0.50868\n",
      "Epoch: 7 | Iteration: 716 | Classification loss: 0.12799 | Regression loss: 0.46915 | Running loss: 0.50924\n",
      "Epoch: 7 | Iteration: 717 | Classification loss: 0.16563 | Regression loss: 0.34097 | Running loss: 0.50886\n",
      "Epoch: 7 | Iteration: 718 | Classification loss: 0.33745 | Regression loss: 0.14640 | Running loss: 0.50922\n",
      "Epoch: 7 | Iteration: 719 | Classification loss: 0.14928 | Regression loss: 0.28556 | Running loss: 0.50891\n",
      "Epoch: 7 | Iteration: 720 | Classification loss: 0.08914 | Regression loss: 0.27376 | Running loss: 0.50900\n",
      "Epoch: 7 | Iteration: 721 | Classification loss: 0.56820 | Regression loss: 0.65975 | Running loss: 0.51050\n",
      "Epoch: 7 | Iteration: 722 | Classification loss: 0.12538 | Regression loss: 0.37382 | Running loss: 0.51054\n",
      "Epoch: 7 | Iteration: 723 | Classification loss: 0.37184 | Regression loss: 0.12361 | Running loss: 0.51095\n",
      "Epoch: 7 | Iteration: 724 | Classification loss: 0.07326 | Regression loss: 0.21031 | Running loss: 0.51012\n",
      "Epoch: 7 | Iteration: 725 | Classification loss: 0.13628 | Regression loss: 0.24847 | Running loss: 0.51020\n",
      "Epoch: 7 | Iteration: 726 | Classification loss: 0.04815 | Regression loss: 0.23559 | Running loss: 0.51019\n",
      "Epoch: 7 | Iteration: 727 | Classification loss: 0.11602 | Regression loss: 0.20693 | Running loss: 0.50989\n",
      "Epoch: 7 | Iteration: 728 | Classification loss: 0.27474 | Regression loss: 0.24553 | Running loss: 0.50989\n",
      "Epoch: 7 | Iteration: 729 | Classification loss: 0.18975 | Regression loss: 0.55077 | Running loss: 0.51007\n",
      "Epoch: 7 | Iteration: 730 | Classification loss: 0.28658 | Regression loss: 0.35682 | Running loss: 0.51050\n",
      "Epoch: 7 | Iteration: 731 | Classification loss: 0.18452 | Regression loss: 0.32431 | Running loss: 0.51100\n",
      "Epoch: 7 | Iteration: 732 | Classification loss: 0.32259 | Regression loss: 0.48681 | Running loss: 0.51148\n",
      "Epoch: 7 | Iteration: 733 | Classification loss: 0.30688 | Regression loss: 0.64450 | Running loss: 0.51249\n",
      "Epoch: 7 | Iteration: 734 | Classification loss: 0.26587 | Regression loss: 0.25966 | Running loss: 0.51187\n",
      "Epoch: 7 | Iteration: 735 | Classification loss: 0.24866 | Regression loss: 0.45528 | Running loss: 0.51214\n",
      "Epoch: 7 | Iteration: 736 | Classification loss: 0.06917 | Regression loss: 0.28010 | Running loss: 0.51229\n",
      "Epoch: 7 | Iteration: 737 | Classification loss: 0.09370 | Regression loss: 0.31368 | Running loss: 0.51200\n",
      "Epoch: 7 | Iteration: 738 | Classification loss: 0.03505 | Regression loss: 0.24986 | Running loss: 0.51143\n",
      "Epoch: 7 | Iteration: 739 | Classification loss: 0.06244 | Regression loss: 0.21323 | Running loss: 0.51103\n",
      "Epoch: 7 | Iteration: 740 | Classification loss: 0.16630 | Regression loss: 0.13415 | Running loss: 0.51013\n",
      "Epoch: 7 | Iteration: 741 | Classification loss: 0.11941 | Regression loss: 0.40559 | Running loss: 0.51035\n",
      "Epoch: 7 | Iteration: 742 | Classification loss: 0.24484 | Regression loss: 0.42776 | Running loss: 0.51087\n",
      "Epoch: 7 | Iteration: 743 | Classification loss: 0.09695 | Regression loss: 0.27473 | Running loss: 0.51095\n",
      "Epoch: 7 | Iteration: 744 | Classification loss: 0.19335 | Regression loss: 0.31609 | Running loss: 0.51122\n",
      "Epoch: 7 | Iteration: 745 | Classification loss: 0.27233 | Regression loss: 0.32074 | Running loss: 0.51171\n",
      "Epoch: 7 | Iteration: 746 | Classification loss: 0.18303 | Regression loss: 0.32808 | Running loss: 0.51142\n",
      "Epoch: 7 | Iteration: 747 | Classification loss: 0.61972 | Regression loss: 0.23161 | Running loss: 0.51225\n",
      "Epoch: 7 | Iteration: 748 | Classification loss: 0.27302 | Regression loss: 0.25136 | Running loss: 0.51187\n",
      "Epoch: 7 | Iteration: 749 | Classification loss: 0.08451 | Regression loss: 0.30453 | Running loss: 0.51182\n",
      "Epoch: 7 | Iteration: 750 | Classification loss: 0.23389 | Regression loss: 0.48119 | Running loss: 0.51196\n",
      "Epoch: 7 | Iteration: 751 | Classification loss: 0.17234 | Regression loss: 0.33051 | Running loss: 0.51149\n",
      "Epoch: 7 | Iteration: 752 | Classification loss: 0.17418 | Regression loss: 0.26725 | Running loss: 0.51083\n",
      "Epoch: 7 | Iteration: 753 | Classification loss: 0.32634 | Regression loss: 0.58586 | Running loss: 0.51065\n",
      "Epoch: 7 | Iteration: 754 | Classification loss: 0.07811 | Regression loss: 0.23583 | Running loss: 0.51045\n",
      "Epoch: 7 | Iteration: 755 | Classification loss: 0.12093 | Regression loss: 0.29558 | Running loss: 0.50869\n",
      "Epoch: 7 | Iteration: 756 | Classification loss: 0.17336 | Regression loss: 0.45088 | Running loss: 0.50903\n",
      "Epoch: 7 | Iteration: 757 | Classification loss: 0.55746 | Regression loss: 0.38756 | Running loss: 0.50990\n",
      "Epoch: 7 | Iteration: 758 | Classification loss: 0.15376 | Regression loss: 0.35433 | Running loss: 0.51022\n",
      "Epoch: 7 | Iteration: 759 | Classification loss: 0.17119 | Regression loss: 0.44259 | Running loss: 0.51085\n",
      "Epoch: 7 | Iteration: 760 | Classification loss: 0.05567 | Regression loss: 0.12195 | Running loss: 0.51000\n",
      "Epoch: 7 | Iteration: 761 | Classification loss: 0.21970 | Regression loss: 0.25518 | Running loss: 0.50936\n",
      "Epoch: 7 | Iteration: 762 | Classification loss: 0.23768 | Regression loss: 0.29119 | Running loss: 0.50935\n",
      "Epoch: 7 | Iteration: 763 | Classification loss: 0.07624 | Regression loss: 0.22532 | Running loss: 0.50895\n",
      "Epoch: 7 | Iteration: 764 | Classification loss: 0.10944 | Regression loss: 0.19542 | Running loss: 0.50857\n",
      "Epoch: 7 | Iteration: 765 | Classification loss: 0.03349 | Regression loss: 0.14923 | Running loss: 0.50771\n",
      "Epoch: 7 | Iteration: 766 | Classification loss: 0.10194 | Regression loss: 0.25905 | Running loss: 0.50766\n",
      "Epoch: 7 | Iteration: 767 | Classification loss: 0.19239 | Regression loss: 0.10469 | Running loss: 0.50759\n",
      "Epoch: 7 | Iteration: 768 | Classification loss: 0.11458 | Regression loss: 0.19055 | Running loss: 0.50677\n",
      "Epoch: 7 | Iteration: 769 | Classification loss: 0.20946 | Regression loss: 0.32861 | Running loss: 0.50696\n",
      "Epoch: 7 | Iteration: 770 | Classification loss: 0.13164 | Regression loss: 0.03841 | Running loss: 0.50669\n",
      "Epoch: 7 | Iteration: 771 | Classification loss: 0.43638 | Regression loss: 0.22842 | Running loss: 0.50691\n",
      "Epoch: 7 | Iteration: 772 | Classification loss: 0.18259 | Regression loss: 0.21257 | Running loss: 0.50630\n",
      "Epoch: 7 | Iteration: 773 | Classification loss: 0.09496 | Regression loss: 0.20416 | Running loss: 0.50499\n",
      "Epoch: 7 | Iteration: 774 | Classification loss: 0.30139 | Regression loss: 0.14400 | Running loss: 0.50452\n",
      "Epoch: 7 | Iteration: 775 | Classification loss: 0.07735 | Regression loss: 0.25881 | Running loss: 0.50436\n",
      "Epoch: 7 | Iteration: 776 | Classification loss: 0.18510 | Regression loss: 0.32654 | Running loss: 0.50456\n",
      "Epoch: 7 | Iteration: 777 | Classification loss: 0.17786 | Regression loss: 0.31641 | Running loss: 0.50521\n",
      "Epoch: 7 | Iteration: 778 | Classification loss: 0.09495 | Regression loss: 0.21661 | Running loss: 0.50471\n",
      "Epoch: 7 | Iteration: 779 | Classification loss: 0.15636 | Regression loss: 0.41443 | Running loss: 0.50379\n",
      "Epoch: 7 | Iteration: 780 | Classification loss: 0.08945 | Regression loss: 0.39124 | Running loss: 0.50410\n",
      "Epoch: 7 | Iteration: 781 | Classification loss: 0.17856 | Regression loss: 0.23733 | Running loss: 0.50382\n",
      "Epoch: 7 | Iteration: 782 | Classification loss: 0.25632 | Regression loss: 0.25903 | Running loss: 0.50412\n",
      "Epoch: 7 | Iteration: 783 | Classification loss: 0.06849 | Regression loss: 0.25783 | Running loss: 0.50354\n",
      "Epoch: 7 | Iteration: 784 | Classification loss: 0.38441 | Regression loss: 0.71435 | Running loss: 0.50465\n",
      "Epoch: 7 | Iteration: 785 | Classification loss: 0.08937 | Regression loss: 0.30086 | Running loss: 0.50497\n",
      "Epoch: 7 | Iteration: 786 | Classification loss: 0.04778 | Regression loss: 0.15308 | Running loss: 0.50410\n",
      "Epoch: 7 | Iteration: 787 | Classification loss: 0.17357 | Regression loss: 0.43649 | Running loss: 0.50476\n",
      "Epoch: 7 | Iteration: 788 | Classification loss: 0.13331 | Regression loss: 0.26246 | Running loss: 0.50461\n",
      "Epoch: 7 | Iteration: 789 | Classification loss: 0.22871 | Regression loss: 0.26885 | Running loss: 0.50498\n",
      "Epoch: 7 | Iteration: 790 | Classification loss: 0.27135 | Regression loss: 0.21797 | Running loss: 0.50485\n",
      "Epoch: 7 | Iteration: 791 | Classification loss: 0.11895 | Regression loss: 0.19758 | Running loss: 0.50450\n",
      "Epoch: 7 | Iteration: 792 | Classification loss: 0.04097 | Regression loss: 0.19945 | Running loss: 0.50441\n",
      "Epoch: 7 | Iteration: 793 | Classification loss: 0.14795 | Regression loss: 0.44334 | Running loss: 0.50329\n",
      "Epoch: 7 | Iteration: 794 | Classification loss: 0.31690 | Regression loss: 0.23694 | Running loss: 0.50263\n",
      "Epoch: 7 | Iteration: 795 | Classification loss: 0.06341 | Regression loss: 0.15710 | Running loss: 0.50187\n",
      "Epoch: 7 | Iteration: 796 | Classification loss: 0.06675 | Regression loss: 0.21645 | Running loss: 0.50181\n",
      "Epoch: 7 | Iteration: 797 | Classification loss: 0.19087 | Regression loss: 0.32591 | Running loss: 0.50177\n",
      "Epoch: 7 | Iteration: 798 | Classification loss: 0.28958 | Regression loss: 0.39741 | Running loss: 0.50234\n",
      "Epoch: 7 | Iteration: 799 | Classification loss: 0.08514 | Regression loss: 0.33317 | Running loss: 0.50143\n",
      "Epoch: 7 | Iteration: 800 | Classification loss: 0.24059 | Regression loss: 0.46047 | Running loss: 0.50251\n",
      "Epoch: 7 | Iteration: 801 | Classification loss: 0.04579 | Regression loss: 0.12323 | Running loss: 0.50222\n",
      "Epoch: 7 | Iteration: 802 | Classification loss: 0.18009 | Regression loss: 0.37242 | Running loss: 0.50263\n",
      "Epoch: 7 | Iteration: 803 | Classification loss: 0.20785 | Regression loss: 0.42251 | Running loss: 0.50280\n",
      "Epoch: 7 | Iteration: 804 | Classification loss: 0.07435 | Regression loss: 0.10913 | Running loss: 0.50229\n",
      "Epoch: 7 | Iteration: 805 | Classification loss: 0.03828 | Regression loss: 0.20350 | Running loss: 0.50196\n",
      "Epoch: 7 | Iteration: 806 | Classification loss: 0.16856 | Regression loss: 0.28606 | Running loss: 0.50221\n",
      "Epoch: 7 | Iteration: 807 | Classification loss: 0.06621 | Regression loss: 0.29755 | Running loss: 0.50219\n",
      "Epoch: 7 | Iteration: 808 | Classification loss: 0.72641 | Regression loss: 0.20649 | Running loss: 0.50311\n",
      "Epoch: 7 | Iteration: 809 | Classification loss: 0.11429 | Regression loss: 0.16314 | Running loss: 0.50272\n",
      "Epoch: 7 | Iteration: 810 | Classification loss: 0.13678 | Regression loss: 0.27631 | Running loss: 0.50273\n",
      "Epoch: 7 | Iteration: 811 | Classification loss: 0.09701 | Regression loss: 0.14422 | Running loss: 0.50264\n",
      "Epoch: 7 | Iteration: 812 | Classification loss: 0.38191 | Regression loss: 0.42780 | Running loss: 0.50360\n",
      "Epoch: 7 | Iteration: 813 | Classification loss: 0.08834 | Regression loss: 0.20237 | Running loss: 0.50283\n",
      "Epoch: 7 | Iteration: 814 | Classification loss: 0.14030 | Regression loss: 0.31589 | Running loss: 0.50295\n",
      "Epoch: 7 | Iteration: 815 | Classification loss: 0.30934 | Regression loss: 0.61583 | Running loss: 0.50404\n",
      "Epoch: 7 | Iteration: 816 | Classification loss: 0.04956 | Regression loss: 0.14793 | Running loss: 0.50399\n",
      "Epoch: 7 | Iteration: 817 | Classification loss: 0.20568 | Regression loss: 0.41039 | Running loss: 0.50437\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.504\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 8 | Iteration: 0 | Classification loss: 0.17987 | Regression loss: 0.37939 | Running loss: 0.50383\n",
      "Epoch: 8 | Iteration: 1 | Classification loss: 0.22630 | Regression loss: 0.16528 | Running loss: 0.50387\n",
      "Epoch: 8 | Iteration: 2 | Classification loss: 0.15078 | Regression loss: 0.28714 | Running loss: 0.50425\n",
      "Epoch: 8 | Iteration: 3 | Classification loss: 0.58718 | Regression loss: 0.62556 | Running loss: 0.50517\n",
      "Epoch: 8 | Iteration: 4 | Classification loss: 0.23505 | Regression loss: 0.38984 | Running loss: 0.50509\n",
      "Epoch: 8 | Iteration: 5 | Classification loss: 0.08340 | Regression loss: 0.20073 | Running loss: 0.50490\n",
      "Epoch: 8 | Iteration: 6 | Classification loss: 0.07589 | Regression loss: 0.29795 | Running loss: 0.50512\n",
      "Epoch: 8 | Iteration: 7 | Classification loss: 0.08793 | Regression loss: 0.27110 | Running loss: 0.50447\n",
      "Epoch: 8 | Iteration: 8 | Classification loss: 0.05372 | Regression loss: 0.18414 | Running loss: 0.50422\n",
      "Epoch: 8 | Iteration: 9 | Classification loss: 0.09605 | Regression loss: 0.17575 | Running loss: 0.50385\n",
      "Epoch: 8 | Iteration: 10 | Classification loss: 0.46230 | Regression loss: 0.43938 | Running loss: 0.50442\n",
      "Epoch: 8 | Iteration: 11 | Classification loss: 0.08965 | Regression loss: 0.31893 | Running loss: 0.50385\n",
      "Epoch: 8 | Iteration: 12 | Classification loss: 0.16675 | Regression loss: 0.16659 | Running loss: 0.50337\n",
      "Epoch: 8 | Iteration: 13 | Classification loss: 0.04788 | Regression loss: 0.09145 | Running loss: 0.50248\n",
      "Epoch: 8 | Iteration: 14 | Classification loss: 0.10168 | Regression loss: 0.29399 | Running loss: 0.50197\n",
      "Epoch: 8 | Iteration: 15 | Classification loss: 0.03558 | Regression loss: 0.24160 | Running loss: 0.50142\n",
      "Epoch: 8 | Iteration: 16 | Classification loss: 0.21829 | Regression loss: 0.16746 | Running loss: 0.50159\n",
      "Epoch: 8 | Iteration: 17 | Classification loss: 0.19675 | Regression loss: 0.30018 | Running loss: 0.50140\n",
      "Epoch: 8 | Iteration: 18 | Classification loss: 0.09682 | Regression loss: 0.26863 | Running loss: 0.50123\n",
      "Epoch: 8 | Iteration: 19 | Classification loss: 0.08262 | Regression loss: 0.15575 | Running loss: 0.50079\n",
      "Epoch: 8 | Iteration: 20 | Classification loss: 0.57332 | Regression loss: 0.26176 | Running loss: 0.50153\n",
      "Epoch: 8 | Iteration: 21 | Classification loss: 0.12508 | Regression loss: 0.45065 | Running loss: 0.50198\n",
      "Epoch: 8 | Iteration: 22 | Classification loss: 0.18962 | Regression loss: 0.34708 | Running loss: 0.50258\n",
      "Epoch: 8 | Iteration: 23 | Classification loss: 0.08503 | Regression loss: 0.24853 | Running loss: 0.50261\n",
      "Epoch: 8 | Iteration: 24 | Classification loss: 0.17737 | Regression loss: 0.30149 | Running loss: 0.50258\n",
      "Epoch: 8 | Iteration: 25 | Classification loss: 0.06296 | Regression loss: 0.18753 | Running loss: 0.50219\n",
      "Epoch: 8 | Iteration: 26 | Classification loss: 0.41795 | Regression loss: 0.34574 | Running loss: 0.50288\n",
      "Epoch: 8 | Iteration: 27 | Classification loss: 0.05106 | Regression loss: 0.27924 | Running loss: 0.50305\n",
      "Epoch: 8 | Iteration: 28 | Classification loss: 0.06472 | Regression loss: 0.26269 | Running loss: 0.50259\n",
      "Epoch: 8 | Iteration: 29 | Classification loss: 0.16562 | Regression loss: 0.18420 | Running loss: 0.50238\n",
      "Epoch: 8 | Iteration: 30 | Classification loss: 0.22618 | Regression loss: 0.31780 | Running loss: 0.50281\n",
      "Epoch: 8 | Iteration: 31 | Classification loss: 0.62030 | Regression loss: 0.19624 | Running loss: 0.50291\n",
      "Epoch: 8 | Iteration: 32 | Classification loss: 0.37349 | Regression loss: 0.18454 | Running loss: 0.50316\n",
      "Epoch: 8 | Iteration: 33 | Classification loss: 0.16225 | Regression loss: 0.30941 | Running loss: 0.50306\n",
      "Epoch: 8 | Iteration: 34 | Classification loss: 0.08424 | Regression loss: 0.51131 | Running loss: 0.50325\n",
      "Epoch: 8 | Iteration: 35 | Classification loss: 0.08170 | Regression loss: 0.23248 | Running loss: 0.50207\n",
      "Epoch: 8 | Iteration: 36 | Classification loss: 0.12843 | Regression loss: 0.22907 | Running loss: 0.50181\n",
      "Epoch: 8 | Iteration: 37 | Classification loss: 0.06111 | Regression loss: 0.16815 | Running loss: 0.50075\n",
      "Epoch: 8 | Iteration: 38 | Classification loss: 0.25114 | Regression loss: 0.19988 | Running loss: 0.50020\n",
      "Epoch: 8 | Iteration: 39 | Classification loss: 0.61121 | Regression loss: 0.16036 | Running loss: 0.50007\n",
      "Epoch: 8 | Iteration: 40 | Classification loss: 0.04600 | Regression loss: 0.18862 | Running loss: 0.49945\n",
      "Epoch: 8 | Iteration: 41 | Classification loss: 0.06528 | Regression loss: 0.19381 | Running loss: 0.49918\n",
      "Epoch: 8 | Iteration: 42 | Classification loss: 0.19217 | Regression loss: 0.28509 | Running loss: 0.49933\n",
      "Epoch: 8 | Iteration: 43 | Classification loss: 0.25326 | Regression loss: 0.34628 | Running loss: 0.49955\n",
      "Epoch: 8 | Iteration: 44 | Classification loss: 0.05092 | Regression loss: 0.14351 | Running loss: 0.49994\n",
      "Epoch: 8 | Iteration: 45 | Classification loss: 0.22777 | Regression loss: 0.31851 | Running loss: 0.49971\n",
      "Epoch: 8 | Iteration: 46 | Classification loss: 0.18612 | Regression loss: 0.30889 | Running loss: 0.49948\n",
      "Epoch: 8 | Iteration: 47 | Classification loss: 0.26711 | Regression loss: 0.15925 | Running loss: 0.49913\n",
      "Epoch: 8 | Iteration: 48 | Classification loss: 0.14189 | Regression loss: 0.30464 | Running loss: 0.49914\n",
      "Epoch: 8 | Iteration: 49 | Classification loss: 0.09764 | Regression loss: 0.15381 | Running loss: 0.49878\n",
      "Epoch: 8 | Iteration: 50 | Classification loss: 0.23578 | Regression loss: 0.50358 | Running loss: 0.49959\n",
      "Epoch: 8 | Iteration: 51 | Classification loss: 0.21647 | Regression loss: 0.48313 | Running loss: 0.49964\n",
      "Epoch: 8 | Iteration: 52 | Classification loss: 0.15836 | Regression loss: 0.28684 | Running loss: 0.50001\n",
      "Epoch: 8 | Iteration: 53 | Classification loss: 0.12429 | Regression loss: 0.37229 | Running loss: 0.49919\n",
      "Epoch: 8 | Iteration: 54 | Classification loss: 0.07994 | Regression loss: 0.19924 | Running loss: 0.49855\n",
      "Epoch: 8 | Iteration: 55 | Classification loss: 0.13048 | Regression loss: 0.46679 | Running loss: 0.49819\n",
      "Epoch: 8 | Iteration: 56 | Classification loss: 0.15031 | Regression loss: 0.20852 | Running loss: 0.49785\n",
      "Epoch: 8 | Iteration: 57 | Classification loss: 0.13442 | Regression loss: 0.49765 | Running loss: 0.49824\n",
      "Epoch: 8 | Iteration: 58 | Classification loss: 0.14940 | Regression loss: 0.26338 | Running loss: 0.49828\n",
      "Epoch: 8 | Iteration: 59 | Classification loss: 0.22619 | Regression loss: 0.12422 | Running loss: 0.49851\n",
      "Epoch: 8 | Iteration: 60 | Classification loss: 0.17565 | Regression loss: 0.27606 | Running loss: 0.49815\n",
      "Epoch: 8 | Iteration: 61 | Classification loss: 0.10240 | Regression loss: 0.28702 | Running loss: 0.49833\n",
      "Epoch: 8 | Iteration: 62 | Classification loss: 0.11579 | Regression loss: 0.34194 | Running loss: 0.49855\n",
      "Epoch: 8 | Iteration: 63 | Classification loss: 0.10184 | Regression loss: 0.24705 | Running loss: 0.49766\n",
      "Epoch: 8 | Iteration: 64 | Classification loss: 0.16205 | Regression loss: 0.26179 | Running loss: 0.49709\n",
      "Epoch: 8 | Iteration: 65 | Classification loss: 0.15889 | Regression loss: 0.53837 | Running loss: 0.49769\n",
      "Epoch: 8 | Iteration: 66 | Classification loss: 0.19352 | Regression loss: 0.40859 | Running loss: 0.49772\n",
      "Epoch: 8 | Iteration: 67 | Classification loss: 0.21741 | Regression loss: 0.25277 | Running loss: 0.49745\n",
      "Epoch: 8 | Iteration: 68 | Classification loss: 0.20244 | Regression loss: 0.25637 | Running loss: 0.49750\n",
      "Epoch: 8 | Iteration: 69 | Classification loss: 0.12568 | Regression loss: 0.35337 | Running loss: 0.49762\n",
      "Epoch: 8 | Iteration: 70 | Classification loss: 0.08292 | Regression loss: 0.19634 | Running loss: 0.49732\n",
      "Epoch: 8 | Iteration: 71 | Classification loss: 0.07802 | Regression loss: 0.27609 | Running loss: 0.49708\n",
      "Epoch: 8 | Iteration: 72 | Classification loss: 0.26903 | Regression loss: 0.21305 | Running loss: 0.49694\n",
      "Epoch: 8 | Iteration: 73 | Classification loss: 0.08585 | Regression loss: 0.39382 | Running loss: 0.49661\n",
      "Epoch: 8 | Iteration: 74 | Classification loss: 0.22929 | Regression loss: 0.44009 | Running loss: 0.49741\n",
      "Epoch: 8 | Iteration: 75 | Classification loss: 0.09051 | Regression loss: 0.15410 | Running loss: 0.49642\n",
      "Epoch: 8 | Iteration: 76 | Classification loss: 0.12277 | Regression loss: 0.42702 | Running loss: 0.49681\n",
      "Epoch: 8 | Iteration: 77 | Classification loss: 0.16891 | Regression loss: 0.38727 | Running loss: 0.49614\n",
      "Epoch: 8 | Iteration: 78 | Classification loss: 0.14954 | Regression loss: 0.18146 | Running loss: 0.49545\n",
      "Epoch: 8 | Iteration: 79 | Classification loss: 0.09103 | Regression loss: 0.30758 | Running loss: 0.49496\n",
      "Epoch: 8 | Iteration: 80 | Classification loss: 0.36132 | Regression loss: 1.02714 | Running loss: 0.49663\n",
      "Epoch: 8 | Iteration: 81 | Classification loss: 0.11820 | Regression loss: 0.32054 | Running loss: 0.49669\n",
      "Epoch: 8 | Iteration: 82 | Classification loss: 0.06109 | Regression loss: 0.13502 | Running loss: 0.49641\n",
      "Epoch: 8 | Iteration: 83 | Classification loss: 0.18316 | Regression loss: 0.13906 | Running loss: 0.49556\n",
      "Epoch: 8 | Iteration: 84 | Classification loss: 0.28329 | Regression loss: 0.57217 | Running loss: 0.49652\n",
      "Epoch: 8 | Iteration: 85 | Classification loss: 0.13071 | Regression loss: 0.61206 | Running loss: 0.49738\n",
      "Epoch: 8 | Iteration: 86 | Classification loss: 0.19860 | Regression loss: 0.17607 | Running loss: 0.49732\n",
      "Epoch: 8 | Iteration: 87 | Classification loss: 0.09772 | Regression loss: 0.27653 | Running loss: 0.49702\n",
      "Epoch: 8 | Iteration: 88 | Classification loss: 0.18438 | Regression loss: 0.24884 | Running loss: 0.49702\n",
      "Epoch: 8 | Iteration: 89 | Classification loss: 0.05233 | Regression loss: 0.14724 | Running loss: 0.49699\n",
      "Epoch: 8 | Iteration: 90 | Classification loss: 0.16566 | Regression loss: 0.40771 | Running loss: 0.49639\n",
      "Epoch: 8 | Iteration: 91 | Classification loss: 0.17797 | Regression loss: 0.21921 | Running loss: 0.49686\n",
      "Epoch: 8 | Iteration: 92 | Classification loss: 0.07480 | Regression loss: 0.27331 | Running loss: 0.49572\n",
      "Epoch: 8 | Iteration: 93 | Classification loss: 0.41216 | Regression loss: 0.32043 | Running loss: 0.49618\n",
      "Epoch: 8 | Iteration: 94 | Classification loss: 0.10854 | Regression loss: 0.30730 | Running loss: 0.49641\n",
      "Epoch: 8 | Iteration: 95 | Classification loss: 0.11583 | Regression loss: 0.25495 | Running loss: 0.49602\n",
      "Epoch: 8 | Iteration: 96 | Classification loss: 0.04881 | Regression loss: 0.28316 | Running loss: 0.49591\n",
      "Epoch: 8 | Iteration: 97 | Classification loss: 0.12279 | Regression loss: 0.34688 | Running loss: 0.49588\n",
      "Epoch: 8 | Iteration: 98 | Classification loss: 0.06694 | Regression loss: 0.26240 | Running loss: 0.49597\n",
      "Epoch: 8 | Iteration: 99 | Classification loss: 0.23847 | Regression loss: 0.16376 | Running loss: 0.49476\n",
      "Epoch: 8 | Iteration: 100 | Classification loss: 0.13917 | Regression loss: 0.21557 | Running loss: 0.49469\n",
      "Epoch: 8 | Iteration: 101 | Classification loss: 0.05709 | Regression loss: 0.20786 | Running loss: 0.49371\n",
      "Epoch: 8 | Iteration: 102 | Classification loss: 0.12867 | Regression loss: 0.37993 | Running loss: 0.49367\n",
      "Epoch: 8 | Iteration: 103 | Classification loss: 0.10828 | Regression loss: 0.38343 | Running loss: 0.49367\n",
      "Epoch: 8 | Iteration: 104 | Classification loss: 0.14714 | Regression loss: 0.16292 | Running loss: 0.49340\n",
      "Epoch: 8 | Iteration: 105 | Classification loss: 0.24793 | Regression loss: 0.43254 | Running loss: 0.49392\n",
      "Epoch: 8 | Iteration: 106 | Classification loss: 0.05563 | Regression loss: 0.14830 | Running loss: 0.49248\n",
      "Epoch: 8 | Iteration: 107 | Classification loss: 0.19457 | Regression loss: 0.25621 | Running loss: 0.49247\n",
      "Epoch: 8 | Iteration: 108 | Classification loss: 0.13284 | Regression loss: 0.36526 | Running loss: 0.49259\n",
      "Epoch: 8 | Iteration: 109 | Classification loss: 0.16552 | Regression loss: 0.16870 | Running loss: 0.49264\n",
      "Epoch: 8 | Iteration: 110 | Classification loss: 0.13549 | Regression loss: 0.19087 | Running loss: 0.49196\n",
      "Epoch: 8 | Iteration: 111 | Classification loss: 0.04147 | Regression loss: 0.12958 | Running loss: 0.49089\n",
      "Epoch: 8 | Iteration: 112 | Classification loss: 0.11595 | Regression loss: 0.28233 | Running loss: 0.49060\n",
      "Epoch: 8 | Iteration: 113 | Classification loss: 0.11360 | Regression loss: 0.23730 | Running loss: 0.48988\n",
      "Epoch: 8 | Iteration: 114 | Classification loss: 0.60344 | Regression loss: 0.23569 | Running loss: 0.49082\n",
      "Epoch: 8 | Iteration: 115 | Classification loss: 0.15106 | Regression loss: 0.32700 | Running loss: 0.49088\n",
      "Epoch: 8 | Iteration: 116 | Classification loss: 0.11029 | Regression loss: 0.30236 | Running loss: 0.49107\n",
      "Epoch: 8 | Iteration: 117 | Classification loss: 0.22349 | Regression loss: 0.44423 | Running loss: 0.49120\n",
      "Epoch: 8 | Iteration: 118 | Classification loss: 0.21535 | Regression loss: 0.18733 | Running loss: 0.49136\n",
      "Epoch: 8 | Iteration: 119 | Classification loss: 0.15559 | Regression loss: 0.25444 | Running loss: 0.49103\n",
      "Epoch: 8 | Iteration: 120 | Classification loss: 0.18218 | Regression loss: 0.40226 | Running loss: 0.49071\n",
      "Epoch: 8 | Iteration: 121 | Classification loss: 0.20804 | Regression loss: 0.40530 | Running loss: 0.49116\n",
      "Epoch: 8 | Iteration: 122 | Classification loss: 0.17597 | Regression loss: 0.27981 | Running loss: 0.49117\n",
      "Epoch: 8 | Iteration: 123 | Classification loss: 0.12237 | Regression loss: 0.20482 | Running loss: 0.49084\n",
      "Epoch: 8 | Iteration: 124 | Classification loss: 0.32740 | Regression loss: 0.26551 | Running loss: 0.49135\n",
      "Epoch: 8 | Iteration: 125 | Classification loss: 0.21045 | Regression loss: 0.20435 | Running loss: 0.49173\n",
      "Epoch: 8 | Iteration: 126 | Classification loss: 0.12017 | Regression loss: 0.31593 | Running loss: 0.49057\n",
      "Epoch: 8 | Iteration: 127 | Classification loss: 0.07925 | Regression loss: 0.22535 | Running loss: 0.49006\n",
      "Epoch: 8 | Iteration: 128 | Classification loss: 0.05607 | Regression loss: 0.27715 | Running loss: 0.48964\n",
      "Epoch: 8 | Iteration: 129 | Classification loss: 0.24645 | Regression loss: 0.19541 | Running loss: 0.48924\n",
      "Epoch: 8 | Iteration: 130 | Classification loss: 0.26247 | Regression loss: 0.45952 | Running loss: 0.48988\n",
      "Epoch: 8 | Iteration: 131 | Classification loss: 0.09024 | Regression loss: 0.41947 | Running loss: 0.49035\n",
      "Epoch: 8 | Iteration: 132 | Classification loss: 0.22251 | Regression loss: 0.60584 | Running loss: 0.49076\n",
      "Epoch: 8 | Iteration: 133 | Classification loss: 0.05360 | Regression loss: 0.19012 | Running loss: 0.49042\n",
      "Epoch: 8 | Iteration: 134 | Classification loss: 0.25259 | Regression loss: 0.49674 | Running loss: 0.49009\n",
      "Epoch: 8 | Iteration: 135 | Classification loss: 0.19350 | Regression loss: 0.20703 | Running loss: 0.49015\n",
      "Epoch: 8 | Iteration: 136 | Classification loss: 0.06733 | Regression loss: 0.23039 | Running loss: 0.48960\n",
      "Epoch: 8 | Iteration: 137 | Classification loss: 0.10145 | Regression loss: 0.19991 | Running loss: 0.48824\n",
      "Epoch: 8 | Iteration: 138 | Classification loss: 0.04616 | Regression loss: 0.16351 | Running loss: 0.48770\n",
      "Epoch: 8 | Iteration: 139 | Classification loss: 0.25950 | Regression loss: 0.57461 | Running loss: 0.48814\n",
      "Epoch: 8 | Iteration: 140 | Classification loss: 0.24059 | Regression loss: 0.54617 | Running loss: 0.48853\n",
      "Epoch: 8 | Iteration: 141 | Classification loss: 0.33361 | Regression loss: 0.38132 | Running loss: 0.48960\n",
      "Epoch: 8 | Iteration: 142 | Classification loss: 0.20066 | Regression loss: 0.34368 | Running loss: 0.48912\n",
      "Epoch: 8 | Iteration: 143 | Classification loss: 0.17470 | Regression loss: 0.26205 | Running loss: 0.48922\n",
      "Epoch: 8 | Iteration: 144 | Classification loss: 0.07901 | Regression loss: 0.31246 | Running loss: 0.48928\n",
      "Epoch: 8 | Iteration: 145 | Classification loss: 0.07913 | Regression loss: 0.25581 | Running loss: 0.48919\n",
      "Epoch: 8 | Iteration: 146 | Classification loss: 0.27550 | Regression loss: 0.45754 | Running loss: 0.48984\n",
      "Epoch: 8 | Iteration: 147 | Classification loss: 0.21035 | Regression loss: 0.42083 | Running loss: 0.48874\n",
      "Epoch: 8 | Iteration: 148 | Classification loss: 0.11408 | Regression loss: 0.13967 | Running loss: 0.48876\n",
      "Epoch: 8 | Iteration: 149 | Classification loss: 0.11222 | Regression loss: 0.34929 | Running loss: 0.48897\n",
      "Epoch: 8 | Iteration: 150 | Classification loss: 0.17201 | Regression loss: 0.39798 | Running loss: 0.48886\n",
      "Epoch: 8 | Iteration: 151 | Classification loss: 0.08086 | Regression loss: 0.35358 | Running loss: 0.48892\n",
      "Epoch: 8 | Iteration: 152 | Classification loss: 0.32471 | Regression loss: 0.59000 | Running loss: 0.48977\n",
      "Epoch: 8 | Iteration: 153 | Classification loss: 0.24169 | Regression loss: 0.68558 | Running loss: 0.49097\n",
      "Epoch: 8 | Iteration: 154 | Classification loss: 0.20645 | Regression loss: 0.26150 | Running loss: 0.49037\n",
      "Epoch: 8 | Iteration: 155 | Classification loss: 0.26943 | Regression loss: 0.28934 | Running loss: 0.49066\n",
      "Epoch: 8 | Iteration: 156 | Classification loss: 0.28838 | Regression loss: 0.07424 | Running loss: 0.49093\n",
      "Epoch: 8 | Iteration: 157 | Classification loss: 0.19726 | Regression loss: 0.26021 | Running loss: 0.49133\n",
      "Epoch: 8 | Iteration: 158 | Classification loss: 0.18343 | Regression loss: 0.22726 | Running loss: 0.49042\n",
      "Epoch: 8 | Iteration: 159 | Classification loss: 0.11288 | Regression loss: 0.32612 | Running loss: 0.49029\n",
      "Epoch: 8 | Iteration: 160 | Classification loss: 0.22543 | Regression loss: 0.54666 | Running loss: 0.49108\n",
      "Epoch: 8 | Iteration: 161 | Classification loss: 0.13152 | Regression loss: 0.18737 | Running loss: 0.49088\n",
      "Epoch: 8 | Iteration: 162 | Classification loss: 0.25512 | Regression loss: 0.34644 | Running loss: 0.49108\n",
      "Epoch: 8 | Iteration: 163 | Classification loss: 0.12683 | Regression loss: 0.38418 | Running loss: 0.49022\n",
      "Epoch: 8 | Iteration: 164 | Classification loss: 0.08994 | Regression loss: 0.29230 | Running loss: 0.48941\n",
      "Epoch: 8 | Iteration: 165 | Classification loss: 0.07302 | Regression loss: 0.23855 | Running loss: 0.48952\n",
      "Epoch: 8 | Iteration: 166 | Classification loss: 0.16182 | Regression loss: 0.17848 | Running loss: 0.48951\n",
      "Epoch: 8 | Iteration: 167 | Classification loss: 0.07144 | Regression loss: 0.14216 | Running loss: 0.48896\n",
      "Epoch: 8 | Iteration: 168 | Classification loss: 0.08979 | Regression loss: 0.22070 | Running loss: 0.48817\n",
      "Epoch: 8 | Iteration: 169 | Classification loss: 0.14949 | Regression loss: 0.16471 | Running loss: 0.48773\n",
      "Epoch: 8 | Iteration: 170 | Classification loss: 0.14354 | Regression loss: 0.19951 | Running loss: 0.48619\n",
      "Epoch: 8 | Iteration: 171 | Classification loss: 0.06558 | Regression loss: 0.34551 | Running loss: 0.48582\n",
      "Epoch: 8 | Iteration: 172 | Classification loss: 0.15527 | Regression loss: 0.26744 | Running loss: 0.48555\n",
      "Epoch: 8 | Iteration: 173 | Classification loss: 0.09611 | Regression loss: 0.35112 | Running loss: 0.48507\n",
      "Epoch: 8 | Iteration: 174 | Classification loss: 0.66129 | Regression loss: 0.15858 | Running loss: 0.48587\n",
      "Epoch: 8 | Iteration: 175 | Classification loss: 0.03218 | Regression loss: 0.14825 | Running loss: 0.48572\n",
      "Epoch: 8 | Iteration: 176 | Classification loss: 0.09175 | Regression loss: 0.43230 | Running loss: 0.48602\n",
      "Epoch: 8 | Iteration: 177 | Classification loss: 0.25819 | Regression loss: 0.56663 | Running loss: 0.48699\n",
      "Epoch: 8 | Iteration: 178 | Classification loss: 0.29288 | Regression loss: 0.33765 | Running loss: 0.48674\n",
      "Epoch: 8 | Iteration: 179 | Classification loss: 0.15649 | Regression loss: 0.32168 | Running loss: 0.48567\n",
      "Epoch: 8 | Iteration: 180 | Classification loss: 0.04312 | Regression loss: 0.27202 | Running loss: 0.48495\n",
      "Epoch: 8 | Iteration: 181 | Classification loss: 0.16289 | Regression loss: 0.30095 | Running loss: 0.48450\n",
      "Epoch: 8 | Iteration: 182 | Classification loss: 0.18564 | Regression loss: 0.35802 | Running loss: 0.48491\n",
      "Epoch: 8 | Iteration: 183 | Classification loss: 0.08510 | Regression loss: 0.14241 | Running loss: 0.48427\n",
      "Epoch: 8 | Iteration: 184 | Classification loss: 0.07012 | Regression loss: 0.24567 | Running loss: 0.48357\n",
      "Epoch: 8 | Iteration: 185 | Classification loss: 0.09439 | Regression loss: 0.26019 | Running loss: 0.48364\n",
      "Epoch: 8 | Iteration: 186 | Classification loss: 0.50145 | Regression loss: 0.21540 | Running loss: 0.48427\n",
      "Epoch: 8 | Iteration: 187 | Classification loss: 0.19867 | Regression loss: 0.36326 | Running loss: 0.48408\n",
      "Epoch: 8 | Iteration: 188 | Classification loss: 0.45908 | Regression loss: 0.51887 | Running loss: 0.48525\n",
      "Epoch: 8 | Iteration: 189 | Classification loss: 0.61005 | Regression loss: 0.22715 | Running loss: 0.48549\n",
      "Epoch: 8 | Iteration: 190 | Classification loss: 0.09961 | Regression loss: 0.27947 | Running loss: 0.48553\n",
      "Epoch: 8 | Iteration: 191 | Classification loss: 0.17154 | Regression loss: 0.29523 | Running loss: 0.48556\n",
      "Epoch: 8 | Iteration: 192 | Classification loss: 0.23829 | Regression loss: 0.14570 | Running loss: 0.48578\n",
      "Epoch: 8 | Iteration: 193 | Classification loss: 0.05115 | Regression loss: 0.26572 | Running loss: 0.48491\n",
      "Epoch: 8 | Iteration: 194 | Classification loss: 0.21232 | Regression loss: 0.36638 | Running loss: 0.48478\n",
      "Epoch: 8 | Iteration: 195 | Classification loss: 0.10815 | Regression loss: 0.17566 | Running loss: 0.48452\n",
      "Epoch: 8 | Iteration: 196 | Classification loss: 0.30965 | Regression loss: 0.19253 | Running loss: 0.48481\n",
      "Epoch: 8 | Iteration: 197 | Classification loss: 0.16076 | Regression loss: 0.19247 | Running loss: 0.48317\n",
      "Epoch: 8 | Iteration: 198 | Classification loss: 0.02807 | Regression loss: 0.21914 | Running loss: 0.48298\n",
      "Epoch: 8 | Iteration: 199 | Classification loss: 0.24307 | Regression loss: 0.26497 | Running loss: 0.48215\n",
      "Epoch: 8 | Iteration: 200 | Classification loss: 0.11941 | Regression loss: 0.43583 | Running loss: 0.48215\n",
      "Epoch: 8 | Iteration: 201 | Classification loss: 0.22392 | Regression loss: 0.34028 | Running loss: 0.48260\n",
      "Epoch: 8 | Iteration: 202 | Classification loss: 0.09147 | Regression loss: 0.11893 | Running loss: 0.48257\n",
      "Epoch: 8 | Iteration: 203 | Classification loss: 0.12001 | Regression loss: 0.24286 | Running loss: 0.48272\n",
      "Epoch: 8 | Iteration: 204 | Classification loss: 0.09309 | Regression loss: 0.28294 | Running loss: 0.48249\n",
      "Epoch: 8 | Iteration: 205 | Classification loss: 0.22953 | Regression loss: 0.28902 | Running loss: 0.48272\n",
      "Epoch: 8 | Iteration: 206 | Classification loss: 0.19682 | Regression loss: 0.40538 | Running loss: 0.48347\n",
      "Epoch: 8 | Iteration: 207 | Classification loss: 0.02924 | Regression loss: 0.20254 | Running loss: 0.48299\n",
      "Epoch: 8 | Iteration: 208 | Classification loss: 0.11177 | Regression loss: 0.32810 | Running loss: 0.48298\n",
      "Epoch: 8 | Iteration: 209 | Classification loss: 0.09796 | Regression loss: 0.34368 | Running loss: 0.48318\n",
      "Epoch: 8 | Iteration: 210 | Classification loss: 0.07082 | Regression loss: 0.22763 | Running loss: 0.48291\n",
      "Epoch: 8 | Iteration: 211 | Classification loss: 0.15606 | Regression loss: 0.35902 | Running loss: 0.48347\n",
      "Epoch: 8 | Iteration: 212 | Classification loss: 0.10823 | Regression loss: 0.20591 | Running loss: 0.48238\n",
      "Epoch: 8 | Iteration: 213 | Classification loss: 0.13012 | Regression loss: 0.42723 | Running loss: 0.48238\n",
      "Epoch: 8 | Iteration: 214 | Classification loss: 0.16182 | Regression loss: 0.19854 | Running loss: 0.48134\n",
      "Epoch: 8 | Iteration: 215 | Classification loss: 0.19433 | Regression loss: 0.16556 | Running loss: 0.48129\n",
      "Epoch: 8 | Iteration: 216 | Classification loss: 0.07183 | Regression loss: 0.16745 | Running loss: 0.48032\n",
      "Epoch: 8 | Iteration: 217 | Classification loss: 0.10041 | Regression loss: 0.25431 | Running loss: 0.47987\n",
      "Epoch: 8 | Iteration: 218 | Classification loss: 0.07792 | Regression loss: 0.33899 | Running loss: 0.47946\n",
      "Epoch: 8 | Iteration: 219 | Classification loss: 0.35996 | Regression loss: 0.30389 | Running loss: 0.47996\n",
      "Epoch: 8 | Iteration: 220 | Classification loss: 0.07817 | Regression loss: 0.19254 | Running loss: 0.47977\n",
      "Epoch: 8 | Iteration: 221 | Classification loss: 0.12530 | Regression loss: 0.25094 | Running loss: 0.47991\n",
      "Epoch: 8 | Iteration: 222 | Classification loss: 0.13879 | Regression loss: 0.21176 | Running loss: 0.47981\n",
      "Epoch: 8 | Iteration: 223 | Classification loss: 0.26373 | Regression loss: 0.38175 | Running loss: 0.48019\n",
      "Epoch: 8 | Iteration: 224 | Classification loss: 0.11007 | Regression loss: 0.32381 | Running loss: 0.48045\n",
      "Epoch: 8 | Iteration: 225 | Classification loss: 0.24662 | Regression loss: 0.15926 | Running loss: 0.48059\n",
      "Epoch: 8 | Iteration: 226 | Classification loss: 0.14991 | Regression loss: 0.16852 | Running loss: 0.48016\n",
      "Epoch: 8 | Iteration: 227 | Classification loss: 0.09268 | Regression loss: 0.25524 | Running loss: 0.47989\n",
      "Epoch: 8 | Iteration: 228 | Classification loss: 0.09797 | Regression loss: 0.25803 | Running loss: 0.48014\n",
      "Epoch: 8 | Iteration: 229 | Classification loss: 0.04835 | Regression loss: 0.12096 | Running loss: 0.47933\n",
      "Epoch: 8 | Iteration: 230 | Classification loss: 0.22292 | Regression loss: 0.38204 | Running loss: 0.48053\n",
      "Epoch: 8 | Iteration: 231 | Classification loss: 0.31076 | Regression loss: 0.35530 | Running loss: 0.48098\n",
      "Epoch: 8 | Iteration: 232 | Classification loss: 0.19043 | Regression loss: 0.31605 | Running loss: 0.48152\n",
      "Epoch: 8 | Iteration: 233 | Classification loss: 0.14834 | Regression loss: 0.41167 | Running loss: 0.48148\n",
      "Epoch: 8 | Iteration: 234 | Classification loss: 0.47490 | Regression loss: 0.13221 | Running loss: 0.48164\n",
      "Epoch: 8 | Iteration: 235 | Classification loss: 0.17027 | Regression loss: 0.39315 | Running loss: 0.48121\n",
      "Epoch: 8 | Iteration: 236 | Classification loss: 0.32676 | Regression loss: 0.29091 | Running loss: 0.48086\n",
      "Epoch: 8 | Iteration: 237 | Classification loss: 0.26969 | Regression loss: 0.50321 | Running loss: 0.48122\n",
      "Epoch: 8 | Iteration: 238 | Classification loss: 0.18370 | Regression loss: 0.16676 | Running loss: 0.48055\n",
      "Epoch: 8 | Iteration: 239 | Classification loss: 0.09131 | Regression loss: 0.16455 | Running loss: 0.47997\n",
      "Epoch: 8 | Iteration: 240 | Classification loss: 0.21424 | Regression loss: 0.25637 | Running loss: 0.47961\n",
      "Epoch: 8 | Iteration: 241 | Classification loss: 0.24072 | Regression loss: 0.33111 | Running loss: 0.47972\n",
      "Epoch: 8 | Iteration: 242 | Classification loss: 0.15543 | Regression loss: 0.24657 | Running loss: 0.47981\n",
      "Epoch: 8 | Iteration: 243 | Classification loss: 0.26383 | Regression loss: 0.35088 | Running loss: 0.48058\n",
      "Epoch: 8 | Iteration: 244 | Classification loss: 0.33850 | Regression loss: 0.18867 | Running loss: 0.48126\n",
      "Epoch: 8 | Iteration: 245 | Classification loss: 0.27534 | Regression loss: 0.15813 | Running loss: 0.48102\n",
      "Epoch: 8 | Iteration: 246 | Classification loss: 0.06418 | Regression loss: 0.12073 | Running loss: 0.48004\n",
      "Epoch: 8 | Iteration: 247 | Classification loss: 0.26830 | Regression loss: 0.35422 | Running loss: 0.48035\n",
      "Epoch: 8 | Iteration: 248 | Classification loss: 0.16961 | Regression loss: 0.26035 | Running loss: 0.48085\n",
      "Epoch: 8 | Iteration: 249 | Classification loss: 0.32045 | Regression loss: 0.51886 | Running loss: 0.48145\n",
      "Epoch: 8 | Iteration: 250 | Classification loss: 0.05426 | Regression loss: 0.25949 | Running loss: 0.48107\n",
      "Epoch: 8 | Iteration: 251 | Classification loss: 0.07247 | Regression loss: 0.24113 | Running loss: 0.47965\n",
      "Epoch: 8 | Iteration: 252 | Classification loss: 0.04453 | Regression loss: 0.24049 | Running loss: 0.47770\n",
      "Epoch: 8 | Iteration: 253 | Classification loss: 0.08223 | Regression loss: 0.22234 | Running loss: 0.47764\n",
      "Epoch: 8 | Iteration: 254 | Classification loss: 0.14185 | Regression loss: 0.34379 | Running loss: 0.47810\n",
      "Epoch: 8 | Iteration: 255 | Classification loss: 0.06310 | Regression loss: 0.23850 | Running loss: 0.47775\n",
      "Epoch: 8 | Iteration: 256 | Classification loss: 0.19110 | Regression loss: 0.24866 | Running loss: 0.47778\n",
      "Epoch: 8 | Iteration: 257 | Classification loss: 0.05269 | Regression loss: 0.16043 | Running loss: 0.47678\n",
      "Epoch: 8 | Iteration: 258 | Classification loss: 0.25836 | Regression loss: 0.40478 | Running loss: 0.47759\n",
      "Epoch: 8 | Iteration: 259 | Classification loss: 0.08623 | Regression loss: 0.06196 | Running loss: 0.47675\n",
      "Epoch: 8 | Iteration: 260 | Classification loss: 0.09212 | Regression loss: 0.17173 | Running loss: 0.47682\n",
      "Epoch: 8 | Iteration: 261 | Classification loss: 0.06500 | Regression loss: 0.18639 | Running loss: 0.47628\n",
      "Epoch: 8 | Iteration: 262 | Classification loss: 0.19710 | Regression loss: 0.37050 | Running loss: 0.47593\n",
      "Epoch: 8 | Iteration: 263 | Classification loss: 0.27228 | Regression loss: 0.35014 | Running loss: 0.47662\n",
      "Epoch: 8 | Iteration: 264 | Classification loss: 0.23123 | Regression loss: 0.35648 | Running loss: 0.47700\n",
      "Epoch: 8 | Iteration: 265 | Classification loss: 0.16492 | Regression loss: 0.23790 | Running loss: 0.47745\n",
      "Epoch: 8 | Iteration: 266 | Classification loss: 0.25375 | Regression loss: 0.28238 | Running loss: 0.47713\n",
      "Epoch: 8 | Iteration: 267 | Classification loss: 0.13151 | Regression loss: 0.33099 | Running loss: 0.47770\n",
      "Epoch: 8 | Iteration: 268 | Classification loss: 0.12040 | Regression loss: 0.37184 | Running loss: 0.47796\n",
      "Epoch: 8 | Iteration: 269 | Classification loss: 0.11492 | Regression loss: 0.20296 | Running loss: 0.47811\n",
      "Epoch: 8 | Iteration: 270 | Classification loss: 0.15362 | Regression loss: 0.40540 | Running loss: 0.47746\n",
      "Epoch: 8 | Iteration: 271 | Classification loss: 0.12862 | Regression loss: 0.49923 | Running loss: 0.47791\n",
      "Epoch: 8 | Iteration: 272 | Classification loss: 0.05853 | Regression loss: 0.17496 | Running loss: 0.47726\n",
      "Epoch: 8 | Iteration: 273 | Classification loss: 0.22313 | Regression loss: 0.44740 | Running loss: 0.47751\n",
      "Epoch: 8 | Iteration: 274 | Classification loss: 0.29517 | Regression loss: 0.19125 | Running loss: 0.47751\n",
      "Epoch: 8 | Iteration: 275 | Classification loss: 0.22918 | Regression loss: 0.39640 | Running loss: 0.47793\n",
      "Epoch: 8 | Iteration: 276 | Classification loss: 0.25019 | Regression loss: 0.33610 | Running loss: 0.47807\n",
      "Epoch: 8 | Iteration: 277 | Classification loss: 0.13937 | Regression loss: 0.22784 | Running loss: 0.47747\n",
      "Epoch: 8 | Iteration: 278 | Classification loss: 0.29285 | Regression loss: 0.45296 | Running loss: 0.47778\n",
      "Epoch: 8 | Iteration: 279 | Classification loss: 0.27899 | Regression loss: 0.37371 | Running loss: 0.47755\n",
      "Epoch: 8 | Iteration: 280 | Classification loss: 0.06179 | Regression loss: 0.08111 | Running loss: 0.47702\n",
      "Epoch: 8 | Iteration: 281 | Classification loss: 0.06928 | Regression loss: 0.23155 | Running loss: 0.47702\n",
      "Epoch: 8 | Iteration: 282 | Classification loss: 0.14351 | Regression loss: 0.34220 | Running loss: 0.47712\n",
      "Epoch: 8 | Iteration: 283 | Classification loss: 0.12085 | Regression loss: 0.24305 | Running loss: 0.47704\n",
      "Epoch: 8 | Iteration: 284 | Classification loss: 0.07590 | Regression loss: 0.14739 | Running loss: 0.47677\n",
      "Epoch: 8 | Iteration: 285 | Classification loss: 0.26248 | Regression loss: 0.26815 | Running loss: 0.47737\n",
      "Epoch: 8 | Iteration: 286 | Classification loss: 0.25572 | Regression loss: 0.54730 | Running loss: 0.47834\n",
      "Epoch: 8 | Iteration: 287 | Classification loss: 0.04355 | Regression loss: 0.29608 | Running loss: 0.47866\n",
      "Epoch: 8 | Iteration: 288 | Classification loss: 0.11099 | Regression loss: 0.46530 | Running loss: 0.47936\n",
      "Epoch: 8 | Iteration: 289 | Classification loss: 0.05699 | Regression loss: 0.21897 | Running loss: 0.47973\n",
      "Epoch: 8 | Iteration: 290 | Classification loss: 0.14279 | Regression loss: 0.22559 | Running loss: 0.47930\n",
      "Epoch: 8 | Iteration: 291 | Classification loss: 0.06166 | Regression loss: 0.25791 | Running loss: 0.47923\n",
      "Epoch: 8 | Iteration: 292 | Classification loss: 0.11561 | Regression loss: 0.36724 | Running loss: 0.47875\n",
      "Epoch: 8 | Iteration: 293 | Classification loss: 0.13288 | Regression loss: 0.35236 | Running loss: 0.47826\n",
      "Epoch: 8 | Iteration: 294 | Classification loss: 0.12864 | Regression loss: 0.34253 | Running loss: 0.47812\n",
      "Epoch: 8 | Iteration: 295 | Classification loss: 0.09284 | Regression loss: 0.32597 | Running loss: 0.47722\n",
      "Epoch: 8 | Iteration: 296 | Classification loss: 0.19852 | Regression loss: 0.48041 | Running loss: 0.47797\n",
      "Epoch: 8 | Iteration: 297 | Classification loss: 0.64635 | Regression loss: 0.57547 | Running loss: 0.47979\n",
      "Epoch: 8 | Iteration: 298 | Classification loss: 0.08256 | Regression loss: 0.31357 | Running loss: 0.47995\n",
      "Epoch: 8 | Iteration: 299 | Classification loss: 0.20320 | Regression loss: 0.16351 | Running loss: 0.47999\n",
      "Epoch: 8 | Iteration: 300 | Classification loss: 0.13670 | Regression loss: 0.43056 | Running loss: 0.48039\n",
      "Epoch: 8 | Iteration: 301 | Classification loss: 0.43885 | Regression loss: 0.72417 | Running loss: 0.48158\n",
      "Epoch: 8 | Iteration: 302 | Classification loss: 0.15441 | Regression loss: 0.22183 | Running loss: 0.47994\n",
      "Epoch: 8 | Iteration: 303 | Classification loss: 0.16467 | Regression loss: 0.46699 | Running loss: 0.48047\n",
      "Epoch: 8 | Iteration: 304 | Classification loss: 0.22546 | Regression loss: 0.33574 | Running loss: 0.48032\n",
      "Epoch: 8 | Iteration: 305 | Classification loss: 0.12922 | Regression loss: 0.21904 | Running loss: 0.47996\n",
      "Epoch: 8 | Iteration: 306 | Classification loss: 0.05006 | Regression loss: 0.15752 | Running loss: 0.47947\n",
      "Epoch: 8 | Iteration: 307 | Classification loss: 0.24080 | Regression loss: 0.23871 | Running loss: 0.47954\n",
      "Epoch: 8 | Iteration: 308 | Classification loss: 0.09122 | Regression loss: 0.22983 | Running loss: 0.47892\n",
      "Epoch: 8 | Iteration: 309 | Classification loss: 0.06963 | Regression loss: 0.16705 | Running loss: 0.47874\n",
      "Epoch: 8 | Iteration: 310 | Classification loss: 0.05892 | Regression loss: 0.11827 | Running loss: 0.47816\n",
      "Epoch: 8 | Iteration: 311 | Classification loss: 0.10443 | Regression loss: 0.22853 | Running loss: 0.47755\n",
      "Epoch: 8 | Iteration: 312 | Classification loss: 0.32333 | Regression loss: 0.25486 | Running loss: 0.47781\n",
      "Epoch: 8 | Iteration: 313 | Classification loss: 0.04867 | Regression loss: 0.19930 | Running loss: 0.47779\n",
      "Epoch: 8 | Iteration: 314 | Classification loss: 0.20003 | Regression loss: 0.23298 | Running loss: 0.47778\n",
      "Epoch: 8 | Iteration: 315 | Classification loss: 0.05993 | Regression loss: 0.21735 | Running loss: 0.47607\n",
      "Epoch: 8 | Iteration: 316 | Classification loss: 0.14384 | Regression loss: 0.25225 | Running loss: 0.47593\n",
      "Epoch: 8 | Iteration: 317 | Classification loss: 0.32428 | Regression loss: 0.68545 | Running loss: 0.47714\n",
      "Epoch: 8 | Iteration: 318 | Classification loss: 0.04906 | Regression loss: 0.15689 | Running loss: 0.47603\n",
      "Epoch: 8 | Iteration: 319 | Classification loss: 0.23546 | Regression loss: 0.50313 | Running loss: 0.47666\n",
      "Epoch: 8 | Iteration: 320 | Classification loss: 0.16252 | Regression loss: 0.23891 | Running loss: 0.47687\n",
      "Epoch: 8 | Iteration: 321 | Classification loss: 0.05302 | Regression loss: 0.19768 | Running loss: 0.47547\n",
      "Epoch: 8 | Iteration: 322 | Classification loss: 0.19799 | Regression loss: 0.21867 | Running loss: 0.47559\n",
      "Epoch: 8 | Iteration: 323 | Classification loss: 0.09650 | Regression loss: 0.18718 | Running loss: 0.47494\n",
      "Epoch: 8 | Iteration: 324 | Classification loss: 0.05601 | Regression loss: 0.12944 | Running loss: 0.47407\n",
      "Epoch: 8 | Iteration: 325 | Classification loss: 0.04885 | Regression loss: 0.23439 | Running loss: 0.47369\n",
      "Epoch: 8 | Iteration: 326 | Classification loss: 0.12521 | Regression loss: 0.34098 | Running loss: 0.47339\n",
      "Epoch: 8 | Iteration: 327 | Classification loss: 0.05570 | Regression loss: 0.11995 | Running loss: 0.47263\n",
      "Epoch: 8 | Iteration: 328 | Classification loss: 0.08371 | Regression loss: 0.16615 | Running loss: 0.47235\n",
      "Epoch: 8 | Iteration: 329 | Classification loss: 0.40342 | Regression loss: 0.38514 | Running loss: 0.47325\n",
      "Epoch: 8 | Iteration: 330 | Classification loss: 0.10287 | Regression loss: 0.28031 | Running loss: 0.47297\n",
      "Epoch: 8 | Iteration: 331 | Classification loss: 0.09964 | Regression loss: 0.28198 | Running loss: 0.47278\n",
      "Epoch: 8 | Iteration: 332 | Classification loss: 0.08942 | Regression loss: 0.22715 | Running loss: 0.47155\n",
      "Epoch: 8 | Iteration: 333 | Classification loss: 0.24480 | Regression loss: 0.21937 | Running loss: 0.47125\n",
      "Epoch: 8 | Iteration: 334 | Classification loss: 0.50778 | Regression loss: 0.41342 | Running loss: 0.47238\n",
      "Epoch: 8 | Iteration: 335 | Classification loss: 0.08587 | Regression loss: 0.27420 | Running loss: 0.47203\n",
      "Epoch: 8 | Iteration: 336 | Classification loss: 0.14909 | Regression loss: 0.52888 | Running loss: 0.47221\n",
      "Epoch: 8 | Iteration: 337 | Classification loss: 0.21348 | Regression loss: 0.39506 | Running loss: 0.47233\n",
      "Epoch: 8 | Iteration: 338 | Classification loss: 0.56540 | Regression loss: 0.23153 | Running loss: 0.47306\n",
      "Epoch: 8 | Iteration: 339 | Classification loss: 0.22280 | Regression loss: 0.28600 | Running loss: 0.47328\n",
      "Epoch: 8 | Iteration: 340 | Classification loss: 0.31099 | Regression loss: 0.18174 | Running loss: 0.47280\n",
      "Epoch: 8 | Iteration: 341 | Classification loss: 0.23145 | Regression loss: 0.33727 | Running loss: 0.47326\n",
      "Epoch: 8 | Iteration: 342 | Classification loss: 0.05319 | Regression loss: 0.26671 | Running loss: 0.47219\n",
      "Epoch: 8 | Iteration: 343 | Classification loss: 0.12146 | Regression loss: 0.30317 | Running loss: 0.47237\n",
      "Epoch: 8 | Iteration: 344 | Classification loss: 0.11432 | Regression loss: 0.23584 | Running loss: 0.47136\n",
      "Epoch: 8 | Iteration: 345 | Classification loss: 0.21683 | Regression loss: 0.22684 | Running loss: 0.47152\n",
      "Epoch: 8 | Iteration: 346 | Classification loss: 0.16769 | Regression loss: 0.33690 | Running loss: 0.47119\n",
      "Epoch: 8 | Iteration: 347 | Classification loss: 0.70354 | Regression loss: 0.53324 | Running loss: 0.47308\n",
      "Epoch: 8 | Iteration: 348 | Classification loss: 0.11868 | Regression loss: 0.09907 | Running loss: 0.47244\n",
      "Epoch: 8 | Iteration: 349 | Classification loss: 0.27936 | Regression loss: 0.49540 | Running loss: 0.47315\n",
      "Epoch: 8 | Iteration: 350 | Classification loss: 0.21128 | Regression loss: 0.23447 | Running loss: 0.47260\n",
      "Epoch: 8 | Iteration: 351 | Classification loss: 0.22943 | Regression loss: 0.21861 | Running loss: 0.47273\n",
      "Epoch: 8 | Iteration: 352 | Classification loss: 0.06001 | Regression loss: 0.27538 | Running loss: 0.47292\n",
      "Epoch: 8 | Iteration: 353 | Classification loss: 0.03649 | Regression loss: 0.12815 | Running loss: 0.47202\n",
      "Epoch: 8 | Iteration: 354 | Classification loss: 0.11548 | Regression loss: 0.18070 | Running loss: 0.47149\n",
      "Epoch: 8 | Iteration: 355 | Classification loss: 0.19647 | Regression loss: 0.38217 | Running loss: 0.47174\n",
      "Epoch: 8 | Iteration: 356 | Classification loss: 0.18388 | Regression loss: 0.51055 | Running loss: 0.47155\n",
      "Epoch: 8 | Iteration: 357 | Classification loss: 0.03250 | Regression loss: 0.14219 | Running loss: 0.47104\n",
      "Epoch: 8 | Iteration: 358 | Classification loss: 0.05208 | Regression loss: 0.30308 | Running loss: 0.47094\n",
      "Epoch: 8 | Iteration: 359 | Classification loss: 0.16842 | Regression loss: 0.20821 | Running loss: 0.47122\n",
      "Epoch: 8 | Iteration: 360 | Classification loss: 0.35764 | Regression loss: 0.65855 | Running loss: 0.47254\n",
      "Epoch: 8 | Iteration: 361 | Classification loss: 0.27038 | Regression loss: 0.37376 | Running loss: 0.47316\n",
      "Epoch: 8 | Iteration: 362 | Classification loss: 0.10392 | Regression loss: 0.21744 | Running loss: 0.47125\n",
      "Epoch: 8 | Iteration: 363 | Classification loss: 0.09317 | Regression loss: 0.18738 | Running loss: 0.47101\n",
      "Epoch: 8 | Iteration: 364 | Classification loss: 0.17915 | Regression loss: 0.52867 | Running loss: 0.47147\n",
      "Epoch: 8 | Iteration: 365 | Classification loss: 0.09052 | Regression loss: 0.51771 | Running loss: 0.47194\n",
      "Epoch: 8 | Iteration: 366 | Classification loss: 0.18822 | Regression loss: 0.35226 | Running loss: 0.47202\n",
      "Epoch: 8 | Iteration: 367 | Classification loss: 0.31913 | Regression loss: 0.44338 | Running loss: 0.47248\n",
      "Epoch: 8 | Iteration: 368 | Classification loss: 0.19527 | Regression loss: 0.33017 | Running loss: 0.47151\n",
      "Epoch: 8 | Iteration: 369 | Classification loss: 0.29688 | Regression loss: 0.54409 | Running loss: 0.47190\n",
      "Epoch: 8 | Iteration: 370 | Classification loss: 0.19774 | Regression loss: 0.36320 | Running loss: 0.47235\n",
      "Epoch: 8 | Iteration: 371 | Classification loss: 0.27023 | Regression loss: 0.40162 | Running loss: 0.47323\n",
      "Epoch: 8 | Iteration: 372 | Classification loss: 0.30652 | Regression loss: 0.47572 | Running loss: 0.47373\n",
      "Epoch: 8 | Iteration: 373 | Classification loss: 0.17585 | Regression loss: 0.23498 | Running loss: 0.47382\n",
      "Epoch: 8 | Iteration: 374 | Classification loss: 0.38967 | Regression loss: 0.21653 | Running loss: 0.47415\n",
      "Epoch: 8 | Iteration: 375 | Classification loss: 0.09784 | Regression loss: 0.20647 | Running loss: 0.47353\n",
      "Epoch: 8 | Iteration: 376 | Classification loss: 0.52129 | Regression loss: 0.59361 | Running loss: 0.47446\n",
      "Epoch: 8 | Iteration: 377 | Classification loss: 0.05139 | Regression loss: 0.09621 | Running loss: 0.47402\n",
      "Epoch: 8 | Iteration: 378 | Classification loss: 0.08284 | Regression loss: 0.15232 | Running loss: 0.47363\n",
      "Epoch: 8 | Iteration: 379 | Classification loss: 0.07656 | Regression loss: 0.15767 | Running loss: 0.47291\n",
      "Epoch: 8 | Iteration: 380 | Classification loss: 0.14252 | Regression loss: 0.48491 | Running loss: 0.47340\n",
      "Epoch: 8 | Iteration: 381 | Classification loss: 0.36266 | Regression loss: 0.27347 | Running loss: 0.47421\n",
      "Epoch: 8 | Iteration: 382 | Classification loss: 0.12277 | Regression loss: 0.17111 | Running loss: 0.47296\n",
      "Epoch: 8 | Iteration: 383 | Classification loss: 0.08346 | Regression loss: 0.18532 | Running loss: 0.47287\n",
      "Epoch: 8 | Iteration: 384 | Classification loss: 0.38011 | Regression loss: 0.27191 | Running loss: 0.47366\n",
      "Epoch: 8 | Iteration: 385 | Classification loss: 0.27866 | Regression loss: 0.17306 | Running loss: 0.47337\n",
      "Epoch: 8 | Iteration: 386 | Classification loss: 0.09152 | Regression loss: 0.15411 | Running loss: 0.47281\n",
      "Epoch: 8 | Iteration: 387 | Classification loss: 0.11099 | Regression loss: 0.30314 | Running loss: 0.47282\n",
      "Epoch: 8 | Iteration: 388 | Classification loss: 0.05279 | Regression loss: 0.19623 | Running loss: 0.47263\n",
      "Epoch: 8 | Iteration: 389 | Classification loss: 0.28853 | Regression loss: 0.48110 | Running loss: 0.47299\n",
      "Epoch: 8 | Iteration: 390 | Classification loss: 0.21124 | Regression loss: 0.20458 | Running loss: 0.47192\n",
      "Epoch: 8 | Iteration: 391 | Classification loss: 0.06280 | Regression loss: 0.24899 | Running loss: 0.47184\n",
      "Epoch: 8 | Iteration: 392 | Classification loss: 0.19105 | Regression loss: 0.26323 | Running loss: 0.47173\n",
      "Epoch: 8 | Iteration: 393 | Classification loss: 0.26998 | Regression loss: 0.31030 | Running loss: 0.47134\n",
      "Epoch: 8 | Iteration: 394 | Classification loss: 0.14058 | Regression loss: 0.35114 | Running loss: 0.47084\n",
      "Epoch: 8 | Iteration: 395 | Classification loss: 0.12646 | Regression loss: 0.32526 | Running loss: 0.47067\n",
      "Epoch: 8 | Iteration: 396 | Classification loss: 0.12417 | Regression loss: 0.37075 | Running loss: 0.47092\n",
      "Epoch: 8 | Iteration: 397 | Classification loss: 0.07007 | Regression loss: 0.35110 | Running loss: 0.47089\n",
      "Epoch: 8 | Iteration: 398 | Classification loss: 0.41225 | Regression loss: 0.68722 | Running loss: 0.47190\n",
      "Epoch: 8 | Iteration: 399 | Classification loss: 0.07135 | Regression loss: 0.17313 | Running loss: 0.47137\n",
      "Epoch: 8 | Iteration: 400 | Classification loss: 0.11231 | Regression loss: 0.25311 | Running loss: 0.47113\n",
      "Epoch: 8 | Iteration: 401 | Classification loss: 0.21178 | Regression loss: 0.38890 | Running loss: 0.47147\n",
      "Epoch: 8 | Iteration: 402 | Classification loss: 0.15530 | Regression loss: 0.26297 | Running loss: 0.47158\n",
      "Epoch: 8 | Iteration: 403 | Classification loss: 0.30413 | Regression loss: 0.14980 | Running loss: 0.47003\n",
      "Epoch: 8 | Iteration: 404 | Classification loss: 0.21361 | Regression loss: 0.20264 | Running loss: 0.46986\n",
      "Epoch: 8 | Iteration: 405 | Classification loss: 0.13362 | Regression loss: 0.10732 | Running loss: 0.46935\n",
      "Epoch: 8 | Iteration: 406 | Classification loss: 0.20511 | Regression loss: 0.11485 | Running loss: 0.46943\n",
      "Epoch: 8 | Iteration: 407 | Classification loss: 0.13065 | Regression loss: 0.20691 | Running loss: 0.46933\n",
      "Epoch: 8 | Iteration: 408 | Classification loss: 0.07034 | Regression loss: 0.18743 | Running loss: 0.46928\n",
      "Epoch: 8 | Iteration: 409 | Classification loss: 0.18695 | Regression loss: 0.39560 | Running loss: 0.46980\n",
      "Epoch: 8 | Iteration: 410 | Classification loss: 0.14396 | Regression loss: 0.26382 | Running loss: 0.46957\n",
      "Epoch: 8 | Iteration: 411 | Classification loss: 0.18293 | Regression loss: 0.21703 | Running loss: 0.46889\n",
      "Epoch: 8 | Iteration: 412 | Classification loss: 0.20001 | Regression loss: 0.44528 | Running loss: 0.46890\n",
      "Epoch: 8 | Iteration: 413 | Classification loss: 0.10539 | Regression loss: 0.34356 | Running loss: 0.46878\n",
      "Epoch: 8 | Iteration: 414 | Classification loss: 0.17546 | Regression loss: 0.15290 | Running loss: 0.46782\n",
      "Epoch: 8 | Iteration: 415 | Classification loss: 0.09101 | Regression loss: 0.17481 | Running loss: 0.46644\n",
      "Epoch: 8 | Iteration: 416 | Classification loss: 0.29308 | Regression loss: 0.26153 | Running loss: 0.46650\n",
      "Epoch: 8 | Iteration: 417 | Classification loss: 0.29327 | Regression loss: 0.35281 | Running loss: 0.46639\n",
      "Epoch: 8 | Iteration: 418 | Classification loss: 0.04549 | Regression loss: 0.13646 | Running loss: 0.46605\n",
      "Epoch: 8 | Iteration: 419 | Classification loss: 0.45795 | Regression loss: 0.39022 | Running loss: 0.46693\n",
      "Epoch: 8 | Iteration: 420 | Classification loss: 0.09280 | Regression loss: 0.24727 | Running loss: 0.46704\n",
      "Epoch: 8 | Iteration: 421 | Classification loss: 0.08495 | Regression loss: 0.16772 | Running loss: 0.46700\n",
      "Epoch: 8 | Iteration: 422 | Classification loss: 0.17871 | Regression loss: 0.27065 | Running loss: 0.46730\n",
      "Epoch: 8 | Iteration: 423 | Classification loss: 0.13113 | Regression loss: 0.26474 | Running loss: 0.46704\n",
      "Epoch: 8 | Iteration: 424 | Classification loss: 0.08806 | Regression loss: 0.25910 | Running loss: 0.46639\n",
      "Epoch: 8 | Iteration: 425 | Classification loss: 0.20854 | Regression loss: 0.20798 | Running loss: 0.46648\n",
      "Epoch: 8 | Iteration: 426 | Classification loss: 0.11446 | Regression loss: 0.24447 | Running loss: 0.46618\n",
      "Epoch: 8 | Iteration: 427 | Classification loss: 0.29929 | Regression loss: 0.37725 | Running loss: 0.46634\n",
      "Epoch: 8 | Iteration: 428 | Classification loss: 0.31174 | Regression loss: 0.42035 | Running loss: 0.46678\n",
      "Epoch: 8 | Iteration: 429 | Classification loss: 0.04895 | Regression loss: 0.16741 | Running loss: 0.46551\n",
      "Epoch: 8 | Iteration: 430 | Classification loss: 0.22654 | Regression loss: 0.16723 | Running loss: 0.46525\n",
      "Epoch: 8 | Iteration: 431 | Classification loss: 0.16715 | Regression loss: 0.38841 | Running loss: 0.46559\n",
      "Epoch: 8 | Iteration: 432 | Classification loss: 0.13600 | Regression loss: 0.26971 | Running loss: 0.46497\n",
      "Epoch: 8 | Iteration: 433 | Classification loss: 0.09377 | Regression loss: 0.23466 | Running loss: 0.46462\n",
      "Epoch: 8 | Iteration: 434 | Classification loss: 0.14184 | Regression loss: 0.32623 | Running loss: 0.46467\n",
      "Epoch: 8 | Iteration: 435 | Classification loss: 0.23723 | Regression loss: 0.39943 | Running loss: 0.46412\n",
      "Epoch: 8 | Iteration: 436 | Classification loss: 0.06417 | Regression loss: 0.39290 | Running loss: 0.46441\n",
      "Epoch: 8 | Iteration: 437 | Classification loss: 0.06995 | Regression loss: 0.13940 | Running loss: 0.46399\n",
      "Epoch: 8 | Iteration: 438 | Classification loss: 0.09007 | Regression loss: 0.34692 | Running loss: 0.46362\n",
      "Epoch: 8 | Iteration: 439 | Classification loss: 0.14127 | Regression loss: 0.25704 | Running loss: 0.46252\n",
      "Epoch: 8 | Iteration: 440 | Classification loss: 0.25237 | Regression loss: 0.28737 | Running loss: 0.46259\n",
      "Epoch: 8 | Iteration: 441 | Classification loss: 0.26356 | Regression loss: 0.26369 | Running loss: 0.46241\n",
      "Epoch: 8 | Iteration: 442 | Classification loss: 0.23162 | Regression loss: 0.45518 | Running loss: 0.46343\n",
      "Epoch: 8 | Iteration: 443 | Classification loss: 0.16006 | Regression loss: 0.20925 | Running loss: 0.46322\n",
      "Epoch: 8 | Iteration: 444 | Classification loss: 0.46553 | Regression loss: 0.35881 | Running loss: 0.46381\n",
      "Epoch: 8 | Iteration: 445 | Classification loss: 0.19791 | Regression loss: 0.20207 | Running loss: 0.46401\n",
      "Epoch: 8 | Iteration: 446 | Classification loss: 0.10584 | Regression loss: 0.17613 | Running loss: 0.46396\n",
      "Epoch: 8 | Iteration: 447 | Classification loss: 0.03590 | Regression loss: 0.13635 | Running loss: 0.46394\n",
      "Epoch: 8 | Iteration: 448 | Classification loss: 0.14693 | Regression loss: 0.22251 | Running loss: 0.46396\n",
      "Epoch: 8 | Iteration: 449 | Classification loss: 0.16997 | Regression loss: 0.28036 | Running loss: 0.46427\n",
      "Epoch: 8 | Iteration: 450 | Classification loss: 0.07331 | Regression loss: 0.26642 | Running loss: 0.46434\n",
      "Epoch: 8 | Iteration: 451 | Classification loss: 0.16298 | Regression loss: 0.10263 | Running loss: 0.46379\n",
      "Epoch: 8 | Iteration: 452 | Classification loss: 0.12729 | Regression loss: 0.16343 | Running loss: 0.46403\n",
      "Epoch: 8 | Iteration: 453 | Classification loss: 0.17630 | Regression loss: 0.40909 | Running loss: 0.46387\n",
      "Epoch: 8 | Iteration: 454 | Classification loss: 0.16172 | Regression loss: 0.40176 | Running loss: 0.46421\n",
      "Epoch: 8 | Iteration: 455 | Classification loss: 0.09994 | Regression loss: 0.24413 | Running loss: 0.46430\n",
      "Epoch: 8 | Iteration: 456 | Classification loss: 0.33531 | Regression loss: 0.42787 | Running loss: 0.46494\n",
      "Epoch: 8 | Iteration: 457 | Classification loss: 0.16145 | Regression loss: 0.26346 | Running loss: 0.46511\n",
      "Epoch: 8 | Iteration: 458 | Classification loss: 0.06430 | Regression loss: 0.28213 | Running loss: 0.46478\n",
      "Epoch: 8 | Iteration: 459 | Classification loss: 0.30280 | Regression loss: 0.16578 | Running loss: 0.46473\n",
      "Epoch: 8 | Iteration: 460 | Classification loss: 0.20505 | Regression loss: 0.47326 | Running loss: 0.46546\n",
      "Epoch: 8 | Iteration: 461 | Classification loss: 0.17175 | Regression loss: 0.29237 | Running loss: 0.46525\n",
      "Epoch: 8 | Iteration: 462 | Classification loss: 0.34982 | Regression loss: 0.45337 | Running loss: 0.46590\n",
      "Epoch: 8 | Iteration: 463 | Classification loss: 0.33608 | Regression loss: 0.40793 | Running loss: 0.46655\n",
      "Epoch: 8 | Iteration: 464 | Classification loss: 0.13851 | Regression loss: 0.11723 | Running loss: 0.46603\n",
      "Epoch: 8 | Iteration: 465 | Classification loss: 0.08154 | Regression loss: 0.23937 | Running loss: 0.46602\n",
      "Epoch: 8 | Iteration: 466 | Classification loss: 0.14911 | Regression loss: 0.28062 | Running loss: 0.46468\n",
      "Epoch: 8 | Iteration: 467 | Classification loss: 0.05572 | Regression loss: 0.16449 | Running loss: 0.46434\n",
      "Epoch: 8 | Iteration: 468 | Classification loss: 0.07303 | Regression loss: 0.20020 | Running loss: 0.46449\n",
      "Epoch: 8 | Iteration: 469 | Classification loss: 0.08561 | Regression loss: 0.20931 | Running loss: 0.46386\n",
      "Epoch: 8 | Iteration: 470 | Classification loss: 0.20023 | Regression loss: 0.16319 | Running loss: 0.46379\n",
      "Epoch: 8 | Iteration: 471 | Classification loss: 0.27411 | Regression loss: 0.39739 | Running loss: 0.46414\n",
      "Epoch: 8 | Iteration: 472 | Classification loss: 0.32846 | Regression loss: 0.20702 | Running loss: 0.46423\n",
      "Epoch: 8 | Iteration: 473 | Classification loss: 0.05947 | Regression loss: 0.11929 | Running loss: 0.46396\n",
      "Epoch: 8 | Iteration: 474 | Classification loss: 0.14451 | Regression loss: 0.15189 | Running loss: 0.46407\n",
      "Epoch: 8 | Iteration: 475 | Classification loss: 0.20869 | Regression loss: 0.36229 | Running loss: 0.46403\n",
      "Epoch: 8 | Iteration: 476 | Classification loss: 0.17586 | Regression loss: 0.33156 | Running loss: 0.46394\n",
      "Epoch: 8 | Iteration: 477 | Classification loss: 0.30005 | Regression loss: 0.30031 | Running loss: 0.46470\n",
      "Epoch: 8 | Iteration: 478 | Classification loss: 0.25939 | Regression loss: 0.19636 | Running loss: 0.46504\n",
      "Epoch: 8 | Iteration: 479 | Classification loss: 0.12386 | Regression loss: 0.34991 | Running loss: 0.46496\n",
      "Epoch: 8 | Iteration: 480 | Classification loss: 0.14809 | Regression loss: 0.39017 | Running loss: 0.46466\n",
      "Epoch: 8 | Iteration: 481 | Classification loss: 0.31972 | Regression loss: 0.74584 | Running loss: 0.46595\n",
      "Epoch: 8 | Iteration: 482 | Classification loss: 0.50180 | Regression loss: 0.34467 | Running loss: 0.46624\n",
      "Epoch: 8 | Iteration: 483 | Classification loss: 0.17086 | Regression loss: 0.36126 | Running loss: 0.46697\n",
      "Epoch: 8 | Iteration: 484 | Classification loss: 0.30453 | Regression loss: 0.45915 | Running loss: 0.46739\n",
      "Epoch: 8 | Iteration: 485 | Classification loss: 0.08194 | Regression loss: 0.38300 | Running loss: 0.46706\n",
      "Epoch: 8 | Iteration: 486 | Classification loss: 0.32464 | Regression loss: 0.26710 | Running loss: 0.46788\n",
      "Epoch: 8 | Iteration: 487 | Classification loss: 0.31067 | Regression loss: 0.30393 | Running loss: 0.46862\n",
      "Epoch: 8 | Iteration: 488 | Classification loss: 0.10460 | Regression loss: 0.24277 | Running loss: 0.46841\n",
      "Epoch: 8 | Iteration: 489 | Classification loss: 0.20766 | Regression loss: 0.32587 | Running loss: 0.46875\n",
      "Epoch: 8 | Iteration: 490 | Classification loss: 0.11502 | Regression loss: 0.22005 | Running loss: 0.46755\n",
      "Epoch: 8 | Iteration: 491 | Classification loss: 0.34416 | Regression loss: 0.32531 | Running loss: 0.46834\n",
      "Epoch: 8 | Iteration: 492 | Classification loss: 0.21324 | Regression loss: 0.28679 | Running loss: 0.46851\n",
      "Epoch: 8 | Iteration: 493 | Classification loss: 0.13074 | Regression loss: 0.18288 | Running loss: 0.46866\n",
      "Epoch: 8 | Iteration: 494 | Classification loss: 0.11197 | Regression loss: 0.26010 | Running loss: 0.46778\n",
      "Epoch: 8 | Iteration: 495 | Classification loss: 0.20131 | Regression loss: 0.37905 | Running loss: 0.46836\n",
      "Epoch: 8 | Iteration: 496 | Classification loss: 0.16999 | Regression loss: 0.45657 | Running loss: 0.46870\n",
      "Epoch: 8 | Iteration: 497 | Classification loss: 0.10131 | Regression loss: 0.31323 | Running loss: 0.46768\n",
      "Epoch: 8 | Iteration: 498 | Classification loss: 0.15921 | Regression loss: 0.33750 | Running loss: 0.46828\n",
      "Epoch: 8 | Iteration: 499 | Classification loss: 0.15428 | Regression loss: 0.26584 | Running loss: 0.46789\n",
      "Epoch: 8 | Iteration: 500 | Classification loss: 0.43088 | Regression loss: 0.32423 | Running loss: 0.46828\n",
      "Epoch: 8 | Iteration: 501 | Classification loss: 0.17914 | Regression loss: 0.30217 | Running loss: 0.46846\n",
      "Epoch: 8 | Iteration: 502 | Classification loss: 0.09715 | Regression loss: 0.16915 | Running loss: 0.46811\n",
      "Epoch: 8 | Iteration: 503 | Classification loss: 0.13195 | Regression loss: 0.39993 | Running loss: 0.46675\n",
      "Epoch: 8 | Iteration: 504 | Classification loss: 0.27694 | Regression loss: 0.34801 | Running loss: 0.46675\n",
      "Epoch: 8 | Iteration: 505 | Classification loss: 0.08606 | Regression loss: 0.24915 | Running loss: 0.46685\n",
      "Epoch: 8 | Iteration: 506 | Classification loss: 0.25111 | Regression loss: 0.31485 | Running loss: 0.46724\n",
      "Epoch: 8 | Iteration: 507 | Classification loss: 0.04631 | Regression loss: 0.09163 | Running loss: 0.46680\n",
      "Epoch: 8 | Iteration: 508 | Classification loss: 0.13647 | Regression loss: 0.22903 | Running loss: 0.46705\n",
      "Epoch: 8 | Iteration: 509 | Classification loss: 0.05212 | Regression loss: 0.18112 | Running loss: 0.46697\n",
      "Epoch: 8 | Iteration: 510 | Classification loss: 0.09286 | Regression loss: 0.09187 | Running loss: 0.46554\n",
      "Epoch: 8 | Iteration: 511 | Classification loss: 0.11676 | Regression loss: 0.22458 | Running loss: 0.46541\n",
      "Epoch: 8 | Iteration: 512 | Classification loss: 0.06933 | Regression loss: 0.07276 | Running loss: 0.46502\n",
      "Epoch: 8 | Iteration: 513 | Classification loss: 0.07797 | Regression loss: 0.24180 | Running loss: 0.46538\n",
      "Epoch: 8 | Iteration: 514 | Classification loss: 0.07803 | Regression loss: 0.18431 | Running loss: 0.46512\n",
      "Epoch: 8 | Iteration: 515 | Classification loss: 0.12852 | Regression loss: 0.19368 | Running loss: 0.46521\n",
      "Epoch: 8 | Iteration: 516 | Classification loss: 0.11667 | Regression loss: 0.36934 | Running loss: 0.46541\n",
      "Epoch: 8 | Iteration: 517 | Classification loss: 0.25083 | Regression loss: 0.26013 | Running loss: 0.46544\n",
      "Epoch: 8 | Iteration: 518 | Classification loss: 0.12637 | Regression loss: 0.22445 | Running loss: 0.46541\n",
      "Epoch: 8 | Iteration: 519 | Classification loss: 0.16037 | Regression loss: 0.23841 | Running loss: 0.46573\n",
      "Epoch: 8 | Iteration: 520 | Classification loss: 0.08440 | Regression loss: 0.27419 | Running loss: 0.46478\n",
      "Epoch: 8 | Iteration: 521 | Classification loss: 0.29427 | Regression loss: 0.19702 | Running loss: 0.46461\n",
      "Epoch: 8 | Iteration: 522 | Classification loss: 0.10887 | Regression loss: 0.24123 | Running loss: 0.46423\n",
      "Epoch: 8 | Iteration: 523 | Classification loss: 2.49015 | Regression loss: 0.21309 | Running loss: 0.46897\n",
      "Epoch: 8 | Iteration: 524 | Classification loss: 0.09075 | Regression loss: 0.22237 | Running loss: 0.46864\n",
      "Epoch: 8 | Iteration: 525 | Classification loss: 0.19249 | Regression loss: 0.50059 | Running loss: 0.46953\n",
      "Epoch: 8 | Iteration: 526 | Classification loss: 0.06520 | Regression loss: 0.20188 | Running loss: 0.46853\n",
      "Epoch: 8 | Iteration: 527 | Classification loss: 0.18706 | Regression loss: 0.26275 | Running loss: 0.46877\n",
      "Epoch: 8 | Iteration: 528 | Classification loss: 0.08078 | Regression loss: 0.30557 | Running loss: 0.46889\n",
      "Epoch: 8 | Iteration: 529 | Classification loss: 0.22066 | Regression loss: 0.21154 | Running loss: 0.46905\n",
      "Epoch: 8 | Iteration: 530 | Classification loss: 0.15350 | Regression loss: 0.17249 | Running loss: 0.46862\n",
      "Epoch: 8 | Iteration: 531 | Classification loss: 0.05538 | Regression loss: 0.13836 | Running loss: 0.46737\n",
      "Epoch: 8 | Iteration: 532 | Classification loss: 0.28411 | Regression loss: 0.43467 | Running loss: 0.46769\n",
      "Epoch: 8 | Iteration: 533 | Classification loss: 0.03673 | Regression loss: 0.13093 | Running loss: 0.46709\n",
      "Epoch: 8 | Iteration: 534 | Classification loss: 0.18923 | Regression loss: 0.30085 | Running loss: 0.46688\n",
      "Epoch: 8 | Iteration: 535 | Classification loss: 0.35498 | Regression loss: 0.07807 | Running loss: 0.46711\n",
      "Epoch: 8 | Iteration: 536 | Classification loss: 0.32148 | Regression loss: 0.16981 | Running loss: 0.46738\n",
      "Epoch: 8 | Iteration: 537 | Classification loss: 0.33630 | Regression loss: 0.20106 | Running loss: 0.46800\n",
      "Epoch: 8 | Iteration: 538 | Classification loss: 0.04762 | Regression loss: 0.20764 | Running loss: 0.46761\n",
      "Epoch: 8 | Iteration: 539 | Classification loss: 0.13360 | Regression loss: 0.43968 | Running loss: 0.46721\n",
      "Epoch: 8 | Iteration: 540 | Classification loss: 0.13107 | Regression loss: 0.49559 | Running loss: 0.46799\n",
      "Epoch: 8 | Iteration: 541 | Classification loss: 0.13578 | Regression loss: 0.22504 | Running loss: 0.46820\n",
      "Epoch: 8 | Iteration: 542 | Classification loss: 0.13218 | Regression loss: 0.47864 | Running loss: 0.46846\n",
      "Epoch: 8 | Iteration: 543 | Classification loss: 0.10677 | Regression loss: 0.24113 | Running loss: 0.46796\n",
      "Epoch: 8 | Iteration: 544 | Classification loss: 0.09904 | Regression loss: 0.18403 | Running loss: 0.46814\n",
      "Epoch: 8 | Iteration: 545 | Classification loss: 0.07072 | Regression loss: 0.09794 | Running loss: 0.46738\n",
      "Epoch: 8 | Iteration: 546 | Classification loss: 0.11965 | Regression loss: 0.33987 | Running loss: 0.46731\n",
      "Epoch: 8 | Iteration: 547 | Classification loss: 0.11233 | Regression loss: 0.15151 | Running loss: 0.46699\n",
      "Epoch: 8 | Iteration: 548 | Classification loss: 0.11431 | Regression loss: 0.18128 | Running loss: 0.46668\n",
      "Epoch: 8 | Iteration: 549 | Classification loss: 0.09538 | Regression loss: 0.26964 | Running loss: 0.46691\n",
      "Epoch: 8 | Iteration: 550 | Classification loss: 0.10683 | Regression loss: 0.13802 | Running loss: 0.46592\n",
      "Epoch: 8 | Iteration: 551 | Classification loss: 0.22301 | Regression loss: 0.17974 | Running loss: 0.46533\n",
      "Epoch: 8 | Iteration: 552 | Classification loss: 0.40709 | Regression loss: 0.45876 | Running loss: 0.46617\n",
      "Epoch: 8 | Iteration: 553 | Classification loss: 0.05948 | Regression loss: 0.23189 | Running loss: 0.46576\n",
      "Epoch: 8 | Iteration: 554 | Classification loss: 0.15485 | Regression loss: 0.44292 | Running loss: 0.46640\n",
      "Epoch: 8 | Iteration: 555 | Classification loss: 0.08489 | Regression loss: 0.16902 | Running loss: 0.46571\n",
      "Epoch: 8 | Iteration: 556 | Classification loss: 0.39840 | Regression loss: 0.57746 | Running loss: 0.46694\n",
      "Epoch: 8 | Iteration: 557 | Classification loss: 0.25927 | Regression loss: 0.27654 | Running loss: 0.46675\n",
      "Epoch: 8 | Iteration: 558 | Classification loss: 0.22008 | Regression loss: 0.44466 | Running loss: 0.46726\n",
      "Epoch: 8 | Iteration: 559 | Classification loss: 0.12292 | Regression loss: 0.34367 | Running loss: 0.46749\n",
      "Epoch: 8 | Iteration: 560 | Classification loss: 0.09094 | Regression loss: 0.22509 | Running loss: 0.46722\n",
      "Epoch: 8 | Iteration: 561 | Classification loss: 0.09702 | Regression loss: 0.35554 | Running loss: 0.46734\n",
      "Epoch: 8 | Iteration: 562 | Classification loss: 0.12619 | Regression loss: 0.25670 | Running loss: 0.46719\n",
      "Epoch: 8 | Iteration: 563 | Classification loss: 0.18985 | Regression loss: 0.38074 | Running loss: 0.46764\n",
      "Epoch: 8 | Iteration: 564 | Classification loss: 0.13730 | Regression loss: 0.43863 | Running loss: 0.46794\n",
      "Epoch: 8 | Iteration: 565 | Classification loss: 0.15794 | Regression loss: 0.38318 | Running loss: 0.46763\n",
      "Epoch: 8 | Iteration: 566 | Classification loss: 0.16790 | Regression loss: 0.27243 | Running loss: 0.46730\n",
      "Epoch: 8 | Iteration: 567 | Classification loss: 0.11867 | Regression loss: 0.36674 | Running loss: 0.46734\n",
      "Epoch: 8 | Iteration: 568 | Classification loss: 0.19975 | Regression loss: 0.26174 | Running loss: 0.46734\n",
      "Epoch: 8 | Iteration: 569 | Classification loss: 0.14068 | Regression loss: 0.23968 | Running loss: 0.46714\n",
      "Epoch: 8 | Iteration: 570 | Classification loss: 0.10939 | Regression loss: 0.32801 | Running loss: 0.46746\n",
      "Epoch: 8 | Iteration: 571 | Classification loss: 0.07083 | Regression loss: 0.35516 | Running loss: 0.46760\n",
      "Epoch: 8 | Iteration: 572 | Classification loss: 0.22922 | Regression loss: 0.38822 | Running loss: 0.46787\n",
      "Epoch: 8 | Iteration: 573 | Classification loss: 0.10052 | Regression loss: 0.27468 | Running loss: 0.46767\n",
      "Epoch: 8 | Iteration: 574 | Classification loss: 0.08386 | Regression loss: 0.37891 | Running loss: 0.46725\n",
      "Epoch: 8 | Iteration: 575 | Classification loss: 0.10859 | Regression loss: 0.35450 | Running loss: 0.46769\n",
      "Epoch: 8 | Iteration: 576 | Classification loss: 0.13398 | Regression loss: 0.33258 | Running loss: 0.46752\n",
      "Epoch: 8 | Iteration: 577 | Classification loss: 0.25310 | Regression loss: 0.48890 | Running loss: 0.46789\n",
      "Epoch: 8 | Iteration: 578 | Classification loss: 0.28240 | Regression loss: 0.44148 | Running loss: 0.46868\n",
      "Epoch: 8 | Iteration: 579 | Classification loss: 0.17757 | Regression loss: 0.33163 | Running loss: 0.46890\n",
      "Epoch: 8 | Iteration: 580 | Classification loss: 0.11495 | Regression loss: 0.33882 | Running loss: 0.46703\n",
      "Epoch: 8 | Iteration: 581 | Classification loss: 0.17305 | Regression loss: 0.14131 | Running loss: 0.46678\n",
      "Epoch: 8 | Iteration: 582 | Classification loss: 0.09277 | Regression loss: 0.31624 | Running loss: 0.46721\n",
      "Epoch: 8 | Iteration: 583 | Classification loss: 0.14406 | Regression loss: 0.35823 | Running loss: 0.46757\n",
      "Epoch: 8 | Iteration: 584 | Classification loss: 0.30228 | Regression loss: 0.27665 | Running loss: 0.46702\n",
      "Epoch: 8 | Iteration: 585 | Classification loss: 0.32536 | Regression loss: 0.29363 | Running loss: 0.46677\n",
      "Epoch: 8 | Iteration: 586 | Classification loss: 0.10848 | Regression loss: 0.33598 | Running loss: 0.46691\n",
      "Epoch: 8 | Iteration: 587 | Classification loss: 0.19116 | Regression loss: 0.43372 | Running loss: 0.46741\n",
      "Epoch: 8 | Iteration: 588 | Classification loss: 0.11026 | Regression loss: 0.21526 | Running loss: 0.46719\n",
      "Epoch: 8 | Iteration: 589 | Classification loss: 0.09428 | Regression loss: 0.24783 | Running loss: 0.46748\n",
      "Epoch: 8 | Iteration: 590 | Classification loss: 0.09219 | Regression loss: 0.20323 | Running loss: 0.46692\n",
      "Epoch: 8 | Iteration: 591 | Classification loss: 0.20583 | Regression loss: 0.45539 | Running loss: 0.46745\n",
      "Epoch: 8 | Iteration: 592 | Classification loss: 0.05994 | Regression loss: 0.20446 | Running loss: 0.46728\n",
      "Epoch: 8 | Iteration: 593 | Classification loss: 0.08755 | Regression loss: 0.25820 | Running loss: 0.46651\n",
      "Epoch: 8 | Iteration: 594 | Classification loss: 0.10710 | Regression loss: 0.22701 | Running loss: 0.46635\n",
      "Epoch: 8 | Iteration: 595 | Classification loss: 0.28900 | Regression loss: 0.37487 | Running loss: 0.46693\n",
      "Epoch: 8 | Iteration: 596 | Classification loss: 0.32013 | Regression loss: 0.24262 | Running loss: 0.46739\n",
      "Epoch: 8 | Iteration: 597 | Classification loss: 0.15797 | Regression loss: 0.26613 | Running loss: 0.46730\n",
      "Epoch: 8 | Iteration: 598 | Classification loss: 0.03671 | Regression loss: 0.15400 | Running loss: 0.46703\n",
      "Epoch: 8 | Iteration: 599 | Classification loss: 0.17924 | Regression loss: 0.42946 | Running loss: 0.46744\n",
      "Epoch: 8 | Iteration: 600 | Classification loss: 0.24086 | Regression loss: 0.40809 | Running loss: 0.46803\n",
      "Epoch: 8 | Iteration: 601 | Classification loss: 0.03894 | Regression loss: 0.25937 | Running loss: 0.46809\n",
      "Epoch: 8 | Iteration: 602 | Classification loss: 0.12549 | Regression loss: 0.24974 | Running loss: 0.46783\n",
      "Epoch: 8 | Iteration: 603 | Classification loss: 0.12842 | Regression loss: 0.34599 | Running loss: 0.46779\n",
      "Epoch: 8 | Iteration: 604 | Classification loss: 0.09694 | Regression loss: 0.32483 | Running loss: 0.46802\n",
      "Epoch: 8 | Iteration: 605 | Classification loss: 0.16140 | Regression loss: 0.44759 | Running loss: 0.46787\n",
      "Epoch: 8 | Iteration: 606 | Classification loss: 0.07666 | Regression loss: 0.13883 | Running loss: 0.46790\n",
      "Epoch: 8 | Iteration: 607 | Classification loss: 0.37129 | Regression loss: 0.35067 | Running loss: 0.46844\n",
      "Epoch: 8 | Iteration: 608 | Classification loss: 0.03873 | Regression loss: 0.14478 | Running loss: 0.46781\n",
      "Epoch: 8 | Iteration: 609 | Classification loss: 0.30079 | Regression loss: 0.35587 | Running loss: 0.46845\n",
      "Epoch: 8 | Iteration: 610 | Classification loss: 0.46691 | Regression loss: 0.24595 | Running loss: 0.46923\n",
      "Epoch: 8 | Iteration: 611 | Classification loss: 0.06378 | Regression loss: 0.24305 | Running loss: 0.46950\n",
      "Epoch: 8 | Iteration: 612 | Classification loss: 0.05646 | Regression loss: 0.18163 | Running loss: 0.46918\n",
      "Epoch: 8 | Iteration: 613 | Classification loss: 0.03683 | Regression loss: 0.09846 | Running loss: 0.46875\n",
      "Epoch: 8 | Iteration: 614 | Classification loss: 0.19492 | Regression loss: 0.35292 | Running loss: 0.46816\n",
      "Epoch: 8 | Iteration: 615 | Classification loss: 0.16695 | Regression loss: 0.28804 | Running loss: 0.46812\n",
      "Epoch: 8 | Iteration: 616 | Classification loss: 0.08615 | Regression loss: 0.25366 | Running loss: 0.46797\n",
      "Epoch: 8 | Iteration: 617 | Classification loss: 0.05271 | Regression loss: 0.18832 | Running loss: 0.46712\n",
      "Epoch: 8 | Iteration: 618 | Classification loss: 0.28624 | Regression loss: 0.19689 | Running loss: 0.46728\n",
      "Epoch: 8 | Iteration: 619 | Classification loss: 0.06678 | Regression loss: 0.14148 | Running loss: 0.46688\n",
      "Epoch: 8 | Iteration: 620 | Classification loss: 0.11246 | Regression loss: 0.31652 | Running loss: 0.46657\n",
      "Epoch: 8 | Iteration: 621 | Classification loss: 0.17151 | Regression loss: 0.26358 | Running loss: 0.46621\n",
      "Epoch: 8 | Iteration: 622 | Classification loss: 0.17064 | Regression loss: 0.45560 | Running loss: 0.46655\n",
      "Epoch: 8 | Iteration: 623 | Classification loss: 0.09665 | Regression loss: 0.18299 | Running loss: 0.46645\n",
      "Epoch: 8 | Iteration: 624 | Classification loss: 0.10639 | Regression loss: 0.08646 | Running loss: 0.46565\n",
      "Epoch: 8 | Iteration: 625 | Classification loss: 0.16416 | Regression loss: 0.32196 | Running loss: 0.46580\n",
      "Epoch: 8 | Iteration: 626 | Classification loss: 0.06232 | Regression loss: 0.16082 | Running loss: 0.46537\n",
      "Epoch: 8 | Iteration: 627 | Classification loss: 0.04425 | Regression loss: 0.11747 | Running loss: 0.46509\n",
      "Epoch: 8 | Iteration: 628 | Classification loss: 0.08846 | Regression loss: 0.24421 | Running loss: 0.46508\n",
      "Epoch: 8 | Iteration: 629 | Classification loss: 0.30189 | Regression loss: 0.25387 | Running loss: 0.46531\n",
      "Epoch: 8 | Iteration: 630 | Classification loss: 0.13224 | Regression loss: 0.20446 | Running loss: 0.46454\n",
      "Epoch: 8 | Iteration: 631 | Classification loss: 0.07679 | Regression loss: 0.18618 | Running loss: 0.46405\n",
      "Epoch: 8 | Iteration: 632 | Classification loss: 0.13734 | Regression loss: 0.22191 | Running loss: 0.46311\n",
      "Epoch: 8 | Iteration: 633 | Classification loss: 0.09427 | Regression loss: 0.31845 | Running loss: 0.46345\n",
      "Epoch: 8 | Iteration: 634 | Classification loss: 0.13449 | Regression loss: 0.17854 | Running loss: 0.46258\n",
      "Epoch: 8 | Iteration: 635 | Classification loss: 0.08502 | Regression loss: 0.45780 | Running loss: 0.46286\n",
      "Epoch: 8 | Iteration: 636 | Classification loss: 0.19599 | Regression loss: 0.28504 | Running loss: 0.46323\n",
      "Epoch: 8 | Iteration: 637 | Classification loss: 0.18870 | Regression loss: 0.21765 | Running loss: 0.46344\n",
      "Epoch: 8 | Iteration: 638 | Classification loss: 0.16522 | Regression loss: 0.41778 | Running loss: 0.46418\n",
      "Epoch: 8 | Iteration: 639 | Classification loss: 0.05326 | Regression loss: 0.19045 | Running loss: 0.46300\n",
      "Epoch: 8 | Iteration: 640 | Classification loss: 0.06142 | Regression loss: 0.25015 | Running loss: 0.46205\n",
      "Epoch: 8 | Iteration: 641 | Classification loss: 0.12557 | Regression loss: 0.27632 | Running loss: 0.46143\n",
      "Epoch: 8 | Iteration: 642 | Classification loss: 0.12841 | Regression loss: 0.23104 | Running loss: 0.46106\n",
      "Epoch: 8 | Iteration: 643 | Classification loss: 0.12280 | Regression loss: 0.17988 | Running loss: 0.46079\n",
      "Epoch: 8 | Iteration: 644 | Classification loss: 0.05388 | Regression loss: 0.33632 | Running loss: 0.46079\n",
      "Epoch: 8 | Iteration: 645 | Classification loss: 0.13078 | Regression loss: 0.30585 | Running loss: 0.46099\n",
      "Epoch: 8 | Iteration: 646 | Classification loss: 0.12692 | Regression loss: 0.21309 | Running loss: 0.46020\n",
      "Epoch: 8 | Iteration: 647 | Classification loss: 0.18119 | Regression loss: 0.29903 | Running loss: 0.45990\n",
      "Epoch: 8 | Iteration: 648 | Classification loss: 0.06969 | Regression loss: 0.20102 | Running loss: 0.45994\n",
      "Epoch: 8 | Iteration: 649 | Classification loss: 0.18165 | Regression loss: 0.29068 | Running loss: 0.45996\n",
      "Epoch: 8 | Iteration: 650 | Classification loss: 0.19050 | Regression loss: 0.30987 | Running loss: 0.45982\n",
      "Epoch: 8 | Iteration: 651 | Classification loss: 0.08384 | Regression loss: 0.17203 | Running loss: 0.45946\n",
      "Epoch: 8 | Iteration: 652 | Classification loss: 0.09245 | Regression loss: 0.37912 | Running loss: 0.45857\n",
      "Epoch: 8 | Iteration: 653 | Classification loss: 0.12524 | Regression loss: 0.27525 | Running loss: 0.45752\n",
      "Epoch: 8 | Iteration: 654 | Classification loss: 0.24780 | Regression loss: 0.50289 | Running loss: 0.45809\n",
      "Epoch: 8 | Iteration: 655 | Classification loss: 0.24672 | Regression loss: 0.57008 | Running loss: 0.45860\n",
      "Epoch: 8 | Iteration: 656 | Classification loss: 0.14909 | Regression loss: 0.29200 | Running loss: 0.45876\n",
      "Epoch: 8 | Iteration: 657 | Classification loss: 0.16647 | Regression loss: 0.66486 | Running loss: 0.45951\n",
      "Epoch: 8 | Iteration: 658 | Classification loss: 0.05419 | Regression loss: 0.11919 | Running loss: 0.45903\n",
      "Epoch: 8 | Iteration: 659 | Classification loss: 0.27316 | Regression loss: 0.38270 | Running loss: 0.45947\n",
      "Epoch: 8 | Iteration: 660 | Classification loss: 0.20386 | Regression loss: 0.38195 | Running loss: 0.45909\n",
      "Epoch: 8 | Iteration: 661 | Classification loss: 0.18244 | Regression loss: 0.46702 | Running loss: 0.45975\n",
      "Epoch: 8 | Iteration: 662 | Classification loss: 0.12349 | Regression loss: 0.34274 | Running loss: 0.45948\n",
      "Epoch: 8 | Iteration: 663 | Classification loss: 0.23444 | Regression loss: 0.50648 | Running loss: 0.45994\n",
      "Epoch: 8 | Iteration: 664 | Classification loss: 0.13982 | Regression loss: 0.36758 | Running loss: 0.46019\n",
      "Epoch: 8 | Iteration: 665 | Classification loss: 0.04886 | Regression loss: 0.22353 | Running loss: 0.46012\n",
      "Epoch: 8 | Iteration: 666 | Classification loss: 0.37454 | Regression loss: 0.37316 | Running loss: 0.46093\n",
      "Epoch: 8 | Iteration: 667 | Classification loss: 0.03440 | Regression loss: 0.12396 | Running loss: 0.46082\n",
      "Epoch: 8 | Iteration: 668 | Classification loss: 0.10003 | Regression loss: 0.21462 | Running loss: 0.46083\n",
      "Epoch: 8 | Iteration: 669 | Classification loss: 0.08121 | Regression loss: 0.30988 | Running loss: 0.46098\n",
      "Epoch: 8 | Iteration: 670 | Classification loss: 0.21681 | Regression loss: 0.28104 | Running loss: 0.46129\n",
      "Epoch: 8 | Iteration: 671 | Classification loss: 0.13642 | Regression loss: 0.21779 | Running loss: 0.46118\n",
      "Epoch: 8 | Iteration: 672 | Classification loss: 0.05465 | Regression loss: 0.19943 | Running loss: 0.46084\n",
      "Epoch: 8 | Iteration: 673 | Classification loss: 0.04509 | Regression loss: 0.09972 | Running loss: 0.46024\n",
      "Epoch: 8 | Iteration: 674 | Classification loss: 0.13040 | Regression loss: 0.33730 | Running loss: 0.45953\n",
      "Epoch: 8 | Iteration: 675 | Classification loss: 0.10130 | Regression loss: 0.32726 | Running loss: 0.46003\n",
      "Epoch: 8 | Iteration: 676 | Classification loss: 0.07360 | Regression loss: 0.21868 | Running loss: 0.45956\n",
      "Epoch: 8 | Iteration: 677 | Classification loss: 0.65627 | Regression loss: 0.31334 | Running loss: 0.45985\n",
      "Epoch: 8 | Iteration: 678 | Classification loss: 0.11201 | Regression loss: 0.30927 | Running loss: 0.45944\n",
      "Epoch: 8 | Iteration: 679 | Classification loss: 0.38031 | Regression loss: 0.35345 | Running loss: 0.45995\n",
      "Epoch: 8 | Iteration: 680 | Classification loss: 0.13021 | Regression loss: 0.23130 | Running loss: 0.46004\n",
      "Epoch: 8 | Iteration: 681 | Classification loss: 0.13328 | Regression loss: 0.29599 | Running loss: 0.45997\n",
      "Epoch: 8 | Iteration: 682 | Classification loss: 0.11978 | Regression loss: 0.20408 | Running loss: 0.45953\n",
      "Epoch: 8 | Iteration: 683 | Classification loss: 0.04458 | Regression loss: 0.16311 | Running loss: 0.45949\n",
      "Epoch: 8 | Iteration: 684 | Classification loss: 0.13531 | Regression loss: 0.21028 | Running loss: 0.45955\n",
      "Epoch: 8 | Iteration: 685 | Classification loss: 0.25780 | Regression loss: 0.42035 | Running loss: 0.46020\n",
      "Epoch: 8 | Iteration: 686 | Classification loss: 0.11539 | Regression loss: 0.30980 | Running loss: 0.45961\n",
      "Epoch: 8 | Iteration: 687 | Classification loss: 0.20064 | Regression loss: 0.38100 | Running loss: 0.45965\n",
      "Epoch: 8 | Iteration: 688 | Classification loss: 0.06093 | Regression loss: 0.24471 | Running loss: 0.45831\n",
      "Epoch: 8 | Iteration: 689 | Classification loss: 0.14724 | Regression loss: 0.15999 | Running loss: 0.45725\n",
      "Epoch: 8 | Iteration: 690 | Classification loss: 0.07831 | Regression loss: 0.22865 | Running loss: 0.45710\n",
      "Epoch: 8 | Iteration: 691 | Classification loss: 0.13914 | Regression loss: 0.31370 | Running loss: 0.45708\n",
      "Epoch: 8 | Iteration: 692 | Classification loss: 0.08772 | Regression loss: 0.19864 | Running loss: 0.45688\n",
      "Epoch: 8 | Iteration: 693 | Classification loss: 0.16952 | Regression loss: 0.20880 | Running loss: 0.45700\n",
      "Epoch: 8 | Iteration: 694 | Classification loss: 0.20683 | Regression loss: 0.15437 | Running loss: 0.45657\n",
      "Epoch: 8 | Iteration: 695 | Classification loss: 0.33479 | Regression loss: 0.30329 | Running loss: 0.45728\n",
      "Epoch: 8 | Iteration: 696 | Classification loss: 0.11062 | Regression loss: 0.30850 | Running loss: 0.45711\n",
      "Epoch: 8 | Iteration: 697 | Classification loss: 0.11048 | Regression loss: 0.19878 | Running loss: 0.45702\n",
      "Epoch: 8 | Iteration: 698 | Classification loss: 0.05324 | Regression loss: 0.23558 | Running loss: 0.45711\n",
      "Epoch: 8 | Iteration: 699 | Classification loss: 0.05284 | Regression loss: 0.21308 | Running loss: 0.45662\n",
      "Epoch: 8 | Iteration: 700 | Classification loss: 0.13668 | Regression loss: 0.13288 | Running loss: 0.45605\n",
      "Epoch: 8 | Iteration: 701 | Classification loss: 0.35808 | Regression loss: 0.32401 | Running loss: 0.45629\n",
      "Epoch: 8 | Iteration: 702 | Classification loss: 0.56801 | Regression loss: 0.40209 | Running loss: 0.45781\n",
      "Epoch: 8 | Iteration: 703 | Classification loss: 0.15355 | Regression loss: 0.53507 | Running loss: 0.45846\n",
      "Epoch: 8 | Iteration: 704 | Classification loss: 0.45406 | Regression loss: 0.25374 | Running loss: 0.45912\n",
      "Epoch: 8 | Iteration: 705 | Classification loss: 0.06031 | Regression loss: 0.28000 | Running loss: 0.45877\n",
      "Epoch: 8 | Iteration: 706 | Classification loss: 0.16376 | Regression loss: 0.35499 | Running loss: 0.45860\n",
      "Epoch: 8 | Iteration: 707 | Classification loss: 0.27708 | Regression loss: 0.37381 | Running loss: 0.45944\n",
      "Epoch: 8 | Iteration: 708 | Classification loss: 0.10669 | Regression loss: 0.34995 | Running loss: 0.45947\n",
      "Epoch: 8 | Iteration: 709 | Classification loss: 0.07285 | Regression loss: 0.27173 | Running loss: 0.45928\n",
      "Epoch: 8 | Iteration: 710 | Classification loss: 0.09348 | Regression loss: 0.29707 | Running loss: 0.45946\n",
      "Epoch: 8 | Iteration: 711 | Classification loss: 0.12750 | Regression loss: 0.14967 | Running loss: 0.45898\n",
      "Epoch: 8 | Iteration: 712 | Classification loss: 0.10339 | Regression loss: 0.32959 | Running loss: 0.45922\n",
      "Epoch: 8 | Iteration: 713 | Classification loss: 0.08111 | Regression loss: 0.20473 | Running loss: 0.45868\n",
      "Epoch: 8 | Iteration: 714 | Classification loss: 0.10329 | Regression loss: 0.27674 | Running loss: 0.45872\n",
      "Epoch: 8 | Iteration: 715 | Classification loss: 0.09911 | Regression loss: 0.20301 | Running loss: 0.45860\n",
      "Epoch: 8 | Iteration: 716 | Classification loss: 0.13577 | Regression loss: 0.17047 | Running loss: 0.45874\n",
      "Epoch: 8 | Iteration: 717 | Classification loss: 0.13049 | Regression loss: 0.20617 | Running loss: 0.45870\n",
      "Epoch: 8 | Iteration: 718 | Classification loss: 0.14866 | Regression loss: 0.35868 | Running loss: 0.45888\n",
      "Epoch: 8 | Iteration: 719 | Classification loss: 0.06629 | Regression loss: 0.14789 | Running loss: 0.45798\n",
      "Epoch: 8 | Iteration: 720 | Classification loss: 0.08906 | Regression loss: 0.12843 | Running loss: 0.45788\n",
      "Epoch: 8 | Iteration: 721 | Classification loss: 0.29343 | Regression loss: 0.43413 | Running loss: 0.45858\n",
      "Epoch: 8 | Iteration: 722 | Classification loss: 0.11001 | Regression loss: 0.26450 | Running loss: 0.45863\n",
      "Epoch: 8 | Iteration: 723 | Classification loss: 0.08229 | Regression loss: 0.25528 | Running loss: 0.45801\n",
      "Epoch: 8 | Iteration: 724 | Classification loss: 0.06583 | Regression loss: 0.10481 | Running loss: 0.45748\n",
      "Epoch: 8 | Iteration: 725 | Classification loss: 0.05570 | Regression loss: 0.25605 | Running loss: 0.45730\n",
      "Epoch: 8 | Iteration: 726 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 0.45666\n",
      "Epoch: 8 | Iteration: 727 | Classification loss: 0.20710 | Regression loss: 0.37098 | Running loss: 0.45712\n",
      "Epoch: 8 | Iteration: 728 | Classification loss: 0.18235 | Regression loss: 0.21893 | Running loss: 0.45721\n",
      "Epoch: 8 | Iteration: 729 | Classification loss: 0.04517 | Regression loss: 0.16102 | Running loss: 0.45728\n",
      "Epoch: 8 | Iteration: 730 | Classification loss: 0.20577 | Regression loss: 0.75755 | Running loss: 0.45800\n",
      "Epoch: 8 | Iteration: 731 | Classification loss: 0.24069 | Regression loss: 0.73082 | Running loss: 0.45861\n",
      "Epoch: 8 | Iteration: 732 | Classification loss: 0.06560 | Regression loss: 0.21967 | Running loss: 0.45817\n",
      "Epoch: 8 | Iteration: 733 | Classification loss: 0.30144 | Regression loss: 0.43892 | Running loss: 0.45853\n",
      "Epoch: 8 | Iteration: 734 | Classification loss: 0.13696 | Regression loss: 0.29300 | Running loss: 0.45818\n",
      "Epoch: 8 | Iteration: 735 | Classification loss: 0.10779 | Regression loss: 0.27290 | Running loss: 0.45781\n",
      "Epoch: 8 | Iteration: 736 | Classification loss: 0.34563 | Regression loss: 0.10835 | Running loss: 0.45748\n",
      "Epoch: 8 | Iteration: 737 | Classification loss: 0.14008 | Regression loss: 0.21514 | Running loss: 0.45665\n",
      "Epoch: 8 | Iteration: 738 | Classification loss: 0.14120 | Regression loss: 0.34502 | Running loss: 0.45692\n",
      "Epoch: 8 | Iteration: 739 | Classification loss: 0.11696 | Regression loss: 0.12704 | Running loss: 0.45689\n",
      "Epoch: 8 | Iteration: 740 | Classification loss: 0.08499 | Regression loss: 0.29972 | Running loss: 0.45672\n",
      "Epoch: 8 | Iteration: 741 | Classification loss: 0.13887 | Regression loss: 0.27841 | Running loss: 0.45641\n",
      "Epoch: 8 | Iteration: 742 | Classification loss: 0.18638 | Regression loss: 0.13577 | Running loss: 0.45625\n",
      "Epoch: 8 | Iteration: 743 | Classification loss: 0.28205 | Regression loss: 0.45504 | Running loss: 0.45650\n",
      "Epoch: 8 | Iteration: 744 | Classification loss: 0.15482 | Regression loss: 0.36583 | Running loss: 0.45649\n",
      "Epoch: 8 | Iteration: 745 | Classification loss: 0.11224 | Regression loss: 0.31907 | Running loss: 0.45648\n",
      "Epoch: 8 | Iteration: 746 | Classification loss: 0.04644 | Regression loss: 0.30322 | Running loss: 0.45681\n",
      "Epoch: 8 | Iteration: 747 | Classification loss: 0.05260 | Regression loss: 0.23504 | Running loss: 0.45614\n",
      "Epoch: 8 | Iteration: 748 | Classification loss: 0.13606 | Regression loss: 0.25282 | Running loss: 0.45606\n",
      "Epoch: 8 | Iteration: 749 | Classification loss: 0.41368 | Regression loss: 0.54189 | Running loss: 0.45629\n",
      "Epoch: 8 | Iteration: 750 | Classification loss: 0.18527 | Regression loss: 0.56607 | Running loss: 0.45717\n",
      "Epoch: 8 | Iteration: 751 | Classification loss: 0.08506 | Regression loss: 0.29432 | Running loss: 0.45730\n",
      "Epoch: 8 | Iteration: 752 | Classification loss: 0.12466 | Regression loss: 0.46319 | Running loss: 0.45790\n",
      "Epoch: 8 | Iteration: 753 | Classification loss: 0.22771 | Regression loss: 0.50351 | Running loss: 0.45876\n",
      "Epoch: 8 | Iteration: 754 | Classification loss: 0.29181 | Regression loss: 0.20442 | Running loss: 0.45878\n",
      "Epoch: 8 | Iteration: 755 | Classification loss: 0.31791 | Regression loss: 0.20560 | Running loss: 0.45922\n",
      "Epoch: 8 | Iteration: 756 | Classification loss: 0.05108 | Regression loss: 0.19028 | Running loss: 0.45883\n",
      "Epoch: 8 | Iteration: 757 | Classification loss: 0.16791 | Regression loss: 0.21108 | Running loss: 0.45916\n",
      "Epoch: 8 | Iteration: 758 | Classification loss: 0.07854 | Regression loss: 0.22545 | Running loss: 0.45844\n",
      "Epoch: 8 | Iteration: 759 | Classification loss: 0.20644 | Regression loss: 0.38005 | Running loss: 0.45932\n",
      "Epoch: 8 | Iteration: 760 | Classification loss: 0.42197 | Regression loss: 0.37981 | Running loss: 0.46039\n",
      "Epoch: 8 | Iteration: 761 | Classification loss: 0.08972 | Regression loss: 0.23696 | Running loss: 0.46054\n",
      "Epoch: 8 | Iteration: 762 | Classification loss: 0.43718 | Regression loss: 0.26586 | Running loss: 0.46081\n",
      "Epoch: 8 | Iteration: 763 | Classification loss: 0.07509 | Regression loss: 0.35884 | Running loss: 0.46044\n",
      "Epoch: 8 | Iteration: 764 | Classification loss: 0.28090 | Regression loss: 0.49707 | Running loss: 0.46082\n",
      "Epoch: 8 | Iteration: 765 | Classification loss: 0.09183 | Regression loss: 0.09619 | Running loss: 0.46039\n",
      "Epoch: 8 | Iteration: 766 | Classification loss: 0.11318 | Regression loss: 0.19709 | Running loss: 0.45994\n",
      "Epoch: 8 | Iteration: 767 | Classification loss: 0.22119 | Regression loss: 0.21397 | Running loss: 0.45988\n",
      "Epoch: 8 | Iteration: 768 | Classification loss: 0.10332 | Regression loss: 0.26847 | Running loss: 0.45964\n",
      "Epoch: 8 | Iteration: 769 | Classification loss: 0.30833 | Regression loss: 0.39321 | Running loss: 0.46041\n",
      "Epoch: 8 | Iteration: 770 | Classification loss: 0.06398 | Regression loss: 0.17812 | Running loss: 0.45977\n",
      "Epoch: 8 | Iteration: 771 | Classification loss: 0.18643 | Regression loss: 0.26838 | Running loss: 0.45943\n",
      "Epoch: 8 | Iteration: 772 | Classification loss: 0.28024 | Regression loss: 0.37683 | Running loss: 0.46027\n",
      "Epoch: 8 | Iteration: 773 | Classification loss: 0.09188 | Regression loss: 0.22085 | Running loss: 0.45956\n",
      "Epoch: 8 | Iteration: 774 | Classification loss: 0.06106 | Regression loss: 0.28163 | Running loss: 0.45927\n",
      "Epoch: 8 | Iteration: 775 | Classification loss: 0.21782 | Regression loss: 0.26432 | Running loss: 0.45898\n",
      "Epoch: 8 | Iteration: 776 | Classification loss: 0.22770 | Regression loss: 0.16259 | Running loss: 0.45859\n",
      "Epoch: 8 | Iteration: 777 | Classification loss: 0.26201 | Regression loss: 0.30154 | Running loss: 0.45898\n",
      "Epoch: 8 | Iteration: 778 | Classification loss: 0.08759 | Regression loss: 0.08121 | Running loss: 0.45783\n",
      "Epoch: 8 | Iteration: 779 | Classification loss: 0.24209 | Regression loss: 0.63158 | Running loss: 0.45827\n",
      "Epoch: 8 | Iteration: 780 | Classification loss: 0.20450 | Regression loss: 0.25439 | Running loss: 0.45890\n",
      "Epoch: 8 | Iteration: 781 | Classification loss: 0.07722 | Regression loss: 0.31481 | Running loss: 0.45909\n",
      "Epoch: 8 | Iteration: 782 | Classification loss: 0.17266 | Regression loss: 0.41364 | Running loss: 0.45929\n",
      "Epoch: 8 | Iteration: 783 | Classification loss: 0.04292 | Regression loss: 0.19696 | Running loss: 0.45904\n",
      "Epoch: 8 | Iteration: 784 | Classification loss: 0.25847 | Regression loss: 0.63290 | Running loss: 0.46038\n",
      "Epoch: 8 | Iteration: 785 | Classification loss: 0.35145 | Regression loss: 0.44231 | Running loss: 0.46090\n",
      "Epoch: 8 | Iteration: 786 | Classification loss: 0.07998 | Regression loss: 0.30148 | Running loss: 0.46006\n",
      "Epoch: 8 | Iteration: 787 | Classification loss: 0.07165 | Regression loss: 0.23942 | Running loss: 0.46000\n",
      "Epoch: 8 | Iteration: 788 | Classification loss: 0.05296 | Regression loss: 0.19374 | Running loss: 0.45934\n",
      "Epoch: 8 | Iteration: 789 | Classification loss: 0.07066 | Regression loss: 0.28281 | Running loss: 0.45950\n",
      "Epoch: 8 | Iteration: 790 | Classification loss: 0.14948 | Regression loss: 0.41637 | Running loss: 0.45989\n",
      "Epoch: 8 | Iteration: 791 | Classification loss: 0.08592 | Regression loss: 0.33017 | Running loss: 0.46009\n",
      "Epoch: 8 | Iteration: 792 | Classification loss: 0.17689 | Regression loss: 0.40362 | Running loss: 0.46028\n",
      "Epoch: 8 | Iteration: 793 | Classification loss: 0.09076 | Regression loss: 0.19236 | Running loss: 0.45988\n",
      "Epoch: 8 | Iteration: 794 | Classification loss: 0.00029 | Regression loss: 0.00000 | Running loss: 0.45894\n",
      "Epoch: 8 | Iteration: 795 | Classification loss: 0.06678 | Regression loss: 0.12547 | Running loss: 0.45848\n",
      "Epoch: 8 | Iteration: 796 | Classification loss: 0.17720 | Regression loss: 0.19622 | Running loss: 0.45787\n",
      "Epoch: 8 | Iteration: 797 | Classification loss: 0.14451 | Regression loss: 0.46503 | Running loss: 0.45665\n",
      "Epoch: 8 | Iteration: 798 | Classification loss: 0.13632 | Regression loss: 0.20762 | Running loss: 0.45654\n",
      "Epoch: 8 | Iteration: 799 | Classification loss: 0.09641 | Regression loss: 0.25834 | Running loss: 0.45652\n",
      "Epoch: 8 | Iteration: 800 | Classification loss: 0.24633 | Regression loss: 0.36891 | Running loss: 0.45661\n",
      "Epoch: 8 | Iteration: 801 | Classification loss: 0.11626 | Regression loss: 0.30012 | Running loss: 0.45512\n",
      "Epoch: 8 | Iteration: 802 | Classification loss: 0.10921 | Regression loss: 0.34244 | Running loss: 0.45527\n",
      "Epoch: 8 | Iteration: 803 | Classification loss: 0.08478 | Regression loss: 0.27792 | Running loss: 0.45473\n",
      "Epoch: 8 | Iteration: 804 | Classification loss: 1.13977 | Regression loss: 0.18197 | Running loss: 0.45626\n",
      "Epoch: 8 | Iteration: 805 | Classification loss: 0.06530 | Regression loss: 0.32933 | Running loss: 0.45635\n",
      "Epoch: 8 | Iteration: 806 | Classification loss: 0.16885 | Regression loss: 0.21521 | Running loss: 0.45670\n",
      "Epoch: 8 | Iteration: 807 | Classification loss: 0.13887 | Regression loss: 0.16082 | Running loss: 0.45634\n",
      "Epoch: 8 | Iteration: 808 | Classification loss: 0.31851 | Regression loss: 0.44910 | Running loss: 0.45723\n",
      "Epoch: 8 | Iteration: 809 | Classification loss: 0.13850 | Regression loss: 0.20360 | Running loss: 0.45745\n",
      "Epoch: 8 | Iteration: 810 | Classification loss: 0.07975 | Regression loss: 0.30490 | Running loss: 0.45786\n",
      "Epoch: 8 | Iteration: 811 | Classification loss: 0.10147 | Regression loss: 0.21401 | Running loss: 0.45783\n",
      "Epoch: 8 | Iteration: 812 | Classification loss: 0.21260 | Regression loss: 0.33009 | Running loss: 0.45775\n",
      "Epoch: 8 | Iteration: 813 | Classification loss: 0.24235 | Regression loss: 0.39145 | Running loss: 0.45853\n",
      "Epoch: 8 | Iteration: 814 | Classification loss: 0.03705 | Regression loss: 0.17250 | Running loss: 0.45808\n",
      "Epoch: 8 | Iteration: 815 | Classification loss: 0.08964 | Regression loss: 0.22889 | Running loss: 0.45816\n",
      "Epoch: 8 | Iteration: 816 | Classification loss: 0.04393 | Regression loss: 0.16247 | Running loss: 0.45778\n",
      "Epoch: 8 | Iteration: 817 | Classification loss: 0.08280 | Regression loss: 0.23651 | Running loss: 0.45640\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.554\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 9 | Iteration: 0 | Classification loss: 0.06422 | Regression loss: 0.18480 | Running loss: 0.45649\n",
      "Epoch: 9 | Iteration: 1 | Classification loss: 0.11544 | Regression loss: 0.19759 | Running loss: 0.45564\n",
      "Epoch: 9 | Iteration: 2 | Classification loss: 0.12676 | Regression loss: 0.18588 | Running loss: 0.45546\n",
      "Epoch: 9 | Iteration: 3 | Classification loss: 0.14686 | Regression loss: 0.30066 | Running loss: 0.45585\n",
      "Epoch: 9 | Iteration: 4 | Classification loss: 0.14262 | Regression loss: 0.19581 | Running loss: 0.45570\n",
      "Epoch: 9 | Iteration: 5 | Classification loss: 0.05896 | Regression loss: 0.19675 | Running loss: 0.45564\n",
      "Epoch: 9 | Iteration: 6 | Classification loss: 0.11211 | Regression loss: 0.33651 | Running loss: 0.45617\n",
      "Epoch: 9 | Iteration: 7 | Classification loss: 0.06900 | Regression loss: 0.24991 | Running loss: 0.45624\n",
      "Epoch: 9 | Iteration: 8 | Classification loss: 0.08059 | Regression loss: 0.24453 | Running loss: 0.45596\n",
      "Epoch: 9 | Iteration: 9 | Classification loss: 0.16600 | Regression loss: 0.30019 | Running loss: 0.45654\n",
      "Epoch: 9 | Iteration: 10 | Classification loss: 0.11658 | Regression loss: 0.37064 | Running loss: 0.45701\n",
      "Epoch: 9 | Iteration: 11 | Classification loss: 0.06352 | Regression loss: 0.12756 | Running loss: 0.45582\n",
      "Epoch: 9 | Iteration: 12 | Classification loss: 0.21773 | Regression loss: 0.26193 | Running loss: 0.45601\n",
      "Epoch: 9 | Iteration: 13 | Classification loss: 0.40960 | Regression loss: 0.29396 | Running loss: 0.45665\n",
      "Epoch: 9 | Iteration: 14 | Classification loss: 0.09451 | Regression loss: 0.14509 | Running loss: 0.45650\n",
      "Epoch: 9 | Iteration: 15 | Classification loss: 0.09779 | Regression loss: 0.19999 | Running loss: 0.45617\n",
      "Epoch: 9 | Iteration: 16 | Classification loss: 0.13480 | Regression loss: 0.38206 | Running loss: 0.45536\n",
      "Epoch: 9 | Iteration: 17 | Classification loss: 0.10819 | Regression loss: 0.41569 | Running loss: 0.45569\n",
      "Epoch: 9 | Iteration: 18 | Classification loss: 0.43122 | Regression loss: 0.44266 | Running loss: 0.45608\n",
      "Epoch: 9 | Iteration: 19 | Classification loss: 0.22035 | Regression loss: 0.34968 | Running loss: 0.45600\n",
      "Epoch: 9 | Iteration: 20 | Classification loss: 0.12826 | Regression loss: 0.22652 | Running loss: 0.45512\n",
      "Epoch: 9 | Iteration: 21 | Classification loss: 0.10430 | Regression loss: 0.30134 | Running loss: 0.45491\n",
      "Epoch: 9 | Iteration: 22 | Classification loss: 0.07091 | Regression loss: 0.23776 | Running loss: 0.45454\n",
      "Epoch: 9 | Iteration: 23 | Classification loss: 0.12457 | Regression loss: 0.23950 | Running loss: 0.45413\n",
      "Epoch: 9 | Iteration: 24 | Classification loss: 0.07610 | Regression loss: 0.27214 | Running loss: 0.45419\n",
      "Epoch: 9 | Iteration: 25 | Classification loss: 0.08166 | Regression loss: 0.22757 | Running loss: 0.45396\n",
      "Epoch: 9 | Iteration: 26 | Classification loss: 0.22074 | Regression loss: 0.34143 | Running loss: 0.45438\n",
      "Epoch: 9 | Iteration: 27 | Classification loss: 0.21956 | Regression loss: 0.57864 | Running loss: 0.45509\n",
      "Epoch: 9 | Iteration: 28 | Classification loss: 0.05656 | Regression loss: 0.24758 | Running loss: 0.45469\n",
      "Epoch: 9 | Iteration: 29 | Classification loss: 0.19262 | Regression loss: 0.34172 | Running loss: 0.45329\n",
      "Epoch: 9 | Iteration: 30 | Classification loss: 0.28498 | Regression loss: 0.29757 | Running loss: 0.45401\n",
      "Epoch: 9 | Iteration: 31 | Classification loss: 0.03909 | Regression loss: 0.31266 | Running loss: 0.45317\n",
      "Epoch: 9 | Iteration: 32 | Classification loss: 0.28173 | Regression loss: 0.44303 | Running loss: 0.45373\n",
      "Epoch: 9 | Iteration: 33 | Classification loss: 0.13076 | Regression loss: 0.25931 | Running loss: 0.45361\n",
      "Epoch: 9 | Iteration: 34 | Classification loss: 0.14412 | Regression loss: 0.28708 | Running loss: 0.45380\n",
      "Epoch: 9 | Iteration: 35 | Classification loss: 0.14581 | Regression loss: 0.35078 | Running loss: 0.45447\n",
      "Epoch: 9 | Iteration: 36 | Classification loss: 0.20664 | Regression loss: 0.24684 | Running loss: 0.45478\n",
      "Epoch: 9 | Iteration: 37 | Classification loss: 0.06239 | Regression loss: 0.18597 | Running loss: 0.45412\n",
      "Epoch: 9 | Iteration: 38 | Classification loss: 0.04528 | Regression loss: 0.10753 | Running loss: 0.45304\n",
      "Epoch: 9 | Iteration: 39 | Classification loss: 0.04896 | Regression loss: 0.19059 | Running loss: 0.45317\n",
      "Epoch: 9 | Iteration: 40 | Classification loss: 0.41340 | Regression loss: 0.30378 | Running loss: 0.45389\n",
      "Epoch: 9 | Iteration: 41 | Classification loss: 0.07383 | Regression loss: 0.28907 | Running loss: 0.45386\n",
      "Epoch: 9 | Iteration: 42 | Classification loss: 0.05628 | Regression loss: 0.32745 | Running loss: 0.45260\n",
      "Epoch: 9 | Iteration: 43 | Classification loss: 0.04989 | Regression loss: 0.17120 | Running loss: 0.45175\n",
      "Epoch: 9 | Iteration: 44 | Classification loss: 0.09249 | Regression loss: 0.20548 | Running loss: 0.45171\n",
      "Epoch: 9 | Iteration: 45 | Classification loss: 0.12674 | Regression loss: 0.20754 | Running loss: 0.45181\n",
      "Epoch: 9 | Iteration: 46 | Classification loss: 0.10078 | Regression loss: 0.23912 | Running loss: 0.45108\n",
      "Epoch: 9 | Iteration: 47 | Classification loss: 0.11317 | Regression loss: 0.29813 | Running loss: 0.45068\n",
      "Epoch: 9 | Iteration: 48 | Classification loss: 0.04856 | Regression loss: 0.15722 | Running loss: 0.45001\n",
      "Epoch: 9 | Iteration: 49 | Classification loss: 0.09277 | Regression loss: 0.30484 | Running loss: 0.44928\n",
      "Epoch: 9 | Iteration: 50 | Classification loss: 0.08508 | Regression loss: 0.26967 | Running loss: 0.44894\n",
      "Epoch: 9 | Iteration: 51 | Classification loss: 0.09204 | Regression loss: 0.31057 | Running loss: 0.44807\n",
      "Epoch: 9 | Iteration: 52 | Classification loss: 0.05881 | Regression loss: 0.24186 | Running loss: 0.44755\n",
      "Epoch: 9 | Iteration: 53 | Classification loss: 0.04668 | Regression loss: 0.24725 | Running loss: 0.44679\n",
      "Epoch: 9 | Iteration: 54 | Classification loss: 0.30277 | Regression loss: 0.66020 | Running loss: 0.44715\n",
      "Epoch: 9 | Iteration: 55 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 0.44633\n",
      "Epoch: 9 | Iteration: 56 | Classification loss: 0.06925 | Regression loss: 0.22151 | Running loss: 0.44570\n",
      "Epoch: 9 | Iteration: 57 | Classification loss: 0.08903 | Regression loss: 0.20131 | Running loss: 0.44567\n",
      "Epoch: 9 | Iteration: 58 | Classification loss: 0.25940 | Regression loss: 0.44042 | Running loss: 0.44484\n",
      "Epoch: 9 | Iteration: 59 | Classification loss: 0.11606 | Regression loss: 0.42902 | Running loss: 0.44564\n",
      "Epoch: 9 | Iteration: 60 | Classification loss: 0.03035 | Regression loss: 0.10124 | Running loss: 0.44543\n",
      "Epoch: 9 | Iteration: 61 | Classification loss: 0.07668 | Regression loss: 0.13754 | Running loss: 0.44539\n",
      "Epoch: 9 | Iteration: 62 | Classification loss: 0.13993 | Regression loss: 0.22243 | Running loss: 0.44486\n",
      "Epoch: 9 | Iteration: 63 | Classification loss: 0.05777 | Regression loss: 0.17677 | Running loss: 0.44406\n",
      "Epoch: 9 | Iteration: 64 | Classification loss: 0.08752 | Regression loss: 0.13969 | Running loss: 0.44392\n",
      "Epoch: 9 | Iteration: 65 | Classification loss: 0.20900 | Regression loss: 0.49685 | Running loss: 0.44480\n",
      "Epoch: 9 | Iteration: 66 | Classification loss: 0.07047 | Regression loss: 0.22229 | Running loss: 0.44408\n",
      "Epoch: 9 | Iteration: 67 | Classification loss: 0.05429 | Regression loss: 0.45932 | Running loss: 0.44420\n",
      "Epoch: 9 | Iteration: 68 | Classification loss: 0.09046 | Regression loss: 0.34145 | Running loss: 0.44457\n",
      "Epoch: 9 | Iteration: 69 | Classification loss: 0.10141 | Regression loss: 0.24266 | Running loss: 0.44443\n",
      "Epoch: 9 | Iteration: 70 | Classification loss: 0.06842 | Regression loss: 0.14900 | Running loss: 0.44437\n",
      "Epoch: 9 | Iteration: 71 | Classification loss: 0.04670 | Regression loss: 0.27685 | Running loss: 0.44348\n",
      "Epoch: 9 | Iteration: 72 | Classification loss: 0.54198 | Regression loss: 0.32007 | Running loss: 0.44437\n",
      "Epoch: 9 | Iteration: 73 | Classification loss: 0.08035 | Regression loss: 0.31027 | Running loss: 0.44453\n",
      "Epoch: 9 | Iteration: 74 | Classification loss: 0.35733 | Regression loss: 0.34423 | Running loss: 0.44502\n",
      "Epoch: 9 | Iteration: 75 | Classification loss: 0.06233 | Regression loss: 0.33234 | Running loss: 0.44465\n",
      "Epoch: 9 | Iteration: 76 | Classification loss: 0.03390 | Regression loss: 0.11319 | Running loss: 0.44396\n",
      "Epoch: 9 | Iteration: 77 | Classification loss: 0.19781 | Regression loss: 0.23897 | Running loss: 0.44393\n",
      "Epoch: 9 | Iteration: 78 | Classification loss: 0.16711 | Regression loss: 0.27021 | Running loss: 0.44382\n",
      "Epoch: 9 | Iteration: 79 | Classification loss: 0.25388 | Regression loss: 0.46353 | Running loss: 0.44441\n",
      "Epoch: 9 | Iteration: 80 | Classification loss: 0.13883 | Regression loss: 0.18586 | Running loss: 0.44286\n",
      "Epoch: 9 | Iteration: 81 | Classification loss: 0.09835 | Regression loss: 0.31546 | Running loss: 0.44320\n",
      "Epoch: 9 | Iteration: 82 | Classification loss: 0.17217 | Regression loss: 0.17767 | Running loss: 0.44317\n",
      "Epoch: 9 | Iteration: 83 | Classification loss: 0.10052 | Regression loss: 0.25750 | Running loss: 0.44268\n",
      "Epoch: 9 | Iteration: 84 | Classification loss: 0.89495 | Regression loss: 0.59959 | Running loss: 0.44484\n",
      "Epoch: 9 | Iteration: 85 | Classification loss: 0.22067 | Regression loss: 0.24197 | Running loss: 0.44485\n",
      "Epoch: 9 | Iteration: 86 | Classification loss: 0.24803 | Regression loss: 0.20549 | Running loss: 0.44493\n",
      "Epoch: 9 | Iteration: 87 | Classification loss: 0.21444 | Regression loss: 0.09976 | Running loss: 0.44507\n",
      "Epoch: 9 | Iteration: 88 | Classification loss: 0.05522 | Regression loss: 0.15386 | Running loss: 0.44485\n",
      "Epoch: 9 | Iteration: 89 | Classification loss: 0.15062 | Regression loss: 0.48812 | Running loss: 0.44545\n",
      "Epoch: 9 | Iteration: 90 | Classification loss: 0.13141 | Regression loss: 0.36635 | Running loss: 0.44593\n",
      "Epoch: 9 | Iteration: 91 | Classification loss: 0.19470 | Regression loss: 0.27313 | Running loss: 0.44570\n",
      "Epoch: 9 | Iteration: 92 | Classification loss: 0.05175 | Regression loss: 0.18951 | Running loss: 0.44537\n",
      "Epoch: 9 | Iteration: 93 | Classification loss: 0.08176 | Regression loss: 0.26673 | Running loss: 0.44527\n",
      "Epoch: 9 | Iteration: 94 | Classification loss: 0.11106 | Regression loss: 0.17394 | Running loss: 0.44455\n",
      "Epoch: 9 | Iteration: 95 | Classification loss: 0.07838 | Regression loss: 0.27726 | Running loss: 0.44436\n",
      "Epoch: 9 | Iteration: 96 | Classification loss: 0.23857 | Regression loss: 0.46749 | Running loss: 0.44512\n",
      "Epoch: 9 | Iteration: 97 | Classification loss: 0.06375 | Regression loss: 0.27142 | Running loss: 0.44526\n",
      "Epoch: 9 | Iteration: 98 | Classification loss: 0.04169 | Regression loss: 0.18370 | Running loss: 0.44460\n",
      "Epoch: 9 | Iteration: 99 | Classification loss: 0.33877 | Regression loss: 0.12863 | Running loss: 0.44424\n",
      "Epoch: 9 | Iteration: 100 | Classification loss: 0.05265 | Regression loss: 0.17370 | Running loss: 0.44433\n",
      "Epoch: 9 | Iteration: 101 | Classification loss: 0.12032 | Regression loss: 0.37232 | Running loss: 0.44362\n",
      "Epoch: 9 | Iteration: 102 | Classification loss: 0.22501 | Regression loss: 0.32996 | Running loss: 0.44405\n",
      "Epoch: 9 | Iteration: 103 | Classification loss: 0.12341 | Regression loss: 0.28295 | Running loss: 0.44435\n",
      "Epoch: 9 | Iteration: 104 | Classification loss: 0.10432 | Regression loss: 0.39674 | Running loss: 0.44446\n",
      "Epoch: 9 | Iteration: 105 | Classification loss: 0.07350 | Regression loss: 0.22756 | Running loss: 0.44427\n",
      "Epoch: 9 | Iteration: 106 | Classification loss: 0.02192 | Regression loss: 0.13446 | Running loss: 0.44389\n",
      "Epoch: 9 | Iteration: 107 | Classification loss: 0.15496 | Regression loss: 0.15708 | Running loss: 0.44368\n",
      "Epoch: 9 | Iteration: 108 | Classification loss: 0.29885 | Regression loss: 0.52458 | Running loss: 0.44461\n",
      "Epoch: 9 | Iteration: 109 | Classification loss: 0.15391 | Regression loss: 0.23929 | Running loss: 0.44404\n",
      "Epoch: 9 | Iteration: 110 | Classification loss: 0.08325 | Regression loss: 0.23784 | Running loss: 0.44322\n",
      "Epoch: 9 | Iteration: 111 | Classification loss: 0.05357 | Regression loss: 0.15823 | Running loss: 0.44321\n",
      "Epoch: 9 | Iteration: 112 | Classification loss: 0.04638 | Regression loss: 0.14910 | Running loss: 0.44281\n",
      "Epoch: 9 | Iteration: 113 | Classification loss: 0.29955 | Regression loss: 0.19743 | Running loss: 0.44270\n",
      "Epoch: 9 | Iteration: 114 | Classification loss: 0.05346 | Regression loss: 0.38494 | Running loss: 0.44276\n",
      "Epoch: 9 | Iteration: 115 | Classification loss: 0.09104 | Regression loss: 0.30175 | Running loss: 0.44289\n",
      "Epoch: 9 | Iteration: 116 | Classification loss: 0.17030 | Regression loss: 0.43046 | Running loss: 0.44315\n",
      "Epoch: 9 | Iteration: 117 | Classification loss: 0.05705 | Regression loss: 0.26938 | Running loss: 0.44253\n",
      "Epoch: 9 | Iteration: 118 | Classification loss: 0.04135 | Regression loss: 0.22071 | Running loss: 0.44214\n",
      "Epoch: 9 | Iteration: 119 | Classification loss: 0.06573 | Regression loss: 0.42803 | Running loss: 0.44271\n",
      "Epoch: 9 | Iteration: 120 | Classification loss: 0.74232 | Regression loss: 0.15345 | Running loss: 0.44363\n",
      "Epoch: 9 | Iteration: 121 | Classification loss: 0.10354 | Regression loss: 0.07650 | Running loss: 0.44319\n",
      "Epoch: 9 | Iteration: 122 | Classification loss: 0.08918 | Regression loss: 0.33174 | Running loss: 0.44296\n",
      "Epoch: 9 | Iteration: 123 | Classification loss: 0.13678 | Regression loss: 0.32303 | Running loss: 0.44282\n",
      "Epoch: 9 | Iteration: 124 | Classification loss: 0.18747 | Regression loss: 0.33450 | Running loss: 0.44249\n",
      "Epoch: 9 | Iteration: 125 | Classification loss: 0.07529 | Regression loss: 0.16923 | Running loss: 0.44224\n",
      "Epoch: 9 | Iteration: 126 | Classification loss: 0.20845 | Regression loss: 0.39820 | Running loss: 0.44181\n",
      "Epoch: 9 | Iteration: 127 | Classification loss: 0.15057 | Regression loss: 0.25436 | Running loss: 0.44182\n",
      "Epoch: 9 | Iteration: 128 | Classification loss: 0.07810 | Regression loss: 0.33813 | Running loss: 0.44209\n",
      "Epoch: 9 | Iteration: 129 | Classification loss: 0.39134 | Regression loss: 0.28704 | Running loss: 0.44310\n",
      "Epoch: 9 | Iteration: 130 | Classification loss: 0.05058 | Regression loss: 0.19158 | Running loss: 0.44284\n",
      "Epoch: 9 | Iteration: 131 | Classification loss: 0.06788 | Regression loss: 0.16446 | Running loss: 0.44241\n",
      "Epoch: 9 | Iteration: 132 | Classification loss: 0.10119 | Regression loss: 0.35224 | Running loss: 0.44263\n",
      "Epoch: 9 | Iteration: 133 | Classification loss: 0.03793 | Regression loss: 0.09889 | Running loss: 0.44238\n",
      "Epoch: 9 | Iteration: 134 | Classification loss: 0.18918 | Regression loss: 0.29169 | Running loss: 0.44276\n",
      "Epoch: 9 | Iteration: 135 | Classification loss: 0.22757 | Regression loss: 0.43890 | Running loss: 0.44292\n",
      "Epoch: 9 | Iteration: 136 | Classification loss: 0.08460 | Regression loss: 0.22009 | Running loss: 0.44240\n",
      "Epoch: 9 | Iteration: 137 | Classification loss: 0.12666 | Regression loss: 0.34017 | Running loss: 0.44265\n",
      "Epoch: 9 | Iteration: 138 | Classification loss: 0.15516 | Regression loss: 0.31076 | Running loss: 0.44205\n",
      "Epoch: 9 | Iteration: 139 | Classification loss: 0.13316 | Regression loss: 0.15780 | Running loss: 0.44179\n",
      "Epoch: 9 | Iteration: 140 | Classification loss: 0.03374 | Regression loss: 0.12836 | Running loss: 0.44142\n",
      "Epoch: 9 | Iteration: 141 | Classification loss: 0.13497 | Regression loss: 0.12229 | Running loss: 0.44099\n",
      "Epoch: 9 | Iteration: 142 | Classification loss: 0.21930 | Regression loss: 0.22136 | Running loss: 0.44052\n",
      "Epoch: 9 | Iteration: 143 | Classification loss: 0.04332 | Regression loss: 0.18673 | Running loss: 0.44005\n",
      "Epoch: 9 | Iteration: 144 | Classification loss: 0.44982 | Regression loss: 0.25082 | Running loss: 0.43985\n",
      "Epoch: 9 | Iteration: 145 | Classification loss: 0.27593 | Regression loss: 0.46923 | Running loss: 0.43985\n",
      "Epoch: 9 | Iteration: 146 | Classification loss: 0.08193 | Regression loss: 0.17240 | Running loss: 0.43984\n",
      "Epoch: 9 | Iteration: 147 | Classification loss: 0.20899 | Regression loss: 0.30010 | Running loss: 0.44022\n",
      "Epoch: 9 | Iteration: 148 | Classification loss: 0.14562 | Regression loss: 0.37630 | Running loss: 0.44041\n",
      "Epoch: 9 | Iteration: 149 | Classification loss: 0.25755 | Regression loss: 0.29741 | Running loss: 0.44108\n",
      "Epoch: 9 | Iteration: 150 | Classification loss: 0.08553 | Regression loss: 0.27549 | Running loss: 0.44125\n",
      "Epoch: 9 | Iteration: 151 | Classification loss: 0.13309 | Regression loss: 0.37881 | Running loss: 0.44168\n",
      "Epoch: 9 | Iteration: 152 | Classification loss: 0.18719 | Regression loss: 0.17360 | Running loss: 0.44168\n",
      "Epoch: 9 | Iteration: 153 | Classification loss: 0.09770 | Regression loss: 0.20928 | Running loss: 0.44095\n",
      "Epoch: 9 | Iteration: 154 | Classification loss: 0.08146 | Regression loss: 0.22253 | Running loss: 0.44049\n",
      "Epoch: 9 | Iteration: 155 | Classification loss: 0.08381 | Regression loss: 0.33374 | Running loss: 0.44096\n",
      "Epoch: 9 | Iteration: 156 | Classification loss: 0.23162 | Regression loss: 0.39020 | Running loss: 0.44162\n",
      "Epoch: 9 | Iteration: 157 | Classification loss: 0.20686 | Regression loss: 0.26167 | Running loss: 0.44141\n",
      "Epoch: 9 | Iteration: 158 | Classification loss: 0.08319 | Regression loss: 0.24194 | Running loss: 0.44105\n",
      "Epoch: 9 | Iteration: 159 | Classification loss: 0.14974 | Regression loss: 0.17888 | Running loss: 0.44050\n",
      "Epoch: 9 | Iteration: 160 | Classification loss: 0.06420 | Regression loss: 0.25437 | Running loss: 0.44023\n",
      "Epoch: 9 | Iteration: 161 | Classification loss: 0.56496 | Regression loss: 0.20918 | Running loss: 0.44083\n",
      "Epoch: 9 | Iteration: 162 | Classification loss: 0.31429 | Regression loss: 0.24826 | Running loss: 0.44088\n",
      "Epoch: 9 | Iteration: 163 | Classification loss: 0.30754 | Regression loss: 0.57772 | Running loss: 0.44052\n",
      "Epoch: 9 | Iteration: 164 | Classification loss: 0.36379 | Regression loss: 0.26787 | Running loss: 0.44009\n",
      "Epoch: 9 | Iteration: 165 | Classification loss: 0.42004 | Regression loss: 0.57936 | Running loss: 0.44102\n",
      "Epoch: 9 | Iteration: 166 | Classification loss: 0.08801 | Regression loss: 0.36282 | Running loss: 0.44040\n",
      "Epoch: 9 | Iteration: 167 | Classification loss: 0.12562 | Regression loss: 0.29912 | Running loss: 0.44032\n",
      "Epoch: 9 | Iteration: 168 | Classification loss: 0.19936 | Regression loss: 0.39275 | Running loss: 0.44032\n",
      "Epoch: 9 | Iteration: 169 | Classification loss: 0.10302 | Regression loss: 0.19607 | Running loss: 0.43969\n",
      "Epoch: 9 | Iteration: 170 | Classification loss: 0.11898 | Regression loss: 0.30310 | Running loss: 0.43984\n",
      "Epoch: 9 | Iteration: 171 | Classification loss: 0.12257 | Regression loss: 0.25291 | Running loss: 0.43952\n",
      "Epoch: 9 | Iteration: 172 | Classification loss: 0.06137 | Regression loss: 0.25511 | Running loss: 0.43948\n",
      "Epoch: 9 | Iteration: 173 | Classification loss: 0.04224 | Regression loss: 0.15252 | Running loss: 0.43853\n",
      "Epoch: 9 | Iteration: 174 | Classification loss: 0.26794 | Regression loss: 0.15492 | Running loss: 0.43838\n",
      "Epoch: 9 | Iteration: 175 | Classification loss: 0.18583 | Regression loss: 0.36170 | Running loss: 0.43885\n",
      "Epoch: 9 | Iteration: 176 | Classification loss: 0.42643 | Regression loss: 0.16836 | Running loss: 0.43929\n",
      "Epoch: 9 | Iteration: 177 | Classification loss: 0.19015 | Regression loss: 0.22167 | Running loss: 0.43895\n",
      "Epoch: 9 | Iteration: 178 | Classification loss: 0.12075 | Regression loss: 0.16867 | Running loss: 0.43828\n",
      "Epoch: 9 | Iteration: 179 | Classification loss: 0.26760 | Regression loss: 0.40463 | Running loss: 0.43880\n",
      "Epoch: 9 | Iteration: 180 | Classification loss: 0.09748 | Regression loss: 0.35738 | Running loss: 0.43871\n",
      "Epoch: 9 | Iteration: 181 | Classification loss: 0.08797 | Regression loss: 0.30292 | Running loss: 0.43865\n",
      "Epoch: 9 | Iteration: 182 | Classification loss: 0.03385 | Regression loss: 0.15422 | Running loss: 0.43752\n",
      "Epoch: 9 | Iteration: 183 | Classification loss: 0.10120 | Regression loss: 0.33632 | Running loss: 0.43743\n",
      "Epoch: 9 | Iteration: 184 | Classification loss: 0.02650 | Regression loss: 0.10633 | Running loss: 0.43716\n",
      "Epoch: 9 | Iteration: 185 | Classification loss: 0.05260 | Regression loss: 0.24770 | Running loss: 0.43670\n",
      "Epoch: 9 | Iteration: 186 | Classification loss: 0.19185 | Regression loss: 0.31205 | Running loss: 0.43646\n",
      "Epoch: 9 | Iteration: 187 | Classification loss: 0.17665 | Regression loss: 0.20414 | Running loss: 0.43655\n",
      "Epoch: 9 | Iteration: 188 | Classification loss: 0.11283 | Regression loss: 0.18425 | Running loss: 0.43601\n",
      "Epoch: 9 | Iteration: 189 | Classification loss: 0.05159 | Regression loss: 0.18041 | Running loss: 0.43620\n",
      "Epoch: 9 | Iteration: 190 | Classification loss: 0.22146 | Regression loss: 0.49377 | Running loss: 0.43690\n",
      "Epoch: 9 | Iteration: 191 | Classification loss: 0.09782 | Regression loss: 0.26949 | Running loss: 0.43717\n",
      "Epoch: 9 | Iteration: 192 | Classification loss: 0.16917 | Regression loss: 0.29250 | Running loss: 0.43772\n",
      "Epoch: 9 | Iteration: 193 | Classification loss: 0.10289 | Regression loss: 0.27103 | Running loss: 0.43779\n",
      "Epoch: 9 | Iteration: 194 | Classification loss: 0.16013 | Regression loss: 0.29094 | Running loss: 0.43841\n",
      "Epoch: 9 | Iteration: 195 | Classification loss: 0.18356 | Regression loss: 0.33013 | Running loss: 0.43879\n",
      "Epoch: 9 | Iteration: 196 | Classification loss: 0.15177 | Regression loss: 0.15398 | Running loss: 0.43888\n",
      "Epoch: 9 | Iteration: 197 | Classification loss: 0.17569 | Regression loss: 0.69196 | Running loss: 0.43997\n",
      "Epoch: 9 | Iteration: 198 | Classification loss: 0.08105 | Regression loss: 0.20644 | Running loss: 0.43957\n",
      "Epoch: 9 | Iteration: 199 | Classification loss: 0.08150 | Regression loss: 0.15077 | Running loss: 0.43902\n",
      "Epoch: 9 | Iteration: 200 | Classification loss: 0.14047 | Regression loss: 0.36000 | Running loss: 0.43932\n",
      "Epoch: 9 | Iteration: 201 | Classification loss: 0.08315 | Regression loss: 0.16547 | Running loss: 0.43902\n",
      "Epoch: 9 | Iteration: 202 | Classification loss: 0.08886 | Regression loss: 0.18904 | Running loss: 0.43885\n",
      "Epoch: 9 | Iteration: 203 | Classification loss: 0.07956 | Regression loss: 0.30566 | Running loss: 0.43864\n",
      "Epoch: 9 | Iteration: 204 | Classification loss: 0.06150 | Regression loss: 0.27792 | Running loss: 0.43862\n",
      "Epoch: 9 | Iteration: 205 | Classification loss: 0.03757 | Regression loss: 0.19784 | Running loss: 0.43369\n",
      "Epoch: 9 | Iteration: 206 | Classification loss: 0.24779 | Regression loss: 0.42688 | Running loss: 0.43441\n",
      "Epoch: 9 | Iteration: 207 | Classification loss: 0.37419 | Regression loss: 0.45018 | Running loss: 0.43467\n",
      "Epoch: 9 | Iteration: 208 | Classification loss: 0.25182 | Regression loss: 0.38786 | Running loss: 0.43542\n",
      "Epoch: 9 | Iteration: 209 | Classification loss: 0.18612 | Regression loss: 0.24760 | Running loss: 0.43538\n",
      "Epoch: 9 | Iteration: 210 | Classification loss: 0.02267 | Regression loss: 0.10962 | Running loss: 0.43488\n",
      "Epoch: 9 | Iteration: 211 | Classification loss: 0.04962 | Regression loss: 0.07613 | Running loss: 0.43426\n",
      "Epoch: 9 | Iteration: 212 | Classification loss: 0.11233 | Regression loss: 0.21046 | Running loss: 0.43426\n",
      "Epoch: 9 | Iteration: 213 | Classification loss: 0.11354 | Regression loss: 0.20720 | Running loss: 0.43451\n",
      "Epoch: 9 | Iteration: 214 | Classification loss: 0.28403 | Regression loss: 0.23631 | Running loss: 0.43411\n",
      "Epoch: 9 | Iteration: 215 | Classification loss: 0.07464 | Regression loss: 0.24389 | Running loss: 0.43442\n",
      "Epoch: 9 | Iteration: 216 | Classification loss: 0.07283 | Regression loss: 0.37577 | Running loss: 0.43433\n",
      "Epoch: 9 | Iteration: 217 | Classification loss: 0.11000 | Regression loss: 0.18807 | Running loss: 0.43406\n",
      "Epoch: 9 | Iteration: 218 | Classification loss: 0.18870 | Regression loss: 0.44852 | Running loss: 0.43435\n",
      "Epoch: 9 | Iteration: 219 | Classification loss: 0.07843 | Regression loss: 0.30390 | Running loss: 0.43404\n",
      "Epoch: 9 | Iteration: 220 | Classification loss: 0.17109 | Regression loss: 0.37608 | Running loss: 0.43463\n",
      "Epoch: 9 | Iteration: 221 | Classification loss: 0.12416 | Regression loss: 0.37626 | Running loss: 0.43448\n",
      "Epoch: 9 | Iteration: 222 | Classification loss: 0.05644 | Regression loss: 0.33509 | Running loss: 0.43401\n",
      "Epoch: 9 | Iteration: 223 | Classification loss: 0.08388 | Regression loss: 0.18325 | Running loss: 0.43382\n",
      "Epoch: 9 | Iteration: 224 | Classification loss: 0.50637 | Regression loss: 0.19473 | Running loss: 0.43401\n",
      "Epoch: 9 | Iteration: 225 | Classification loss: 0.34939 | Regression loss: 0.32474 | Running loss: 0.43466\n",
      "Epoch: 9 | Iteration: 226 | Classification loss: 0.06115 | Regression loss: 0.18039 | Running loss: 0.43457\n",
      "Epoch: 9 | Iteration: 227 | Classification loss: 0.09074 | Regression loss: 0.32807 | Running loss: 0.43507\n",
      "Epoch: 9 | Iteration: 228 | Classification loss: 0.07194 | Regression loss: 0.35160 | Running loss: 0.43500\n",
      "Epoch: 9 | Iteration: 229 | Classification loss: 0.06336 | Regression loss: 0.18888 | Running loss: 0.43498\n",
      "Epoch: 9 | Iteration: 230 | Classification loss: 0.18888 | Regression loss: 0.25481 | Running loss: 0.43528\n",
      "Epoch: 9 | Iteration: 231 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.43455\n",
      "Epoch: 9 | Iteration: 232 | Classification loss: 0.17888 | Regression loss: 0.19815 | Running loss: 0.43481\n",
      "Epoch: 9 | Iteration: 233 | Classification loss: 0.08102 | Regression loss: 0.17604 | Running loss: 0.43452\n",
      "Epoch: 9 | Iteration: 234 | Classification loss: 0.09661 | Regression loss: 0.15149 | Running loss: 0.43328\n",
      "Epoch: 9 | Iteration: 235 | Classification loss: 0.11001 | Regression loss: 0.23947 | Running loss: 0.43340\n",
      "Epoch: 9 | Iteration: 236 | Classification loss: 0.05664 | Regression loss: 0.25691 | Running loss: 0.43283\n",
      "Epoch: 9 | Iteration: 237 | Classification loss: 0.05371 | Regression loss: 0.23120 | Running loss: 0.43289\n",
      "Epoch: 9 | Iteration: 238 | Classification loss: 0.05808 | Regression loss: 0.28917 | Running loss: 0.43164\n",
      "Epoch: 9 | Iteration: 239 | Classification loss: 0.27614 | Regression loss: 0.49934 | Running loss: 0.43212\n",
      "Epoch: 9 | Iteration: 240 | Classification loss: 0.14306 | Regression loss: 0.37133 | Running loss: 0.43181\n",
      "Epoch: 9 | Iteration: 241 | Classification loss: 0.07947 | Regression loss: 0.41577 | Running loss: 0.43187\n",
      "Epoch: 9 | Iteration: 242 | Classification loss: 0.12964 | Regression loss: 0.20546 | Running loss: 0.43191\n",
      "Epoch: 9 | Iteration: 243 | Classification loss: 0.18534 | Regression loss: 0.38168 | Running loss: 0.43214\n",
      "Epoch: 9 | Iteration: 244 | Classification loss: 0.08774 | Regression loss: 0.23398 | Running loss: 0.43202\n",
      "Epoch: 9 | Iteration: 245 | Classification loss: 0.06245 | Regression loss: 0.21302 | Running loss: 0.43143\n",
      "Epoch: 9 | Iteration: 246 | Classification loss: 0.12383 | Regression loss: 0.42668 | Running loss: 0.43138\n",
      "Epoch: 9 | Iteration: 247 | Classification loss: 0.20811 | Regression loss: 0.29685 | Running loss: 0.43130\n",
      "Epoch: 9 | Iteration: 248 | Classification loss: 0.14521 | Regression loss: 0.34019 | Running loss: 0.43139\n",
      "Epoch: 9 | Iteration: 249 | Classification loss: 0.17154 | Regression loss: 0.35820 | Running loss: 0.43148\n",
      "Epoch: 9 | Iteration: 250 | Classification loss: 0.39623 | Regression loss: 0.59480 | Running loss: 0.43254\n",
      "Epoch: 9 | Iteration: 251 | Classification loss: 0.04569 | Regression loss: 0.15730 | Running loss: 0.43219\n",
      "Epoch: 9 | Iteration: 252 | Classification loss: 0.03549 | Regression loss: 0.23729 | Running loss: 0.43186\n",
      "Epoch: 9 | Iteration: 253 | Classification loss: 0.15065 | Regression loss: 0.45438 | Running loss: 0.43222\n",
      "Epoch: 9 | Iteration: 254 | Classification loss: 0.17286 | Regression loss: 0.35379 | Running loss: 0.43203\n",
      "Epoch: 9 | Iteration: 255 | Classification loss: 0.11878 | Regression loss: 0.27186 | Running loss: 0.43206\n",
      "Epoch: 9 | Iteration: 256 | Classification loss: 0.15647 | Regression loss: 0.33424 | Running loss: 0.43212\n",
      "Epoch: 9 | Iteration: 257 | Classification loss: 0.04122 | Regression loss: 0.19352 | Running loss: 0.43166\n",
      "Epoch: 9 | Iteration: 258 | Classification loss: 0.24824 | Regression loss: 0.18162 | Running loss: 0.43159\n",
      "Epoch: 9 | Iteration: 259 | Classification loss: 0.02839 | Regression loss: 0.13703 | Running loss: 0.43044\n",
      "Epoch: 9 | Iteration: 260 | Classification loss: 0.03793 | Regression loss: 0.12472 | Running loss: 0.42931\n",
      "Epoch: 9 | Iteration: 261 | Classification loss: 0.07937 | Regression loss: 0.29319 | Running loss: 0.42904\n",
      "Epoch: 9 | Iteration: 262 | Classification loss: 0.04242 | Regression loss: 0.15039 | Running loss: 0.42852\n",
      "Epoch: 9 | Iteration: 263 | Classification loss: 0.11652 | Regression loss: 0.24034 | Running loss: 0.42860\n",
      "Epoch: 9 | Iteration: 264 | Classification loss: 0.27572 | Regression loss: 0.19841 | Running loss: 0.42873\n",
      "Epoch: 9 | Iteration: 265 | Classification loss: 0.29977 | Regression loss: 0.29851 | Running loss: 0.42893\n",
      "Epoch: 9 | Iteration: 266 | Classification loss: 0.05569 | Regression loss: 0.13775 | Running loss: 0.42816\n",
      "Epoch: 9 | Iteration: 267 | Classification loss: 0.07357 | Regression loss: 0.33607 | Running loss: 0.42774\n",
      "Epoch: 9 | Iteration: 268 | Classification loss: 0.15394 | Regression loss: 0.26643 | Running loss: 0.42769\n",
      "Epoch: 9 | Iteration: 269 | Classification loss: 0.03714 | Regression loss: 0.15169 | Running loss: 0.42682\n",
      "Epoch: 9 | Iteration: 270 | Classification loss: 0.06287 | Regression loss: 0.32010 | Running loss: 0.42693\n",
      "Epoch: 9 | Iteration: 271 | Classification loss: 0.15017 | Regression loss: 0.21617 | Running loss: 0.42698\n",
      "Epoch: 9 | Iteration: 272 | Classification loss: 0.07869 | Regression loss: 0.24692 | Running loss: 0.42704\n",
      "Epoch: 9 | Iteration: 273 | Classification loss: 0.30587 | Regression loss: 0.38383 | Running loss: 0.42710\n",
      "Epoch: 9 | Iteration: 274 | Classification loss: 0.27188 | Regression loss: 0.49131 | Running loss: 0.42810\n",
      "Epoch: 9 | Iteration: 275 | Classification loss: 0.16719 | Regression loss: 0.18981 | Running loss: 0.42812\n",
      "Epoch: 9 | Iteration: 276 | Classification loss: 0.06690 | Regression loss: 0.19792 | Running loss: 0.42798\n",
      "Epoch: 9 | Iteration: 277 | Classification loss: 0.11520 | Regression loss: 0.21649 | Running loss: 0.42731\n",
      "Epoch: 9 | Iteration: 278 | Classification loss: 0.06942 | Regression loss: 0.08736 | Running loss: 0.42650\n",
      "Epoch: 9 | Iteration: 279 | Classification loss: 0.23426 | Regression loss: 0.37992 | Running loss: 0.42688\n",
      "Epoch: 9 | Iteration: 280 | Classification loss: 0.06035 | Regression loss: 0.23723 | Running loss: 0.42710\n",
      "Epoch: 9 | Iteration: 281 | Classification loss: 0.23802 | Regression loss: 0.35098 | Running loss: 0.42706\n",
      "Epoch: 9 | Iteration: 282 | Classification loss: 0.19101 | Regression loss: 0.24549 | Running loss: 0.42663\n",
      "Epoch: 9 | Iteration: 283 | Classification loss: 0.19267 | Regression loss: 0.18669 | Running loss: 0.42679\n",
      "Epoch: 9 | Iteration: 284 | Classification loss: 0.44146 | Regression loss: 0.67603 | Running loss: 0.42828\n",
      "Epoch: 9 | Iteration: 285 | Classification loss: 0.10317 | Regression loss: 0.06818 | Running loss: 0.42767\n",
      "Epoch: 9 | Iteration: 286 | Classification loss: 0.13078 | Regression loss: 0.27554 | Running loss: 0.42764\n",
      "Epoch: 9 | Iteration: 287 | Classification loss: 0.05816 | Regression loss: 0.22886 | Running loss: 0.42700\n",
      "Epoch: 9 | Iteration: 288 | Classification loss: 0.12390 | Regression loss: 0.34220 | Running loss: 0.42750\n",
      "Epoch: 9 | Iteration: 289 | Classification loss: 0.11465 | Regression loss: 0.17331 | Running loss: 0.42663\n",
      "Epoch: 9 | Iteration: 290 | Classification loss: 0.12723 | Regression loss: 0.19112 | Running loss: 0.42690\n",
      "Epoch: 9 | Iteration: 291 | Classification loss: 0.08640 | Regression loss: 0.25650 | Running loss: 0.42627\n",
      "Epoch: 9 | Iteration: 292 | Classification loss: 0.08844 | Regression loss: 0.27198 | Running loss: 0.42557\n",
      "Epoch: 9 | Iteration: 293 | Classification loss: 0.20788 | Regression loss: 0.33584 | Running loss: 0.42604\n",
      "Epoch: 9 | Iteration: 294 | Classification loss: 0.26360 | Regression loss: 0.47547 | Running loss: 0.42704\n",
      "Epoch: 9 | Iteration: 295 | Classification loss: 0.09478 | Regression loss: 0.18979 | Running loss: 0.42734\n",
      "Epoch: 9 | Iteration: 296 | Classification loss: 0.06877 | Regression loss: 0.15238 | Running loss: 0.42669\n",
      "Epoch: 9 | Iteration: 297 | Classification loss: 0.05807 | Regression loss: 0.11046 | Running loss: 0.42612\n",
      "Epoch: 9 | Iteration: 298 | Classification loss: 0.03059 | Regression loss: 0.16462 | Running loss: 0.42583\n",
      "Epoch: 9 | Iteration: 299 | Classification loss: 0.21309 | Regression loss: 0.20911 | Running loss: 0.42619\n",
      "Epoch: 9 | Iteration: 300 | Classification loss: 0.39242 | Regression loss: 0.34987 | Running loss: 0.42671\n",
      "Epoch: 9 | Iteration: 301 | Classification loss: 0.14187 | Regression loss: 0.34622 | Running loss: 0.42727\n",
      "Epoch: 9 | Iteration: 302 | Classification loss: 0.16353 | Regression loss: 0.24923 | Running loss: 0.42724\n",
      "Epoch: 9 | Iteration: 303 | Classification loss: 0.06770 | Regression loss: 0.29601 | Running loss: 0.42709\n",
      "Epoch: 9 | Iteration: 304 | Classification loss: 0.12186 | Regression loss: 0.29794 | Running loss: 0.42668\n",
      "Epoch: 9 | Iteration: 305 | Classification loss: 0.12010 | Regression loss: 0.18814 | Running loss: 0.42674\n",
      "Epoch: 9 | Iteration: 306 | Classification loss: 0.28435 | Regression loss: 0.38059 | Running loss: 0.42768\n",
      "Epoch: 9 | Iteration: 307 | Classification loss: 0.07476 | Regression loss: 0.22203 | Running loss: 0.42730\n",
      "Epoch: 9 | Iteration: 308 | Classification loss: 0.26837 | Regression loss: 0.11364 | Running loss: 0.42762\n",
      "Epoch: 9 | Iteration: 309 | Classification loss: 0.07451 | Regression loss: 0.27808 | Running loss: 0.42800\n",
      "Epoch: 9 | Iteration: 310 | Classification loss: 0.03819 | Regression loss: 0.29869 | Running loss: 0.42801\n",
      "Epoch: 9 | Iteration: 311 | Classification loss: 0.11388 | Regression loss: 0.31836 | Running loss: 0.42776\n",
      "Epoch: 9 | Iteration: 312 | Classification loss: 0.15154 | Regression loss: 0.25821 | Running loss: 0.42791\n",
      "Epoch: 9 | Iteration: 313 | Classification loss: 0.05775 | Regression loss: 0.15390 | Running loss: 0.42781\n",
      "Epoch: 9 | Iteration: 314 | Classification loss: 0.06231 | Regression loss: 0.09933 | Running loss: 0.42741\n",
      "Epoch: 9 | Iteration: 315 | Classification loss: 0.09579 | Regression loss: 0.13255 | Running loss: 0.42704\n",
      "Epoch: 9 | Iteration: 316 | Classification loss: 0.07759 | Regression loss: 0.23395 | Running loss: 0.42704\n",
      "Epoch: 9 | Iteration: 317 | Classification loss: 0.09363 | Regression loss: 0.19174 | Running loss: 0.42652\n",
      "Epoch: 9 | Iteration: 318 | Classification loss: 0.12510 | Regression loss: 0.26770 | Running loss: 0.42635\n",
      "Epoch: 9 | Iteration: 319 | Classification loss: 0.21648 | Regression loss: 0.35710 | Running loss: 0.42668\n",
      "Epoch: 9 | Iteration: 320 | Classification loss: 0.05619 | Regression loss: 0.10396 | Running loss: 0.42584\n",
      "Epoch: 9 | Iteration: 321 | Classification loss: 0.11603 | Regression loss: 0.34196 | Running loss: 0.42627\n",
      "Epoch: 9 | Iteration: 322 | Classification loss: 0.13628 | Regression loss: 0.33407 | Running loss: 0.42658\n",
      "Epoch: 9 | Iteration: 323 | Classification loss: 0.07461 | Regression loss: 0.27575 | Running loss: 0.42648\n",
      "Epoch: 9 | Iteration: 324 | Classification loss: 0.14887 | Regression loss: 0.28912 | Running loss: 0.42664\n",
      "Epoch: 9 | Iteration: 325 | Classification loss: 0.14418 | Regression loss: 0.21030 | Running loss: 0.42674\n",
      "Epoch: 9 | Iteration: 326 | Classification loss: 0.09088 | Regression loss: 0.16951 | Running loss: 0.42648\n",
      "Epoch: 9 | Iteration: 327 | Classification loss: 0.09406 | Regression loss: 0.18347 | Running loss: 0.42616\n",
      "Epoch: 9 | Iteration: 328 | Classification loss: 0.13189 | Regression loss: 0.28027 | Running loss: 0.42631\n",
      "Epoch: 9 | Iteration: 329 | Classification loss: 0.14779 | Regression loss: 0.25806 | Running loss: 0.42616\n",
      "Epoch: 9 | Iteration: 330 | Classification loss: 0.08178 | Regression loss: 0.26100 | Running loss: 0.42630\n",
      "Epoch: 9 | Iteration: 331 | Classification loss: 0.05824 | Regression loss: 0.23730 | Running loss: 0.42595\n",
      "Epoch: 9 | Iteration: 332 | Classification loss: 0.38462 | Regression loss: 0.30317 | Running loss: 0.42632\n",
      "Epoch: 9 | Iteration: 333 | Classification loss: 0.04231 | Regression loss: 0.19136 | Running loss: 0.42628\n",
      "Epoch: 9 | Iteration: 334 | Classification loss: 0.17972 | Regression loss: 0.30994 | Running loss: 0.42632\n",
      "Epoch: 9 | Iteration: 335 | Classification loss: 0.08377 | Regression loss: 0.25126 | Running loss: 0.42618\n",
      "Epoch: 9 | Iteration: 336 | Classification loss: 0.22657 | Regression loss: 0.21761 | Running loss: 0.42557\n",
      "Epoch: 9 | Iteration: 337 | Classification loss: 0.12361 | Regression loss: 0.15938 | Running loss: 0.42450\n",
      "Epoch: 9 | Iteration: 338 | Classification loss: 0.17516 | Regression loss: 0.30507 | Running loss: 0.42458\n",
      "Epoch: 9 | Iteration: 339 | Classification loss: 0.08732 | Regression loss: 0.27293 | Running loss: 0.42364\n",
      "Epoch: 9 | Iteration: 340 | Classification loss: 0.10799 | Regression loss: 0.25266 | Running loss: 0.42401\n",
      "Epoch: 9 | Iteration: 341 | Classification loss: 0.07102 | Regression loss: 0.16851 | Running loss: 0.42318\n",
      "Epoch: 9 | Iteration: 342 | Classification loss: 0.05510 | Regression loss: 0.10780 | Running loss: 0.42234\n",
      "Epoch: 9 | Iteration: 343 | Classification loss: 0.13016 | Regression loss: 0.31155 | Running loss: 0.42192\n",
      "Epoch: 9 | Iteration: 344 | Classification loss: 0.08837 | Regression loss: 0.15314 | Running loss: 0.42147\n",
      "Epoch: 9 | Iteration: 345 | Classification loss: 0.25062 | Regression loss: 0.23967 | Running loss: 0.42097\n",
      "Epoch: 9 | Iteration: 346 | Classification loss: 0.07311 | Regression loss: 0.22198 | Running loss: 0.42055\n",
      "Epoch: 9 | Iteration: 347 | Classification loss: 0.09933 | Regression loss: 0.24020 | Running loss: 0.42068\n",
      "Epoch: 9 | Iteration: 348 | Classification loss: 0.09705 | Regression loss: 0.52917 | Running loss: 0.42044\n",
      "Epoch: 9 | Iteration: 349 | Classification loss: 0.14576 | Regression loss: 0.17104 | Running loss: 0.42075\n",
      "Epoch: 9 | Iteration: 350 | Classification loss: 0.11205 | Regression loss: 0.30890 | Running loss: 0.42097\n",
      "Epoch: 9 | Iteration: 351 | Classification loss: 0.10449 | Regression loss: 0.31327 | Running loss: 0.42102\n",
      "Epoch: 9 | Iteration: 352 | Classification loss: 0.16324 | Regression loss: 0.27630 | Running loss: 0.42090\n",
      "Epoch: 9 | Iteration: 353 | Classification loss: 0.07158 | Regression loss: 0.16003 | Running loss: 0.42066\n",
      "Epoch: 9 | Iteration: 354 | Classification loss: 0.19888 | Regression loss: 0.28392 | Running loss: 0.42112\n",
      "Epoch: 9 | Iteration: 355 | Classification loss: 0.13847 | Regression loss: 0.17491 | Running loss: 0.42145\n",
      "Epoch: 9 | Iteration: 356 | Classification loss: 0.05859 | Regression loss: 0.21521 | Running loss: 0.42106\n",
      "Epoch: 9 | Iteration: 357 | Classification loss: 0.21111 | Regression loss: 0.23051 | Running loss: 0.42109\n",
      "Epoch: 9 | Iteration: 358 | Classification loss: 0.15296 | Regression loss: 0.17742 | Running loss: 0.42117\n",
      "Epoch: 9 | Iteration: 359 | Classification loss: 0.10013 | Regression loss: 0.30968 | Running loss: 0.42005\n",
      "Epoch: 9 | Iteration: 360 | Classification loss: 0.15841 | Regression loss: 0.33763 | Running loss: 0.42020\n",
      "Epoch: 9 | Iteration: 361 | Classification loss: 0.23044 | Regression loss: 0.11044 | Running loss: 0.41941\n",
      "Epoch: 9 | Iteration: 362 | Classification loss: 0.06431 | Regression loss: 0.22476 | Running loss: 0.41927\n",
      "Epoch: 9 | Iteration: 363 | Classification loss: 0.08436 | Regression loss: 0.15627 | Running loss: 0.41889\n",
      "Epoch: 9 | Iteration: 364 | Classification loss: 0.06129 | Regression loss: 0.17711 | Running loss: 0.41872\n",
      "Epoch: 9 | Iteration: 365 | Classification loss: 0.03353 | Regression loss: 0.15758 | Running loss: 0.41868\n",
      "Epoch: 9 | Iteration: 366 | Classification loss: 0.11384 | Regression loss: 0.17524 | Running loss: 0.41857\n",
      "Epoch: 9 | Iteration: 367 | Classification loss: 0.19536 | Regression loss: 0.25147 | Running loss: 0.41811\n",
      "Epoch: 9 | Iteration: 368 | Classification loss: 0.25294 | Regression loss: 0.33044 | Running loss: 0.41843\n",
      "Epoch: 9 | Iteration: 369 | Classification loss: 0.25167 | Regression loss: 0.39410 | Running loss: 0.41855\n",
      "Epoch: 9 | Iteration: 370 | Classification loss: 0.05023 | Regression loss: 0.18261 | Running loss: 0.41841\n",
      "Epoch: 9 | Iteration: 371 | Classification loss: 0.21291 | Regression loss: 0.24680 | Running loss: 0.41871\n",
      "Epoch: 9 | Iteration: 372 | Classification loss: 0.13777 | Regression loss: 0.22740 | Running loss: 0.41883\n",
      "Epoch: 9 | Iteration: 373 | Classification loss: 0.11458 | Regression loss: 0.21305 | Running loss: 0.41858\n",
      "Epoch: 9 | Iteration: 374 | Classification loss: 0.02854 | Regression loss: 0.13872 | Running loss: 0.41834\n",
      "Epoch: 9 | Iteration: 375 | Classification loss: 0.07880 | Regression loss: 0.30620 | Running loss: 0.41835\n",
      "Epoch: 9 | Iteration: 376 | Classification loss: 0.11844 | Regression loss: 0.48680 | Running loss: 0.41884\n",
      "Epoch: 9 | Iteration: 377 | Classification loss: 0.09814 | Regression loss: 0.27289 | Running loss: 0.41831\n",
      "Epoch: 9 | Iteration: 378 | Classification loss: 0.11373 | Regression loss: 0.39959 | Running loss: 0.41850\n",
      "Epoch: 9 | Iteration: 379 | Classification loss: 0.06721 | Regression loss: 0.36773 | Running loss: 0.41875\n",
      "Epoch: 9 | Iteration: 380 | Classification loss: 0.13907 | Regression loss: 0.36558 | Running loss: 0.41918\n",
      "Epoch: 9 | Iteration: 381 | Classification loss: 0.34294 | Regression loss: 0.53298 | Running loss: 0.42040\n",
      "Epoch: 9 | Iteration: 382 | Classification loss: 0.31985 | Regression loss: 0.32158 | Running loss: 0.42114\n",
      "Epoch: 9 | Iteration: 383 | Classification loss: 0.10469 | Regression loss: 0.31576 | Running loss: 0.42062\n",
      "Epoch: 9 | Iteration: 384 | Classification loss: 0.03108 | Regression loss: 0.14475 | Running loss: 0.41903\n",
      "Epoch: 9 | Iteration: 385 | Classification loss: 0.07623 | Regression loss: 0.32007 | Running loss: 0.41845\n",
      "Epoch: 9 | Iteration: 386 | Classification loss: 0.03956 | Regression loss: 0.19111 | Running loss: 0.41749\n",
      "Epoch: 9 | Iteration: 387 | Classification loss: 0.04993 | Regression loss: 0.19847 | Running loss: 0.41731\n",
      "Epoch: 9 | Iteration: 388 | Classification loss: 0.15705 | Regression loss: 0.29205 | Running loss: 0.41717\n",
      "Epoch: 9 | Iteration: 389 | Classification loss: 0.12482 | Regression loss: 0.21210 | Running loss: 0.41654\n",
      "Epoch: 9 | Iteration: 390 | Classification loss: 0.09239 | Regression loss: 0.26420 | Running loss: 0.41634\n",
      "Epoch: 9 | Iteration: 391 | Classification loss: 0.03114 | Regression loss: 0.10937 | Running loss: 0.41593\n",
      "Epoch: 9 | Iteration: 392 | Classification loss: 0.28895 | Regression loss: 0.25427 | Running loss: 0.41624\n",
      "Epoch: 9 | Iteration: 393 | Classification loss: 0.09528 | Regression loss: 0.19198 | Running loss: 0.41626\n",
      "Epoch: 9 | Iteration: 394 | Classification loss: 0.05782 | Regression loss: 0.19281 | Running loss: 0.41589\n",
      "Epoch: 9 | Iteration: 395 | Classification loss: 0.03850 | Regression loss: 0.19075 | Running loss: 0.41578\n",
      "Epoch: 9 | Iteration: 396 | Classification loss: 0.04144 | Regression loss: 0.15322 | Running loss: 0.41541\n",
      "Epoch: 9 | Iteration: 397 | Classification loss: 0.13677 | Regression loss: 0.35716 | Running loss: 0.41579\n",
      "Epoch: 9 | Iteration: 398 | Classification loss: 0.16715 | Regression loss: 0.17855 | Running loss: 0.41587\n",
      "Epoch: 9 | Iteration: 399 | Classification loss: 0.19641 | Regression loss: 0.44529 | Running loss: 0.41648\n",
      "Epoch: 9 | Iteration: 400 | Classification loss: 0.10151 | Regression loss: 0.25076 | Running loss: 0.41617\n",
      "Epoch: 9 | Iteration: 401 | Classification loss: 0.21905 | Regression loss: 0.56021 | Running loss: 0.41730\n",
      "Epoch: 9 | Iteration: 402 | Classification loss: 0.15058 | Regression loss: 0.50840 | Running loss: 0.41819\n",
      "Epoch: 9 | Iteration: 403 | Classification loss: 0.14761 | Regression loss: 0.36111 | Running loss: 0.41775\n",
      "Epoch: 9 | Iteration: 404 | Classification loss: 0.43695 | Regression loss: 0.20830 | Running loss: 0.41829\n",
      "Epoch: 9 | Iteration: 405 | Classification loss: 0.07904 | Regression loss: 0.27881 | Running loss: 0.41833\n",
      "Epoch: 9 | Iteration: 406 | Classification loss: 0.13974 | Regression loss: 0.48291 | Running loss: 0.41923\n",
      "Epoch: 9 | Iteration: 407 | Classification loss: 0.10500 | Regression loss: 0.19237 | Running loss: 0.41921\n",
      "Epoch: 9 | Iteration: 408 | Classification loss: 0.05200 | Regression loss: 0.18570 | Running loss: 0.41968\n",
      "Epoch: 9 | Iteration: 409 | Classification loss: 0.25477 | Regression loss: 0.29934 | Running loss: 0.41963\n",
      "Epoch: 9 | Iteration: 410 | Classification loss: 0.18033 | Regression loss: 0.45233 | Running loss: 0.42010\n",
      "Epoch: 9 | Iteration: 411 | Classification loss: 0.10700 | Regression loss: 0.19321 | Running loss: 0.42028\n",
      "Epoch: 9 | Iteration: 412 | Classification loss: 0.57334 | Regression loss: 0.38097 | Running loss: 0.42027\n",
      "Epoch: 9 | Iteration: 413 | Classification loss: 0.36462 | Regression loss: 0.13548 | Running loss: 0.41932\n",
      "Epoch: 9 | Iteration: 414 | Classification loss: 0.22701 | Regression loss: 0.33099 | Running loss: 0.41987\n",
      "Epoch: 9 | Iteration: 415 | Classification loss: 0.05883 | Regression loss: 0.14513 | Running loss: 0.41880\n",
      "Epoch: 9 | Iteration: 416 | Classification loss: 0.13632 | Regression loss: 0.23409 | Running loss: 0.41868\n",
      "Epoch: 9 | Iteration: 417 | Classification loss: 0.10233 | Regression loss: 0.34309 | Running loss: 0.41881\n",
      "Epoch: 9 | Iteration: 418 | Classification loss: 0.17611 | Regression loss: 0.27889 | Running loss: 0.41881\n",
      "Epoch: 9 | Iteration: 419 | Classification loss: 0.07161 | Regression loss: 0.11384 | Running loss: 0.41847\n",
      "Epoch: 9 | Iteration: 420 | Classification loss: 0.12164 | Regression loss: 0.23166 | Running loss: 0.41820\n",
      "Epoch: 9 | Iteration: 421 | Classification loss: 0.21427 | Regression loss: 0.50198 | Running loss: 0.41915\n",
      "Epoch: 9 | Iteration: 422 | Classification loss: 0.65899 | Regression loss: 0.51661 | Running loss: 0.42073\n",
      "Epoch: 9 | Iteration: 423 | Classification loss: 0.18158 | Regression loss: 0.47422 | Running loss: 0.42121\n",
      "Epoch: 9 | Iteration: 424 | Classification loss: 0.07144 | Regression loss: 0.18649 | Running loss: 0.42108\n",
      "Epoch: 9 | Iteration: 425 | Classification loss: 0.25283 | Regression loss: 0.36809 | Running loss: 0.42085\n",
      "Epoch: 9 | Iteration: 426 | Classification loss: 0.14459 | Regression loss: 0.14543 | Running loss: 0.42038\n",
      "Epoch: 9 | Iteration: 427 | Classification loss: 0.05889 | Regression loss: 0.19533 | Running loss: 0.42003\n",
      "Epoch: 9 | Iteration: 428 | Classification loss: 0.06670 | Regression loss: 0.19729 | Running loss: 0.41986\n",
      "Epoch: 9 | Iteration: 429 | Classification loss: 0.17249 | Regression loss: 0.24712 | Running loss: 0.42012\n",
      "Epoch: 9 | Iteration: 430 | Classification loss: 0.26242 | Regression loss: 0.56412 | Running loss: 0.42100\n",
      "Epoch: 9 | Iteration: 431 | Classification loss: 0.20975 | Regression loss: 0.22948 | Running loss: 0.41996\n",
      "Epoch: 9 | Iteration: 432 | Classification loss: 0.17498 | Regression loss: 0.25129 | Running loss: 0.41931\n",
      "Epoch: 9 | Iteration: 433 | Classification loss: 0.06019 | Regression loss: 0.34243 | Running loss: 0.41936\n",
      "Epoch: 9 | Iteration: 434 | Classification loss: 0.05818 | Regression loss: 0.13764 | Running loss: 0.41858\n",
      "Epoch: 9 | Iteration: 435 | Classification loss: 0.23449 | Regression loss: 0.13232 | Running loss: 0.41785\n",
      "Epoch: 9 | Iteration: 436 | Classification loss: 0.30587 | Regression loss: 0.55730 | Running loss: 0.41858\n",
      "Epoch: 9 | Iteration: 437 | Classification loss: 0.09789 | Regression loss: 0.17695 | Running loss: 0.41808\n",
      "Epoch: 9 | Iteration: 438 | Classification loss: 0.25984 | Regression loss: 0.40583 | Running loss: 0.41893\n",
      "Epoch: 9 | Iteration: 439 | Classification loss: 0.08445 | Regression loss: 0.31958 | Running loss: 0.41898\n",
      "Epoch: 9 | Iteration: 440 | Classification loss: 0.15360 | Regression loss: 0.51711 | Running loss: 0.41972\n",
      "Epoch: 9 | Iteration: 441 | Classification loss: 0.37460 | Regression loss: 0.36938 | Running loss: 0.42003\n",
      "Epoch: 9 | Iteration: 442 | Classification loss: 0.10134 | Regression loss: 0.23140 | Running loss: 0.41909\n",
      "Epoch: 9 | Iteration: 443 | Classification loss: 0.14001 | Regression loss: 0.19814 | Running loss: 0.41912\n",
      "Epoch: 9 | Iteration: 444 | Classification loss: 0.18499 | Regression loss: 0.39455 | Running loss: 0.41887\n",
      "Epoch: 9 | Iteration: 445 | Classification loss: 0.23772 | Regression loss: 0.49562 | Running loss: 0.41947\n",
      "Epoch: 9 | Iteration: 446 | Classification loss: 0.06778 | Regression loss: 0.18623 | Running loss: 0.41842\n",
      "Epoch: 9 | Iteration: 447 | Classification loss: 0.05814 | Regression loss: 0.17027 | Running loss: 0.41850\n",
      "Epoch: 9 | Iteration: 448 | Classification loss: 0.09824 | Regression loss: 0.27615 | Running loss: 0.41863\n",
      "Epoch: 9 | Iteration: 449 | Classification loss: 0.10389 | Regression loss: 0.17008 | Running loss: 0.41831\n",
      "Epoch: 9 | Iteration: 450 | Classification loss: 0.62992 | Regression loss: 0.26660 | Running loss: 0.41936\n",
      "Epoch: 9 | Iteration: 451 | Classification loss: 0.10790 | Regression loss: 0.20374 | Running loss: 0.41858\n",
      "Epoch: 9 | Iteration: 452 | Classification loss: 0.17670 | Regression loss: 0.13643 | Running loss: 0.41872\n",
      "Epoch: 9 | Iteration: 453 | Classification loss: 0.12475 | Regression loss: 0.22312 | Running loss: 0.41851\n",
      "Epoch: 9 | Iteration: 454 | Classification loss: 0.18248 | Regression loss: 0.44493 | Running loss: 0.41845\n",
      "Epoch: 9 | Iteration: 455 | Classification loss: 0.13812 | Regression loss: 0.22559 | Running loss: 0.41855\n",
      "Epoch: 9 | Iteration: 456 | Classification loss: 0.07694 | Regression loss: 0.23447 | Running loss: 0.41849\n",
      "Epoch: 9 | Iteration: 457 | Classification loss: 0.23186 | Regression loss: 0.44037 | Running loss: 0.41887\n",
      "Epoch: 9 | Iteration: 458 | Classification loss: 0.13446 | Regression loss: 0.25039 | Running loss: 0.41885\n",
      "Epoch: 9 | Iteration: 459 | Classification loss: 0.08472 | Regression loss: 0.25469 | Running loss: 0.41841\n",
      "Epoch: 9 | Iteration: 460 | Classification loss: 0.05872 | Regression loss: 0.25675 | Running loss: 0.41870\n",
      "Epoch: 9 | Iteration: 461 | Classification loss: 0.08707 | Regression loss: 0.18074 | Running loss: 0.41749\n",
      "Epoch: 9 | Iteration: 462 | Classification loss: 0.28470 | Regression loss: 0.41187 | Running loss: 0.41796\n",
      "Epoch: 9 | Iteration: 463 | Classification loss: 0.09817 | Regression loss: 0.27567 | Running loss: 0.41793\n",
      "Epoch: 9 | Iteration: 464 | Classification loss: 0.08551 | Regression loss: 0.46541 | Running loss: 0.41786\n",
      "Epoch: 9 | Iteration: 465 | Classification loss: 0.24702 | Regression loss: 0.23420 | Running loss: 0.41834\n",
      "Epoch: 9 | Iteration: 466 | Classification loss: 0.16126 | Regression loss: 0.23107 | Running loss: 0.41734\n",
      "Epoch: 9 | Iteration: 467 | Classification loss: 0.19917 | Regression loss: 0.49531 | Running loss: 0.41714\n",
      "Epoch: 9 | Iteration: 468 | Classification loss: 0.18201 | Regression loss: 0.42573 | Running loss: 0.41759\n",
      "Epoch: 9 | Iteration: 469 | Classification loss: 0.07306 | Regression loss: 0.27390 | Running loss: 0.41767\n",
      "Epoch: 9 | Iteration: 470 | Classification loss: 0.16576 | Regression loss: 0.23986 | Running loss: 0.41798\n",
      "Epoch: 9 | Iteration: 471 | Classification loss: 0.13976 | Regression loss: 0.35356 | Running loss: 0.41826\n",
      "Epoch: 9 | Iteration: 472 | Classification loss: 0.14299 | Regression loss: 0.26932 | Running loss: 0.41796\n",
      "Epoch: 9 | Iteration: 473 | Classification loss: 0.21405 | Regression loss: 0.34222 | Running loss: 0.41824\n",
      "Epoch: 9 | Iteration: 474 | Classification loss: 0.13034 | Regression loss: 0.18946 | Running loss: 0.41772\n",
      "Epoch: 9 | Iteration: 475 | Classification loss: 0.09044 | Regression loss: 0.24100 | Running loss: 0.41781\n",
      "Epoch: 9 | Iteration: 476 | Classification loss: 0.12269 | Regression loss: 0.25796 | Running loss: 0.41857\n",
      "Epoch: 9 | Iteration: 477 | Classification loss: 0.08004 | Regression loss: 0.23266 | Running loss: 0.41881\n",
      "Epoch: 9 | Iteration: 478 | Classification loss: 0.07755 | Regression loss: 0.22281 | Running loss: 0.41867\n",
      "Epoch: 9 | Iteration: 479 | Classification loss: 0.19617 | Regression loss: 0.22414 | Running loss: 0.41829\n",
      "Epoch: 9 | Iteration: 480 | Classification loss: 0.06503 | Regression loss: 0.30952 | Running loss: 0.41835\n",
      "Epoch: 9 | Iteration: 481 | Classification loss: 0.11376 | Regression loss: 0.36559 | Running loss: 0.41860\n",
      "Epoch: 9 | Iteration: 482 | Classification loss: 0.10211 | Regression loss: 0.27067 | Running loss: 0.41812\n",
      "Epoch: 9 | Iteration: 483 | Classification loss: 0.04678 | Regression loss: 0.17440 | Running loss: 0.41772\n",
      "Epoch: 9 | Iteration: 484 | Classification loss: 0.07783 | Regression loss: 0.18656 | Running loss: 0.41735\n",
      "Epoch: 9 | Iteration: 485 | Classification loss: 0.05266 | Regression loss: 0.15561 | Running loss: 0.41704\n",
      "Epoch: 9 | Iteration: 486 | Classification loss: 0.08763 | Regression loss: 0.25929 | Running loss: 0.41509\n",
      "Epoch: 9 | Iteration: 487 | Classification loss: 0.03722 | Regression loss: 0.23370 | Running loss: 0.41484\n",
      "Epoch: 9 | Iteration: 488 | Classification loss: 0.15736 | Regression loss: 0.24891 | Running loss: 0.41489\n",
      "Epoch: 9 | Iteration: 489 | Classification loss: 0.07353 | Regression loss: 0.10944 | Running loss: 0.41466\n",
      "Epoch: 9 | Iteration: 490 | Classification loss: 0.17530 | Regression loss: 0.43631 | Running loss: 0.41434\n",
      "Epoch: 9 | Iteration: 491 | Classification loss: 0.02012 | Regression loss: 0.11567 | Running loss: 0.41393\n",
      "Epoch: 9 | Iteration: 492 | Classification loss: 0.09829 | Regression loss: 0.20846 | Running loss: 0.41377\n",
      "Epoch: 9 | Iteration: 493 | Classification loss: 0.05928 | Regression loss: 0.24871 | Running loss: 0.41376\n",
      "Epoch: 9 | Iteration: 494 | Classification loss: 0.28297 | Regression loss: 0.23699 | Running loss: 0.41371\n",
      "Epoch: 9 | Iteration: 495 | Classification loss: 0.07868 | Regression loss: 0.18184 | Running loss: 0.41297\n",
      "Epoch: 9 | Iteration: 496 | Classification loss: 0.05541 | Regression loss: 0.17758 | Running loss: 0.41301\n",
      "Epoch: 9 | Iteration: 497 | Classification loss: 0.03846 | Regression loss: 0.21041 | Running loss: 0.41288\n",
      "Epoch: 9 | Iteration: 498 | Classification loss: 0.05392 | Regression loss: 0.21446 | Running loss: 0.41300\n",
      "Epoch: 9 | Iteration: 499 | Classification loss: 0.04488 | Regression loss: 0.14321 | Running loss: 0.41274\n",
      "Epoch: 9 | Iteration: 500 | Classification loss: 0.25468 | Regression loss: 0.33492 | Running loss: 0.41342\n",
      "Epoch: 9 | Iteration: 501 | Classification loss: 0.05309 | Regression loss: 0.14260 | Running loss: 0.41318\n",
      "Epoch: 9 | Iteration: 502 | Classification loss: 0.07318 | Regression loss: 0.29233 | Running loss: 0.41329\n",
      "Epoch: 9 | Iteration: 503 | Classification loss: 0.09381 | Regression loss: 0.16101 | Running loss: 0.41290\n",
      "Epoch: 9 | Iteration: 504 | Classification loss: 0.05898 | Regression loss: 0.18014 | Running loss: 0.41271\n",
      "Epoch: 9 | Iteration: 505 | Classification loss: 0.08535 | Regression loss: 0.19412 | Running loss: 0.41275\n",
      "Epoch: 9 | Iteration: 506 | Classification loss: 0.39395 | Regression loss: 0.29624 | Running loss: 0.41324\n",
      "Epoch: 9 | Iteration: 507 | Classification loss: 0.10710 | Regression loss: 0.34420 | Running loss: 0.41350\n",
      "Epoch: 9 | Iteration: 508 | Classification loss: 0.10619 | Regression loss: 0.12179 | Running loss: 0.41331\n",
      "Epoch: 9 | Iteration: 509 | Classification loss: 0.08106 | Regression loss: 0.11862 | Running loss: 0.41277\n",
      "Epoch: 9 | Iteration: 510 | Classification loss: 0.07270 | Regression loss: 0.26388 | Running loss: 0.41247\n",
      "Epoch: 9 | Iteration: 511 | Classification loss: 0.18372 | Regression loss: 0.41438 | Running loss: 0.41329\n",
      "Epoch: 9 | Iteration: 512 | Classification loss: 0.26238 | Regression loss: 0.42898 | Running loss: 0.41371\n",
      "Epoch: 9 | Iteration: 513 | Classification loss: 0.06164 | Regression loss: 0.19613 | Running loss: 0.41282\n",
      "Epoch: 9 | Iteration: 514 | Classification loss: 0.14962 | Regression loss: 0.19418 | Running loss: 0.41303\n",
      "Epoch: 9 | Iteration: 515 | Classification loss: 0.19681 | Regression loss: 0.13615 | Running loss: 0.41310\n",
      "Epoch: 9 | Iteration: 516 | Classification loss: 0.19535 | Regression loss: 0.25573 | Running loss: 0.41296\n",
      "Epoch: 9 | Iteration: 517 | Classification loss: 0.23240 | Regression loss: 0.28826 | Running loss: 0.41296\n",
      "Epoch: 9 | Iteration: 518 | Classification loss: 0.07018 | Regression loss: 0.22428 | Running loss: 0.41180\n",
      "Epoch: 9 | Iteration: 519 | Classification loss: 0.10229 | Regression loss: 0.23171 | Running loss: 0.41133\n",
      "Epoch: 9 | Iteration: 520 | Classification loss: 0.22504 | Regression loss: 0.37522 | Running loss: 0.41182\n",
      "Epoch: 9 | Iteration: 521 | Classification loss: 0.09591 | Regression loss: 0.21842 | Running loss: 0.41164\n",
      "Epoch: 9 | Iteration: 522 | Classification loss: 0.09625 | Regression loss: 0.24874 | Running loss: 0.41171\n",
      "Epoch: 9 | Iteration: 523 | Classification loss: 0.04937 | Regression loss: 0.25025 | Running loss: 0.41158\n",
      "Epoch: 9 | Iteration: 524 | Classification loss: 0.07171 | Regression loss: 0.24923 | Running loss: 0.41153\n",
      "Epoch: 9 | Iteration: 525 | Classification loss: 0.15451 | Regression loss: 0.21425 | Running loss: 0.41164\n",
      "Epoch: 9 | Iteration: 526 | Classification loss: 0.12167 | Regression loss: 0.21614 | Running loss: 0.41120\n",
      "Epoch: 9 | Iteration: 527 | Classification loss: 0.17996 | Regression loss: 0.31404 | Running loss: 0.41059\n",
      "Epoch: 9 | Iteration: 528 | Classification loss: 0.19471 | Regression loss: 0.45945 | Running loss: 0.41129\n",
      "Epoch: 9 | Iteration: 529 | Classification loss: 0.04302 | Regression loss: 0.16041 | Running loss: 0.41063\n",
      "Epoch: 9 | Iteration: 530 | Classification loss: 0.11833 | Regression loss: 0.24367 | Running loss: 0.41018\n",
      "Epoch: 9 | Iteration: 531 | Classification loss: 0.26885 | Regression loss: 0.28438 | Running loss: 0.41059\n",
      "Epoch: 9 | Iteration: 532 | Classification loss: 0.08682 | Regression loss: 0.24969 | Running loss: 0.40981\n",
      "Epoch: 9 | Iteration: 533 | Classification loss: 0.04095 | Regression loss: 0.26039 | Running loss: 0.40963\n",
      "Epoch: 9 | Iteration: 534 | Classification loss: 0.03615 | Regression loss: 0.12692 | Running loss: 0.40910\n",
      "Epoch: 9 | Iteration: 535 | Classification loss: 0.47583 | Regression loss: 0.30977 | Running loss: 0.40967\n",
      "Epoch: 9 | Iteration: 536 | Classification loss: 0.38599 | Regression loss: 0.38750 | Running loss: 0.41031\n",
      "Epoch: 9 | Iteration: 537 | Classification loss: 0.08681 | Regression loss: 0.21589 | Running loss: 0.41042\n",
      "Epoch: 9 | Iteration: 538 | Classification loss: 0.15694 | Regression loss: 0.22975 | Running loss: 0.41089\n",
      "Epoch: 9 | Iteration: 539 | Classification loss: 0.05290 | Regression loss: 0.20452 | Running loss: 0.41093\n",
      "Epoch: 9 | Iteration: 540 | Classification loss: 0.07592 | Regression loss: 0.35375 | Running loss: 0.41035\n",
      "Epoch: 9 | Iteration: 541 | Classification loss: 0.10749 | Regression loss: 0.23119 | Running loss: 0.41030\n",
      "Epoch: 9 | Iteration: 542 | Classification loss: 0.30353 | Regression loss: 0.19265 | Running loss: 0.41053\n",
      "Epoch: 9 | Iteration: 543 | Classification loss: 0.04311 | Regression loss: 0.33128 | Running loss: 0.41084\n",
      "Epoch: 9 | Iteration: 544 | Classification loss: 0.06782 | Regression loss: 0.25293 | Running loss: 0.41088\n",
      "Epoch: 9 | Iteration: 545 | Classification loss: 0.06501 | Regression loss: 0.23622 | Running loss: 0.41081\n",
      "Epoch: 9 | Iteration: 546 | Classification loss: 0.05347 | Regression loss: 0.14880 | Running loss: 0.41054\n",
      "Epoch: 9 | Iteration: 547 | Classification loss: 0.25001 | Regression loss: 0.47940 | Running loss: 0.41118\n",
      "Epoch: 9 | Iteration: 548 | Classification loss: 0.12252 | Regression loss: 0.41055 | Running loss: 0.41183\n",
      "Epoch: 9 | Iteration: 549 | Classification loss: 0.11207 | Regression loss: 0.33593 | Running loss: 0.41193\n",
      "Epoch: 9 | Iteration: 550 | Classification loss: 0.46838 | Regression loss: 0.16781 | Running loss: 0.41249\n",
      "Epoch: 9 | Iteration: 551 | Classification loss: 0.21785 | Regression loss: 0.16431 | Running loss: 0.41245\n",
      "Epoch: 9 | Iteration: 552 | Classification loss: 0.05896 | Regression loss: 0.24334 | Running loss: 0.41246\n",
      "Epoch: 9 | Iteration: 553 | Classification loss: 0.31250 | Regression loss: 0.55917 | Running loss: 0.41361\n",
      "Epoch: 9 | Iteration: 554 | Classification loss: 0.15587 | Regression loss: 0.18214 | Running loss: 0.41236\n",
      "Epoch: 9 | Iteration: 555 | Classification loss: 0.30961 | Regression loss: 0.34994 | Running loss: 0.41368\n",
      "Epoch: 9 | Iteration: 556 | Classification loss: 0.08828 | Regression loss: 0.25038 | Running loss: 0.41378\n",
      "Epoch: 9 | Iteration: 557 | Classification loss: 0.04399 | Regression loss: 0.16688 | Running loss: 0.41362\n",
      "Epoch: 9 | Iteration: 558 | Classification loss: 0.04491 | Regression loss: 0.24670 | Running loss: 0.41280\n",
      "Epoch: 9 | Iteration: 559 | Classification loss: 0.22263 | Regression loss: 0.22617 | Running loss: 0.41261\n",
      "Epoch: 9 | Iteration: 560 | Classification loss: 0.07655 | Regression loss: 0.21003 | Running loss: 0.41292\n",
      "Epoch: 9 | Iteration: 561 | Classification loss: 0.09074 | Regression loss: 0.20472 | Running loss: 0.41308\n",
      "Epoch: 9 | Iteration: 562 | Classification loss: 0.16671 | Regression loss: 0.24872 | Running loss: 0.41319\n",
      "Epoch: 9 | Iteration: 563 | Classification loss: 0.06613 | Regression loss: 0.25894 | Running loss: 0.41337\n",
      "Epoch: 9 | Iteration: 564 | Classification loss: 0.08804 | Regression loss: 0.21940 | Running loss: 0.41353\n",
      "Epoch: 9 | Iteration: 565 | Classification loss: 0.45542 | Regression loss: 0.54690 | Running loss: 0.41412\n",
      "Epoch: 9 | Iteration: 566 | Classification loss: 0.11260 | Regression loss: 0.33284 | Running loss: 0.41443\n",
      "Epoch: 9 | Iteration: 567 | Classification loss: 0.06107 | Regression loss: 0.13168 | Running loss: 0.41379\n",
      "Epoch: 9 | Iteration: 568 | Classification loss: 0.13273 | Regression loss: 0.25202 | Running loss: 0.41369\n",
      "Epoch: 9 | Iteration: 569 | Classification loss: 0.27921 | Regression loss: 0.30685 | Running loss: 0.41418\n",
      "Epoch: 9 | Iteration: 570 | Classification loss: 0.04397 | Regression loss: 0.16534 | Running loss: 0.41416\n",
      "Epoch: 9 | Iteration: 571 | Classification loss: 0.20630 | Regression loss: 0.22740 | Running loss: 0.41438\n",
      "Epoch: 9 | Iteration: 572 | Classification loss: 0.02504 | Regression loss: 0.15150 | Running loss: 0.41301\n",
      "Epoch: 9 | Iteration: 573 | Classification loss: 0.17899 | Regression loss: 0.47479 | Running loss: 0.41353\n",
      "Epoch: 9 | Iteration: 574 | Classification loss: 0.10356 | Regression loss: 0.25762 | Running loss: 0.41285\n",
      "Epoch: 9 | Iteration: 575 | Classification loss: 0.45682 | Regression loss: 0.32686 | Running loss: 0.41363\n",
      "Epoch: 9 | Iteration: 576 | Classification loss: 0.08398 | Regression loss: 0.20921 | Running loss: 0.41392\n",
      "Epoch: 9 | Iteration: 577 | Classification loss: 0.18200 | Regression loss: 0.32155 | Running loss: 0.41406\n",
      "Epoch: 9 | Iteration: 578 | Classification loss: 0.13149 | Regression loss: 0.14839 | Running loss: 0.41374\n",
      "Epoch: 9 | Iteration: 579 | Classification loss: 0.04852 | Regression loss: 0.18264 | Running loss: 0.41277\n",
      "Epoch: 9 | Iteration: 580 | Classification loss: 0.06813 | Regression loss: 0.18765 | Running loss: 0.41263\n",
      "Epoch: 9 | Iteration: 581 | Classification loss: 0.09569 | Regression loss: 0.29731 | Running loss: 0.41259\n",
      "Epoch: 9 | Iteration: 582 | Classification loss: 0.06147 | Regression loss: 0.20512 | Running loss: 0.41242\n",
      "Epoch: 9 | Iteration: 583 | Classification loss: 0.29516 | Regression loss: 0.41685 | Running loss: 0.41313\n",
      "Epoch: 9 | Iteration: 584 | Classification loss: 0.09109 | Regression loss: 0.34296 | Running loss: 0.41101\n",
      "Epoch: 9 | Iteration: 585 | Classification loss: 0.08652 | Regression loss: 0.26368 | Running loss: 0.41079\n",
      "Epoch: 9 | Iteration: 586 | Classification loss: 0.10360 | Regression loss: 0.25690 | Running loss: 0.41060\n",
      "Epoch: 9 | Iteration: 587 | Classification loss: 0.28977 | Regression loss: 0.34666 | Running loss: 0.41124\n",
      "Epoch: 9 | Iteration: 588 | Classification loss: 0.19563 | Regression loss: 0.25321 | Running loss: 0.41172\n",
      "Epoch: 9 | Iteration: 589 | Classification loss: 0.03635 | Regression loss: 0.22855 | Running loss: 0.41098\n",
      "Epoch: 9 | Iteration: 590 | Classification loss: 0.19666 | Regression loss: 0.24729 | Running loss: 0.41087\n",
      "Epoch: 9 | Iteration: 591 | Classification loss: 0.15664 | Regression loss: 0.27977 | Running loss: 0.41081\n",
      "Epoch: 9 | Iteration: 592 | Classification loss: 0.16461 | Regression loss: 0.27707 | Running loss: 0.41121\n",
      "Epoch: 9 | Iteration: 593 | Classification loss: 0.16483 | Regression loss: 0.19600 | Running loss: 0.41123\n",
      "Epoch: 9 | Iteration: 594 | Classification loss: 0.24457 | Regression loss: 0.18734 | Running loss: 0.41153\n",
      "Epoch: 9 | Iteration: 595 | Classification loss: 0.09934 | Regression loss: 0.20654 | Running loss: 0.41143\n",
      "Epoch: 9 | Iteration: 596 | Classification loss: 0.08026 | Regression loss: 0.14711 | Running loss: 0.41047\n",
      "Epoch: 9 | Iteration: 597 | Classification loss: 0.03915 | Regression loss: 0.12494 | Running loss: 0.41013\n",
      "Epoch: 9 | Iteration: 598 | Classification loss: 0.11256 | Regression loss: 0.33405 | Running loss: 0.41057\n",
      "Epoch: 9 | Iteration: 599 | Classification loss: 0.13460 | Regression loss: 0.32064 | Running loss: 0.41054\n",
      "Epoch: 9 | Iteration: 600 | Classification loss: 0.19046 | Regression loss: 0.12917 | Running loss: 0.41073\n",
      "Epoch: 9 | Iteration: 601 | Classification loss: 0.32119 | Regression loss: 0.15539 | Running loss: 0.41070\n",
      "Epoch: 9 | Iteration: 602 | Classification loss: 0.07581 | Regression loss: 0.18611 | Running loss: 0.41011\n",
      "Epoch: 9 | Iteration: 603 | Classification loss: 0.04064 | Regression loss: 0.15180 | Running loss: 0.40968\n",
      "Epoch: 9 | Iteration: 604 | Classification loss: 0.43926 | Regression loss: 0.67539 | Running loss: 0.41091\n",
      "Epoch: 9 | Iteration: 605 | Classification loss: 0.24390 | Regression loss: 0.45202 | Running loss: 0.41170\n",
      "Epoch: 9 | Iteration: 606 | Classification loss: 0.38032 | Regression loss: 0.49522 | Running loss: 0.41314\n",
      "Epoch: 9 | Iteration: 607 | Classification loss: 0.22311 | Regression loss: 0.23399 | Running loss: 0.41343\n",
      "Epoch: 9 | Iteration: 608 | Classification loss: 0.24697 | Regression loss: 0.48458 | Running loss: 0.41325\n",
      "Epoch: 9 | Iteration: 609 | Classification loss: 0.20022 | Regression loss: 0.61141 | Running loss: 0.41408\n",
      "Epoch: 9 | Iteration: 610 | Classification loss: 0.33444 | Regression loss: 0.49222 | Running loss: 0.41509\n",
      "Epoch: 9 | Iteration: 611 | Classification loss: 0.15720 | Regression loss: 0.27129 | Running loss: 0.41553\n",
      "Epoch: 9 | Iteration: 612 | Classification loss: 0.07392 | Regression loss: 0.22620 | Running loss: 0.41574\n",
      "Epoch: 9 | Iteration: 613 | Classification loss: 0.11397 | Regression loss: 0.20973 | Running loss: 0.41539\n",
      "Epoch: 9 | Iteration: 614 | Classification loss: 0.22441 | Regression loss: 0.52227 | Running loss: 0.41601\n",
      "Epoch: 9 | Iteration: 615 | Classification loss: 0.09290 | Regression loss: 0.26195 | Running loss: 0.41593\n",
      "Epoch: 9 | Iteration: 616 | Classification loss: 0.06325 | Regression loss: 0.14594 | Running loss: 0.41515\n",
      "Epoch: 9 | Iteration: 617 | Classification loss: 0.07586 | Regression loss: 0.21458 | Running loss: 0.41508\n",
      "Epoch: 9 | Iteration: 618 | Classification loss: 0.08329 | Regression loss: 0.29227 | Running loss: 0.41530\n",
      "Epoch: 9 | Iteration: 619 | Classification loss: 0.11319 | Regression loss: 0.19962 | Running loss: 0.41494\n",
      "Epoch: 9 | Iteration: 620 | Classification loss: 0.05892 | Regression loss: 0.19679 | Running loss: 0.41366\n",
      "Epoch: 9 | Iteration: 621 | Classification loss: 0.15167 | Regression loss: 0.20411 | Running loss: 0.41401\n",
      "Epoch: 9 | Iteration: 622 | Classification loss: 0.03050 | Regression loss: 0.17591 | Running loss: 0.41358\n",
      "Epoch: 9 | Iteration: 623 | Classification loss: 0.08793 | Regression loss: 0.26170 | Running loss: 0.41336\n",
      "Epoch: 9 | Iteration: 624 | Classification loss: 0.04956 | Regression loss: 0.09709 | Running loss: 0.41261\n",
      "Epoch: 9 | Iteration: 625 | Classification loss: 0.08595 | Regression loss: 0.13560 | Running loss: 0.41257\n",
      "Epoch: 9 | Iteration: 626 | Classification loss: 0.06759 | Regression loss: 0.12822 | Running loss: 0.41175\n",
      "Epoch: 9 | Iteration: 627 | Classification loss: 0.47805 | Regression loss: 0.14589 | Running loss: 0.41218\n",
      "Epoch: 9 | Iteration: 628 | Classification loss: 0.21121 | Regression loss: 0.24459 | Running loss: 0.41226\n",
      "Epoch: 9 | Iteration: 629 | Classification loss: 0.10867 | Regression loss: 0.36873 | Running loss: 0.41186\n",
      "Epoch: 9 | Iteration: 630 | Classification loss: 0.04412 | Regression loss: 0.43205 | Running loss: 0.41233\n",
      "Epoch: 9 | Iteration: 631 | Classification loss: 0.04845 | Regression loss: 0.20490 | Running loss: 0.41237\n",
      "Epoch: 9 | Iteration: 632 | Classification loss: 0.10536 | Regression loss: 0.43773 | Running loss: 0.41255\n",
      "Epoch: 9 | Iteration: 633 | Classification loss: 0.15535 | Regression loss: 0.25471 | Running loss: 0.41310\n",
      "Epoch: 9 | Iteration: 634 | Classification loss: 0.09182 | Regression loss: 0.20655 | Running loss: 0.41273\n",
      "Epoch: 9 | Iteration: 635 | Classification loss: 0.49695 | Regression loss: 0.48586 | Running loss: 0.41336\n",
      "Epoch: 9 | Iteration: 636 | Classification loss: 0.09364 | Regression loss: 0.15755 | Running loss: 0.41326\n",
      "Epoch: 9 | Iteration: 637 | Classification loss: 0.19504 | Regression loss: 0.19822 | Running loss: 0.41311\n",
      "Epoch: 9 | Iteration: 638 | Classification loss: 0.04292 | Regression loss: 0.23853 | Running loss: 0.41274\n",
      "Epoch: 9 | Iteration: 639 | Classification loss: 0.72786 | Regression loss: 0.04745 | Running loss: 0.41371\n",
      "Epoch: 9 | Iteration: 640 | Classification loss: 0.05852 | Regression loss: 0.21610 | Running loss: 0.41393\n",
      "Epoch: 9 | Iteration: 641 | Classification loss: 0.12291 | Regression loss: 0.28220 | Running loss: 0.41423\n",
      "Epoch: 9 | Iteration: 642 | Classification loss: 0.01759 | Regression loss: 0.26142 | Running loss: 0.41391\n",
      "Epoch: 9 | Iteration: 643 | Classification loss: 0.14044 | Regression loss: 0.20470 | Running loss: 0.41414\n",
      "Epoch: 9 | Iteration: 644 | Classification loss: 0.08247 | Regression loss: 0.26752 | Running loss: 0.41344\n",
      "Epoch: 9 | Iteration: 645 | Classification loss: 0.08335 | Regression loss: 0.32747 | Running loss: 0.41277\n",
      "Epoch: 9 | Iteration: 646 | Classification loss: 0.16569 | Regression loss: 0.30391 | Running loss: 0.41320\n",
      "Epoch: 9 | Iteration: 647 | Classification loss: 0.17087 | Regression loss: 0.31008 | Running loss: 0.41314\n",
      "Epoch: 9 | Iteration: 648 | Classification loss: 0.22141 | Regression loss: 0.55235 | Running loss: 0.41364\n",
      "Epoch: 9 | Iteration: 649 | Classification loss: 0.21344 | Regression loss: 0.16296 | Running loss: 0.41329\n",
      "Epoch: 9 | Iteration: 650 | Classification loss: 0.11299 | Regression loss: 0.29133 | Running loss: 0.41337\n",
      "Epoch: 9 | Iteration: 651 | Classification loss: 0.10334 | Regression loss: 0.35026 | Running loss: 0.41326\n",
      "Epoch: 9 | Iteration: 652 | Classification loss: 0.20898 | Regression loss: 0.19084 | Running loss: 0.41334\n",
      "Epoch: 9 | Iteration: 653 | Classification loss: 0.11847 | Regression loss: 0.30189 | Running loss: 0.41356\n",
      "Epoch: 9 | Iteration: 654 | Classification loss: 0.08181 | Regression loss: 0.08538 | Running loss: 0.41329\n",
      "Epoch: 9 | Iteration: 655 | Classification loss: 0.08523 | Regression loss: 0.32265 | Running loss: 0.41327\n",
      "Epoch: 9 | Iteration: 656 | Classification loss: 0.36492 | Regression loss: 0.19762 | Running loss: 0.41315\n",
      "Epoch: 9 | Iteration: 657 | Classification loss: 0.17976 | Regression loss: 0.22731 | Running loss: 0.41303\n",
      "Epoch: 9 | Iteration: 658 | Classification loss: 0.09810 | Regression loss: 0.25358 | Running loss: 0.41308\n",
      "Epoch: 9 | Iteration: 659 | Classification loss: 0.32058 | Regression loss: 0.25438 | Running loss: 0.41357\n",
      "Epoch: 9 | Iteration: 660 | Classification loss: 0.32635 | Regression loss: 0.48558 | Running loss: 0.41456\n",
      "Epoch: 9 | Iteration: 661 | Classification loss: 0.06892 | Regression loss: 0.29948 | Running loss: 0.41375\n",
      "Epoch: 9 | Iteration: 662 | Classification loss: 0.07333 | Regression loss: 0.25097 | Running loss: 0.41327\n",
      "Epoch: 9 | Iteration: 663 | Classification loss: 0.06369 | Regression loss: 0.30051 | Running loss: 0.41223\n",
      "Epoch: 9 | Iteration: 664 | Classification loss: 0.19055 | Regression loss: 0.36033 | Running loss: 0.41207\n",
      "Epoch: 9 | Iteration: 665 | Classification loss: 0.07324 | Regression loss: 0.22005 | Running loss: 0.41066\n",
      "Epoch: 9 | Iteration: 666 | Classification loss: 0.27751 | Regression loss: 0.18825 | Running loss: 0.41069\n",
      "Epoch: 9 | Iteration: 667 | Classification loss: 0.09536 | Regression loss: 0.21876 | Running loss: 0.41047\n",
      "Epoch: 9 | Iteration: 668 | Classification loss: 0.21103 | Regression loss: 0.44164 | Running loss: 0.41059\n",
      "Epoch: 9 | Iteration: 669 | Classification loss: 0.03702 | Regression loss: 0.19747 | Running loss: 0.41046\n",
      "Epoch: 9 | Iteration: 670 | Classification loss: 0.13043 | Regression loss: 0.17210 | Running loss: 0.41022\n",
      "Epoch: 9 | Iteration: 671 | Classification loss: 0.18263 | Regression loss: 0.30610 | Running loss: 0.41044\n",
      "Epoch: 9 | Iteration: 672 | Classification loss: 0.08528 | Regression loss: 0.26932 | Running loss: 0.41052\n",
      "Epoch: 9 | Iteration: 673 | Classification loss: 0.23430 | Regression loss: 0.13397 | Running loss: 0.41087\n",
      "Epoch: 9 | Iteration: 674 | Classification loss: 0.44396 | Regression loss: 0.37452 | Running loss: 0.41166\n",
      "Epoch: 9 | Iteration: 675 | Classification loss: 0.11572 | Regression loss: 0.41470 | Running loss: 0.41163\n",
      "Epoch: 9 | Iteration: 676 | Classification loss: 0.26468 | Regression loss: 0.18437 | Running loss: 0.41133\n",
      "Epoch: 9 | Iteration: 677 | Classification loss: 0.15793 | Regression loss: 0.43390 | Running loss: 0.41169\n",
      "Epoch: 9 | Iteration: 678 | Classification loss: 0.19516 | Regression loss: 0.21294 | Running loss: 0.41193\n",
      "Epoch: 9 | Iteration: 679 | Classification loss: 0.13285 | Regression loss: 0.21541 | Running loss: 0.41128\n",
      "Epoch: 9 | Iteration: 680 | Classification loss: 0.14213 | Regression loss: 0.27474 | Running loss: 0.41121\n",
      "Epoch: 9 | Iteration: 681 | Classification loss: 0.06915 | Regression loss: 0.25627 | Running loss: 0.41108\n",
      "Epoch: 9 | Iteration: 682 | Classification loss: 0.18357 | Regression loss: 0.31415 | Running loss: 0.41170\n",
      "Epoch: 9 | Iteration: 683 | Classification loss: 0.40947 | Regression loss: 0.59784 | Running loss: 0.41284\n",
      "Epoch: 9 | Iteration: 684 | Classification loss: 0.23495 | Regression loss: 0.37321 | Running loss: 0.41379\n",
      "Epoch: 9 | Iteration: 685 | Classification loss: 0.07515 | Regression loss: 0.21637 | Running loss: 0.41377\n",
      "Epoch: 9 | Iteration: 686 | Classification loss: 0.07725 | Regression loss: 0.25945 | Running loss: 0.41343\n",
      "Epoch: 9 | Iteration: 687 | Classification loss: 0.22877 | Regression loss: 0.17197 | Running loss: 0.41347\n",
      "Epoch: 9 | Iteration: 688 | Classification loss: 0.04844 | Regression loss: 0.18077 | Running loss: 0.41334\n",
      "Epoch: 9 | Iteration: 689 | Classification loss: 0.17963 | Regression loss: 0.19481 | Running loss: 0.41362\n",
      "Epoch: 9 | Iteration: 690 | Classification loss: 0.03241 | Regression loss: 0.14846 | Running loss: 0.41255\n",
      "Epoch: 9 | Iteration: 691 | Classification loss: 0.16554 | Regression loss: 0.16229 | Running loss: 0.41248\n",
      "Epoch: 9 | Iteration: 692 | Classification loss: 0.08051 | Regression loss: 0.16495 | Running loss: 0.41204\n",
      "Epoch: 9 | Iteration: 693 | Classification loss: 0.16001 | Regression loss: 0.28126 | Running loss: 0.41218\n",
      "Epoch: 9 | Iteration: 694 | Classification loss: 0.16838 | Regression loss: 0.45171 | Running loss: 0.41252\n",
      "Epoch: 9 | Iteration: 695 | Classification loss: 0.04785 | Regression loss: 0.24805 | Running loss: 0.41208\n",
      "Epoch: 9 | Iteration: 696 | Classification loss: 0.33493 | Regression loss: 0.34758 | Running loss: 0.41283\n",
      "Epoch: 9 | Iteration: 697 | Classification loss: 0.05527 | Regression loss: 0.12141 | Running loss: 0.41145\n",
      "Epoch: 9 | Iteration: 698 | Classification loss: 0.13592 | Regression loss: 0.24574 | Running loss: 0.41164\n",
      "Epoch: 9 | Iteration: 699 | Classification loss: 0.14039 | Regression loss: 0.51493 | Running loss: 0.41249\n",
      "Epoch: 9 | Iteration: 700 | Classification loss: 0.06625 | Regression loss: 0.15601 | Running loss: 0.41193\n",
      "Epoch: 9 | Iteration: 701 | Classification loss: 0.09153 | Regression loss: 0.31421 | Running loss: 0.41224\n",
      "Epoch: 9 | Iteration: 702 | Classification loss: 0.29533 | Regression loss: 0.07682 | Running loss: 0.41243\n",
      "Epoch: 9 | Iteration: 703 | Classification loss: 0.09344 | Regression loss: 0.33177 | Running loss: 0.41251\n",
      "Epoch: 9 | Iteration: 704 | Classification loss: 0.29404 | Regression loss: 0.38743 | Running loss: 0.41320\n",
      "Epoch: 9 | Iteration: 705 | Classification loss: 0.04945 | Regression loss: 0.18338 | Running loss: 0.41319\n",
      "Epoch: 9 | Iteration: 706 | Classification loss: 0.08965 | Regression loss: 0.23554 | Running loss: 0.41249\n",
      "Epoch: 9 | Iteration: 707 | Classification loss: 0.10364 | Regression loss: 0.31447 | Running loss: 0.41168\n",
      "Epoch: 9 | Iteration: 708 | Classification loss: 0.23649 | Regression loss: 0.42244 | Running loss: 0.41172\n",
      "Epoch: 9 | Iteration: 709 | Classification loss: 0.13023 | Regression loss: 0.18392 | Running loss: 0.41148\n",
      "Epoch: 9 | Iteration: 710 | Classification loss: 0.24379 | Regression loss: 0.29913 | Running loss: 0.41230\n",
      "Epoch: 9 | Iteration: 711 | Classification loss: 0.02897 | Regression loss: 0.11846 | Running loss: 0.41234\n",
      "Epoch: 9 | Iteration: 712 | Classification loss: 0.10673 | Regression loss: 0.12538 | Running loss: 0.41216\n",
      "Epoch: 9 | Iteration: 713 | Classification loss: 0.05982 | Regression loss: 0.18333 | Running loss: 0.41201\n",
      "Epoch: 9 | Iteration: 714 | Classification loss: 0.12871 | Regression loss: 0.18911 | Running loss: 0.41160\n",
      "Epoch: 9 | Iteration: 715 | Classification loss: 0.16531 | Regression loss: 0.21659 | Running loss: 0.41173\n",
      "Epoch: 9 | Iteration: 716 | Classification loss: 0.06884 | Regression loss: 0.13710 | Running loss: 0.41124\n",
      "Epoch: 9 | Iteration: 717 | Classification loss: 0.21347 | Regression loss: 0.58134 | Running loss: 0.41224\n",
      "Epoch: 9 | Iteration: 718 | Classification loss: 0.39698 | Regression loss: 0.26512 | Running loss: 0.41229\n",
      "Epoch: 9 | Iteration: 719 | Classification loss: 0.28229 | Regression loss: 0.23708 | Running loss: 0.41256\n",
      "Epoch: 9 | Iteration: 720 | Classification loss: 0.23687 | Regression loss: 0.41423 | Running loss: 0.41277\n",
      "Epoch: 9 | Iteration: 721 | Classification loss: 0.21185 | Regression loss: 0.35789 | Running loss: 0.41291\n",
      "Epoch: 9 | Iteration: 722 | Classification loss: 0.19410 | Regression loss: 0.47397 | Running loss: 0.41346\n",
      "Epoch: 9 | Iteration: 723 | Classification loss: 0.04319 | Regression loss: 0.18265 | Running loss: 0.41338\n",
      "Epoch: 9 | Iteration: 724 | Classification loss: 0.08558 | Regression loss: 0.28999 | Running loss: 0.41273\n",
      "Epoch: 9 | Iteration: 725 | Classification loss: 0.13289 | Regression loss: 0.34587 | Running loss: 0.41234\n",
      "Epoch: 9 | Iteration: 726 | Classification loss: 0.16086 | Regression loss: 0.31339 | Running loss: 0.41280\n",
      "Epoch: 9 | Iteration: 727 | Classification loss: 0.27572 | Regression loss: 0.26626 | Running loss: 0.41305\n",
      "Epoch: 9 | Iteration: 728 | Classification loss: 0.06701 | Regression loss: 0.19104 | Running loss: 0.41272\n",
      "Epoch: 9 | Iteration: 729 | Classification loss: 0.26688 | Regression loss: 0.27887 | Running loss: 0.41330\n",
      "Epoch: 9 | Iteration: 730 | Classification loss: 0.13248 | Regression loss: 0.35226 | Running loss: 0.41339\n",
      "Epoch: 9 | Iteration: 731 | Classification loss: 0.12940 | Regression loss: 0.30032 | Running loss: 0.41425\n",
      "Epoch: 9 | Iteration: 732 | Classification loss: 0.09617 | Regression loss: 0.49755 | Running loss: 0.41468\n",
      "Epoch: 9 | Iteration: 733 | Classification loss: 0.22589 | Regression loss: 0.44106 | Running loss: 0.41550\n",
      "Epoch: 9 | Iteration: 734 | Classification loss: 0.39943 | Regression loss: 0.27945 | Running loss: 0.41636\n",
      "Epoch: 9 | Iteration: 735 | Classification loss: 0.07530 | Regression loss: 0.24438 | Running loss: 0.41630\n",
      "Epoch: 9 | Iteration: 736 | Classification loss: 0.17380 | Regression loss: 0.37893 | Running loss: 0.41678\n",
      "Epoch: 9 | Iteration: 737 | Classification loss: 0.16725 | Regression loss: 0.32436 | Running loss: 0.41719\n",
      "Epoch: 9 | Iteration: 738 | Classification loss: 0.42358 | Regression loss: 0.14114 | Running loss: 0.41763\n",
      "Epoch: 9 | Iteration: 739 | Classification loss: 0.13381 | Regression loss: 0.38106 | Running loss: 0.41711\n",
      "Epoch: 9 | Iteration: 740 | Classification loss: 0.11598 | Regression loss: 0.14696 | Running loss: 0.41660\n",
      "Epoch: 9 | Iteration: 741 | Classification loss: 0.11854 | Regression loss: 0.18090 | Running loss: 0.41621\n",
      "Epoch: 9 | Iteration: 742 | Classification loss: 0.15304 | Regression loss: 0.32339 | Running loss: 0.41649\n",
      "Epoch: 9 | Iteration: 743 | Classification loss: 0.25891 | Regression loss: 0.22398 | Running loss: 0.41633\n",
      "Epoch: 9 | Iteration: 744 | Classification loss: 0.12530 | Regression loss: 0.23389 | Running loss: 0.41640\n",
      "Epoch: 9 | Iteration: 745 | Classification loss: 0.12729 | Regression loss: 0.59651 | Running loss: 0.41730\n",
      "Epoch: 9 | Iteration: 746 | Classification loss: 0.31235 | Regression loss: 0.23320 | Running loss: 0.41729\n",
      "Epoch: 9 | Iteration: 747 | Classification loss: 0.23015 | Regression loss: 0.27506 | Running loss: 0.41729\n",
      "Epoch: 9 | Iteration: 748 | Classification loss: 0.05834 | Regression loss: 0.34378 | Running loss: 0.41712\n",
      "Epoch: 9 | Iteration: 749 | Classification loss: 0.07110 | Regression loss: 0.21159 | Running loss: 0.41663\n",
      "Epoch: 9 | Iteration: 750 | Classification loss: 0.28924 | Regression loss: 0.64834 | Running loss: 0.41652\n",
      "Epoch: 9 | Iteration: 751 | Classification loss: 0.12911 | Regression loss: 0.29084 | Running loss: 0.41695\n",
      "Epoch: 9 | Iteration: 752 | Classification loss: 0.26874 | Regression loss: 0.43091 | Running loss: 0.41781\n",
      "Epoch: 9 | Iteration: 753 | Classification loss: 0.08323 | Regression loss: 0.16674 | Running loss: 0.41710\n",
      "Epoch: 9 | Iteration: 754 | Classification loss: 0.25491 | Regression loss: 0.32326 | Running loss: 0.41720\n",
      "Epoch: 9 | Iteration: 755 | Classification loss: 0.11405 | Regression loss: 0.19627 | Running loss: 0.41704\n",
      "Epoch: 9 | Iteration: 756 | Classification loss: 0.08485 | Regression loss: 0.20321 | Running loss: 0.41663\n",
      "Epoch: 9 | Iteration: 757 | Classification loss: 0.20435 | Regression loss: 0.24101 | Running loss: 0.41706\n",
      "Epoch: 9 | Iteration: 758 | Classification loss: 0.30813 | Regression loss: 0.20229 | Running loss: 0.41722\n",
      "Epoch: 9 | Iteration: 759 | Classification loss: 0.18180 | Regression loss: 0.34090 | Running loss: 0.41793\n",
      "Epoch: 9 | Iteration: 760 | Classification loss: 0.39423 | Regression loss: 0.38224 | Running loss: 0.41916\n",
      "Epoch: 9 | Iteration: 761 | Classification loss: 0.02834 | Regression loss: 0.20598 | Running loss: 0.41888\n",
      "Epoch: 9 | Iteration: 762 | Classification loss: 0.08344 | Regression loss: 0.09797 | Running loss: 0.41886\n",
      "Epoch: 9 | Iteration: 763 | Classification loss: 0.03275 | Regression loss: 0.14966 | Running loss: 0.41851\n",
      "Epoch: 9 | Iteration: 764 | Classification loss: 0.06375 | Regression loss: 0.20085 | Running loss: 0.41809\n",
      "Epoch: 9 | Iteration: 765 | Classification loss: 0.05231 | Regression loss: 0.21228 | Running loss: 0.41742\n",
      "Epoch: 9 | Iteration: 766 | Classification loss: 0.06926 | Regression loss: 0.35349 | Running loss: 0.41788\n",
      "Epoch: 9 | Iteration: 767 | Classification loss: 0.16588 | Regression loss: 0.39412 | Running loss: 0.41818\n",
      "Epoch: 9 | Iteration: 768 | Classification loss: 0.23336 | Regression loss: 0.37759 | Running loss: 0.41857\n",
      "Epoch: 9 | Iteration: 769 | Classification loss: 0.06908 | Regression loss: 0.28869 | Running loss: 0.41890\n",
      "Epoch: 9 | Iteration: 770 | Classification loss: 0.08057 | Regression loss: 0.09169 | Running loss: 0.41848\n",
      "Epoch: 9 | Iteration: 771 | Classification loss: 0.11299 | Regression loss: 0.24887 | Running loss: 0.41847\n",
      "Epoch: 9 | Iteration: 772 | Classification loss: 0.29426 | Regression loss: 0.32418 | Running loss: 0.41906\n",
      "Epoch: 9 | Iteration: 773 | Classification loss: 0.02800 | Regression loss: 0.12456 | Running loss: 0.41798\n",
      "Epoch: 9 | Iteration: 774 | Classification loss: 0.16207 | Regression loss: 0.29446 | Running loss: 0.41737\n",
      "Epoch: 9 | Iteration: 775 | Classification loss: 0.07392 | Regression loss: 0.28921 | Running loss: 0.41738\n",
      "Epoch: 9 | Iteration: 776 | Classification loss: 0.06751 | Regression loss: 0.30603 | Running loss: 0.41760\n",
      "Epoch: 9 | Iteration: 777 | Classification loss: 0.29472 | Regression loss: 0.47810 | Running loss: 0.41848\n",
      "Epoch: 9 | Iteration: 778 | Classification loss: 0.25829 | Regression loss: 0.20468 | Running loss: 0.41910\n",
      "Epoch: 9 | Iteration: 779 | Classification loss: 0.06944 | Regression loss: 0.17847 | Running loss: 0.41836\n",
      "Epoch: 9 | Iteration: 780 | Classification loss: 0.11916 | Regression loss: 0.20112 | Running loss: 0.41841\n",
      "Epoch: 9 | Iteration: 781 | Classification loss: 0.12382 | Regression loss: 0.19911 | Running loss: 0.41788\n",
      "Epoch: 9 | Iteration: 782 | Classification loss: 0.07446 | Regression loss: 0.16888 | Running loss: 0.41749\n",
      "Epoch: 9 | Iteration: 783 | Classification loss: 0.07974 | Regression loss: 0.21540 | Running loss: 0.41732\n",
      "Epoch: 9 | Iteration: 784 | Classification loss: 0.13788 | Regression loss: 0.33412 | Running loss: 0.41603\n",
      "Epoch: 9 | Iteration: 785 | Classification loss: 0.24473 | Regression loss: 0.26430 | Running loss: 0.41671\n",
      "Epoch: 9 | Iteration: 786 | Classification loss: 0.06575 | Regression loss: 0.15510 | Running loss: 0.41633\n",
      "Epoch: 9 | Iteration: 787 | Classification loss: 0.39282 | Regression loss: 0.12896 | Running loss: 0.41680\n",
      "Epoch: 9 | Iteration: 788 | Classification loss: 0.13298 | Regression loss: 0.22929 | Running loss: 0.41660\n",
      "Epoch: 9 | Iteration: 789 | Classification loss: 0.13270 | Regression loss: 0.33122 | Running loss: 0.41695\n",
      "Epoch: 9 | Iteration: 790 | Classification loss: 0.07736 | Regression loss: 0.40952 | Running loss: 0.41729\n",
      "Epoch: 9 | Iteration: 791 | Classification loss: 0.31579 | Regression loss: 0.63425 | Running loss: 0.41850\n",
      "Epoch: 9 | Iteration: 792 | Classification loss: 0.23856 | Regression loss: 0.13245 | Running loss: 0.41852\n",
      "Epoch: 9 | Iteration: 793 | Classification loss: 0.22044 | Regression loss: 0.31664 | Running loss: 0.41851\n",
      "Epoch: 9 | Iteration: 794 | Classification loss: 0.12440 | Regression loss: 0.32702 | Running loss: 0.41793\n",
      "Epoch: 9 | Iteration: 795 | Classification loss: 0.07061 | Regression loss: 0.19323 | Running loss: 0.41789\n",
      "Epoch: 9 | Iteration: 796 | Classification loss: 0.04623 | Regression loss: 0.22001 | Running loss: 0.41798\n",
      "Epoch: 9 | Iteration: 797 | Classification loss: 0.16123 | Regression loss: 0.19115 | Running loss: 0.41835\n",
      "Epoch: 9 | Iteration: 798 | Classification loss: 0.09845 | Regression loss: 0.20999 | Running loss: 0.41858\n",
      "Epoch: 9 | Iteration: 799 | Classification loss: 0.04682 | Regression loss: 0.14464 | Running loss: 0.41811\n",
      "Epoch: 9 | Iteration: 800 | Classification loss: 0.22423 | Regression loss: 0.09920 | Running loss: 0.41728\n",
      "Epoch: 9 | Iteration: 801 | Classification loss: 0.11122 | Regression loss: 0.16940 | Running loss: 0.41686\n",
      "Epoch: 9 | Iteration: 802 | Classification loss: 0.34388 | Regression loss: 0.67362 | Running loss: 0.41807\n",
      "Epoch: 9 | Iteration: 803 | Classification loss: 0.08003 | Regression loss: 0.17612 | Running loss: 0.41786\n",
      "Epoch: 9 | Iteration: 804 | Classification loss: 0.12766 | Regression loss: 0.20015 | Running loss: 0.41767\n",
      "Epoch: 9 | Iteration: 805 | Classification loss: 0.13473 | Regression loss: 0.18533 | Running loss: 0.41770\n",
      "Epoch: 9 | Iteration: 806 | Classification loss: 0.05253 | Regression loss: 0.12648 | Running loss: 0.41672\n",
      "Epoch: 9 | Iteration: 807 | Classification loss: 0.07508 | Regression loss: 0.12843 | Running loss: 0.41654\n",
      "Epoch: 9 | Iteration: 808 | Classification loss: 0.05476 | Regression loss: 0.20087 | Running loss: 0.41628\n",
      "Epoch: 9 | Iteration: 809 | Classification loss: 0.03690 | Regression loss: 0.21355 | Running loss: 0.41608\n",
      "Epoch: 9 | Iteration: 810 | Classification loss: 0.08521 | Regression loss: 0.24227 | Running loss: 0.41606\n",
      "Epoch: 9 | Iteration: 811 | Classification loss: 0.21797 | Regression loss: 0.54776 | Running loss: 0.41673\n",
      "Epoch: 9 | Iteration: 812 | Classification loss: 0.08739 | Regression loss: 0.26304 | Running loss: 0.41661\n",
      "Epoch: 9 | Iteration: 813 | Classification loss: 0.03538 | Regression loss: 0.21391 | Running loss: 0.41668\n",
      "Epoch: 9 | Iteration: 814 | Classification loss: 0.15375 | Regression loss: 0.42915 | Running loss: 0.41753\n",
      "Epoch: 9 | Iteration: 815 | Classification loss: 0.08578 | Regression loss: 0.29134 | Running loss: 0.41782\n",
      "Epoch: 9 | Iteration: 816 | Classification loss: 0.04032 | Regression loss: 0.23610 | Running loss: 0.41775\n",
      "Epoch: 9 | Iteration: 817 | Classification loss: 0.04511 | Regression loss: 0.21581 | Running loss: 0.41771\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 10 | Iteration: 0 | Classification loss: 0.08941 | Regression loss: 0.27629 | Running loss: 0.41765\n",
      "Epoch: 10 | Iteration: 1 | Classification loss: 0.26844 | Regression loss: 0.24275 | Running loss: 0.41753\n",
      "Epoch: 10 | Iteration: 2 | Classification loss: 0.10144 | Regression loss: 0.27977 | Running loss: 0.41797\n",
      "Epoch: 10 | Iteration: 3 | Classification loss: 0.13970 | Regression loss: 0.27157 | Running loss: 0.41788\n",
      "Epoch: 10 | Iteration: 4 | Classification loss: 0.13814 | Regression loss: 0.19521 | Running loss: 0.41760\n",
      "Epoch: 10 | Iteration: 5 | Classification loss: 0.23857 | Regression loss: 0.54327 | Running loss: 0.41846\n",
      "Epoch: 10 | Iteration: 6 | Classification loss: 0.01923 | Regression loss: 0.16745 | Running loss: 0.41796\n",
      "Epoch: 10 | Iteration: 7 | Classification loss: 0.12916 | Regression loss: 0.30123 | Running loss: 0.41811\n",
      "Epoch: 10 | Iteration: 8 | Classification loss: 0.18703 | Regression loss: 0.19909 | Running loss: 0.41836\n",
      "Epoch: 10 | Iteration: 9 | Classification loss: 0.06546 | Regression loss: 0.42138 | Running loss: 0.41878\n",
      "Epoch: 10 | Iteration: 10 | Classification loss: 0.05248 | Regression loss: 0.19714 | Running loss: 0.41846\n",
      "Epoch: 10 | Iteration: 11 | Classification loss: 0.08874 | Regression loss: 0.27088 | Running loss: 0.41837\n",
      "Epoch: 10 | Iteration: 12 | Classification loss: 0.10947 | Regression loss: 0.29027 | Running loss: 0.41848\n",
      "Epoch: 10 | Iteration: 13 | Classification loss: 0.04563 | Regression loss: 0.23098 | Running loss: 0.41844\n",
      "Epoch: 10 | Iteration: 14 | Classification loss: 0.08731 | Regression loss: 0.37536 | Running loss: 0.41799\n",
      "Epoch: 10 | Iteration: 15 | Classification loss: 0.08605 | Regression loss: 0.29182 | Running loss: 0.41828\n",
      "Epoch: 10 | Iteration: 16 | Classification loss: 0.18753 | Regression loss: 0.21858 | Running loss: 0.41811\n",
      "Epoch: 10 | Iteration: 17 | Classification loss: 0.03027 | Regression loss: 0.26501 | Running loss: 0.41803\n",
      "Epoch: 10 | Iteration: 18 | Classification loss: 0.23250 | Regression loss: 0.42803 | Running loss: 0.41847\n",
      "Epoch: 10 | Iteration: 19 | Classification loss: 0.22599 | Regression loss: 0.27064 | Running loss: 0.41889\n",
      "Epoch: 10 | Iteration: 20 | Classification loss: 0.04830 | Regression loss: 0.10129 | Running loss: 0.41823\n",
      "Epoch: 10 | Iteration: 21 | Classification loss: 0.09771 | Regression loss: 0.43344 | Running loss: 0.41857\n",
      "Epoch: 10 | Iteration: 22 | Classification loss: 0.05581 | Regression loss: 0.16626 | Running loss: 0.41830\n",
      "Epoch: 10 | Iteration: 23 | Classification loss: 0.22768 | Regression loss: 0.20452 | Running loss: 0.41868\n",
      "Epoch: 10 | Iteration: 24 | Classification loss: 0.23094 | Regression loss: 0.22660 | Running loss: 0.41927\n",
      "Epoch: 10 | Iteration: 25 | Classification loss: 0.08920 | Regression loss: 0.30856 | Running loss: 0.41918\n",
      "Epoch: 10 | Iteration: 26 | Classification loss: 0.09798 | Regression loss: 0.20578 | Running loss: 0.41931\n",
      "Epoch: 10 | Iteration: 27 | Classification loss: 0.06771 | Regression loss: 0.26699 | Running loss: 0.41900\n",
      "Epoch: 10 | Iteration: 28 | Classification loss: 0.12989 | Regression loss: 0.27480 | Running loss: 0.41922\n",
      "Epoch: 10 | Iteration: 29 | Classification loss: 0.07431 | Regression loss: 0.19647 | Running loss: 0.41908\n",
      "Epoch: 10 | Iteration: 30 | Classification loss: 0.05344 | Regression loss: 0.12945 | Running loss: 0.41819\n",
      "Epoch: 10 | Iteration: 31 | Classification loss: 0.13297 | Regression loss: 0.22492 | Running loss: 0.41827\n",
      "Epoch: 10 | Iteration: 32 | Classification loss: 0.12921 | Regression loss: 0.15521 | Running loss: 0.41800\n",
      "Epoch: 10 | Iteration: 33 | Classification loss: 0.11329 | Regression loss: 0.10713 | Running loss: 0.41761\n",
      "Epoch: 10 | Iteration: 34 | Classification loss: 0.05009 | Regression loss: 0.26854 | Running loss: 0.41736\n",
      "Epoch: 10 | Iteration: 35 | Classification loss: 0.08053 | Regression loss: 0.23748 | Running loss: 0.41754\n",
      "Epoch: 10 | Iteration: 36 | Classification loss: 0.09494 | Regression loss: 0.21271 | Running loss: 0.41719\n",
      "Epoch: 10 | Iteration: 37 | Classification loss: 0.07021 | Regression loss: 0.23674 | Running loss: 0.41717\n",
      "Epoch: 10 | Iteration: 38 | Classification loss: 0.22603 | Regression loss: 0.34799 | Running loss: 0.41777\n",
      "Epoch: 10 | Iteration: 39 | Classification loss: 0.03446 | Regression loss: 0.23911 | Running loss: 0.41744\n",
      "Epoch: 10 | Iteration: 40 | Classification loss: 0.08367 | Regression loss: 0.21203 | Running loss: 0.41737\n",
      "Epoch: 10 | Iteration: 41 | Classification loss: 0.05579 | Regression loss: 0.28225 | Running loss: 0.41723\n",
      "Epoch: 10 | Iteration: 42 | Classification loss: 0.10140 | Regression loss: 0.20388 | Running loss: 0.41684\n",
      "Epoch: 10 | Iteration: 43 | Classification loss: 0.12815 | Regression loss: 0.27006 | Running loss: 0.41696\n",
      "Epoch: 10 | Iteration: 44 | Classification loss: 0.08614 | Regression loss: 0.12658 | Running loss: 0.41681\n",
      "Epoch: 10 | Iteration: 45 | Classification loss: 0.11375 | Regression loss: 0.12277 | Running loss: 0.41680\n",
      "Epoch: 10 | Iteration: 46 | Classification loss: 0.05634 | Regression loss: 0.17066 | Running loss: 0.41678\n",
      "Epoch: 10 | Iteration: 47 | Classification loss: 0.05579 | Regression loss: 0.30913 | Running loss: 0.41712\n",
      "Epoch: 10 | Iteration: 48 | Classification loss: 0.08933 | Regression loss: 0.25052 | Running loss: 0.41722\n",
      "Epoch: 10 | Iteration: 49 | Classification loss: 0.14829 | Regression loss: 0.26736 | Running loss: 0.41716\n",
      "Epoch: 10 | Iteration: 50 | Classification loss: 0.05273 | Regression loss: 0.33216 | Running loss: 0.41676\n",
      "Epoch: 10 | Iteration: 51 | Classification loss: 0.16873 | Regression loss: 0.25527 | Running loss: 0.41632\n",
      "Epoch: 10 | Iteration: 52 | Classification loss: 0.10629 | Regression loss: 0.30346 | Running loss: 0.41668\n",
      "Epoch: 10 | Iteration: 53 | Classification loss: 0.07324 | Regression loss: 0.16574 | Running loss: 0.41623\n",
      "Epoch: 10 | Iteration: 54 | Classification loss: 0.05403 | Regression loss: 0.14485 | Running loss: 0.41590\n",
      "Epoch: 10 | Iteration: 55 | Classification loss: 0.04790 | Regression loss: 0.14465 | Running loss: 0.41563\n",
      "Epoch: 10 | Iteration: 56 | Classification loss: 0.02981 | Regression loss: 0.12282 | Running loss: 0.41560\n",
      "Epoch: 10 | Iteration: 57 | Classification loss: 0.03758 | Regression loss: 0.14310 | Running loss: 0.41519\n",
      "Epoch: 10 | Iteration: 58 | Classification loss: 0.10179 | Regression loss: 0.39015 | Running loss: 0.41497\n",
      "Epoch: 10 | Iteration: 59 | Classification loss: 0.26380 | Regression loss: 0.50872 | Running loss: 0.41577\n",
      "Epoch: 10 | Iteration: 60 | Classification loss: 0.12317 | Regression loss: 0.28013 | Running loss: 0.41555\n",
      "Epoch: 10 | Iteration: 61 | Classification loss: 0.07049 | Regression loss: 0.19899 | Running loss: 0.41522\n",
      "Epoch: 10 | Iteration: 62 | Classification loss: 0.07023 | Regression loss: 0.23266 | Running loss: 0.41481\n",
      "Epoch: 10 | Iteration: 63 | Classification loss: 0.11734 | Regression loss: 0.53961 | Running loss: 0.41438\n",
      "Epoch: 10 | Iteration: 64 | Classification loss: 0.29522 | Regression loss: 0.08446 | Running loss: 0.41385\n",
      "Epoch: 10 | Iteration: 65 | Classification loss: 0.19931 | Regression loss: 0.36791 | Running loss: 0.41415\n",
      "Epoch: 10 | Iteration: 66 | Classification loss: 0.04918 | Regression loss: 0.12527 | Running loss: 0.41414\n",
      "Epoch: 10 | Iteration: 67 | Classification loss: 0.10928 | Regression loss: 0.41645 | Running loss: 0.41440\n",
      "Epoch: 10 | Iteration: 68 | Classification loss: 0.05667 | Regression loss: 0.14594 | Running loss: 0.41435\n",
      "Epoch: 10 | Iteration: 69 | Classification loss: 0.07677 | Regression loss: 0.27374 | Running loss: 0.41455\n",
      "Epoch: 10 | Iteration: 70 | Classification loss: 0.11289 | Regression loss: 0.30649 | Running loss: 0.41449\n",
      "Epoch: 10 | Iteration: 71 | Classification loss: 0.02560 | Regression loss: 0.25096 | Running loss: 0.41437\n",
      "Epoch: 10 | Iteration: 72 | Classification loss: 0.21400 | Regression loss: 0.22562 | Running loss: 0.41454\n",
      "Epoch: 10 | Iteration: 73 | Classification loss: 0.06953 | Regression loss: 0.21707 | Running loss: 0.41483\n",
      "Epoch: 10 | Iteration: 74 | Classification loss: 0.00004 | Regression loss: 0.00000 | Running loss: 0.41374\n",
      "Epoch: 10 | Iteration: 75 | Classification loss: 0.06189 | Regression loss: 0.22042 | Running loss: 0.41373\n",
      "Epoch: 10 | Iteration: 76 | Classification loss: 0.04873 | Regression loss: 0.13332 | Running loss: 0.41360\n",
      "Epoch: 10 | Iteration: 77 | Classification loss: 0.01988 | Regression loss: 0.17930 | Running loss: 0.41354\n",
      "Epoch: 10 | Iteration: 78 | Classification loss: 0.08345 | Regression loss: 0.10279 | Running loss: 0.41352\n",
      "Epoch: 10 | Iteration: 79 | Classification loss: 0.03432 | Regression loss: 0.07628 | Running loss: 0.41275\n",
      "Epoch: 10 | Iteration: 80 | Classification loss: 0.06290 | Regression loss: 0.27036 | Running loss: 0.41273\n",
      "Epoch: 10 | Iteration: 81 | Classification loss: 0.10609 | Regression loss: 0.36163 | Running loss: 0.41238\n",
      "Epoch: 10 | Iteration: 82 | Classification loss: 0.08948 | Regression loss: 0.30018 | Running loss: 0.41245\n",
      "Epoch: 10 | Iteration: 83 | Classification loss: 0.10498 | Regression loss: 0.28960 | Running loss: 0.41168\n",
      "Epoch: 10 | Iteration: 84 | Classification loss: 0.10995 | Regression loss: 0.30396 | Running loss: 0.41119\n",
      "Epoch: 10 | Iteration: 85 | Classification loss: 0.06340 | Regression loss: 0.10757 | Running loss: 0.41052\n",
      "Epoch: 10 | Iteration: 86 | Classification loss: 0.13595 | Regression loss: 0.28823 | Running loss: 0.41008\n",
      "Epoch: 10 | Iteration: 87 | Classification loss: 0.03249 | Regression loss: 0.16601 | Running loss: 0.40976\n",
      "Epoch: 10 | Iteration: 88 | Classification loss: 0.12436 | Regression loss: 0.29228 | Running loss: 0.40935\n",
      "Epoch: 10 | Iteration: 89 | Classification loss: 0.13181 | Regression loss: 0.23357 | Running loss: 0.40948\n",
      "Epoch: 10 | Iteration: 90 | Classification loss: 0.28460 | Regression loss: 0.42940 | Running loss: 0.41044\n",
      "Epoch: 10 | Iteration: 91 | Classification loss: 0.07145 | Regression loss: 0.11383 | Running loss: 0.40970\n",
      "Epoch: 10 | Iteration: 92 | Classification loss: 0.04577 | Regression loss: 0.18185 | Running loss: 0.40889\n",
      "Epoch: 10 | Iteration: 93 | Classification loss: 0.11669 | Regression loss: 0.33709 | Running loss: 0.40919\n",
      "Epoch: 10 | Iteration: 94 | Classification loss: 0.07476 | Regression loss: 0.29401 | Running loss: 0.40802\n",
      "Epoch: 10 | Iteration: 95 | Classification loss: 0.03649 | Regression loss: 0.16472 | Running loss: 0.40743\n",
      "Epoch: 10 | Iteration: 96 | Classification loss: 0.02553 | Regression loss: 0.19184 | Running loss: 0.40674\n",
      "Epoch: 10 | Iteration: 97 | Classification loss: 0.02904 | Regression loss: 0.12005 | Running loss: 0.40663\n",
      "Epoch: 10 | Iteration: 98 | Classification loss: 0.00501 | Regression loss: 0.00000 | Running loss: 0.40590\n",
      "Epoch: 10 | Iteration: 99 | Classification loss: 0.02258 | Regression loss: 0.17562 | Running loss: 0.40541\n",
      "Epoch: 10 | Iteration: 100 | Classification loss: 0.06761 | Regression loss: 0.33393 | Running loss: 0.40530\n",
      "Epoch: 10 | Iteration: 101 | Classification loss: 0.04195 | Regression loss: 0.20890 | Running loss: 0.40543\n",
      "Epoch: 10 | Iteration: 102 | Classification loss: 0.17476 | Regression loss: 0.16620 | Running loss: 0.40541\n",
      "Epoch: 10 | Iteration: 103 | Classification loss: 0.07603 | Regression loss: 0.16009 | Running loss: 0.40445\n",
      "Epoch: 10 | Iteration: 104 | Classification loss: 0.05991 | Regression loss: 0.13472 | Running loss: 0.40249\n",
      "Epoch: 10 | Iteration: 105 | Classification loss: 0.03183 | Regression loss: 0.13125 | Running loss: 0.40150\n",
      "Epoch: 10 | Iteration: 106 | Classification loss: 0.08286 | Regression loss: 0.18550 | Running loss: 0.40152\n",
      "Epoch: 10 | Iteration: 107 | Classification loss: 0.11457 | Regression loss: 0.19643 | Running loss: 0.40090\n",
      "Epoch: 10 | Iteration: 108 | Classification loss: 0.11077 | Regression loss: 0.31339 | Running loss: 0.40117\n",
      "Epoch: 10 | Iteration: 109 | Classification loss: 0.07484 | Regression loss: 0.19510 | Running loss: 0.40120\n",
      "Epoch: 10 | Iteration: 110 | Classification loss: 0.05150 | Regression loss: 0.31880 | Running loss: 0.40141\n",
      "Epoch: 10 | Iteration: 111 | Classification loss: 0.10318 | Regression loss: 0.28972 | Running loss: 0.40136\n",
      "Epoch: 10 | Iteration: 112 | Classification loss: 0.16706 | Regression loss: 0.32698 | Running loss: 0.40070\n",
      "Epoch: 10 | Iteration: 113 | Classification loss: 0.35818 | Regression loss: 0.11630 | Running loss: 0.40077\n",
      "Epoch: 10 | Iteration: 114 | Classification loss: 0.17954 | Regression loss: 0.21203 | Running loss: 0.40070\n",
      "Epoch: 10 | Iteration: 115 | Classification loss: 0.09789 | Regression loss: 0.21717 | Running loss: 0.40052\n",
      "Epoch: 10 | Iteration: 116 | Classification loss: 0.08627 | Regression loss: 0.15969 | Running loss: 0.40062\n",
      "Epoch: 10 | Iteration: 117 | Classification loss: 0.04179 | Regression loss: 0.16235 | Running loss: 0.40030\n",
      "Epoch: 10 | Iteration: 118 | Classification loss: 0.26608 | Regression loss: 0.18489 | Running loss: 0.39947\n",
      "Epoch: 10 | Iteration: 119 | Classification loss: 0.34112 | Regression loss: 0.21055 | Running loss: 0.40003\n",
      "Epoch: 10 | Iteration: 120 | Classification loss: 0.09392 | Regression loss: 0.24900 | Running loss: 0.39938\n",
      "Epoch: 10 | Iteration: 121 | Classification loss: 0.05898 | Regression loss: 0.10467 | Running loss: 0.39890\n",
      "Epoch: 10 | Iteration: 122 | Classification loss: 0.09036 | Regression loss: 0.26855 | Running loss: 0.39828\n",
      "Epoch: 10 | Iteration: 123 | Classification loss: 0.18091 | Regression loss: 0.23094 | Running loss: 0.39761\n",
      "Epoch: 10 | Iteration: 124 | Classification loss: 0.16636 | Regression loss: 0.38516 | Running loss: 0.39805\n",
      "Epoch: 10 | Iteration: 125 | Classification loss: 0.29803 | Regression loss: 0.44085 | Running loss: 0.39885\n",
      "Epoch: 10 | Iteration: 126 | Classification loss: 0.01998 | Regression loss: 0.06767 | Running loss: 0.39787\n",
      "Epoch: 10 | Iteration: 127 | Classification loss: 0.23822 | Regression loss: 0.20279 | Running loss: 0.39728\n",
      "Epoch: 10 | Iteration: 128 | Classification loss: 0.03097 | Regression loss: 0.27372 | Running loss: 0.39738\n",
      "Epoch: 10 | Iteration: 129 | Classification loss: 0.08185 | Regression loss: 0.13757 | Running loss: 0.39737\n",
      "Epoch: 10 | Iteration: 130 | Classification loss: 0.10681 | Regression loss: 0.29863 | Running loss: 0.39743\n",
      "Epoch: 10 | Iteration: 131 | Classification loss: 0.06853 | Regression loss: 0.42745 | Running loss: 0.39787\n",
      "Epoch: 10 | Iteration: 132 | Classification loss: 0.06372 | Regression loss: 0.34954 | Running loss: 0.39691\n",
      "Epoch: 10 | Iteration: 133 | Classification loss: 0.17179 | Regression loss: 0.24143 | Running loss: 0.39711\n",
      "Epoch: 10 | Iteration: 134 | Classification loss: 0.05003 | Regression loss: 0.24258 | Running loss: 0.39707\n",
      "Epoch: 10 | Iteration: 135 | Classification loss: 0.04023 | Regression loss: 0.17389 | Running loss: 0.39680\n",
      "Epoch: 10 | Iteration: 136 | Classification loss: 0.03473 | Regression loss: 0.20224 | Running loss: 0.39602\n",
      "Epoch: 10 | Iteration: 137 | Classification loss: 0.07089 | Regression loss: 0.19704 | Running loss: 0.39583\n",
      "Epoch: 10 | Iteration: 138 | Classification loss: 0.17371 | Regression loss: 0.31552 | Running loss: 0.39618\n",
      "Epoch: 10 | Iteration: 139 | Classification loss: 0.05778 | Regression loss: 0.24193 | Running loss: 0.39544\n",
      "Epoch: 10 | Iteration: 140 | Classification loss: 0.04184 | Regression loss: 0.21405 | Running loss: 0.39518\n",
      "Epoch: 10 | Iteration: 141 | Classification loss: 0.29992 | Regression loss: 0.23089 | Running loss: 0.39556\n",
      "Epoch: 10 | Iteration: 142 | Classification loss: 0.11599 | Regression loss: 0.32022 | Running loss: 0.39580\n",
      "Epoch: 10 | Iteration: 143 | Classification loss: 0.06887 | Regression loss: 0.19071 | Running loss: 0.39579\n",
      "Epoch: 10 | Iteration: 144 | Classification loss: 0.02768 | Regression loss: 0.19350 | Running loss: 0.39484\n",
      "Epoch: 10 | Iteration: 145 | Classification loss: 0.08830 | Regression loss: 0.24209 | Running loss: 0.39475\n",
      "Epoch: 10 | Iteration: 146 | Classification loss: 0.21627 | Regression loss: 0.10989 | Running loss: 0.39430\n",
      "Epoch: 10 | Iteration: 147 | Classification loss: 0.04365 | Regression loss: 0.22045 | Running loss: 0.39387\n",
      "Epoch: 10 | Iteration: 148 | Classification loss: 0.03440 | Regression loss: 0.18227 | Running loss: 0.39352\n",
      "Epoch: 10 | Iteration: 149 | Classification loss: 0.08797 | Regression loss: 0.17092 | Running loss: 0.39264\n",
      "Epoch: 10 | Iteration: 150 | Classification loss: 0.05683 | Regression loss: 0.24743 | Running loss: 0.39204\n",
      "Epoch: 10 | Iteration: 151 | Classification loss: 0.04017 | Regression loss: 0.07907 | Running loss: 0.39158\n",
      "Epoch: 10 | Iteration: 152 | Classification loss: 0.10748 | Regression loss: 0.19560 | Running loss: 0.39138\n",
      "Epoch: 10 | Iteration: 153 | Classification loss: 0.26300 | Regression loss: 0.24543 | Running loss: 0.39141\n",
      "Epoch: 10 | Iteration: 154 | Classification loss: 0.16834 | Regression loss: 0.22140 | Running loss: 0.39136\n",
      "Epoch: 10 | Iteration: 155 | Classification loss: 0.06401 | Regression loss: 0.14377 | Running loss: 0.39066\n",
      "Epoch: 10 | Iteration: 156 | Classification loss: 0.04959 | Regression loss: 0.14398 | Running loss: 0.39041\n",
      "Epoch: 10 | Iteration: 157 | Classification loss: 0.09949 | Regression loss: 0.28250 | Running loss: 0.39051\n",
      "Epoch: 10 | Iteration: 158 | Classification loss: 0.13076 | Regression loss: 0.21419 | Running loss: 0.39044\n",
      "Epoch: 10 | Iteration: 159 | Classification loss: 0.17441 | Regression loss: 0.35006 | Running loss: 0.39087\n",
      "Epoch: 10 | Iteration: 160 | Classification loss: 0.22109 | Regression loss: 0.50333 | Running loss: 0.39171\n",
      "Epoch: 10 | Iteration: 161 | Classification loss: 0.11844 | Regression loss: 0.24470 | Running loss: 0.39160\n",
      "Epoch: 10 | Iteration: 162 | Classification loss: 0.06279 | Regression loss: 0.14230 | Running loss: 0.39126\n",
      "Epoch: 10 | Iteration: 163 | Classification loss: 0.07869 | Regression loss: 0.35024 | Running loss: 0.39116\n",
      "Epoch: 10 | Iteration: 164 | Classification loss: 0.28990 | Regression loss: 0.41270 | Running loss: 0.39182\n",
      "Epoch: 10 | Iteration: 165 | Classification loss: 0.21639 | Regression loss: 0.32566 | Running loss: 0.39246\n",
      "Epoch: 10 | Iteration: 166 | Classification loss: 0.05790 | Regression loss: 0.22880 | Running loss: 0.39251\n",
      "Epoch: 10 | Iteration: 167 | Classification loss: 0.14180 | Regression loss: 0.25743 | Running loss: 0.39289\n",
      "Epoch: 10 | Iteration: 168 | Classification loss: 0.41302 | Regression loss: 0.18093 | Running loss: 0.39338\n",
      "Epoch: 10 | Iteration: 169 | Classification loss: 0.31170 | Regression loss: 0.48785 | Running loss: 0.39444\n",
      "Epoch: 10 | Iteration: 170 | Classification loss: 0.51579 | Regression loss: 0.21251 | Running loss: 0.39508\n",
      "Epoch: 10 | Iteration: 171 | Classification loss: 0.15932 | Regression loss: 0.20881 | Running loss: 0.39545\n",
      "Epoch: 10 | Iteration: 172 | Classification loss: 0.17048 | Regression loss: 0.26110 | Running loss: 0.39509\n",
      "Epoch: 10 | Iteration: 173 | Classification loss: 0.02969 | Regression loss: 0.13817 | Running loss: 0.39516\n",
      "Epoch: 10 | Iteration: 174 | Classification loss: 0.11348 | Regression loss: 0.26628 | Running loss: 0.39530\n",
      "Epoch: 10 | Iteration: 175 | Classification loss: 0.15787 | Regression loss: 0.14250 | Running loss: 0.39529\n",
      "Epoch: 10 | Iteration: 176 | Classification loss: 0.14010 | Regression loss: 0.17973 | Running loss: 0.39489\n",
      "Epoch: 10 | Iteration: 177 | Classification loss: 0.04152 | Regression loss: 0.16091 | Running loss: 0.39477\n",
      "Epoch: 10 | Iteration: 178 | Classification loss: 0.20194 | Regression loss: 0.24281 | Running loss: 0.39520\n",
      "Epoch: 10 | Iteration: 179 | Classification loss: 0.07460 | Regression loss: 0.24230 | Running loss: 0.39533\n",
      "Epoch: 10 | Iteration: 180 | Classification loss: 0.05377 | Regression loss: 0.12785 | Running loss: 0.39516\n",
      "Epoch: 10 | Iteration: 181 | Classification loss: 0.11649 | Regression loss: 0.30082 | Running loss: 0.39562\n",
      "Epoch: 10 | Iteration: 182 | Classification loss: 0.10401 | Regression loss: 0.41465 | Running loss: 0.39547\n",
      "Epoch: 10 | Iteration: 183 | Classification loss: 0.05692 | Regression loss: 0.23007 | Running loss: 0.39566\n",
      "Epoch: 10 | Iteration: 184 | Classification loss: 0.15015 | Regression loss: 0.29870 | Running loss: 0.39582\n",
      "Epoch: 10 | Iteration: 185 | Classification loss: 0.19686 | Regression loss: 0.53897 | Running loss: 0.39679\n",
      "Epoch: 10 | Iteration: 186 | Classification loss: 0.12425 | Regression loss: 0.42848 | Running loss: 0.39741\n",
      "Epoch: 10 | Iteration: 187 | Classification loss: 0.06906 | Regression loss: 0.34808 | Running loss: 0.39769\n",
      "Epoch: 10 | Iteration: 188 | Classification loss: 0.07410 | Regression loss: 0.24734 | Running loss: 0.39695\n",
      "Epoch: 10 | Iteration: 189 | Classification loss: 0.03782 | Regression loss: 0.21163 | Running loss: 0.39655\n",
      "Epoch: 10 | Iteration: 190 | Classification loss: 0.07808 | Regression loss: 0.13426 | Running loss: 0.39652\n",
      "Epoch: 10 | Iteration: 191 | Classification loss: 0.05709 | Regression loss: 0.15736 | Running loss: 0.39655\n",
      "Epoch: 10 | Iteration: 192 | Classification loss: 0.12377 | Regression loss: 0.28407 | Running loss: 0.39669\n",
      "Epoch: 10 | Iteration: 193 | Classification loss: 0.19669 | Regression loss: 0.13977 | Running loss: 0.39616\n",
      "Epoch: 10 | Iteration: 194 | Classification loss: 0.18594 | Regression loss: 0.24684 | Running loss: 0.39565\n",
      "Epoch: 10 | Iteration: 195 | Classification loss: 0.08839 | Regression loss: 0.07366 | Running loss: 0.39546\n",
      "Epoch: 10 | Iteration: 196 | Classification loss: 0.04604 | Regression loss: 0.15068 | Running loss: 0.39516\n",
      "Epoch: 10 | Iteration: 197 | Classification loss: 0.20267 | Regression loss: 0.18562 | Running loss: 0.39527\n",
      "Epoch: 10 | Iteration: 198 | Classification loss: 0.25123 | Regression loss: 0.25188 | Running loss: 0.39538\n",
      "Epoch: 10 | Iteration: 199 | Classification loss: 0.12699 | Regression loss: 0.26685 | Running loss: 0.39512\n",
      "Epoch: 10 | Iteration: 200 | Classification loss: 0.04688 | Regression loss: 0.17261 | Running loss: 0.39497\n",
      "Epoch: 10 | Iteration: 201 | Classification loss: 0.03542 | Regression loss: 0.12606 | Running loss: 0.39463\n",
      "Epoch: 10 | Iteration: 202 | Classification loss: 0.05927 | Regression loss: 0.12415 | Running loss: 0.39379\n",
      "Epoch: 10 | Iteration: 203 | Classification loss: 0.07432 | Regression loss: 0.24344 | Running loss: 0.39380\n",
      "Epoch: 10 | Iteration: 204 | Classification loss: 0.09551 | Regression loss: 0.20951 | Running loss: 0.39372\n",
      "Epoch: 10 | Iteration: 205 | Classification loss: 0.11563 | Regression loss: 0.22720 | Running loss: 0.39381\n",
      "Epoch: 10 | Iteration: 206 | Classification loss: 0.10077 | Regression loss: 0.33972 | Running loss: 0.39405\n",
      "Epoch: 10 | Iteration: 207 | Classification loss: 0.14494 | Regression loss: 0.30205 | Running loss: 0.39420\n",
      "Epoch: 10 | Iteration: 208 | Classification loss: 0.10786 | Regression loss: 0.21805 | Running loss: 0.39418\n",
      "Epoch: 10 | Iteration: 209 | Classification loss: 0.18724 | Regression loss: 0.16019 | Running loss: 0.39389\n",
      "Epoch: 10 | Iteration: 210 | Classification loss: 0.30354 | Regression loss: 0.28990 | Running loss: 0.39376\n",
      "Epoch: 10 | Iteration: 211 | Classification loss: 0.08827 | Regression loss: 0.27356 | Running loss: 0.39408\n",
      "Epoch: 10 | Iteration: 212 | Classification loss: 0.01723 | Regression loss: 0.16989 | Running loss: 0.39373\n",
      "Epoch: 10 | Iteration: 213 | Classification loss: 0.07367 | Regression loss: 0.23798 | Running loss: 0.39325\n",
      "Epoch: 10 | Iteration: 214 | Classification loss: 0.08390 | Regression loss: 0.05124 | Running loss: 0.39285\n",
      "Epoch: 10 | Iteration: 215 | Classification loss: 0.26188 | Regression loss: 0.42162 | Running loss: 0.39361\n",
      "Epoch: 10 | Iteration: 216 | Classification loss: 0.51747 | Regression loss: 0.31151 | Running loss: 0.39494\n",
      "Epoch: 10 | Iteration: 217 | Classification loss: 0.07164 | Regression loss: 0.25061 | Running loss: 0.39402\n",
      "Epoch: 10 | Iteration: 218 | Classification loss: 0.12871 | Regression loss: 0.14740 | Running loss: 0.39302\n",
      "Epoch: 10 | Iteration: 219 | Classification loss: 0.46810 | Regression loss: 0.61383 | Running loss: 0.39458\n",
      "Epoch: 10 | Iteration: 220 | Classification loss: 0.10797 | Regression loss: 0.39827 | Running loss: 0.39482\n",
      "Epoch: 10 | Iteration: 221 | Classification loss: 0.15424 | Regression loss: 0.28408 | Running loss: 0.39518\n",
      "Epoch: 10 | Iteration: 222 | Classification loss: 0.27148 | Regression loss: 0.20806 | Running loss: 0.39528\n",
      "Epoch: 10 | Iteration: 223 | Classification loss: 0.08000 | Regression loss: 0.38947 | Running loss: 0.39554\n",
      "Epoch: 10 | Iteration: 224 | Classification loss: 0.08840 | Regression loss: 0.29352 | Running loss: 0.39531\n",
      "Epoch: 10 | Iteration: 225 | Classification loss: 0.20104 | Regression loss: 0.48465 | Running loss: 0.39594\n",
      "Epoch: 10 | Iteration: 226 | Classification loss: 0.04552 | Regression loss: 0.23656 | Running loss: 0.39586\n",
      "Epoch: 10 | Iteration: 227 | Classification loss: 0.09294 | Regression loss: 0.16464 | Running loss: 0.39577\n",
      "Epoch: 10 | Iteration: 228 | Classification loss: 0.10009 | Regression loss: 0.19954 | Running loss: 0.39597\n",
      "Epoch: 10 | Iteration: 229 | Classification loss: 0.15976 | Regression loss: 0.24710 | Running loss: 0.39532\n",
      "Epoch: 10 | Iteration: 230 | Classification loss: 0.03643 | Regression loss: 0.20090 | Running loss: 0.39473\n",
      "Epoch: 10 | Iteration: 231 | Classification loss: 0.08066 | Regression loss: 0.20068 | Running loss: 0.39440\n",
      "Epoch: 10 | Iteration: 232 | Classification loss: 0.05855 | Regression loss: 0.15023 | Running loss: 0.39354\n",
      "Epoch: 10 | Iteration: 233 | Classification loss: 0.04722 | Regression loss: 0.27607 | Running loss: 0.39342\n",
      "Epoch: 10 | Iteration: 234 | Classification loss: 0.22487 | Regression loss: 0.31948 | Running loss: 0.39391\n",
      "Epoch: 10 | Iteration: 235 | Classification loss: 0.19976 | Regression loss: 0.15380 | Running loss: 0.39287\n",
      "Epoch: 10 | Iteration: 236 | Classification loss: 0.12095 | Regression loss: 0.53470 | Running loss: 0.39351\n",
      "Epoch: 10 | Iteration: 237 | Classification loss: 0.10584 | Regression loss: 0.12200 | Running loss: 0.39264\n",
      "Epoch: 10 | Iteration: 238 | Classification loss: 0.21689 | Regression loss: 0.57049 | Running loss: 0.39354\n",
      "Epoch: 10 | Iteration: 239 | Classification loss: 0.02565 | Regression loss: 0.17142 | Running loss: 0.39351\n",
      "Epoch: 10 | Iteration: 240 | Classification loss: 0.16038 | Regression loss: 0.25835 | Running loss: 0.39377\n",
      "Epoch: 10 | Iteration: 241 | Classification loss: 0.09989 | Regression loss: 0.25481 | Running loss: 0.39358\n",
      "Epoch: 10 | Iteration: 242 | Classification loss: 0.13719 | Regression loss: 0.37759 | Running loss: 0.39404\n",
      "Epoch: 10 | Iteration: 243 | Classification loss: 0.07855 | Regression loss: 0.15118 | Running loss: 0.39390\n",
      "Epoch: 10 | Iteration: 244 | Classification loss: 0.08691 | Regression loss: 0.14677 | Running loss: 0.39354\n",
      "Epoch: 10 | Iteration: 245 | Classification loss: 0.17704 | Regression loss: 0.22551 | Running loss: 0.39370\n",
      "Epoch: 10 | Iteration: 246 | Classification loss: 0.08048 | Regression loss: 0.25126 | Running loss: 0.39374\n",
      "Epoch: 10 | Iteration: 247 | Classification loss: 0.08075 | Regression loss: 0.21522 | Running loss: 0.39233\n",
      "Epoch: 10 | Iteration: 248 | Classification loss: 0.08413 | Regression loss: 0.20979 | Running loss: 0.39203\n",
      "Epoch: 10 | Iteration: 249 | Classification loss: 0.21382 | Regression loss: 0.38755 | Running loss: 0.39285\n",
      "Epoch: 10 | Iteration: 250 | Classification loss: 0.14718 | Regression loss: 0.12775 | Running loss: 0.39263\n",
      "Epoch: 10 | Iteration: 251 | Classification loss: 0.04601 | Regression loss: 0.21970 | Running loss: 0.39198\n",
      "Epoch: 10 | Iteration: 252 | Classification loss: 0.05156 | Regression loss: 0.14767 | Running loss: 0.39196\n",
      "Epoch: 10 | Iteration: 253 | Classification loss: 0.35295 | Regression loss: 0.58952 | Running loss: 0.39298\n",
      "Epoch: 10 | Iteration: 254 | Classification loss: 0.54596 | Regression loss: 0.30978 | Running loss: 0.39434\n",
      "Epoch: 10 | Iteration: 255 | Classification loss: 0.09985 | Regression loss: 0.21513 | Running loss: 0.39366\n",
      "Epoch: 10 | Iteration: 256 | Classification loss: 0.07453 | Regression loss: 0.26566 | Running loss: 0.39362\n",
      "Epoch: 10 | Iteration: 257 | Classification loss: 0.09015 | Regression loss: 0.10810 | Running loss: 0.39245\n",
      "Epoch: 10 | Iteration: 258 | Classification loss: 0.37152 | Regression loss: 0.31499 | Running loss: 0.39324\n",
      "Epoch: 10 | Iteration: 259 | Classification loss: 0.05378 | Regression loss: 0.27945 | Running loss: 0.39290\n",
      "Epoch: 10 | Iteration: 260 | Classification loss: 0.15119 | Regression loss: 0.32846 | Running loss: 0.39330\n",
      "Epoch: 10 | Iteration: 261 | Classification loss: 0.06302 | Regression loss: 0.17708 | Running loss: 0.39331\n",
      "Epoch: 10 | Iteration: 262 | Classification loss: 0.15580 | Regression loss: 0.33873 | Running loss: 0.39379\n",
      "Epoch: 10 | Iteration: 263 | Classification loss: 0.05504 | Regression loss: 0.26732 | Running loss: 0.39365\n",
      "Epoch: 10 | Iteration: 264 | Classification loss: 0.34438 | Regression loss: 0.42230 | Running loss: 0.39465\n",
      "Epoch: 10 | Iteration: 265 | Classification loss: 0.06784 | Regression loss: 0.14424 | Running loss: 0.39365\n",
      "Epoch: 10 | Iteration: 266 | Classification loss: 0.23734 | Regression loss: 0.21260 | Running loss: 0.39368\n",
      "Epoch: 10 | Iteration: 267 | Classification loss: 0.28511 | Regression loss: 0.19764 | Running loss: 0.39395\n",
      "Epoch: 10 | Iteration: 268 | Classification loss: 0.06362 | Regression loss: 0.21683 | Running loss: 0.39379\n",
      "Epoch: 10 | Iteration: 269 | Classification loss: 0.14141 | Regression loss: 0.34979 | Running loss: 0.39350\n",
      "Epoch: 10 | Iteration: 270 | Classification loss: 0.12645 | Regression loss: 0.17061 | Running loss: 0.39319\n",
      "Epoch: 10 | Iteration: 271 | Classification loss: 0.16354 | Regression loss: 0.39366 | Running loss: 0.39378\n",
      "Epoch: 10 | Iteration: 272 | Classification loss: 0.22209 | Regression loss: 0.19485 | Running loss: 0.39372\n",
      "Epoch: 10 | Iteration: 273 | Classification loss: 0.25295 | Regression loss: 0.34922 | Running loss: 0.39406\n",
      "Epoch: 10 | Iteration: 274 | Classification loss: 0.03881 | Regression loss: 0.22786 | Running loss: 0.39371\n",
      "Epoch: 10 | Iteration: 275 | Classification loss: 0.20119 | Regression loss: 0.33041 | Running loss: 0.39405\n",
      "Epoch: 10 | Iteration: 276 | Classification loss: 0.18270 | Regression loss: 0.25377 | Running loss: 0.39406\n",
      "Epoch: 10 | Iteration: 277 | Classification loss: 0.08429 | Regression loss: 0.20346 | Running loss: 0.39402\n",
      "Epoch: 10 | Iteration: 278 | Classification loss: 0.07238 | Regression loss: 0.31309 | Running loss: 0.39434\n",
      "Epoch: 10 | Iteration: 279 | Classification loss: 0.09444 | Regression loss: 0.35581 | Running loss: 0.39491\n",
      "Epoch: 10 | Iteration: 280 | Classification loss: 0.12038 | Regression loss: 0.30181 | Running loss: 0.39486\n",
      "Epoch: 10 | Iteration: 281 | Classification loss: 0.14244 | Regression loss: 0.24917 | Running loss: 0.39473\n",
      "Epoch: 10 | Iteration: 282 | Classification loss: 0.20886 | Regression loss: 0.25254 | Running loss: 0.39502\n",
      "Epoch: 10 | Iteration: 283 | Classification loss: 0.29767 | Regression loss: 0.29267 | Running loss: 0.39524\n",
      "Epoch: 10 | Iteration: 284 | Classification loss: 0.13268 | Regression loss: 0.23222 | Running loss: 0.39545\n",
      "Epoch: 10 | Iteration: 285 | Classification loss: 0.01751 | Regression loss: 0.08182 | Running loss: 0.39526\n",
      "Epoch: 10 | Iteration: 286 | Classification loss: 0.04296 | Regression loss: 0.08564 | Running loss: 0.39329\n",
      "Epoch: 10 | Iteration: 287 | Classification loss: 0.06600 | Regression loss: 0.17612 | Running loss: 0.39238\n",
      "Epoch: 10 | Iteration: 288 | Classification loss: 0.04697 | Regression loss: 0.17976 | Running loss: 0.39109\n",
      "Epoch: 10 | Iteration: 289 | Classification loss: 0.08647 | Regression loss: 0.22797 | Running loss: 0.39080\n",
      "Epoch: 10 | Iteration: 290 | Classification loss: 0.11180 | Regression loss: 0.32267 | Running loss: 0.39021\n",
      "Epoch: 10 | Iteration: 291 | Classification loss: 0.08708 | Regression loss: 0.19918 | Running loss: 0.38916\n",
      "Epoch: 10 | Iteration: 292 | Classification loss: 0.15087 | Regression loss: 0.20515 | Running loss: 0.38821\n",
      "Epoch: 10 | Iteration: 293 | Classification loss: 0.05760 | Regression loss: 0.09443 | Running loss: 0.38766\n",
      "Epoch: 10 | Iteration: 294 | Classification loss: 0.04106 | Regression loss: 0.16999 | Running loss: 0.38748\n",
      "Epoch: 10 | Iteration: 295 | Classification loss: 0.27039 | Regression loss: 0.24548 | Running loss: 0.38787\n",
      "Epoch: 10 | Iteration: 296 | Classification loss: 0.10466 | Regression loss: 0.18667 | Running loss: 0.38696\n",
      "Epoch: 10 | Iteration: 297 | Classification loss: 0.13443 | Regression loss: 0.16490 | Running loss: 0.38685\n",
      "Epoch: 10 | Iteration: 298 | Classification loss: 0.16076 | Regression loss: 0.27508 | Running loss: 0.38730\n",
      "Epoch: 10 | Iteration: 299 | Classification loss: 0.08021 | Regression loss: 0.21828 | Running loss: 0.38731\n",
      "Epoch: 10 | Iteration: 300 | Classification loss: 0.09481 | Regression loss: 0.29148 | Running loss: 0.38734\n",
      "Epoch: 10 | Iteration: 301 | Classification loss: 0.01977 | Regression loss: 0.11209 | Running loss: 0.38697\n",
      "Epoch: 10 | Iteration: 302 | Classification loss: 0.07963 | Regression loss: 0.18745 | Running loss: 0.38700\n",
      "Epoch: 10 | Iteration: 303 | Classification loss: 0.16109 | Regression loss: 0.33582 | Running loss: 0.38728\n",
      "Epoch: 10 | Iteration: 304 | Classification loss: 0.06691 | Regression loss: 0.16998 | Running loss: 0.38734\n",
      "Epoch: 10 | Iteration: 305 | Classification loss: 0.13811 | Regression loss: 0.48160 | Running loss: 0.38788\n",
      "Epoch: 10 | Iteration: 306 | Classification loss: 0.34998 | Regression loss: 0.50239 | Running loss: 0.38929\n",
      "Epoch: 10 | Iteration: 307 | Classification loss: 0.43573 | Regression loss: 0.10617 | Running loss: 0.38993\n",
      "Epoch: 10 | Iteration: 308 | Classification loss: 0.11371 | Regression loss: 0.20537 | Running loss: 0.39018\n",
      "Epoch: 10 | Iteration: 309 | Classification loss: 0.09406 | Regression loss: 0.15359 | Running loss: 0.38943\n",
      "Epoch: 10 | Iteration: 310 | Classification loss: 0.12034 | Regression loss: 0.17834 | Running loss: 0.38911\n",
      "Epoch: 10 | Iteration: 311 | Classification loss: 0.15749 | Regression loss: 0.36884 | Running loss: 0.38921\n",
      "Epoch: 10 | Iteration: 312 | Classification loss: 0.09661 | Regression loss: 0.16931 | Running loss: 0.38879\n",
      "Epoch: 10 | Iteration: 313 | Classification loss: 0.07585 | Regression loss: 0.31360 | Running loss: 0.38906\n",
      "Epoch: 10 | Iteration: 314 | Classification loss: 0.21927 | Regression loss: 0.16902 | Running loss: 0.38875\n",
      "Epoch: 10 | Iteration: 315 | Classification loss: 0.15663 | Regression loss: 0.37250 | Running loss: 0.38899\n",
      "Epoch: 10 | Iteration: 316 | Classification loss: 0.12434 | Regression loss: 0.19172 | Running loss: 0.38903\n",
      "Epoch: 10 | Iteration: 317 | Classification loss: 0.13251 | Regression loss: 0.07630 | Running loss: 0.38748\n",
      "Epoch: 10 | Iteration: 318 | Classification loss: 0.08437 | Regression loss: 0.22424 | Running loss: 0.38759\n",
      "Epoch: 10 | Iteration: 319 | Classification loss: 0.13228 | Regression loss: 0.28627 | Running loss: 0.38764\n",
      "Epoch: 10 | Iteration: 320 | Classification loss: 0.07250 | Regression loss: 0.26954 | Running loss: 0.38776\n",
      "Epoch: 10 | Iteration: 321 | Classification loss: 0.06603 | Regression loss: 0.15021 | Running loss: 0.38665\n",
      "Epoch: 10 | Iteration: 322 | Classification loss: 0.10794 | Regression loss: 0.29934 | Running loss: 0.38691\n",
      "Epoch: 10 | Iteration: 323 | Classification loss: 0.13275 | Regression loss: 0.24566 | Running loss: 0.38686\n",
      "Epoch: 10 | Iteration: 324 | Classification loss: 0.16546 | Regression loss: 0.20179 | Running loss: 0.38703\n",
      "Epoch: 10 | Iteration: 325 | Classification loss: 0.10175 | Regression loss: 0.37715 | Running loss: 0.38730\n",
      "Epoch: 10 | Iteration: 326 | Classification loss: 0.13529 | Regression loss: 0.20818 | Running loss: 0.38729\n",
      "Epoch: 10 | Iteration: 327 | Classification loss: 0.11354 | Regression loss: 0.16080 | Running loss: 0.38702\n",
      "Epoch: 10 | Iteration: 328 | Classification loss: 0.11084 | Regression loss: 0.22016 | Running loss: 0.38674\n",
      "Epoch: 10 | Iteration: 329 | Classification loss: 0.09191 | Regression loss: 0.17330 | Running loss: 0.38631\n",
      "Epoch: 10 | Iteration: 330 | Classification loss: 0.22641 | Regression loss: 0.22458 | Running loss: 0.38566\n",
      "Epoch: 10 | Iteration: 331 | Classification loss: 0.09484 | Regression loss: 0.32106 | Running loss: 0.38574\n",
      "Epoch: 10 | Iteration: 332 | Classification loss: 0.07570 | Regression loss: 0.31780 | Running loss: 0.38572\n",
      "Epoch: 10 | Iteration: 333 | Classification loss: 0.10100 | Regression loss: 0.20234 | Running loss: 0.38542\n",
      "Epoch: 10 | Iteration: 334 | Classification loss: 0.07654 | Regression loss: 0.30950 | Running loss: 0.38539\n",
      "Epoch: 10 | Iteration: 335 | Classification loss: 0.05432 | Regression loss: 0.22128 | Running loss: 0.38510\n",
      "Epoch: 10 | Iteration: 336 | Classification loss: 0.09291 | Regression loss: 0.25836 | Running loss: 0.38547\n",
      "Epoch: 10 | Iteration: 337 | Classification loss: 0.06216 | Regression loss: 0.20235 | Running loss: 0.38518\n",
      "Epoch: 10 | Iteration: 338 | Classification loss: 0.07380 | Regression loss: 0.37229 | Running loss: 0.38495\n",
      "Epoch: 10 | Iteration: 339 | Classification loss: 0.12988 | Regression loss: 0.11344 | Running loss: 0.38462\n",
      "Epoch: 10 | Iteration: 340 | Classification loss: 0.05626 | Regression loss: 0.15366 | Running loss: 0.38434\n",
      "Epoch: 10 | Iteration: 341 | Classification loss: 0.06899 | Regression loss: 0.32560 | Running loss: 0.38398\n",
      "Epoch: 10 | Iteration: 342 | Classification loss: 0.10784 | Regression loss: 0.26251 | Running loss: 0.38310\n",
      "Epoch: 10 | Iteration: 343 | Classification loss: 0.20808 | Regression loss: 0.18170 | Running loss: 0.38314\n",
      "Epoch: 10 | Iteration: 344 | Classification loss: 0.03658 | Regression loss: 0.19553 | Running loss: 0.38295\n",
      "Epoch: 10 | Iteration: 345 | Classification loss: 0.42984 | Regression loss: 0.43745 | Running loss: 0.38396\n",
      "Epoch: 10 | Iteration: 346 | Classification loss: 0.31174 | Regression loss: 0.64817 | Running loss: 0.38478\n",
      "Epoch: 10 | Iteration: 347 | Classification loss: 0.43662 | Regression loss: 0.13430 | Running loss: 0.38533\n",
      "Epoch: 10 | Iteration: 348 | Classification loss: 0.09214 | Regression loss: 0.14845 | Running loss: 0.38488\n",
      "Epoch: 10 | Iteration: 349 | Classification loss: 0.04721 | Regression loss: 0.11901 | Running loss: 0.38459\n",
      "Epoch: 10 | Iteration: 350 | Classification loss: 0.10061 | Regression loss: 0.23157 | Running loss: 0.38395\n",
      "Epoch: 10 | Iteration: 351 | Classification loss: 0.05660 | Regression loss: 0.44116 | Running loss: 0.38447\n",
      "Epoch: 10 | Iteration: 352 | Classification loss: 0.09776 | Regression loss: 0.21369 | Running loss: 0.38449\n",
      "Epoch: 10 | Iteration: 353 | Classification loss: 0.17639 | Regression loss: 0.37390 | Running loss: 0.38461\n",
      "Epoch: 10 | Iteration: 354 | Classification loss: 0.09529 | Regression loss: 0.27812 | Running loss: 0.38465\n",
      "Epoch: 10 | Iteration: 355 | Classification loss: 0.04528 | Regression loss: 0.21208 | Running loss: 0.38443\n",
      "Epoch: 10 | Iteration: 356 | Classification loss: 0.05146 | Regression loss: 0.30135 | Running loss: 0.38350\n",
      "Epoch: 10 | Iteration: 357 | Classification loss: 0.11540 | Regression loss: 0.45107 | Running loss: 0.38357\n",
      "Epoch: 10 | Iteration: 358 | Classification loss: 0.14514 | Regression loss: 0.38129 | Running loss: 0.38372\n",
      "Epoch: 10 | Iteration: 359 | Classification loss: 0.15403 | Regression loss: 0.28388 | Running loss: 0.38342\n",
      "Epoch: 10 | Iteration: 360 | Classification loss: 0.06077 | Regression loss: 0.27105 | Running loss: 0.38326\n",
      "Epoch: 10 | Iteration: 361 | Classification loss: 0.09044 | Regression loss: 0.24877 | Running loss: 0.38325\n",
      "Epoch: 10 | Iteration: 362 | Classification loss: 0.08909 | Regression loss: 0.22524 | Running loss: 0.38304\n",
      "Epoch: 10 | Iteration: 363 | Classification loss: 0.08501 | Regression loss: 0.27060 | Running loss: 0.38310\n",
      "Epoch: 10 | Iteration: 364 | Classification loss: 0.24737 | Regression loss: 0.31787 | Running loss: 0.38324\n",
      "Epoch: 10 | Iteration: 365 | Classification loss: 0.22497 | Regression loss: 0.52171 | Running loss: 0.38272\n",
      "Epoch: 10 | Iteration: 366 | Classification loss: 0.23083 | Regression loss: 0.49394 | Running loss: 0.38295\n",
      "Epoch: 10 | Iteration: 367 | Classification loss: 0.18891 | Regression loss: 0.23619 | Running loss: 0.38322\n",
      "Epoch: 10 | Iteration: 368 | Classification loss: 0.14706 | Regression loss: 0.51084 | Running loss: 0.38386\n",
      "Epoch: 10 | Iteration: 369 | Classification loss: 0.13131 | Regression loss: 0.23412 | Running loss: 0.38379\n",
      "Epoch: 10 | Iteration: 370 | Classification loss: 0.20526 | Regression loss: 0.41722 | Running loss: 0.38457\n",
      "Epoch: 10 | Iteration: 371 | Classification loss: 0.05882 | Regression loss: 0.20199 | Running loss: 0.38435\n",
      "Epoch: 10 | Iteration: 372 | Classification loss: 0.11829 | Regression loss: 0.27522 | Running loss: 0.38477\n",
      "Epoch: 10 | Iteration: 373 | Classification loss: 0.13059 | Regression loss: 0.36030 | Running loss: 0.38510\n",
      "Epoch: 10 | Iteration: 374 | Classification loss: 0.24913 | Regression loss: 0.48270 | Running loss: 0.38607\n",
      "Epoch: 10 | Iteration: 375 | Classification loss: 0.13893 | Regression loss: 0.17452 | Running loss: 0.38582\n",
      "Epoch: 10 | Iteration: 376 | Classification loss: 0.07119 | Regression loss: 0.28750 | Running loss: 0.38529\n",
      "Epoch: 10 | Iteration: 377 | Classification loss: 0.07566 | Regression loss: 0.19177 | Running loss: 0.38524\n",
      "Epoch: 10 | Iteration: 378 | Classification loss: 0.29570 | Regression loss: 0.57983 | Running loss: 0.38562\n",
      "Epoch: 10 | Iteration: 379 | Classification loss: 0.20592 | Regression loss: 0.28219 | Running loss: 0.38624\n",
      "Epoch: 10 | Iteration: 380 | Classification loss: 0.12448 | Regression loss: 0.39327 | Running loss: 0.38652\n",
      "Epoch: 10 | Iteration: 381 | Classification loss: 0.12892 | Regression loss: 0.34682 | Running loss: 0.38616\n",
      "Epoch: 10 | Iteration: 382 | Classification loss: 0.27469 | Regression loss: 0.37857 | Running loss: 0.38702\n",
      "Epoch: 10 | Iteration: 383 | Classification loss: 0.09804 | Regression loss: 0.18981 | Running loss: 0.38678\n",
      "Epoch: 10 | Iteration: 384 | Classification loss: 0.37210 | Regression loss: 0.18432 | Running loss: 0.38715\n",
      "Epoch: 10 | Iteration: 385 | Classification loss: 0.18696 | Regression loss: 0.16846 | Running loss: 0.38701\n",
      "Epoch: 10 | Iteration: 386 | Classification loss: 0.10283 | Regression loss: 0.14907 | Running loss: 0.38615\n",
      "Epoch: 10 | Iteration: 387 | Classification loss: 0.09577 | Regression loss: 0.20027 | Running loss: 0.38628\n",
      "Epoch: 10 | Iteration: 388 | Classification loss: 0.13146 | Regression loss: 0.14575 | Running loss: 0.38618\n",
      "Epoch: 10 | Iteration: 389 | Classification loss: 0.05582 | Regression loss: 0.20223 | Running loss: 0.38586\n",
      "Epoch: 10 | Iteration: 390 | Classification loss: 0.03660 | Regression loss: 0.15665 | Running loss: 0.38493\n",
      "Epoch: 10 | Iteration: 391 | Classification loss: 0.11349 | Regression loss: 0.25660 | Running loss: 0.38504\n",
      "Epoch: 10 | Iteration: 392 | Classification loss: 0.09772 | Regression loss: 0.12437 | Running loss: 0.38440\n",
      "Epoch: 10 | Iteration: 393 | Classification loss: 0.04475 | Regression loss: 0.18752 | Running loss: 0.38457\n",
      "Epoch: 10 | Iteration: 394 | Classification loss: 0.24739 | Regression loss: 0.43086 | Running loss: 0.38546\n",
      "Epoch: 10 | Iteration: 395 | Classification loss: 0.08681 | Regression loss: 0.17450 | Running loss: 0.38550\n",
      "Epoch: 10 | Iteration: 396 | Classification loss: 0.03337 | Regression loss: 0.11877 | Running loss: 0.38517\n",
      "Epoch: 10 | Iteration: 397 | Classification loss: 0.04699 | Regression loss: 0.23523 | Running loss: 0.38497\n",
      "Epoch: 10 | Iteration: 398 | Classification loss: 0.23463 | Regression loss: 0.58408 | Running loss: 0.38620\n",
      "Epoch: 10 | Iteration: 399 | Classification loss: 0.10753 | Regression loss: 0.14433 | Running loss: 0.38511\n",
      "Epoch: 10 | Iteration: 400 | Classification loss: 0.05738 | Regression loss: 0.11640 | Running loss: 0.38413\n",
      "Epoch: 10 | Iteration: 401 | Classification loss: 0.04187 | Regression loss: 0.10856 | Running loss: 0.38340\n",
      "Epoch: 10 | Iteration: 402 | Classification loss: 0.05763 | Regression loss: 0.21619 | Running loss: 0.38264\n",
      "Epoch: 10 | Iteration: 403 | Classification loss: 0.10875 | Regression loss: 0.35760 | Running loss: 0.38243\n",
      "Epoch: 10 | Iteration: 404 | Classification loss: 0.06394 | Regression loss: 0.13740 | Running loss: 0.38150\n",
      "Epoch: 10 | Iteration: 405 | Classification loss: 0.05085 | Regression loss: 0.18021 | Running loss: 0.38151\n",
      "Epoch: 10 | Iteration: 406 | Classification loss: 0.05762 | Regression loss: 0.17746 | Running loss: 0.38123\n",
      "Epoch: 10 | Iteration: 407 | Classification loss: 0.13731 | Regression loss: 0.48477 | Running loss: 0.38152\n",
      "Epoch: 10 | Iteration: 408 | Classification loss: 0.14461 | Regression loss: 0.14312 | Running loss: 0.38114\n",
      "Epoch: 10 | Iteration: 409 | Classification loss: 0.08510 | Regression loss: 0.31897 | Running loss: 0.38087\n",
      "Epoch: 10 | Iteration: 410 | Classification loss: 0.02193 | Regression loss: 0.17162 | Running loss: 0.38074\n",
      "Epoch: 10 | Iteration: 411 | Classification loss: 0.05214 | Regression loss: 0.20391 | Running loss: 0.38016\n",
      "Epoch: 10 | Iteration: 412 | Classification loss: 0.08912 | Regression loss: 0.24009 | Running loss: 0.37985\n",
      "Epoch: 10 | Iteration: 413 | Classification loss: 0.37139 | Regression loss: 0.40641 | Running loss: 0.38054\n",
      "Epoch: 10 | Iteration: 414 | Classification loss: 0.20189 | Regression loss: 0.30938 | Running loss: 0.38038\n",
      "Epoch: 10 | Iteration: 415 | Classification loss: 0.07463 | Regression loss: 0.22673 | Running loss: 0.37965\n",
      "Epoch: 10 | Iteration: 416 | Classification loss: 0.16033 | Regression loss: 0.18041 | Running loss: 0.37897\n",
      "Epoch: 10 | Iteration: 417 | Classification loss: 0.06895 | Regression loss: 0.18851 | Running loss: 0.37885\n",
      "Epoch: 10 | Iteration: 418 | Classification loss: 0.06649 | Regression loss: 0.26461 | Running loss: 0.37840\n",
      "Epoch: 10 | Iteration: 419 | Classification loss: 0.24617 | Regression loss: 0.34033 | Running loss: 0.37859\n",
      "Epoch: 10 | Iteration: 420 | Classification loss: 0.11303 | Regression loss: 0.16969 | Running loss: 0.37803\n",
      "Epoch: 10 | Iteration: 421 | Classification loss: 0.09845 | Regression loss: 0.25376 | Running loss: 0.37771\n",
      "Epoch: 10 | Iteration: 422 | Classification loss: 0.22553 | Regression loss: 0.35878 | Running loss: 0.37835\n",
      "Epoch: 10 | Iteration: 423 | Classification loss: 0.21770 | Regression loss: 0.41620 | Running loss: 0.37902\n",
      "Epoch: 10 | Iteration: 424 | Classification loss: 0.11263 | Regression loss: 0.25456 | Running loss: 0.37880\n",
      "Epoch: 10 | Iteration: 425 | Classification loss: 0.27078 | Regression loss: 0.17729 | Running loss: 0.37873\n",
      "Epoch: 10 | Iteration: 426 | Classification loss: 0.14093 | Regression loss: 0.33897 | Running loss: 0.37897\n",
      "Epoch: 10 | Iteration: 427 | Classification loss: 0.07311 | Regression loss: 0.17068 | Running loss: 0.37801\n",
      "Epoch: 10 | Iteration: 428 | Classification loss: 0.34863 | Regression loss: 0.77349 | Running loss: 0.37916\n",
      "Epoch: 10 | Iteration: 429 | Classification loss: 0.10228 | Regression loss: 0.16072 | Running loss: 0.37868\n",
      "Epoch: 10 | Iteration: 430 | Classification loss: 0.33344 | Regression loss: 0.18281 | Running loss: 0.37891\n",
      "Epoch: 10 | Iteration: 431 | Classification loss: 0.11304 | Regression loss: 0.21166 | Running loss: 0.37899\n",
      "Epoch: 10 | Iteration: 432 | Classification loss: 0.05199 | Regression loss: 0.17058 | Running loss: 0.37756\n",
      "Epoch: 10 | Iteration: 433 | Classification loss: 0.08993 | Regression loss: 0.12441 | Running loss: 0.37715\n",
      "Epoch: 10 | Iteration: 434 | Classification loss: 0.25392 | Regression loss: 0.35056 | Running loss: 0.37696\n",
      "Epoch: 10 | Iteration: 435 | Classification loss: 0.25823 | Regression loss: 0.12338 | Running loss: 0.37722\n",
      "Epoch: 10 | Iteration: 436 | Classification loss: 0.09955 | Regression loss: 0.19941 | Running loss: 0.37666\n",
      "Epoch: 10 | Iteration: 437 | Classification loss: 0.06047 | Regression loss: 0.26636 | Running loss: 0.37670\n",
      "Epoch: 10 | Iteration: 438 | Classification loss: 0.21476 | Regression loss: 0.38979 | Running loss: 0.37733\n",
      "Epoch: 10 | Iteration: 439 | Classification loss: 0.26559 | Regression loss: 0.51595 | Running loss: 0.37800\n",
      "Epoch: 10 | Iteration: 440 | Classification loss: 0.04484 | Regression loss: 0.14632 | Running loss: 0.37736\n",
      "Epoch: 10 | Iteration: 441 | Classification loss: 0.12652 | Regression loss: 0.37263 | Running loss: 0.37732\n",
      "Epoch: 10 | Iteration: 442 | Classification loss: 0.05223 | Regression loss: 0.19474 | Running loss: 0.37626\n",
      "Epoch: 10 | Iteration: 443 | Classification loss: 0.09240 | Regression loss: 0.22014 | Running loss: 0.37641\n",
      "Epoch: 10 | Iteration: 444 | Classification loss: 0.10028 | Regression loss: 0.26610 | Running loss: 0.37678\n",
      "Epoch: 10 | Iteration: 445 | Classification loss: 0.03742 | Regression loss: 0.13382 | Running loss: 0.37676\n",
      "Epoch: 10 | Iteration: 446 | Classification loss: 0.17059 | Regression loss: 0.32052 | Running loss: 0.37722\n",
      "Epoch: 10 | Iteration: 447 | Classification loss: 0.04082 | Regression loss: 0.10580 | Running loss: 0.37698\n",
      "Epoch: 10 | Iteration: 448 | Classification loss: 0.03016 | Regression loss: 0.18691 | Running loss: 0.37657\n",
      "Epoch: 10 | Iteration: 449 | Classification loss: 0.11488 | Regression loss: 0.16418 | Running loss: 0.37601\n",
      "Epoch: 10 | Iteration: 450 | Classification loss: 0.14711 | Regression loss: 0.16280 | Running loss: 0.37540\n",
      "Epoch: 10 | Iteration: 451 | Classification loss: 0.04599 | Regression loss: 0.18750 | Running loss: 0.37516\n",
      "Epoch: 10 | Iteration: 452 | Classification loss: 0.17798 | Regression loss: 0.16187 | Running loss: 0.37549\n",
      "Epoch: 10 | Iteration: 453 | Classification loss: 0.18861 | Regression loss: 0.39696 | Running loss: 0.37594\n",
      "Epoch: 10 | Iteration: 454 | Classification loss: 0.16067 | Regression loss: 0.51087 | Running loss: 0.37604\n",
      "Epoch: 10 | Iteration: 455 | Classification loss: 0.04221 | Regression loss: 0.11400 | Running loss: 0.37605\n",
      "Epoch: 10 | Iteration: 456 | Classification loss: 0.36208 | Regression loss: 0.69831 | Running loss: 0.37726\n",
      "Epoch: 10 | Iteration: 457 | Classification loss: 0.14610 | Regression loss: 0.47439 | Running loss: 0.37777\n",
      "Epoch: 10 | Iteration: 458 | Classification loss: 0.11981 | Regression loss: 0.25784 | Running loss: 0.37778\n",
      "Epoch: 10 | Iteration: 459 | Classification loss: 0.12862 | Regression loss: 0.17852 | Running loss: 0.37685\n",
      "Epoch: 10 | Iteration: 460 | Classification loss: 0.24125 | Regression loss: 0.25954 | Running loss: 0.37693\n",
      "Epoch: 10 | Iteration: 461 | Classification loss: 0.03641 | Regression loss: 0.19992 | Running loss: 0.37690\n",
      "Epoch: 10 | Iteration: 462 | Classification loss: 0.18077 | Regression loss: 0.34665 | Running loss: 0.37732\n",
      "Epoch: 10 | Iteration: 463 | Classification loss: 0.08717 | Regression loss: 0.12669 | Running loss: 0.37710\n",
      "Epoch: 10 | Iteration: 464 | Classification loss: 0.18286 | Regression loss: 0.19173 | Running loss: 0.37736\n",
      "Epoch: 10 | Iteration: 465 | Classification loss: 0.07107 | Regression loss: 0.22913 | Running loss: 0.37737\n",
      "Epoch: 10 | Iteration: 466 | Classification loss: 0.06889 | Regression loss: 0.21769 | Running loss: 0.37700\n",
      "Epoch: 10 | Iteration: 467 | Classification loss: 0.19334 | Regression loss: 0.30715 | Running loss: 0.37698\n",
      "Epoch: 10 | Iteration: 468 | Classification loss: 0.20693 | Regression loss: 0.22412 | Running loss: 0.37740\n",
      "Epoch: 10 | Iteration: 469 | Classification loss: 0.05501 | Regression loss: 0.30026 | Running loss: 0.37707\n",
      "Epoch: 10 | Iteration: 470 | Classification loss: 0.11060 | Regression loss: 0.08152 | Running loss: 0.37673\n",
      "Epoch: 10 | Iteration: 471 | Classification loss: 0.14880 | Regression loss: 0.23888 | Running loss: 0.37658\n",
      "Epoch: 10 | Iteration: 472 | Classification loss: 0.11211 | Regression loss: 0.21873 | Running loss: 0.37627\n",
      "Epoch: 10 | Iteration: 473 | Classification loss: 0.13429 | Regression loss: 0.36571 | Running loss: 0.37537\n",
      "Epoch: 10 | Iteration: 474 | Classification loss: 0.08636 | Regression loss: 0.39186 | Running loss: 0.37558\n",
      "Epoch: 10 | Iteration: 475 | Classification loss: 0.28334 | Regression loss: 0.48018 | Running loss: 0.37603\n",
      "Epoch: 10 | Iteration: 476 | Classification loss: 0.06690 | Regression loss: 0.31218 | Running loss: 0.37589\n",
      "Epoch: 10 | Iteration: 477 | Classification loss: 0.04408 | Regression loss: 0.25997 | Running loss: 0.37597\n",
      "Epoch: 10 | Iteration: 478 | Classification loss: 0.30734 | Regression loss: 0.27632 | Running loss: 0.37660\n",
      "Epoch: 10 | Iteration: 479 | Classification loss: 0.30516 | Regression loss: 0.29269 | Running loss: 0.37710\n",
      "Epoch: 10 | Iteration: 480 | Classification loss: 0.05676 | Regression loss: 0.26634 | Running loss: 0.37712\n",
      "Epoch: 10 | Iteration: 481 | Classification loss: 0.03226 | Regression loss: 0.20290 | Running loss: 0.37721\n",
      "Epoch: 10 | Iteration: 482 | Classification loss: 0.02800 | Regression loss: 0.13666 | Running loss: 0.37689\n",
      "Epoch: 10 | Iteration: 483 | Classification loss: 0.15275 | Regression loss: 0.28320 | Running loss: 0.37721\n",
      "Epoch: 10 | Iteration: 484 | Classification loss: 0.26951 | Regression loss: 0.44677 | Running loss: 0.37660\n",
      "Epoch: 10 | Iteration: 485 | Classification loss: 0.12399 | Regression loss: 0.22335 | Running loss: 0.37679\n",
      "Epoch: 10 | Iteration: 486 | Classification loss: 0.07384 | Regression loss: 0.18477 | Running loss: 0.37665\n",
      "Epoch: 10 | Iteration: 487 | Classification loss: 0.24634 | Regression loss: 0.44224 | Running loss: 0.37738\n",
      "Epoch: 10 | Iteration: 488 | Classification loss: 0.10501 | Regression loss: 0.31527 | Running loss: 0.37787\n",
      "Epoch: 10 | Iteration: 489 | Classification loss: 0.15174 | Regression loss: 0.25597 | Running loss: 0.37827\n",
      "Epoch: 10 | Iteration: 490 | Classification loss: 0.02917 | Regression loss: 0.18366 | Running loss: 0.37819\n",
      "Epoch: 10 | Iteration: 491 | Classification loss: 0.05142 | Regression loss: 0.24335 | Running loss: 0.37828\n",
      "Epoch: 10 | Iteration: 492 | Classification loss: 0.09530 | Regression loss: 0.27301 | Running loss: 0.37836\n",
      "Epoch: 10 | Iteration: 493 | Classification loss: 0.04546 | Regression loss: 0.16384 | Running loss: 0.37725\n",
      "Epoch: 10 | Iteration: 494 | Classification loss: 0.03386 | Regression loss: 0.15852 | Running loss: 0.37693\n",
      "Epoch: 10 | Iteration: 495 | Classification loss: 0.16284 | Regression loss: 0.25835 | Running loss: 0.37727\n",
      "Epoch: 10 | Iteration: 496 | Classification loss: 0.19006 | Regression loss: 0.46863 | Running loss: 0.37743\n",
      "Epoch: 10 | Iteration: 497 | Classification loss: 0.04536 | Regression loss: 0.10284 | Running loss: 0.37697\n",
      "Epoch: 10 | Iteration: 498 | Classification loss: 0.17131 | Regression loss: 0.21576 | Running loss: 0.37719\n",
      "Epoch: 10 | Iteration: 499 | Classification loss: 0.14432 | Regression loss: 0.34923 | Running loss: 0.37765\n",
      "Epoch: 10 | Iteration: 500 | Classification loss: 0.07769 | Regression loss: 0.18953 | Running loss: 0.37746\n",
      "Epoch: 10 | Iteration: 501 | Classification loss: 0.06920 | Regression loss: 0.22572 | Running loss: 0.37703\n",
      "Epoch: 10 | Iteration: 502 | Classification loss: 0.03346 | Regression loss: 0.13538 | Running loss: 0.37660\n",
      "Epoch: 10 | Iteration: 503 | Classification loss: 0.18767 | Regression loss: 0.39943 | Running loss: 0.37695\n",
      "Epoch: 10 | Iteration: 504 | Classification loss: 0.13790 | Regression loss: 0.29646 | Running loss: 0.37715\n",
      "Epoch: 10 | Iteration: 505 | Classification loss: 0.14913 | Regression loss: 0.49144 | Running loss: 0.37687\n",
      "Epoch: 10 | Iteration: 506 | Classification loss: 0.15200 | Regression loss: 0.38340 | Running loss: 0.37757\n",
      "Epoch: 10 | Iteration: 507 | Classification loss: 0.14141 | Regression loss: 0.12000 | Running loss: 0.37723\n",
      "Epoch: 10 | Iteration: 508 | Classification loss: 0.31140 | Regression loss: 0.56575 | Running loss: 0.37821\n",
      "Epoch: 10 | Iteration: 509 | Classification loss: 0.05521 | Regression loss: 0.35508 | Running loss: 0.37806\n",
      "Epoch: 10 | Iteration: 510 | Classification loss: 0.04230 | Regression loss: 0.20118 | Running loss: 0.37805\n",
      "Epoch: 10 | Iteration: 511 | Classification loss: 0.10856 | Regression loss: 0.31658 | Running loss: 0.37818\n",
      "Epoch: 10 | Iteration: 512 | Classification loss: 0.09588 | Regression loss: 0.27888 | Running loss: 0.37813\n",
      "Epoch: 10 | Iteration: 513 | Classification loss: 0.10611 | Regression loss: 0.17296 | Running loss: 0.37813\n",
      "Epoch: 10 | Iteration: 514 | Classification loss: 0.21238 | Regression loss: 0.23529 | Running loss: 0.37810\n",
      "Epoch: 10 | Iteration: 515 | Classification loss: 0.12189 | Regression loss: 0.22054 | Running loss: 0.37803\n",
      "Epoch: 10 | Iteration: 516 | Classification loss: 0.14286 | Regression loss: 0.18586 | Running loss: 0.37788\n",
      "Epoch: 10 | Iteration: 517 | Classification loss: 0.06404 | Regression loss: 0.22502 | Running loss: 0.37787\n",
      "Epoch: 10 | Iteration: 518 | Classification loss: 0.07304 | Regression loss: 0.30914 | Running loss: 0.37731\n",
      "Epoch: 10 | Iteration: 519 | Classification loss: 0.56762 | Regression loss: 0.41268 | Running loss: 0.37828\n",
      "Epoch: 10 | Iteration: 520 | Classification loss: 0.05809 | Regression loss: 0.17736 | Running loss: 0.37845\n",
      "Epoch: 10 | Iteration: 521 | Classification loss: 0.17056 | Regression loss: 0.26113 | Running loss: 0.37825\n",
      "Epoch: 10 | Iteration: 522 | Classification loss: 0.10455 | Regression loss: 0.22845 | Running loss: 0.37847\n",
      "Epoch: 10 | Iteration: 523 | Classification loss: 0.30743 | Regression loss: 0.41187 | Running loss: 0.37905\n",
      "Epoch: 10 | Iteration: 524 | Classification loss: 0.28207 | Regression loss: 0.30751 | Running loss: 0.37931\n",
      "Epoch: 10 | Iteration: 525 | Classification loss: 0.15841 | Regression loss: 0.22261 | Running loss: 0.37928\n",
      "Epoch: 10 | Iteration: 526 | Classification loss: 0.08202 | Regression loss: 0.23799 | Running loss: 0.37931\n",
      "Epoch: 10 | Iteration: 527 | Classification loss: 0.12091 | Regression loss: 0.20380 | Running loss: 0.37929\n",
      "Epoch: 10 | Iteration: 528 | Classification loss: 0.07481 | Regression loss: 0.26188 | Running loss: 0.37915\n",
      "Epoch: 10 | Iteration: 529 | Classification loss: 0.10259 | Regression loss: 0.29425 | Running loss: 0.37940\n",
      "Epoch: 10 | Iteration: 530 | Classification loss: 0.09852 | Regression loss: 0.24678 | Running loss: 0.37973\n",
      "Epoch: 10 | Iteration: 531 | Classification loss: 0.04560 | Regression loss: 0.21964 | Running loss: 0.37954\n",
      "Epoch: 10 | Iteration: 532 | Classification loss: 0.06782 | Regression loss: 0.39607 | Running loss: 0.37990\n",
      "Epoch: 10 | Iteration: 533 | Classification loss: 0.07448 | Regression loss: 0.27707 | Running loss: 0.38017\n",
      "Epoch: 10 | Iteration: 534 | Classification loss: 0.03021 | Regression loss: 0.20852 | Running loss: 0.38001\n",
      "Epoch: 10 | Iteration: 535 | Classification loss: 0.05963 | Regression loss: 0.24248 | Running loss: 0.37997\n",
      "Epoch: 10 | Iteration: 536 | Classification loss: 0.05020 | Regression loss: 0.19781 | Running loss: 0.37985\n",
      "Epoch: 10 | Iteration: 537 | Classification loss: 0.13426 | Regression loss: 0.41194 | Running loss: 0.38033\n",
      "Epoch: 10 | Iteration: 538 | Classification loss: 0.16362 | Regression loss: 0.10035 | Running loss: 0.37971\n",
      "Epoch: 10 | Iteration: 539 | Classification loss: 0.09901 | Regression loss: 0.24121 | Running loss: 0.37985\n",
      "Epoch: 10 | Iteration: 540 | Classification loss: 0.16973 | Regression loss: 0.15446 | Running loss: 0.37990\n",
      "Epoch: 10 | Iteration: 541 | Classification loss: 0.10648 | Regression loss: 0.21125 | Running loss: 0.37986\n",
      "Epoch: 10 | Iteration: 542 | Classification loss: 0.17993 | Regression loss: 0.26919 | Running loss: 0.38015\n",
      "Epoch: 10 | Iteration: 543 | Classification loss: 0.29334 | Regression loss: 0.38200 | Running loss: 0.38070\n",
      "Epoch: 10 | Iteration: 544 | Classification loss: 0.09518 | Regression loss: 0.13830 | Running loss: 0.38075\n",
      "Epoch: 10 | Iteration: 545 | Classification loss: 0.27946 | Regression loss: 0.41722 | Running loss: 0.38167\n",
      "Epoch: 10 | Iteration: 546 | Classification loss: 0.16789 | Regression loss: 0.20442 | Running loss: 0.38196\n",
      "Epoch: 10 | Iteration: 547 | Classification loss: 0.03248 | Regression loss: 0.09678 | Running loss: 0.38149\n",
      "Epoch: 10 | Iteration: 548 | Classification loss: 0.25283 | Regression loss: 0.34006 | Running loss: 0.38199\n",
      "Epoch: 10 | Iteration: 549 | Classification loss: 0.09356 | Regression loss: 0.11993 | Running loss: 0.38159\n",
      "Epoch: 10 | Iteration: 550 | Classification loss: 0.07428 | Regression loss: 0.10264 | Running loss: 0.38117\n",
      "Epoch: 10 | Iteration: 551 | Classification loss: 0.03274 | Regression loss: 0.19204 | Running loss: 0.38077\n",
      "Epoch: 10 | Iteration: 552 | Classification loss: 0.10497 | Regression loss: 0.21007 | Running loss: 0.38058\n",
      "Epoch: 10 | Iteration: 553 | Classification loss: 0.31282 | Regression loss: 0.48218 | Running loss: 0.38170\n",
      "Epoch: 10 | Iteration: 554 | Classification loss: 0.13355 | Regression loss: 0.41207 | Running loss: 0.38239\n",
      "Epoch: 10 | Iteration: 555 | Classification loss: 0.15701 | Regression loss: 0.17785 | Running loss: 0.38267\n",
      "Epoch: 10 | Iteration: 556 | Classification loss: 0.14644 | Regression loss: 0.30394 | Running loss: 0.38327\n",
      "Epoch: 10 | Iteration: 557 | Classification loss: 0.15027 | Regression loss: 0.28704 | Running loss: 0.38378\n",
      "Epoch: 10 | Iteration: 558 | Classification loss: 0.07181 | Regression loss: 0.26498 | Running loss: 0.38347\n",
      "Epoch: 10 | Iteration: 559 | Classification loss: 0.11851 | Regression loss: 0.24335 | Running loss: 0.38265\n",
      "Epoch: 10 | Iteration: 560 | Classification loss: 0.07614 | Regression loss: 0.18293 | Running loss: 0.38236\n",
      "Epoch: 10 | Iteration: 561 | Classification loss: 0.10692 | Regression loss: 0.24638 | Running loss: 0.38253\n",
      "Epoch: 10 | Iteration: 562 | Classification loss: 0.05926 | Regression loss: 0.15919 | Running loss: 0.38236\n",
      "Epoch: 10 | Iteration: 563 | Classification loss: 0.08766 | Regression loss: 0.31060 | Running loss: 0.38184\n",
      "Epoch: 10 | Iteration: 564 | Classification loss: 0.04902 | Regression loss: 0.12840 | Running loss: 0.38144\n",
      "Epoch: 10 | Iteration: 565 | Classification loss: 0.21580 | Regression loss: 0.32750 | Running loss: 0.38139\n",
      "Epoch: 10 | Iteration: 566 | Classification loss: 0.15098 | Regression loss: 0.31713 | Running loss: 0.38198\n",
      "Epoch: 10 | Iteration: 567 | Classification loss: 0.04694 | Regression loss: 0.13869 | Running loss: 0.38130\n",
      "Epoch: 10 | Iteration: 568 | Classification loss: 0.14525 | Regression loss: 0.34738 | Running loss: 0.38188\n",
      "Epoch: 10 | Iteration: 569 | Classification loss: 0.04278 | Regression loss: 0.19114 | Running loss: 0.38165\n",
      "Epoch: 10 | Iteration: 570 | Classification loss: 0.26960 | Regression loss: 0.47001 | Running loss: 0.38229\n",
      "Epoch: 10 | Iteration: 571 | Classification loss: 0.01719 | Regression loss: 0.08213 | Running loss: 0.38193\n",
      "Epoch: 10 | Iteration: 572 | Classification loss: 0.03908 | Regression loss: 0.14636 | Running loss: 0.38142\n",
      "Epoch: 10 | Iteration: 573 | Classification loss: 0.09179 | Regression loss: 0.18280 | Running loss: 0.38140\n",
      "Epoch: 10 | Iteration: 574 | Classification loss: 0.06465 | Regression loss: 0.25530 | Running loss: 0.38204\n",
      "Epoch: 10 | Iteration: 575 | Classification loss: 0.15534 | Regression loss: 0.21619 | Running loss: 0.38222\n",
      "Epoch: 10 | Iteration: 576 | Classification loss: 0.12284 | Regression loss: 0.14882 | Running loss: 0.38240\n",
      "Epoch: 10 | Iteration: 577 | Classification loss: 0.14558 | Regression loss: 0.32981 | Running loss: 0.38295\n",
      "Epoch: 10 | Iteration: 578 | Classification loss: 0.10578 | Regression loss: 0.27898 | Running loss: 0.38335\n",
      "Epoch: 10 | Iteration: 579 | Classification loss: 0.03124 | Regression loss: 0.14937 | Running loss: 0.38349\n",
      "Epoch: 10 | Iteration: 580 | Classification loss: 0.08551 | Regression loss: 0.22899 | Running loss: 0.38345\n",
      "Epoch: 10 | Iteration: 581 | Classification loss: 0.06028 | Regression loss: 0.22709 | Running loss: 0.38309\n",
      "Epoch: 10 | Iteration: 582 | Classification loss: 0.10192 | Regression loss: 0.28050 | Running loss: 0.38307\n",
      "Epoch: 10 | Iteration: 583 | Classification loss: 0.09632 | Regression loss: 0.47694 | Running loss: 0.38343\n",
      "Epoch: 10 | Iteration: 584 | Classification loss: 0.09221 | Regression loss: 0.23935 | Running loss: 0.38327\n",
      "Epoch: 10 | Iteration: 585 | Classification loss: 0.07252 | Regression loss: 0.21207 | Running loss: 0.38349\n",
      "Epoch: 10 | Iteration: 586 | Classification loss: 0.10543 | Regression loss: 0.13994 | Running loss: 0.38314\n",
      "Epoch: 10 | Iteration: 587 | Classification loss: 0.06179 | Regression loss: 0.27850 | Running loss: 0.38342\n",
      "Epoch: 10 | Iteration: 588 | Classification loss: 0.09344 | Regression loss: 0.31617 | Running loss: 0.38340\n",
      "Epoch: 10 | Iteration: 589 | Classification loss: 0.05652 | Regression loss: 0.14343 | Running loss: 0.38307\n",
      "Epoch: 10 | Iteration: 590 | Classification loss: 0.10884 | Regression loss: 0.21955 | Running loss: 0.38230\n",
      "Epoch: 10 | Iteration: 591 | Classification loss: 0.09543 | Regression loss: 0.27528 | Running loss: 0.38267\n",
      "Epoch: 10 | Iteration: 592 | Classification loss: 0.35901 | Regression loss: 0.07368 | Running loss: 0.38308\n",
      "Epoch: 10 | Iteration: 593 | Classification loss: 0.12043 | Regression loss: 0.31188 | Running loss: 0.38304\n",
      "Epoch: 10 | Iteration: 594 | Classification loss: 0.13516 | Regression loss: 0.37735 | Running loss: 0.38333\n",
      "Epoch: 10 | Iteration: 595 | Classification loss: 0.32305 | Regression loss: 0.27523 | Running loss: 0.38412\n",
      "Epoch: 10 | Iteration: 596 | Classification loss: 0.21453 | Regression loss: 0.41468 | Running loss: 0.38495\n",
      "Epoch: 10 | Iteration: 597 | Classification loss: 0.14059 | Regression loss: 0.34746 | Running loss: 0.38562\n",
      "Epoch: 10 | Iteration: 598 | Classification loss: 0.05537 | Regression loss: 0.16022 | Running loss: 0.38605\n",
      "Epoch: 10 | Iteration: 599 | Classification loss: 0.03123 | Regression loss: 0.08557 | Running loss: 0.38588\n",
      "Epoch: 10 | Iteration: 600 | Classification loss: 0.15371 | Regression loss: 0.13201 | Running loss: 0.38565\n",
      "Epoch: 10 | Iteration: 601 | Classification loss: 0.29497 | Regression loss: 0.54699 | Running loss: 0.38683\n",
      "Epoch: 10 | Iteration: 602 | Classification loss: 0.78923 | Regression loss: 0.29566 | Running loss: 0.38832\n",
      "Epoch: 10 | Iteration: 603 | Classification loss: 0.11396 | Regression loss: 0.32971 | Running loss: 0.38874\n",
      "Epoch: 10 | Iteration: 604 | Classification loss: 0.05275 | Regression loss: 0.18063 | Running loss: 0.38881\n",
      "Epoch: 10 | Iteration: 605 | Classification loss: 0.04701 | Regression loss: 0.30633 | Running loss: 0.38919\n",
      "Epoch: 10 | Iteration: 606 | Classification loss: 0.13696 | Regression loss: 0.28007 | Running loss: 0.38949\n",
      "Epoch: 10 | Iteration: 607 | Classification loss: 0.08051 | Regression loss: 0.29737 | Running loss: 0.38962\n",
      "Epoch: 10 | Iteration: 608 | Classification loss: 0.15115 | Regression loss: 0.36730 | Running loss: 0.38981\n",
      "Epoch: 10 | Iteration: 609 | Classification loss: 0.04364 | Regression loss: 0.22151 | Running loss: 0.38980\n",
      "Epoch: 10 | Iteration: 610 | Classification loss: 0.10525 | Regression loss: 0.25293 | Running loss: 0.38978\n",
      "Epoch: 10 | Iteration: 611 | Classification loss: 0.67777 | Regression loss: 0.30548 | Running loss: 0.39096\n",
      "Epoch: 10 | Iteration: 612 | Classification loss: 0.03869 | Regression loss: 0.21888 | Running loss: 0.39049\n",
      "Epoch: 10 | Iteration: 613 | Classification loss: 0.30627 | Regression loss: 0.31401 | Running loss: 0.39078\n",
      "Epoch: 10 | Iteration: 614 | Classification loss: 0.10776 | Regression loss: 0.26775 | Running loss: 0.39075\n",
      "Epoch: 10 | Iteration: 615 | Classification loss: 0.06674 | Regression loss: 0.20574 | Running loss: 0.39066\n",
      "Epoch: 10 | Iteration: 616 | Classification loss: 0.03406 | Regression loss: 0.13435 | Running loss: 0.39051\n",
      "Epoch: 10 | Iteration: 617 | Classification loss: 0.14686 | Regression loss: 0.06094 | Running loss: 0.39051\n",
      "Epoch: 10 | Iteration: 618 | Classification loss: 0.15728 | Regression loss: 0.15571 | Running loss: 0.39024\n",
      "Epoch: 10 | Iteration: 619 | Classification loss: 0.13161 | Regression loss: 0.16209 | Running loss: 0.38972\n",
      "Epoch: 10 | Iteration: 620 | Classification loss: 0.27655 | Regression loss: 0.15474 | Running loss: 0.38990\n",
      "Epoch: 10 | Iteration: 621 | Classification loss: 0.17238 | Regression loss: 0.24170 | Running loss: 0.39040\n",
      "Epoch: 10 | Iteration: 622 | Classification loss: 0.12312 | Regression loss: 0.17893 | Running loss: 0.39029\n",
      "Epoch: 10 | Iteration: 623 | Classification loss: 0.05837 | Regression loss: 0.17890 | Running loss: 0.38994\n",
      "Epoch: 10 | Iteration: 624 | Classification loss: 0.18340 | Regression loss: 0.33165 | Running loss: 0.38986\n",
      "Epoch: 10 | Iteration: 625 | Classification loss: 0.20302 | Regression loss: 0.24397 | Running loss: 0.38928\n",
      "Epoch: 10 | Iteration: 626 | Classification loss: 0.12812 | Regression loss: 0.25642 | Running loss: 0.38987\n",
      "Epoch: 10 | Iteration: 627 | Classification loss: 0.06969 | Regression loss: 0.07058 | Running loss: 0.38927\n",
      "Epoch: 10 | Iteration: 628 | Classification loss: 0.12053 | Regression loss: 0.15038 | Running loss: 0.38920\n",
      "Epoch: 10 | Iteration: 629 | Classification loss: 0.04740 | Regression loss: 0.12418 | Running loss: 0.38911\n",
      "Epoch: 10 | Iteration: 630 | Classification loss: 0.64800 | Regression loss: 0.22126 | Running loss: 0.39004\n",
      "Epoch: 10 | Iteration: 631 | Classification loss: 0.22304 | Regression loss: 0.36551 | Running loss: 0.39022\n",
      "Epoch: 10 | Iteration: 632 | Classification loss: 0.10261 | Regression loss: 0.27208 | Running loss: 0.39014\n",
      "Epoch: 10 | Iteration: 633 | Classification loss: 0.07917 | Regression loss: 0.21173 | Running loss: 0.38990\n",
      "Epoch: 10 | Iteration: 634 | Classification loss: 0.09529 | Regression loss: 0.36274 | Running loss: 0.39023\n",
      "Epoch: 10 | Iteration: 635 | Classification loss: 0.08399 | Regression loss: 0.28596 | Running loss: 0.39054\n",
      "Epoch: 10 | Iteration: 636 | Classification loss: 0.03451 | Regression loss: 0.17067 | Running loss: 0.39048\n",
      "Epoch: 10 | Iteration: 637 | Classification loss: 0.13332 | Regression loss: 0.33947 | Running loss: 0.39089\n",
      "Epoch: 10 | Iteration: 638 | Classification loss: 0.05420 | Regression loss: 0.18597 | Running loss: 0.39039\n",
      "Epoch: 10 | Iteration: 639 | Classification loss: 0.12769 | Regression loss: 0.26810 | Running loss: 0.39058\n",
      "Epoch: 10 | Iteration: 640 | Classification loss: 0.06386 | Regression loss: 0.24897 | Running loss: 0.39070\n",
      "Epoch: 10 | Iteration: 641 | Classification loss: 0.17688 | Regression loss: 0.18863 | Running loss: 0.39037\n",
      "Epoch: 10 | Iteration: 642 | Classification loss: 0.04786 | Regression loss: 0.24825 | Running loss: 0.39009\n",
      "Epoch: 10 | Iteration: 643 | Classification loss: 0.06057 | Regression loss: 0.16684 | Running loss: 0.39002\n",
      "Epoch: 10 | Iteration: 644 | Classification loss: 0.11797 | Regression loss: 0.32882 | Running loss: 0.39047\n",
      "Epoch: 10 | Iteration: 645 | Classification loss: 0.04620 | Regression loss: 0.20690 | Running loss: 0.39032\n",
      "Epoch: 10 | Iteration: 646 | Classification loss: 0.30652 | Regression loss: 0.21015 | Running loss: 0.39070\n",
      "Epoch: 10 | Iteration: 647 | Classification loss: 0.12854 | Regression loss: 0.29468 | Running loss: 0.39102\n",
      "Epoch: 10 | Iteration: 648 | Classification loss: 0.06241 | Regression loss: 0.24017 | Running loss: 0.39119\n",
      "Epoch: 10 | Iteration: 649 | Classification loss: 0.05822 | Regression loss: 0.21464 | Running loss: 0.39122\n",
      "Epoch: 10 | Iteration: 650 | Classification loss: 0.25273 | Regression loss: 0.26462 | Running loss: 0.39164\n",
      "Epoch: 10 | Iteration: 651 | Classification loss: 0.10098 | Regression loss: 0.30447 | Running loss: 0.39222\n",
      "Epoch: 10 | Iteration: 652 | Classification loss: 0.04638 | Regression loss: 0.24810 | Running loss: 0.39220\n",
      "Epoch: 10 | Iteration: 653 | Classification loss: 0.09085 | Regression loss: 0.18823 | Running loss: 0.39174\n",
      "Epoch: 10 | Iteration: 654 | Classification loss: 0.26353 | Regression loss: 0.37664 | Running loss: 0.39224\n",
      "Epoch: 10 | Iteration: 655 | Classification loss: 0.20097 | Regression loss: 0.30536 | Running loss: 0.39284\n",
      "Epoch: 10 | Iteration: 656 | Classification loss: 0.12795 | Regression loss: 0.26370 | Running loss: 0.39323\n",
      "Epoch: 10 | Iteration: 657 | Classification loss: 0.14495 | Regression loss: 0.31819 | Running loss: 0.39340\n",
      "Epoch: 10 | Iteration: 658 | Classification loss: 0.19354 | Regression loss: 0.25656 | Running loss: 0.39361\n",
      "Epoch: 10 | Iteration: 659 | Classification loss: 0.06497 | Regression loss: 0.36266 | Running loss: 0.39341\n",
      "Epoch: 10 | Iteration: 660 | Classification loss: 0.03824 | Regression loss: 0.25952 | Running loss: 0.39256\n",
      "Epoch: 10 | Iteration: 661 | Classification loss: 0.11864 | Regression loss: 0.13718 | Running loss: 0.39234\n",
      "Epoch: 10 | Iteration: 662 | Classification loss: 0.15472 | Regression loss: 0.51544 | Running loss: 0.39328\n",
      "Epoch: 10 | Iteration: 663 | Classification loss: 0.10380 | Regression loss: 0.39045 | Running loss: 0.39341\n",
      "Epoch: 10 | Iteration: 664 | Classification loss: 0.10170 | Regression loss: 0.12121 | Running loss: 0.39245\n",
      "Epoch: 10 | Iteration: 665 | Classification loss: 0.05609 | Regression loss: 0.21524 | Running loss: 0.39190\n",
      "Epoch: 10 | Iteration: 666 | Classification loss: 0.10042 | Regression loss: 0.15567 | Running loss: 0.39184\n",
      "Epoch: 10 | Iteration: 667 | Classification loss: 0.03850 | Regression loss: 0.25447 | Running loss: 0.39163\n",
      "Epoch: 10 | Iteration: 668 | Classification loss: 0.04718 | Regression loss: 0.18871 | Running loss: 0.39091\n",
      "Epoch: 10 | Iteration: 669 | Classification loss: 0.06753 | Regression loss: 0.19168 | Running loss: 0.38983\n",
      "Epoch: 10 | Iteration: 670 | Classification loss: 0.06804 | Regression loss: 0.13381 | Running loss: 0.38878\n",
      "Epoch: 10 | Iteration: 671 | Classification loss: 0.05372 | Regression loss: 0.17346 | Running loss: 0.38850\n",
      "Epoch: 10 | Iteration: 672 | Classification loss: 0.09028 | Regression loss: 0.15885 | Running loss: 0.38813\n",
      "Epoch: 10 | Iteration: 673 | Classification loss: 0.06506 | Regression loss: 0.22861 | Running loss: 0.38839\n",
      "Epoch: 10 | Iteration: 674 | Classification loss: 0.03666 | Regression loss: 0.10551 | Running loss: 0.38791\n",
      "Epoch: 10 | Iteration: 675 | Classification loss: 0.15237 | Regression loss: 0.20376 | Running loss: 0.38802\n",
      "Epoch: 10 | Iteration: 676 | Classification loss: 0.02128 | Regression loss: 0.30308 | Running loss: 0.38803\n",
      "Epoch: 10 | Iteration: 677 | Classification loss: 0.04958 | Regression loss: 0.16911 | Running loss: 0.38806\n",
      "Epoch: 10 | Iteration: 678 | Classification loss: 0.13514 | Regression loss: 0.18807 | Running loss: 0.38782\n",
      "Epoch: 10 | Iteration: 679 | Classification loss: 0.25732 | Regression loss: 0.22572 | Running loss: 0.38815\n",
      "Epoch: 10 | Iteration: 680 | Classification loss: 0.05649 | Regression loss: 0.11213 | Running loss: 0.38813\n",
      "Epoch: 10 | Iteration: 681 | Classification loss: 0.10661 | Regression loss: 0.21666 | Running loss: 0.38794\n",
      "Epoch: 10 | Iteration: 682 | Classification loss: 0.11657 | Regression loss: 0.32797 | Running loss: 0.38779\n",
      "Epoch: 10 | Iteration: 683 | Classification loss: 0.03994 | Regression loss: 0.16253 | Running loss: 0.38762\n",
      "Epoch: 10 | Iteration: 684 | Classification loss: 0.08448 | Regression loss: 0.17695 | Running loss: 0.38725\n",
      "Epoch: 10 | Iteration: 685 | Classification loss: 0.12743 | Regression loss: 0.27780 | Running loss: 0.38659\n",
      "Epoch: 10 | Iteration: 686 | Classification loss: 0.16103 | Regression loss: 0.30980 | Running loss: 0.38642\n",
      "Epoch: 10 | Iteration: 687 | Classification loss: 0.01449 | Regression loss: 0.05238 | Running loss: 0.38572\n",
      "Epoch: 10 | Iteration: 688 | Classification loss: 0.18409 | Regression loss: 0.33968 | Running loss: 0.38613\n",
      "Epoch: 10 | Iteration: 689 | Classification loss: 0.08081 | Regression loss: 0.18417 | Running loss: 0.38616\n",
      "Epoch: 10 | Iteration: 690 | Classification loss: 0.12532 | Regression loss: 0.42996 | Running loss: 0.38684\n",
      "Epoch: 10 | Iteration: 691 | Classification loss: 0.10018 | Regression loss: 0.17492 | Running loss: 0.38696\n",
      "Epoch: 10 | Iteration: 692 | Classification loss: 0.07418 | Regression loss: 0.19131 | Running loss: 0.38668\n",
      "Epoch: 10 | Iteration: 693 | Classification loss: 0.18107 | Regression loss: 0.35705 | Running loss: 0.38708\n",
      "Epoch: 10 | Iteration: 694 | Classification loss: 0.11058 | Regression loss: 0.21496 | Running loss: 0.38687\n",
      "Epoch: 10 | Iteration: 695 | Classification loss: 0.07677 | Regression loss: 0.21851 | Running loss: 0.38714\n",
      "Epoch: 10 | Iteration: 696 | Classification loss: 0.24581 | Regression loss: 0.15691 | Running loss: 0.38755\n",
      "Epoch: 10 | Iteration: 697 | Classification loss: 0.08367 | Regression loss: 0.15683 | Running loss: 0.38725\n",
      "Epoch: 10 | Iteration: 698 | Classification loss: 0.09126 | Regression loss: 0.34322 | Running loss: 0.38711\n",
      "Epoch: 10 | Iteration: 699 | Classification loss: 0.05821 | Regression loss: 0.15903 | Running loss: 0.38676\n",
      "Epoch: 10 | Iteration: 700 | Classification loss: 0.32690 | Regression loss: 0.61130 | Running loss: 0.38820\n",
      "Epoch: 10 | Iteration: 701 | Classification loss: 0.08495 | Regression loss: 0.19709 | Running loss: 0.38844\n",
      "Epoch: 10 | Iteration: 702 | Classification loss: 0.10632 | Regression loss: 0.40169 | Running loss: 0.38909\n",
      "Epoch: 10 | Iteration: 703 | Classification loss: 0.29464 | Regression loss: 0.16341 | Running loss: 0.38937\n",
      "Epoch: 10 | Iteration: 704 | Classification loss: 0.10640 | Regression loss: 0.27574 | Running loss: 0.38952\n",
      "Epoch: 10 | Iteration: 705 | Classification loss: 0.13113 | Regression loss: 0.17740 | Running loss: 0.38946\n",
      "Epoch: 10 | Iteration: 706 | Classification loss: 0.05350 | Regression loss: 0.22063 | Running loss: 0.38912\n",
      "Epoch: 10 | Iteration: 707 | Classification loss: 0.34657 | Regression loss: 0.31176 | Running loss: 0.38954\n",
      "Epoch: 10 | Iteration: 708 | Classification loss: 0.05590 | Regression loss: 0.14736 | Running loss: 0.38930\n",
      "Epoch: 10 | Iteration: 709 | Classification loss: 0.11699 | Regression loss: 0.28719 | Running loss: 0.38941\n",
      "Epoch: 10 | Iteration: 710 | Classification loss: 0.27357 | Regression loss: 0.49373 | Running loss: 0.38976\n",
      "Epoch: 10 | Iteration: 711 | Classification loss: 0.39036 | Regression loss: 0.12377 | Running loss: 0.39007\n",
      "Epoch: 10 | Iteration: 712 | Classification loss: 0.03605 | Regression loss: 0.19641 | Running loss: 0.39016\n",
      "Epoch: 10 | Iteration: 713 | Classification loss: 0.17082 | Regression loss: 0.26680 | Running loss: 0.39041\n",
      "Epoch: 10 | Iteration: 714 | Classification loss: 0.04691 | Regression loss: 0.16008 | Running loss: 0.39055\n",
      "Epoch: 10 | Iteration: 715 | Classification loss: 0.04291 | Regression loss: 0.16896 | Running loss: 0.38961\n",
      "Epoch: 10 | Iteration: 716 | Classification loss: 0.10418 | Regression loss: 0.23531 | Running loss: 0.38863\n",
      "Epoch: 10 | Iteration: 717 | Classification loss: 0.03275 | Regression loss: 0.22682 | Running loss: 0.38850\n",
      "Epoch: 10 | Iteration: 718 | Classification loss: 0.10946 | Regression loss: 0.21003 | Running loss: 0.38859\n",
      "Epoch: 10 | Iteration: 719 | Classification loss: 0.05891 | Regression loss: 0.11514 | Running loss: 0.38678\n",
      "Epoch: 10 | Iteration: 720 | Classification loss: 0.10942 | Regression loss: 0.32684 | Running loss: 0.38664\n",
      "Epoch: 10 | Iteration: 721 | Classification loss: 0.09913 | Regression loss: 0.17051 | Running loss: 0.38630\n",
      "Epoch: 10 | Iteration: 722 | Classification loss: 0.07628 | Regression loss: 0.33292 | Running loss: 0.38616\n",
      "Epoch: 10 | Iteration: 723 | Classification loss: 0.05211 | Regression loss: 0.16406 | Running loss: 0.38565\n",
      "Epoch: 10 | Iteration: 724 | Classification loss: 0.04618 | Regression loss: 0.15671 | Running loss: 0.38529\n",
      "Epoch: 10 | Iteration: 725 | Classification loss: 0.12693 | Regression loss: 0.34226 | Running loss: 0.38486\n",
      "Epoch: 10 | Iteration: 726 | Classification loss: 0.03094 | Regression loss: 0.18511 | Running loss: 0.38473\n",
      "Epoch: 10 | Iteration: 727 | Classification loss: 0.07143 | Regression loss: 0.21564 | Running loss: 0.38479\n",
      "Epoch: 10 | Iteration: 728 | Classification loss: 0.12098 | Regression loss: 0.25287 | Running loss: 0.38493\n",
      "Epoch: 10 | Iteration: 729 | Classification loss: 0.05587 | Regression loss: 0.20675 | Running loss: 0.38465\n",
      "Epoch: 10 | Iteration: 730 | Classification loss: 0.21459 | Regression loss: 0.58726 | Running loss: 0.38578\n",
      "Epoch: 10 | Iteration: 731 | Classification loss: 0.03924 | Regression loss: 0.13569 | Running loss: 0.38556\n",
      "Epoch: 10 | Iteration: 732 | Classification loss: 0.19678 | Regression loss: 0.34115 | Running loss: 0.38622\n",
      "Epoch: 10 | Iteration: 733 | Classification loss: 0.13239 | Regression loss: 0.24925 | Running loss: 0.38634\n",
      "Epoch: 10 | Iteration: 734 | Classification loss: 0.11704 | Regression loss: 0.27967 | Running loss: 0.38604\n",
      "Epoch: 10 | Iteration: 735 | Classification loss: 0.20571 | Regression loss: 0.29950 | Running loss: 0.38635\n",
      "Epoch: 10 | Iteration: 736 | Classification loss: 0.10328 | Regression loss: 0.18180 | Running loss: 0.38560\n",
      "Epoch: 10 | Iteration: 737 | Classification loss: 0.16141 | Regression loss: 0.30364 | Running loss: 0.38608\n",
      "Epoch: 10 | Iteration: 738 | Classification loss: 0.05581 | Regression loss: 0.34882 | Running loss: 0.38531\n",
      "Epoch: 10 | Iteration: 739 | Classification loss: 0.09587 | Regression loss: 0.19819 | Running loss: 0.38551\n",
      "Epoch: 10 | Iteration: 740 | Classification loss: 0.16633 | Regression loss: 0.21001 | Running loss: 0.38542\n",
      "Epoch: 10 | Iteration: 741 | Classification loss: 0.12457 | Regression loss: 0.28458 | Running loss: 0.38553\n",
      "Epoch: 10 | Iteration: 742 | Classification loss: 0.22404 | Regression loss: 0.26345 | Running loss: 0.38548\n",
      "Epoch: 10 | Iteration: 743 | Classification loss: 0.12640 | Regression loss: 0.34788 | Running loss: 0.38597\n",
      "Epoch: 10 | Iteration: 744 | Classification loss: 0.14229 | Regression loss: 0.45370 | Running loss: 0.38669\n",
      "Epoch: 10 | Iteration: 745 | Classification loss: 0.07389 | Regression loss: 0.18310 | Running loss: 0.38640\n",
      "Epoch: 10 | Iteration: 746 | Classification loss: 0.06165 | Regression loss: 0.16236 | Running loss: 0.38618\n",
      "Epoch: 10 | Iteration: 747 | Classification loss: 0.16366 | Regression loss: 0.40120 | Running loss: 0.38672\n",
      "Epoch: 10 | Iteration: 748 | Classification loss: 0.08857 | Regression loss: 0.23489 | Running loss: 0.38678\n",
      "Epoch: 10 | Iteration: 749 | Classification loss: 0.05120 | Regression loss: 0.23261 | Running loss: 0.38615\n",
      "Epoch: 10 | Iteration: 750 | Classification loss: 0.09740 | Regression loss: 0.31825 | Running loss: 0.38643\n",
      "Epoch: 10 | Iteration: 751 | Classification loss: 0.10650 | Regression loss: 0.34959 | Running loss: 0.38681\n",
      "Epoch: 10 | Iteration: 752 | Classification loss: 0.08158 | Regression loss: 0.29813 | Running loss: 0.38717\n",
      "Epoch: 10 | Iteration: 753 | Classification loss: 0.08119 | Regression loss: 0.19633 | Running loss: 0.38584\n",
      "Epoch: 10 | Iteration: 754 | Classification loss: 0.04055 | Regression loss: 0.16257 | Running loss: 0.38453\n",
      "Epoch: 10 | Iteration: 755 | Classification loss: 0.10603 | Regression loss: 0.42763 | Running loss: 0.38497\n",
      "Epoch: 10 | Iteration: 756 | Classification loss: 0.16590 | Regression loss: 0.34852 | Running loss: 0.38532\n",
      "Epoch: 10 | Iteration: 757 | Classification loss: 0.06985 | Regression loss: 0.19829 | Running loss: 0.38546\n",
      "Epoch: 10 | Iteration: 758 | Classification loss: 0.10136 | Regression loss: 0.22115 | Running loss: 0.38473\n",
      "Epoch: 10 | Iteration: 759 | Classification loss: 0.12640 | Regression loss: 0.22495 | Running loss: 0.38477\n",
      "Epoch: 10 | Iteration: 760 | Classification loss: 0.12483 | Regression loss: 0.34759 | Running loss: 0.38475\n",
      "Epoch: 10 | Iteration: 761 | Classification loss: 0.11118 | Regression loss: 0.35837 | Running loss: 0.38521\n",
      "Epoch: 10 | Iteration: 762 | Classification loss: 0.13125 | Regression loss: 0.46611 | Running loss: 0.38542\n",
      "Epoch: 10 | Iteration: 763 | Classification loss: 0.10028 | Regression loss: 0.22794 | Running loss: 0.38543\n",
      "Epoch: 10 | Iteration: 764 | Classification loss: 0.04603 | Regression loss: 0.27413 | Running loss: 0.38454\n",
      "Epoch: 10 | Iteration: 765 | Classification loss: 0.07576 | Regression loss: 0.34537 | Running loss: 0.38495\n",
      "Epoch: 10 | Iteration: 766 | Classification loss: 0.12864 | Regression loss: 0.27988 | Running loss: 0.38487\n",
      "Epoch: 10 | Iteration: 767 | Classification loss: 0.31861 | Regression loss: 0.25851 | Running loss: 0.38506\n",
      "Epoch: 10 | Iteration: 768 | Classification loss: 0.15136 | Regression loss: 0.22475 | Running loss: 0.38525\n",
      "Epoch: 10 | Iteration: 769 | Classification loss: 0.12002 | Regression loss: 0.36848 | Running loss: 0.38525\n",
      "Epoch: 10 | Iteration: 770 | Classification loss: 0.08061 | Regression loss: 0.29465 | Running loss: 0.38540\n",
      "Epoch: 10 | Iteration: 771 | Classification loss: 0.24586 | Regression loss: 0.17060 | Running loss: 0.38512\n",
      "Epoch: 10 | Iteration: 772 | Classification loss: 0.14166 | Regression loss: 0.27553 | Running loss: 0.38512\n",
      "Epoch: 10 | Iteration: 773 | Classification loss: 0.12731 | Regression loss: 0.28773 | Running loss: 0.38475\n",
      "Epoch: 10 | Iteration: 774 | Classification loss: 0.17006 | Regression loss: 0.37261 | Running loss: 0.38530\n",
      "Epoch: 10 | Iteration: 775 | Classification loss: 0.06440 | Regression loss: 0.33344 | Running loss: 0.38503\n",
      "Epoch: 10 | Iteration: 776 | Classification loss: 0.08868 | Regression loss: 0.39956 | Running loss: 0.38514\n",
      "Epoch: 10 | Iteration: 777 | Classification loss: 0.03924 | Regression loss: 0.26761 | Running loss: 0.38517\n",
      "Epoch: 10 | Iteration: 778 | Classification loss: 0.07910 | Regression loss: 0.32795 | Running loss: 0.38522\n",
      "Epoch: 10 | Iteration: 779 | Classification loss: 0.06197 | Regression loss: 0.30812 | Running loss: 0.38506\n",
      "Epoch: 10 | Iteration: 780 | Classification loss: 0.09177 | Regression loss: 0.20102 | Running loss: 0.38480\n",
      "Epoch: 10 | Iteration: 781 | Classification loss: 0.30562 | Regression loss: 0.28671 | Running loss: 0.38520\n",
      "Epoch: 10 | Iteration: 782 | Classification loss: 0.12178 | Regression loss: 0.15546 | Running loss: 0.38483\n",
      "Epoch: 10 | Iteration: 783 | Classification loss: 0.10281 | Regression loss: 0.37093 | Running loss: 0.38460\n",
      "Epoch: 10 | Iteration: 784 | Classification loss: 0.26198 | Regression loss: 0.43091 | Running loss: 0.38525\n",
      "Epoch: 10 | Iteration: 785 | Classification loss: 0.24783 | Regression loss: 0.66294 | Running loss: 0.38688\n",
      "Epoch: 10 | Iteration: 786 | Classification loss: 0.12407 | Regression loss: 0.38625 | Running loss: 0.38764\n",
      "Epoch: 10 | Iteration: 787 | Classification loss: 0.06250 | Regression loss: 0.20242 | Running loss: 0.38769\n",
      "Epoch: 10 | Iteration: 788 | Classification loss: 0.12414 | Regression loss: 0.24155 | Running loss: 0.38796\n",
      "Epoch: 10 | Iteration: 789 | Classification loss: 0.12026 | Regression loss: 0.13531 | Running loss: 0.38785\n",
      "Epoch: 10 | Iteration: 790 | Classification loss: 0.24376 | Regression loss: 0.16723 | Running loss: 0.38780\n",
      "Epoch: 10 | Iteration: 791 | Classification loss: 0.07928 | Regression loss: 0.21485 | Running loss: 0.38781\n",
      "Epoch: 10 | Iteration: 792 | Classification loss: 0.36460 | Regression loss: 0.25731 | Running loss: 0.38835\n",
      "Epoch: 10 | Iteration: 793 | Classification loss: 0.03129 | Regression loss: 0.14887 | Running loss: 0.38840\n",
      "Epoch: 10 | Iteration: 794 | Classification loss: 0.03770 | Regression loss: 0.19360 | Running loss: 0.38844\n",
      "Epoch: 10 | Iteration: 795 | Classification loss: 0.15201 | Regression loss: 0.31911 | Running loss: 0.38835\n",
      "Epoch: 10 | Iteration: 796 | Classification loss: 0.08406 | Regression loss: 0.45076 | Running loss: 0.38884\n",
      "Epoch: 10 | Iteration: 797 | Classification loss: 0.07891 | Regression loss: 0.18830 | Running loss: 0.38878\n",
      "Epoch: 10 | Iteration: 798 | Classification loss: 0.28036 | Regression loss: 0.17786 | Running loss: 0.38882\n",
      "Epoch: 10 | Iteration: 799 | Classification loss: 0.13481 | Regression loss: 0.43367 | Running loss: 0.38936\n",
      "Epoch: 10 | Iteration: 800 | Classification loss: 0.07514 | Regression loss: 0.41755 | Running loss: 0.38957\n",
      "Epoch: 10 | Iteration: 801 | Classification loss: 0.05567 | Regression loss: 0.24313 | Running loss: 0.38991\n",
      "Epoch: 10 | Iteration: 802 | Classification loss: 0.09940 | Regression loss: 0.21449 | Running loss: 0.39000\n",
      "Epoch: 10 | Iteration: 803 | Classification loss: 0.04668 | Regression loss: 0.22376 | Running loss: 0.38955\n",
      "Epoch: 10 | Iteration: 804 | Classification loss: 0.08956 | Regression loss: 0.20451 | Running loss: 0.38966\n",
      "Epoch: 10 | Iteration: 805 | Classification loss: 0.10333 | Regression loss: 0.22860 | Running loss: 0.38909\n",
      "Epoch: 10 | Iteration: 806 | Classification loss: 0.17225 | Regression loss: 0.16657 | Running loss: 0.38806\n",
      "Epoch: 10 | Iteration: 807 | Classification loss: 0.13920 | Regression loss: 0.18031 | Running loss: 0.38762\n",
      "Epoch: 10 | Iteration: 808 | Classification loss: 0.20103 | Regression loss: 0.13823 | Running loss: 0.38766\n",
      "Epoch: 10 | Iteration: 809 | Classification loss: 0.05725 | Regression loss: 0.19288 | Running loss: 0.38766\n",
      "Epoch: 10 | Iteration: 810 | Classification loss: 0.06734 | Regression loss: 0.20976 | Running loss: 0.38762\n",
      "Epoch: 10 | Iteration: 811 | Classification loss: 0.27916 | Regression loss: 0.35334 | Running loss: 0.38783\n",
      "Epoch: 10 | Iteration: 812 | Classification loss: 0.13480 | Regression loss: 0.26554 | Running loss: 0.38810\n",
      "Epoch: 10 | Iteration: 813 | Classification loss: 0.06371 | Regression loss: 0.21309 | Running loss: 0.38787\n",
      "Epoch: 10 | Iteration: 814 | Classification loss: 0.10368 | Regression loss: 0.17896 | Running loss: 0.38766\n",
      "Epoch: 10 | Iteration: 815 | Classification loss: 0.28744 | Regression loss: 0.53383 | Running loss: 0.38825\n",
      "Epoch: 10 | Iteration: 816 | Classification loss: 0.13481 | Regression loss: 0.26331 | Running loss: 0.38841\n",
      "Epoch: 10 | Iteration: 817 | Classification loss: 0.22846 | Regression loss: 0.22962 | Running loss: 0.38891\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 11 | Iteration: 0 | Classification loss: 0.10922 | Regression loss: 0.35107 | Running loss: 0.38921\n",
      "Epoch: 11 | Iteration: 1 | Classification loss: 0.23613 | Regression loss: 0.37543 | Running loss: 0.38960\n",
      "Epoch: 11 | Iteration: 2 | Classification loss: 0.25108 | Regression loss: 0.16483 | Running loss: 0.38975\n",
      "Epoch: 11 | Iteration: 3 | Classification loss: 0.04251 | Regression loss: 0.15750 | Running loss: 0.38971\n",
      "Epoch: 11 | Iteration: 4 | Classification loss: 0.13609 | Regression loss: 0.19377 | Running loss: 0.38956\n",
      "Epoch: 11 | Iteration: 5 | Classification loss: 0.14386 | Regression loss: 0.61172 | Running loss: 0.39031\n",
      "Epoch: 11 | Iteration: 6 | Classification loss: 0.16382 | Regression loss: 0.16317 | Running loss: 0.39023\n",
      "Epoch: 11 | Iteration: 7 | Classification loss: 0.05915 | Regression loss: 0.17666 | Running loss: 0.38975\n",
      "Epoch: 11 | Iteration: 8 | Classification loss: 0.06686 | Regression loss: 0.10152 | Running loss: 0.38940\n",
      "Epoch: 11 | Iteration: 9 | Classification loss: 0.08100 | Regression loss: 0.28864 | Running loss: 0.38959\n",
      "Epoch: 11 | Iteration: 10 | Classification loss: 0.07056 | Regression loss: 0.09050 | Running loss: 0.38925\n",
      "Epoch: 11 | Iteration: 11 | Classification loss: 0.19793 | Regression loss: 0.34942 | Running loss: 0.38981\n",
      "Epoch: 11 | Iteration: 12 | Classification loss: 0.05662 | Regression loss: 0.14033 | Running loss: 0.38930\n",
      "Epoch: 11 | Iteration: 13 | Classification loss: 0.50834 | Regression loss: 0.17183 | Running loss: 0.38983\n",
      "Epoch: 11 | Iteration: 14 | Classification loss: 0.05575 | Regression loss: 0.22467 | Running loss: 0.38961\n",
      "Epoch: 11 | Iteration: 15 | Classification loss: 0.08656 | Regression loss: 0.24641 | Running loss: 0.38966\n",
      "Epoch: 11 | Iteration: 16 | Classification loss: 0.02784 | Regression loss: 0.07461 | Running loss: 0.38910\n",
      "Epoch: 11 | Iteration: 17 | Classification loss: 0.09901 | Regression loss: 0.24044 | Running loss: 0.38923\n",
      "Epoch: 11 | Iteration: 18 | Classification loss: 0.03613 | Regression loss: 0.21788 | Running loss: 0.38903\n",
      "Epoch: 11 | Iteration: 19 | Classification loss: 0.14337 | Regression loss: 0.46088 | Running loss: 0.38971\n",
      "Epoch: 11 | Iteration: 20 | Classification loss: 0.20158 | Regression loss: 0.17741 | Running loss: 0.38958\n",
      "Epoch: 11 | Iteration: 21 | Classification loss: 0.73959 | Regression loss: 0.15459 | Running loss: 0.39088\n",
      "Epoch: 11 | Iteration: 22 | Classification loss: 0.11244 | Regression loss: 0.12897 | Running loss: 0.39094\n",
      "Epoch: 11 | Iteration: 23 | Classification loss: 0.04531 | Regression loss: 0.20997 | Running loss: 0.39066\n",
      "Epoch: 11 | Iteration: 24 | Classification loss: 0.05240 | Regression loss: 0.25913 | Running loss: 0.39054\n",
      "Epoch: 11 | Iteration: 25 | Classification loss: 0.03915 | Regression loss: 0.11475 | Running loss: 0.39007\n",
      "Epoch: 11 | Iteration: 26 | Classification loss: 0.19163 | Regression loss: 0.20379 | Running loss: 0.39040\n",
      "Epoch: 11 | Iteration: 27 | Classification loss: 0.13770 | Regression loss: 0.37638 | Running loss: 0.38969\n",
      "Epoch: 11 | Iteration: 28 | Classification loss: 0.01375 | Regression loss: 0.06227 | Running loss: 0.38793\n",
      "Epoch: 11 | Iteration: 29 | Classification loss: 0.11470 | Regression loss: 0.19647 | Running loss: 0.38741\n",
      "Epoch: 11 | Iteration: 30 | Classification loss: 0.03309 | Regression loss: 0.22638 | Running loss: 0.38744\n",
      "Epoch: 11 | Iteration: 31 | Classification loss: 0.27140 | Regression loss: 0.18058 | Running loss: 0.38801\n",
      "Epoch: 11 | Iteration: 32 | Classification loss: 0.03925 | Regression loss: 0.26260 | Running loss: 0.38795\n",
      "Epoch: 11 | Iteration: 33 | Classification loss: 0.06481 | Regression loss: 0.24071 | Running loss: 0.38757\n",
      "Epoch: 11 | Iteration: 34 | Classification loss: 0.13891 | Regression loss: 0.30490 | Running loss: 0.38783\n",
      "Epoch: 11 | Iteration: 35 | Classification loss: 0.08694 | Regression loss: 0.28101 | Running loss: 0.38747\n",
      "Epoch: 11 | Iteration: 36 | Classification loss: 0.02990 | Regression loss: 0.07288 | Running loss: 0.38693\n",
      "Epoch: 11 | Iteration: 37 | Classification loss: 0.14872 | Regression loss: 0.17397 | Running loss: 0.38706\n",
      "Epoch: 11 | Iteration: 38 | Classification loss: 0.05319 | Regression loss: 0.18773 | Running loss: 0.38684\n",
      "Epoch: 11 | Iteration: 39 | Classification loss: 0.13205 | Regression loss: 0.36272 | Running loss: 0.38669\n",
      "Epoch: 11 | Iteration: 40 | Classification loss: 0.29641 | Regression loss: 0.19936 | Running loss: 0.38663\n",
      "Epoch: 11 | Iteration: 41 | Classification loss: 0.08700 | Regression loss: 0.21117 | Running loss: 0.38635\n",
      "Epoch: 11 | Iteration: 42 | Classification loss: 0.39364 | Regression loss: 0.11166 | Running loss: 0.38670\n",
      "Epoch: 11 | Iteration: 43 | Classification loss: 0.14646 | Regression loss: 0.59854 | Running loss: 0.38751\n",
      "Epoch: 11 | Iteration: 44 | Classification loss: 0.13068 | Regression loss: 0.27666 | Running loss: 0.38770\n",
      "Epoch: 11 | Iteration: 45 | Classification loss: 0.05125 | Regression loss: 0.18305 | Running loss: 0.38745\n",
      "Epoch: 11 | Iteration: 46 | Classification loss: 0.06948 | Regression loss: 0.09124 | Running loss: 0.38664\n",
      "Epoch: 11 | Iteration: 47 | Classification loss: 0.03470 | Regression loss: 0.18129 | Running loss: 0.38558\n",
      "Epoch: 11 | Iteration: 48 | Classification loss: 0.14177 | Regression loss: 0.16431 | Running loss: 0.38475\n",
      "Epoch: 11 | Iteration: 49 | Classification loss: 0.09530 | Regression loss: 0.22367 | Running loss: 0.38453\n",
      "Epoch: 11 | Iteration: 50 | Classification loss: 0.02597 | Regression loss: 0.12598 | Running loss: 0.38352\n",
      "Epoch: 11 | Iteration: 51 | Classification loss: 0.04395 | Regression loss: 0.21109 | Running loss: 0.38330\n",
      "Epoch: 11 | Iteration: 52 | Classification loss: 0.12198 | Regression loss: 0.27961 | Running loss: 0.38286\n",
      "Epoch: 11 | Iteration: 53 | Classification loss: 0.08504 | Regression loss: 0.15165 | Running loss: 0.38281\n",
      "Epoch: 11 | Iteration: 54 | Classification loss: 0.07892 | Regression loss: 0.20383 | Running loss: 0.38259\n",
      "Epoch: 11 | Iteration: 55 | Classification loss: 0.02012 | Regression loss: 0.16829 | Running loss: 0.38198\n",
      "Epoch: 11 | Iteration: 56 | Classification loss: 0.05799 | Regression loss: 0.14662 | Running loss: 0.38093\n",
      "Epoch: 11 | Iteration: 57 | Classification loss: 0.02085 | Regression loss: 0.06343 | Running loss: 0.38047\n",
      "Epoch: 11 | Iteration: 58 | Classification loss: 0.40303 | Regression loss: 0.57650 | Running loss: 0.38171\n",
      "Epoch: 11 | Iteration: 59 | Classification loss: 0.03734 | Regression loss: 0.15615 | Running loss: 0.38156\n",
      "Epoch: 11 | Iteration: 60 | Classification loss: 0.23411 | Regression loss: 0.18500 | Running loss: 0.38065\n",
      "Epoch: 11 | Iteration: 61 | Classification loss: 0.11671 | Regression loss: 0.16284 | Running loss: 0.38023\n",
      "Epoch: 11 | Iteration: 62 | Classification loss: 0.20346 | Regression loss: 0.60903 | Running loss: 0.38082\n",
      "Epoch: 11 | Iteration: 63 | Classification loss: 0.08253 | Regression loss: 0.34317 | Running loss: 0.38072\n",
      "Epoch: 11 | Iteration: 64 | Classification loss: 0.12919 | Regression loss: 0.09919 | Running loss: 0.37987\n",
      "Epoch: 11 | Iteration: 65 | Classification loss: 0.06950 | Regression loss: 0.28861 | Running loss: 0.38002\n",
      "Epoch: 11 | Iteration: 66 | Classification loss: 0.06805 | Regression loss: 0.13398 | Running loss: 0.37931\n",
      "Epoch: 11 | Iteration: 67 | Classification loss: 0.07760 | Regression loss: 0.29505 | Running loss: 0.37934\n",
      "Epoch: 11 | Iteration: 68 | Classification loss: 0.06713 | Regression loss: 0.20355 | Running loss: 0.37938\n",
      "Epoch: 11 | Iteration: 69 | Classification loss: 0.04128 | Regression loss: 0.12616 | Running loss: 0.37912\n",
      "Epoch: 11 | Iteration: 70 | Classification loss: 0.17308 | Regression loss: 0.22227 | Running loss: 0.37936\n",
      "Epoch: 11 | Iteration: 71 | Classification loss: 0.06326 | Regression loss: 0.28796 | Running loss: 0.37954\n",
      "Epoch: 11 | Iteration: 72 | Classification loss: 0.18295 | Regression loss: 0.16447 | Running loss: 0.37985\n",
      "Epoch: 11 | Iteration: 73 | Classification loss: 0.07212 | Regression loss: 0.28317 | Running loss: 0.37982\n",
      "Epoch: 11 | Iteration: 74 | Classification loss: 0.04008 | Regression loss: 0.19895 | Running loss: 0.37986\n",
      "Epoch: 11 | Iteration: 75 | Classification loss: 0.07415 | Regression loss: 0.06891 | Running loss: 0.37968\n",
      "Epoch: 11 | Iteration: 76 | Classification loss: 0.13223 | Regression loss: 0.18341 | Running loss: 0.37895\n",
      "Epoch: 11 | Iteration: 77 | Classification loss: 0.11604 | Regression loss: 0.31418 | Running loss: 0.37929\n",
      "Epoch: 11 | Iteration: 78 | Classification loss: 0.10020 | Regression loss: 0.20603 | Running loss: 0.37960\n",
      "Epoch: 11 | Iteration: 79 | Classification loss: 0.16681 | Regression loss: 0.13158 | Running loss: 0.37963\n",
      "Epoch: 11 | Iteration: 80 | Classification loss: 0.13554 | Regression loss: 0.21892 | Running loss: 0.37870\n",
      "Epoch: 11 | Iteration: 81 | Classification loss: 0.13224 | Regression loss: 0.20421 | Running loss: 0.37887\n",
      "Epoch: 11 | Iteration: 82 | Classification loss: 0.06904 | Regression loss: 0.18404 | Running loss: 0.37903\n",
      "Epoch: 11 | Iteration: 83 | Classification loss: 0.17260 | Regression loss: 0.13529 | Running loss: 0.37935\n",
      "Epoch: 11 | Iteration: 84 | Classification loss: 0.12528 | Regression loss: 0.12302 | Running loss: 0.37929\n",
      "Epoch: 11 | Iteration: 85 | Classification loss: 0.15165 | Regression loss: 0.15136 | Running loss: 0.37897\n",
      "Epoch: 11 | Iteration: 86 | Classification loss: 0.06473 | Regression loss: 0.19402 | Running loss: 0.37908\n",
      "Epoch: 11 | Iteration: 87 | Classification loss: 0.03964 | Regression loss: 0.24479 | Running loss: 0.37919\n",
      "Epoch: 11 | Iteration: 88 | Classification loss: 0.05204 | Regression loss: 0.19076 | Running loss: 0.37920\n",
      "Epoch: 11 | Iteration: 89 | Classification loss: 0.13904 | Regression loss: 0.24787 | Running loss: 0.37873\n",
      "Epoch: 11 | Iteration: 90 | Classification loss: 0.02250 | Regression loss: 0.14623 | Running loss: 0.37850\n",
      "Epoch: 11 | Iteration: 91 | Classification loss: 0.07525 | Regression loss: 0.23776 | Running loss: 0.37831\n",
      "Epoch: 11 | Iteration: 92 | Classification loss: 0.03051 | Regression loss: 0.15648 | Running loss: 0.37830\n",
      "Epoch: 11 | Iteration: 93 | Classification loss: 0.08011 | Regression loss: 0.16089 | Running loss: 0.37827\n",
      "Epoch: 11 | Iteration: 94 | Classification loss: 0.06131 | Regression loss: 0.13688 | Running loss: 0.37801\n",
      "Epoch: 11 | Iteration: 95 | Classification loss: 0.11535 | Regression loss: 0.13747 | Running loss: 0.37696\n",
      "Epoch: 11 | Iteration: 96 | Classification loss: 0.12854 | Regression loss: 0.18934 | Running loss: 0.37657\n",
      "Epoch: 11 | Iteration: 97 | Classification loss: 0.21447 | Regression loss: 0.27322 | Running loss: 0.37694\n",
      "Epoch: 11 | Iteration: 98 | Classification loss: 0.12845 | Regression loss: 0.16766 | Running loss: 0.37686\n",
      "Epoch: 11 | Iteration: 99 | Classification loss: 0.04306 | Regression loss: 0.07723 | Running loss: 0.37658\n",
      "Epoch: 11 | Iteration: 100 | Classification loss: 0.08240 | Regression loss: 0.19571 | Running loss: 0.37648\n",
      "Epoch: 11 | Iteration: 101 | Classification loss: 0.07086 | Regression loss: 0.21777 | Running loss: 0.37588\n",
      "Epoch: 11 | Iteration: 102 | Classification loss: 0.06109 | Regression loss: 0.20125 | Running loss: 0.37584\n",
      "Epoch: 11 | Iteration: 103 | Classification loss: 0.02619 | Regression loss: 0.09685 | Running loss: 0.37538\n",
      "Epoch: 11 | Iteration: 104 | Classification loss: 0.08308 | Regression loss: 0.24919 | Running loss: 0.37488\n",
      "Epoch: 11 | Iteration: 105 | Classification loss: 0.06480 | Regression loss: 0.27491 | Running loss: 0.37429\n",
      "Epoch: 11 | Iteration: 106 | Classification loss: 0.17660 | Regression loss: 0.30798 | Running loss: 0.37452\n",
      "Epoch: 11 | Iteration: 107 | Classification loss: 0.10868 | Regression loss: 0.14133 | Running loss: 0.37413\n",
      "Epoch: 11 | Iteration: 108 | Classification loss: 0.18527 | Regression loss: 0.31458 | Running loss: 0.37417\n",
      "Epoch: 11 | Iteration: 109 | Classification loss: 0.04063 | Regression loss: 0.13230 | Running loss: 0.37402\n",
      "Epoch: 11 | Iteration: 110 | Classification loss: 0.01752 | Regression loss: 0.09709 | Running loss: 0.37201\n",
      "Epoch: 11 | Iteration: 111 | Classification loss: 0.03888 | Regression loss: 0.15200 | Running loss: 0.37187\n",
      "Epoch: 11 | Iteration: 112 | Classification loss: 0.04000 | Regression loss: 0.13278 | Running loss: 0.37118\n",
      "Epoch: 11 | Iteration: 113 | Classification loss: 0.15902 | Regression loss: 0.32091 | Running loss: 0.37149\n",
      "Epoch: 11 | Iteration: 114 | Classification loss: 0.10193 | Regression loss: 0.38949 | Running loss: 0.37203\n",
      "Epoch: 11 | Iteration: 115 | Classification loss: 0.04821 | Regression loss: 0.19729 | Running loss: 0.37209\n",
      "Epoch: 11 | Iteration: 116 | Classification loss: 0.06412 | Regression loss: 0.25375 | Running loss: 0.37152\n",
      "Epoch: 11 | Iteration: 117 | Classification loss: 0.03931 | Regression loss: 0.10954 | Running loss: 0.37105\n",
      "Epoch: 11 | Iteration: 118 | Classification loss: 0.04199 | Regression loss: 0.12645 | Running loss: 0.37079\n",
      "Epoch: 11 | Iteration: 119 | Classification loss: 0.01850 | Regression loss: 0.15828 | Running loss: 0.37049\n",
      "Epoch: 11 | Iteration: 120 | Classification loss: 0.08238 | Regression loss: 0.38680 | Running loss: 0.37022\n",
      "Epoch: 11 | Iteration: 121 | Classification loss: 0.04003 | Regression loss: 0.29029 | Running loss: 0.36932\n",
      "Epoch: 11 | Iteration: 122 | Classification loss: 0.15737 | Regression loss: 0.13930 | Running loss: 0.36953\n",
      "Epoch: 11 | Iteration: 123 | Classification loss: 0.06324 | Regression loss: 0.35505 | Running loss: 0.36937\n",
      "Epoch: 11 | Iteration: 124 | Classification loss: 0.14508 | Regression loss: 0.26302 | Running loss: 0.36969\n",
      "Epoch: 11 | Iteration: 125 | Classification loss: 0.06171 | Regression loss: 0.29800 | Running loss: 0.36978\n",
      "Epoch: 11 | Iteration: 126 | Classification loss: 0.03789 | Regression loss: 0.16686 | Running loss: 0.36946\n",
      "Epoch: 11 | Iteration: 127 | Classification loss: 0.09802 | Regression loss: 0.29192 | Running loss: 0.36990\n",
      "Epoch: 11 | Iteration: 128 | Classification loss: 0.04087 | Regression loss: 0.25099 | Running loss: 0.36950\n",
      "Epoch: 11 | Iteration: 129 | Classification loss: 0.06671 | Regression loss: 0.22889 | Running loss: 0.36980\n",
      "Epoch: 11 | Iteration: 130 | Classification loss: 0.04105 | Regression loss: 0.14412 | Running loss: 0.36973\n",
      "Epoch: 11 | Iteration: 131 | Classification loss: 0.08987 | Regression loss: 0.36850 | Running loss: 0.37009\n",
      "Epoch: 11 | Iteration: 132 | Classification loss: 0.06031 | Regression loss: 0.23674 | Running loss: 0.37006\n",
      "Epoch: 11 | Iteration: 133 | Classification loss: 0.12752 | Regression loss: 0.24441 | Running loss: 0.37034\n",
      "Epoch: 11 | Iteration: 134 | Classification loss: 0.03177 | Regression loss: 0.11468 | Running loss: 0.36995\n",
      "Epoch: 11 | Iteration: 135 | Classification loss: 0.09119 | Regression loss: 0.31942 | Running loss: 0.36960\n",
      "Epoch: 11 | Iteration: 136 | Classification loss: 0.07718 | Regression loss: 0.29196 | Running loss: 0.36900\n",
      "Epoch: 11 | Iteration: 137 | Classification loss: 0.05694 | Regression loss: 0.19131 | Running loss: 0.36918\n",
      "Epoch: 11 | Iteration: 138 | Classification loss: 0.02784 | Regression loss: 0.13792 | Running loss: 0.36739\n",
      "Epoch: 11 | Iteration: 139 | Classification loss: 0.15805 | Regression loss: 0.18849 | Running loss: 0.36685\n",
      "Epoch: 11 | Iteration: 140 | Classification loss: 0.03777 | Regression loss: 0.20970 | Running loss: 0.36659\n",
      "Epoch: 11 | Iteration: 141 | Classification loss: 0.12966 | Regression loss: 0.30552 | Running loss: 0.36684\n",
      "Epoch: 11 | Iteration: 142 | Classification loss: 0.04058 | Regression loss: 0.23409 | Running loss: 0.36639\n",
      "Epoch: 11 | Iteration: 143 | Classification loss: 0.05263 | Regression loss: 0.21844 | Running loss: 0.36646\n",
      "Epoch: 11 | Iteration: 144 | Classification loss: 0.17104 | Regression loss: 0.38364 | Running loss: 0.36651\n",
      "Epoch: 11 | Iteration: 145 | Classification loss: 0.09770 | Regression loss: 0.26851 | Running loss: 0.36682\n",
      "Epoch: 11 | Iteration: 146 | Classification loss: 0.27148 | Regression loss: 0.46069 | Running loss: 0.36753\n",
      "Epoch: 11 | Iteration: 147 | Classification loss: 0.15895 | Regression loss: 0.30364 | Running loss: 0.36786\n",
      "Epoch: 11 | Iteration: 148 | Classification loss: 0.14964 | Regression loss: 0.27847 | Running loss: 0.36814\n",
      "Epoch: 11 | Iteration: 149 | Classification loss: 0.16586 | Regression loss: 0.27837 | Running loss: 0.36803\n",
      "Epoch: 11 | Iteration: 150 | Classification loss: 0.12289 | Regression loss: 0.26530 | Running loss: 0.36794\n",
      "Epoch: 11 | Iteration: 151 | Classification loss: 0.03500 | Regression loss: 0.14114 | Running loss: 0.36759\n",
      "Epoch: 11 | Iteration: 152 | Classification loss: 0.23392 | Regression loss: 0.35803 | Running loss: 0.36839\n",
      "Epoch: 11 | Iteration: 153 | Classification loss: 0.05165 | Regression loss: 0.21583 | Running loss: 0.36814\n",
      "Epoch: 11 | Iteration: 154 | Classification loss: 0.07193 | Regression loss: 0.22494 | Running loss: 0.36808\n",
      "Epoch: 11 | Iteration: 155 | Classification loss: 0.12129 | Regression loss: 0.33011 | Running loss: 0.36798\n",
      "Epoch: 11 | Iteration: 156 | Classification loss: 0.12033 | Regression loss: 0.31720 | Running loss: 0.36790\n",
      "Epoch: 11 | Iteration: 157 | Classification loss: 0.10085 | Regression loss: 0.39704 | Running loss: 0.36737\n",
      "Epoch: 11 | Iteration: 158 | Classification loss: 0.08926 | Regression loss: 0.30511 | Running loss: 0.36740\n",
      "Epoch: 11 | Iteration: 159 | Classification loss: 0.28603 | Regression loss: 0.16383 | Running loss: 0.36769\n",
      "Epoch: 11 | Iteration: 160 | Classification loss: 0.25200 | Regression loss: 0.16588 | Running loss: 0.36736\n",
      "Epoch: 11 | Iteration: 161 | Classification loss: 0.11946 | Regression loss: 0.32160 | Running loss: 0.36704\n",
      "Epoch: 11 | Iteration: 162 | Classification loss: 0.01973 | Regression loss: 0.13611 | Running loss: 0.36671\n",
      "Epoch: 11 | Iteration: 163 | Classification loss: 0.11897 | Regression loss: 0.35295 | Running loss: 0.36718\n",
      "Epoch: 11 | Iteration: 164 | Classification loss: 0.08544 | Regression loss: 0.28209 | Running loss: 0.36759\n",
      "Epoch: 11 | Iteration: 165 | Classification loss: 0.02319 | Regression loss: 0.14553 | Running loss: 0.36705\n",
      "Epoch: 11 | Iteration: 166 | Classification loss: 0.08063 | Regression loss: 0.20171 | Running loss: 0.36619\n",
      "Epoch: 11 | Iteration: 167 | Classification loss: 0.35960 | Regression loss: 0.60892 | Running loss: 0.36743\n",
      "Epoch: 11 | Iteration: 168 | Classification loss: 0.09548 | Regression loss: 0.27997 | Running loss: 0.36766\n",
      "Epoch: 11 | Iteration: 169 | Classification loss: 0.04560 | Regression loss: 0.28462 | Running loss: 0.36695\n",
      "Epoch: 11 | Iteration: 170 | Classification loss: 0.04786 | Regression loss: 0.12220 | Running loss: 0.36645\n",
      "Epoch: 11 | Iteration: 171 | Classification loss: 0.04329 | Regression loss: 0.28792 | Running loss: 0.36629\n",
      "Epoch: 11 | Iteration: 172 | Classification loss: 0.05991 | Regression loss: 0.16258 | Running loss: 0.36631\n",
      "Epoch: 11 | Iteration: 173 | Classification loss: 0.33158 | Regression loss: 0.38275 | Running loss: 0.36715\n",
      "Epoch: 11 | Iteration: 174 | Classification loss: 0.05295 | Regression loss: 0.20011 | Running loss: 0.36692\n",
      "Epoch: 11 | Iteration: 175 | Classification loss: 0.43730 | Regression loss: 0.24674 | Running loss: 0.36787\n",
      "Epoch: 11 | Iteration: 176 | Classification loss: 0.21778 | Regression loss: 0.34505 | Running loss: 0.36861\n",
      "Epoch: 11 | Iteration: 177 | Classification loss: 0.36028 | Regression loss: 0.35438 | Running loss: 0.36920\n",
      "Epoch: 11 | Iteration: 178 | Classification loss: 0.04772 | Regression loss: 0.23841 | Running loss: 0.36845\n",
      "Epoch: 11 | Iteration: 179 | Classification loss: 0.25438 | Regression loss: 0.18169 | Running loss: 0.36903\n",
      "Epoch: 11 | Iteration: 180 | Classification loss: 0.27750 | Regression loss: 0.43323 | Running loss: 0.36968\n",
      "Epoch: 11 | Iteration: 181 | Classification loss: 0.14058 | Regression loss: 0.25089 | Running loss: 0.36947\n",
      "Epoch: 11 | Iteration: 182 | Classification loss: 0.14269 | Regression loss: 0.46213 | Running loss: 0.37015\n",
      "Epoch: 11 | Iteration: 183 | Classification loss: 0.10921 | Regression loss: 0.38970 | Running loss: 0.37055\n",
      "Epoch: 11 | Iteration: 184 | Classification loss: 0.07487 | Regression loss: 0.19203 | Running loss: 0.37075\n",
      "Epoch: 11 | Iteration: 185 | Classification loss: 0.08548 | Regression loss: 0.27346 | Running loss: 0.37029\n",
      "Epoch: 11 | Iteration: 186 | Classification loss: 0.08902 | Regression loss: 0.11701 | Running loss: 0.36984\n",
      "Epoch: 11 | Iteration: 187 | Classification loss: 0.09912 | Regression loss: 0.26184 | Running loss: 0.36928\n",
      "Epoch: 11 | Iteration: 188 | Classification loss: 0.08897 | Regression loss: 0.21159 | Running loss: 0.36881\n",
      "Epoch: 11 | Iteration: 189 | Classification loss: 0.04117 | Regression loss: 0.21995 | Running loss: 0.36881\n",
      "Epoch: 11 | Iteration: 190 | Classification loss: 0.05116 | Regression loss: 0.15672 | Running loss: 0.36747\n",
      "Epoch: 11 | Iteration: 191 | Classification loss: 0.11937 | Regression loss: 0.24800 | Running loss: 0.36738\n",
      "Epoch: 11 | Iteration: 192 | Classification loss: 0.07209 | Regression loss: 0.20073 | Running loss: 0.36744\n",
      "Epoch: 11 | Iteration: 193 | Classification loss: 0.32961 | Regression loss: 0.13560 | Running loss: 0.36752\n",
      "Epoch: 11 | Iteration: 194 | Classification loss: 0.08690 | Regression loss: 0.22226 | Running loss: 0.36739\n",
      "Epoch: 11 | Iteration: 195 | Classification loss: 0.09245 | Regression loss: 0.16895 | Running loss: 0.36736\n",
      "Epoch: 11 | Iteration: 196 | Classification loss: 0.08933 | Regression loss: 0.15268 | Running loss: 0.36694\n",
      "Epoch: 11 | Iteration: 197 | Classification loss: 0.20161 | Regression loss: 0.28516 | Running loss: 0.36723\n",
      "Epoch: 11 | Iteration: 198 | Classification loss: 0.40454 | Regression loss: 0.32173 | Running loss: 0.36803\n",
      "Epoch: 11 | Iteration: 199 | Classification loss: 0.12474 | Regression loss: 0.30871 | Running loss: 0.36832\n",
      "Epoch: 11 | Iteration: 200 | Classification loss: 0.08681 | Regression loss: 0.32433 | Running loss: 0.36838\n",
      "Epoch: 11 | Iteration: 201 | Classification loss: 0.10971 | Regression loss: 0.24392 | Running loss: 0.36712\n",
      "Epoch: 11 | Iteration: 202 | Classification loss: 0.16904 | Regression loss: 0.15374 | Running loss: 0.36730\n",
      "Epoch: 11 | Iteration: 203 | Classification loss: 0.21716 | Regression loss: 0.34196 | Running loss: 0.36755\n",
      "Epoch: 11 | Iteration: 204 | Classification loss: 0.17021 | Regression loss: 0.19165 | Running loss: 0.36761\n",
      "Epoch: 11 | Iteration: 205 | Classification loss: 0.13811 | Regression loss: 0.16058 | Running loss: 0.36677\n",
      "Epoch: 11 | Iteration: 206 | Classification loss: 0.04795 | Regression loss: 0.20176 | Running loss: 0.36609\n",
      "Epoch: 11 | Iteration: 207 | Classification loss: 0.11767 | Regression loss: 0.37199 | Running loss: 0.36631\n",
      "Epoch: 11 | Iteration: 208 | Classification loss: 0.04885 | Regression loss: 0.14193 | Running loss: 0.36605\n",
      "Epoch: 11 | Iteration: 209 | Classification loss: 0.11999 | Regression loss: 0.31791 | Running loss: 0.36627\n",
      "Epoch: 11 | Iteration: 210 | Classification loss: 0.46611 | Regression loss: 0.11881 | Running loss: 0.36677\n",
      "Epoch: 11 | Iteration: 211 | Classification loss: 0.05485 | Regression loss: 0.24489 | Running loss: 0.36658\n",
      "Epoch: 11 | Iteration: 212 | Classification loss: 0.08515 | Regression loss: 0.16637 | Running loss: 0.36639\n",
      "Epoch: 11 | Iteration: 213 | Classification loss: 0.06960 | Regression loss: 0.34366 | Running loss: 0.36668\n",
      "Epoch: 11 | Iteration: 214 | Classification loss: 0.14842 | Regression loss: 0.22329 | Running loss: 0.36650\n",
      "Epoch: 11 | Iteration: 215 | Classification loss: 0.41886 | Regression loss: 0.37745 | Running loss: 0.36739\n",
      "Epoch: 11 | Iteration: 216 | Classification loss: 0.14128 | Regression loss: 0.24009 | Running loss: 0.36767\n",
      "Epoch: 11 | Iteration: 217 | Classification loss: 0.07988 | Regression loss: 0.17867 | Running loss: 0.36759\n",
      "Epoch: 11 | Iteration: 218 | Classification loss: 0.47622 | Regression loss: 0.43228 | Running loss: 0.36891\n",
      "Epoch: 11 | Iteration: 219 | Classification loss: 0.11868 | Regression loss: 0.22885 | Running loss: 0.36851\n",
      "Epoch: 11 | Iteration: 220 | Classification loss: 0.05768 | Regression loss: 0.16688 | Running loss: 0.36843\n",
      "Epoch: 11 | Iteration: 221 | Classification loss: 0.16226 | Regression loss: 0.18251 | Running loss: 0.36844\n",
      "Epoch: 11 | Iteration: 222 | Classification loss: 0.08161 | Regression loss: 0.27872 | Running loss: 0.36851\n",
      "Epoch: 11 | Iteration: 223 | Classification loss: 0.15725 | Regression loss: 0.08337 | Running loss: 0.36836\n",
      "Epoch: 11 | Iteration: 224 | Classification loss: 0.08418 | Regression loss: 0.15990 | Running loss: 0.36795\n",
      "Epoch: 11 | Iteration: 225 | Classification loss: 0.10340 | Regression loss: 0.21572 | Running loss: 0.36724\n",
      "Epoch: 11 | Iteration: 226 | Classification loss: 0.17010 | Regression loss: 0.49396 | Running loss: 0.36810\n",
      "Epoch: 11 | Iteration: 227 | Classification loss: 0.12731 | Regression loss: 0.30946 | Running loss: 0.36758\n",
      "Epoch: 11 | Iteration: 228 | Classification loss: 0.07592 | Regression loss: 0.17941 | Running loss: 0.36734\n",
      "Epoch: 11 | Iteration: 229 | Classification loss: 0.27907 | Regression loss: 0.39669 | Running loss: 0.36844\n",
      "Epoch: 11 | Iteration: 230 | Classification loss: 0.11110 | Regression loss: 0.33711 | Running loss: 0.36815\n",
      "Epoch: 11 | Iteration: 231 | Classification loss: 0.15357 | Regression loss: 0.34242 | Running loss: 0.36871\n",
      "Epoch: 11 | Iteration: 232 | Classification loss: 0.19768 | Regression loss: 0.17706 | Running loss: 0.36911\n",
      "Epoch: 11 | Iteration: 233 | Classification loss: 0.03438 | Regression loss: 0.12412 | Running loss: 0.36898\n",
      "Epoch: 11 | Iteration: 234 | Classification loss: 0.10964 | Regression loss: 0.20277 | Running loss: 0.36897\n",
      "Epoch: 11 | Iteration: 235 | Classification loss: 0.07127 | Regression loss: 0.26256 | Running loss: 0.36805\n",
      "Epoch: 11 | Iteration: 236 | Classification loss: 0.35098 | Regression loss: 0.15238 | Running loss: 0.36796\n",
      "Epoch: 11 | Iteration: 237 | Classification loss: 0.39339 | Regression loss: 0.32514 | Running loss: 0.36873\n",
      "Epoch: 11 | Iteration: 238 | Classification loss: 0.06722 | Regression loss: 0.42186 | Running loss: 0.36881\n",
      "Epoch: 11 | Iteration: 239 | Classification loss: 0.09049 | Regression loss: 0.32516 | Running loss: 0.36877\n",
      "Epoch: 11 | Iteration: 240 | Classification loss: 0.23477 | Regression loss: 0.32407 | Running loss: 0.36921\n",
      "Epoch: 11 | Iteration: 241 | Classification loss: 0.08135 | Regression loss: 0.21386 | Running loss: 0.36908\n",
      "Epoch: 11 | Iteration: 242 | Classification loss: 0.13189 | Regression loss: 0.10015 | Running loss: 0.36902\n",
      "Epoch: 11 | Iteration: 243 | Classification loss: 0.16108 | Regression loss: 0.33367 | Running loss: 0.36930\n",
      "Epoch: 11 | Iteration: 244 | Classification loss: 0.04794 | Regression loss: 0.33599 | Running loss: 0.36964\n",
      "Epoch: 11 | Iteration: 245 | Classification loss: 0.08572 | Regression loss: 0.24420 | Running loss: 0.36950\n",
      "Epoch: 11 | Iteration: 246 | Classification loss: 0.04937 | Regression loss: 0.15384 | Running loss: 0.36955\n",
      "Epoch: 11 | Iteration: 247 | Classification loss: 0.09835 | Regression loss: 0.33437 | Running loss: 0.36933\n",
      "Epoch: 11 | Iteration: 248 | Classification loss: 0.10393 | Regression loss: 0.35862 | Running loss: 0.36932\n",
      "Epoch: 11 | Iteration: 249 | Classification loss: 0.30311 | Regression loss: 0.35054 | Running loss: 0.37025\n",
      "Epoch: 11 | Iteration: 250 | Classification loss: 0.17185 | Regression loss: 0.51311 | Running loss: 0.37064\n",
      "Epoch: 11 | Iteration: 251 | Classification loss: 0.09572 | Regression loss: 0.24791 | Running loss: 0.37086\n",
      "Epoch: 11 | Iteration: 252 | Classification loss: 0.03047 | Regression loss: 0.15398 | Running loss: 0.36975\n",
      "Epoch: 11 | Iteration: 253 | Classification loss: 0.01302 | Regression loss: 0.14312 | Running loss: 0.36986\n",
      "Epoch: 11 | Iteration: 254 | Classification loss: 0.06599 | Regression loss: 0.25706 | Running loss: 0.37014\n",
      "Epoch: 11 | Iteration: 255 | Classification loss: 0.26823 | Regression loss: 0.40404 | Running loss: 0.37093\n",
      "Epoch: 11 | Iteration: 256 | Classification loss: 0.08157 | Regression loss: 0.24591 | Running loss: 0.37095\n",
      "Epoch: 11 | Iteration: 257 | Classification loss: 0.08194 | Regression loss: 0.20886 | Running loss: 0.37079\n",
      "Epoch: 11 | Iteration: 258 | Classification loss: 0.08731 | Regression loss: 0.31851 | Running loss: 0.37105\n",
      "Epoch: 11 | Iteration: 259 | Classification loss: 0.24328 | Regression loss: 0.13056 | Running loss: 0.37085\n",
      "Epoch: 11 | Iteration: 260 | Classification loss: 0.06499 | Regression loss: 0.21312 | Running loss: 0.37064\n",
      "Epoch: 11 | Iteration: 261 | Classification loss: 0.00005 | Regression loss: 0.00000 | Running loss: 0.37028\n",
      "Epoch: 11 | Iteration: 262 | Classification loss: 0.05243 | Regression loss: 0.15301 | Running loss: 0.37006\n",
      "Epoch: 11 | Iteration: 263 | Classification loss: 0.06571 | Regression loss: 0.16409 | Running loss: 0.36994\n",
      "Epoch: 11 | Iteration: 264 | Classification loss: 0.51573 | Regression loss: 0.46623 | Running loss: 0.37114\n",
      "Epoch: 11 | Iteration: 265 | Classification loss: 0.04045 | Regression loss: 0.24695 | Running loss: 0.37057\n",
      "Epoch: 11 | Iteration: 266 | Classification loss: 0.03535 | Regression loss: 0.13392 | Running loss: 0.37025\n",
      "Epoch: 11 | Iteration: 267 | Classification loss: 0.05237 | Regression loss: 0.22835 | Running loss: 0.37024\n",
      "Epoch: 11 | Iteration: 268 | Classification loss: 0.10760 | Regression loss: 0.26548 | Running loss: 0.37049\n",
      "Epoch: 11 | Iteration: 269 | Classification loss: 0.15655 | Regression loss: 0.19288 | Running loss: 0.37051\n",
      "Epoch: 11 | Iteration: 270 | Classification loss: 0.06997 | Regression loss: 0.17062 | Running loss: 0.37017\n",
      "Epoch: 11 | Iteration: 271 | Classification loss: 0.07445 | Regression loss: 0.21662 | Running loss: 0.37036\n",
      "Epoch: 11 | Iteration: 272 | Classification loss: 0.09533 | Regression loss: 0.25759 | Running loss: 0.37041\n",
      "Epoch: 11 | Iteration: 273 | Classification loss: 0.34604 | Regression loss: 0.20188 | Running loss: 0.37076\n",
      "Epoch: 11 | Iteration: 274 | Classification loss: 0.13097 | Regression loss: 0.14873 | Running loss: 0.37045\n",
      "Epoch: 11 | Iteration: 275 | Classification loss: 0.06825 | Regression loss: 0.19405 | Running loss: 0.37011\n",
      "Epoch: 11 | Iteration: 276 | Classification loss: 0.06910 | Regression loss: 0.36017 | Running loss: 0.36995\n",
      "Epoch: 11 | Iteration: 277 | Classification loss: 0.04217 | Regression loss: 0.22371 | Running loss: 0.36928\n",
      "Epoch: 11 | Iteration: 278 | Classification loss: 0.04162 | Regression loss: 0.20503 | Running loss: 0.36852\n",
      "Epoch: 11 | Iteration: 279 | Classification loss: 0.03614 | Regression loss: 0.27674 | Running loss: 0.36817\n",
      "Epoch: 11 | Iteration: 280 | Classification loss: 0.05358 | Regression loss: 0.19288 | Running loss: 0.36823\n",
      "Epoch: 11 | Iteration: 281 | Classification loss: 0.05417 | Regression loss: 0.24147 | Running loss: 0.36859\n",
      "Epoch: 11 | Iteration: 282 | Classification loss: 0.06763 | Regression loss: 0.11754 | Running loss: 0.36839\n",
      "Epoch: 11 | Iteration: 283 | Classification loss: 0.02015 | Regression loss: 0.11166 | Running loss: 0.36697\n",
      "Epoch: 11 | Iteration: 284 | Classification loss: 0.10226 | Regression loss: 0.15229 | Running loss: 0.36530\n",
      "Epoch: 11 | Iteration: 285 | Classification loss: 0.05098 | Regression loss: 0.12724 | Running loss: 0.36477\n",
      "Epoch: 11 | Iteration: 286 | Classification loss: 0.03501 | Regression loss: 0.19635 | Running loss: 0.36477\n",
      "Epoch: 11 | Iteration: 287 | Classification loss: 0.04625 | Regression loss: 0.19189 | Running loss: 0.36454\n",
      "Epoch: 11 | Iteration: 288 | Classification loss: 0.02988 | Regression loss: 0.21548 | Running loss: 0.36420\n",
      "Epoch: 11 | Iteration: 289 | Classification loss: 0.06648 | Regression loss: 0.22432 | Running loss: 0.36402\n",
      "Epoch: 11 | Iteration: 290 | Classification loss: 0.04653 | Regression loss: 0.15268 | Running loss: 0.36338\n",
      "Epoch: 11 | Iteration: 291 | Classification loss: 0.07169 | Regression loss: 0.22815 | Running loss: 0.36345\n",
      "Epoch: 11 | Iteration: 292 | Classification loss: 0.11499 | Regression loss: 0.09995 | Running loss: 0.36317\n",
      "Epoch: 11 | Iteration: 293 | Classification loss: 0.26870 | Regression loss: 0.24063 | Running loss: 0.36222\n",
      "Epoch: 11 | Iteration: 294 | Classification loss: 0.02946 | Regression loss: 0.15518 | Running loss: 0.36207\n",
      "Epoch: 11 | Iteration: 295 | Classification loss: 0.15880 | Regression loss: 0.31283 | Running loss: 0.36178\n",
      "Epoch: 11 | Iteration: 296 | Classification loss: 0.06038 | Regression loss: 0.23491 | Running loss: 0.36161\n",
      "Epoch: 11 | Iteration: 297 | Classification loss: 0.09457 | Regression loss: 0.25920 | Running loss: 0.36178\n",
      "Epoch: 11 | Iteration: 298 | Classification loss: 0.31941 | Regression loss: 0.26535 | Running loss: 0.36261\n",
      "Epoch: 11 | Iteration: 299 | Classification loss: 0.23217 | Regression loss: 0.38656 | Running loss: 0.36343\n",
      "Epoch: 11 | Iteration: 300 | Classification loss: 0.03041 | Regression loss: 0.11803 | Running loss: 0.36310\n",
      "Epoch: 11 | Iteration: 301 | Classification loss: 0.14336 | Regression loss: 0.43373 | Running loss: 0.36367\n",
      "Epoch: 11 | Iteration: 302 | Classification loss: 0.08922 | Regression loss: 0.17167 | Running loss: 0.36333\n",
      "Epoch: 11 | Iteration: 303 | Classification loss: 0.04106 | Regression loss: 0.24438 | Running loss: 0.36307\n",
      "Epoch: 11 | Iteration: 304 | Classification loss: 0.03246 | Regression loss: 0.16543 | Running loss: 0.36286\n",
      "Epoch: 11 | Iteration: 305 | Classification loss: 0.06583 | Regression loss: 0.16622 | Running loss: 0.36285\n",
      "Epoch: 11 | Iteration: 306 | Classification loss: 0.12458 | Regression loss: 0.42005 | Running loss: 0.36291\n",
      "Epoch: 11 | Iteration: 307 | Classification loss: 0.05623 | Regression loss: 0.17069 | Running loss: 0.36247\n",
      "Epoch: 11 | Iteration: 308 | Classification loss: 0.17667 | Regression loss: 0.44449 | Running loss: 0.36295\n",
      "Epoch: 11 | Iteration: 309 | Classification loss: 0.09531 | Regression loss: 0.16450 | Running loss: 0.36318\n",
      "Epoch: 11 | Iteration: 310 | Classification loss: 0.18425 | Regression loss: 0.39706 | Running loss: 0.36381\n",
      "Epoch: 11 | Iteration: 311 | Classification loss: 0.07849 | Regression loss: 0.23925 | Running loss: 0.36410\n",
      "Epoch: 11 | Iteration: 312 | Classification loss: 0.05639 | Regression loss: 0.33992 | Running loss: 0.36315\n",
      "Epoch: 11 | Iteration: 313 | Classification loss: 0.06990 | Regression loss: 0.20971 | Running loss: 0.36253\n",
      "Epoch: 11 | Iteration: 314 | Classification loss: 0.12558 | Regression loss: 0.22160 | Running loss: 0.36248\n",
      "Epoch: 11 | Iteration: 315 | Classification loss: 0.13148 | Regression loss: 0.29456 | Running loss: 0.36275\n",
      "Epoch: 11 | Iteration: 316 | Classification loss: 0.07245 | Regression loss: 0.32435 | Running loss: 0.36263\n",
      "Epoch: 11 | Iteration: 317 | Classification loss: 0.07328 | Regression loss: 0.10076 | Running loss: 0.36223\n",
      "Epoch: 11 | Iteration: 318 | Classification loss: 0.04047 | Regression loss: 0.20143 | Running loss: 0.36231\n",
      "Epoch: 11 | Iteration: 319 | Classification loss: 0.05116 | Regression loss: 0.14843 | Running loss: 0.36176\n",
      "Epoch: 11 | Iteration: 320 | Classification loss: 0.04426 | Regression loss: 0.16865 | Running loss: 0.36171\n",
      "Epoch: 11 | Iteration: 321 | Classification loss: 0.12992 | Regression loss: 0.16896 | Running loss: 0.36151\n",
      "Epoch: 11 | Iteration: 322 | Classification loss: 0.07725 | Regression loss: 0.28806 | Running loss: 0.36162\n",
      "Epoch: 11 | Iteration: 323 | Classification loss: 0.15066 | Regression loss: 0.25082 | Running loss: 0.36169\n",
      "Epoch: 11 | Iteration: 324 | Classification loss: 0.13118 | Regression loss: 0.11716 | Running loss: 0.36159\n",
      "Epoch: 11 | Iteration: 325 | Classification loss: 0.03661 | Regression loss: 0.13959 | Running loss: 0.36149\n",
      "Epoch: 11 | Iteration: 326 | Classification loss: 0.12502 | Regression loss: 0.34683 | Running loss: 0.36154\n",
      "Epoch: 11 | Iteration: 327 | Classification loss: 0.12506 | Regression loss: 0.22335 | Running loss: 0.36173\n",
      "Epoch: 11 | Iteration: 328 | Classification loss: 0.03373 | Regression loss: 0.14416 | Running loss: 0.36106\n",
      "Epoch: 11 | Iteration: 329 | Classification loss: 0.08933 | Regression loss: 0.17441 | Running loss: 0.36074\n",
      "Epoch: 11 | Iteration: 330 | Classification loss: 0.24868 | Regression loss: 0.24629 | Running loss: 0.36112\n",
      "Epoch: 11 | Iteration: 331 | Classification loss: 0.04940 | Regression loss: 0.17274 | Running loss: 0.36102\n",
      "Epoch: 11 | Iteration: 332 | Classification loss: 0.04111 | Regression loss: 0.20084 | Running loss: 0.36047\n",
      "Epoch: 11 | Iteration: 333 | Classification loss: 0.11096 | Regression loss: 0.20707 | Running loss: 0.36029\n",
      "Epoch: 11 | Iteration: 334 | Classification loss: 0.07655 | Regression loss: 0.18016 | Running loss: 0.36022\n",
      "Epoch: 11 | Iteration: 335 | Classification loss: 0.21443 | Regression loss: 0.54368 | Running loss: 0.36118\n",
      "Epoch: 11 | Iteration: 336 | Classification loss: 0.04177 | Regression loss: 0.19206 | Running loss: 0.36036\n",
      "Epoch: 11 | Iteration: 337 | Classification loss: 0.08994 | Regression loss: 0.27453 | Running loss: 0.36008\n",
      "Epoch: 11 | Iteration: 338 | Classification loss: 0.06035 | Regression loss: 0.25682 | Running loss: 0.35993\n",
      "Epoch: 11 | Iteration: 339 | Classification loss: 0.07965 | Regression loss: 0.32450 | Running loss: 0.35981\n",
      "Epoch: 11 | Iteration: 340 | Classification loss: 0.08938 | Regression loss: 0.25784 | Running loss: 0.35961\n",
      "Epoch: 11 | Iteration: 341 | Classification loss: 0.02570 | Regression loss: 0.16347 | Running loss: 0.35913\n",
      "Epoch: 11 | Iteration: 342 | Classification loss: 0.37103 | Regression loss: 0.18813 | Running loss: 0.35965\n",
      "Epoch: 11 | Iteration: 343 | Classification loss: 0.07578 | Regression loss: 0.22717 | Running loss: 0.35975\n",
      "Epoch: 11 | Iteration: 344 | Classification loss: 0.06150 | Regression loss: 0.06499 | Running loss: 0.35866\n",
      "Epoch: 11 | Iteration: 345 | Classification loss: 0.06724 | Regression loss: 0.30546 | Running loss: 0.35842\n",
      "Epoch: 11 | Iteration: 346 | Classification loss: 0.09758 | Regression loss: 0.21943 | Running loss: 0.35861\n",
      "Epoch: 11 | Iteration: 347 | Classification loss: 0.09390 | Regression loss: 0.26419 | Running loss: 0.35878\n",
      "Epoch: 11 | Iteration: 348 | Classification loss: 0.08969 | Regression loss: 0.39288 | Running loss: 0.35923\n",
      "Epoch: 11 | Iteration: 349 | Classification loss: 0.10084 | Regression loss: 0.25039 | Running loss: 0.35935\n",
      "Epoch: 11 | Iteration: 350 | Classification loss: 0.07289 | Regression loss: 0.17855 | Running loss: 0.35938\n",
      "Epoch: 11 | Iteration: 351 | Classification loss: 0.05579 | Regression loss: 0.14786 | Running loss: 0.35927\n",
      "Epoch: 11 | Iteration: 352 | Classification loss: 0.17355 | Regression loss: 0.30083 | Running loss: 0.35981\n",
      "Epoch: 11 | Iteration: 353 | Classification loss: 0.05649 | Regression loss: 0.13883 | Running loss: 0.35975\n",
      "Epoch: 11 | Iteration: 354 | Classification loss: 0.06195 | Regression loss: 0.20566 | Running loss: 0.35979\n",
      "Epoch: 11 | Iteration: 355 | Classification loss: 0.03337 | Regression loss: 0.12180 | Running loss: 0.35951\n",
      "Epoch: 11 | Iteration: 356 | Classification loss: 0.08330 | Regression loss: 0.24333 | Running loss: 0.35988\n",
      "Epoch: 11 | Iteration: 357 | Classification loss: 0.06344 | Regression loss: 0.18733 | Running loss: 0.35967\n",
      "Epoch: 11 | Iteration: 358 | Classification loss: 0.03848 | Regression loss: 0.11865 | Running loss: 0.35933\n",
      "Epoch: 11 | Iteration: 359 | Classification loss: 0.03826 | Regression loss: 0.15634 | Running loss: 0.35929\n",
      "Epoch: 11 | Iteration: 360 | Classification loss: 0.19742 | Regression loss: 0.22137 | Running loss: 0.35948\n",
      "Epoch: 11 | Iteration: 361 | Classification loss: 0.10003 | Regression loss: 0.19525 | Running loss: 0.35910\n",
      "Epoch: 11 | Iteration: 362 | Classification loss: 0.06541 | Regression loss: 0.19469 | Running loss: 0.35928\n",
      "Epoch: 11 | Iteration: 363 | Classification loss: 0.03867 | Regression loss: 0.18483 | Running loss: 0.35908\n",
      "Epoch: 11 | Iteration: 364 | Classification loss: 0.11672 | Regression loss: 0.16770 | Running loss: 0.35876\n",
      "Epoch: 11 | Iteration: 365 | Classification loss: 0.16044 | Regression loss: 0.30643 | Running loss: 0.35929\n",
      "Epoch: 11 | Iteration: 366 | Classification loss: 0.05438 | Regression loss: 0.13811 | Running loss: 0.35916\n",
      "Epoch: 11 | Iteration: 367 | Classification loss: 0.38419 | Regression loss: 0.27873 | Running loss: 0.35967\n",
      "Epoch: 11 | Iteration: 368 | Classification loss: 0.08539 | Regression loss: 0.18204 | Running loss: 0.35926\n",
      "Epoch: 11 | Iteration: 369 | Classification loss: 0.22110 | Regression loss: 0.12992 | Running loss: 0.35983\n",
      "Epoch: 11 | Iteration: 370 | Classification loss: 0.11018 | Regression loss: 0.21437 | Running loss: 0.35943\n",
      "Epoch: 11 | Iteration: 371 | Classification loss: 0.16513 | Regression loss: 0.49798 | Running loss: 0.36023\n",
      "Epoch: 11 | Iteration: 372 | Classification loss: 0.03086 | Regression loss: 0.21087 | Running loss: 0.35960\n",
      "Epoch: 11 | Iteration: 373 | Classification loss: 0.18390 | Regression loss: 0.38681 | Running loss: 0.36019\n",
      "Epoch: 11 | Iteration: 374 | Classification loss: 0.21786 | Regression loss: 0.32333 | Running loss: 0.36075\n",
      "Epoch: 11 | Iteration: 375 | Classification loss: 0.06540 | Regression loss: 0.18709 | Running loss: 0.36017\n",
      "Epoch: 11 | Iteration: 376 | Classification loss: 0.11521 | Regression loss: 0.25479 | Running loss: 0.36026\n",
      "Epoch: 11 | Iteration: 377 | Classification loss: 0.23586 | Regression loss: 0.19624 | Running loss: 0.36054\n",
      "Epoch: 11 | Iteration: 378 | Classification loss: 0.09781 | Regression loss: 0.19607 | Running loss: 0.36032\n",
      "Epoch: 11 | Iteration: 379 | Classification loss: 0.20966 | Regression loss: 0.21122 | Running loss: 0.36068\n",
      "Epoch: 11 | Iteration: 380 | Classification loss: 0.23414 | Regression loss: 0.53570 | Running loss: 0.36135\n",
      "Epoch: 11 | Iteration: 381 | Classification loss: 0.12604 | Regression loss: 0.15900 | Running loss: 0.36149\n",
      "Epoch: 11 | Iteration: 382 | Classification loss: 0.08518 | Regression loss: 0.19342 | Running loss: 0.36017\n",
      "Epoch: 11 | Iteration: 383 | Classification loss: 0.03737 | Regression loss: 0.14587 | Running loss: 0.35997\n",
      "Epoch: 11 | Iteration: 384 | Classification loss: 0.05400 | Regression loss: 0.15941 | Running loss: 0.35938\n",
      "Epoch: 11 | Iteration: 385 | Classification loss: 0.11816 | Regression loss: 0.25650 | Running loss: 0.35921\n",
      "Epoch: 11 | Iteration: 386 | Classification loss: 0.36982 | Regression loss: 0.53393 | Running loss: 0.36026\n",
      "Epoch: 11 | Iteration: 387 | Classification loss: 0.09788 | Regression loss: 0.19239 | Running loss: 0.36022\n",
      "Epoch: 11 | Iteration: 388 | Classification loss: 0.05429 | Regression loss: 0.18995 | Running loss: 0.36016\n",
      "Epoch: 11 | Iteration: 389 | Classification loss: 0.03822 | Regression loss: 0.14591 | Running loss: 0.35921\n",
      "Epoch: 11 | Iteration: 390 | Classification loss: 0.05545 | Regression loss: 0.20675 | Running loss: 0.35933\n",
      "Epoch: 11 | Iteration: 391 | Classification loss: 0.12160 | Regression loss: 0.30481 | Running loss: 0.35937\n",
      "Epoch: 11 | Iteration: 392 | Classification loss: 0.13858 | Regression loss: 0.10404 | Running loss: 0.35832\n",
      "Epoch: 11 | Iteration: 393 | Classification loss: 0.30267 | Regression loss: 0.15520 | Running loss: 0.35821\n",
      "Epoch: 11 | Iteration: 394 | Classification loss: 0.08922 | Regression loss: 0.12194 | Running loss: 0.35817\n",
      "Epoch: 11 | Iteration: 395 | Classification loss: 0.05692 | Regression loss: 0.29421 | Running loss: 0.35800\n",
      "Epoch: 11 | Iteration: 396 | Classification loss: 0.03834 | Regression loss: 0.20987 | Running loss: 0.35808\n",
      "Epoch: 11 | Iteration: 397 | Classification loss: 0.03915 | Regression loss: 0.18786 | Running loss: 0.35811\n",
      "Epoch: 11 | Iteration: 398 | Classification loss: 0.05714 | Regression loss: 0.20662 | Running loss: 0.35796\n",
      "Epoch: 11 | Iteration: 399 | Classification loss: 0.06738 | Regression loss: 0.10065 | Running loss: 0.35777\n",
      "Epoch: 11 | Iteration: 400 | Classification loss: 0.03749 | Regression loss: 0.15734 | Running loss: 0.35753\n",
      "Epoch: 11 | Iteration: 401 | Classification loss: 0.10461 | Regression loss: 0.19110 | Running loss: 0.35777\n",
      "Epoch: 11 | Iteration: 402 | Classification loss: 0.20146 | Regression loss: 0.35760 | Running loss: 0.35801\n",
      "Epoch: 11 | Iteration: 403 | Classification loss: 0.22902 | Regression loss: 0.18136 | Running loss: 0.35830\n",
      "Epoch: 11 | Iteration: 404 | Classification loss: 0.05575 | Regression loss: 0.24938 | Running loss: 0.35809\n",
      "Epoch: 11 | Iteration: 405 | Classification loss: 0.05894 | Regression loss: 0.26930 | Running loss: 0.35831\n",
      "Epoch: 11 | Iteration: 406 | Classification loss: 0.18159 | Regression loss: 0.39868 | Running loss: 0.35907\n",
      "Epoch: 11 | Iteration: 407 | Classification loss: 0.18895 | Regression loss: 0.33241 | Running loss: 0.35917\n",
      "Epoch: 11 | Iteration: 408 | Classification loss: 0.04693 | Regression loss: 0.26139 | Running loss: 0.35936\n",
      "Epoch: 11 | Iteration: 409 | Classification loss: 0.03417 | Regression loss: 0.13161 | Running loss: 0.35911\n",
      "Epoch: 11 | Iteration: 410 | Classification loss: 0.24344 | Regression loss: 0.27251 | Running loss: 0.35940\n",
      "Epoch: 11 | Iteration: 411 | Classification loss: 0.09112 | Regression loss: 0.34350 | Running loss: 0.35974\n",
      "Epoch: 11 | Iteration: 412 | Classification loss: 0.03342 | Regression loss: 0.14395 | Running loss: 0.35849\n",
      "Epoch: 11 | Iteration: 413 | Classification loss: 0.11200 | Regression loss: 0.28839 | Running loss: 0.35894\n",
      "Epoch: 11 | Iteration: 414 | Classification loss: 0.03613 | Regression loss: 0.16172 | Running loss: 0.35826\n",
      "Epoch: 11 | Iteration: 415 | Classification loss: 0.04807 | Regression loss: 0.21644 | Running loss: 0.35803\n",
      "Epoch: 11 | Iteration: 416 | Classification loss: 0.05338 | Regression loss: 0.27749 | Running loss: 0.35790\n",
      "Epoch: 11 | Iteration: 417 | Classification loss: 0.04563 | Regression loss: 0.18906 | Running loss: 0.35736\n",
      "Epoch: 11 | Iteration: 418 | Classification loss: 0.20177 | Regression loss: 0.37271 | Running loss: 0.35793\n",
      "Epoch: 11 | Iteration: 419 | Classification loss: 0.17058 | Regression loss: 0.19776 | Running loss: 0.35774\n",
      "Epoch: 11 | Iteration: 420 | Classification loss: 0.14433 | Regression loss: 0.27531 | Running loss: 0.35777\n",
      "Epoch: 11 | Iteration: 421 | Classification loss: 0.10143 | Regression loss: 0.31145 | Running loss: 0.35801\n",
      "Epoch: 11 | Iteration: 422 | Classification loss: 0.04650 | Regression loss: 0.07864 | Running loss: 0.35751\n",
      "Epoch: 11 | Iteration: 423 | Classification loss: 0.20029 | Regression loss: 0.16929 | Running loss: 0.35743\n",
      "Epoch: 11 | Iteration: 424 | Classification loss: 0.04676 | Regression loss: 0.18089 | Running loss: 0.35691\n",
      "Epoch: 11 | Iteration: 425 | Classification loss: 0.05469 | Regression loss: 0.20834 | Running loss: 0.35649\n",
      "Epoch: 11 | Iteration: 426 | Classification loss: 0.11742 | Regression loss: 0.29587 | Running loss: 0.35612\n",
      "Epoch: 11 | Iteration: 427 | Classification loss: 0.07275 | Regression loss: 0.32082 | Running loss: 0.35639\n",
      "Epoch: 11 | Iteration: 428 | Classification loss: 0.12494 | Regression loss: 0.48249 | Running loss: 0.35716\n",
      "Epoch: 11 | Iteration: 429 | Classification loss: 0.08880 | Regression loss: 0.25713 | Running loss: 0.35672\n",
      "Epoch: 11 | Iteration: 430 | Classification loss: 0.02996 | Regression loss: 0.16142 | Running loss: 0.35646\n",
      "Epoch: 11 | Iteration: 431 | Classification loss: 0.05327 | Regression loss: 0.26623 | Running loss: 0.35653\n",
      "Epoch: 11 | Iteration: 432 | Classification loss: 0.03055 | Regression loss: 0.26264 | Running loss: 0.35628\n",
      "Epoch: 11 | Iteration: 433 | Classification loss: 0.13037 | Regression loss: 0.11731 | Running loss: 0.35587\n",
      "Epoch: 11 | Iteration: 434 | Classification loss: 0.18628 | Regression loss: 0.35644 | Running loss: 0.35619\n",
      "Epoch: 11 | Iteration: 435 | Classification loss: 0.03862 | Regression loss: 0.27891 | Running loss: 0.35627\n",
      "Epoch: 11 | Iteration: 436 | Classification loss: 0.07629 | Regression loss: 0.18724 | Running loss: 0.35639\n",
      "Epoch: 11 | Iteration: 437 | Classification loss: 0.06553 | Regression loss: 0.36514 | Running loss: 0.35619\n",
      "Epoch: 11 | Iteration: 438 | Classification loss: 0.24995 | Regression loss: 0.26189 | Running loss: 0.35618\n",
      "Epoch: 11 | Iteration: 439 | Classification loss: 0.06358 | Regression loss: 0.29564 | Running loss: 0.35637\n",
      "Epoch: 11 | Iteration: 440 | Classification loss: 0.18320 | Regression loss: 0.20930 | Running loss: 0.35651\n",
      "Epoch: 11 | Iteration: 441 | Classification loss: 0.07823 | Regression loss: 0.22405 | Running loss: 0.35641\n",
      "Epoch: 11 | Iteration: 442 | Classification loss: 0.17085 | Regression loss: 0.21291 | Running loss: 0.35623\n",
      "Epoch: 11 | Iteration: 443 | Classification loss: 0.18235 | Regression loss: 0.16556 | Running loss: 0.35599\n",
      "Epoch: 11 | Iteration: 444 | Classification loss: 0.30603 | Regression loss: 0.29656 | Running loss: 0.35600\n",
      "Epoch: 11 | Iteration: 445 | Classification loss: 0.07509 | Regression loss: 0.13532 | Running loss: 0.35576\n",
      "Epoch: 11 | Iteration: 446 | Classification loss: 0.03294 | Regression loss: 0.13606 | Running loss: 0.35546\n",
      "Epoch: 11 | Iteration: 447 | Classification loss: 0.06855 | Regression loss: 0.25205 | Running loss: 0.35526\n",
      "Epoch: 11 | Iteration: 448 | Classification loss: 0.03511 | Regression loss: 0.18823 | Running loss: 0.35489\n",
      "Epoch: 11 | Iteration: 449 | Classification loss: 0.04952 | Regression loss: 0.23546 | Running loss: 0.35430\n",
      "Epoch: 11 | Iteration: 450 | Classification loss: 0.07124 | Regression loss: 0.25750 | Running loss: 0.35421\n",
      "Epoch: 11 | Iteration: 451 | Classification loss: 0.17467 | Regression loss: 0.40132 | Running loss: 0.35438\n",
      "Epoch: 11 | Iteration: 452 | Classification loss: 0.01579 | Regression loss: 0.09411 | Running loss: 0.35385\n",
      "Epoch: 11 | Iteration: 453 | Classification loss: 0.08288 | Regression loss: 0.09204 | Running loss: 0.35337\n",
      "Epoch: 11 | Iteration: 454 | Classification loss: 0.08095 | Regression loss: 0.27666 | Running loss: 0.35325\n",
      "Epoch: 11 | Iteration: 455 | Classification loss: 0.04106 | Regression loss: 0.21734 | Running loss: 0.35294\n",
      "Epoch: 11 | Iteration: 456 | Classification loss: 0.31838 | Regression loss: 0.47917 | Running loss: 0.35345\n",
      "Epoch: 11 | Iteration: 457 | Classification loss: 0.04448 | Regression loss: 0.20655 | Running loss: 0.35315\n",
      "Epoch: 11 | Iteration: 458 | Classification loss: 0.11444 | Regression loss: 0.09594 | Running loss: 0.35260\n",
      "Epoch: 11 | Iteration: 459 | Classification loss: 0.06994 | Regression loss: 0.16440 | Running loss: 0.35245\n",
      "Epoch: 11 | Iteration: 460 | Classification loss: 0.08052 | Regression loss: 0.39201 | Running loss: 0.35258\n",
      "Epoch: 11 | Iteration: 461 | Classification loss: 0.11658 | Regression loss: 0.24113 | Running loss: 0.35256\n",
      "Epoch: 11 | Iteration: 462 | Classification loss: 0.30325 | Regression loss: 0.46052 | Running loss: 0.35350\n",
      "Epoch: 11 | Iteration: 463 | Classification loss: 0.40295 | Regression loss: 0.29971 | Running loss: 0.35372\n",
      "Epoch: 11 | Iteration: 464 | Classification loss: 0.09998 | Regression loss: 0.23299 | Running loss: 0.35383\n",
      "Epoch: 11 | Iteration: 465 | Classification loss: 0.01709 | Regression loss: 0.08648 | Running loss: 0.35309\n",
      "Epoch: 11 | Iteration: 466 | Classification loss: 0.22866 | Regression loss: 0.27557 | Running loss: 0.35272\n",
      "Epoch: 11 | Iteration: 467 | Classification loss: 0.06389 | Regression loss: 0.14418 | Running loss: 0.35131\n",
      "Epoch: 11 | Iteration: 468 | Classification loss: 0.06438 | Regression loss: 0.30393 | Running loss: 0.35103\n",
      "Epoch: 11 | Iteration: 469 | Classification loss: 0.02261 | Regression loss: 0.13535 | Running loss: 0.35081\n",
      "Epoch: 11 | Iteration: 470 | Classification loss: 0.13014 | Regression loss: 0.23920 | Running loss: 0.35082\n",
      "Epoch: 11 | Iteration: 471 | Classification loss: 0.08068 | Regression loss: 0.13146 | Running loss: 0.35073\n",
      "Epoch: 11 | Iteration: 472 | Classification loss: 0.47907 | Regression loss: 0.46108 | Running loss: 0.35179\n",
      "Epoch: 11 | Iteration: 473 | Classification loss: 0.13651 | Regression loss: 0.17965 | Running loss: 0.35183\n",
      "Epoch: 11 | Iteration: 474 | Classification loss: 0.04420 | Regression loss: 0.19881 | Running loss: 0.35108\n",
      "Epoch: 11 | Iteration: 475 | Classification loss: 0.10426 | Regression loss: 0.28843 | Running loss: 0.35150\n",
      "Epoch: 11 | Iteration: 476 | Classification loss: 0.03692 | Regression loss: 0.18031 | Running loss: 0.35147\n",
      "Epoch: 11 | Iteration: 477 | Classification loss: 0.16013 | Regression loss: 0.40735 | Running loss: 0.35167\n",
      "Epoch: 11 | Iteration: 478 | Classification loss: 0.13171 | Regression loss: 0.27308 | Running loss: 0.35141\n",
      "Epoch: 11 | Iteration: 479 | Classification loss: 0.04822 | Regression loss: 0.17598 | Running loss: 0.35132\n",
      "Epoch: 11 | Iteration: 480 | Classification loss: 0.13054 | Regression loss: 0.10993 | Running loss: 0.35089\n",
      "Epoch: 11 | Iteration: 481 | Classification loss: 0.07905 | Regression loss: 0.28664 | Running loss: 0.35048\n",
      "Epoch: 11 | Iteration: 482 | Classification loss: 0.24079 | Regression loss: 0.50159 | Running loss: 0.35098\n",
      "Epoch: 11 | Iteration: 483 | Classification loss: 0.08108 | Regression loss: 0.25331 | Running loss: 0.35105\n",
      "Epoch: 11 | Iteration: 484 | Classification loss: 0.06117 | Regression loss: 0.16465 | Running loss: 0.35087\n",
      "Epoch: 11 | Iteration: 485 | Classification loss: 0.11488 | Regression loss: 0.16156 | Running loss: 0.35089\n",
      "Epoch: 11 | Iteration: 486 | Classification loss: 0.03007 | Regression loss: 0.19251 | Running loss: 0.35074\n",
      "Epoch: 11 | Iteration: 487 | Classification loss: 0.07168 | Regression loss: 0.18889 | Running loss: 0.35060\n",
      "Epoch: 11 | Iteration: 488 | Classification loss: 0.04275 | Regression loss: 0.18257 | Running loss: 0.35037\n",
      "Epoch: 11 | Iteration: 489 | Classification loss: 0.08972 | Regression loss: 0.20542 | Running loss: 0.35032\n",
      "Epoch: 11 | Iteration: 490 | Classification loss: 0.09307 | Regression loss: 0.28384 | Running loss: 0.35040\n",
      "Epoch: 11 | Iteration: 491 | Classification loss: 0.02436 | Regression loss: 0.18455 | Running loss: 0.35032\n",
      "Epoch: 11 | Iteration: 492 | Classification loss: 0.25881 | Regression loss: 0.65340 | Running loss: 0.35159\n",
      "Epoch: 11 | Iteration: 493 | Classification loss: 0.09333 | Regression loss: 0.26564 | Running loss: 0.35104\n",
      "Epoch: 11 | Iteration: 494 | Classification loss: 0.06572 | Regression loss: 0.18828 | Running loss: 0.35075\n",
      "Epoch: 11 | Iteration: 495 | Classification loss: 0.14236 | Regression loss: 0.17529 | Running loss: 0.35083\n",
      "Epoch: 11 | Iteration: 496 | Classification loss: 0.05739 | Regression loss: 0.15132 | Running loss: 0.35068\n",
      "Epoch: 11 | Iteration: 497 | Classification loss: 0.10725 | Regression loss: 0.21277 | Running loss: 0.34968\n",
      "Epoch: 11 | Iteration: 498 | Classification loss: 0.10827 | Regression loss: 0.26011 | Running loss: 0.34962\n",
      "Epoch: 11 | Iteration: 499 | Classification loss: 0.03915 | Regression loss: 0.17218 | Running loss: 0.34913\n",
      "Epoch: 11 | Iteration: 500 | Classification loss: 0.12421 | Regression loss: 0.26326 | Running loss: 0.34898\n",
      "Epoch: 11 | Iteration: 501 | Classification loss: 0.06101 | Regression loss: 0.32899 | Running loss: 0.34854\n",
      "Epoch: 11 | Iteration: 502 | Classification loss: 0.06685 | Regression loss: 0.17466 | Running loss: 0.34819\n",
      "Epoch: 11 | Iteration: 503 | Classification loss: 0.02651 | Regression loss: 0.13018 | Running loss: 0.34810\n",
      "Epoch: 11 | Iteration: 504 | Classification loss: 0.04377 | Regression loss: 0.16038 | Running loss: 0.34785\n",
      "Epoch: 11 | Iteration: 505 | Classification loss: 0.05612 | Regression loss: 0.25206 | Running loss: 0.34696\n",
      "Epoch: 11 | Iteration: 506 | Classification loss: 0.11397 | Regression loss: 0.40276 | Running loss: 0.34734\n",
      "Epoch: 11 | Iteration: 507 | Classification loss: 0.12726 | Regression loss: 0.16696 | Running loss: 0.34745\n",
      "Epoch: 11 | Iteration: 508 | Classification loss: 0.03073 | Regression loss: 0.20806 | Running loss: 0.34759\n",
      "Epoch: 11 | Iteration: 509 | Classification loss: 0.37098 | Regression loss: 0.53044 | Running loss: 0.34866\n",
      "Epoch: 11 | Iteration: 510 | Classification loss: 0.09422 | Regression loss: 0.27594 | Running loss: 0.34907\n",
      "Epoch: 11 | Iteration: 511 | Classification loss: 0.17977 | Regression loss: 0.39887 | Running loss: 0.34914\n",
      "Epoch: 11 | Iteration: 512 | Classification loss: 0.05522 | Regression loss: 0.23809 | Running loss: 0.34933\n",
      "Epoch: 11 | Iteration: 513 | Classification loss: 0.15760 | Regression loss: 0.38676 | Running loss: 0.34906\n",
      "Epoch: 11 | Iteration: 514 | Classification loss: 0.08631 | Regression loss: 0.20663 | Running loss: 0.34908\n",
      "Epoch: 11 | Iteration: 515 | Classification loss: 0.02458 | Regression loss: 0.10887 | Running loss: 0.34868\n",
      "Epoch: 11 | Iteration: 516 | Classification loss: 0.06638 | Regression loss: 0.25516 | Running loss: 0.34912\n",
      "Epoch: 11 | Iteration: 517 | Classification loss: 0.02999 | Regression loss: 0.12184 | Running loss: 0.34875\n",
      "Epoch: 11 | Iteration: 518 | Classification loss: 0.11113 | Regression loss: 0.39582 | Running loss: 0.34925\n",
      "Epoch: 11 | Iteration: 519 | Classification loss: 0.06080 | Regression loss: 0.14775 | Running loss: 0.34846\n",
      "Epoch: 11 | Iteration: 520 | Classification loss: 0.10420 | Regression loss: 0.19695 | Running loss: 0.34831\n",
      "Epoch: 11 | Iteration: 521 | Classification loss: 0.03953 | Regression loss: 0.23634 | Running loss: 0.34707\n",
      "Epoch: 11 | Iteration: 522 | Classification loss: 0.03779 | Regression loss: 0.11237 | Running loss: 0.34689\n",
      "Epoch: 11 | Iteration: 523 | Classification loss: 0.03228 | Regression loss: 0.23202 | Running loss: 0.34690\n",
      "Epoch: 11 | Iteration: 524 | Classification loss: 0.17201 | Regression loss: 0.32298 | Running loss: 0.34727\n",
      "Epoch: 11 | Iteration: 525 | Classification loss: 0.13669 | Regression loss: 0.25720 | Running loss: 0.34775\n",
      "Epoch: 11 | Iteration: 526 | Classification loss: 0.02697 | Regression loss: 0.14418 | Running loss: 0.34730\n",
      "Epoch: 11 | Iteration: 527 | Classification loss: 0.15168 | Regression loss: 0.14961 | Running loss: 0.34688\n",
      "Epoch: 11 | Iteration: 528 | Classification loss: 0.06975 | Regression loss: 0.17466 | Running loss: 0.34721\n",
      "Epoch: 11 | Iteration: 529 | Classification loss: 0.06339 | Regression loss: 0.15734 | Running loss: 0.34703\n",
      "Epoch: 11 | Iteration: 530 | Classification loss: 0.19525 | Regression loss: 0.35507 | Running loss: 0.34762\n",
      "Epoch: 11 | Iteration: 531 | Classification loss: 0.10459 | Regression loss: 0.33250 | Running loss: 0.34759\n",
      "Epoch: 11 | Iteration: 532 | Classification loss: 0.08490 | Regression loss: 0.17017 | Running loss: 0.34749\n",
      "Epoch: 11 | Iteration: 533 | Classification loss: 0.09235 | Regression loss: 0.55080 | Running loss: 0.34817\n",
      "Epoch: 11 | Iteration: 534 | Classification loss: 0.12160 | Regression loss: 0.24229 | Running loss: 0.34801\n",
      "Epoch: 11 | Iteration: 535 | Classification loss: 0.02507 | Regression loss: 0.15640 | Running loss: 0.34763\n",
      "Epoch: 11 | Iteration: 536 | Classification loss: 0.11648 | Regression loss: 0.28623 | Running loss: 0.34823\n",
      "Epoch: 11 | Iteration: 537 | Classification loss: 0.03855 | Regression loss: 0.27658 | Running loss: 0.34822\n",
      "Epoch: 11 | Iteration: 538 | Classification loss: 0.03501 | Regression loss: 0.09768 | Running loss: 0.34800\n",
      "Epoch: 11 | Iteration: 539 | Classification loss: 0.04896 | Regression loss: 0.17569 | Running loss: 0.34746\n",
      "Epoch: 11 | Iteration: 540 | Classification loss: 0.19605 | Regression loss: 0.36856 | Running loss: 0.34760\n",
      "Epoch: 11 | Iteration: 541 | Classification loss: 0.02772 | Regression loss: 0.19475 | Running loss: 0.34745\n",
      "Epoch: 11 | Iteration: 542 | Classification loss: 0.04622 | Regression loss: 0.11902 | Running loss: 0.34677\n",
      "Epoch: 11 | Iteration: 543 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.34528\n",
      "Epoch: 11 | Iteration: 544 | Classification loss: 0.14055 | Regression loss: 0.23454 | Running loss: 0.34521\n",
      "Epoch: 11 | Iteration: 545 | Classification loss: 0.16156 | Regression loss: 0.33567 | Running loss: 0.34574\n",
      "Epoch: 11 | Iteration: 546 | Classification loss: 0.27224 | Regression loss: 0.36781 | Running loss: 0.34670\n",
      "Epoch: 11 | Iteration: 547 | Classification loss: 0.04643 | Regression loss: 0.20127 | Running loss: 0.34676\n",
      "Epoch: 11 | Iteration: 548 | Classification loss: 0.22277 | Regression loss: 0.19278 | Running loss: 0.34698\n",
      "Epoch: 11 | Iteration: 549 | Classification loss: 0.10443 | Regression loss: 0.14995 | Running loss: 0.34685\n",
      "Epoch: 11 | Iteration: 550 | Classification loss: 0.09759 | Regression loss: 0.23567 | Running loss: 0.34721\n",
      "Epoch: 11 | Iteration: 551 | Classification loss: 0.07217 | Regression loss: 0.21605 | Running loss: 0.34728\n",
      "Epoch: 11 | Iteration: 552 | Classification loss: 0.11250 | Regression loss: 0.21100 | Running loss: 0.34712\n",
      "Epoch: 11 | Iteration: 553 | Classification loss: 0.09080 | Regression loss: 0.16053 | Running loss: 0.34715\n",
      "Epoch: 11 | Iteration: 554 | Classification loss: 0.02693 | Regression loss: 0.11873 | Running loss: 0.34688\n",
      "Epoch: 11 | Iteration: 555 | Classification loss: 0.13923 | Regression loss: 0.28618 | Running loss: 0.34735\n",
      "Epoch: 11 | Iteration: 556 | Classification loss: 0.08894 | Regression loss: 0.27892 | Running loss: 0.34768\n",
      "Epoch: 11 | Iteration: 557 | Classification loss: 0.08052 | Regression loss: 0.23986 | Running loss: 0.34815\n",
      "Epoch: 11 | Iteration: 558 | Classification loss: 0.06830 | Regression loss: 0.22940 | Running loss: 0.34679\n",
      "Epoch: 11 | Iteration: 559 | Classification loss: 0.04069 | Regression loss: 0.22633 | Running loss: 0.34694\n",
      "Epoch: 11 | Iteration: 560 | Classification loss: 0.20013 | Regression loss: 0.11006 | Running loss: 0.34672\n",
      "Epoch: 11 | Iteration: 561 | Classification loss: 0.04993 | Regression loss: 0.19729 | Running loss: 0.34665\n",
      "Epoch: 11 | Iteration: 562 | Classification loss: 0.24899 | Regression loss: 0.18739 | Running loss: 0.34590\n",
      "Epoch: 11 | Iteration: 563 | Classification loss: 0.08150 | Regression loss: 0.14179 | Running loss: 0.34550\n",
      "Epoch: 11 | Iteration: 564 | Classification loss: 0.07535 | Regression loss: 0.26113 | Running loss: 0.34571\n",
      "Epoch: 11 | Iteration: 565 | Classification loss: 0.06465 | Regression loss: 0.30245 | Running loss: 0.34573\n",
      "Epoch: 11 | Iteration: 566 | Classification loss: 0.08170 | Regression loss: 0.23677 | Running loss: 0.34596\n",
      "Epoch: 11 | Iteration: 567 | Classification loss: 0.06716 | Regression loss: 0.23399 | Running loss: 0.34582\n",
      "Epoch: 11 | Iteration: 568 | Classification loss: 0.09285 | Regression loss: 0.26302 | Running loss: 0.34599\n",
      "Epoch: 11 | Iteration: 569 | Classification loss: 0.16092 | Regression loss: 0.46428 | Running loss: 0.34691\n",
      "Epoch: 11 | Iteration: 570 | Classification loss: 0.04179 | Regression loss: 0.15110 | Running loss: 0.34650\n",
      "Epoch: 11 | Iteration: 571 | Classification loss: 0.24847 | Regression loss: 0.32610 | Running loss: 0.34695\n",
      "Epoch: 11 | Iteration: 572 | Classification loss: 0.02670 | Regression loss: 0.16645 | Running loss: 0.34664\n",
      "Epoch: 11 | Iteration: 573 | Classification loss: 0.10613 | Regression loss: 0.18500 | Running loss: 0.34651\n",
      "Epoch: 11 | Iteration: 574 | Classification loss: 0.07327 | Regression loss: 0.21276 | Running loss: 0.34661\n",
      "Epoch: 11 | Iteration: 575 | Classification loss: 0.19665 | Regression loss: 0.18539 | Running loss: 0.34708\n",
      "Epoch: 11 | Iteration: 576 | Classification loss: 0.13208 | Regression loss: 0.22436 | Running loss: 0.34716\n",
      "Epoch: 11 | Iteration: 577 | Classification loss: 0.18138 | Regression loss: 0.33532 | Running loss: 0.34734\n",
      "Epoch: 11 | Iteration: 578 | Classification loss: 0.10900 | Regression loss: 0.20701 | Running loss: 0.34736\n",
      "Epoch: 11 | Iteration: 579 | Classification loss: 0.19356 | Regression loss: 0.27279 | Running loss: 0.34769\n",
      "Epoch: 11 | Iteration: 580 | Classification loss: 0.18353 | Regression loss: 0.15634 | Running loss: 0.34766\n",
      "Epoch: 11 | Iteration: 581 | Classification loss: 0.10690 | Regression loss: 0.26201 | Running loss: 0.34773\n",
      "Epoch: 11 | Iteration: 582 | Classification loss: 0.12145 | Regression loss: 0.24113 | Running loss: 0.34795\n",
      "Epoch: 11 | Iteration: 583 | Classification loss: 0.07293 | Regression loss: 0.13747 | Running loss: 0.34775\n",
      "Epoch: 11 | Iteration: 584 | Classification loss: 0.05901 | Regression loss: 0.20357 | Running loss: 0.34778\n",
      "Epoch: 11 | Iteration: 585 | Classification loss: 0.14387 | Regression loss: 0.39982 | Running loss: 0.34826\n",
      "Epoch: 11 | Iteration: 586 | Classification loss: 0.14326 | Regression loss: 0.39044 | Running loss: 0.34881\n",
      "Epoch: 11 | Iteration: 587 | Classification loss: 0.16263 | Regression loss: 0.22371 | Running loss: 0.34902\n",
      "Epoch: 11 | Iteration: 588 | Classification loss: 0.16856 | Regression loss: 0.36225 | Running loss: 0.34959\n",
      "Epoch: 11 | Iteration: 589 | Classification loss: 0.02321 | Regression loss: 0.22015 | Running loss: 0.34931\n",
      "Epoch: 11 | Iteration: 590 | Classification loss: 0.09775 | Regression loss: 0.06211 | Running loss: 0.34929\n",
      "Epoch: 11 | Iteration: 591 | Classification loss: 0.06872 | Regression loss: 0.30940 | Running loss: 0.34942\n",
      "Epoch: 11 | Iteration: 592 | Classification loss: 0.04973 | Regression loss: 0.09803 | Running loss: 0.34934\n",
      "Epoch: 11 | Iteration: 593 | Classification loss: 0.28901 | Regression loss: 0.35930 | Running loss: 0.35015\n",
      "Epoch: 11 | Iteration: 594 | Classification loss: 0.47904 | Regression loss: 0.15986 | Running loss: 0.35104\n",
      "Epoch: 11 | Iteration: 595 | Classification loss: 0.10066 | Regression loss: 0.16511 | Running loss: 0.35106\n",
      "Epoch: 11 | Iteration: 596 | Classification loss: 0.07107 | Regression loss: 0.24241 | Running loss: 0.35105\n",
      "Epoch: 11 | Iteration: 597 | Classification loss: 0.13413 | Regression loss: 0.19555 | Running loss: 0.35074\n",
      "Epoch: 11 | Iteration: 598 | Classification loss: 0.12314 | Regression loss: 0.36183 | Running loss: 0.35111\n",
      "Epoch: 11 | Iteration: 599 | Classification loss: 0.37896 | Regression loss: 0.13970 | Running loss: 0.35191\n",
      "Epoch: 11 | Iteration: 600 | Classification loss: 0.05728 | Regression loss: 0.22525 | Running loss: 0.35192\n",
      "Epoch: 11 | Iteration: 601 | Classification loss: 0.10720 | Regression loss: 0.40771 | Running loss: 0.35237\n",
      "Epoch: 11 | Iteration: 602 | Classification loss: 0.20466 | Regression loss: 0.36219 | Running loss: 0.35298\n",
      "Epoch: 11 | Iteration: 603 | Classification loss: 0.11332 | Regression loss: 0.19831 | Running loss: 0.35336\n",
      "Epoch: 11 | Iteration: 604 | Classification loss: 0.12092 | Regression loss: 0.41566 | Running loss: 0.35377\n",
      "Epoch: 11 | Iteration: 605 | Classification loss: 0.12294 | Regression loss: 0.29487 | Running loss: 0.35392\n",
      "Epoch: 11 | Iteration: 606 | Classification loss: 0.06027 | Regression loss: 0.24112 | Running loss: 0.35356\n",
      "Epoch: 11 | Iteration: 607 | Classification loss: 0.08445 | Regression loss: 0.30315 | Running loss: 0.35383\n",
      "Epoch: 11 | Iteration: 608 | Classification loss: 0.13137 | Regression loss: 0.17562 | Running loss: 0.35345\n",
      "Epoch: 11 | Iteration: 609 | Classification loss: 0.13881 | Regression loss: 0.32995 | Running loss: 0.35404\n",
      "Epoch: 11 | Iteration: 610 | Classification loss: 0.09785 | Regression loss: 0.23179 | Running loss: 0.35447\n",
      "Epoch: 11 | Iteration: 611 | Classification loss: 0.07961 | Regression loss: 0.28234 | Running loss: 0.35481\n",
      "Epoch: 11 | Iteration: 612 | Classification loss: 0.05830 | Regression loss: 0.09728 | Running loss: 0.35478\n",
      "Epoch: 11 | Iteration: 613 | Classification loss: 0.06623 | Regression loss: 0.21077 | Running loss: 0.35437\n",
      "Epoch: 11 | Iteration: 614 | Classification loss: 0.17869 | Regression loss: 0.29154 | Running loss: 0.35433\n",
      "Epoch: 11 | Iteration: 615 | Classification loss: 0.04136 | Regression loss: 0.27042 | Running loss: 0.35446\n",
      "Epoch: 11 | Iteration: 616 | Classification loss: 0.03526 | Regression loss: 0.14213 | Running loss: 0.35418\n",
      "Epoch: 11 | Iteration: 617 | Classification loss: 0.06380 | Regression loss: 0.23720 | Running loss: 0.35448\n",
      "Epoch: 11 | Iteration: 618 | Classification loss: 0.07294 | Regression loss: 0.18753 | Running loss: 0.35467\n",
      "Epoch: 11 | Iteration: 619 | Classification loss: 0.06684 | Regression loss: 0.22314 | Running loss: 0.35489\n",
      "Epoch: 11 | Iteration: 620 | Classification loss: 0.11006 | Regression loss: 0.28245 | Running loss: 0.35474\n",
      "Epoch: 11 | Iteration: 621 | Classification loss: 0.10405 | Regression loss: 0.43423 | Running loss: 0.35516\n",
      "Epoch: 11 | Iteration: 622 | Classification loss: 0.03039 | Regression loss: 0.20166 | Running loss: 0.35503\n",
      "Epoch: 11 | Iteration: 623 | Classification loss: 0.03346 | Regression loss: 0.12980 | Running loss: 0.35452\n",
      "Epoch: 11 | Iteration: 624 | Classification loss: 0.07067 | Regression loss: 0.25745 | Running loss: 0.35436\n",
      "Epoch: 11 | Iteration: 625 | Classification loss: 0.03205 | Regression loss: 0.12155 | Running loss: 0.35395\n",
      "Epoch: 11 | Iteration: 626 | Classification loss: 0.05537 | Regression loss: 0.11731 | Running loss: 0.35388\n",
      "Epoch: 11 | Iteration: 627 | Classification loss: 0.06415 | Regression loss: 0.21449 | Running loss: 0.35366\n",
      "Epoch: 11 | Iteration: 628 | Classification loss: 0.05876 | Regression loss: 0.24328 | Running loss: 0.35368\n",
      "Epoch: 11 | Iteration: 629 | Classification loss: 0.06293 | Regression loss: 0.27504 | Running loss: 0.35376\n",
      "Epoch: 11 | Iteration: 630 | Classification loss: 0.05167 | Regression loss: 0.21724 | Running loss: 0.35393\n",
      "Epoch: 11 | Iteration: 631 | Classification loss: 0.11778 | Regression loss: 0.37902 | Running loss: 0.35401\n",
      "Epoch: 11 | Iteration: 632 | Classification loss: 0.09762 | Regression loss: 0.25575 | Running loss: 0.35412\n",
      "Epoch: 11 | Iteration: 633 | Classification loss: 0.09872 | Regression loss: 0.15811 | Running loss: 0.35389\n",
      "Epoch: 11 | Iteration: 634 | Classification loss: 0.25815 | Regression loss: 0.42130 | Running loss: 0.35496\n",
      "Epoch: 11 | Iteration: 635 | Classification loss: 0.17110 | Regression loss: 0.14089 | Running loss: 0.35476\n",
      "Epoch: 11 | Iteration: 636 | Classification loss: 0.05091 | Regression loss: 0.14196 | Running loss: 0.35441\n",
      "Epoch: 11 | Iteration: 637 | Classification loss: 0.16082 | Regression loss: 0.53382 | Running loss: 0.35530\n",
      "Epoch: 11 | Iteration: 638 | Classification loss: 0.14033 | Regression loss: 0.25434 | Running loss: 0.35576\n",
      "Epoch: 11 | Iteration: 639 | Classification loss: 0.11557 | Regression loss: 0.38356 | Running loss: 0.35606\n",
      "Epoch: 11 | Iteration: 640 | Classification loss: 0.20189 | Regression loss: 0.23816 | Running loss: 0.35645\n",
      "Epoch: 11 | Iteration: 641 | Classification loss: 0.06886 | Regression loss: 0.29439 | Running loss: 0.35630\n",
      "Epoch: 11 | Iteration: 642 | Classification loss: 0.08614 | Regression loss: 0.19033 | Running loss: 0.35631\n",
      "Epoch: 11 | Iteration: 643 | Classification loss: 0.08815 | Regression loss: 0.16193 | Running loss: 0.35627\n",
      "Epoch: 11 | Iteration: 644 | Classification loss: 0.09688 | Regression loss: 0.22133 | Running loss: 0.35579\n",
      "Epoch: 11 | Iteration: 645 | Classification loss: 0.01542 | Regression loss: 0.10099 | Running loss: 0.35529\n",
      "Epoch: 11 | Iteration: 646 | Classification loss: 0.01214 | Regression loss: 0.06920 | Running loss: 0.35399\n",
      "Epoch: 11 | Iteration: 647 | Classification loss: 0.06139 | Regression loss: 0.20955 | Running loss: 0.35361\n",
      "Epoch: 11 | Iteration: 648 | Classification loss: 0.02931 | Regression loss: 0.21346 | Running loss: 0.35324\n",
      "Epoch: 11 | Iteration: 649 | Classification loss: 0.04455 | Regression loss: 0.22656 | Running loss: 0.35289\n",
      "Epoch: 11 | Iteration: 650 | Classification loss: 0.15458 | Regression loss: 0.45613 | Running loss: 0.35334\n",
      "Epoch: 11 | Iteration: 651 | Classification loss: 0.10984 | Regression loss: 0.24424 | Running loss: 0.35369\n",
      "Epoch: 11 | Iteration: 652 | Classification loss: 0.17354 | Regression loss: 0.33941 | Running loss: 0.35353\n",
      "Epoch: 11 | Iteration: 653 | Classification loss: 0.09447 | Regression loss: 0.37621 | Running loss: 0.35394\n",
      "Epoch: 11 | Iteration: 654 | Classification loss: 0.12989 | Regression loss: 0.27967 | Running loss: 0.35417\n",
      "Epoch: 11 | Iteration: 655 | Classification loss: 0.07243 | Regression loss: 0.24452 | Running loss: 0.35390\n",
      "Epoch: 11 | Iteration: 656 | Classification loss: 0.11826 | Regression loss: 0.18679 | Running loss: 0.35363\n",
      "Epoch: 11 | Iteration: 657 | Classification loss: 0.30422 | Regression loss: 0.25182 | Running loss: 0.35375\n",
      "Epoch: 11 | Iteration: 658 | Classification loss: 0.02127 | Regression loss: 0.18623 | Running loss: 0.35337\n",
      "Epoch: 11 | Iteration: 659 | Classification loss: 0.23996 | Regression loss: 0.29450 | Running loss: 0.35354\n",
      "Epoch: 11 | Iteration: 660 | Classification loss: 0.01902 | Regression loss: 0.20743 | Running loss: 0.35316\n",
      "Epoch: 11 | Iteration: 661 | Classification loss: 0.17572 | Regression loss: 0.34132 | Running loss: 0.35331\n",
      "Epoch: 11 | Iteration: 662 | Classification loss: 0.02101 | Regression loss: 0.11384 | Running loss: 0.35327\n",
      "Epoch: 11 | Iteration: 663 | Classification loss: 0.10751 | Regression loss: 0.19511 | Running loss: 0.35293\n",
      "Epoch: 11 | Iteration: 664 | Classification loss: 0.08014 | Regression loss: 0.17331 | Running loss: 0.35270\n",
      "Epoch: 11 | Iteration: 665 | Classification loss: 0.26387 | Regression loss: 0.46283 | Running loss: 0.35382\n",
      "Epoch: 11 | Iteration: 666 | Classification loss: 0.06731 | Regression loss: 0.18702 | Running loss: 0.35376\n",
      "Epoch: 11 | Iteration: 667 | Classification loss: 0.14586 | Regression loss: 0.25507 | Running loss: 0.35263\n",
      "Epoch: 11 | Iteration: 668 | Classification loss: 0.04923 | Regression loss: 0.17570 | Running loss: 0.35233\n",
      "Epoch: 11 | Iteration: 669 | Classification loss: 0.30997 | Regression loss: 0.30562 | Running loss: 0.35290\n",
      "Epoch: 11 | Iteration: 670 | Classification loss: 0.06189 | Regression loss: 0.09063 | Running loss: 0.35286\n",
      "Epoch: 11 | Iteration: 671 | Classification loss: 0.13263 | Regression loss: 0.25281 | Running loss: 0.35297\n",
      "Epoch: 11 | Iteration: 672 | Classification loss: 0.06125 | Regression loss: 0.21999 | Running loss: 0.35309\n",
      "Epoch: 11 | Iteration: 673 | Classification loss: 0.41965 | Regression loss: 0.20314 | Running loss: 0.35291\n",
      "Epoch: 11 | Iteration: 674 | Classification loss: 0.26317 | Regression loss: 0.50465 | Running loss: 0.35394\n",
      "Epoch: 11 | Iteration: 675 | Classification loss: 0.26776 | Regression loss: 0.38879 | Running loss: 0.35388\n",
      "Epoch: 11 | Iteration: 676 | Classification loss: 0.05201 | Regression loss: 0.23008 | Running loss: 0.35332\n",
      "Epoch: 11 | Iteration: 677 | Classification loss: 0.02983 | Regression loss: 0.18640 | Running loss: 0.35232\n",
      "Epoch: 11 | Iteration: 678 | Classification loss: 0.18947 | Regression loss: 0.32922 | Running loss: 0.35279\n",
      "Epoch: 11 | Iteration: 679 | Classification loss: 0.25123 | Regression loss: 0.41040 | Running loss: 0.35324\n",
      "Epoch: 11 | Iteration: 680 | Classification loss: 0.06449 | Regression loss: 0.26103 | Running loss: 0.35247\n",
      "Epoch: 11 | Iteration: 681 | Classification loss: 0.05138 | Regression loss: 0.16619 | Running loss: 0.35212\n",
      "Epoch: 11 | Iteration: 682 | Classification loss: 0.13281 | Regression loss: 0.34231 | Running loss: 0.35186\n",
      "Epoch: 11 | Iteration: 683 | Classification loss: 0.07761 | Regression loss: 0.23709 | Running loss: 0.35149\n",
      "Epoch: 11 | Iteration: 684 | Classification loss: 0.13022 | Regression loss: 0.27567 | Running loss: 0.35177\n",
      "Epoch: 11 | Iteration: 685 | Classification loss: 0.08277 | Regression loss: 0.12943 | Running loss: 0.35148\n",
      "Epoch: 11 | Iteration: 686 | Classification loss: 0.09360 | Regression loss: 0.16814 | Running loss: 0.35159\n",
      "Epoch: 11 | Iteration: 687 | Classification loss: 0.06088 | Regression loss: 0.16986 | Running loss: 0.35133\n",
      "Epoch: 11 | Iteration: 688 | Classification loss: 0.06991 | Regression loss: 0.16018 | Running loss: 0.35119\n",
      "Epoch: 11 | Iteration: 689 | Classification loss: 0.06246 | Regression loss: 0.27025 | Running loss: 0.35133\n",
      "Epoch: 11 | Iteration: 690 | Classification loss: 0.15909 | Regression loss: 0.28322 | Running loss: 0.35180\n",
      "Epoch: 11 | Iteration: 691 | Classification loss: 0.08480 | Regression loss: 0.16401 | Running loss: 0.35156\n",
      "Epoch: 11 | Iteration: 692 | Classification loss: 0.05620 | Regression loss: 0.20542 | Running loss: 0.35154\n",
      "Epoch: 11 | Iteration: 693 | Classification loss: 0.19143 | Regression loss: 0.14263 | Running loss: 0.35128\n",
      "Epoch: 11 | Iteration: 694 | Classification loss: 0.06348 | Regression loss: 0.26229 | Running loss: 0.35131\n",
      "Epoch: 11 | Iteration: 695 | Classification loss: 0.10280 | Regression loss: 0.13908 | Running loss: 0.35127\n",
      "Epoch: 11 | Iteration: 696 | Classification loss: 0.09532 | Regression loss: 0.22944 | Running loss: 0.35144\n",
      "Epoch: 11 | Iteration: 697 | Classification loss: 0.09413 | Regression loss: 0.25615 | Running loss: 0.35116\n",
      "Epoch: 11 | Iteration: 698 | Classification loss: 0.03040 | Regression loss: 0.11962 | Running loss: 0.35001\n",
      "Epoch: 11 | Iteration: 699 | Classification loss: 0.13665 | Regression loss: 0.30508 | Running loss: 0.35003\n",
      "Epoch: 11 | Iteration: 700 | Classification loss: 0.05338 | Regression loss: 0.22886 | Running loss: 0.34977\n",
      "Epoch: 11 | Iteration: 701 | Classification loss: 0.09143 | Regression loss: 0.33662 | Running loss: 0.34992\n",
      "Epoch: 11 | Iteration: 702 | Classification loss: 0.10858 | Regression loss: 0.29915 | Running loss: 0.35009\n",
      "Epoch: 11 | Iteration: 703 | Classification loss: 0.11370 | Regression loss: 0.36057 | Running loss: 0.34992\n",
      "Epoch: 11 | Iteration: 704 | Classification loss: 0.08128 | Regression loss: 0.19603 | Running loss: 0.34975\n",
      "Epoch: 11 | Iteration: 705 | Classification loss: 0.05474 | Regression loss: 0.22811 | Running loss: 0.34972\n",
      "Epoch: 11 | Iteration: 706 | Classification loss: 0.36071 | Regression loss: 0.33093 | Running loss: 0.35060\n",
      "Epoch: 11 | Iteration: 707 | Classification loss: 0.02652 | Regression loss: 0.20321 | Running loss: 0.35008\n",
      "Epoch: 11 | Iteration: 708 | Classification loss: 0.08874 | Regression loss: 0.15135 | Running loss: 0.35018\n",
      "Epoch: 11 | Iteration: 709 | Classification loss: 0.04797 | Regression loss: 0.20649 | Running loss: 0.34981\n",
      "Epoch: 11 | Iteration: 710 | Classification loss: 0.27844 | Regression loss: 0.27422 | Running loss: 0.34975\n",
      "Epoch: 11 | Iteration: 711 | Classification loss: 0.06812 | Regression loss: 0.31335 | Running loss: 0.34991\n",
      "Epoch: 11 | Iteration: 712 | Classification loss: 0.04671 | Regression loss: 0.09649 | Running loss: 0.34970\n",
      "Epoch: 11 | Iteration: 713 | Classification loss: 0.08190 | Regression loss: 0.16775 | Running loss: 0.34937\n",
      "Epoch: 11 | Iteration: 714 | Classification loss: 0.20299 | Regression loss: 0.41264 | Running loss: 0.34986\n",
      "Epoch: 11 | Iteration: 715 | Classification loss: 0.22220 | Regression loss: 0.28023 | Running loss: 0.34927\n",
      "Epoch: 11 | Iteration: 716 | Classification loss: 0.18676 | Regression loss: 0.25712 | Running loss: 0.34939\n",
      "Epoch: 11 | Iteration: 717 | Classification loss: 0.04835 | Regression loss: 0.18375 | Running loss: 0.34934\n",
      "Epoch: 11 | Iteration: 718 | Classification loss: 0.09323 | Regression loss: 0.20298 | Running loss: 0.34812\n",
      "Epoch: 11 | Iteration: 719 | Classification loss: 0.13106 | Regression loss: 0.26179 | Running loss: 0.34821\n",
      "Epoch: 11 | Iteration: 720 | Classification loss: 0.10335 | Regression loss: 0.12494 | Running loss: 0.34821\n",
      "Epoch: 11 | Iteration: 721 | Classification loss: 0.05972 | Regression loss: 0.24546 | Running loss: 0.34814\n",
      "Epoch: 11 | Iteration: 722 | Classification loss: 0.04654 | Regression loss: 0.32590 | Running loss: 0.34816\n",
      "Epoch: 11 | Iteration: 723 | Classification loss: 0.06094 | Regression loss: 0.21900 | Running loss: 0.34824\n",
      "Epoch: 11 | Iteration: 724 | Classification loss: 0.55448 | Regression loss: 0.12013 | Running loss: 0.34910\n",
      "Epoch: 11 | Iteration: 725 | Classification loss: 0.04869 | Regression loss: 0.17239 | Running loss: 0.34890\n",
      "Epoch: 11 | Iteration: 726 | Classification loss: 0.10089 | Regression loss: 0.09969 | Running loss: 0.34798\n",
      "Epoch: 11 | Iteration: 727 | Classification loss: 0.07744 | Regression loss: 0.35177 | Running loss: 0.34796\n",
      "Epoch: 11 | Iteration: 728 | Classification loss: 0.02755 | Regression loss: 0.20000 | Running loss: 0.34791\n",
      "Epoch: 11 | Iteration: 729 | Classification loss: 0.04002 | Regression loss: 0.21545 | Running loss: 0.34707\n",
      "Epoch: 11 | Iteration: 730 | Classification loss: 0.19539 | Regression loss: 0.53881 | Running loss: 0.34764\n",
      "Epoch: 11 | Iteration: 731 | Classification loss: 0.11584 | Regression loss: 0.33122 | Running loss: 0.34754\n",
      "Epoch: 11 | Iteration: 732 | Classification loss: 0.09025 | Regression loss: 0.25405 | Running loss: 0.34748\n",
      "Epoch: 11 | Iteration: 733 | Classification loss: 0.24302 | Regression loss: 0.55985 | Running loss: 0.34877\n",
      "Epoch: 11 | Iteration: 734 | Classification loss: 0.04651 | Regression loss: 0.20580 | Running loss: 0.34865\n",
      "Epoch: 11 | Iteration: 735 | Classification loss: 0.02663 | Regression loss: 0.20360 | Running loss: 0.34844\n",
      "Epoch: 11 | Iteration: 736 | Classification loss: 0.04391 | Regression loss: 0.16581 | Running loss: 0.34785\n",
      "Epoch: 11 | Iteration: 737 | Classification loss: 0.13845 | Regression loss: 0.17322 | Running loss: 0.34704\n",
      "Epoch: 11 | Iteration: 738 | Classification loss: 0.07499 | Regression loss: 0.13814 | Running loss: 0.34649\n",
      "Epoch: 11 | Iteration: 739 | Classification loss: 0.06021 | Regression loss: 0.35795 | Running loss: 0.34649\n",
      "Epoch: 11 | Iteration: 740 | Classification loss: 0.07663 | Regression loss: 0.10986 | Running loss: 0.34575\n",
      "Epoch: 11 | Iteration: 741 | Classification loss: 0.24458 | Regression loss: 0.31526 | Running loss: 0.34628\n",
      "Epoch: 11 | Iteration: 742 | Classification loss: 0.08924 | Regression loss: 0.27783 | Running loss: 0.34655\n",
      "Epoch: 11 | Iteration: 743 | Classification loss: 0.36083 | Regression loss: 0.15225 | Running loss: 0.34658\n",
      "Epoch: 11 | Iteration: 744 | Classification loss: 0.09356 | Regression loss: 0.29689 | Running loss: 0.34660\n",
      "Epoch: 11 | Iteration: 745 | Classification loss: 0.02664 | Regression loss: 0.09440 | Running loss: 0.34618\n",
      "Epoch: 11 | Iteration: 746 | Classification loss: 0.08365 | Regression loss: 0.29995 | Running loss: 0.34654\n",
      "Epoch: 11 | Iteration: 747 | Classification loss: 0.03708 | Regression loss: 0.21904 | Running loss: 0.34619\n",
      "Epoch: 11 | Iteration: 748 | Classification loss: 0.07894 | Regression loss: 0.21022 | Running loss: 0.34584\n",
      "Epoch: 11 | Iteration: 749 | Classification loss: 0.05332 | Regression loss: 0.17402 | Running loss: 0.34499\n",
      "Epoch: 11 | Iteration: 750 | Classification loss: 0.14252 | Regression loss: 0.08961 | Running loss: 0.34408\n",
      "Epoch: 11 | Iteration: 751 | Classification loss: 0.23249 | Regression loss: 0.32165 | Running loss: 0.34450\n",
      "Epoch: 11 | Iteration: 752 | Classification loss: 0.07290 | Regression loss: 0.11427 | Running loss: 0.34451\n",
      "Epoch: 11 | Iteration: 753 | Classification loss: 0.03254 | Regression loss: 0.07964 | Running loss: 0.34442\n",
      "Epoch: 11 | Iteration: 754 | Classification loss: 0.09312 | Regression loss: 0.19876 | Running loss: 0.34436\n",
      "Epoch: 11 | Iteration: 755 | Classification loss: 0.05621 | Regression loss: 0.16741 | Running loss: 0.34346\n",
      "Epoch: 11 | Iteration: 756 | Classification loss: 0.06489 | Regression loss: 0.20038 | Running loss: 0.34334\n",
      "Epoch: 11 | Iteration: 757 | Classification loss: 0.07995 | Regression loss: 0.31036 | Running loss: 0.34353\n",
      "Epoch: 11 | Iteration: 758 | Classification loss: 0.04347 | Regression loss: 0.18112 | Running loss: 0.34317\n",
      "Epoch: 11 | Iteration: 759 | Classification loss: 0.04810 | Regression loss: 0.27595 | Running loss: 0.34307\n",
      "Epoch: 11 | Iteration: 760 | Classification loss: 0.02631 | Regression loss: 0.17184 | Running loss: 0.34291\n",
      "Epoch: 11 | Iteration: 761 | Classification loss: 0.05381 | Regression loss: 0.30149 | Running loss: 0.34362\n",
      "Epoch: 11 | Iteration: 762 | Classification loss: 0.10721 | Regression loss: 0.17148 | Running loss: 0.34377\n",
      "Epoch: 11 | Iteration: 763 | Classification loss: 0.11484 | Regression loss: 0.54717 | Running loss: 0.34463\n",
      "Epoch: 11 | Iteration: 764 | Classification loss: 0.03927 | Regression loss: 0.20368 | Running loss: 0.34316\n",
      "Epoch: 11 | Iteration: 765 | Classification loss: 0.02321 | Regression loss: 0.17017 | Running loss: 0.34297\n",
      "Epoch: 11 | Iteration: 766 | Classification loss: 0.02705 | Regression loss: 0.15032 | Running loss: 0.34298\n",
      "Epoch: 11 | Iteration: 767 | Classification loss: 0.11776 | Regression loss: 0.26693 | Running loss: 0.34319\n",
      "Epoch: 11 | Iteration: 768 | Classification loss: 0.02558 | Regression loss: 0.20081 | Running loss: 0.34290\n",
      "Epoch: 11 | Iteration: 769 | Classification loss: 0.10389 | Regression loss: 0.14947 | Running loss: 0.34271\n",
      "Epoch: 11 | Iteration: 770 | Classification loss: 0.07868 | Regression loss: 0.24604 | Running loss: 0.34287\n",
      "Epoch: 11 | Iteration: 771 | Classification loss: 0.01935 | Regression loss: 0.14656 | Running loss: 0.34262\n",
      "Epoch: 11 | Iteration: 772 | Classification loss: 0.09340 | Regression loss: 0.19610 | Running loss: 0.34250\n",
      "Epoch: 11 | Iteration: 773 | Classification loss: 0.08600 | Regression loss: 0.32426 | Running loss: 0.34222\n",
      "Epoch: 11 | Iteration: 774 | Classification loss: 0.17901 | Regression loss: 0.36488 | Running loss: 0.34275\n",
      "Epoch: 11 | Iteration: 775 | Classification loss: 0.05253 | Regression loss: 0.05901 | Running loss: 0.34245\n",
      "Epoch: 11 | Iteration: 776 | Classification loss: 0.09860 | Regression loss: 0.40175 | Running loss: 0.34259\n",
      "Epoch: 11 | Iteration: 777 | Classification loss: 0.05945 | Regression loss: 0.28771 | Running loss: 0.34275\n",
      "Epoch: 11 | Iteration: 778 | Classification loss: 0.04388 | Regression loss: 0.21671 | Running loss: 0.34278\n",
      "Epoch: 11 | Iteration: 779 | Classification loss: 0.34790 | Regression loss: 0.33733 | Running loss: 0.34353\n",
      "Epoch: 11 | Iteration: 780 | Classification loss: 0.22344 | Regression loss: 0.27366 | Running loss: 0.34403\n",
      "Epoch: 11 | Iteration: 781 | Classification loss: 0.02203 | Regression loss: 0.16909 | Running loss: 0.34382\n",
      "Epoch: 11 | Iteration: 782 | Classification loss: 0.12933 | Regression loss: 0.35826 | Running loss: 0.34442\n",
      "Epoch: 11 | Iteration: 783 | Classification loss: 0.14619 | Regression loss: 0.23038 | Running loss: 0.34491\n",
      "Epoch: 11 | Iteration: 784 | Classification loss: 0.02916 | Regression loss: 0.18889 | Running loss: 0.34484\n",
      "Epoch: 11 | Iteration: 785 | Classification loss: 0.04175 | Regression loss: 0.13459 | Running loss: 0.34484\n",
      "Epoch: 11 | Iteration: 786 | Classification loss: 0.02550 | Regression loss: 0.23509 | Running loss: 0.34489\n",
      "Epoch: 11 | Iteration: 787 | Classification loss: 0.18619 | Regression loss: 0.19741 | Running loss: 0.34519\n",
      "Epoch: 11 | Iteration: 788 | Classification loss: 0.04018 | Regression loss: 0.20327 | Running loss: 0.34518\n",
      "Epoch: 11 | Iteration: 789 | Classification loss: 0.09176 | Regression loss: 0.35118 | Running loss: 0.34549\n",
      "Epoch: 11 | Iteration: 790 | Classification loss: 0.14451 | Regression loss: 0.30877 | Running loss: 0.34599\n",
      "Epoch: 11 | Iteration: 791 | Classification loss: 0.07496 | Regression loss: 0.10323 | Running loss: 0.34575\n",
      "Epoch: 11 | Iteration: 792 | Classification loss: 0.09756 | Regression loss: 0.31865 | Running loss: 0.34615\n",
      "Epoch: 11 | Iteration: 793 | Classification loss: 0.28873 | Regression loss: 0.38944 | Running loss: 0.34649\n",
      "Epoch: 11 | Iteration: 794 | Classification loss: 0.06207 | Regression loss: 0.20367 | Running loss: 0.34665\n",
      "Epoch: 11 | Iteration: 795 | Classification loss: 0.04695 | Regression loss: 0.23396 | Running loss: 0.34627\n",
      "Epoch: 11 | Iteration: 796 | Classification loss: 0.10781 | Regression loss: 0.12003 | Running loss: 0.34614\n",
      "Epoch: 11 | Iteration: 797 | Classification loss: 0.03182 | Regression loss: 0.18260 | Running loss: 0.34586\n",
      "Epoch: 11 | Iteration: 798 | Classification loss: 0.05325 | Regression loss: 0.25925 | Running loss: 0.34531\n",
      "Epoch: 11 | Iteration: 799 | Classification loss: 0.09139 | Regression loss: 0.25849 | Running loss: 0.34478\n",
      "Epoch: 11 | Iteration: 800 | Classification loss: 0.05204 | Regression loss: 0.15714 | Running loss: 0.34490\n",
      "Epoch: 11 | Iteration: 801 | Classification loss: 0.19789 | Regression loss: 0.23948 | Running loss: 0.34462\n",
      "Epoch: 11 | Iteration: 802 | Classification loss: 0.08951 | Regression loss: 0.15806 | Running loss: 0.34459\n",
      "Epoch: 11 | Iteration: 803 | Classification loss: 0.06384 | Regression loss: 0.27584 | Running loss: 0.34470\n",
      "Epoch: 11 | Iteration: 804 | Classification loss: 0.04755 | Regression loss: 0.27928 | Running loss: 0.34496\n",
      "Epoch: 11 | Iteration: 805 | Classification loss: 0.13720 | Regression loss: 0.14804 | Running loss: 0.34506\n",
      "Epoch: 11 | Iteration: 806 | Classification loss: 0.16759 | Regression loss: 0.46588 | Running loss: 0.34524\n",
      "Epoch: 11 | Iteration: 807 | Classification loss: 0.04084 | Regression loss: 0.10597 | Running loss: 0.34508\n",
      "Epoch: 11 | Iteration: 808 | Classification loss: 0.15578 | Regression loss: 0.38529 | Running loss: 0.34492\n",
      "Epoch: 11 | Iteration: 809 | Classification loss: 0.06620 | Regression loss: 0.36309 | Running loss: 0.34526\n",
      "Epoch: 11 | Iteration: 810 | Classification loss: 0.03303 | Regression loss: 0.31132 | Running loss: 0.34479\n",
      "Epoch: 11 | Iteration: 811 | Classification loss: 0.17276 | Regression loss: 0.42133 | Running loss: 0.34534\n",
      "Epoch: 11 | Iteration: 812 | Classification loss: 0.10675 | Regression loss: 0.32467 | Running loss: 0.34541\n",
      "Epoch: 11 | Iteration: 813 | Classification loss: 0.27195 | Regression loss: 0.18363 | Running loss: 0.34576\n",
      "Epoch: 11 | Iteration: 814 | Classification loss: 0.19662 | Regression loss: 0.27429 | Running loss: 0.34601\n",
      "Epoch: 11 | Iteration: 815 | Classification loss: 0.02958 | Regression loss: 0.24649 | Running loss: 0.34571\n",
      "Epoch: 11 | Iteration: 816 | Classification loss: 0.07706 | Regression loss: 0.24398 | Running loss: 0.34556\n",
      "Epoch: 11 | Iteration: 817 | Classification loss: 0.03389 | Regression loss: 0.16053 | Running loss: 0.34560\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.588\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 12 | Iteration: 0 | Classification loss: 0.08068 | Regression loss: 0.10241 | Running loss: 0.34548\n",
      "Epoch: 12 | Iteration: 1 | Classification loss: 0.05237 | Regression loss: 0.17017 | Running loss: 0.34553\n",
      "Epoch: 12 | Iteration: 2 | Classification loss: 0.04109 | Regression loss: 0.27687 | Running loss: 0.34574\n",
      "Epoch: 12 | Iteration: 3 | Classification loss: 0.27901 | Regression loss: 0.23388 | Running loss: 0.34616\n",
      "Epoch: 12 | Iteration: 4 | Classification loss: 0.03197 | Regression loss: 0.14066 | Running loss: 0.34578\n",
      "Epoch: 12 | Iteration: 5 | Classification loss: 0.06076 | Regression loss: 0.19647 | Running loss: 0.34549\n",
      "Epoch: 12 | Iteration: 6 | Classification loss: 0.06927 | Regression loss: 0.28644 | Running loss: 0.34571\n",
      "Epoch: 12 | Iteration: 7 | Classification loss: 0.06150 | Regression loss: 0.15812 | Running loss: 0.34579\n",
      "Epoch: 12 | Iteration: 8 | Classification loss: 0.13139 | Regression loss: 0.27485 | Running loss: 0.34566\n",
      "Epoch: 12 | Iteration: 9 | Classification loss: 0.16782 | Regression loss: 0.26336 | Running loss: 0.34583\n",
      "Epoch: 12 | Iteration: 10 | Classification loss: 0.40719 | Regression loss: 0.08642 | Running loss: 0.34646\n",
      "Epoch: 12 | Iteration: 11 | Classification loss: 0.02975 | Regression loss: 0.14389 | Running loss: 0.34628\n",
      "Epoch: 12 | Iteration: 12 | Classification loss: 0.04523 | Regression loss: 0.14869 | Running loss: 0.34568\n",
      "Epoch: 12 | Iteration: 13 | Classification loss: 0.28917 | Regression loss: 0.55713 | Running loss: 0.34692\n",
      "Epoch: 12 | Iteration: 14 | Classification loss: 0.08121 | Regression loss: 0.22682 | Running loss: 0.34706\n",
      "Epoch: 12 | Iteration: 15 | Classification loss: 0.03167 | Regression loss: 0.08479 | Running loss: 0.34665\n",
      "Epoch: 12 | Iteration: 16 | Classification loss: 0.03812 | Regression loss: 0.30659 | Running loss: 0.34683\n",
      "Epoch: 12 | Iteration: 17 | Classification loss: 0.06248 | Regression loss: 0.20750 | Running loss: 0.34585\n",
      "Epoch: 12 | Iteration: 18 | Classification loss: 0.12049 | Regression loss: 0.21663 | Running loss: 0.34606\n",
      "Epoch: 12 | Iteration: 19 | Classification loss: 0.12353 | Regression loss: 0.33134 | Running loss: 0.34624\n",
      "Epoch: 12 | Iteration: 20 | Classification loss: 0.06918 | Regression loss: 0.19331 | Running loss: 0.34613\n",
      "Epoch: 12 | Iteration: 21 | Classification loss: 0.02252 | Regression loss: 0.12909 | Running loss: 0.34563\n",
      "Epoch: 12 | Iteration: 22 | Classification loss: 0.09543 | Regression loss: 0.17065 | Running loss: 0.34546\n",
      "Epoch: 12 | Iteration: 23 | Classification loss: 0.08828 | Regression loss: 0.32558 | Running loss: 0.34591\n",
      "Epoch: 12 | Iteration: 24 | Classification loss: 0.14224 | Regression loss: 0.33433 | Running loss: 0.34575\n",
      "Epoch: 12 | Iteration: 25 | Classification loss: 0.04410 | Regression loss: 0.18264 | Running loss: 0.34560\n",
      "Epoch: 12 | Iteration: 26 | Classification loss: 0.10550 | Regression loss: 0.30904 | Running loss: 0.34617\n",
      "Epoch: 12 | Iteration: 27 | Classification loss: 0.03873 | Regression loss: 0.19660 | Running loss: 0.34590\n",
      "Epoch: 12 | Iteration: 28 | Classification loss: 0.24141 | Regression loss: 0.46833 | Running loss: 0.34668\n",
      "Epoch: 12 | Iteration: 29 | Classification loss: 0.07150 | Regression loss: 0.63258 | Running loss: 0.34737\n",
      "Epoch: 12 | Iteration: 30 | Classification loss: 0.07975 | Regression loss: 0.15747 | Running loss: 0.34688\n",
      "Epoch: 12 | Iteration: 31 | Classification loss: 0.14938 | Regression loss: 0.24898 | Running loss: 0.34698\n",
      "Epoch: 12 | Iteration: 32 | Classification loss: 0.13120 | Regression loss: 0.32113 | Running loss: 0.34738\n",
      "Epoch: 12 | Iteration: 33 | Classification loss: 0.06648 | Regression loss: 0.20896 | Running loss: 0.34752\n",
      "Epoch: 12 | Iteration: 34 | Classification loss: 0.03889 | Regression loss: 0.17956 | Running loss: 0.34701\n",
      "Epoch: 12 | Iteration: 35 | Classification loss: 0.08852 | Regression loss: 0.20804 | Running loss: 0.34721\n",
      "Epoch: 12 | Iteration: 36 | Classification loss: 0.02656 | Regression loss: 0.10376 | Running loss: 0.34694\n",
      "Epoch: 12 | Iteration: 37 | Classification loss: 0.12477 | Regression loss: 0.30072 | Running loss: 0.34748\n",
      "Epoch: 12 | Iteration: 38 | Classification loss: 0.13890 | Regression loss: 0.36127 | Running loss: 0.34783\n",
      "Epoch: 12 | Iteration: 39 | Classification loss: 0.04938 | Regression loss: 0.23296 | Running loss: 0.34789\n",
      "Epoch: 12 | Iteration: 40 | Classification loss: 0.28936 | Regression loss: 0.17221 | Running loss: 0.34850\n",
      "Epoch: 12 | Iteration: 41 | Classification loss: 0.03449 | Regression loss: 0.15422 | Running loss: 0.34849\n",
      "Epoch: 12 | Iteration: 42 | Classification loss: 0.22698 | Regression loss: 0.32403 | Running loss: 0.34875\n",
      "Epoch: 12 | Iteration: 43 | Classification loss: 0.08650 | Regression loss: 0.26488 | Running loss: 0.34886\n",
      "Epoch: 12 | Iteration: 44 | Classification loss: 0.06468 | Regression loss: 0.16851 | Running loss: 0.34881\n",
      "Epoch: 12 | Iteration: 45 | Classification loss: 0.08975 | Regression loss: 0.13638 | Running loss: 0.34882\n",
      "Epoch: 12 | Iteration: 46 | Classification loss: 0.07800 | Regression loss: 0.29562 | Running loss: 0.34899\n",
      "Epoch: 12 | Iteration: 47 | Classification loss: 0.03686 | Regression loss: 0.15458 | Running loss: 0.34844\n",
      "Epoch: 12 | Iteration: 48 | Classification loss: 0.41010 | Regression loss: 0.43710 | Running loss: 0.34975\n",
      "Epoch: 12 | Iteration: 49 | Classification loss: 0.22106 | Regression loss: 0.22987 | Running loss: 0.34933\n",
      "Epoch: 12 | Iteration: 50 | Classification loss: 0.03796 | Regression loss: 0.14038 | Running loss: 0.34915\n",
      "Epoch: 12 | Iteration: 51 | Classification loss: 0.05376 | Regression loss: 0.24160 | Running loss: 0.34904\n",
      "Epoch: 12 | Iteration: 52 | Classification loss: 0.16927 | Regression loss: 0.39343 | Running loss: 0.34951\n",
      "Epoch: 12 | Iteration: 53 | Classification loss: 0.04181 | Regression loss: 0.33034 | Running loss: 0.34893\n",
      "Epoch: 12 | Iteration: 54 | Classification loss: 0.02293 | Regression loss: 0.15732 | Running loss: 0.34881\n",
      "Epoch: 12 | Iteration: 55 | Classification loss: 0.07695 | Regression loss: 0.24613 | Running loss: 0.34831\n",
      "Epoch: 12 | Iteration: 56 | Classification loss: 0.03829 | Regression loss: 0.11203 | Running loss: 0.34753\n",
      "Epoch: 12 | Iteration: 57 | Classification loss: 0.03067 | Regression loss: 0.14324 | Running loss: 0.34738\n",
      "Epoch: 12 | Iteration: 58 | Classification loss: 0.57564 | Regression loss: 0.21833 | Running loss: 0.34822\n",
      "Epoch: 12 | Iteration: 59 | Classification loss: 0.06601 | Regression loss: 0.09788 | Running loss: 0.34769\n",
      "Epoch: 12 | Iteration: 60 | Classification loss: 0.04785 | Regression loss: 0.15162 | Running loss: 0.34750\n",
      "Epoch: 12 | Iteration: 61 | Classification loss: 0.02099 | Regression loss: 0.14454 | Running loss: 0.34699\n",
      "Epoch: 12 | Iteration: 62 | Classification loss: 0.04145 | Regression loss: 0.26804 | Running loss: 0.34607\n",
      "Epoch: 12 | Iteration: 63 | Classification loss: 0.06301 | Regression loss: 0.21408 | Running loss: 0.34605\n",
      "Epoch: 12 | Iteration: 64 | Classification loss: 0.07898 | Regression loss: 0.38457 | Running loss: 0.34642\n",
      "Epoch: 12 | Iteration: 65 | Classification loss: 0.05852 | Regression loss: 0.28750 | Running loss: 0.34675\n",
      "Epoch: 12 | Iteration: 66 | Classification loss: 0.31317 | Regression loss: 0.15077 | Running loss: 0.34725\n",
      "Epoch: 12 | Iteration: 67 | Classification loss: 0.06054 | Regression loss: 0.13255 | Running loss: 0.34688\n",
      "Epoch: 12 | Iteration: 68 | Classification loss: 0.10282 | Regression loss: 0.29051 | Running loss: 0.34586\n",
      "Epoch: 12 | Iteration: 69 | Classification loss: 0.35899 | Regression loss: 0.24090 | Running loss: 0.34648\n",
      "Epoch: 12 | Iteration: 70 | Classification loss: 0.12486 | Regression loss: 0.24567 | Running loss: 0.34674\n",
      "Epoch: 12 | Iteration: 71 | Classification loss: 0.08690 | Regression loss: 0.25195 | Running loss: 0.34705\n",
      "Epoch: 12 | Iteration: 72 | Classification loss: 0.04960 | Regression loss: 0.10436 | Running loss: 0.34683\n",
      "Epoch: 12 | Iteration: 73 | Classification loss: 0.04527 | Regression loss: 0.21186 | Running loss: 0.34649\n",
      "Epoch: 12 | Iteration: 74 | Classification loss: 0.05805 | Regression loss: 0.21974 | Running loss: 0.34656\n",
      "Epoch: 12 | Iteration: 75 | Classification loss: 0.06810 | Regression loss: 0.24567 | Running loss: 0.34627\n",
      "Epoch: 12 | Iteration: 76 | Classification loss: 0.06551 | Regression loss: 0.22192 | Running loss: 0.34642\n",
      "Epoch: 12 | Iteration: 77 | Classification loss: 0.13547 | Regression loss: 0.21561 | Running loss: 0.34642\n",
      "Epoch: 12 | Iteration: 78 | Classification loss: 0.13486 | Regression loss: 0.27562 | Running loss: 0.34675\n",
      "Epoch: 12 | Iteration: 79 | Classification loss: 0.04416 | Regression loss: 0.28471 | Running loss: 0.34695\n",
      "Epoch: 12 | Iteration: 80 | Classification loss: 0.06289 | Regression loss: 0.21364 | Running loss: 0.34698\n",
      "Epoch: 12 | Iteration: 81 | Classification loss: 0.17244 | Regression loss: 0.20622 | Running loss: 0.34740\n",
      "Epoch: 12 | Iteration: 82 | Classification loss: 0.08677 | Regression loss: 0.28863 | Running loss: 0.34776\n",
      "Epoch: 12 | Iteration: 83 | Classification loss: 0.12959 | Regression loss: 0.27952 | Running loss: 0.34799\n",
      "Epoch: 12 | Iteration: 84 | Classification loss: 0.19968 | Regression loss: 0.26413 | Running loss: 0.34780\n",
      "Epoch: 12 | Iteration: 85 | Classification loss: 0.12420 | Regression loss: 0.42834 | Running loss: 0.34808\n",
      "Epoch: 12 | Iteration: 86 | Classification loss: 0.09437 | Regression loss: 0.37352 | Running loss: 0.34841\n",
      "Epoch: 12 | Iteration: 87 | Classification loss: 0.07455 | Regression loss: 0.14624 | Running loss: 0.34819\n",
      "Epoch: 12 | Iteration: 88 | Classification loss: 0.03735 | Regression loss: 0.14042 | Running loss: 0.34739\n",
      "Epoch: 12 | Iteration: 89 | Classification loss: 0.07470 | Regression loss: 0.15818 | Running loss: 0.34681\n",
      "Epoch: 12 | Iteration: 90 | Classification loss: 0.09017 | Regression loss: 0.30991 | Running loss: 0.34699\n",
      "Epoch: 12 | Iteration: 91 | Classification loss: 0.06280 | Regression loss: 0.18434 | Running loss: 0.34716\n",
      "Epoch: 12 | Iteration: 92 | Classification loss: 0.08503 | Regression loss: 0.28150 | Running loss: 0.34686\n",
      "Epoch: 12 | Iteration: 93 | Classification loss: 0.05026 | Regression loss: 0.17087 | Running loss: 0.34643\n",
      "Epoch: 12 | Iteration: 94 | Classification loss: 0.05762 | Regression loss: 0.39171 | Running loss: 0.34697\n",
      "Epoch: 12 | Iteration: 95 | Classification loss: 0.06470 | Regression loss: 0.14236 | Running loss: 0.34659\n",
      "Epoch: 12 | Iteration: 96 | Classification loss: 0.00055 | Regression loss: 0.00000 | Running loss: 0.34619\n",
      "Epoch: 12 | Iteration: 97 | Classification loss: 0.13540 | Regression loss: 0.10254 | Running loss: 0.34614\n",
      "Epoch: 12 | Iteration: 98 | Classification loss: 0.25152 | Regression loss: 0.17996 | Running loss: 0.34634\n",
      "Epoch: 12 | Iteration: 99 | Classification loss: 0.06124 | Regression loss: 0.33072 | Running loss: 0.34666\n",
      "Epoch: 12 | Iteration: 100 | Classification loss: 0.07819 | Regression loss: 0.23083 | Running loss: 0.34612\n",
      "Epoch: 12 | Iteration: 101 | Classification loss: 0.09559 | Regression loss: 0.21882 | Running loss: 0.34602\n",
      "Epoch: 12 | Iteration: 102 | Classification loss: 0.05955 | Regression loss: 0.16470 | Running loss: 0.34563\n",
      "Epoch: 12 | Iteration: 103 | Classification loss: 0.08189 | Regression loss: 0.23638 | Running loss: 0.34544\n",
      "Epoch: 12 | Iteration: 104 | Classification loss: 0.03942 | Regression loss: 0.23666 | Running loss: 0.34574\n",
      "Epoch: 12 | Iteration: 105 | Classification loss: 0.07994 | Regression loss: 0.19901 | Running loss: 0.34556\n",
      "Epoch: 12 | Iteration: 106 | Classification loss: 0.15467 | Regression loss: 0.22260 | Running loss: 0.34586\n",
      "Epoch: 12 | Iteration: 107 | Classification loss: 0.13457 | Regression loss: 0.18905 | Running loss: 0.34598\n",
      "Epoch: 12 | Iteration: 108 | Classification loss: 0.06783 | Regression loss: 0.28248 | Running loss: 0.34585\n",
      "Epoch: 12 | Iteration: 109 | Classification loss: 0.04158 | Regression loss: 0.20953 | Running loss: 0.34557\n",
      "Epoch: 12 | Iteration: 110 | Classification loss: 0.06123 | Regression loss: 0.16571 | Running loss: 0.34481\n",
      "Epoch: 12 | Iteration: 111 | Classification loss: 0.13981 | Regression loss: 0.13639 | Running loss: 0.34467\n",
      "Epoch: 12 | Iteration: 112 | Classification loss: 0.17538 | Regression loss: 0.30832 | Running loss: 0.34525\n",
      "Epoch: 12 | Iteration: 113 | Classification loss: 0.06174 | Regression loss: 0.16579 | Running loss: 0.34507\n",
      "Epoch: 12 | Iteration: 114 | Classification loss: 0.11280 | Regression loss: 0.14983 | Running loss: 0.34501\n",
      "Epoch: 12 | Iteration: 115 | Classification loss: 0.04304 | Regression loss: 0.23483 | Running loss: 0.34507\n",
      "Epoch: 12 | Iteration: 116 | Classification loss: 0.02781 | Regression loss: 0.07937 | Running loss: 0.34420\n",
      "Epoch: 12 | Iteration: 117 | Classification loss: 0.06124 | Regression loss: 0.17119 | Running loss: 0.34403\n",
      "Epoch: 12 | Iteration: 118 | Classification loss: 0.02878 | Regression loss: 0.19931 | Running loss: 0.34395\n",
      "Epoch: 12 | Iteration: 119 | Classification loss: 0.15613 | Regression loss: 0.40448 | Running loss: 0.34421\n",
      "Epoch: 12 | Iteration: 120 | Classification loss: 0.08743 | Regression loss: 0.18308 | Running loss: 0.34373\n",
      "Epoch: 12 | Iteration: 121 | Classification loss: 0.05162 | Regression loss: 0.21250 | Running loss: 0.34354\n",
      "Epoch: 12 | Iteration: 122 | Classification loss: 0.12020 | Regression loss: 0.38841 | Running loss: 0.34377\n",
      "Epoch: 12 | Iteration: 123 | Classification loss: 0.05675 | Regression loss: 0.25699 | Running loss: 0.34380\n",
      "Epoch: 12 | Iteration: 124 | Classification loss: 0.05343 | Regression loss: 0.25827 | Running loss: 0.34365\n",
      "Epoch: 12 | Iteration: 125 | Classification loss: 0.03905 | Regression loss: 0.16167 | Running loss: 0.34336\n",
      "Epoch: 12 | Iteration: 126 | Classification loss: 0.02320 | Regression loss: 0.18988 | Running loss: 0.34258\n",
      "Epoch: 12 | Iteration: 127 | Classification loss: 0.03603 | Regression loss: 0.14564 | Running loss: 0.34252\n",
      "Epoch: 12 | Iteration: 128 | Classification loss: 0.05317 | Regression loss: 0.18299 | Running loss: 0.34266\n",
      "Epoch: 12 | Iteration: 129 | Classification loss: 0.01930 | Regression loss: 0.21139 | Running loss: 0.34248\n",
      "Epoch: 12 | Iteration: 130 | Classification loss: 0.08871 | Regression loss: 0.17577 | Running loss: 0.34256\n",
      "Epoch: 12 | Iteration: 131 | Classification loss: 0.02828 | Regression loss: 0.11631 | Running loss: 0.34228\n",
      "Epoch: 12 | Iteration: 132 | Classification loss: 0.10698 | Regression loss: 0.13195 | Running loss: 0.34210\n",
      "Epoch: 12 | Iteration: 133 | Classification loss: 0.05670 | Regression loss: 0.27610 | Running loss: 0.34161\n",
      "Epoch: 12 | Iteration: 134 | Classification loss: 0.06810 | Regression loss: 0.15261 | Running loss: 0.34183\n",
      "Epoch: 12 | Iteration: 135 | Classification loss: 0.05488 | Regression loss: 0.20234 | Running loss: 0.34200\n",
      "Epoch: 12 | Iteration: 136 | Classification loss: 0.02699 | Regression loss: 0.18529 | Running loss: 0.34171\n",
      "Epoch: 12 | Iteration: 137 | Classification loss: 0.12925 | Regression loss: 0.17330 | Running loss: 0.34180\n",
      "Epoch: 12 | Iteration: 138 | Classification loss: 0.04724 | Regression loss: 0.30989 | Running loss: 0.34091\n",
      "Epoch: 12 | Iteration: 139 | Classification loss: 0.02613 | Regression loss: 0.17050 | Running loss: 0.34081\n",
      "Epoch: 12 | Iteration: 140 | Classification loss: 0.06888 | Regression loss: 0.26166 | Running loss: 0.34105\n",
      "Epoch: 12 | Iteration: 141 | Classification loss: 0.04891 | Regression loss: 0.19101 | Running loss: 0.34106\n",
      "Epoch: 12 | Iteration: 142 | Classification loss: 0.07338 | Regression loss: 0.12978 | Running loss: 0.34052\n",
      "Epoch: 12 | Iteration: 143 | Classification loss: 0.07512 | Regression loss: 0.34858 | Running loss: 0.34065\n",
      "Epoch: 12 | Iteration: 144 | Classification loss: 0.03926 | Regression loss: 0.25551 | Running loss: 0.33971\n",
      "Epoch: 12 | Iteration: 145 | Classification loss: 0.08908 | Regression loss: 0.17890 | Running loss: 0.33884\n",
      "Epoch: 12 | Iteration: 146 | Classification loss: 0.03378 | Regression loss: 0.15956 | Running loss: 0.33856\n",
      "Epoch: 12 | Iteration: 147 | Classification loss: 0.04889 | Regression loss: 0.18283 | Running loss: 0.33882\n",
      "Epoch: 12 | Iteration: 148 | Classification loss: 0.08383 | Regression loss: 0.15972 | Running loss: 0.33830\n",
      "Epoch: 12 | Iteration: 149 | Classification loss: 0.04330 | Regression loss: 0.14023 | Running loss: 0.33825\n",
      "Epoch: 12 | Iteration: 150 | Classification loss: 0.07680 | Regression loss: 0.26508 | Running loss: 0.33820\n",
      "Epoch: 12 | Iteration: 151 | Classification loss: 0.02051 | Regression loss: 0.07611 | Running loss: 0.33807\n",
      "Epoch: 12 | Iteration: 152 | Classification loss: 0.03215 | Regression loss: 0.19440 | Running loss: 0.33779\n",
      "Epoch: 12 | Iteration: 153 | Classification loss: 0.04791 | Regression loss: 0.20354 | Running loss: 0.33787\n",
      "Epoch: 12 | Iteration: 154 | Classification loss: 0.02901 | Regression loss: 0.13838 | Running loss: 0.33632\n",
      "Epoch: 12 | Iteration: 155 | Classification loss: 0.07632 | Regression loss: 0.30684 | Running loss: 0.33646\n",
      "Epoch: 12 | Iteration: 156 | Classification loss: 0.02389 | Regression loss: 0.22921 | Running loss: 0.33648\n",
      "Epoch: 12 | Iteration: 157 | Classification loss: 0.15622 | Regression loss: 0.35869 | Running loss: 0.33672\n",
      "Epoch: 12 | Iteration: 158 | Classification loss: 0.11868 | Regression loss: 0.18748 | Running loss: 0.33690\n",
      "Epoch: 12 | Iteration: 159 | Classification loss: 0.16115 | Regression loss: 0.14549 | Running loss: 0.33638\n",
      "Epoch: 12 | Iteration: 160 | Classification loss: 0.13226 | Regression loss: 0.21445 | Running loss: 0.33626\n",
      "Epoch: 12 | Iteration: 161 | Classification loss: 0.03401 | Regression loss: 0.13667 | Running loss: 0.33615\n",
      "Epoch: 12 | Iteration: 162 | Classification loss: 0.07596 | Regression loss: 0.20051 | Running loss: 0.33623\n",
      "Epoch: 12 | Iteration: 163 | Classification loss: 0.07164 | Regression loss: 0.32487 | Running loss: 0.33629\n",
      "Epoch: 12 | Iteration: 164 | Classification loss: 0.06951 | Regression loss: 0.17425 | Running loss: 0.33529\n",
      "Epoch: 12 | Iteration: 165 | Classification loss: 0.04149 | Regression loss: 0.21762 | Running loss: 0.33514\n",
      "Epoch: 12 | Iteration: 166 | Classification loss: 0.23372 | Regression loss: 0.20499 | Running loss: 0.33557\n",
      "Epoch: 12 | Iteration: 167 | Classification loss: 0.07274 | Regression loss: 0.28636 | Running loss: 0.33573\n",
      "Epoch: 12 | Iteration: 168 | Classification loss: 0.03794 | Regression loss: 0.24231 | Running loss: 0.33585\n",
      "Epoch: 12 | Iteration: 169 | Classification loss: 0.04107 | Regression loss: 0.14230 | Running loss: 0.33569\n",
      "Epoch: 12 | Iteration: 170 | Classification loss: 0.09981 | Regression loss: 0.17480 | Running loss: 0.33579\n",
      "Epoch: 12 | Iteration: 171 | Classification loss: 0.01944 | Regression loss: 0.13948 | Running loss: 0.33552\n",
      "Epoch: 12 | Iteration: 172 | Classification loss: 0.06484 | Regression loss: 0.19012 | Running loss: 0.33527\n",
      "Epoch: 12 | Iteration: 173 | Classification loss: 0.07706 | Regression loss: 0.20557 | Running loss: 0.33542\n",
      "Epoch: 12 | Iteration: 174 | Classification loss: 0.09756 | Regression loss: 0.32750 | Running loss: 0.33445\n",
      "Epoch: 12 | Iteration: 175 | Classification loss: 0.11541 | Regression loss: 0.27114 | Running loss: 0.33450\n",
      "Epoch: 12 | Iteration: 176 | Classification loss: 0.16688 | Regression loss: 0.11500 | Running loss: 0.33456\n",
      "Epoch: 12 | Iteration: 177 | Classification loss: 0.06090 | Regression loss: 0.18722 | Running loss: 0.33442\n",
      "Epoch: 12 | Iteration: 178 | Classification loss: 0.08574 | Regression loss: 0.28363 | Running loss: 0.33474\n",
      "Epoch: 12 | Iteration: 179 | Classification loss: 0.06972 | Regression loss: 0.18881 | Running loss: 0.33462\n",
      "Epoch: 12 | Iteration: 180 | Classification loss: 0.01924 | Regression loss: 0.21071 | Running loss: 0.33434\n",
      "Epoch: 12 | Iteration: 181 | Classification loss: 0.25092 | Regression loss: 0.41414 | Running loss: 0.33525\n",
      "Epoch: 12 | Iteration: 182 | Classification loss: 0.08573 | Regression loss: 0.14310 | Running loss: 0.33493\n",
      "Epoch: 12 | Iteration: 183 | Classification loss: 0.03160 | Regression loss: 0.11265 | Running loss: 0.33444\n",
      "Epoch: 12 | Iteration: 184 | Classification loss: 0.08287 | Regression loss: 0.16856 | Running loss: 0.33446\n",
      "Epoch: 12 | Iteration: 185 | Classification loss: 0.08546 | Regression loss: 0.21371 | Running loss: 0.33474\n",
      "Epoch: 12 | Iteration: 186 | Classification loss: 0.07190 | Regression loss: 0.19180 | Running loss: 0.33486\n",
      "Epoch: 12 | Iteration: 187 | Classification loss: 0.11732 | Regression loss: 0.34084 | Running loss: 0.33516\n",
      "Epoch: 12 | Iteration: 188 | Classification loss: 0.02719 | Regression loss: 0.22689 | Running loss: 0.33464\n",
      "Epoch: 12 | Iteration: 189 | Classification loss: 0.03326 | Regression loss: 0.21680 | Running loss: 0.33455\n",
      "Epoch: 12 | Iteration: 190 | Classification loss: 0.33306 | Regression loss: 0.12757 | Running loss: 0.33499\n",
      "Epoch: 12 | Iteration: 191 | Classification loss: 0.02538 | Regression loss: 0.15658 | Running loss: 0.33355\n",
      "Epoch: 12 | Iteration: 192 | Classification loss: 1.14233 | Regression loss: 0.27532 | Running loss: 0.33565\n",
      "Epoch: 12 | Iteration: 193 | Classification loss: 0.09266 | Regression loss: 0.26085 | Running loss: 0.33520\n",
      "Epoch: 12 | Iteration: 194 | Classification loss: 0.03232 | Regression loss: 0.14358 | Running loss: 0.33496\n",
      "Epoch: 12 | Iteration: 195 | Classification loss: 0.06661 | Regression loss: 0.11792 | Running loss: 0.33424\n",
      "Epoch: 12 | Iteration: 196 | Classification loss: 0.08508 | Regression loss: 0.17550 | Running loss: 0.33418\n",
      "Epoch: 12 | Iteration: 197 | Classification loss: 0.24243 | Regression loss: 0.28736 | Running loss: 0.33497\n",
      "Epoch: 12 | Iteration: 198 | Classification loss: 0.06812 | Regression loss: 0.20003 | Running loss: 0.33487\n",
      "Epoch: 12 | Iteration: 199 | Classification loss: 0.04769 | Regression loss: 0.16850 | Running loss: 0.33499\n",
      "Epoch: 12 | Iteration: 200 | Classification loss: 0.02318 | Regression loss: 0.20411 | Running loss: 0.33443\n",
      "Epoch: 12 | Iteration: 201 | Classification loss: 0.03390 | Regression loss: 0.23591 | Running loss: 0.33456\n",
      "Epoch: 12 | Iteration: 202 | Classification loss: 0.04504 | Regression loss: 0.24779 | Running loss: 0.33454\n",
      "Epoch: 12 | Iteration: 203 | Classification loss: 0.01378 | Regression loss: 0.12580 | Running loss: 0.33427\n",
      "Epoch: 12 | Iteration: 204 | Classification loss: 0.02554 | Regression loss: 0.12000 | Running loss: 0.33426\n",
      "Epoch: 12 | Iteration: 205 | Classification loss: 0.05309 | Regression loss: 0.18643 | Running loss: 0.33421\n",
      "Epoch: 12 | Iteration: 206 | Classification loss: 0.19173 | Regression loss: 0.41373 | Running loss: 0.33443\n",
      "Epoch: 12 | Iteration: 207 | Classification loss: 0.04643 | Regression loss: 0.18848 | Running loss: 0.33411\n",
      "Epoch: 12 | Iteration: 208 | Classification loss: 0.03895 | Regression loss: 0.25394 | Running loss: 0.33436\n",
      "Epoch: 12 | Iteration: 209 | Classification loss: 0.06112 | Regression loss: 0.19169 | Running loss: 0.33426\n",
      "Epoch: 12 | Iteration: 210 | Classification loss: 0.07400 | Regression loss: 0.33035 | Running loss: 0.33458\n",
      "Epoch: 12 | Iteration: 211 | Classification loss: 0.14984 | Regression loss: 0.39320 | Running loss: 0.33522\n",
      "Epoch: 12 | Iteration: 212 | Classification loss: 0.08134 | Regression loss: 0.17305 | Running loss: 0.33463\n",
      "Epoch: 12 | Iteration: 213 | Classification loss: 0.06577 | Regression loss: 0.22460 | Running loss: 0.33434\n",
      "Epoch: 12 | Iteration: 214 | Classification loss: 0.05455 | Regression loss: 0.16880 | Running loss: 0.33427\n",
      "Epoch: 12 | Iteration: 215 | Classification loss: 0.09498 | Regression loss: 0.29794 | Running loss: 0.33377\n",
      "Epoch: 12 | Iteration: 216 | Classification loss: 0.09323 | Regression loss: 0.21025 | Running loss: 0.33365\n",
      "Epoch: 12 | Iteration: 217 | Classification loss: 0.08066 | Regression loss: 0.30160 | Running loss: 0.33405\n",
      "Epoch: 12 | Iteration: 218 | Classification loss: 0.03361 | Regression loss: 0.30744 | Running loss: 0.33393\n",
      "Epoch: 12 | Iteration: 219 | Classification loss: 0.24049 | Regression loss: 0.24731 | Running loss: 0.33428\n",
      "Epoch: 12 | Iteration: 220 | Classification loss: 0.04276 | Regression loss: 0.19802 | Running loss: 0.33449\n",
      "Epoch: 12 | Iteration: 221 | Classification loss: 0.06518 | Regression loss: 0.16937 | Running loss: 0.33451\n",
      "Epoch: 12 | Iteration: 222 | Classification loss: 0.05084 | Regression loss: 0.30648 | Running loss: 0.33410\n",
      "Epoch: 12 | Iteration: 223 | Classification loss: 0.05806 | Regression loss: 0.15162 | Running loss: 0.33407\n",
      "Epoch: 12 | Iteration: 224 | Classification loss: 0.07944 | Regression loss: 0.20227 | Running loss: 0.33431\n",
      "Epoch: 12 | Iteration: 225 | Classification loss: 0.04674 | Regression loss: 0.27274 | Running loss: 0.33494\n",
      "Epoch: 12 | Iteration: 226 | Classification loss: 0.19105 | Regression loss: 0.32980 | Running loss: 0.33524\n",
      "Epoch: 12 | Iteration: 227 | Classification loss: 0.07781 | Regression loss: 0.19503 | Running loss: 0.33479\n",
      "Epoch: 12 | Iteration: 228 | Classification loss: 0.05044 | Regression loss: 0.17390 | Running loss: 0.33396\n",
      "Epoch: 12 | Iteration: 229 | Classification loss: 0.03907 | Regression loss: 0.19483 | Running loss: 0.33393\n",
      "Epoch: 12 | Iteration: 230 | Classification loss: 0.20408 | Regression loss: 0.17470 | Running loss: 0.33385\n",
      "Epoch: 12 | Iteration: 231 | Classification loss: 0.05756 | Regression loss: 0.14945 | Running loss: 0.33376\n",
      "Epoch: 12 | Iteration: 232 | Classification loss: 0.02281 | Regression loss: 0.24508 | Running loss: 0.33363\n",
      "Epoch: 12 | Iteration: 233 | Classification loss: 0.07315 | Regression loss: 0.35164 | Running loss: 0.33390\n",
      "Epoch: 12 | Iteration: 234 | Classification loss: 0.03176 | Regression loss: 0.25618 | Running loss: 0.33383\n",
      "Epoch: 12 | Iteration: 235 | Classification loss: 0.05564 | Regression loss: 0.24234 | Running loss: 0.33392\n",
      "Epoch: 12 | Iteration: 236 | Classification loss: 0.08176 | Regression loss: 0.17324 | Running loss: 0.33414\n",
      "Epoch: 12 | Iteration: 237 | Classification loss: 0.02739 | Regression loss: 0.17262 | Running loss: 0.33369\n",
      "Epoch: 12 | Iteration: 238 | Classification loss: 0.10557 | Regression loss: 0.36262 | Running loss: 0.33389\n",
      "Epoch: 12 | Iteration: 239 | Classification loss: 0.06245 | Regression loss: 0.27910 | Running loss: 0.33394\n",
      "Epoch: 12 | Iteration: 240 | Classification loss: 0.02926 | Regression loss: 0.13326 | Running loss: 0.33366\n",
      "Epoch: 12 | Iteration: 241 | Classification loss: 0.03749 | Regression loss: 0.18118 | Running loss: 0.33357\n",
      "Epoch: 12 | Iteration: 242 | Classification loss: 0.05413 | Regression loss: 0.15602 | Running loss: 0.33337\n",
      "Epoch: 12 | Iteration: 243 | Classification loss: 0.05474 | Regression loss: 0.21188 | Running loss: 0.33341\n",
      "Epoch: 12 | Iteration: 244 | Classification loss: 0.02820 | Regression loss: 0.27099 | Running loss: 0.33313\n",
      "Epoch: 12 | Iteration: 245 | Classification loss: 0.29768 | Regression loss: 0.20346 | Running loss: 0.33369\n",
      "Epoch: 12 | Iteration: 246 | Classification loss: 0.15294 | Regression loss: 0.47043 | Running loss: 0.33426\n",
      "Epoch: 12 | Iteration: 247 | Classification loss: 0.14895 | Regression loss: 0.36720 | Running loss: 0.33456\n",
      "Epoch: 12 | Iteration: 248 | Classification loss: 0.03738 | Regression loss: 0.28934 | Running loss: 0.33458\n",
      "Epoch: 12 | Iteration: 249 | Classification loss: 0.06562 | Regression loss: 0.38026 | Running loss: 0.33487\n",
      "Epoch: 12 | Iteration: 250 | Classification loss: 0.24514 | Regression loss: 0.39065 | Running loss: 0.33543\n",
      "Epoch: 12 | Iteration: 251 | Classification loss: 0.04210 | Regression loss: 0.14812 | Running loss: 0.33456\n",
      "Epoch: 12 | Iteration: 252 | Classification loss: 0.18441 | Regression loss: 0.20368 | Running loss: 0.33495\n",
      "Epoch: 12 | Iteration: 253 | Classification loss: 0.06615 | Regression loss: 0.22369 | Running loss: 0.33438\n",
      "Epoch: 12 | Iteration: 254 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.33399\n",
      "Epoch: 12 | Iteration: 255 | Classification loss: 0.05896 | Regression loss: 0.14225 | Running loss: 0.33381\n",
      "Epoch: 12 | Iteration: 256 | Classification loss: 0.04669 | Regression loss: 0.11815 | Running loss: 0.33357\n",
      "Epoch: 12 | Iteration: 257 | Classification loss: 0.07972 | Regression loss: 0.21848 | Running loss: 0.33340\n",
      "Epoch: 12 | Iteration: 258 | Classification loss: 0.12904 | Regression loss: 0.10684 | Running loss: 0.33316\n",
      "Epoch: 12 | Iteration: 259 | Classification loss: 0.11663 | Regression loss: 0.28007 | Running loss: 0.33292\n",
      "Epoch: 12 | Iteration: 260 | Classification loss: 0.06789 | Regression loss: 0.12806 | Running loss: 0.33268\n",
      "Epoch: 12 | Iteration: 261 | Classification loss: 0.04965 | Regression loss: 0.26875 | Running loss: 0.33238\n",
      "Epoch: 12 | Iteration: 262 | Classification loss: 0.19054 | Regression loss: 0.26631 | Running loss: 0.33262\n",
      "Epoch: 12 | Iteration: 263 | Classification loss: 0.06896 | Regression loss: 0.14406 | Running loss: 0.33231\n",
      "Epoch: 12 | Iteration: 264 | Classification loss: 0.21614 | Regression loss: 0.30606 | Running loss: 0.33262\n",
      "Epoch: 12 | Iteration: 265 | Classification loss: 0.06217 | Regression loss: 0.14574 | Running loss: 0.33262\n",
      "Epoch: 12 | Iteration: 266 | Classification loss: 0.05349 | Regression loss: 0.11047 | Running loss: 0.33242\n",
      "Epoch: 12 | Iteration: 267 | Classification loss: 0.06062 | Regression loss: 0.33006 | Running loss: 0.33212\n",
      "Epoch: 12 | Iteration: 268 | Classification loss: 0.02705 | Regression loss: 0.13284 | Running loss: 0.33137\n",
      "Epoch: 12 | Iteration: 269 | Classification loss: 0.03101 | Regression loss: 0.17497 | Running loss: 0.33101\n",
      "Epoch: 12 | Iteration: 270 | Classification loss: 0.02506 | Regression loss: 0.14166 | Running loss: 0.33028\n",
      "Epoch: 12 | Iteration: 271 | Classification loss: 0.06410 | Regression loss: 0.15018 | Running loss: 0.33022\n",
      "Epoch: 12 | Iteration: 272 | Classification loss: 0.05224 | Regression loss: 0.10886 | Running loss: 0.33022\n",
      "Epoch: 12 | Iteration: 273 | Classification loss: 0.04117 | Regression loss: 0.13987 | Running loss: 0.32983\n",
      "Epoch: 12 | Iteration: 274 | Classification loss: 0.02348 | Regression loss: 0.14494 | Running loss: 0.32987\n",
      "Epoch: 12 | Iteration: 275 | Classification loss: 0.12658 | Regression loss: 0.32624 | Running loss: 0.32948\n",
      "Epoch: 12 | Iteration: 276 | Classification loss: 0.12316 | Regression loss: 0.26941 | Running loss: 0.32899\n",
      "Epoch: 12 | Iteration: 277 | Classification loss: 0.02148 | Regression loss: 0.13173 | Running loss: 0.32876\n",
      "Epoch: 12 | Iteration: 278 | Classification loss: 0.04661 | Regression loss: 0.18203 | Running loss: 0.32859\n",
      "Epoch: 12 | Iteration: 279 | Classification loss: 0.03593 | Regression loss: 0.18909 | Running loss: 0.32838\n",
      "Epoch: 12 | Iteration: 280 | Classification loss: 0.02569 | Regression loss: 0.19079 | Running loss: 0.32785\n",
      "Epoch: 12 | Iteration: 281 | Classification loss: 0.05346 | Regression loss: 0.24414 | Running loss: 0.32740\n",
      "Epoch: 12 | Iteration: 282 | Classification loss: 0.04266 | Regression loss: 0.22117 | Running loss: 0.32737\n",
      "Epoch: 12 | Iteration: 283 | Classification loss: 0.01738 | Regression loss: 0.13241 | Running loss: 0.32664\n",
      "Epoch: 12 | Iteration: 284 | Classification loss: 0.04276 | Regression loss: 0.15392 | Running loss: 0.32590\n",
      "Epoch: 12 | Iteration: 285 | Classification loss: 0.02136 | Regression loss: 0.15416 | Running loss: 0.32562\n",
      "Epoch: 12 | Iteration: 286 | Classification loss: 0.02623 | Regression loss: 0.08870 | Running loss: 0.32478\n",
      "Epoch: 12 | Iteration: 287 | Classification loss: 0.12649 | Regression loss: 0.21674 | Running loss: 0.32463\n",
      "Epoch: 12 | Iteration: 288 | Classification loss: 0.07235 | Regression loss: 0.18678 | Running loss: 0.32455\n",
      "Epoch: 12 | Iteration: 289 | Classification loss: 0.28671 | Regression loss: 0.14379 | Running loss: 0.32463\n",
      "Epoch: 12 | Iteration: 290 | Classification loss: 0.07425 | Regression loss: 0.40064 | Running loss: 0.32497\n",
      "Epoch: 12 | Iteration: 291 | Classification loss: 0.09162 | Regression loss: 0.31226 | Running loss: 0.32484\n",
      "Epoch: 12 | Iteration: 292 | Classification loss: 0.04252 | Regression loss: 0.12112 | Running loss: 0.32451\n",
      "Epoch: 12 | Iteration: 293 | Classification loss: 0.01428 | Regression loss: 0.13579 | Running loss: 0.32408\n",
      "Epoch: 12 | Iteration: 294 | Classification loss: 0.10987 | Regression loss: 0.30827 | Running loss: 0.32461\n",
      "Epoch: 12 | Iteration: 295 | Classification loss: 0.13290 | Regression loss: 0.32827 | Running loss: 0.32498\n",
      "Epoch: 12 | Iteration: 296 | Classification loss: 0.06131 | Regression loss: 0.11405 | Running loss: 0.32439\n",
      "Epoch: 12 | Iteration: 297 | Classification loss: 0.02552 | Regression loss: 0.15306 | Running loss: 0.32412\n",
      "Epoch: 12 | Iteration: 298 | Classification loss: 0.12735 | Regression loss: 0.32230 | Running loss: 0.32467\n",
      "Epoch: 12 | Iteration: 299 | Classification loss: 0.06719 | Regression loss: 0.18257 | Running loss: 0.32456\n",
      "Epoch: 12 | Iteration: 300 | Classification loss: 0.17494 | Regression loss: 0.25742 | Running loss: 0.32491\n",
      "Epoch: 12 | Iteration: 301 | Classification loss: 0.16596 | Regression loss: 0.19531 | Running loss: 0.32505\n",
      "Epoch: 12 | Iteration: 302 | Classification loss: 0.07756 | Regression loss: 0.21704 | Running loss: 0.32485\n",
      "Epoch: 12 | Iteration: 303 | Classification loss: 0.03912 | Regression loss: 0.22555 | Running loss: 0.32431\n",
      "Epoch: 12 | Iteration: 304 | Classification loss: 0.14380 | Regression loss: 0.38035 | Running loss: 0.32489\n",
      "Epoch: 12 | Iteration: 305 | Classification loss: 0.45555 | Regression loss: 0.38289 | Running loss: 0.32624\n",
      "Epoch: 12 | Iteration: 306 | Classification loss: 0.15706 | Regression loss: 0.23971 | Running loss: 0.32638\n",
      "Epoch: 12 | Iteration: 307 | Classification loss: 0.09608 | Regression loss: 0.34164 | Running loss: 0.32695\n",
      "Epoch: 12 | Iteration: 308 | Classification loss: 0.04040 | Regression loss: 0.24149 | Running loss: 0.32716\n",
      "Epoch: 12 | Iteration: 309 | Classification loss: 0.17493 | Regression loss: 0.26745 | Running loss: 0.32749\n",
      "Epoch: 12 | Iteration: 310 | Classification loss: 0.03289 | Regression loss: 0.17666 | Running loss: 0.32731\n",
      "Epoch: 12 | Iteration: 311 | Classification loss: 0.06926 | Regression loss: 0.27828 | Running loss: 0.32733\n",
      "Epoch: 12 | Iteration: 312 | Classification loss: 0.03285 | Regression loss: 0.16208 | Running loss: 0.32718\n",
      "Epoch: 12 | Iteration: 313 | Classification loss: 0.10930 | Regression loss: 0.21194 | Running loss: 0.32683\n",
      "Epoch: 12 | Iteration: 314 | Classification loss: 0.04075 | Regression loss: 0.12721 | Running loss: 0.32646\n",
      "Epoch: 12 | Iteration: 315 | Classification loss: 0.06458 | Regression loss: 0.16875 | Running loss: 0.32641\n",
      "Epoch: 12 | Iteration: 316 | Classification loss: 0.05493 | Regression loss: 0.13299 | Running loss: 0.32543\n",
      "Epoch: 12 | Iteration: 317 | Classification loss: 0.24260 | Regression loss: 0.20212 | Running loss: 0.32569\n",
      "Epoch: 12 | Iteration: 318 | Classification loss: 0.09563 | Regression loss: 0.17324 | Running loss: 0.32584\n",
      "Epoch: 12 | Iteration: 319 | Classification loss: 0.05549 | Regression loss: 0.26348 | Running loss: 0.32509\n",
      "Epoch: 12 | Iteration: 320 | Classification loss: 0.07644 | Regression loss: 0.32425 | Running loss: 0.32510\n",
      "Epoch: 12 | Iteration: 321 | Classification loss: 0.03810 | Regression loss: 0.13451 | Running loss: 0.32445\n",
      "Epoch: 12 | Iteration: 322 | Classification loss: 0.02160 | Regression loss: 0.08905 | Running loss: 0.32379\n",
      "Epoch: 12 | Iteration: 323 | Classification loss: 0.04287 | Regression loss: 0.27542 | Running loss: 0.32370\n",
      "Epoch: 12 | Iteration: 324 | Classification loss: 0.02332 | Regression loss: 0.08277 | Running loss: 0.32336\n",
      "Epoch: 12 | Iteration: 325 | Classification loss: 0.05649 | Regression loss: 0.18992 | Running loss: 0.32335\n",
      "Epoch: 12 | Iteration: 326 | Classification loss: 0.13731 | Regression loss: 0.23571 | Running loss: 0.32346\n",
      "Epoch: 12 | Iteration: 327 | Classification loss: 0.07279 | Regression loss: 0.22399 | Running loss: 0.32383\n",
      "Epoch: 12 | Iteration: 328 | Classification loss: 0.01888 | Regression loss: 0.10224 | Running loss: 0.32390\n",
      "Epoch: 12 | Iteration: 329 | Classification loss: 0.03527 | Regression loss: 0.20886 | Running loss: 0.32385\n",
      "Epoch: 12 | Iteration: 330 | Classification loss: 0.01982 | Regression loss: 0.26250 | Running loss: 0.32393\n",
      "Epoch: 12 | Iteration: 331 | Classification loss: 0.15704 | Regression loss: 0.34297 | Running loss: 0.32439\n",
      "Epoch: 12 | Iteration: 332 | Classification loss: 0.04718 | Regression loss: 0.19985 | Running loss: 0.32366\n",
      "Epoch: 12 | Iteration: 333 | Classification loss: 0.15295 | Regression loss: 0.34910 | Running loss: 0.32396\n",
      "Epoch: 12 | Iteration: 334 | Classification loss: 0.15368 | Regression loss: 0.18149 | Running loss: 0.32360\n",
      "Epoch: 12 | Iteration: 335 | Classification loss: 0.03940 | Regression loss: 0.08390 | Running loss: 0.32291\n",
      "Epoch: 12 | Iteration: 336 | Classification loss: 0.03656 | Regression loss: 0.18940 | Running loss: 0.32254\n",
      "Epoch: 12 | Iteration: 337 | Classification loss: 0.06770 | Regression loss: 0.15755 | Running loss: 0.32236\n",
      "Epoch: 12 | Iteration: 338 | Classification loss: 0.04170 | Regression loss: 0.13567 | Running loss: 0.32210\n",
      "Epoch: 12 | Iteration: 339 | Classification loss: 0.06370 | Regression loss: 0.18156 | Running loss: 0.32148\n",
      "Epoch: 12 | Iteration: 340 | Classification loss: 0.03337 | Regression loss: 0.17725 | Running loss: 0.32149\n",
      "Epoch: 12 | Iteration: 341 | Classification loss: 0.11113 | Regression loss: 0.29755 | Running loss: 0.32123\n",
      "Epoch: 12 | Iteration: 342 | Classification loss: 0.24648 | Regression loss: 0.49871 | Running loss: 0.32227\n",
      "Epoch: 12 | Iteration: 343 | Classification loss: 0.11947 | Regression loss: 0.29422 | Running loss: 0.32206\n",
      "Epoch: 12 | Iteration: 344 | Classification loss: 0.09454 | Regression loss: 0.29221 | Running loss: 0.32257\n",
      "Epoch: 12 | Iteration: 345 | Classification loss: 0.04209 | Regression loss: 0.21586 | Running loss: 0.32248\n",
      "Epoch: 12 | Iteration: 346 | Classification loss: 0.06750 | Regression loss: 0.23579 | Running loss: 0.32258\n",
      "Epoch: 12 | Iteration: 347 | Classification loss: 0.16183 | Regression loss: 0.40768 | Running loss: 0.32226\n",
      "Epoch: 12 | Iteration: 348 | Classification loss: 0.37938 | Regression loss: 0.40050 | Running loss: 0.32332\n",
      "Epoch: 12 | Iteration: 349 | Classification loss: 0.12896 | Regression loss: 0.19587 | Running loss: 0.32316\n",
      "Epoch: 12 | Iteration: 350 | Classification loss: 0.17874 | Regression loss: 0.19566 | Running loss: 0.32346\n",
      "Epoch: 12 | Iteration: 351 | Classification loss: 0.05014 | Regression loss: 0.23700 | Running loss: 0.32280\n",
      "Epoch: 12 | Iteration: 352 | Classification loss: 0.15318 | Regression loss: 0.44529 | Running loss: 0.32370\n",
      "Epoch: 12 | Iteration: 353 | Classification loss: 0.06846 | Regression loss: 0.13320 | Running loss: 0.32333\n",
      "Epoch: 12 | Iteration: 354 | Classification loss: 0.09381 | Regression loss: 0.16788 | Running loss: 0.32329\n",
      "Epoch: 12 | Iteration: 355 | Classification loss: 0.06954 | Regression loss: 0.17105 | Running loss: 0.32253\n",
      "Epoch: 12 | Iteration: 356 | Classification loss: 0.07234 | Regression loss: 0.17391 | Running loss: 0.32148\n",
      "Epoch: 12 | Iteration: 357 | Classification loss: 0.05586 | Regression loss: 0.14983 | Running loss: 0.32058\n",
      "Epoch: 12 | Iteration: 358 | Classification loss: 0.19627 | Regression loss: 0.42463 | Running loss: 0.32126\n",
      "Epoch: 12 | Iteration: 359 | Classification loss: 0.08622 | Regression loss: 0.15626 | Running loss: 0.32131\n",
      "Epoch: 12 | Iteration: 360 | Classification loss: 0.15647 | Regression loss: 0.43226 | Running loss: 0.32145\n",
      "Epoch: 12 | Iteration: 361 | Classification loss: 0.05937 | Regression loss: 0.16994 | Running loss: 0.32059\n",
      "Epoch: 12 | Iteration: 362 | Classification loss: 0.03840 | Regression loss: 0.16269 | Running loss: 0.32034\n",
      "Epoch: 12 | Iteration: 363 | Classification loss: 0.04967 | Regression loss: 0.14923 | Running loss: 0.32030\n",
      "Epoch: 12 | Iteration: 364 | Classification loss: 0.08324 | Regression loss: 0.24007 | Running loss: 0.32000\n",
      "Epoch: 12 | Iteration: 365 | Classification loss: 0.25688 | Regression loss: 0.54271 | Running loss: 0.32097\n",
      "Epoch: 12 | Iteration: 366 | Classification loss: 0.03615 | Regression loss: 0.14130 | Running loss: 0.32051\n",
      "Epoch: 12 | Iteration: 367 | Classification loss: 0.05915 | Regression loss: 0.24241 | Running loss: 0.32069\n",
      "Epoch: 12 | Iteration: 368 | Classification loss: 0.08058 | Regression loss: 0.22096 | Running loss: 0.32077\n",
      "Epoch: 12 | Iteration: 369 | Classification loss: 0.12284 | Regression loss: 0.43331 | Running loss: 0.32142\n",
      "Epoch: 12 | Iteration: 370 | Classification loss: 0.03020 | Regression loss: 0.15941 | Running loss: 0.32134\n",
      "Epoch: 12 | Iteration: 371 | Classification loss: 0.12381 | Regression loss: 0.45706 | Running loss: 0.32183\n",
      "Epoch: 12 | Iteration: 372 | Classification loss: 0.01791 | Regression loss: 0.11215 | Running loss: 0.32121\n",
      "Epoch: 12 | Iteration: 373 | Classification loss: 0.04151 | Regression loss: 0.22715 | Running loss: 0.32125\n",
      "Epoch: 12 | Iteration: 374 | Classification loss: 0.06372 | Regression loss: 0.25075 | Running loss: 0.32135\n",
      "Epoch: 12 | Iteration: 375 | Classification loss: 0.23258 | Regression loss: 0.22408 | Running loss: 0.32160\n",
      "Epoch: 12 | Iteration: 376 | Classification loss: 0.01480 | Regression loss: 0.09696 | Running loss: 0.32117\n",
      "Epoch: 12 | Iteration: 377 | Classification loss: 0.06857 | Regression loss: 0.25818 | Running loss: 0.32134\n",
      "Epoch: 12 | Iteration: 378 | Classification loss: 0.13322 | Regression loss: 0.29534 | Running loss: 0.32155\n",
      "Epoch: 12 | Iteration: 379 | Classification loss: 0.04720 | Regression loss: 0.25514 | Running loss: 0.32145\n",
      "Epoch: 12 | Iteration: 380 | Classification loss: 0.01757 | Regression loss: 0.14187 | Running loss: 0.32147\n",
      "Epoch: 12 | Iteration: 381 | Classification loss: 0.22063 | Regression loss: 0.09760 | Running loss: 0.32123\n",
      "Epoch: 12 | Iteration: 382 | Classification loss: 0.16971 | Regression loss: 0.35540 | Running loss: 0.32171\n",
      "Epoch: 12 | Iteration: 383 | Classification loss: 0.11341 | Regression loss: 0.28899 | Running loss: 0.32166\n",
      "Epoch: 12 | Iteration: 384 | Classification loss: 0.10595 | Regression loss: 0.37413 | Running loss: 0.32180\n",
      "Epoch: 12 | Iteration: 385 | Classification loss: 0.18527 | Regression loss: 0.39151 | Running loss: 0.32201\n",
      "Epoch: 12 | Iteration: 386 | Classification loss: 0.11640 | Regression loss: 0.40949 | Running loss: 0.32251\n",
      "Epoch: 12 | Iteration: 387 | Classification loss: 0.02430 | Regression loss: 0.15896 | Running loss: 0.32231\n",
      "Epoch: 12 | Iteration: 388 | Classification loss: 0.04862 | Regression loss: 0.24949 | Running loss: 0.32152\n",
      "Epoch: 12 | Iteration: 389 | Classification loss: 0.03734 | Regression loss: 0.16240 | Running loss: 0.32146\n",
      "Epoch: 12 | Iteration: 390 | Classification loss: 0.01112 | Regression loss: 0.05658 | Running loss: 0.32112\n",
      "Epoch: 12 | Iteration: 391 | Classification loss: 0.36091 | Regression loss: 0.06736 | Running loss: 0.32146\n",
      "Epoch: 12 | Iteration: 392 | Classification loss: 0.03234 | Regression loss: 0.06437 | Running loss: 0.32055\n",
      "Epoch: 12 | Iteration: 393 | Classification loss: 0.08428 | Regression loss: 0.24043 | Running loss: 0.32044\n",
      "Epoch: 12 | Iteration: 394 | Classification loss: 0.08738 | Regression loss: 0.27775 | Running loss: 0.32088\n",
      "Epoch: 12 | Iteration: 395 | Classification loss: 0.09390 | Regression loss: 0.33726 | Running loss: 0.32124\n",
      "Epoch: 12 | Iteration: 396 | Classification loss: 0.09518 | Regression loss: 0.31260 | Running loss: 0.32083\n",
      "Epoch: 12 | Iteration: 397 | Classification loss: 0.14369 | Regression loss: 0.20868 | Running loss: 0.32053\n",
      "Epoch: 12 | Iteration: 398 | Classification loss: 0.24736 | Regression loss: 0.21342 | Running loss: 0.32056\n",
      "Epoch: 12 | Iteration: 399 | Classification loss: 0.08031 | Regression loss: 0.26602 | Running loss: 0.32079\n",
      "Epoch: 12 | Iteration: 400 | Classification loss: 0.11690 | Regression loss: 0.37329 | Running loss: 0.32118\n",
      "Epoch: 12 | Iteration: 401 | Classification loss: 0.05983 | Regression loss: 0.12946 | Running loss: 0.32077\n",
      "Epoch: 12 | Iteration: 402 | Classification loss: 0.10970 | Regression loss: 0.47293 | Running loss: 0.32148\n",
      "Epoch: 12 | Iteration: 403 | Classification loss: 0.29267 | Regression loss: 0.40815 | Running loss: 0.32227\n",
      "Epoch: 12 | Iteration: 404 | Classification loss: 0.08788 | Regression loss: 0.18075 | Running loss: 0.32206\n",
      "Epoch: 12 | Iteration: 405 | Classification loss: 0.22462 | Regression loss: 0.28773 | Running loss: 0.32253\n",
      "Epoch: 12 | Iteration: 406 | Classification loss: 0.06432 | Regression loss: 0.23317 | Running loss: 0.32178\n",
      "Epoch: 12 | Iteration: 407 | Classification loss: 0.12651 | Regression loss: 0.28516 | Running loss: 0.32216\n",
      "Epoch: 12 | Iteration: 408 | Classification loss: 0.04183 | Regression loss: 0.21193 | Running loss: 0.32226\n",
      "Epoch: 12 | Iteration: 409 | Classification loss: 0.01401 | Regression loss: 0.10879 | Running loss: 0.32165\n",
      "Epoch: 12 | Iteration: 410 | Classification loss: 0.22080 | Regression loss: 0.37822 | Running loss: 0.32239\n",
      "Epoch: 12 | Iteration: 411 | Classification loss: 0.04364 | Regression loss: 0.19941 | Running loss: 0.32237\n",
      "Epoch: 12 | Iteration: 412 | Classification loss: 0.10805 | Regression loss: 0.35860 | Running loss: 0.32183\n",
      "Epoch: 12 | Iteration: 413 | Classification loss: 0.13577 | Regression loss: 0.33892 | Running loss: 0.32189\n",
      "Epoch: 12 | Iteration: 414 | Classification loss: 0.14622 | Regression loss: 0.16177 | Running loss: 0.32182\n",
      "Epoch: 12 | Iteration: 415 | Classification loss: 0.03882 | Regression loss: 0.17061 | Running loss: 0.32063\n",
      "Epoch: 12 | Iteration: 416 | Classification loss: 0.17134 | Regression loss: 0.34023 | Running loss: 0.32115\n",
      "Epoch: 12 | Iteration: 417 | Classification loss: 0.06956 | Regression loss: 0.15843 | Running loss: 0.32114\n",
      "Epoch: 12 | Iteration: 418 | Classification loss: 0.06190 | Regression loss: 0.24079 | Running loss: 0.32133\n",
      "Epoch: 12 | Iteration: 419 | Classification loss: 0.05531 | Regression loss: 0.17970 | Running loss: 0.32118\n",
      "Epoch: 12 | Iteration: 420 | Classification loss: 0.07980 | Regression loss: 0.16374 | Running loss: 0.32124\n",
      "Epoch: 12 | Iteration: 421 | Classification loss: 0.03666 | Regression loss: 0.18508 | Running loss: 0.32084\n",
      "Epoch: 12 | Iteration: 422 | Classification loss: 0.05118 | Regression loss: 0.25470 | Running loss: 0.32108\n",
      "Epoch: 12 | Iteration: 423 | Classification loss: 0.36155 | Regression loss: 0.30539 | Running loss: 0.32130\n",
      "Epoch: 12 | Iteration: 424 | Classification loss: 0.11403 | Regression loss: 0.24006 | Running loss: 0.32127\n",
      "Epoch: 12 | Iteration: 425 | Classification loss: 0.11115 | Regression loss: 0.30206 | Running loss: 0.32107\n",
      "Epoch: 12 | Iteration: 426 | Classification loss: 0.05005 | Regression loss: 0.24913 | Running loss: 0.32089\n",
      "Epoch: 12 | Iteration: 427 | Classification loss: 0.16338 | Regression loss: 0.18317 | Running loss: 0.32134\n",
      "Epoch: 12 | Iteration: 428 | Classification loss: 0.03787 | Regression loss: 0.15023 | Running loss: 0.32095\n",
      "Epoch: 12 | Iteration: 429 | Classification loss: 0.13491 | Regression loss: 0.22161 | Running loss: 0.32115\n",
      "Epoch: 12 | Iteration: 430 | Classification loss: 0.26264 | Regression loss: 0.09448 | Running loss: 0.32128\n",
      "Epoch: 12 | Iteration: 431 | Classification loss: 0.10810 | Regression loss: 0.14999 | Running loss: 0.32135\n",
      "Epoch: 12 | Iteration: 432 | Classification loss: 0.12098 | Regression loss: 0.31684 | Running loss: 0.32176\n",
      "Epoch: 12 | Iteration: 433 | Classification loss: 0.02622 | Regression loss: 0.17375 | Running loss: 0.32105\n",
      "Epoch: 12 | Iteration: 434 | Classification loss: 0.12264 | Regression loss: 0.23579 | Running loss: 0.32139\n",
      "Epoch: 12 | Iteration: 435 | Classification loss: 0.01932 | Regression loss: 0.19809 | Running loss: 0.32160\n",
      "Epoch: 12 | Iteration: 436 | Classification loss: 0.03773 | Regression loss: 0.16682 | Running loss: 0.32143\n",
      "Epoch: 12 | Iteration: 437 | Classification loss: 0.12075 | Regression loss: 0.27391 | Running loss: 0.32177\n",
      "Epoch: 12 | Iteration: 438 | Classification loss: 0.04879 | Regression loss: 0.19543 | Running loss: 0.32173\n",
      "Epoch: 12 | Iteration: 439 | Classification loss: 0.02921 | Regression loss: 0.22524 | Running loss: 0.32146\n",
      "Epoch: 12 | Iteration: 440 | Classification loss: 0.08040 | Regression loss: 0.10740 | Running loss: 0.32138\n",
      "Epoch: 12 | Iteration: 441 | Classification loss: 0.07125 | Regression loss: 0.12779 | Running loss: 0.32113\n",
      "Epoch: 12 | Iteration: 442 | Classification loss: 0.22505 | Regression loss: 0.47016 | Running loss: 0.32213\n",
      "Epoch: 12 | Iteration: 443 | Classification loss: 0.04500 | Regression loss: 0.05198 | Running loss: 0.32161\n",
      "Epoch: 12 | Iteration: 444 | Classification loss: 0.05363 | Regression loss: 0.22532 | Running loss: 0.32161\n",
      "Epoch: 12 | Iteration: 445 | Classification loss: 0.15143 | Regression loss: 0.37899 | Running loss: 0.32135\n",
      "Epoch: 12 | Iteration: 446 | Classification loss: 0.05304 | Regression loss: 0.20960 | Running loss: 0.32139\n",
      "Epoch: 12 | Iteration: 447 | Classification loss: 0.11593 | Regression loss: 0.36946 | Running loss: 0.32197\n",
      "Epoch: 12 | Iteration: 448 | Classification loss: 0.09261 | Regression loss: 0.27344 | Running loss: 0.32235\n",
      "Epoch: 12 | Iteration: 449 | Classification loss: 0.15112 | Regression loss: 0.22869 | Running loss: 0.32234\n",
      "Epoch: 12 | Iteration: 450 | Classification loss: 0.06730 | Regression loss: 0.21702 | Running loss: 0.32245\n",
      "Epoch: 12 | Iteration: 451 | Classification loss: 0.08807 | Regression loss: 0.38657 | Running loss: 0.32290\n",
      "Epoch: 12 | Iteration: 452 | Classification loss: 0.32610 | Regression loss: 0.39966 | Running loss: 0.32370\n",
      "Epoch: 12 | Iteration: 453 | Classification loss: 0.04550 | Regression loss: 0.10484 | Running loss: 0.32367\n",
      "Epoch: 12 | Iteration: 454 | Classification loss: 0.02777 | Regression loss: 0.30083 | Running loss: 0.32375\n",
      "Epoch: 12 | Iteration: 455 | Classification loss: 0.13077 | Regression loss: 0.38833 | Running loss: 0.32396\n",
      "Epoch: 12 | Iteration: 456 | Classification loss: 0.03268 | Regression loss: 0.08654 | Running loss: 0.32311\n",
      "Epoch: 12 | Iteration: 457 | Classification loss: 0.11257 | Regression loss: 0.21076 | Running loss: 0.32354\n",
      "Epoch: 12 | Iteration: 458 | Classification loss: 0.28931 | Regression loss: 0.39894 | Running loss: 0.32391\n",
      "Epoch: 12 | Iteration: 459 | Classification loss: 0.05196 | Regression loss: 0.24098 | Running loss: 0.32380\n",
      "Epoch: 12 | Iteration: 460 | Classification loss: 0.05330 | Regression loss: 0.44347 | Running loss: 0.32428\n",
      "Epoch: 12 | Iteration: 461 | Classification loss: 0.05019 | Regression loss: 0.21777 | Running loss: 0.32344\n",
      "Epoch: 12 | Iteration: 462 | Classification loss: 0.21557 | Regression loss: 0.33280 | Running loss: 0.32355\n",
      "Epoch: 12 | Iteration: 463 | Classification loss: 0.13521 | Regression loss: 0.24608 | Running loss: 0.32393\n",
      "Epoch: 12 | Iteration: 464 | Classification loss: 0.34443 | Regression loss: 0.25229 | Running loss: 0.32414\n",
      "Epoch: 12 | Iteration: 465 | Classification loss: 0.03563 | Regression loss: 0.30066 | Running loss: 0.32406\n",
      "Epoch: 12 | Iteration: 466 | Classification loss: 0.09750 | Regression loss: 0.41449 | Running loss: 0.32465\n",
      "Epoch: 12 | Iteration: 467 | Classification loss: 0.07610 | Regression loss: 0.37247 | Running loss: 0.32520\n",
      "Epoch: 12 | Iteration: 468 | Classification loss: 0.05137 | Regression loss: 0.26020 | Running loss: 0.32530\n",
      "Epoch: 12 | Iteration: 469 | Classification loss: 0.02970 | Regression loss: 0.15579 | Running loss: 0.32490\n",
      "Epoch: 12 | Iteration: 470 | Classification loss: 0.03862 | Regression loss: 0.15074 | Running loss: 0.32479\n",
      "Epoch: 12 | Iteration: 471 | Classification loss: 0.14697 | Regression loss: 0.25253 | Running loss: 0.32471\n",
      "Epoch: 12 | Iteration: 472 | Classification loss: 0.07897 | Regression loss: 0.28035 | Running loss: 0.32452\n",
      "Epoch: 12 | Iteration: 473 | Classification loss: 0.12190 | Regression loss: 0.24594 | Running loss: 0.32490\n",
      "Epoch: 12 | Iteration: 474 | Classification loss: 0.04339 | Regression loss: 0.13675 | Running loss: 0.32443\n",
      "Epoch: 12 | Iteration: 475 | Classification loss: 0.16472 | Regression loss: 0.24783 | Running loss: 0.32389\n",
      "Epoch: 12 | Iteration: 476 | Classification loss: 0.08748 | Regression loss: 0.18046 | Running loss: 0.32390\n",
      "Epoch: 12 | Iteration: 477 | Classification loss: 0.20542 | Regression loss: 0.29891 | Running loss: 0.32435\n",
      "Epoch: 12 | Iteration: 478 | Classification loss: 0.09817 | Regression loss: 0.17255 | Running loss: 0.32443\n",
      "Epoch: 12 | Iteration: 479 | Classification loss: 0.03881 | Regression loss: 0.17761 | Running loss: 0.32444\n",
      "Epoch: 12 | Iteration: 480 | Classification loss: 0.04646 | Regression loss: 0.30791 | Running loss: 0.32452\n",
      "Epoch: 12 | Iteration: 481 | Classification loss: 0.04935 | Regression loss: 0.23914 | Running loss: 0.32440\n",
      "Epoch: 12 | Iteration: 482 | Classification loss: 0.07498 | Regression loss: 0.22595 | Running loss: 0.32458\n",
      "Epoch: 12 | Iteration: 483 | Classification loss: 0.11281 | Regression loss: 0.28994 | Running loss: 0.32451\n",
      "Epoch: 12 | Iteration: 484 | Classification loss: 0.07299 | Regression loss: 0.24784 | Running loss: 0.32466\n",
      "Epoch: 12 | Iteration: 485 | Classification loss: 0.08475 | Regression loss: 0.30415 | Running loss: 0.32476\n",
      "Epoch: 12 | Iteration: 486 | Classification loss: 0.06633 | Regression loss: 0.16382 | Running loss: 0.32456\n",
      "Epoch: 12 | Iteration: 487 | Classification loss: 0.44099 | Regression loss: 0.16071 | Running loss: 0.32520\n",
      "Epoch: 12 | Iteration: 488 | Classification loss: 0.32334 | Regression loss: 0.19285 | Running loss: 0.32496\n",
      "Epoch: 12 | Iteration: 489 | Classification loss: 0.30237 | Regression loss: 0.61658 | Running loss: 0.32650\n",
      "Epoch: 12 | Iteration: 490 | Classification loss: 0.04220 | Regression loss: 0.23381 | Running loss: 0.32597\n",
      "Epoch: 12 | Iteration: 491 | Classification loss: 0.05239 | Regression loss: 0.22285 | Running loss: 0.32567\n",
      "Epoch: 12 | Iteration: 492 | Classification loss: 0.09511 | Regression loss: 0.19772 | Running loss: 0.32556\n",
      "Epoch: 12 | Iteration: 493 | Classification loss: 0.02510 | Regression loss: 0.07590 | Running loss: 0.32458\n",
      "Epoch: 12 | Iteration: 494 | Classification loss: 0.30560 | Regression loss: 0.15969 | Running loss: 0.32465\n",
      "Epoch: 12 | Iteration: 495 | Classification loss: 0.04635 | Regression loss: 0.12692 | Running loss: 0.32408\n",
      "Epoch: 12 | Iteration: 496 | Classification loss: 0.10715 | Regression loss: 0.19100 | Running loss: 0.32373\n",
      "Epoch: 12 | Iteration: 497 | Classification loss: 0.05862 | Regression loss: 0.18147 | Running loss: 0.32366\n",
      "Epoch: 12 | Iteration: 498 | Classification loss: 0.04270 | Regression loss: 0.24048 | Running loss: 0.32359\n",
      "Epoch: 12 | Iteration: 499 | Classification loss: 0.02199 | Regression loss: 0.13649 | Running loss: 0.32352\n",
      "Epoch: 12 | Iteration: 500 | Classification loss: 0.03814 | Regression loss: 0.18915 | Running loss: 0.32360\n",
      "Epoch: 12 | Iteration: 501 | Classification loss: 0.08016 | Regression loss: 0.28758 | Running loss: 0.32389\n",
      "Epoch: 12 | Iteration: 502 | Classification loss: 0.04228 | Regression loss: 0.21194 | Running loss: 0.32377\n",
      "Epoch: 12 | Iteration: 503 | Classification loss: 0.13310 | Regression loss: 0.26008 | Running loss: 0.32353\n",
      "Epoch: 12 | Iteration: 504 | Classification loss: 0.26377 | Regression loss: 0.19604 | Running loss: 0.32410\n",
      "Epoch: 12 | Iteration: 505 | Classification loss: 0.25840 | Regression loss: 0.63988 | Running loss: 0.32538\n",
      "Epoch: 12 | Iteration: 506 | Classification loss: 0.13768 | Regression loss: 0.24773 | Running loss: 0.32544\n",
      "Epoch: 12 | Iteration: 507 | Classification loss: 0.03208 | Regression loss: 0.27626 | Running loss: 0.32562\n",
      "Epoch: 12 | Iteration: 508 | Classification loss: 0.14697 | Regression loss: 0.39686 | Running loss: 0.32590\n",
      "Epoch: 12 | Iteration: 509 | Classification loss: 0.07207 | Regression loss: 0.24743 | Running loss: 0.32567\n",
      "Epoch: 12 | Iteration: 510 | Classification loss: 0.07173 | Regression loss: 0.21953 | Running loss: 0.32527\n",
      "Epoch: 12 | Iteration: 511 | Classification loss: 0.09069 | Regression loss: 0.31962 | Running loss: 0.32574\n",
      "Epoch: 12 | Iteration: 512 | Classification loss: 0.09086 | Regression loss: 0.19262 | Running loss: 0.32592\n",
      "Epoch: 12 | Iteration: 513 | Classification loss: 0.04035 | Regression loss: 0.12813 | Running loss: 0.32456\n",
      "Epoch: 12 | Iteration: 514 | Classification loss: 0.05730 | Regression loss: 0.19652 | Running loss: 0.32446\n",
      "Epoch: 12 | Iteration: 515 | Classification loss: 0.14144 | Regression loss: 0.28704 | Running loss: 0.32508\n",
      "Epoch: 12 | Iteration: 516 | Classification loss: 0.04993 | Regression loss: 0.13419 | Running loss: 0.32476\n",
      "Epoch: 12 | Iteration: 517 | Classification loss: 0.09746 | Regression loss: 0.29475 | Running loss: 0.32500\n",
      "Epoch: 12 | Iteration: 518 | Classification loss: 0.08631 | Regression loss: 0.16601 | Running loss: 0.32483\n",
      "Epoch: 12 | Iteration: 519 | Classification loss: 0.19935 | Regression loss: 0.17963 | Running loss: 0.32468\n",
      "Epoch: 12 | Iteration: 520 | Classification loss: 0.12125 | Regression loss: 0.30991 | Running loss: 0.32502\n",
      "Epoch: 12 | Iteration: 521 | Classification loss: 0.27467 | Regression loss: 0.20212 | Running loss: 0.32567\n",
      "Epoch: 12 | Iteration: 522 | Classification loss: 0.06654 | Regression loss: 0.24930 | Running loss: 0.32577\n",
      "Epoch: 12 | Iteration: 523 | Classification loss: 0.15254 | Regression loss: 0.21322 | Running loss: 0.32567\n",
      "Epoch: 12 | Iteration: 524 | Classification loss: 0.15412 | Regression loss: 0.32746 | Running loss: 0.32568\n",
      "Epoch: 12 | Iteration: 525 | Classification loss: 0.06936 | Regression loss: 0.38267 | Running loss: 0.32613\n",
      "Epoch: 12 | Iteration: 526 | Classification loss: 0.06366 | Regression loss: 0.34259 | Running loss: 0.32612\n",
      "Epoch: 12 | Iteration: 527 | Classification loss: 0.12212 | Regression loss: 0.12976 | Running loss: 0.32615\n",
      "Epoch: 12 | Iteration: 528 | Classification loss: 0.23294 | Regression loss: 0.16781 | Running loss: 0.32553\n",
      "Epoch: 12 | Iteration: 529 | Classification loss: 0.17506 | Regression loss: 0.32714 | Running loss: 0.32513\n",
      "Epoch: 12 | Iteration: 530 | Classification loss: 0.05358 | Regression loss: 0.21181 | Running loss: 0.32518\n",
      "Epoch: 12 | Iteration: 531 | Classification loss: 0.34842 | Regression loss: 0.39676 | Running loss: 0.32588\n",
      "Epoch: 12 | Iteration: 532 | Classification loss: 0.08165 | Regression loss: 0.15715 | Running loss: 0.32545\n",
      "Epoch: 12 | Iteration: 533 | Classification loss: 0.14008 | Regression loss: 0.32709 | Running loss: 0.32583\n",
      "Epoch: 12 | Iteration: 534 | Classification loss: 0.09189 | Regression loss: 0.37453 | Running loss: 0.32633\n",
      "Epoch: 12 | Iteration: 535 | Classification loss: 0.10320 | Regression loss: 0.56891 | Running loss: 0.32708\n",
      "Epoch: 12 | Iteration: 536 | Classification loss: 0.11616 | Regression loss: 0.30762 | Running loss: 0.32767\n",
      "Epoch: 12 | Iteration: 537 | Classification loss: 0.11428 | Regression loss: 0.47842 | Running loss: 0.32800\n",
      "Epoch: 12 | Iteration: 538 | Classification loss: 0.07847 | Regression loss: 0.06507 | Running loss: 0.32729\n",
      "Epoch: 12 | Iteration: 539 | Classification loss: 0.09448 | Regression loss: 0.17705 | Running loss: 0.32727\n",
      "Epoch: 12 | Iteration: 540 | Classification loss: 0.16701 | Regression loss: 0.32932 | Running loss: 0.32734\n",
      "Epoch: 12 | Iteration: 541 | Classification loss: 0.02530 | Regression loss: 0.11463 | Running loss: 0.32724\n",
      "Epoch: 12 | Iteration: 542 | Classification loss: 0.05262 | Regression loss: 0.12943 | Running loss: 0.32650\n",
      "Epoch: 12 | Iteration: 543 | Classification loss: 0.09796 | Regression loss: 0.22521 | Running loss: 0.32645\n",
      "Epoch: 12 | Iteration: 544 | Classification loss: 0.08995 | Regression loss: 0.32266 | Running loss: 0.32680\n",
      "Epoch: 12 | Iteration: 545 | Classification loss: 0.03243 | Regression loss: 0.07747 | Running loss: 0.32657\n",
      "Epoch: 12 | Iteration: 546 | Classification loss: 0.40603 | Regression loss: 0.82233 | Running loss: 0.32828\n",
      "Epoch: 12 | Iteration: 547 | Classification loss: 0.02368 | Regression loss: 0.05965 | Running loss: 0.32807\n",
      "Epoch: 12 | Iteration: 548 | Classification loss: 0.11771 | Regression loss: 0.21065 | Running loss: 0.32703\n",
      "Epoch: 12 | Iteration: 549 | Classification loss: 0.05408 | Regression loss: 0.15717 | Running loss: 0.32655\n",
      "Epoch: 12 | Iteration: 550 | Classification loss: 0.04866 | Regression loss: 0.17386 | Running loss: 0.32664\n",
      "Epoch: 12 | Iteration: 551 | Classification loss: 0.06351 | Regression loss: 0.26228 | Running loss: 0.32670\n",
      "Epoch: 12 | Iteration: 552 | Classification loss: 0.04075 | Regression loss: 0.23564 | Running loss: 0.32613\n",
      "Epoch: 12 | Iteration: 553 | Classification loss: 0.07642 | Regression loss: 0.20347 | Running loss: 0.32594\n",
      "Epoch: 12 | Iteration: 554 | Classification loss: 0.08086 | Regression loss: 0.20380 | Running loss: 0.32615\n",
      "Epoch: 12 | Iteration: 555 | Classification loss: 0.04474 | Regression loss: 0.11488 | Running loss: 0.32582\n",
      "Epoch: 12 | Iteration: 556 | Classification loss: 0.23837 | Regression loss: 0.49473 | Running loss: 0.32699\n",
      "Epoch: 12 | Iteration: 557 | Classification loss: 0.04543 | Regression loss: 0.16992 | Running loss: 0.32707\n",
      "Epoch: 12 | Iteration: 558 | Classification loss: 0.10402 | Regression loss: 0.19577 | Running loss: 0.32608\n",
      "Epoch: 12 | Iteration: 559 | Classification loss: 0.07123 | Regression loss: 0.26105 | Running loss: 0.32642\n",
      "Epoch: 12 | Iteration: 560 | Classification loss: 0.10410 | Regression loss: 0.33241 | Running loss: 0.32689\n",
      "Epoch: 12 | Iteration: 561 | Classification loss: 0.05449 | Regression loss: 0.19970 | Running loss: 0.32707\n",
      "Epoch: 12 | Iteration: 562 | Classification loss: 0.09967 | Regression loss: 0.28452 | Running loss: 0.32722\n",
      "Epoch: 12 | Iteration: 563 | Classification loss: 0.04710 | Regression loss: 0.16518 | Running loss: 0.32709\n",
      "Epoch: 12 | Iteration: 564 | Classification loss: 0.04570 | Regression loss: 0.24792 | Running loss: 0.32675\n",
      "Epoch: 12 | Iteration: 565 | Classification loss: 0.03044 | Regression loss: 0.18514 | Running loss: 0.32649\n",
      "Epoch: 12 | Iteration: 566 | Classification loss: 0.10835 | Regression loss: 0.37880 | Running loss: 0.32654\n",
      "Epoch: 12 | Iteration: 567 | Classification loss: 0.08529 | Regression loss: 0.14950 | Running loss: 0.32662\n",
      "Epoch: 12 | Iteration: 568 | Classification loss: 0.20174 | Regression loss: 0.23915 | Running loss: 0.32671\n",
      "Epoch: 12 | Iteration: 569 | Classification loss: 0.07459 | Regression loss: 0.12151 | Running loss: 0.32591\n",
      "Epoch: 12 | Iteration: 570 | Classification loss: 0.15581 | Regression loss: 0.28419 | Running loss: 0.32605\n",
      "Epoch: 12 | Iteration: 571 | Classification loss: 0.03922 | Regression loss: 0.22826 | Running loss: 0.32590\n",
      "Epoch: 12 | Iteration: 572 | Classification loss: 0.05973 | Regression loss: 0.19073 | Running loss: 0.32610\n",
      "Epoch: 12 | Iteration: 573 | Classification loss: 0.34971 | Regression loss: 0.71144 | Running loss: 0.32770\n",
      "Epoch: 12 | Iteration: 574 | Classification loss: 0.31288 | Regression loss: 0.26553 | Running loss: 0.32831\n",
      "Epoch: 12 | Iteration: 575 | Classification loss: 0.24002 | Regression loss: 0.37051 | Running loss: 0.32890\n",
      "Epoch: 12 | Iteration: 576 | Classification loss: 0.10657 | Regression loss: 0.39305 | Running loss: 0.32932\n",
      "Epoch: 12 | Iteration: 577 | Classification loss: 0.49973 | Regression loss: 0.04659 | Running loss: 0.32971\n",
      "Epoch: 12 | Iteration: 578 | Classification loss: 0.12729 | Regression loss: 0.25645 | Running loss: 0.32966\n",
      "Epoch: 12 | Iteration: 579 | Classification loss: 0.09199 | Regression loss: 0.11104 | Running loss: 0.32941\n",
      "Epoch: 12 | Iteration: 580 | Classification loss: 0.03727 | Regression loss: 0.23095 | Running loss: 0.32939\n",
      "Epoch: 12 | Iteration: 581 | Classification loss: 0.03689 | Regression loss: 0.09783 | Running loss: 0.32890\n",
      "Epoch: 12 | Iteration: 582 | Classification loss: 0.04035 | Regression loss: 0.23130 | Running loss: 0.32870\n",
      "Epoch: 12 | Iteration: 583 | Classification loss: 0.22334 | Regression loss: 0.42340 | Running loss: 0.32917\n",
      "Epoch: 12 | Iteration: 584 | Classification loss: 0.07728 | Regression loss: 0.24223 | Running loss: 0.32888\n",
      "Epoch: 12 | Iteration: 585 | Classification loss: 0.04332 | Regression loss: 0.16207 | Running loss: 0.32819\n",
      "Epoch: 12 | Iteration: 586 | Classification loss: 0.28423 | Regression loss: 0.17169 | Running loss: 0.32817\n",
      "Epoch: 12 | Iteration: 587 | Classification loss: 0.06489 | Regression loss: 0.23783 | Running loss: 0.32833\n",
      "Epoch: 12 | Iteration: 588 | Classification loss: 0.07275 | Regression loss: 0.22574 | Running loss: 0.32857\n",
      "Epoch: 12 | Iteration: 589 | Classification loss: 0.11493 | Regression loss: 0.13862 | Running loss: 0.32861\n",
      "Epoch: 12 | Iteration: 590 | Classification loss: 0.23960 | Regression loss: 0.53423 | Running loss: 0.32936\n",
      "Epoch: 12 | Iteration: 591 | Classification loss: 0.10728 | Regression loss: 0.28809 | Running loss: 0.32966\n",
      "Epoch: 12 | Iteration: 592 | Classification loss: 0.19311 | Regression loss: 0.28474 | Running loss: 0.32988\n",
      "Epoch: 12 | Iteration: 593 | Classification loss: 0.03276 | Regression loss: 0.22152 | Running loss: 0.32994\n",
      "Epoch: 12 | Iteration: 594 | Classification loss: 0.04580 | Regression loss: 0.26135 | Running loss: 0.32966\n",
      "Epoch: 12 | Iteration: 595 | Classification loss: 0.03083 | Regression loss: 0.21532 | Running loss: 0.32974\n",
      "Epoch: 12 | Iteration: 596 | Classification loss: 0.04783 | Regression loss: 0.18849 | Running loss: 0.33021\n",
      "Epoch: 12 | Iteration: 597 | Classification loss: 0.03515 | Regression loss: 0.20356 | Running loss: 0.33021\n",
      "Epoch: 12 | Iteration: 598 | Classification loss: 0.07013 | Regression loss: 0.15836 | Running loss: 0.32981\n",
      "Epoch: 12 | Iteration: 599 | Classification loss: 0.07412 | Regression loss: 0.09766 | Running loss: 0.32937\n",
      "Epoch: 12 | Iteration: 600 | Classification loss: 0.05094 | Regression loss: 0.28553 | Running loss: 0.32942\n",
      "Epoch: 12 | Iteration: 601 | Classification loss: 0.07217 | Regression loss: 0.26500 | Running loss: 0.32947\n",
      "Epoch: 12 | Iteration: 602 | Classification loss: 0.02865 | Regression loss: 0.10057 | Running loss: 0.32928\n",
      "Epoch: 12 | Iteration: 603 | Classification loss: 0.02944 | Regression loss: 0.13451 | Running loss: 0.32897\n",
      "Epoch: 12 | Iteration: 604 | Classification loss: 0.12330 | Regression loss: 0.20865 | Running loss: 0.32908\n",
      "Epoch: 12 | Iteration: 605 | Classification loss: 0.04695 | Regression loss: 0.20744 | Running loss: 0.32903\n",
      "Epoch: 12 | Iteration: 606 | Classification loss: 0.11884 | Regression loss: 0.24827 | Running loss: 0.32901\n",
      "Epoch: 12 | Iteration: 607 | Classification loss: 0.24021 | Regression loss: 0.33603 | Running loss: 0.32951\n",
      "Epoch: 12 | Iteration: 608 | Classification loss: 0.03859 | Regression loss: 0.13142 | Running loss: 0.32915\n",
      "Epoch: 12 | Iteration: 609 | Classification loss: 0.04808 | Regression loss: 0.19006 | Running loss: 0.32913\n",
      "Epoch: 12 | Iteration: 610 | Classification loss: 0.15730 | Regression loss: 0.12795 | Running loss: 0.32924\n",
      "Epoch: 12 | Iteration: 611 | Classification loss: 0.12019 | Regression loss: 0.29885 | Running loss: 0.32953\n",
      "Epoch: 12 | Iteration: 612 | Classification loss: 0.02849 | Regression loss: 0.15479 | Running loss: 0.32893\n",
      "Epoch: 12 | Iteration: 613 | Classification loss: 0.02080 | Regression loss: 0.05766 | Running loss: 0.32863\n",
      "Epoch: 12 | Iteration: 614 | Classification loss: 0.10721 | Regression loss: 0.24245 | Running loss: 0.32881\n",
      "Epoch: 12 | Iteration: 615 | Classification loss: 0.24250 | Regression loss: 0.29698 | Running loss: 0.32933\n",
      "Epoch: 12 | Iteration: 616 | Classification loss: 0.05300 | Regression loss: 0.26036 | Running loss: 0.32974\n",
      "Epoch: 12 | Iteration: 617 | Classification loss: 0.03152 | Regression loss: 0.21578 | Running loss: 0.32977\n",
      "Epoch: 12 | Iteration: 618 | Classification loss: 0.10181 | Regression loss: 0.26585 | Running loss: 0.33005\n",
      "Epoch: 12 | Iteration: 619 | Classification loss: 0.22171 | Regression loss: 0.57554 | Running loss: 0.33052\n",
      "Epoch: 12 | Iteration: 620 | Classification loss: 0.10803 | Regression loss: 0.27169 | Running loss: 0.33074\n",
      "Epoch: 12 | Iteration: 621 | Classification loss: 0.19374 | Regression loss: 0.47020 | Running loss: 0.33154\n",
      "Epoch: 12 | Iteration: 622 | Classification loss: 0.05819 | Regression loss: 0.26095 | Running loss: 0.33116\n",
      "Epoch: 12 | Iteration: 623 | Classification loss: 0.06759 | Regression loss: 0.19972 | Running loss: 0.33107\n",
      "Epoch: 12 | Iteration: 624 | Classification loss: 0.04507 | Regression loss: 0.15626 | Running loss: 0.33085\n",
      "Epoch: 12 | Iteration: 625 | Classification loss: 0.03067 | Regression loss: 0.24376 | Running loss: 0.33100\n",
      "Epoch: 12 | Iteration: 626 | Classification loss: 0.03075 | Regression loss: 0.27164 | Running loss: 0.33117\n",
      "Epoch: 12 | Iteration: 627 | Classification loss: 0.09584 | Regression loss: 0.23849 | Running loss: 0.33148\n",
      "Epoch: 12 | Iteration: 628 | Classification loss: 0.11220 | Regression loss: 0.28642 | Running loss: 0.33181\n",
      "Epoch: 12 | Iteration: 629 | Classification loss: 0.06236 | Regression loss: 0.17482 | Running loss: 0.33182\n",
      "Epoch: 12 | Iteration: 630 | Classification loss: 0.03906 | Regression loss: 0.20192 | Running loss: 0.33177\n",
      "Epoch: 12 | Iteration: 631 | Classification loss: 0.05486 | Regression loss: 0.31413 | Running loss: 0.33222\n",
      "Epoch: 12 | Iteration: 632 | Classification loss: 0.03265 | Regression loss: 0.18526 | Running loss: 0.33218\n",
      "Epoch: 12 | Iteration: 633 | Classification loss: 0.08299 | Regression loss: 0.30722 | Running loss: 0.33229\n",
      "Epoch: 12 | Iteration: 634 | Classification loss: 0.04002 | Regression loss: 0.22842 | Running loss: 0.33239\n",
      "Epoch: 12 | Iteration: 635 | Classification loss: 0.05286 | Regression loss: 0.14010 | Running loss: 0.33226\n",
      "Epoch: 12 | Iteration: 636 | Classification loss: 0.04234 | Regression loss: 0.23995 | Running loss: 0.33240\n",
      "Epoch: 12 | Iteration: 637 | Classification loss: 0.07652 | Regression loss: 0.14990 | Running loss: 0.33225\n",
      "Epoch: 12 | Iteration: 638 | Classification loss: 0.08636 | Regression loss: 0.12951 | Running loss: 0.33196\n",
      "Epoch: 12 | Iteration: 639 | Classification loss: 0.04524 | Regression loss: 0.20546 | Running loss: 0.33207\n",
      "Epoch: 12 | Iteration: 640 | Classification loss: 0.25498 | Regression loss: 0.46753 | Running loss: 0.33286\n",
      "Epoch: 12 | Iteration: 641 | Classification loss: 0.02277 | Regression loss: 0.08230 | Running loss: 0.33259\n",
      "Epoch: 12 | Iteration: 642 | Classification loss: 0.04713 | Regression loss: 0.16722 | Running loss: 0.33261\n",
      "Epoch: 12 | Iteration: 643 | Classification loss: 0.03738 | Regression loss: 0.20204 | Running loss: 0.33224\n",
      "Epoch: 12 | Iteration: 644 | Classification loss: 0.05494 | Regression loss: 0.21341 | Running loss: 0.33219\n",
      "Epoch: 12 | Iteration: 645 | Classification loss: 0.06773 | Regression loss: 0.19636 | Running loss: 0.33218\n",
      "Epoch: 12 | Iteration: 646 | Classification loss: 0.04564 | Regression loss: 0.23713 | Running loss: 0.33236\n",
      "Epoch: 12 | Iteration: 647 | Classification loss: 0.03482 | Regression loss: 0.23462 | Running loss: 0.33243\n",
      "Epoch: 12 | Iteration: 648 | Classification loss: 0.03771 | Regression loss: 0.21219 | Running loss: 0.33245\n",
      "Epoch: 12 | Iteration: 649 | Classification loss: 0.02801 | Regression loss: 0.18680 | Running loss: 0.33251\n",
      "Epoch: 12 | Iteration: 650 | Classification loss: 0.02588 | Regression loss: 0.08732 | Running loss: 0.33205\n",
      "Epoch: 12 | Iteration: 651 | Classification loss: 0.01767 | Regression loss: 0.09723 | Running loss: 0.33209\n",
      "Epoch: 12 | Iteration: 652 | Classification loss: 0.04984 | Regression loss: 0.12939 | Running loss: 0.33199\n",
      "Epoch: 12 | Iteration: 653 | Classification loss: 0.06892 | Regression loss: 0.29385 | Running loss: 0.33222\n",
      "Epoch: 12 | Iteration: 654 | Classification loss: 0.05252 | Regression loss: 0.14347 | Running loss: 0.33227\n",
      "Epoch: 12 | Iteration: 655 | Classification loss: 0.07713 | Regression loss: 0.14774 | Running loss: 0.33196\n",
      "Epoch: 12 | Iteration: 656 | Classification loss: 0.19499 | Regression loss: 0.35568 | Running loss: 0.33255\n",
      "Epoch: 12 | Iteration: 657 | Classification loss: 0.03107 | Regression loss: 0.09824 | Running loss: 0.33178\n",
      "Epoch: 12 | Iteration: 658 | Classification loss: 0.08384 | Regression loss: 0.27338 | Running loss: 0.33188\n",
      "Epoch: 12 | Iteration: 659 | Classification loss: 0.03835 | Regression loss: 0.26683 | Running loss: 0.33188\n",
      "Epoch: 12 | Iteration: 660 | Classification loss: 0.03593 | Regression loss: 0.13283 | Running loss: 0.33153\n",
      "Epoch: 12 | Iteration: 661 | Classification loss: 0.42050 | Regression loss: 0.28809 | Running loss: 0.33260\n",
      "Epoch: 12 | Iteration: 662 | Classification loss: 0.04326 | Regression loss: 0.12780 | Running loss: 0.33239\n",
      "Epoch: 12 | Iteration: 663 | Classification loss: 0.23290 | Regression loss: 0.10442 | Running loss: 0.33227\n",
      "Epoch: 12 | Iteration: 664 | Classification loss: 0.04191 | Regression loss: 0.14613 | Running loss: 0.33216\n",
      "Epoch: 12 | Iteration: 665 | Classification loss: 0.02284 | Regression loss: 0.16986 | Running loss: 0.33203\n",
      "Epoch: 12 | Iteration: 666 | Classification loss: 0.08178 | Regression loss: 0.24277 | Running loss: 0.33180\n",
      "Epoch: 12 | Iteration: 667 | Classification loss: 0.13014 | Regression loss: 0.22434 | Running loss: 0.33179\n",
      "Epoch: 12 | Iteration: 668 | Classification loss: 0.05526 | Regression loss: 0.29522 | Running loss: 0.33193\n",
      "Epoch: 12 | Iteration: 669 | Classification loss: 0.07570 | Regression loss: 0.11690 | Running loss: 0.33195\n",
      "Epoch: 12 | Iteration: 670 | Classification loss: 0.09374 | Regression loss: 0.32827 | Running loss: 0.33224\n",
      "Epoch: 12 | Iteration: 671 | Classification loss: 0.03033 | Regression loss: 0.14175 | Running loss: 0.33227\n",
      "Epoch: 12 | Iteration: 672 | Classification loss: 0.05124 | Regression loss: 0.16547 | Running loss: 0.33219\n",
      "Epoch: 12 | Iteration: 673 | Classification loss: 0.04216 | Regression loss: 0.15157 | Running loss: 0.33202\n",
      "Epoch: 12 | Iteration: 674 | Classification loss: 0.06294 | Regression loss: 0.14445 | Running loss: 0.33158\n",
      "Epoch: 12 | Iteration: 675 | Classification loss: 0.04292 | Regression loss: 0.27873 | Running loss: 0.33145\n",
      "Epoch: 12 | Iteration: 676 | Classification loss: 0.07186 | Regression loss: 0.29125 | Running loss: 0.33161\n",
      "Epoch: 12 | Iteration: 677 | Classification loss: 0.09489 | Regression loss: 0.18864 | Running loss: 0.33168\n",
      "Epoch: 12 | Iteration: 678 | Classification loss: 0.02830 | Regression loss: 0.22413 | Running loss: 0.33145\n",
      "Epoch: 12 | Iteration: 679 | Classification loss: 0.11753 | Regression loss: 0.15458 | Running loss: 0.33148\n",
      "Epoch: 12 | Iteration: 680 | Classification loss: 0.01656 | Regression loss: 0.13974 | Running loss: 0.33133\n",
      "Epoch: 12 | Iteration: 681 | Classification loss: 0.06951 | Regression loss: 0.21108 | Running loss: 0.33056\n",
      "Epoch: 12 | Iteration: 682 | Classification loss: 0.03050 | Regression loss: 0.07671 | Running loss: 0.33032\n",
      "Epoch: 12 | Iteration: 683 | Classification loss: 0.02374 | Regression loss: 0.15255 | Running loss: 0.33038\n",
      "Epoch: 12 | Iteration: 684 | Classification loss: 0.03468 | Regression loss: 0.15816 | Running loss: 0.33026\n",
      "Epoch: 12 | Iteration: 685 | Classification loss: 0.07553 | Regression loss: 0.23799 | Running loss: 0.33029\n",
      "Epoch: 12 | Iteration: 686 | Classification loss: 0.23376 | Regression loss: 0.13777 | Running loss: 0.33051\n",
      "Epoch: 12 | Iteration: 687 | Classification loss: 0.12646 | Regression loss: 0.28196 | Running loss: 0.33041\n",
      "Epoch: 12 | Iteration: 688 | Classification loss: 0.16477 | Regression loss: 0.32408 | Running loss: 0.33088\n",
      "Epoch: 12 | Iteration: 689 | Classification loss: 0.17496 | Regression loss: 0.18834 | Running loss: 0.33111\n",
      "Epoch: 12 | Iteration: 690 | Classification loss: 0.05494 | Regression loss: 0.21716 | Running loss: 0.33073\n",
      "Epoch: 12 | Iteration: 691 | Classification loss: 0.07408 | Regression loss: 0.20945 | Running loss: 0.33093\n",
      "Epoch: 12 | Iteration: 692 | Classification loss: 0.10543 | Regression loss: 0.34425 | Running loss: 0.32900\n",
      "Epoch: 12 | Iteration: 693 | Classification loss: 0.12125 | Regression loss: 0.19586 | Running loss: 0.32892\n",
      "Epoch: 12 | Iteration: 694 | Classification loss: 0.12284 | Regression loss: 0.39360 | Running loss: 0.32960\n",
      "Epoch: 12 | Iteration: 695 | Classification loss: 0.07532 | Regression loss: 0.20282 | Running loss: 0.32979\n",
      "Epoch: 12 | Iteration: 696 | Classification loss: 0.05523 | Regression loss: 0.25801 | Running loss: 0.32990\n",
      "Epoch: 12 | Iteration: 697 | Classification loss: 0.07086 | Regression loss: 0.27287 | Running loss: 0.32952\n",
      "Epoch: 12 | Iteration: 698 | Classification loss: 0.03961 | Regression loss: 0.10202 | Running loss: 0.32927\n",
      "Epoch: 12 | Iteration: 699 | Classification loss: 0.05931 | Regression loss: 0.28878 | Running loss: 0.32954\n",
      "Epoch: 12 | Iteration: 700 | Classification loss: 0.08435 | Regression loss: 0.22209 | Running loss: 0.32969\n",
      "Epoch: 12 | Iteration: 701 | Classification loss: 0.04994 | Regression loss: 0.18522 | Running loss: 0.32962\n",
      "Epoch: 12 | Iteration: 702 | Classification loss: 0.21030 | Regression loss: 0.40816 | Running loss: 0.33028\n",
      "Epoch: 12 | Iteration: 703 | Classification loss: 0.07411 | Regression loss: 0.13737 | Running loss: 0.33042\n",
      "Epoch: 12 | Iteration: 704 | Classification loss: 0.04329 | Regression loss: 0.15715 | Running loss: 0.33053\n",
      "Epoch: 12 | Iteration: 705 | Classification loss: 0.11194 | Regression loss: 0.35009 | Running loss: 0.33097\n",
      "Epoch: 12 | Iteration: 706 | Classification loss: 0.08297 | Regression loss: 0.27995 | Running loss: 0.33049\n",
      "Epoch: 12 | Iteration: 707 | Classification loss: 0.10934 | Regression loss: 0.20871 | Running loss: 0.33066\n",
      "Epoch: 12 | Iteration: 708 | Classification loss: 0.03262 | Regression loss: 0.28175 | Running loss: 0.33070\n",
      "Epoch: 12 | Iteration: 709 | Classification loss: 0.08081 | Regression loss: 0.25446 | Running loss: 0.33086\n",
      "Epoch: 12 | Iteration: 710 | Classification loss: 0.09698 | Regression loss: 0.42230 | Running loss: 0.33109\n",
      "Epoch: 12 | Iteration: 711 | Classification loss: 0.08380 | Regression loss: 0.57107 | Running loss: 0.33132\n",
      "Epoch: 12 | Iteration: 712 | Classification loss: 0.11208 | Regression loss: 0.25543 | Running loss: 0.33154\n",
      "Epoch: 12 | Iteration: 713 | Classification loss: 0.06969 | Regression loss: 0.11845 | Running loss: 0.33134\n",
      "Epoch: 12 | Iteration: 714 | Classification loss: 0.05365 | Regression loss: 0.24889 | Running loss: 0.33150\n",
      "Epoch: 12 | Iteration: 715 | Classification loss: 0.03514 | Regression loss: 0.10850 | Running loss: 0.33100\n",
      "Epoch: 12 | Iteration: 716 | Classification loss: 0.08309 | Regression loss: 0.36973 | Running loss: 0.33130\n",
      "Epoch: 12 | Iteration: 717 | Classification loss: 0.02586 | Regression loss: 0.16872 | Running loss: 0.33092\n",
      "Epoch: 12 | Iteration: 718 | Classification loss: 0.02286 | Regression loss: 0.16163 | Running loss: 0.33061\n",
      "Epoch: 12 | Iteration: 719 | Classification loss: 0.12755 | Regression loss: 0.33701 | Running loss: 0.33056\n",
      "Epoch: 12 | Iteration: 720 | Classification loss: 0.09550 | Regression loss: 0.26759 | Running loss: 0.33081\n",
      "Epoch: 12 | Iteration: 721 | Classification loss: 0.02069 | Regression loss: 0.11849 | Running loss: 0.33062\n",
      "Epoch: 12 | Iteration: 722 | Classification loss: 0.07808 | Regression loss: 0.14838 | Running loss: 0.33035\n",
      "Epoch: 12 | Iteration: 723 | Classification loss: 0.10621 | Regression loss: 0.24384 | Running loss: 0.33063\n",
      "Epoch: 12 | Iteration: 724 | Classification loss: 0.05260 | Regression loss: 0.13193 | Running loss: 0.33044\n",
      "Epoch: 12 | Iteration: 725 | Classification loss: 0.12888 | Regression loss: 0.29771 | Running loss: 0.33065\n",
      "Epoch: 12 | Iteration: 726 | Classification loss: 0.05835 | Regression loss: 0.23493 | Running loss: 0.33020\n",
      "Epoch: 12 | Iteration: 727 | Classification loss: 0.05953 | Regression loss: 0.25834 | Running loss: 0.33029\n",
      "Epoch: 12 | Iteration: 728 | Classification loss: 0.15727 | Regression loss: 0.39984 | Running loss: 0.33096\n",
      "Epoch: 12 | Iteration: 729 | Classification loss: 0.06865 | Regression loss: 0.20063 | Running loss: 0.33103\n",
      "Epoch: 12 | Iteration: 730 | Classification loss: 0.08814 | Regression loss: 0.29450 | Running loss: 0.33103\n",
      "Epoch: 12 | Iteration: 731 | Classification loss: 0.06032 | Regression loss: 0.09074 | Running loss: 0.33092\n",
      "Epoch: 12 | Iteration: 732 | Classification loss: 0.04310 | Regression loss: 0.12438 | Running loss: 0.33072\n",
      "Epoch: 12 | Iteration: 733 | Classification loss: 0.02283 | Regression loss: 0.14611 | Running loss: 0.33021\n",
      "Epoch: 12 | Iteration: 734 | Classification loss: 0.02450 | Regression loss: 0.13881 | Running loss: 0.32996\n",
      "Epoch: 12 | Iteration: 735 | Classification loss: 0.11890 | Regression loss: 0.29757 | Running loss: 0.33020\n",
      "Epoch: 12 | Iteration: 736 | Classification loss: 0.03985 | Regression loss: 0.12917 | Running loss: 0.33002\n",
      "Epoch: 12 | Iteration: 737 | Classification loss: 0.01934 | Regression loss: 0.22629 | Running loss: 0.33012\n",
      "Epoch: 12 | Iteration: 738 | Classification loss: 0.08077 | Regression loss: 0.32844 | Running loss: 0.33000\n",
      "Epoch: 12 | Iteration: 739 | Classification loss: 0.03267 | Regression loss: 0.19147 | Running loss: 0.32976\n",
      "Epoch: 12 | Iteration: 740 | Classification loss: 0.12868 | Regression loss: 0.16469 | Running loss: 0.33003\n",
      "Epoch: 12 | Iteration: 741 | Classification loss: 0.04989 | Regression loss: 0.17926 | Running loss: 0.33005\n",
      "Epoch: 12 | Iteration: 742 | Classification loss: 0.04030 | Regression loss: 0.23976 | Running loss: 0.33019\n",
      "Epoch: 12 | Iteration: 743 | Classification loss: 0.09002 | Regression loss: 0.27286 | Running loss: 0.33038\n",
      "Epoch: 12 | Iteration: 744 | Classification loss: 0.08326 | Regression loss: 0.13125 | Running loss: 0.33021\n",
      "Epoch: 12 | Iteration: 745 | Classification loss: 0.04921 | Regression loss: 0.20651 | Running loss: 0.32972\n",
      "Epoch: 12 | Iteration: 746 | Classification loss: 0.04383 | Regression loss: 0.22392 | Running loss: 0.32901\n",
      "Epoch: 12 | Iteration: 747 | Classification loss: 0.04025 | Regression loss: 0.18548 | Running loss: 0.32843\n",
      "Epoch: 12 | Iteration: 748 | Classification loss: 0.03439 | Regression loss: 0.12348 | Running loss: 0.32809\n",
      "Epoch: 12 | Iteration: 749 | Classification loss: 0.06754 | Regression loss: 0.26263 | Running loss: 0.32786\n",
      "Epoch: 12 | Iteration: 750 | Classification loss: 0.07939 | Regression loss: 0.27261 | Running loss: 0.32729\n",
      "Epoch: 12 | Iteration: 751 | Classification loss: 0.14266 | Regression loss: 0.19100 | Running loss: 0.32758\n",
      "Epoch: 12 | Iteration: 752 | Classification loss: 0.12364 | Regression loss: 0.17074 | Running loss: 0.32739\n",
      "Epoch: 12 | Iteration: 753 | Classification loss: 0.08779 | Regression loss: 0.17881 | Running loss: 0.32734\n",
      "Epoch: 12 | Iteration: 754 | Classification loss: 0.05722 | Regression loss: 0.11768 | Running loss: 0.32769\n",
      "Epoch: 12 | Iteration: 755 | Classification loss: 0.06176 | Regression loss: 0.21869 | Running loss: 0.32785\n",
      "Epoch: 12 | Iteration: 756 | Classification loss: 0.07036 | Regression loss: 0.29445 | Running loss: 0.32825\n",
      "Epoch: 12 | Iteration: 757 | Classification loss: 0.11339 | Regression loss: 0.23751 | Running loss: 0.32836\n",
      "Epoch: 12 | Iteration: 758 | Classification loss: 0.06554 | Regression loss: 0.19780 | Running loss: 0.32841\n",
      "Epoch: 12 | Iteration: 759 | Classification loss: 0.03091 | Regression loss: 0.15807 | Running loss: 0.32800\n",
      "Epoch: 12 | Iteration: 760 | Classification loss: 0.08615 | Regression loss: 0.18610 | Running loss: 0.32815\n",
      "Epoch: 12 | Iteration: 761 | Classification loss: 0.04375 | Regression loss: 0.15833 | Running loss: 0.32792\n",
      "Epoch: 12 | Iteration: 762 | Classification loss: 0.24050 | Regression loss: 0.26953 | Running loss: 0.32802\n",
      "Epoch: 12 | Iteration: 763 | Classification loss: 0.04170 | Regression loss: 0.10284 | Running loss: 0.32788\n",
      "Epoch: 12 | Iteration: 764 | Classification loss: 0.03807 | Regression loss: 0.12053 | Running loss: 0.32716\n",
      "Epoch: 12 | Iteration: 765 | Classification loss: 0.05069 | Regression loss: 0.24499 | Running loss: 0.32733\n",
      "Epoch: 12 | Iteration: 766 | Classification loss: 0.03992 | Regression loss: 0.11744 | Running loss: 0.32732\n",
      "Epoch: 12 | Iteration: 767 | Classification loss: 0.07442 | Regression loss: 0.16874 | Running loss: 0.32703\n",
      "Epoch: 12 | Iteration: 768 | Classification loss: 0.06286 | Regression loss: 0.33124 | Running loss: 0.32749\n",
      "Epoch: 12 | Iteration: 769 | Classification loss: 0.05737 | Regression loss: 0.26076 | Running loss: 0.32772\n",
      "Epoch: 12 | Iteration: 770 | Classification loss: 0.08589 | Regression loss: 0.19501 | Running loss: 0.32795\n",
      "Epoch: 12 | Iteration: 771 | Classification loss: 0.04704 | Regression loss: 0.14530 | Running loss: 0.32790\n",
      "Epoch: 12 | Iteration: 772 | Classification loss: 0.08069 | Regression loss: 0.27561 | Running loss: 0.32829\n",
      "Epoch: 12 | Iteration: 773 | Classification loss: 0.09880 | Regression loss: 0.15626 | Running loss: 0.32844\n",
      "Epoch: 12 | Iteration: 774 | Classification loss: 0.02726 | Regression loss: 0.13646 | Running loss: 0.32843\n",
      "Epoch: 12 | Iteration: 775 | Classification loss: 0.03468 | Regression loss: 0.11110 | Running loss: 0.32782\n",
      "Epoch: 12 | Iteration: 776 | Classification loss: 0.29400 | Regression loss: 0.27774 | Running loss: 0.32818\n",
      "Epoch: 12 | Iteration: 777 | Classification loss: 0.03634 | Regression loss: 0.22400 | Running loss: 0.32839\n",
      "Epoch: 12 | Iteration: 778 | Classification loss: 0.08135 | Regression loss: 0.15944 | Running loss: 0.32841\n",
      "Epoch: 12 | Iteration: 779 | Classification loss: 0.04651 | Regression loss: 0.12530 | Running loss: 0.32831\n",
      "Epoch: 12 | Iteration: 780 | Classification loss: 0.06502 | Regression loss: 0.12873 | Running loss: 0.32826\n",
      "Epoch: 12 | Iteration: 781 | Classification loss: 0.05100 | Regression loss: 0.21494 | Running loss: 0.32820\n",
      "Epoch: 12 | Iteration: 782 | Classification loss: 0.21920 | Regression loss: 0.30956 | Running loss: 0.32873\n",
      "Epoch: 12 | Iteration: 783 | Classification loss: 0.01975 | Regression loss: 0.09989 | Running loss: 0.32867\n",
      "Epoch: 12 | Iteration: 784 | Classification loss: 0.10084 | Regression loss: 0.16697 | Running loss: 0.32881\n",
      "Epoch: 12 | Iteration: 785 | Classification loss: 0.02790 | Regression loss: 0.11999 | Running loss: 0.32876\n",
      "Epoch: 12 | Iteration: 786 | Classification loss: 0.27415 | Regression loss: 0.20928 | Running loss: 0.32949\n",
      "Epoch: 12 | Iteration: 787 | Classification loss: 0.04743 | Regression loss: 0.26768 | Running loss: 0.32944\n",
      "Epoch: 12 | Iteration: 788 | Classification loss: 0.19896 | Regression loss: 0.28377 | Running loss: 0.32988\n",
      "Epoch: 12 | Iteration: 789 | Classification loss: 0.03916 | Regression loss: 0.11353 | Running loss: 0.32933\n",
      "Epoch: 12 | Iteration: 790 | Classification loss: 0.17262 | Regression loss: 0.15879 | Running loss: 0.32904\n",
      "Epoch: 12 | Iteration: 791 | Classification loss: 0.20980 | Regression loss: 0.25373 | Running loss: 0.32916\n",
      "Epoch: 12 | Iteration: 792 | Classification loss: 0.05168 | Regression loss: 0.30117 | Running loss: 0.32954\n",
      "Epoch: 12 | Iteration: 793 | Classification loss: 0.01525 | Regression loss: 0.08193 | Running loss: 0.32943\n",
      "Epoch: 12 | Iteration: 794 | Classification loss: 0.08264 | Regression loss: 0.21451 | Running loss: 0.32919\n",
      "Epoch: 12 | Iteration: 795 | Classification loss: 0.06843 | Regression loss: 0.29702 | Running loss: 0.32900\n",
      "Epoch: 12 | Iteration: 796 | Classification loss: 0.04545 | Regression loss: 0.15736 | Running loss: 0.32905\n",
      "Epoch: 12 | Iteration: 797 | Classification loss: 0.03576 | Regression loss: 0.13300 | Running loss: 0.32903\n",
      "Epoch: 12 | Iteration: 798 | Classification loss: 0.10817 | Regression loss: 0.38609 | Running loss: 0.32912\n",
      "Epoch: 12 | Iteration: 799 | Classification loss: 0.14128 | Regression loss: 0.21395 | Running loss: 0.32933\n",
      "Epoch: 12 | Iteration: 800 | Classification loss: 0.03893 | Regression loss: 0.09468 | Running loss: 0.32874\n",
      "Epoch: 12 | Iteration: 801 | Classification loss: 0.04661 | Regression loss: 0.23288 | Running loss: 0.32857\n",
      "Epoch: 12 | Iteration: 802 | Classification loss: 0.03202 | Regression loss: 0.13525 | Running loss: 0.32832\n",
      "Epoch: 12 | Iteration: 803 | Classification loss: 0.02454 | Regression loss: 0.09831 | Running loss: 0.32804\n",
      "Epoch: 12 | Iteration: 804 | Classification loss: 0.15681 | Regression loss: 0.45933 | Running loss: 0.32822\n",
      "Epoch: 12 | Iteration: 805 | Classification loss: 0.08316 | Regression loss: 0.12066 | Running loss: 0.32695\n",
      "Epoch: 12 | Iteration: 806 | Classification loss: 0.11941 | Regression loss: 0.14872 | Running loss: 0.32669\n",
      "Epoch: 12 | Iteration: 807 | Classification loss: 0.09483 | Regression loss: 0.23618 | Running loss: 0.32648\n",
      "Epoch: 12 | Iteration: 808 | Classification loss: 0.01280 | Regression loss: 0.09061 | Running loss: 0.32612\n",
      "Epoch: 12 | Iteration: 809 | Classification loss: 0.17751 | Regression loss: 0.27780 | Running loss: 0.32615\n",
      "Epoch: 12 | Iteration: 810 | Classification loss: 0.15123 | Regression loss: 0.29321 | Running loss: 0.32662\n",
      "Epoch: 12 | Iteration: 811 | Classification loss: 0.30893 | Regression loss: 0.08092 | Running loss: 0.32670\n",
      "Epoch: 12 | Iteration: 812 | Classification loss: 0.05441 | Regression loss: 0.16782 | Running loss: 0.32676\n",
      "Epoch: 12 | Iteration: 813 | Classification loss: 0.12649 | Regression loss: 0.35668 | Running loss: 0.32708\n",
      "Epoch: 12 | Iteration: 814 | Classification loss: 0.14976 | Regression loss: 0.25901 | Running loss: 0.32756\n",
      "Epoch: 12 | Iteration: 815 | Classification loss: 0.03774 | Regression loss: 0.16911 | Running loss: 0.32751\n",
      "Epoch: 12 | Iteration: 816 | Classification loss: 0.03401 | Regression loss: 0.19759 | Running loss: 0.32760\n",
      "Epoch: 12 | Iteration: 817 | Classification loss: 0.24964 | Regression loss: 0.52889 | Running loss: 0.32826\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.571\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 13 | Iteration: 0 | Classification loss: 0.05863 | Regression loss: 0.08476 | Running loss: 0.32801\n",
      "Epoch: 13 | Iteration: 1 | Classification loss: 0.08079 | Regression loss: 0.24971 | Running loss: 0.32804\n",
      "Epoch: 13 | Iteration: 2 | Classification loss: 0.04175 | Regression loss: 0.13283 | Running loss: 0.32758\n",
      "Epoch: 13 | Iteration: 3 | Classification loss: 0.04802 | Regression loss: 0.22167 | Running loss: 0.32778\n",
      "Epoch: 13 | Iteration: 4 | Classification loss: 0.07426 | Regression loss: 0.25490 | Running loss: 0.32822\n",
      "Epoch: 13 | Iteration: 5 | Classification loss: 0.04590 | Regression loss: 0.20409 | Running loss: 0.32808\n",
      "Epoch: 13 | Iteration: 6 | Classification loss: 0.04540 | Regression loss: 0.15331 | Running loss: 0.32826\n",
      "Epoch: 13 | Iteration: 7 | Classification loss: 0.05161 | Regression loss: 0.12386 | Running loss: 0.32812\n",
      "Epoch: 13 | Iteration: 8 | Classification loss: 0.01665 | Regression loss: 0.12618 | Running loss: 0.32766\n",
      "Epoch: 13 | Iteration: 9 | Classification loss: 0.01922 | Regression loss: 0.07132 | Running loss: 0.32725\n",
      "Epoch: 13 | Iteration: 10 | Classification loss: 0.03583 | Regression loss: 0.16473 | Running loss: 0.32741\n",
      "Epoch: 13 | Iteration: 11 | Classification loss: 0.06433 | Regression loss: 0.23844 | Running loss: 0.32753\n",
      "Epoch: 13 | Iteration: 12 | Classification loss: 0.06024 | Regression loss: 0.13525 | Running loss: 0.32735\n",
      "Epoch: 13 | Iteration: 13 | Classification loss: 0.18866 | Regression loss: 0.29228 | Running loss: 0.32731\n",
      "Epoch: 13 | Iteration: 14 | Classification loss: 0.16017 | Regression loss: 0.28946 | Running loss: 0.32772\n",
      "Epoch: 13 | Iteration: 15 | Classification loss: 0.07426 | Regression loss: 0.26985 | Running loss: 0.32740\n",
      "Epoch: 13 | Iteration: 16 | Classification loss: 0.01044 | Regression loss: 0.15707 | Running loss: 0.32707\n",
      "Epoch: 13 | Iteration: 17 | Classification loss: 0.03620 | Regression loss: 0.12748 | Running loss: 0.32715\n",
      "Epoch: 13 | Iteration: 18 | Classification loss: 0.06704 | Regression loss: 0.25837 | Running loss: 0.32735\n",
      "Epoch: 13 | Iteration: 19 | Classification loss: 0.04401 | Regression loss: 0.15622 | Running loss: 0.32730\n",
      "Epoch: 13 | Iteration: 20 | Classification loss: 0.06198 | Regression loss: 0.13957 | Running loss: 0.32735\n",
      "Epoch: 13 | Iteration: 21 | Classification loss: 0.07451 | Regression loss: 0.33513 | Running loss: 0.32767\n",
      "Epoch: 13 | Iteration: 22 | Classification loss: 0.04004 | Regression loss: 0.14970 | Running loss: 0.32763\n",
      "Epoch: 13 | Iteration: 23 | Classification loss: 0.04336 | Regression loss: 0.17097 | Running loss: 0.32724\n",
      "Epoch: 13 | Iteration: 24 | Classification loss: 0.16714 | Regression loss: 0.37561 | Running loss: 0.32684\n",
      "Epoch: 13 | Iteration: 25 | Classification loss: 0.05393 | Regression loss: 0.28657 | Running loss: 0.32669\n",
      "Epoch: 13 | Iteration: 26 | Classification loss: 0.04850 | Regression loss: 0.11927 | Running loss: 0.32626\n",
      "Epoch: 13 | Iteration: 27 | Classification loss: 0.29300 | Regression loss: 0.47111 | Running loss: 0.32727\n",
      "Epoch: 13 | Iteration: 28 | Classification loss: 0.02935 | Regression loss: 0.12224 | Running loss: 0.32696\n",
      "Epoch: 13 | Iteration: 29 | Classification loss: 0.10046 | Regression loss: 0.57567 | Running loss: 0.32718\n",
      "Epoch: 13 | Iteration: 30 | Classification loss: 0.04206 | Regression loss: 0.10282 | Running loss: 0.32591\n",
      "Epoch: 13 | Iteration: 31 | Classification loss: 0.10759 | Regression loss: 0.11739 | Running loss: 0.32571\n",
      "Epoch: 13 | Iteration: 32 | Classification loss: 0.12672 | Regression loss: 0.15415 | Running loss: 0.32552\n",
      "Epoch: 13 | Iteration: 33 | Classification loss: 0.15959 | Regression loss: 0.28520 | Running loss: 0.32584\n",
      "Epoch: 13 | Iteration: 34 | Classification loss: 0.04968 | Regression loss: 0.25939 | Running loss: 0.32526\n",
      "Epoch: 13 | Iteration: 35 | Classification loss: 0.06683 | Regression loss: 0.20090 | Running loss: 0.32539\n",
      "Epoch: 13 | Iteration: 36 | Classification loss: 0.05150 | Regression loss: 0.27661 | Running loss: 0.32552\n",
      "Epoch: 13 | Iteration: 37 | Classification loss: 0.10600 | Regression loss: 0.31539 | Running loss: 0.32588\n",
      "Epoch: 13 | Iteration: 38 | Classification loss: 0.12605 | Regression loss: 0.33785 | Running loss: 0.32632\n",
      "Epoch: 13 | Iteration: 39 | Classification loss: 0.02724 | Regression loss: 0.16694 | Running loss: 0.32630\n",
      "Epoch: 13 | Iteration: 40 | Classification loss: 0.03818 | Regression loss: 0.19109 | Running loss: 0.32551\n",
      "Epoch: 13 | Iteration: 41 | Classification loss: 0.02922 | Regression loss: 0.19067 | Running loss: 0.32547\n",
      "Epoch: 13 | Iteration: 42 | Classification loss: 0.05493 | Regression loss: 0.32645 | Running loss: 0.32505\n",
      "Epoch: 13 | Iteration: 43 | Classification loss: 0.29249 | Regression loss: 0.23658 | Running loss: 0.32565\n",
      "Epoch: 13 | Iteration: 44 | Classification loss: 0.02105 | Regression loss: 0.09711 | Running loss: 0.32549\n",
      "Epoch: 13 | Iteration: 45 | Classification loss: 0.03158 | Regression loss: 0.14278 | Running loss: 0.32544\n",
      "Epoch: 13 | Iteration: 46 | Classification loss: 0.06214 | Regression loss: 0.18085 | Running loss: 0.32528\n",
      "Epoch: 13 | Iteration: 47 | Classification loss: 0.17283 | Regression loss: 0.52244 | Running loss: 0.32507\n",
      "Epoch: 13 | Iteration: 48 | Classification loss: 0.06822 | Regression loss: 0.29446 | Running loss: 0.32544\n",
      "Epoch: 13 | Iteration: 49 | Classification loss: 0.04047 | Regression loss: 0.17975 | Running loss: 0.32528\n",
      "Epoch: 13 | Iteration: 50 | Classification loss: 0.38109 | Regression loss: 0.08767 | Running loss: 0.32561\n",
      "Epoch: 13 | Iteration: 51 | Classification loss: 0.03876 | Regression loss: 0.24292 | Running loss: 0.32506\n",
      "Epoch: 13 | Iteration: 52 | Classification loss: 0.11472 | Regression loss: 0.23515 | Running loss: 0.32538\n",
      "Epoch: 13 | Iteration: 53 | Classification loss: 0.04573 | Regression loss: 0.12663 | Running loss: 0.32457\n",
      "Epoch: 13 | Iteration: 54 | Classification loss: 0.05461 | Regression loss: 0.14700 | Running loss: 0.32471\n",
      "Epoch: 13 | Iteration: 55 | Classification loss: 0.04844 | Regression loss: 0.26468 | Running loss: 0.32480\n",
      "Epoch: 13 | Iteration: 56 | Classification loss: 0.02493 | Regression loss: 0.10665 | Running loss: 0.32443\n",
      "Epoch: 13 | Iteration: 57 | Classification loss: 0.03878 | Regression loss: 0.24901 | Running loss: 0.32409\n",
      "Epoch: 13 | Iteration: 58 | Classification loss: 0.03085 | Regression loss: 0.27355 | Running loss: 0.32448\n",
      "Epoch: 13 | Iteration: 59 | Classification loss: 0.01163 | Regression loss: 0.11008 | Running loss: 0.32407\n",
      "Epoch: 13 | Iteration: 60 | Classification loss: 0.03443 | Regression loss: 0.17244 | Running loss: 0.32363\n",
      "Epoch: 13 | Iteration: 61 | Classification loss: 0.12740 | Regression loss: 0.25145 | Running loss: 0.32378\n",
      "Epoch: 13 | Iteration: 62 | Classification loss: 0.03915 | Regression loss: 0.18498 | Running loss: 0.32391\n",
      "Epoch: 13 | Iteration: 63 | Classification loss: 0.02414 | Regression loss: 0.11807 | Running loss: 0.32356\n",
      "Epoch: 13 | Iteration: 64 | Classification loss: 0.13139 | Regression loss: 0.22100 | Running loss: 0.32321\n",
      "Epoch: 13 | Iteration: 65 | Classification loss: 0.04045 | Regression loss: 0.13741 | Running loss: 0.32276\n",
      "Epoch: 13 | Iteration: 66 | Classification loss: 0.04356 | Regression loss: 0.16248 | Running loss: 0.32221\n",
      "Epoch: 13 | Iteration: 67 | Classification loss: 0.16595 | Regression loss: 0.29324 | Running loss: 0.32198\n",
      "Epoch: 13 | Iteration: 68 | Classification loss: 0.05190 | Regression loss: 0.22768 | Running loss: 0.32149\n",
      "Epoch: 13 | Iteration: 69 | Classification loss: 0.05371 | Regression loss: 0.19732 | Running loss: 0.32162\n",
      "Epoch: 13 | Iteration: 70 | Classification loss: 0.06284 | Regression loss: 0.18163 | Running loss: 0.32151\n",
      "Epoch: 13 | Iteration: 71 | Classification loss: 0.03758 | Regression loss: 0.20100 | Running loss: 0.32159\n",
      "Epoch: 13 | Iteration: 72 | Classification loss: 0.05114 | Regression loss: 0.20857 | Running loss: 0.32198\n",
      "Epoch: 13 | Iteration: 73 | Classification loss: 0.05076 | Regression loss: 0.18932 | Running loss: 0.32160\n",
      "Epoch: 13 | Iteration: 74 | Classification loss: 0.02765 | Regression loss: 0.11387 | Running loss: 0.32169\n",
      "Epoch: 13 | Iteration: 75 | Classification loss: 0.05048 | Regression loss: 0.24916 | Running loss: 0.32164\n",
      "Epoch: 13 | Iteration: 76 | Classification loss: 0.05563 | Regression loss: 0.16665 | Running loss: 0.32135\n",
      "Epoch: 13 | Iteration: 77 | Classification loss: 0.04276 | Regression loss: 0.11556 | Running loss: 0.32081\n",
      "Epoch: 13 | Iteration: 78 | Classification loss: 0.08463 | Regression loss: 0.21780 | Running loss: 0.32060\n",
      "Epoch: 13 | Iteration: 79 | Classification loss: 0.10703 | Regression loss: 0.20750 | Running loss: 0.32052\n",
      "Epoch: 13 | Iteration: 80 | Classification loss: 0.07271 | Regression loss: 0.30751 | Running loss: 0.32036\n",
      "Epoch: 13 | Iteration: 81 | Classification loss: 0.02080 | Regression loss: 0.24310 | Running loss: 0.32019\n",
      "Epoch: 13 | Iteration: 82 | Classification loss: 0.01589 | Regression loss: 0.13198 | Running loss: 0.31951\n",
      "Epoch: 13 | Iteration: 83 | Classification loss: 0.07726 | Regression loss: 0.20214 | Running loss: 0.31969\n",
      "Epoch: 13 | Iteration: 84 | Classification loss: 0.05505 | Regression loss: 0.27266 | Running loss: 0.31918\n",
      "Epoch: 13 | Iteration: 85 | Classification loss: 0.06559 | Regression loss: 0.25357 | Running loss: 0.31842\n",
      "Epoch: 13 | Iteration: 86 | Classification loss: 0.05527 | Regression loss: 0.17379 | Running loss: 0.31834\n",
      "Epoch: 13 | Iteration: 87 | Classification loss: 0.11271 | Regression loss: 0.16645 | Running loss: 0.31787\n",
      "Epoch: 13 | Iteration: 88 | Classification loss: 0.04198 | Regression loss: 0.18544 | Running loss: 0.31773\n",
      "Epoch: 13 | Iteration: 89 | Classification loss: 0.05320 | Regression loss: 0.14790 | Running loss: 0.31731\n",
      "Epoch: 13 | Iteration: 90 | Classification loss: 0.03614 | Regression loss: 0.12071 | Running loss: 0.31712\n",
      "Epoch: 13 | Iteration: 91 | Classification loss: 0.08247 | Regression loss: 0.17623 | Running loss: 0.31739\n",
      "Epoch: 13 | Iteration: 92 | Classification loss: 0.05887 | Regression loss: 0.12604 | Running loss: 0.31656\n",
      "Epoch: 13 | Iteration: 93 | Classification loss: 0.04654 | Regression loss: 0.19705 | Running loss: 0.31656\n",
      "Epoch: 13 | Iteration: 94 | Classification loss: 0.07726 | Regression loss: 0.23130 | Running loss: 0.31624\n",
      "Epoch: 13 | Iteration: 95 | Classification loss: 0.03315 | Regression loss: 0.22788 | Running loss: 0.31582\n",
      "Epoch: 13 | Iteration: 96 | Classification loss: 0.02799 | Regression loss: 0.14626 | Running loss: 0.31555\n",
      "Epoch: 13 | Iteration: 97 | Classification loss: 0.07394 | Regression loss: 0.24478 | Running loss: 0.31577\n",
      "Epoch: 13 | Iteration: 98 | Classification loss: 0.04361 | Regression loss: 0.15111 | Running loss: 0.31514\n",
      "Epoch: 13 | Iteration: 99 | Classification loss: 0.01881 | Regression loss: 0.03956 | Running loss: 0.31480\n",
      "Epoch: 13 | Iteration: 100 | Classification loss: 0.02391 | Regression loss: 0.19457 | Running loss: 0.31463\n",
      "Epoch: 13 | Iteration: 101 | Classification loss: 0.11310 | Regression loss: 0.29561 | Running loss: 0.31497\n",
      "Epoch: 13 | Iteration: 102 | Classification loss: 0.22790 | Regression loss: 0.48986 | Running loss: 0.31592\n",
      "Epoch: 13 | Iteration: 103 | Classification loss: 0.11145 | Regression loss: 0.23681 | Running loss: 0.31618\n",
      "Epoch: 13 | Iteration: 104 | Classification loss: 0.40511 | Regression loss: 0.16309 | Running loss: 0.31670\n",
      "Epoch: 13 | Iteration: 105 | Classification loss: 0.13457 | Regression loss: 0.36769 | Running loss: 0.31637\n",
      "Epoch: 13 | Iteration: 106 | Classification loss: 0.07669 | Regression loss: 0.26089 | Running loss: 0.31634\n",
      "Epoch: 13 | Iteration: 107 | Classification loss: 0.05032 | Regression loss: 0.26760 | Running loss: 0.31615\n",
      "Epoch: 13 | Iteration: 108 | Classification loss: 0.03426 | Regression loss: 0.16832 | Running loss: 0.31595\n",
      "Epoch: 13 | Iteration: 109 | Classification loss: 0.03501 | Regression loss: 0.21808 | Running loss: 0.31577\n",
      "Epoch: 13 | Iteration: 110 | Classification loss: 0.03406 | Regression loss: 0.16374 | Running loss: 0.31579\n",
      "Epoch: 13 | Iteration: 111 | Classification loss: 0.05239 | Regression loss: 0.30513 | Running loss: 0.31579\n",
      "Epoch: 13 | Iteration: 112 | Classification loss: 0.10767 | Regression loss: 0.17515 | Running loss: 0.31564\n",
      "Epoch: 13 | Iteration: 113 | Classification loss: 0.13060 | Regression loss: 0.38940 | Running loss: 0.31616\n",
      "Epoch: 13 | Iteration: 114 | Classification loss: 0.04322 | Regression loss: 0.12869 | Running loss: 0.31563\n",
      "Epoch: 13 | Iteration: 115 | Classification loss: 0.03219 | Regression loss: 0.14822 | Running loss: 0.31559\n",
      "Epoch: 13 | Iteration: 116 | Classification loss: 0.04945 | Regression loss: 0.24272 | Running loss: 0.31546\n",
      "Epoch: 13 | Iteration: 117 | Classification loss: 0.04639 | Regression loss: 0.06858 | Running loss: 0.31526\n",
      "Epoch: 13 | Iteration: 118 | Classification loss: 0.03876 | Regression loss: 0.18878 | Running loss: 0.31530\n",
      "Epoch: 13 | Iteration: 119 | Classification loss: 0.07441 | Regression loss: 0.19418 | Running loss: 0.31505\n",
      "Epoch: 13 | Iteration: 120 | Classification loss: 0.04487 | Regression loss: 0.28466 | Running loss: 0.31522\n",
      "Epoch: 13 | Iteration: 121 | Classification loss: 0.37974 | Regression loss: 0.14768 | Running loss: 0.31577\n",
      "Epoch: 13 | Iteration: 122 | Classification loss: 0.15604 | Regression loss: 0.25686 | Running loss: 0.31622\n",
      "Epoch: 13 | Iteration: 123 | Classification loss: 0.25578 | Regression loss: 0.11927 | Running loss: 0.31657\n",
      "Epoch: 13 | Iteration: 124 | Classification loss: 0.04148 | Regression loss: 0.20436 | Running loss: 0.31567\n",
      "Epoch: 13 | Iteration: 125 | Classification loss: 0.03616 | Regression loss: 0.22538 | Running loss: 0.31600\n",
      "Epoch: 13 | Iteration: 126 | Classification loss: 0.06020 | Regression loss: 0.49082 | Running loss: 0.31654\n",
      "Epoch: 13 | Iteration: 127 | Classification loss: 0.08052 | Regression loss: 0.23635 | Running loss: 0.31612\n",
      "Epoch: 13 | Iteration: 128 | Classification loss: 0.08830 | Regression loss: 0.30965 | Running loss: 0.31639\n",
      "Epoch: 13 | Iteration: 129 | Classification loss: 0.12758 | Regression loss: 0.38843 | Running loss: 0.31645\n",
      "Epoch: 13 | Iteration: 130 | Classification loss: 0.09361 | Regression loss: 0.24668 | Running loss: 0.31640\n",
      "Epoch: 13 | Iteration: 131 | Classification loss: 0.07034 | Regression loss: 0.23608 | Running loss: 0.31625\n",
      "Epoch: 13 | Iteration: 132 | Classification loss: 0.06706 | Regression loss: 0.26145 | Running loss: 0.31634\n",
      "Epoch: 13 | Iteration: 133 | Classification loss: 0.09533 | Regression loss: 0.20507 | Running loss: 0.31599\n",
      "Epoch: 13 | Iteration: 134 | Classification loss: 0.01916 | Regression loss: 0.16544 | Running loss: 0.31491\n",
      "Epoch: 13 | Iteration: 135 | Classification loss: 0.06090 | Regression loss: 0.25878 | Running loss: 0.31525\n",
      "Epoch: 13 | Iteration: 136 | Classification loss: 0.11683 | Regression loss: 0.24501 | Running loss: 0.31531\n",
      "Epoch: 13 | Iteration: 137 | Classification loss: 0.11782 | Regression loss: 0.18924 | Running loss: 0.31489\n",
      "Epoch: 13 | Iteration: 138 | Classification loss: 0.09506 | Regression loss: 0.17846 | Running loss: 0.31520\n",
      "Epoch: 13 | Iteration: 139 | Classification loss: 0.07197 | Regression loss: 0.10914 | Running loss: 0.31491\n",
      "Epoch: 13 | Iteration: 140 | Classification loss: 0.02727 | Regression loss: 0.20625 | Running loss: 0.31400\n",
      "Epoch: 13 | Iteration: 141 | Classification loss: 0.12939 | Regression loss: 0.10618 | Running loss: 0.31389\n",
      "Epoch: 13 | Iteration: 142 | Classification loss: 0.03787 | Regression loss: 0.19178 | Running loss: 0.31335\n",
      "Epoch: 13 | Iteration: 143 | Classification loss: 0.10195 | Regression loss: 0.42224 | Running loss: 0.31387\n",
      "Epoch: 13 | Iteration: 144 | Classification loss: 0.07707 | Regression loss: 0.17985 | Running loss: 0.31328\n",
      "Epoch: 13 | Iteration: 145 | Classification loss: 0.01217 | Regression loss: 0.05932 | Running loss: 0.31266\n",
      "Epoch: 13 | Iteration: 146 | Classification loss: 0.03724 | Regression loss: 0.26422 | Running loss: 0.31207\n",
      "Epoch: 13 | Iteration: 147 | Classification loss: 0.18425 | Regression loss: 0.21189 | Running loss: 0.31219\n",
      "Epoch: 13 | Iteration: 148 | Classification loss: 0.11787 | Regression loss: 0.16421 | Running loss: 0.31173\n",
      "Epoch: 13 | Iteration: 149 | Classification loss: 0.09974 | Regression loss: 0.24026 | Running loss: 0.31152\n",
      "Epoch: 13 | Iteration: 150 | Classification loss: 0.15460 | Regression loss: 0.32271 | Running loss: 0.31185\n",
      "Epoch: 13 | Iteration: 151 | Classification loss: 0.01232 | Regression loss: 0.17494 | Running loss: 0.31185\n",
      "Epoch: 13 | Iteration: 152 | Classification loss: 0.02532 | Regression loss: 0.23799 | Running loss: 0.31200\n",
      "Epoch: 13 | Iteration: 153 | Classification loss: 0.04095 | Regression loss: 0.13332 | Running loss: 0.31155\n",
      "Epoch: 13 | Iteration: 154 | Classification loss: 0.10909 | Regression loss: 0.21538 | Running loss: 0.31148\n",
      "Epoch: 13 | Iteration: 155 | Classification loss: 0.03988 | Regression loss: 0.14138 | Running loss: 0.31111\n",
      "Epoch: 13 | Iteration: 156 | Classification loss: 0.11223 | Regression loss: 0.11370 | Running loss: 0.31120\n",
      "Epoch: 13 | Iteration: 157 | Classification loss: 0.08358 | Regression loss: 0.29130 | Running loss: 0.31112\n",
      "Epoch: 13 | Iteration: 158 | Classification loss: 0.07135 | Regression loss: 0.25842 | Running loss: 0.31125\n",
      "Epoch: 13 | Iteration: 159 | Classification loss: 0.05967 | Regression loss: 0.23461 | Running loss: 0.31083\n",
      "Epoch: 13 | Iteration: 160 | Classification loss: 0.05056 | Regression loss: 0.24762 | Running loss: 0.31088\n",
      "Epoch: 13 | Iteration: 161 | Classification loss: 0.23953 | Regression loss: 0.14575 | Running loss: 0.31122\n",
      "Epoch: 13 | Iteration: 162 | Classification loss: 0.02091 | Regression loss: 0.16327 | Running loss: 0.31088\n",
      "Epoch: 13 | Iteration: 163 | Classification loss: 0.02291 | Regression loss: 0.12316 | Running loss: 0.31059\n",
      "Epoch: 13 | Iteration: 164 | Classification loss: 0.01064 | Regression loss: 0.10875 | Running loss: 0.31023\n",
      "Epoch: 13 | Iteration: 165 | Classification loss: 0.02988 | Regression loss: 0.17294 | Running loss: 0.30983\n",
      "Epoch: 13 | Iteration: 166 | Classification loss: 0.13964 | Regression loss: 0.19159 | Running loss: 0.30985\n",
      "Epoch: 13 | Iteration: 167 | Classification loss: 0.04841 | Regression loss: 0.13818 | Running loss: 0.30945\n",
      "Epoch: 13 | Iteration: 168 | Classification loss: 0.04228 | Regression loss: 0.16648 | Running loss: 0.30940\n",
      "Epoch: 13 | Iteration: 169 | Classification loss: 0.03058 | Regression loss: 0.22571 | Running loss: 0.30871\n",
      "Epoch: 13 | Iteration: 170 | Classification loss: 0.09984 | Regression loss: 0.26482 | Running loss: 0.30841\n",
      "Epoch: 13 | Iteration: 171 | Classification loss: 0.02816 | Regression loss: 0.18959 | Running loss: 0.30701\n",
      "Epoch: 13 | Iteration: 172 | Classification loss: 0.11708 | Regression loss: 0.14869 | Running loss: 0.30699\n",
      "Epoch: 13 | Iteration: 173 | Classification loss: 0.05644 | Regression loss: 0.20137 | Running loss: 0.30695\n",
      "Epoch: 13 | Iteration: 174 | Classification loss: 0.07106 | Regression loss: 0.23511 | Running loss: 0.30698\n",
      "Epoch: 13 | Iteration: 175 | Classification loss: 0.05641 | Regression loss: 0.20985 | Running loss: 0.30731\n",
      "Epoch: 13 | Iteration: 176 | Classification loss: 0.08389 | Regression loss: 0.21986 | Running loss: 0.30699\n",
      "Epoch: 13 | Iteration: 177 | Classification loss: 0.03309 | Regression loss: 0.15776 | Running loss: 0.30702\n",
      "Epoch: 13 | Iteration: 178 | Classification loss: 0.09361 | Regression loss: 0.22910 | Running loss: 0.30707\n",
      "Epoch: 13 | Iteration: 179 | Classification loss: 0.02444 | Regression loss: 0.10867 | Running loss: 0.30686\n",
      "Epoch: 13 | Iteration: 180 | Classification loss: 0.03271 | Regression loss: 0.16673 | Running loss: 0.30669\n",
      "Epoch: 13 | Iteration: 181 | Classification loss: 0.11295 | Regression loss: 0.20224 | Running loss: 0.30700\n",
      "Epoch: 13 | Iteration: 182 | Classification loss: 0.03828 | Regression loss: 0.22660 | Running loss: 0.30708\n",
      "Epoch: 13 | Iteration: 183 | Classification loss: 0.10103 | Regression loss: 0.28070 | Running loss: 0.30711\n",
      "Epoch: 13 | Iteration: 184 | Classification loss: 0.08647 | Regression loss: 0.12094 | Running loss: 0.30701\n",
      "Epoch: 13 | Iteration: 185 | Classification loss: 0.06590 | Regression loss: 0.29004 | Running loss: 0.30694\n",
      "Epoch: 13 | Iteration: 186 | Classification loss: 0.18701 | Regression loss: 0.19239 | Running loss: 0.30678\n",
      "Epoch: 13 | Iteration: 187 | Classification loss: 0.13654 | Regression loss: 0.07685 | Running loss: 0.30541\n",
      "Epoch: 13 | Iteration: 188 | Classification loss: 0.11863 | Regression loss: 0.19372 | Running loss: 0.30526\n",
      "Epoch: 13 | Iteration: 189 | Classification loss: 0.05363 | Regression loss: 0.27676 | Running loss: 0.30530\n",
      "Epoch: 13 | Iteration: 190 | Classification loss: 0.05612 | Regression loss: 0.21508 | Running loss: 0.30476\n",
      "Epoch: 13 | Iteration: 191 | Classification loss: 0.06590 | Regression loss: 0.13090 | Running loss: 0.30451\n",
      "Epoch: 13 | Iteration: 192 | Classification loss: 0.10828 | Regression loss: 0.27630 | Running loss: 0.30470\n",
      "Epoch: 13 | Iteration: 193 | Classification loss: 0.07112 | Regression loss: 0.24242 | Running loss: 0.30451\n",
      "Epoch: 13 | Iteration: 194 | Classification loss: 0.04123 | Regression loss: 0.17095 | Running loss: 0.30436\n",
      "Epoch: 13 | Iteration: 195 | Classification loss: 0.02864 | Regression loss: 0.11817 | Running loss: 0.30432\n",
      "Epoch: 13 | Iteration: 196 | Classification loss: 0.02896 | Regression loss: 0.13108 | Running loss: 0.30413\n",
      "Epoch: 13 | Iteration: 197 | Classification loss: 0.11910 | Regression loss: 0.19732 | Running loss: 0.30391\n",
      "Epoch: 13 | Iteration: 198 | Classification loss: 0.14972 | Regression loss: 0.13004 | Running loss: 0.30410\n",
      "Epoch: 13 | Iteration: 199 | Classification loss: 0.08981 | Regression loss: 0.20683 | Running loss: 0.30391\n",
      "Epoch: 13 | Iteration: 200 | Classification loss: 0.06698 | Regression loss: 0.24523 | Running loss: 0.30403\n",
      "Epoch: 13 | Iteration: 201 | Classification loss: 0.14856 | Regression loss: 0.35473 | Running loss: 0.30428\n",
      "Epoch: 13 | Iteration: 202 | Classification loss: 0.04300 | Regression loss: 0.20437 | Running loss: 0.30391\n",
      "Epoch: 13 | Iteration: 203 | Classification loss: 0.09103 | Regression loss: 0.28816 | Running loss: 0.30372\n",
      "Epoch: 13 | Iteration: 204 | Classification loss: 0.07627 | Regression loss: 0.28175 | Running loss: 0.30380\n",
      "Epoch: 13 | Iteration: 205 | Classification loss: 0.10014 | Regression loss: 0.36192 | Running loss: 0.30399\n",
      "Epoch: 13 | Iteration: 206 | Classification loss: 0.02441 | Regression loss: 0.03556 | Running loss: 0.30315\n",
      "Epoch: 13 | Iteration: 207 | Classification loss: 0.10511 | Regression loss: 0.32323 | Running loss: 0.30310\n",
      "Epoch: 13 | Iteration: 208 | Classification loss: 0.14370 | Regression loss: 0.14237 | Running loss: 0.30286\n",
      "Epoch: 13 | Iteration: 209 | Classification loss: 0.04362 | Regression loss: 0.18969 | Running loss: 0.30282\n",
      "Epoch: 13 | Iteration: 210 | Classification loss: 0.15249 | Regression loss: 0.34624 | Running loss: 0.30302\n",
      "Epoch: 13 | Iteration: 211 | Classification loss: 0.11926 | Regression loss: 0.21882 | Running loss: 0.30269\n",
      "Epoch: 13 | Iteration: 212 | Classification loss: 0.02623 | Regression loss: 0.23253 | Running loss: 0.30268\n",
      "Epoch: 13 | Iteration: 213 | Classification loss: 0.06317 | Regression loss: 0.23070 | Running loss: 0.30178\n",
      "Epoch: 13 | Iteration: 214 | Classification loss: 0.05992 | Regression loss: 0.16322 | Running loss: 0.30174\n",
      "Epoch: 13 | Iteration: 215 | Classification loss: 0.08584 | Regression loss: 0.26491 | Running loss: 0.30151\n",
      "Epoch: 13 | Iteration: 216 | Classification loss: 0.14433 | Regression loss: 0.12535 | Running loss: 0.30112\n",
      "Epoch: 13 | Iteration: 217 | Classification loss: 0.09322 | Regression loss: 0.31877 | Running loss: 0.30060\n",
      "Epoch: 13 | Iteration: 218 | Classification loss: 0.07496 | Regression loss: 0.26214 | Running loss: 0.30042\n",
      "Epoch: 13 | Iteration: 219 | Classification loss: 0.06372 | Regression loss: 0.17051 | Running loss: 0.29971\n",
      "Epoch: 13 | Iteration: 220 | Classification loss: 0.20803 | Regression loss: 0.13273 | Running loss: 0.30010\n",
      "Epoch: 13 | Iteration: 221 | Classification loss: 0.43981 | Regression loss: 0.33523 | Running loss: 0.30111\n",
      "Epoch: 13 | Iteration: 222 | Classification loss: 0.11676 | Regression loss: 0.26753 | Running loss: 0.30089\n",
      "Epoch: 13 | Iteration: 223 | Classification loss: 0.11084 | Regression loss: 0.24319 | Running loss: 0.30131\n",
      "Epoch: 13 | Iteration: 224 | Classification loss: 0.03080 | Regression loss: 0.22481 | Running loss: 0.30146\n",
      "Epoch: 13 | Iteration: 225 | Classification loss: 0.02984 | Regression loss: 0.15571 | Running loss: 0.30119\n",
      "Epoch: 13 | Iteration: 226 | Classification loss: 0.12901 | Regression loss: 0.19304 | Running loss: 0.30100\n",
      "Epoch: 13 | Iteration: 227 | Classification loss: 0.03475 | Regression loss: 0.13258 | Running loss: 0.30112\n",
      "Epoch: 13 | Iteration: 228 | Classification loss: 0.05240 | Regression loss: 0.23229 | Running loss: 0.29923\n",
      "Epoch: 13 | Iteration: 229 | Classification loss: 0.05061 | Regression loss: 0.14264 | Running loss: 0.29945\n",
      "Epoch: 13 | Iteration: 230 | Classification loss: 0.06432 | Regression loss: 0.19079 | Running loss: 0.29931\n",
      "Epoch: 13 | Iteration: 231 | Classification loss: 0.09972 | Regression loss: 0.18058 | Running loss: 0.29944\n",
      "Epoch: 13 | Iteration: 232 | Classification loss: 0.02858 | Regression loss: 0.18839 | Running loss: 0.29943\n",
      "Epoch: 13 | Iteration: 233 | Classification loss: 0.04347 | Regression loss: 0.18541 | Running loss: 0.29924\n",
      "Epoch: 13 | Iteration: 234 | Classification loss: 0.47593 | Regression loss: 0.24850 | Running loss: 0.30013\n",
      "Epoch: 13 | Iteration: 235 | Classification loss: 0.04104 | Regression loss: 0.21079 | Running loss: 0.30008\n",
      "Epoch: 13 | Iteration: 236 | Classification loss: 0.11630 | Regression loss: 0.13957 | Running loss: 0.30002\n",
      "Epoch: 13 | Iteration: 237 | Classification loss: 0.11723 | Regression loss: 0.39800 | Running loss: 0.30073\n",
      "Epoch: 13 | Iteration: 238 | Classification loss: 0.03736 | Regression loss: 0.20372 | Running loss: 0.29975\n",
      "Epoch: 13 | Iteration: 239 | Classification loss: 0.14854 | Regression loss: 0.28286 | Running loss: 0.30018\n",
      "Epoch: 13 | Iteration: 240 | Classification loss: 0.07987 | Regression loss: 0.13132 | Running loss: 0.30000\n",
      "Epoch: 13 | Iteration: 241 | Classification loss: 0.07234 | Regression loss: 0.41019 | Running loss: 0.30030\n",
      "Epoch: 13 | Iteration: 242 | Classification loss: 0.09979 | Regression loss: 0.25119 | Running loss: 0.30013\n",
      "Epoch: 13 | Iteration: 243 | Classification loss: 0.11623 | Regression loss: 0.19330 | Running loss: 0.30024\n",
      "Epoch: 13 | Iteration: 244 | Classification loss: 0.04922 | Regression loss: 0.18195 | Running loss: 0.29994\n",
      "Epoch: 13 | Iteration: 245 | Classification loss: 0.07429 | Regression loss: 0.16303 | Running loss: 0.29999\n",
      "Epoch: 13 | Iteration: 246 | Classification loss: 0.11363 | Regression loss: 0.37877 | Running loss: 0.30038\n",
      "Epoch: 13 | Iteration: 247 | Classification loss: 0.08913 | Regression loss: 0.11748 | Running loss: 0.30037\n",
      "Epoch: 13 | Iteration: 248 | Classification loss: 0.09386 | Regression loss: 0.14940 | Running loss: 0.29988\n",
      "Epoch: 13 | Iteration: 249 | Classification loss: 0.08486 | Regression loss: 0.25165 | Running loss: 0.30008\n",
      "Epoch: 13 | Iteration: 250 | Classification loss: 0.02432 | Regression loss: 0.19283 | Running loss: 0.29963\n",
      "Epoch: 13 | Iteration: 251 | Classification loss: 0.12505 | Regression loss: 0.38243 | Running loss: 0.30026\n",
      "Epoch: 13 | Iteration: 252 | Classification loss: 0.03223 | Regression loss: 0.23860 | Running loss: 0.29992\n",
      "Epoch: 13 | Iteration: 253 | Classification loss: 0.01343 | Regression loss: 0.13141 | Running loss: 0.29967\n",
      "Epoch: 13 | Iteration: 254 | Classification loss: 0.04561 | Regression loss: 0.15170 | Running loss: 0.29957\n",
      "Epoch: 13 | Iteration: 255 | Classification loss: 0.03310 | Regression loss: 0.08537 | Running loss: 0.29768\n",
      "Epoch: 13 | Iteration: 256 | Classification loss: 0.11350 | Regression loss: 0.23973 | Running loss: 0.29723\n",
      "Epoch: 13 | Iteration: 257 | Classification loss: 0.14986 | Regression loss: 0.15506 | Running loss: 0.29662\n",
      "Epoch: 13 | Iteration: 258 | Classification loss: 0.18957 | Regression loss: 0.58031 | Running loss: 0.29716\n",
      "Epoch: 13 | Iteration: 259 | Classification loss: 0.12871 | Regression loss: 0.16810 | Running loss: 0.29666\n",
      "Epoch: 13 | Iteration: 260 | Classification loss: 0.11480 | Regression loss: 0.34396 | Running loss: 0.29681\n",
      "Epoch: 13 | Iteration: 261 | Classification loss: 0.01961 | Regression loss: 0.16453 | Running loss: 0.29677\n",
      "Epoch: 13 | Iteration: 262 | Classification loss: 0.08043 | Regression loss: 0.11725 | Running loss: 0.29663\n",
      "Epoch: 13 | Iteration: 263 | Classification loss: 0.08136 | Regression loss: 0.20368 | Running loss: 0.29693\n",
      "Epoch: 13 | Iteration: 264 | Classification loss: 0.04153 | Regression loss: 0.11549 | Running loss: 0.29670\n",
      "Epoch: 13 | Iteration: 265 | Classification loss: 0.24869 | Regression loss: 0.24507 | Running loss: 0.29640\n",
      "Epoch: 13 | Iteration: 266 | Classification loss: 0.07124 | Regression loss: 0.13944 | Running loss: 0.29618\n",
      "Epoch: 13 | Iteration: 267 | Classification loss: 0.13326 | Regression loss: 0.45858 | Running loss: 0.29695\n",
      "Epoch: 13 | Iteration: 268 | Classification loss: 0.10898 | Regression loss: 0.28891 | Running loss: 0.29684\n",
      "Epoch: 13 | Iteration: 269 | Classification loss: 0.03954 | Regression loss: 0.17877 | Running loss: 0.29667\n",
      "Epoch: 13 | Iteration: 270 | Classification loss: 0.08518 | Regression loss: 0.16429 | Running loss: 0.29657\n",
      "Epoch: 13 | Iteration: 271 | Classification loss: 0.03692 | Regression loss: 0.17559 | Running loss: 0.29649\n",
      "Epoch: 13 | Iteration: 272 | Classification loss: 0.04365 | Regression loss: 0.31678 | Running loss: 0.29566\n",
      "Epoch: 13 | Iteration: 273 | Classification loss: 0.08166 | Regression loss: 0.25806 | Running loss: 0.29555\n",
      "Epoch: 13 | Iteration: 274 | Classification loss: 0.38225 | Regression loss: 0.18328 | Running loss: 0.29573\n",
      "Epoch: 13 | Iteration: 275 | Classification loss: 0.09785 | Regression loss: 0.30104 | Running loss: 0.29602\n",
      "Epoch: 13 | Iteration: 276 | Classification loss: 0.04802 | Regression loss: 0.19211 | Running loss: 0.29588\n",
      "Epoch: 13 | Iteration: 277 | Classification loss: 0.06345 | Regression loss: 0.18780 | Running loss: 0.29589\n",
      "Epoch: 13 | Iteration: 278 | Classification loss: 0.17356 | Regression loss: 0.21670 | Running loss: 0.29620\n",
      "Epoch: 13 | Iteration: 279 | Classification loss: 0.16389 | Regression loss: 0.26818 | Running loss: 0.29659\n",
      "Epoch: 13 | Iteration: 280 | Classification loss: 0.05670 | Regression loss: 0.20733 | Running loss: 0.29666\n",
      "Epoch: 13 | Iteration: 281 | Classification loss: 0.23343 | Regression loss: 0.15942 | Running loss: 0.29710\n",
      "Epoch: 13 | Iteration: 282 | Classification loss: 0.04067 | Regression loss: 0.18057 | Running loss: 0.29687\n",
      "Epoch: 13 | Iteration: 283 | Classification loss: 0.06572 | Regression loss: 0.17548 | Running loss: 0.29668\n",
      "Epoch: 13 | Iteration: 284 | Classification loss: 0.02962 | Regression loss: 0.15198 | Running loss: 0.29678\n",
      "Epoch: 13 | Iteration: 285 | Classification loss: 0.03309 | Regression loss: 0.14270 | Running loss: 0.29681\n",
      "Epoch: 13 | Iteration: 286 | Classification loss: 0.13905 | Regression loss: 0.30257 | Running loss: 0.29702\n",
      "Epoch: 13 | Iteration: 287 | Classification loss: 0.02569 | Regression loss: 0.10409 | Running loss: 0.29678\n",
      "Epoch: 13 | Iteration: 288 | Classification loss: 0.13808 | Regression loss: 0.27747 | Running loss: 0.29687\n",
      "Epoch: 13 | Iteration: 289 | Classification loss: 0.10305 | Regression loss: 0.20909 | Running loss: 0.29634\n",
      "Epoch: 13 | Iteration: 290 | Classification loss: 0.08396 | Regression loss: 0.30672 | Running loss: 0.29679\n",
      "Epoch: 13 | Iteration: 291 | Classification loss: 0.03206 | Regression loss: 0.25503 | Running loss: 0.29688\n",
      "Epoch: 13 | Iteration: 292 | Classification loss: 0.01203 | Regression loss: 0.08977 | Running loss: 0.29652\n",
      "Epoch: 13 | Iteration: 293 | Classification loss: 0.06985 | Regression loss: 0.18286 | Running loss: 0.29618\n",
      "Epoch: 13 | Iteration: 294 | Classification loss: 0.08181 | Regression loss: 0.12586 | Running loss: 0.29623\n",
      "Epoch: 13 | Iteration: 295 | Classification loss: 0.04912 | Regression loss: 0.23687 | Running loss: 0.29665\n",
      "Epoch: 13 | Iteration: 296 | Classification loss: 0.06670 | Regression loss: 0.10494 | Running loss: 0.29629\n",
      "Epoch: 13 | Iteration: 297 | Classification loss: 0.07791 | Regression loss: 0.18946 | Running loss: 0.29575\n",
      "Epoch: 13 | Iteration: 298 | Classification loss: 0.09537 | Regression loss: 0.30777 | Running loss: 0.29593\n",
      "Epoch: 13 | Iteration: 299 | Classification loss: 0.22870 | Regression loss: 0.17346 | Running loss: 0.29624\n",
      "Epoch: 13 | Iteration: 300 | Classification loss: 0.23647 | Regression loss: 0.16450 | Running loss: 0.29630\n",
      "Epoch: 13 | Iteration: 301 | Classification loss: 0.07640 | Regression loss: 0.20481 | Running loss: 0.29527\n",
      "Epoch: 13 | Iteration: 302 | Classification loss: 0.05609 | Regression loss: 0.21418 | Running loss: 0.29505\n",
      "Epoch: 13 | Iteration: 303 | Classification loss: 0.02306 | Regression loss: 0.25687 | Running loss: 0.29428\n",
      "Epoch: 13 | Iteration: 304 | Classification loss: 0.32888 | Regression loss: 0.46295 | Running loss: 0.29523\n",
      "Epoch: 13 | Iteration: 305 | Classification loss: 0.01569 | Regression loss: 0.11467 | Running loss: 0.29496\n",
      "Epoch: 13 | Iteration: 306 | Classification loss: 0.06799 | Regression loss: 0.17500 | Running loss: 0.29504\n",
      "Epoch: 13 | Iteration: 307 | Classification loss: 0.02950 | Regression loss: 0.17439 | Running loss: 0.29490\n",
      "Epoch: 13 | Iteration: 308 | Classification loss: 0.11118 | Regression loss: 0.34414 | Running loss: 0.29520\n",
      "Epoch: 13 | Iteration: 309 | Classification loss: 0.10360 | Regression loss: 0.35029 | Running loss: 0.29544\n",
      "Epoch: 13 | Iteration: 310 | Classification loss: 0.04983 | Regression loss: 0.30284 | Running loss: 0.29535\n",
      "Epoch: 13 | Iteration: 311 | Classification loss: 0.04811 | Regression loss: 0.14245 | Running loss: 0.29526\n",
      "Epoch: 13 | Iteration: 312 | Classification loss: 0.07084 | Regression loss: 0.21393 | Running loss: 0.29535\n",
      "Epoch: 13 | Iteration: 313 | Classification loss: 0.07215 | Regression loss: 0.16052 | Running loss: 0.29507\n",
      "Epoch: 13 | Iteration: 314 | Classification loss: 0.05417 | Regression loss: 0.15205 | Running loss: 0.29505\n",
      "Epoch: 13 | Iteration: 315 | Classification loss: 0.04037 | Regression loss: 0.27715 | Running loss: 0.29490\n",
      "Epoch: 13 | Iteration: 316 | Classification loss: 0.10207 | Regression loss: 0.17476 | Running loss: 0.29492\n",
      "Epoch: 13 | Iteration: 317 | Classification loss: 0.06141 | Regression loss: 0.11120 | Running loss: 0.29488\n",
      "Epoch: 13 | Iteration: 318 | Classification loss: 0.23457 | Regression loss: 0.13450 | Running loss: 0.29505\n",
      "Epoch: 13 | Iteration: 319 | Classification loss: 0.03478 | Regression loss: 0.26842 | Running loss: 0.29521\n",
      "Epoch: 13 | Iteration: 320 | Classification loss: 0.15824 | Regression loss: 0.35031 | Running loss: 0.29579\n",
      "Epoch: 13 | Iteration: 321 | Classification loss: 0.09023 | Regression loss: 0.17911 | Running loss: 0.29583\n",
      "Epoch: 13 | Iteration: 322 | Classification loss: 0.03955 | Regression loss: 0.26088 | Running loss: 0.29499\n",
      "Epoch: 13 | Iteration: 323 | Classification loss: 0.15458 | Regression loss: 0.22636 | Running loss: 0.29554\n",
      "Epoch: 13 | Iteration: 324 | Classification loss: 0.05722 | Regression loss: 0.22072 | Running loss: 0.29566\n",
      "Epoch: 13 | Iteration: 325 | Classification loss: 0.10723 | Regression loss: 0.28584 | Running loss: 0.29597\n",
      "Epoch: 13 | Iteration: 326 | Classification loss: 0.02877 | Regression loss: 0.13332 | Running loss: 0.29576\n",
      "Epoch: 13 | Iteration: 327 | Classification loss: 0.05591 | Regression loss: 0.22012 | Running loss: 0.29578\n",
      "Epoch: 13 | Iteration: 328 | Classification loss: 0.04026 | Regression loss: 0.24194 | Running loss: 0.29578\n",
      "Epoch: 13 | Iteration: 329 | Classification loss: 0.02695 | Regression loss: 0.09523 | Running loss: 0.29549\n",
      "Epoch: 13 | Iteration: 330 | Classification loss: 0.04592 | Regression loss: 0.15957 | Running loss: 0.29540\n",
      "Epoch: 13 | Iteration: 331 | Classification loss: 0.19279 | Regression loss: 0.43390 | Running loss: 0.29622\n",
      "Epoch: 13 | Iteration: 332 | Classification loss: 0.10358 | Regression loss: 0.29298 | Running loss: 0.29679\n",
      "Epoch: 13 | Iteration: 333 | Classification loss: 0.02953 | Regression loss: 0.12638 | Running loss: 0.29687\n",
      "Epoch: 13 | Iteration: 334 | Classification loss: 0.01398 | Regression loss: 0.14956 | Running loss: 0.29684\n",
      "Epoch: 13 | Iteration: 335 | Classification loss: 0.03706 | Regression loss: 0.23896 | Running loss: 0.29667\n",
      "Epoch: 13 | Iteration: 336 | Classification loss: 0.23616 | Regression loss: 0.58028 | Running loss: 0.29791\n",
      "Epoch: 13 | Iteration: 337 | Classification loss: 0.32105 | Regression loss: 0.33127 | Running loss: 0.29876\n",
      "Epoch: 13 | Iteration: 338 | Classification loss: 0.18934 | Regression loss: 0.12992 | Running loss: 0.29830\n",
      "Epoch: 13 | Iteration: 339 | Classification loss: 0.02974 | Regression loss: 0.12248 | Running loss: 0.29835\n",
      "Epoch: 13 | Iteration: 340 | Classification loss: 0.04513 | Regression loss: 0.18563 | Running loss: 0.29809\n",
      "Epoch: 13 | Iteration: 341 | Classification loss: 0.02452 | Regression loss: 0.22139 | Running loss: 0.29797\n",
      "Epoch: 13 | Iteration: 342 | Classification loss: 0.05453 | Regression loss: 0.16787 | Running loss: 0.29808\n",
      "Epoch: 13 | Iteration: 343 | Classification loss: 0.06526 | Regression loss: 0.20807 | Running loss: 0.29721\n",
      "Epoch: 13 | Iteration: 344 | Classification loss: 0.04833 | Regression loss: 0.10243 | Running loss: 0.29717\n",
      "Epoch: 13 | Iteration: 345 | Classification loss: 0.22324 | Regression loss: 0.41064 | Running loss: 0.29776\n",
      "Epoch: 13 | Iteration: 346 | Classification loss: 0.03919 | Regression loss: 0.10313 | Running loss: 0.29767\n",
      "Epoch: 13 | Iteration: 347 | Classification loss: 0.03129 | Regression loss: 0.14325 | Running loss: 0.29764\n",
      "Epoch: 13 | Iteration: 348 | Classification loss: 0.03727 | Regression loss: 0.20890 | Running loss: 0.29748\n",
      "Epoch: 13 | Iteration: 349 | Classification loss: 0.06551 | Regression loss: 0.10648 | Running loss: 0.29711\n",
      "Epoch: 13 | Iteration: 350 | Classification loss: 0.07834 | Regression loss: 0.43686 | Running loss: 0.29744\n",
      "Epoch: 13 | Iteration: 351 | Classification loss: 0.04677 | Regression loss: 0.08028 | Running loss: 0.29731\n",
      "Epoch: 13 | Iteration: 352 | Classification loss: 0.17212 | Regression loss: 0.52113 | Running loss: 0.29785\n",
      "Epoch: 13 | Iteration: 353 | Classification loss: 0.09780 | Regression loss: 0.20482 | Running loss: 0.29812\n",
      "Epoch: 13 | Iteration: 354 | Classification loss: 0.10180 | Regression loss: 0.29457 | Running loss: 0.29847\n",
      "Epoch: 13 | Iteration: 355 | Classification loss: 0.05237 | Regression loss: 0.16216 | Running loss: 0.29852\n",
      "Epoch: 13 | Iteration: 356 | Classification loss: 0.05362 | Regression loss: 0.24840 | Running loss: 0.29871\n",
      "Epoch: 13 | Iteration: 357 | Classification loss: 0.14735 | Regression loss: 0.18661 | Running loss: 0.29873\n",
      "Epoch: 13 | Iteration: 358 | Classification loss: 0.02339 | Regression loss: 0.19635 | Running loss: 0.29844\n",
      "Epoch: 13 | Iteration: 359 | Classification loss: 0.04780 | Regression loss: 0.20559 | Running loss: 0.29838\n",
      "Epoch: 13 | Iteration: 360 | Classification loss: 0.11021 | Regression loss: 0.19502 | Running loss: 0.29849\n",
      "Epoch: 13 | Iteration: 361 | Classification loss: 0.03761 | Regression loss: 0.12705 | Running loss: 0.29827\n",
      "Epoch: 13 | Iteration: 362 | Classification loss: 0.05088 | Regression loss: 0.25278 | Running loss: 0.29857\n",
      "Epoch: 13 | Iteration: 363 | Classification loss: 0.18748 | Regression loss: 0.45339 | Running loss: 0.29929\n",
      "Epoch: 13 | Iteration: 364 | Classification loss: 0.09215 | Regression loss: 0.14557 | Running loss: 0.29955\n",
      "Epoch: 13 | Iteration: 365 | Classification loss: 0.03683 | Regression loss: 0.20755 | Running loss: 0.29969\n",
      "Epoch: 13 | Iteration: 366 | Classification loss: 0.03051 | Regression loss: 0.15485 | Running loss: 0.29967\n",
      "Epoch: 13 | Iteration: 367 | Classification loss: 0.03340 | Regression loss: 0.20742 | Running loss: 0.29953\n",
      "Epoch: 13 | Iteration: 368 | Classification loss: 0.29418 | Regression loss: 0.42107 | Running loss: 0.30021\n",
      "Epoch: 13 | Iteration: 369 | Classification loss: 0.11020 | Regression loss: 0.30028 | Running loss: 0.30022\n",
      "Epoch: 13 | Iteration: 370 | Classification loss: 0.03729 | Regression loss: 0.19875 | Running loss: 0.29971\n",
      "Epoch: 13 | Iteration: 371 | Classification loss: 0.07967 | Regression loss: 0.39073 | Running loss: 0.29993\n",
      "Epoch: 13 | Iteration: 372 | Classification loss: 0.17260 | Regression loss: 0.39456 | Running loss: 0.30052\n",
      "Epoch: 13 | Iteration: 373 | Classification loss: 0.03272 | Regression loss: 0.12438 | Running loss: 0.30026\n",
      "Epoch: 13 | Iteration: 374 | Classification loss: 0.05523 | Regression loss: 0.27927 | Running loss: 0.30003\n",
      "Epoch: 13 | Iteration: 375 | Classification loss: 0.09615 | Regression loss: 0.17440 | Running loss: 0.29994\n",
      "Epoch: 13 | Iteration: 376 | Classification loss: 0.03450 | Regression loss: 0.24733 | Running loss: 0.29947\n",
      "Epoch: 13 | Iteration: 377 | Classification loss: 0.08583 | Regression loss: 0.07816 | Running loss: 0.29924\n",
      "Epoch: 13 | Iteration: 378 | Classification loss: 0.01720 | Regression loss: 0.07843 | Running loss: 0.29881\n",
      "Epoch: 13 | Iteration: 379 | Classification loss: 0.09610 | Regression loss: 0.21629 | Running loss: 0.29874\n",
      "Epoch: 13 | Iteration: 380 | Classification loss: 0.05974 | Regression loss: 0.18189 | Running loss: 0.29894\n",
      "Epoch: 13 | Iteration: 381 | Classification loss: 0.03267 | Regression loss: 0.12114 | Running loss: 0.29856\n",
      "Epoch: 13 | Iteration: 382 | Classification loss: 0.02334 | Regression loss: 0.11343 | Running loss: 0.29822\n",
      "Epoch: 13 | Iteration: 383 | Classification loss: 0.06810 | Regression loss: 0.30369 | Running loss: 0.29849\n",
      "Epoch: 13 | Iteration: 384 | Classification loss: 0.02828 | Regression loss: 0.23365 | Running loss: 0.29778\n",
      "Epoch: 13 | Iteration: 385 | Classification loss: 0.04760 | Regression loss: 0.22449 | Running loss: 0.29790\n",
      "Epoch: 13 | Iteration: 386 | Classification loss: 0.08658 | Regression loss: 0.30832 | Running loss: 0.29829\n",
      "Epoch: 13 | Iteration: 387 | Classification loss: 0.02945 | Regression loss: 0.05030 | Running loss: 0.29752\n",
      "Epoch: 13 | Iteration: 388 | Classification loss: 0.07746 | Regression loss: 0.30845 | Running loss: 0.29757\n",
      "Epoch: 13 | Iteration: 389 | Classification loss: 0.02607 | Regression loss: 0.09169 | Running loss: 0.29717\n",
      "Epoch: 13 | Iteration: 390 | Classification loss: 0.05485 | Regression loss: 0.23086 | Running loss: 0.29711\n",
      "Epoch: 13 | Iteration: 391 | Classification loss: 0.08651 | Regression loss: 0.21631 | Running loss: 0.29705\n",
      "Epoch: 13 | Iteration: 392 | Classification loss: 0.10365 | Regression loss: 0.15679 | Running loss: 0.29653\n",
      "Epoch: 13 | Iteration: 393 | Classification loss: 0.04382 | Regression loss: 0.04755 | Running loss: 0.29540\n",
      "Epoch: 13 | Iteration: 394 | Classification loss: 0.09489 | Regression loss: 0.18932 | Running loss: 0.29523\n",
      "Epoch: 13 | Iteration: 395 | Classification loss: 0.08089 | Regression loss: 0.28733 | Running loss: 0.29559\n",
      "Epoch: 13 | Iteration: 396 | Classification loss: 0.06971 | Regression loss: 0.22809 | Running loss: 0.29558\n",
      "Epoch: 13 | Iteration: 397 | Classification loss: 0.07877 | Regression loss: 0.18397 | Running loss: 0.29582\n",
      "Epoch: 13 | Iteration: 398 | Classification loss: 0.09362 | Regression loss: 0.22758 | Running loss: 0.29556\n",
      "Epoch: 13 | Iteration: 399 | Classification loss: 0.05357 | Regression loss: 0.29098 | Running loss: 0.29586\n",
      "Epoch: 13 | Iteration: 400 | Classification loss: 0.03969 | Regression loss: 0.21763 | Running loss: 0.29601\n",
      "Epoch: 13 | Iteration: 401 | Classification loss: 0.01907 | Regression loss: 0.09416 | Running loss: 0.29530\n",
      "Epoch: 13 | Iteration: 402 | Classification loss: 0.14767 | Regression loss: 0.50216 | Running loss: 0.29588\n",
      "Epoch: 13 | Iteration: 403 | Classification loss: 0.13326 | Regression loss: 0.40994 | Running loss: 0.29668\n",
      "Epoch: 13 | Iteration: 404 | Classification loss: 0.04346 | Regression loss: 0.36838 | Running loss: 0.29706\n",
      "Epoch: 13 | Iteration: 405 | Classification loss: 0.04184 | Regression loss: 0.09635 | Running loss: 0.29663\n",
      "Epoch: 13 | Iteration: 406 | Classification loss: 0.03051 | Regression loss: 0.18197 | Running loss: 0.29669\n",
      "Epoch: 13 | Iteration: 407 | Classification loss: 0.05663 | Regression loss: 0.23252 | Running loss: 0.29641\n",
      "Epoch: 13 | Iteration: 408 | Classification loss: 0.10071 | Regression loss: 0.21259 | Running loss: 0.29645\n",
      "Epoch: 13 | Iteration: 409 | Classification loss: 0.18280 | Regression loss: 0.25123 | Running loss: 0.29668\n",
      "Epoch: 13 | Iteration: 410 | Classification loss: 0.10563 | Regression loss: 0.15676 | Running loss: 0.29610\n",
      "Epoch: 13 | Iteration: 411 | Classification loss: 0.02129 | Regression loss: 0.15824 | Running loss: 0.29592\n",
      "Epoch: 13 | Iteration: 412 | Classification loss: 0.02104 | Regression loss: 0.15469 | Running loss: 0.29550\n",
      "Epoch: 13 | Iteration: 413 | Classification loss: 0.04136 | Regression loss: 0.19520 | Running loss: 0.29567\n",
      "Epoch: 13 | Iteration: 414 | Classification loss: 0.02803 | Regression loss: 0.13430 | Running loss: 0.29566\n",
      "Epoch: 13 | Iteration: 415 | Classification loss: 0.12655 | Regression loss: 0.11814 | Running loss: 0.29581\n",
      "Epoch: 13 | Iteration: 416 | Classification loss: 0.06176 | Regression loss: 0.19348 | Running loss: 0.29600\n",
      "Epoch: 13 | Iteration: 417 | Classification loss: 0.28249 | Regression loss: 0.47869 | Running loss: 0.29669\n",
      "Epoch: 13 | Iteration: 418 | Classification loss: 0.05778 | Regression loss: 0.22513 | Running loss: 0.29692\n",
      "Epoch: 13 | Iteration: 419 | Classification loss: 0.13965 | Regression loss: 0.19713 | Running loss: 0.29710\n",
      "Epoch: 13 | Iteration: 420 | Classification loss: 0.14324 | Regression loss: 0.25042 | Running loss: 0.29707\n",
      "Epoch: 13 | Iteration: 421 | Classification loss: 0.05025 | Regression loss: 0.23218 | Running loss: 0.29718\n",
      "Epoch: 13 | Iteration: 422 | Classification loss: 0.11557 | Regression loss: 0.23854 | Running loss: 0.29730\n",
      "Epoch: 13 | Iteration: 423 | Classification loss: 0.06333 | Regression loss: 0.22414 | Running loss: 0.29742\n",
      "Epoch: 13 | Iteration: 424 | Classification loss: 0.07995 | Regression loss: 0.26517 | Running loss: 0.29755\n",
      "Epoch: 13 | Iteration: 425 | Classification loss: 0.05260 | Regression loss: 0.15461 | Running loss: 0.29724\n",
      "Epoch: 13 | Iteration: 426 | Classification loss: 0.03359 | Regression loss: 0.16029 | Running loss: 0.29720\n",
      "Epoch: 13 | Iteration: 427 | Classification loss: 0.05169 | Regression loss: 0.10130 | Running loss: 0.29699\n",
      "Epoch: 13 | Iteration: 428 | Classification loss: 0.05631 | Regression loss: 0.18038 | Running loss: 0.29693\n",
      "Epoch: 13 | Iteration: 429 | Classification loss: 0.09085 | Regression loss: 0.22792 | Running loss: 0.29712\n",
      "Epoch: 13 | Iteration: 430 | Classification loss: 0.02954 | Regression loss: 0.14743 | Running loss: 0.29716\n",
      "Epoch: 13 | Iteration: 431 | Classification loss: 0.02076 | Regression loss: 0.20021 | Running loss: 0.29694\n",
      "Epoch: 13 | Iteration: 432 | Classification loss: 0.02725 | Regression loss: 0.05289 | Running loss: 0.29639\n",
      "Epoch: 13 | Iteration: 433 | Classification loss: 0.09369 | Regression loss: 0.22241 | Running loss: 0.29636\n",
      "Epoch: 13 | Iteration: 434 | Classification loss: 0.04017 | Regression loss: 0.18055 | Running loss: 0.29621\n",
      "Epoch: 13 | Iteration: 435 | Classification loss: 0.04499 | Regression loss: 0.13498 | Running loss: 0.29604\n",
      "Epoch: 13 | Iteration: 436 | Classification loss: 0.10659 | Regression loss: 0.21597 | Running loss: 0.29633\n",
      "Epoch: 13 | Iteration: 437 | Classification loss: 0.06449 | Regression loss: 0.17109 | Running loss: 0.29624\n",
      "Epoch: 13 | Iteration: 438 | Classification loss: 0.13256 | Regression loss: 0.37605 | Running loss: 0.29653\n",
      "Epoch: 13 | Iteration: 439 | Classification loss: 0.13439 | Regression loss: 0.22108 | Running loss: 0.29654\n",
      "Epoch: 13 | Iteration: 440 | Classification loss: 0.09303 | Regression loss: 0.23440 | Running loss: 0.29667\n",
      "Epoch: 13 | Iteration: 441 | Classification loss: 0.02354 | Regression loss: 0.21719 | Running loss: 0.29677\n",
      "Epoch: 13 | Iteration: 442 | Classification loss: 0.03248 | Regression loss: 0.12400 | Running loss: 0.29654\n",
      "Epoch: 13 | Iteration: 443 | Classification loss: 0.02497 | Regression loss: 0.15658 | Running loss: 0.29650\n",
      "Epoch: 13 | Iteration: 444 | Classification loss: 0.02980 | Regression loss: 0.15250 | Running loss: 0.29584\n",
      "Epoch: 13 | Iteration: 445 | Classification loss: 0.06180 | Regression loss: 0.25430 | Running loss: 0.29619\n",
      "Epoch: 13 | Iteration: 446 | Classification loss: 0.05333 | Regression loss: 0.14742 | Running loss: 0.29627\n",
      "Epoch: 13 | Iteration: 447 | Classification loss: 0.07926 | Regression loss: 0.18723 | Running loss: 0.29621\n",
      "Epoch: 13 | Iteration: 448 | Classification loss: 0.07818 | Regression loss: 0.18619 | Running loss: 0.29643\n",
      "Epoch: 13 | Iteration: 449 | Classification loss: 0.08642 | Regression loss: 0.22165 | Running loss: 0.29656\n",
      "Epoch: 13 | Iteration: 450 | Classification loss: 0.00771 | Regression loss: 0.08885 | Running loss: 0.29596\n",
      "Epoch: 13 | Iteration: 451 | Classification loss: 0.02765 | Regression loss: 0.16423 | Running loss: 0.29571\n",
      "Epoch: 13 | Iteration: 452 | Classification loss: 0.02839 | Regression loss: 0.16321 | Running loss: 0.29553\n",
      "Epoch: 13 | Iteration: 453 | Classification loss: 0.02749 | Regression loss: 0.28158 | Running loss: 0.29576\n",
      "Epoch: 13 | Iteration: 454 | Classification loss: 0.05728 | Regression loss: 0.18479 | Running loss: 0.29554\n",
      "Epoch: 13 | Iteration: 455 | Classification loss: 0.19774 | Regression loss: 0.29637 | Running loss: 0.29601\n",
      "Epoch: 13 | Iteration: 456 | Classification loss: 0.03154 | Regression loss: 0.24565 | Running loss: 0.29624\n",
      "Epoch: 13 | Iteration: 457 | Classification loss: 0.02585 | Regression loss: 0.09794 | Running loss: 0.29620\n",
      "Epoch: 13 | Iteration: 458 | Classification loss: 0.02030 | Regression loss: 0.14945 | Running loss: 0.29539\n",
      "Epoch: 13 | Iteration: 459 | Classification loss: 0.03193 | Regression loss: 0.19647 | Running loss: 0.29533\n",
      "Epoch: 13 | Iteration: 460 | Classification loss: 0.01810 | Regression loss: 0.19094 | Running loss: 0.29526\n",
      "Epoch: 13 | Iteration: 461 | Classification loss: 0.04842 | Regression loss: 0.32520 | Running loss: 0.29567\n",
      "Epoch: 13 | Iteration: 462 | Classification loss: 0.03836 | Regression loss: 0.17094 | Running loss: 0.29570\n",
      "Epoch: 13 | Iteration: 463 | Classification loss: 0.15929 | Regression loss: 0.46600 | Running loss: 0.29642\n",
      "Epoch: 13 | Iteration: 464 | Classification loss: 0.03709 | Regression loss: 0.15333 | Running loss: 0.29574\n",
      "Epoch: 13 | Iteration: 465 | Classification loss: 0.09343 | Regression loss: 0.16993 | Running loss: 0.29603\n",
      "Epoch: 13 | Iteration: 466 | Classification loss: 0.16393 | Regression loss: 0.44911 | Running loss: 0.29672\n",
      "Epoch: 13 | Iteration: 467 | Classification loss: 0.03935 | Regression loss: 0.26773 | Running loss: 0.29704\n",
      "Epoch: 13 | Iteration: 468 | Classification loss: 0.11001 | Regression loss: 0.22360 | Running loss: 0.29674\n",
      "Epoch: 13 | Iteration: 469 | Classification loss: 0.04930 | Regression loss: 0.25279 | Running loss: 0.29671\n",
      "Epoch: 13 | Iteration: 470 | Classification loss: 0.06452 | Regression loss: 0.21244 | Running loss: 0.29630\n",
      "Epoch: 13 | Iteration: 471 | Classification loss: 0.06515 | Regression loss: 0.08497 | Running loss: 0.29630\n",
      "Epoch: 13 | Iteration: 472 | Classification loss: 0.23699 | Regression loss: 0.27618 | Running loss: 0.29666\n",
      "Epoch: 13 | Iteration: 473 | Classification loss: 0.07121 | Regression loss: 0.11036 | Running loss: 0.29610\n",
      "Epoch: 13 | Iteration: 474 | Classification loss: 0.05494 | Regression loss: 0.13535 | Running loss: 0.29577\n",
      "Epoch: 13 | Iteration: 475 | Classification loss: 0.13306 | Regression loss: 0.32171 | Running loss: 0.29649\n",
      "Epoch: 13 | Iteration: 476 | Classification loss: 0.07472 | Regression loss: 0.19490 | Running loss: 0.29643\n",
      "Epoch: 13 | Iteration: 477 | Classification loss: 0.04245 | Regression loss: 0.22045 | Running loss: 0.29622\n",
      "Epoch: 13 | Iteration: 478 | Classification loss: 0.06299 | Regression loss: 0.23688 | Running loss: 0.29642\n",
      "Epoch: 13 | Iteration: 479 | Classification loss: 0.13444 | Regression loss: 0.30461 | Running loss: 0.29696\n",
      "Epoch: 13 | Iteration: 480 | Classification loss: 0.09770 | Regression loss: 0.32947 | Running loss: 0.29683\n",
      "Epoch: 13 | Iteration: 481 | Classification loss: 0.20163 | Regression loss: 0.18708 | Running loss: 0.29689\n",
      "Epoch: 13 | Iteration: 482 | Classification loss: 0.20779 | Regression loss: 0.43131 | Running loss: 0.29790\n",
      "Epoch: 13 | Iteration: 483 | Classification loss: 0.07429 | Regression loss: 0.28537 | Running loss: 0.29806\n",
      "Epoch: 13 | Iteration: 484 | Classification loss: 0.39646 | Regression loss: 0.17852 | Running loss: 0.29888\n",
      "Epoch: 13 | Iteration: 485 | Classification loss: 0.01232 | Regression loss: 0.11813 | Running loss: 0.29889\n",
      "Epoch: 13 | Iteration: 486 | Classification loss: 0.06665 | Regression loss: 0.11910 | Running loss: 0.29803\n",
      "Epoch: 13 | Iteration: 487 | Classification loss: 0.12458 | Regression loss: 0.33331 | Running loss: 0.29854\n",
      "Epoch: 13 | Iteration: 488 | Classification loss: 0.09155 | Regression loss: 0.16888 | Running loss: 0.29853\n",
      "Epoch: 13 | Iteration: 489 | Classification loss: 0.06335 | Regression loss: 0.27339 | Running loss: 0.29854\n",
      "Epoch: 13 | Iteration: 490 | Classification loss: 0.02759 | Regression loss: 0.14413 | Running loss: 0.29867\n",
      "Epoch: 13 | Iteration: 491 | Classification loss: 0.07946 | Regression loss: 0.12258 | Running loss: 0.29817\n",
      "Epoch: 13 | Iteration: 492 | Classification loss: 0.10800 | Regression loss: 0.15659 | Running loss: 0.29781\n",
      "Epoch: 13 | Iteration: 493 | Classification loss: 0.03600 | Regression loss: 0.16516 | Running loss: 0.29743\n",
      "Epoch: 13 | Iteration: 494 | Classification loss: 0.13006 | Regression loss: 0.56054 | Running loss: 0.29837\n",
      "Epoch: 13 | Iteration: 495 | Classification loss: 0.03187 | Regression loss: 0.12954 | Running loss: 0.29772\n",
      "Epoch: 13 | Iteration: 496 | Classification loss: 0.02137 | Regression loss: 0.15668 | Running loss: 0.29726\n",
      "Epoch: 13 | Iteration: 497 | Classification loss: 0.01204 | Regression loss: 0.13749 | Running loss: 0.29715\n",
      "Epoch: 13 | Iteration: 498 | Classification loss: 0.02668 | Regression loss: 0.11873 | Running loss: 0.29698\n",
      "Epoch: 13 | Iteration: 499 | Classification loss: 0.00996 | Regression loss: 0.13597 | Running loss: 0.29571\n",
      "Epoch: 13 | Iteration: 500 | Classification loss: 0.05181 | Regression loss: 0.19941 | Running loss: 0.29593\n",
      "Epoch: 13 | Iteration: 501 | Classification loss: 0.07849 | Regression loss: 0.32239 | Running loss: 0.29607\n",
      "Epoch: 13 | Iteration: 502 | Classification loss: 0.09771 | Regression loss: 0.13583 | Running loss: 0.29618\n",
      "Epoch: 13 | Iteration: 503 | Classification loss: 0.08306 | Regression loss: 0.22587 | Running loss: 0.29626\n",
      "Epoch: 13 | Iteration: 504 | Classification loss: 0.16574 | Regression loss: 0.15276 | Running loss: 0.29624\n",
      "Epoch: 13 | Iteration: 505 | Classification loss: 0.05127 | Regression loss: 0.21601 | Running loss: 0.29628\n",
      "Epoch: 13 | Iteration: 506 | Classification loss: 0.22494 | Regression loss: 0.38821 | Running loss: 0.29711\n",
      "Epoch: 13 | Iteration: 507 | Classification loss: 0.06087 | Regression loss: 0.21824 | Running loss: 0.29731\n",
      "Epoch: 13 | Iteration: 508 | Classification loss: 0.02509 | Regression loss: 0.09598 | Running loss: 0.29727\n",
      "Epoch: 13 | Iteration: 509 | Classification loss: 0.23860 | Regression loss: 0.15090 | Running loss: 0.29787\n",
      "Epoch: 13 | Iteration: 510 | Classification loss: 0.03426 | Regression loss: 0.10038 | Running loss: 0.29774\n",
      "Epoch: 13 | Iteration: 511 | Classification loss: 0.01108 | Regression loss: 0.13317 | Running loss: 0.29742\n",
      "Epoch: 13 | Iteration: 512 | Classification loss: 0.02038 | Regression loss: 0.09121 | Running loss: 0.29725\n",
      "Epoch: 13 | Iteration: 513 | Classification loss: 0.11318 | Regression loss: 0.15233 | Running loss: 0.29682\n",
      "Epoch: 13 | Iteration: 514 | Classification loss: 0.01563 | Regression loss: 0.13304 | Running loss: 0.29622\n",
      "Epoch: 13 | Iteration: 515 | Classification loss: 0.16084 | Regression loss: 0.17100 | Running loss: 0.29619\n",
      "Epoch: 13 | Iteration: 516 | Classification loss: 0.02780 | Regression loss: 0.19279 | Running loss: 0.29630\n",
      "Epoch: 13 | Iteration: 517 | Classification loss: 0.18664 | Regression loss: 0.18950 | Running loss: 0.29672\n",
      "Epoch: 13 | Iteration: 518 | Classification loss: 0.13893 | Regression loss: 0.22437 | Running loss: 0.29680\n",
      "Epoch: 13 | Iteration: 519 | Classification loss: 0.04260 | Regression loss: 0.28147 | Running loss: 0.29705\n",
      "Epoch: 13 | Iteration: 520 | Classification loss: 0.05873 | Regression loss: 0.19245 | Running loss: 0.29715\n",
      "Epoch: 13 | Iteration: 521 | Classification loss: 0.03897 | Regression loss: 0.26121 | Running loss: 0.29693\n",
      "Epoch: 13 | Iteration: 522 | Classification loss: 0.03328 | Regression loss: 0.21702 | Running loss: 0.29705\n",
      "Epoch: 13 | Iteration: 523 | Classification loss: 0.03052 | Regression loss: 0.14802 | Running loss: 0.29698\n",
      "Epoch: 13 | Iteration: 524 | Classification loss: 0.05452 | Regression loss: 0.21847 | Running loss: 0.29644\n",
      "Epoch: 13 | Iteration: 525 | Classification loss: 0.05123 | Regression loss: 0.18295 | Running loss: 0.29623\n",
      "Epoch: 13 | Iteration: 526 | Classification loss: 0.03180 | Regression loss: 0.12872 | Running loss: 0.29621\n",
      "Epoch: 13 | Iteration: 527 | Classification loss: 0.03637 | Regression loss: 0.13319 | Running loss: 0.29502\n",
      "Epoch: 13 | Iteration: 528 | Classification loss: 0.14004 | Regression loss: 0.12236 | Running loss: 0.29524\n",
      "Epoch: 13 | Iteration: 529 | Classification loss: 0.01977 | Regression loss: 0.12740 | Running loss: 0.29419\n",
      "Epoch: 13 | Iteration: 530 | Classification loss: 0.07400 | Regression loss: 0.16746 | Running loss: 0.29438\n",
      "Epoch: 13 | Iteration: 531 | Classification loss: 0.06685 | Regression loss: 0.32410 | Running loss: 0.29471\n",
      "Epoch: 13 | Iteration: 532 | Classification loss: 0.05459 | Regression loss: 0.25751 | Running loss: 0.29477\n",
      "Epoch: 13 | Iteration: 533 | Classification loss: 0.09531 | Regression loss: 0.31972 | Running loss: 0.29471\n",
      "Epoch: 13 | Iteration: 534 | Classification loss: 0.03320 | Regression loss: 0.29865 | Running loss: 0.29476\n",
      "Epoch: 13 | Iteration: 535 | Classification loss: 0.03901 | Regression loss: 0.09689 | Running loss: 0.29450\n",
      "Epoch: 13 | Iteration: 536 | Classification loss: 0.04963 | Regression loss: 0.17748 | Running loss: 0.29429\n",
      "Epoch: 13 | Iteration: 537 | Classification loss: 0.05628 | Regression loss: 0.17331 | Running loss: 0.29391\n",
      "Epoch: 13 | Iteration: 538 | Classification loss: 0.04554 | Regression loss: 0.12049 | Running loss: 0.29331\n",
      "Epoch: 13 | Iteration: 539 | Classification loss: 0.11955 | Regression loss: 0.21857 | Running loss: 0.29360\n",
      "Epoch: 13 | Iteration: 540 | Classification loss: 0.20762 | Regression loss: 0.46408 | Running loss: 0.29449\n",
      "Epoch: 13 | Iteration: 541 | Classification loss: 0.05184 | Regression loss: 0.26197 | Running loss: 0.29467\n",
      "Epoch: 13 | Iteration: 542 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.29391\n",
      "Epoch: 13 | Iteration: 543 | Classification loss: 0.04697 | Regression loss: 0.19963 | Running loss: 0.29335\n",
      "Epoch: 13 | Iteration: 544 | Classification loss: 0.02756 | Regression loss: 0.32980 | Running loss: 0.29383\n",
      "Epoch: 13 | Iteration: 545 | Classification loss: 0.08452 | Regression loss: 0.25015 | Running loss: 0.29415\n",
      "Epoch: 13 | Iteration: 546 | Classification loss: 0.08844 | Regression loss: 0.31923 | Running loss: 0.29448\n",
      "Epoch: 13 | Iteration: 547 | Classification loss: 0.12244 | Regression loss: 0.30864 | Running loss: 0.29395\n",
      "Epoch: 13 | Iteration: 548 | Classification loss: 0.07338 | Regression loss: 0.32346 | Running loss: 0.29402\n",
      "Epoch: 13 | Iteration: 549 | Classification loss: 0.08065 | Regression loss: 0.19943 | Running loss: 0.29413\n",
      "Epoch: 13 | Iteration: 550 | Classification loss: 0.07993 | Regression loss: 0.31760 | Running loss: 0.29399\n",
      "Epoch: 13 | Iteration: 551 | Classification loss: 0.19963 | Regression loss: 0.25984 | Running loss: 0.29435\n",
      "Epoch: 13 | Iteration: 552 | Classification loss: 0.09264 | Regression loss: 0.29902 | Running loss: 0.29443\n",
      "Epoch: 13 | Iteration: 553 | Classification loss: 0.06605 | Regression loss: 0.29725 | Running loss: 0.29481\n",
      "Epoch: 13 | Iteration: 554 | Classification loss: 0.03315 | Regression loss: 0.13177 | Running loss: 0.29474\n",
      "Epoch: 13 | Iteration: 555 | Classification loss: 0.05062 | Regression loss: 0.18827 | Running loss: 0.29459\n",
      "Epoch: 13 | Iteration: 556 | Classification loss: 0.11446 | Regression loss: 0.25751 | Running loss: 0.29507\n",
      "Epoch: 13 | Iteration: 557 | Classification loss: 0.13668 | Regression loss: 0.22275 | Running loss: 0.29522\n",
      "Epoch: 13 | Iteration: 558 | Classification loss: 0.10390 | Regression loss: 0.11131 | Running loss: 0.29504\n",
      "Epoch: 13 | Iteration: 559 | Classification loss: 0.06251 | Regression loss: 0.16826 | Running loss: 0.29526\n",
      "Epoch: 13 | Iteration: 560 | Classification loss: 0.03879 | Regression loss: 0.21448 | Running loss: 0.29535\n",
      "Epoch: 13 | Iteration: 561 | Classification loss: 0.02458 | Regression loss: 0.15932 | Running loss: 0.29496\n",
      "Epoch: 13 | Iteration: 562 | Classification loss: 0.06794 | Regression loss: 0.23692 | Running loss: 0.29512\n",
      "Epoch: 13 | Iteration: 563 | Classification loss: 0.07597 | Regression loss: 0.37981 | Running loss: 0.29575\n",
      "Epoch: 13 | Iteration: 564 | Classification loss: 0.04611 | Regression loss: 0.15969 | Running loss: 0.29545\n",
      "Epoch: 13 | Iteration: 565 | Classification loss: 0.07917 | Regression loss: 0.15089 | Running loss: 0.29556\n",
      "Epoch: 13 | Iteration: 566 | Classification loss: 0.17342 | Regression loss: 0.45994 | Running loss: 0.29641\n",
      "Epoch: 13 | Iteration: 567 | Classification loss: 0.15730 | Regression loss: 0.31415 | Running loss: 0.29644\n",
      "Epoch: 13 | Iteration: 568 | Classification loss: 0.09873 | Regression loss: 0.11228 | Running loss: 0.29630\n",
      "Epoch: 13 | Iteration: 569 | Classification loss: 0.14179 | Regression loss: 0.40225 | Running loss: 0.29689\n",
      "Epoch: 13 | Iteration: 570 | Classification loss: 0.03185 | Regression loss: 0.17462 | Running loss: 0.29681\n",
      "Epoch: 13 | Iteration: 571 | Classification loss: 0.09167 | Regression loss: 0.32521 | Running loss: 0.29717\n",
      "Epoch: 13 | Iteration: 572 | Classification loss: 0.23077 | Regression loss: 0.44834 | Running loss: 0.29801\n",
      "Epoch: 13 | Iteration: 573 | Classification loss: 0.15591 | Regression loss: 0.27688 | Running loss: 0.29839\n",
      "Epoch: 13 | Iteration: 574 | Classification loss: 0.09269 | Regression loss: 0.35462 | Running loss: 0.29900\n",
      "Epoch: 13 | Iteration: 575 | Classification loss: 0.06432 | Regression loss: 0.28593 | Running loss: 0.29910\n",
      "Epoch: 13 | Iteration: 576 | Classification loss: 0.02766 | Regression loss: 0.27449 | Running loss: 0.29926\n",
      "Epoch: 13 | Iteration: 577 | Classification loss: 0.02175 | Regression loss: 0.13021 | Running loss: 0.29925\n",
      "Epoch: 13 | Iteration: 578 | Classification loss: 0.06837 | Regression loss: 0.14810 | Running loss: 0.29908\n",
      "Epoch: 13 | Iteration: 579 | Classification loss: 0.04666 | Regression loss: 0.21617 | Running loss: 0.29898\n",
      "Epoch: 13 | Iteration: 580 | Classification loss: 0.01661 | Regression loss: 0.13339 | Running loss: 0.29852\n",
      "Epoch: 13 | Iteration: 581 | Classification loss: 0.18695 | Regression loss: 0.41983 | Running loss: 0.29920\n",
      "Epoch: 13 | Iteration: 582 | Classification loss: 0.04434 | Regression loss: 0.12843 | Running loss: 0.29925\n",
      "Epoch: 13 | Iteration: 583 | Classification loss: 0.06622 | Regression loss: 0.35344 | Running loss: 0.29953\n",
      "Epoch: 13 | Iteration: 584 | Classification loss: 0.04579 | Regression loss: 0.16797 | Running loss: 0.29930\n",
      "Epoch: 13 | Iteration: 585 | Classification loss: 0.19256 | Regression loss: 0.25069 | Running loss: 0.29955\n",
      "Epoch: 13 | Iteration: 586 | Classification loss: 0.17626 | Regression loss: 0.22202 | Running loss: 0.29989\n",
      "Epoch: 13 | Iteration: 587 | Classification loss: 0.14438 | Regression loss: 0.14237 | Running loss: 0.29990\n",
      "Epoch: 13 | Iteration: 588 | Classification loss: 0.11891 | Regression loss: 0.13453 | Running loss: 0.29996\n",
      "Epoch: 13 | Iteration: 589 | Classification loss: 0.09630 | Regression loss: 0.26960 | Running loss: 0.30029\n",
      "Epoch: 13 | Iteration: 590 | Classification loss: 0.05818 | Regression loss: 0.13497 | Running loss: 0.30036\n",
      "Epoch: 13 | Iteration: 591 | Classification loss: 0.05133 | Regression loss: 0.17058 | Running loss: 0.30029\n",
      "Epoch: 13 | Iteration: 592 | Classification loss: 0.10473 | Regression loss: 0.48578 | Running loss: 0.30110\n",
      "Epoch: 13 | Iteration: 593 | Classification loss: 0.03837 | Regression loss: 0.24591 | Running loss: 0.30118\n",
      "Epoch: 13 | Iteration: 594 | Classification loss: 0.09122 | Regression loss: 0.22303 | Running loss: 0.30119\n",
      "Epoch: 13 | Iteration: 595 | Classification loss: 0.04039 | Regression loss: 0.17841 | Running loss: 0.30111\n",
      "Epoch: 13 | Iteration: 596 | Classification loss: 0.05577 | Regression loss: 0.35860 | Running loss: 0.30159\n",
      "Epoch: 13 | Iteration: 597 | Classification loss: 0.13569 | Regression loss: 0.15422 | Running loss: 0.30153\n",
      "Epoch: 13 | Iteration: 598 | Classification loss: 0.03961 | Regression loss: 0.13430 | Running loss: 0.30149\n",
      "Epoch: 13 | Iteration: 599 | Classification loss: 0.03986 | Regression loss: 0.28313 | Running loss: 0.30202\n",
      "Epoch: 13 | Iteration: 600 | Classification loss: 0.08785 | Regression loss: 0.36466 | Running loss: 0.30248\n",
      "Epoch: 13 | Iteration: 601 | Classification loss: 0.13841 | Regression loss: 0.18662 | Running loss: 0.30232\n",
      "Epoch: 13 | Iteration: 602 | Classification loss: 0.09278 | Regression loss: 0.18417 | Running loss: 0.30143\n",
      "Epoch: 13 | Iteration: 603 | Classification loss: 0.03978 | Regression loss: 0.13398 | Running loss: 0.30109\n",
      "Epoch: 13 | Iteration: 604 | Classification loss: 0.02201 | Regression loss: 0.12380 | Running loss: 0.30024\n",
      "Epoch: 13 | Iteration: 605 | Classification loss: 0.03173 | Regression loss: 0.10077 | Running loss: 0.29950\n",
      "Epoch: 13 | Iteration: 606 | Classification loss: 0.09404 | Regression loss: 0.21112 | Running loss: 0.29944\n",
      "Epoch: 13 | Iteration: 607 | Classification loss: 0.16393 | Regression loss: 0.37864 | Running loss: 0.29989\n",
      "Epoch: 13 | Iteration: 608 | Classification loss: 0.17101 | Regression loss: 0.41710 | Running loss: 0.30066\n",
      "Epoch: 13 | Iteration: 609 | Classification loss: 0.20859 | Regression loss: 0.13961 | Running loss: 0.30085\n",
      "Epoch: 13 | Iteration: 610 | Classification loss: 0.02514 | Regression loss: 0.12207 | Running loss: 0.30075\n",
      "Epoch: 13 | Iteration: 611 | Classification loss: 0.08424 | Regression loss: 0.21689 | Running loss: 0.30063\n",
      "Epoch: 13 | Iteration: 612 | Classification loss: 0.05269 | Regression loss: 0.13059 | Running loss: 0.30043\n",
      "Epoch: 13 | Iteration: 613 | Classification loss: 0.04254 | Regression loss: 0.26732 | Running loss: 0.30001\n",
      "Epoch: 13 | Iteration: 614 | Classification loss: 0.05001 | Regression loss: 0.24680 | Running loss: 0.30026\n",
      "Epoch: 13 | Iteration: 615 | Classification loss: 0.04043 | Regression loss: 0.20290 | Running loss: 0.30039\n",
      "Epoch: 13 | Iteration: 616 | Classification loss: 0.09933 | Regression loss: 0.32994 | Running loss: 0.30066\n",
      "Epoch: 13 | Iteration: 617 | Classification loss: 0.03350 | Regression loss: 0.18023 | Running loss: 0.30086\n",
      "Epoch: 13 | Iteration: 618 | Classification loss: 0.12873 | Regression loss: 0.38831 | Running loss: 0.30144\n",
      "Epoch: 13 | Iteration: 619 | Classification loss: 0.05912 | Regression loss: 0.29305 | Running loss: 0.30161\n",
      "Epoch: 13 | Iteration: 620 | Classification loss: 0.04081 | Regression loss: 0.11120 | Running loss: 0.30125\n",
      "Epoch: 13 | Iteration: 621 | Classification loss: 0.23840 | Regression loss: 0.22842 | Running loss: 0.30113\n",
      "Epoch: 13 | Iteration: 622 | Classification loss: 0.06812 | Regression loss: 0.17958 | Running loss: 0.30080\n",
      "Epoch: 13 | Iteration: 623 | Classification loss: 0.15252 | Regression loss: 0.34202 | Running loss: 0.30104\n",
      "Epoch: 13 | Iteration: 624 | Classification loss: 0.03814 | Regression loss: 0.17400 | Running loss: 0.30097\n",
      "Epoch: 13 | Iteration: 625 | Classification loss: 0.07135 | Regression loss: 0.22893 | Running loss: 0.30105\n",
      "Epoch: 13 | Iteration: 626 | Classification loss: 0.06620 | Regression loss: 0.26779 | Running loss: 0.30062\n",
      "Epoch: 13 | Iteration: 627 | Classification loss: 0.03958 | Regression loss: 0.22102 | Running loss: 0.30050\n",
      "Epoch: 13 | Iteration: 628 | Classification loss: 0.05284 | Regression loss: 0.28434 | Running loss: 0.30038\n",
      "Epoch: 13 | Iteration: 629 | Classification loss: 0.02651 | Regression loss: 0.16326 | Running loss: 0.29973\n",
      "Epoch: 13 | Iteration: 630 | Classification loss: 0.08534 | Regression loss: 0.19881 | Running loss: 0.29962\n",
      "Epoch: 13 | Iteration: 631 | Classification loss: 0.02703 | Regression loss: 0.17468 | Running loss: 0.29941\n",
      "Epoch: 13 | Iteration: 632 | Classification loss: 0.05500 | Regression loss: 0.16481 | Running loss: 0.29919\n",
      "Epoch: 13 | Iteration: 633 | Classification loss: 0.24801 | Regression loss: 0.09283 | Running loss: 0.29927\n",
      "Epoch: 13 | Iteration: 634 | Classification loss: 0.03687 | Regression loss: 0.16543 | Running loss: 0.29931\n",
      "Epoch: 13 | Iteration: 635 | Classification loss: 0.08812 | Regression loss: 0.23806 | Running loss: 0.29932\n",
      "Epoch: 13 | Iteration: 636 | Classification loss: 0.09571 | Regression loss: 0.29618 | Running loss: 0.29938\n",
      "Epoch: 13 | Iteration: 637 | Classification loss: 0.02093 | Regression loss: 0.22114 | Running loss: 0.29925\n",
      "Epoch: 13 | Iteration: 638 | Classification loss: 0.02764 | Regression loss: 0.10808 | Running loss: 0.29897\n",
      "Epoch: 13 | Iteration: 639 | Classification loss: 0.04273 | Regression loss: 0.14358 | Running loss: 0.29898\n",
      "Epoch: 13 | Iteration: 640 | Classification loss: 0.01261 | Regression loss: 0.15893 | Running loss: 0.29886\n",
      "Epoch: 13 | Iteration: 641 | Classification loss: 0.03006 | Regression loss: 0.13994 | Running loss: 0.29873\n",
      "Epoch: 13 | Iteration: 642 | Classification loss: 0.05623 | Regression loss: 0.18319 | Running loss: 0.29875\n",
      "Epoch: 13 | Iteration: 643 | Classification loss: 0.05109 | Regression loss: 0.18719 | Running loss: 0.29818\n",
      "Epoch: 13 | Iteration: 644 | Classification loss: 0.02672 | Regression loss: 0.16903 | Running loss: 0.29805\n",
      "Epoch: 13 | Iteration: 645 | Classification loss: 0.02628 | Regression loss: 0.20710 | Running loss: 0.29838\n",
      "Epoch: 13 | Iteration: 646 | Classification loss: 0.05445 | Regression loss: 0.13796 | Running loss: 0.29816\n",
      "Epoch: 13 | Iteration: 647 | Classification loss: 0.02526 | Regression loss: 0.18627 | Running loss: 0.29779\n",
      "Epoch: 13 | Iteration: 648 | Classification loss: 0.03545 | Regression loss: 0.21786 | Running loss: 0.29773\n",
      "Epoch: 13 | Iteration: 649 | Classification loss: 0.05172 | Regression loss: 0.19801 | Running loss: 0.29755\n",
      "Epoch: 13 | Iteration: 650 | Classification loss: 0.04262 | Regression loss: 0.15303 | Running loss: 0.29699\n",
      "Epoch: 13 | Iteration: 651 | Classification loss: 0.04337 | Regression loss: 0.23558 | Running loss: 0.29717\n",
      "Epoch: 13 | Iteration: 652 | Classification loss: 0.03013 | Regression loss: 0.20133 | Running loss: 0.29711\n",
      "Epoch: 13 | Iteration: 653 | Classification loss: 0.01656 | Regression loss: 0.19624 | Running loss: 0.29719\n",
      "Epoch: 13 | Iteration: 654 | Classification loss: 0.04601 | Regression loss: 0.20826 | Running loss: 0.29705\n",
      "Epoch: 13 | Iteration: 655 | Classification loss: 0.01923 | Regression loss: 0.09051 | Running loss: 0.29690\n",
      "Epoch: 13 | Iteration: 656 | Classification loss: 0.03173 | Regression loss: 0.16722 | Running loss: 0.29685\n",
      "Epoch: 13 | Iteration: 657 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.29610\n",
      "Epoch: 13 | Iteration: 658 | Classification loss: 0.07294 | Regression loss: 0.23804 | Running loss: 0.29606\n",
      "Epoch: 13 | Iteration: 659 | Classification loss: 0.03331 | Regression loss: 0.20732 | Running loss: 0.29595\n",
      "Epoch: 13 | Iteration: 660 | Classification loss: 0.10780 | Regression loss: 0.13297 | Running loss: 0.29584\n",
      "Epoch: 13 | Iteration: 661 | Classification loss: 0.07796 | Regression loss: 0.17470 | Running loss: 0.29557\n",
      "Epoch: 13 | Iteration: 662 | Classification loss: 0.07761 | Regression loss: 0.11884 | Running loss: 0.29560\n",
      "Epoch: 13 | Iteration: 663 | Classification loss: 0.08060 | Regression loss: 0.11262 | Running loss: 0.29569\n",
      "Epoch: 13 | Iteration: 664 | Classification loss: 0.03054 | Regression loss: 0.15273 | Running loss: 0.29582\n",
      "Epoch: 13 | Iteration: 665 | Classification loss: 0.06113 | Regression loss: 0.09926 | Running loss: 0.29574\n",
      "Epoch: 13 | Iteration: 666 | Classification loss: 0.07446 | Regression loss: 0.26587 | Running loss: 0.29575\n",
      "Epoch: 13 | Iteration: 667 | Classification loss: 0.11775 | Regression loss: 0.20647 | Running loss: 0.29603\n",
      "Epoch: 13 | Iteration: 668 | Classification loss: 0.16562 | Regression loss: 0.33742 | Running loss: 0.29662\n",
      "Epoch: 13 | Iteration: 669 | Classification loss: 0.09996 | Regression loss: 0.27551 | Running loss: 0.29686\n",
      "Epoch: 13 | Iteration: 670 | Classification loss: 0.04586 | Regression loss: 0.13527 | Running loss: 0.29649\n",
      "Epoch: 13 | Iteration: 671 | Classification loss: 0.08153 | Regression loss: 0.13259 | Running loss: 0.29648\n",
      "Epoch: 13 | Iteration: 672 | Classification loss: 0.01997 | Regression loss: 0.18141 | Running loss: 0.29635\n",
      "Epoch: 13 | Iteration: 673 | Classification loss: 0.04956 | Regression loss: 0.11580 | Running loss: 0.29617\n",
      "Epoch: 13 | Iteration: 674 | Classification loss: 0.15378 | Regression loss: 0.38488 | Running loss: 0.29663\n",
      "Epoch: 13 | Iteration: 675 | Classification loss: 0.08430 | Regression loss: 0.32417 | Running loss: 0.29692\n",
      "Epoch: 13 | Iteration: 676 | Classification loss: 0.16974 | Regression loss: 0.40900 | Running loss: 0.29747\n",
      "Epoch: 13 | Iteration: 677 | Classification loss: 0.01767 | Regression loss: 0.08971 | Running loss: 0.29730\n",
      "Epoch: 13 | Iteration: 678 | Classification loss: 0.04847 | Regression loss: 0.23689 | Running loss: 0.29723\n",
      "Epoch: 13 | Iteration: 679 | Classification loss: 0.04425 | Regression loss: 0.19358 | Running loss: 0.29744\n",
      "Epoch: 13 | Iteration: 680 | Classification loss: 0.01927 | Regression loss: 0.10510 | Running loss: 0.29729\n",
      "Epoch: 13 | Iteration: 681 | Classification loss: 0.27063 | Regression loss: 0.40819 | Running loss: 0.29801\n",
      "Epoch: 13 | Iteration: 682 | Classification loss: 0.03348 | Regression loss: 0.10314 | Running loss: 0.29776\n",
      "Epoch: 13 | Iteration: 683 | Classification loss: 0.05883 | Regression loss: 0.23283 | Running loss: 0.29758\n",
      "Epoch: 13 | Iteration: 684 | Classification loss: 0.31983 | Regression loss: 0.14110 | Running loss: 0.29808\n",
      "Epoch: 13 | Iteration: 685 | Classification loss: 0.46542 | Regression loss: 0.12605 | Running loss: 0.29855\n",
      "Epoch: 13 | Iteration: 686 | Classification loss: 0.05479 | Regression loss: 0.12546 | Running loss: 0.29816\n",
      "Epoch: 13 | Iteration: 687 | Classification loss: 0.04894 | Regression loss: 0.32216 | Running loss: 0.29847\n",
      "Epoch: 13 | Iteration: 688 | Classification loss: 0.01618 | Regression loss: 0.14472 | Running loss: 0.29817\n",
      "Epoch: 13 | Iteration: 689 | Classification loss: 0.03403 | Regression loss: 0.10982 | Running loss: 0.29779\n",
      "Epoch: 13 | Iteration: 690 | Classification loss: 0.02644 | Regression loss: 0.05882 | Running loss: 0.29742\n",
      "Epoch: 13 | Iteration: 691 | Classification loss: 0.05859 | Regression loss: 0.10419 | Running loss: 0.29735\n",
      "Epoch: 13 | Iteration: 692 | Classification loss: 0.05246 | Regression loss: 0.20210 | Running loss: 0.29709\n",
      "Epoch: 13 | Iteration: 693 | Classification loss: 0.03796 | Regression loss: 0.17794 | Running loss: 0.29690\n",
      "Epoch: 13 | Iteration: 694 | Classification loss: 0.03364 | Regression loss: 0.26599 | Running loss: 0.29707\n",
      "Epoch: 13 | Iteration: 695 | Classification loss: 0.47989 | Regression loss: 0.54007 | Running loss: 0.29882\n",
      "Epoch: 13 | Iteration: 696 | Classification loss: 0.13036 | Regression loss: 0.25320 | Running loss: 0.29927\n",
      "Epoch: 13 | Iteration: 697 | Classification loss: 0.07261 | Regression loss: 0.23785 | Running loss: 0.29926\n",
      "Epoch: 13 | Iteration: 698 | Classification loss: 0.07999 | Regression loss: 0.20241 | Running loss: 0.29926\n",
      "Epoch: 13 | Iteration: 699 | Classification loss: 0.10675 | Regression loss: 0.27412 | Running loss: 0.29943\n",
      "Epoch: 13 | Iteration: 700 | Classification loss: 0.04913 | Regression loss: 0.17195 | Running loss: 0.29925\n",
      "Epoch: 13 | Iteration: 701 | Classification loss: 0.03551 | Regression loss: 0.14726 | Running loss: 0.29861\n",
      "Epoch: 13 | Iteration: 702 | Classification loss: 0.02407 | Regression loss: 0.11770 | Running loss: 0.29840\n",
      "Epoch: 13 | Iteration: 703 | Classification loss: 0.07405 | Regression loss: 0.37992 | Running loss: 0.29854\n",
      "Epoch: 13 | Iteration: 704 | Classification loss: 0.07386 | Regression loss: 0.15815 | Running loss: 0.29829\n",
      "Epoch: 13 | Iteration: 705 | Classification loss: 0.06251 | Regression loss: 0.14628 | Running loss: 0.29779\n",
      "Epoch: 13 | Iteration: 706 | Classification loss: 0.19674 | Regression loss: 0.17426 | Running loss: 0.29841\n",
      "Epoch: 13 | Iteration: 707 | Classification loss: 0.11429 | Regression loss: 0.32179 | Running loss: 0.29842\n",
      "Epoch: 13 | Iteration: 708 | Classification loss: 0.12322 | Regression loss: 0.18366 | Running loss: 0.29847\n",
      "Epoch: 13 | Iteration: 709 | Classification loss: 0.08995 | Regression loss: 0.24941 | Running loss: 0.29868\n",
      "Epoch: 13 | Iteration: 710 | Classification loss: 0.08575 | Regression loss: 0.21433 | Running loss: 0.29828\n",
      "Epoch: 13 | Iteration: 711 | Classification loss: 0.03045 | Regression loss: 0.16306 | Running loss: 0.29799\n",
      "Epoch: 13 | Iteration: 712 | Classification loss: 0.17077 | Regression loss: 0.36198 | Running loss: 0.29854\n",
      "Epoch: 13 | Iteration: 713 | Classification loss: 0.12281 | Regression loss: 0.22187 | Running loss: 0.29864\n",
      "Epoch: 13 | Iteration: 714 | Classification loss: 0.03756 | Regression loss: 0.13754 | Running loss: 0.29854\n",
      "Epoch: 13 | Iteration: 715 | Classification loss: 0.02184 | Regression loss: 0.22873 | Running loss: 0.29834\n",
      "Epoch: 13 | Iteration: 716 | Classification loss: 0.02229 | Regression loss: 0.16216 | Running loss: 0.29817\n",
      "Epoch: 13 | Iteration: 717 | Classification loss: 0.18247 | Regression loss: 0.13578 | Running loss: 0.29799\n",
      "Epoch: 13 | Iteration: 718 | Classification loss: 0.08542 | Regression loss: 0.20965 | Running loss: 0.29790\n",
      "Epoch: 13 | Iteration: 719 | Classification loss: 0.03730 | Regression loss: 0.10734 | Running loss: 0.29772\n",
      "Epoch: 13 | Iteration: 720 | Classification loss: 0.04387 | Regression loss: 0.18866 | Running loss: 0.29751\n",
      "Epoch: 13 | Iteration: 721 | Classification loss: 0.03420 | Regression loss: 0.17818 | Running loss: 0.29638\n",
      "Epoch: 13 | Iteration: 722 | Classification loss: 0.13866 | Regression loss: 0.13445 | Running loss: 0.29616\n",
      "Epoch: 13 | Iteration: 723 | Classification loss: 0.14541 | Regression loss: 0.24824 | Running loss: 0.29624\n",
      "Epoch: 13 | Iteration: 724 | Classification loss: 0.07400 | Regression loss: 0.19039 | Running loss: 0.29626\n",
      "Epoch: 13 | Iteration: 725 | Classification loss: 0.05905 | Regression loss: 0.22487 | Running loss: 0.29645\n",
      "Epoch: 13 | Iteration: 726 | Classification loss: 0.03785 | Regression loss: 0.13860 | Running loss: 0.29616\n",
      "Epoch: 13 | Iteration: 727 | Classification loss: 0.02546 | Regression loss: 0.18387 | Running loss: 0.29625\n",
      "Epoch: 13 | Iteration: 728 | Classification loss: 0.05716 | Regression loss: 0.31701 | Running loss: 0.29642\n",
      "Epoch: 13 | Iteration: 729 | Classification loss: 0.07415 | Regression loss: 0.12817 | Running loss: 0.29644\n",
      "Epoch: 13 | Iteration: 730 | Classification loss: 0.09641 | Regression loss: 0.19960 | Running loss: 0.29652\n",
      "Epoch: 13 | Iteration: 731 | Classification loss: 0.05295 | Regression loss: 0.17899 | Running loss: 0.29643\n",
      "Epoch: 13 | Iteration: 732 | Classification loss: 0.10997 | Regression loss: 0.23960 | Running loss: 0.29669\n",
      "Epoch: 13 | Iteration: 733 | Classification loss: 0.07171 | Regression loss: 0.36353 | Running loss: 0.29711\n",
      "Epoch: 13 | Iteration: 734 | Classification loss: 0.04145 | Regression loss: 0.20944 | Running loss: 0.29616\n",
      "Epoch: 13 | Iteration: 735 | Classification loss: 0.18969 | Regression loss: 0.38064 | Running loss: 0.29680\n",
      "Epoch: 13 | Iteration: 736 | Classification loss: 0.14607 | Regression loss: 0.11822 | Running loss: 0.29681\n",
      "Epoch: 13 | Iteration: 737 | Classification loss: 0.06548 | Regression loss: 0.18574 | Running loss: 0.29628\n",
      "Epoch: 13 | Iteration: 738 | Classification loss: 0.14144 | Regression loss: 0.25333 | Running loss: 0.29659\n",
      "Epoch: 13 | Iteration: 739 | Classification loss: 0.14255 | Regression loss: 0.38018 | Running loss: 0.29677\n",
      "Epoch: 13 | Iteration: 740 | Classification loss: 0.13438 | Regression loss: 0.17522 | Running loss: 0.29697\n",
      "Epoch: 13 | Iteration: 741 | Classification loss: 0.48119 | Regression loss: 0.04041 | Running loss: 0.29705\n",
      "Epoch: 13 | Iteration: 742 | Classification loss: 0.09268 | Regression loss: 0.27308 | Running loss: 0.29708\n",
      "Epoch: 13 | Iteration: 743 | Classification loss: 0.03388 | Regression loss: 0.17675 | Running loss: 0.29688\n",
      "Epoch: 13 | Iteration: 744 | Classification loss: 0.14454 | Regression loss: 0.12447 | Running loss: 0.29696\n",
      "Epoch: 13 | Iteration: 745 | Classification loss: 0.06444 | Regression loss: 0.14245 | Running loss: 0.29690\n",
      "Epoch: 13 | Iteration: 746 | Classification loss: 0.10245 | Regression loss: 0.13477 | Running loss: 0.29639\n",
      "Epoch: 13 | Iteration: 747 | Classification loss: 0.38107 | Regression loss: 0.38923 | Running loss: 0.29751\n",
      "Epoch: 13 | Iteration: 748 | Classification loss: 0.05254 | Regression loss: 0.14765 | Running loss: 0.29743\n",
      "Epoch: 13 | Iteration: 749 | Classification loss: 0.14918 | Regression loss: 0.33219 | Running loss: 0.29772\n",
      "Epoch: 13 | Iteration: 750 | Classification loss: 0.18668 | Regression loss: 0.28300 | Running loss: 0.29822\n",
      "Epoch: 13 | Iteration: 751 | Classification loss: 0.14590 | Regression loss: 0.30425 | Running loss: 0.29811\n",
      "Epoch: 13 | Iteration: 752 | Classification loss: 0.12589 | Regression loss: 0.06893 | Running loss: 0.29795\n",
      "Epoch: 13 | Iteration: 753 | Classification loss: 0.07819 | Regression loss: 0.11510 | Running loss: 0.29805\n",
      "Epoch: 13 | Iteration: 754 | Classification loss: 0.04634 | Regression loss: 0.20937 | Running loss: 0.29817\n",
      "Epoch: 13 | Iteration: 755 | Classification loss: 0.05628 | Regression loss: 0.15172 | Running loss: 0.29835\n",
      "Epoch: 13 | Iteration: 756 | Classification loss: 0.11625 | Regression loss: 0.21064 | Running loss: 0.29829\n",
      "Epoch: 13 | Iteration: 757 | Classification loss: 0.08065 | Regression loss: 0.17674 | Running loss: 0.29820\n",
      "Epoch: 13 | Iteration: 758 | Classification loss: 0.10371 | Regression loss: 0.15185 | Running loss: 0.29717\n",
      "Epoch: 13 | Iteration: 759 | Classification loss: 0.03118 | Regression loss: 0.21950 | Running loss: 0.29708\n",
      "Epoch: 13 | Iteration: 760 | Classification loss: 0.04640 | Regression loss: 0.18311 | Running loss: 0.29662\n",
      "Epoch: 13 | Iteration: 761 | Classification loss: 0.07191 | Regression loss: 0.24073 | Running loss: 0.29688\n",
      "Epoch: 13 | Iteration: 762 | Classification loss: 0.06314 | Regression loss: 0.23832 | Running loss: 0.29708\n",
      "Epoch: 13 | Iteration: 763 | Classification loss: 0.02401 | Regression loss: 0.11603 | Running loss: 0.29679\n",
      "Epoch: 13 | Iteration: 764 | Classification loss: 0.07335 | Regression loss: 0.31979 | Running loss: 0.29727\n",
      "Epoch: 13 | Iteration: 765 | Classification loss: 0.02163 | Regression loss: 0.06837 | Running loss: 0.29646\n",
      "Epoch: 13 | Iteration: 766 | Classification loss: 0.06847 | Regression loss: 0.15211 | Running loss: 0.29648\n",
      "Epoch: 13 | Iteration: 767 | Classification loss: 0.10480 | Regression loss: 0.16585 | Running loss: 0.29584\n",
      "Epoch: 13 | Iteration: 768 | Classification loss: 0.28238 | Regression loss: 0.20174 | Running loss: 0.29601\n",
      "Epoch: 13 | Iteration: 769 | Classification loss: 0.29070 | Regression loss: 0.62864 | Running loss: 0.29741\n",
      "Epoch: 13 | Iteration: 770 | Classification loss: 0.44420 | Regression loss: 0.08565 | Running loss: 0.29797\n",
      "Epoch: 13 | Iteration: 771 | Classification loss: 0.04500 | Regression loss: 0.22336 | Running loss: 0.29808\n",
      "Epoch: 13 | Iteration: 772 | Classification loss: 0.20529 | Regression loss: 0.39478 | Running loss: 0.29856\n",
      "Epoch: 13 | Iteration: 773 | Classification loss: 0.02423 | Regression loss: 0.18768 | Running loss: 0.29831\n",
      "Epoch: 13 | Iteration: 774 | Classification loss: 0.04172 | Regression loss: 0.20371 | Running loss: 0.29767\n",
      "Epoch: 13 | Iteration: 775 | Classification loss: 0.11841 | Regression loss: 0.22950 | Running loss: 0.29757\n",
      "Epoch: 13 | Iteration: 776 | Classification loss: 0.27781 | Regression loss: 0.32629 | Running loss: 0.29829\n",
      "Epoch: 13 | Iteration: 777 | Classification loss: 0.15797 | Regression loss: 0.28502 | Running loss: 0.29868\n",
      "Epoch: 13 | Iteration: 778 | Classification loss: 0.25823 | Regression loss: 0.21150 | Running loss: 0.29884\n",
      "Epoch: 13 | Iteration: 779 | Classification loss: 0.05507 | Regression loss: 0.10266 | Running loss: 0.29829\n",
      "Epoch: 13 | Iteration: 780 | Classification loss: 0.06277 | Regression loss: 0.24939 | Running loss: 0.29838\n",
      "Epoch: 13 | Iteration: 781 | Classification loss: 0.17159 | Regression loss: 0.22978 | Running loss: 0.29840\n",
      "Epoch: 13 | Iteration: 782 | Classification loss: 0.11203 | Regression loss: 0.22924 | Running loss: 0.29864\n",
      "Epoch: 13 | Iteration: 783 | Classification loss: 0.05290 | Regression loss: 0.24081 | Running loss: 0.29875\n",
      "Epoch: 13 | Iteration: 784 | Classification loss: 0.05710 | Regression loss: 0.17431 | Running loss: 0.29885\n",
      "Epoch: 13 | Iteration: 785 | Classification loss: 0.08132 | Regression loss: 0.13217 | Running loss: 0.29892\n",
      "Epoch: 13 | Iteration: 786 | Classification loss: 0.20937 | Regression loss: 0.38203 | Running loss: 0.29922\n",
      "Epoch: 13 | Iteration: 787 | Classification loss: 0.14991 | Regression loss: 0.27745 | Running loss: 0.29982\n",
      "Epoch: 13 | Iteration: 788 | Classification loss: 0.39981 | Regression loss: 0.07172 | Running loss: 0.29993\n",
      "Epoch: 13 | Iteration: 789 | Classification loss: 0.03072 | Regression loss: 0.12435 | Running loss: 0.29961\n",
      "Epoch: 13 | Iteration: 790 | Classification loss: 0.07385 | Regression loss: 0.18805 | Running loss: 0.29936\n",
      "Epoch: 13 | Iteration: 791 | Classification loss: 0.07765 | Regression loss: 0.10824 | Running loss: 0.29915\n",
      "Epoch: 13 | Iteration: 792 | Classification loss: 0.09558 | Regression loss: 0.32478 | Running loss: 0.29979\n",
      "Epoch: 13 | Iteration: 793 | Classification loss: 0.04273 | Regression loss: 0.17922 | Running loss: 0.29973\n",
      "Epoch: 13 | Iteration: 794 | Classification loss: 0.07392 | Regression loss: 0.29788 | Running loss: 0.30006\n",
      "Epoch: 13 | Iteration: 795 | Classification loss: 0.05138 | Regression loss: 0.33357 | Running loss: 0.30025\n",
      "Epoch: 13 | Iteration: 796 | Classification loss: 0.07993 | Regression loss: 0.36318 | Running loss: 0.30080\n",
      "Epoch: 13 | Iteration: 797 | Classification loss: 0.13989 | Regression loss: 0.44685 | Running loss: 0.30144\n",
      "Epoch: 13 | Iteration: 798 | Classification loss: 0.08938 | Regression loss: 0.13730 | Running loss: 0.30108\n",
      "Epoch: 13 | Iteration: 799 | Classification loss: 0.04515 | Regression loss: 0.23697 | Running loss: 0.30084\n",
      "Epoch: 13 | Iteration: 800 | Classification loss: 0.03073 | Regression loss: 0.22998 | Running loss: 0.30056\n",
      "Epoch: 13 | Iteration: 801 | Classification loss: 0.42193 | Regression loss: 0.30921 | Running loss: 0.30146\n",
      "Epoch: 13 | Iteration: 802 | Classification loss: 0.14214 | Regression loss: 0.18224 | Running loss: 0.30157\n",
      "Epoch: 13 | Iteration: 803 | Classification loss: 0.08867 | Regression loss: 0.18553 | Running loss: 0.30156\n",
      "Epoch: 13 | Iteration: 804 | Classification loss: 0.05330 | Regression loss: 0.17743 | Running loss: 0.30044\n",
      "Epoch: 13 | Iteration: 805 | Classification loss: 0.06093 | Regression loss: 0.20016 | Running loss: 0.30070\n",
      "Epoch: 13 | Iteration: 806 | Classification loss: 0.11914 | Regression loss: 0.24344 | Running loss: 0.30094\n",
      "Epoch: 13 | Iteration: 807 | Classification loss: 0.16220 | Regression loss: 0.17868 | Running loss: 0.30121\n",
      "Epoch: 13 | Iteration: 808 | Classification loss: 0.03133 | Regression loss: 0.09698 | Running loss: 0.30056\n",
      "Epoch: 13 | Iteration: 809 | Classification loss: 0.06095 | Regression loss: 0.29853 | Running loss: 0.30037\n",
      "Epoch: 13 | Iteration: 810 | Classification loss: 0.04693 | Regression loss: 0.16153 | Running loss: 0.30008\n",
      "Epoch: 13 | Iteration: 811 | Classification loss: 0.12474 | Regression loss: 0.25571 | Running loss: 0.30046\n",
      "Epoch: 13 | Iteration: 812 | Classification loss: 0.09082 | Regression loss: 0.11257 | Running loss: 0.30030\n",
      "Epoch: 13 | Iteration: 813 | Classification loss: 0.02566 | Regression loss: 0.20784 | Running loss: 0.30030\n",
      "Epoch: 13 | Iteration: 814 | Classification loss: 0.03962 | Regression loss: 0.16327 | Running loss: 0.30029\n",
      "Epoch: 13 | Iteration: 815 | Classification loss: 0.25477 | Regression loss: 0.16657 | Running loss: 0.30050\n",
      "Epoch: 13 | Iteration: 816 | Classification loss: 0.04994 | Regression loss: 0.19644 | Running loss: 0.30044\n",
      "Epoch: 13 | Iteration: 817 | Classification loss: 0.13382 | Regression loss: 0.18389 | Running loss: 0.30073\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.597\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 14 | Iteration: 0 | Classification loss: 0.07016 | Regression loss: 0.28015 | Running loss: 0.30069\n",
      "Epoch: 14 | Iteration: 1 | Classification loss: 0.06286 | Regression loss: 0.19290 | Running loss: 0.30060\n",
      "Epoch: 14 | Iteration: 2 | Classification loss: 0.04604 | Regression loss: 0.24318 | Running loss: 0.30016\n",
      "Epoch: 14 | Iteration: 3 | Classification loss: 0.01713 | Regression loss: 0.12769 | Running loss: 0.29991\n",
      "Epoch: 14 | Iteration: 4 | Classification loss: 0.05911 | Regression loss: 0.27738 | Running loss: 0.29998\n",
      "Epoch: 14 | Iteration: 5 | Classification loss: 0.05235 | Regression loss: 0.19642 | Running loss: 0.29972\n",
      "Epoch: 14 | Iteration: 6 | Classification loss: 0.04218 | Regression loss: 0.12340 | Running loss: 0.29949\n",
      "Epoch: 14 | Iteration: 7 | Classification loss: 0.05459 | Regression loss: 0.18349 | Running loss: 0.29918\n",
      "Epoch: 14 | Iteration: 8 | Classification loss: 0.04140 | Regression loss: 0.26896 | Running loss: 0.29948\n",
      "Epoch: 14 | Iteration: 9 | Classification loss: 0.09696 | Regression loss: 0.08285 | Running loss: 0.29929\n",
      "Epoch: 14 | Iteration: 10 | Classification loss: 0.03733 | Regression loss: 0.13649 | Running loss: 0.29907\n",
      "Epoch: 14 | Iteration: 11 | Classification loss: 0.08710 | Regression loss: 0.12897 | Running loss: 0.29926\n",
      "Epoch: 14 | Iteration: 12 | Classification loss: 0.29567 | Regression loss: 0.30948 | Running loss: 0.30006\n",
      "Epoch: 14 | Iteration: 13 | Classification loss: 0.06307 | Regression loss: 0.09030 | Running loss: 0.29911\n",
      "Epoch: 14 | Iteration: 14 | Classification loss: 0.03828 | Regression loss: 0.15622 | Running loss: 0.29871\n",
      "Epoch: 14 | Iteration: 15 | Classification loss: 0.21457 | Regression loss: 0.38624 | Running loss: 0.29960\n",
      "Epoch: 14 | Iteration: 16 | Classification loss: 0.17102 | Regression loss: 0.73999 | Running loss: 0.30109\n",
      "Epoch: 14 | Iteration: 17 | Classification loss: 0.02050 | Regression loss: 0.11652 | Running loss: 0.30081\n",
      "Epoch: 14 | Iteration: 18 | Classification loss: 0.01638 | Regression loss: 0.17412 | Running loss: 0.29956\n",
      "Epoch: 14 | Iteration: 19 | Classification loss: 0.03620 | Regression loss: 0.22718 | Running loss: 0.29878\n",
      "Epoch: 14 | Iteration: 20 | Classification loss: 0.04642 | Regression loss: 0.23865 | Running loss: 0.29872\n",
      "Epoch: 14 | Iteration: 21 | Classification loss: 0.05183 | Regression loss: 0.36094 | Running loss: 0.29924\n",
      "Epoch: 14 | Iteration: 22 | Classification loss: 0.23992 | Regression loss: 0.36317 | Running loss: 0.29998\n",
      "Epoch: 14 | Iteration: 23 | Classification loss: 0.04669 | Regression loss: 0.13786 | Running loss: 0.29986\n",
      "Epoch: 14 | Iteration: 24 | Classification loss: 0.05624 | Regression loss: 0.23822 | Running loss: 0.30000\n",
      "Epoch: 14 | Iteration: 25 | Classification loss: 0.03342 | Regression loss: 0.17396 | Running loss: 0.29987\n",
      "Epoch: 14 | Iteration: 26 | Classification loss: 0.03679 | Regression loss: 0.15102 | Running loss: 0.29994\n",
      "Epoch: 14 | Iteration: 27 | Classification loss: 0.06573 | Regression loss: 0.32708 | Running loss: 0.29946\n",
      "Epoch: 14 | Iteration: 28 | Classification loss: 0.14054 | Regression loss: 0.30790 | Running loss: 0.30007\n",
      "Epoch: 14 | Iteration: 29 | Classification loss: 0.11638 | Regression loss: 0.28557 | Running loss: 0.30053\n",
      "Epoch: 14 | Iteration: 30 | Classification loss: 0.10032 | Regression loss: 0.27375 | Running loss: 0.30079\n",
      "Epoch: 14 | Iteration: 31 | Classification loss: 0.07626 | Regression loss: 0.23656 | Running loss: 0.30107\n",
      "Epoch: 14 | Iteration: 32 | Classification loss: 0.04896 | Regression loss: 0.21778 | Running loss: 0.30057\n",
      "Epoch: 14 | Iteration: 33 | Classification loss: 0.01497 | Regression loss: 0.15504 | Running loss: 0.30066\n",
      "Epoch: 14 | Iteration: 34 | Classification loss: 0.35748 | Regression loss: 0.13378 | Running loss: 0.30025\n",
      "Epoch: 14 | Iteration: 35 | Classification loss: 0.02208 | Regression loss: 0.21739 | Running loss: 0.30013\n",
      "Epoch: 14 | Iteration: 36 | Classification loss: 0.02126 | Regression loss: 0.18017 | Running loss: 0.29974\n",
      "Epoch: 14 | Iteration: 37 | Classification loss: 0.02276 | Regression loss: 0.18027 | Running loss: 0.29971\n",
      "Epoch: 14 | Iteration: 38 | Classification loss: 0.09090 | Regression loss: 0.15001 | Running loss: 0.29959\n",
      "Epoch: 14 | Iteration: 39 | Classification loss: 0.09386 | Regression loss: 0.36822 | Running loss: 0.29985\n",
      "Epoch: 14 | Iteration: 40 | Classification loss: 0.03051 | Regression loss: 0.16264 | Running loss: 0.29979\n",
      "Epoch: 14 | Iteration: 41 | Classification loss: 0.10472 | Regression loss: 0.26383 | Running loss: 0.30002\n",
      "Epoch: 14 | Iteration: 42 | Classification loss: 0.07745 | Regression loss: 0.22850 | Running loss: 0.30003\n",
      "Epoch: 14 | Iteration: 43 | Classification loss: 0.03234 | Regression loss: 0.15230 | Running loss: 0.30007\n",
      "Epoch: 14 | Iteration: 44 | Classification loss: 0.24821 | Regression loss: 0.24180 | Running loss: 0.30044\n",
      "Epoch: 14 | Iteration: 45 | Classification loss: 0.06193 | Regression loss: 0.24921 | Running loss: 0.29978\n",
      "Epoch: 14 | Iteration: 46 | Classification loss: 0.07952 | Regression loss: 0.16880 | Running loss: 0.29980\n",
      "Epoch: 14 | Iteration: 47 | Classification loss: 0.05439 | Regression loss: 0.18917 | Running loss: 0.29980\n",
      "Epoch: 14 | Iteration: 48 | Classification loss: 0.05269 | Regression loss: 0.11379 | Running loss: 0.29976\n",
      "Epoch: 14 | Iteration: 49 | Classification loss: 0.06264 | Regression loss: 0.19534 | Running loss: 0.29979\n",
      "Epoch: 14 | Iteration: 50 | Classification loss: 0.04570 | Regression loss: 0.15285 | Running loss: 0.29876\n",
      "Epoch: 14 | Iteration: 51 | Classification loss: 0.02373 | Regression loss: 0.15198 | Running loss: 0.29829\n",
      "Epoch: 14 | Iteration: 52 | Classification loss: 0.01852 | Regression loss: 0.12467 | Running loss: 0.29811\n",
      "Epoch: 14 | Iteration: 53 | Classification loss: 0.02956 | Regression loss: 0.16771 | Running loss: 0.29756\n",
      "Epoch: 14 | Iteration: 54 | Classification loss: 0.04300 | Regression loss: 0.29466 | Running loss: 0.29710\n",
      "Epoch: 14 | Iteration: 55 | Classification loss: 0.11322 | Regression loss: 0.49008 | Running loss: 0.29799\n",
      "Epoch: 14 | Iteration: 56 | Classification loss: 0.06154 | Regression loss: 0.30319 | Running loss: 0.29805\n",
      "Epoch: 14 | Iteration: 57 | Classification loss: 0.08583 | Regression loss: 0.29226 | Running loss: 0.29827\n",
      "Epoch: 14 | Iteration: 58 | Classification loss: 0.15059 | Regression loss: 0.43428 | Running loss: 0.29887\n",
      "Epoch: 14 | Iteration: 59 | Classification loss: 0.11608 | Regression loss: 0.07333 | Running loss: 0.29893\n",
      "Epoch: 14 | Iteration: 60 | Classification loss: 0.08978 | Regression loss: 0.19451 | Running loss: 0.29930\n",
      "Epoch: 14 | Iteration: 61 | Classification loss: 0.06689 | Regression loss: 0.28076 | Running loss: 0.29937\n",
      "Epoch: 14 | Iteration: 62 | Classification loss: 0.02304 | Regression loss: 0.27658 | Running loss: 0.29949\n",
      "Epoch: 14 | Iteration: 63 | Classification loss: 0.03479 | Regression loss: 0.17321 | Running loss: 0.29960\n",
      "Epoch: 14 | Iteration: 64 | Classification loss: 0.03602 | Regression loss: 0.18227 | Running loss: 0.29976\n",
      "Epoch: 14 | Iteration: 65 | Classification loss: 0.04222 | Regression loss: 0.18038 | Running loss: 0.29946\n",
      "Epoch: 14 | Iteration: 66 | Classification loss: 0.08922 | Regression loss: 0.19327 | Running loss: 0.29950\n",
      "Epoch: 14 | Iteration: 67 | Classification loss: 0.19036 | Regression loss: 0.13405 | Running loss: 0.29961\n",
      "Epoch: 14 | Iteration: 68 | Classification loss: 0.05636 | Regression loss: 0.25289 | Running loss: 0.29944\n",
      "Epoch: 14 | Iteration: 69 | Classification loss: 0.11103 | Regression loss: 0.43052 | Running loss: 0.30036\n",
      "Epoch: 14 | Iteration: 70 | Classification loss: 0.01399 | Regression loss: 0.11393 | Running loss: 0.29984\n",
      "Epoch: 14 | Iteration: 71 | Classification loss: 0.13685 | Regression loss: 0.37448 | Running loss: 0.30063\n",
      "Epoch: 14 | Iteration: 72 | Classification loss: 0.15723 | Regression loss: 0.52444 | Running loss: 0.30142\n",
      "Epoch: 14 | Iteration: 73 | Classification loss: 0.10813 | Regression loss: 0.43628 | Running loss: 0.30191\n",
      "Epoch: 14 | Iteration: 74 | Classification loss: 0.09188 | Regression loss: 0.40001 | Running loss: 0.30237\n",
      "Epoch: 14 | Iteration: 75 | Classification loss: 0.06604 | Regression loss: 0.26726 | Running loss: 0.30285\n",
      "Epoch: 14 | Iteration: 76 | Classification loss: 0.08410 | Regression loss: 0.25507 | Running loss: 0.30296\n",
      "Epoch: 14 | Iteration: 77 | Classification loss: 0.09515 | Regression loss: 0.20821 | Running loss: 0.30283\n",
      "Epoch: 14 | Iteration: 78 | Classification loss: 0.09729 | Regression loss: 0.13141 | Running loss: 0.30270\n",
      "Epoch: 14 | Iteration: 79 | Classification loss: 0.01507 | Regression loss: 0.07103 | Running loss: 0.30234\n",
      "Epoch: 14 | Iteration: 80 | Classification loss: 0.03842 | Regression loss: 0.08423 | Running loss: 0.30195\n",
      "Epoch: 14 | Iteration: 81 | Classification loss: 0.18345 | Regression loss: 0.17271 | Running loss: 0.30197\n",
      "Epoch: 14 | Iteration: 82 | Classification loss: 0.02973 | Regression loss: 0.11057 | Running loss: 0.30173\n",
      "Epoch: 14 | Iteration: 83 | Classification loss: 0.06575 | Regression loss: 0.10752 | Running loss: 0.30185\n",
      "Epoch: 14 | Iteration: 84 | Classification loss: 0.11843 | Regression loss: 0.06190 | Running loss: 0.30092\n",
      "Epoch: 14 | Iteration: 85 | Classification loss: 0.06309 | Regression loss: 0.27405 | Running loss: 0.30050\n",
      "Epoch: 14 | Iteration: 86 | Classification loss: 0.03727 | Regression loss: 0.18798 | Running loss: 0.30013\n",
      "Epoch: 14 | Iteration: 87 | Classification loss: 0.03663 | Regression loss: 0.16134 | Running loss: 0.30025\n",
      "Epoch: 14 | Iteration: 88 | Classification loss: 0.04209 | Regression loss: 0.27597 | Running loss: 0.30046\n",
      "Epoch: 14 | Iteration: 89 | Classification loss: 0.14749 | Regression loss: 0.22047 | Running loss: 0.30062\n",
      "Epoch: 14 | Iteration: 90 | Classification loss: 0.03410 | Regression loss: 0.15487 | Running loss: 0.30037\n",
      "Epoch: 14 | Iteration: 91 | Classification loss: 0.14618 | Regression loss: 0.19183 | Running loss: 0.30018\n",
      "Epoch: 14 | Iteration: 92 | Classification loss: 0.02571 | Regression loss: 0.17518 | Running loss: 0.30005\n",
      "Epoch: 14 | Iteration: 93 | Classification loss: 0.02246 | Regression loss: 0.17096 | Running loss: 0.30008\n",
      "Epoch: 14 | Iteration: 94 | Classification loss: 0.07493 | Regression loss: 0.19894 | Running loss: 0.30028\n",
      "Epoch: 14 | Iteration: 95 | Classification loss: 0.10437 | Regression loss: 0.15003 | Running loss: 0.30031\n",
      "Epoch: 14 | Iteration: 96 | Classification loss: 0.03542 | Regression loss: 0.10759 | Running loss: 0.30028\n",
      "Epoch: 14 | Iteration: 97 | Classification loss: 0.09255 | Regression loss: 0.29038 | Running loss: 0.30055\n",
      "Epoch: 14 | Iteration: 98 | Classification loss: 0.08412 | Regression loss: 0.13736 | Running loss: 0.30048\n",
      "Epoch: 14 | Iteration: 99 | Classification loss: 0.12542 | Regression loss: 0.18611 | Running loss: 0.29959\n",
      "Epoch: 14 | Iteration: 100 | Classification loss: 0.06778 | Regression loss: 0.17274 | Running loss: 0.29950\n",
      "Epoch: 14 | Iteration: 101 | Classification loss: 0.01711 | Regression loss: 0.14209 | Running loss: 0.29915\n",
      "Epoch: 14 | Iteration: 102 | Classification loss: 0.02387 | Regression loss: 0.14104 | Running loss: 0.29869\n",
      "Epoch: 14 | Iteration: 103 | Classification loss: 0.01387 | Regression loss: 0.10782 | Running loss: 0.29837\n",
      "Epoch: 14 | Iteration: 104 | Classification loss: 0.06117 | Regression loss: 0.24625 | Running loss: 0.29827\n",
      "Epoch: 14 | Iteration: 105 | Classification loss: 0.01537 | Regression loss: 0.13038 | Running loss: 0.29799\n",
      "Epoch: 14 | Iteration: 106 | Classification loss: 0.09543 | Regression loss: 0.13939 | Running loss: 0.29777\n",
      "Epoch: 14 | Iteration: 107 | Classification loss: 0.04277 | Regression loss: 0.10889 | Running loss: 0.29766\n",
      "Epoch: 14 | Iteration: 108 | Classification loss: 0.03569 | Regression loss: 0.10621 | Running loss: 0.29755\n",
      "Epoch: 14 | Iteration: 109 | Classification loss: 0.03932 | Regression loss: 0.13316 | Running loss: 0.29759\n",
      "Epoch: 14 | Iteration: 110 | Classification loss: 0.05538 | Regression loss: 0.22071 | Running loss: 0.29767\n",
      "Epoch: 14 | Iteration: 111 | Classification loss: 0.03474 | Regression loss: 0.22620 | Running loss: 0.29756\n",
      "Epoch: 14 | Iteration: 112 | Classification loss: 0.02249 | Regression loss: 0.09155 | Running loss: 0.29743\n",
      "Epoch: 14 | Iteration: 113 | Classification loss: 0.05380 | Regression loss: 0.23832 | Running loss: 0.29757\n",
      "Epoch: 14 | Iteration: 114 | Classification loss: 0.16538 | Regression loss: 0.15256 | Running loss: 0.29805\n",
      "Epoch: 14 | Iteration: 115 | Classification loss: 0.04227 | Regression loss: 0.22019 | Running loss: 0.29794\n",
      "Epoch: 14 | Iteration: 116 | Classification loss: 0.03876 | Regression loss: 0.15377 | Running loss: 0.29788\n",
      "Epoch: 14 | Iteration: 117 | Classification loss: 0.07919 | Regression loss: 0.32851 | Running loss: 0.29834\n",
      "Epoch: 14 | Iteration: 118 | Classification loss: 0.09818 | Regression loss: 0.13356 | Running loss: 0.29816\n",
      "Epoch: 14 | Iteration: 119 | Classification loss: 0.04415 | Regression loss: 0.12501 | Running loss: 0.29803\n",
      "Epoch: 14 | Iteration: 120 | Classification loss: 0.03288 | Regression loss: 0.16118 | Running loss: 0.29740\n",
      "Epoch: 14 | Iteration: 121 | Classification loss: 0.02603 | Regression loss: 0.17674 | Running loss: 0.29709\n",
      "Epoch: 14 | Iteration: 122 | Classification loss: 0.04025 | Regression loss: 0.14924 | Running loss: 0.29682\n",
      "Epoch: 14 | Iteration: 123 | Classification loss: 0.02256 | Regression loss: 0.11201 | Running loss: 0.29660\n",
      "Epoch: 14 | Iteration: 124 | Classification loss: 0.02822 | Regression loss: 0.13531 | Running loss: 0.29662\n",
      "Epoch: 14 | Iteration: 125 | Classification loss: 0.06815 | Regression loss: 0.19150 | Running loss: 0.29677\n",
      "Epoch: 14 | Iteration: 126 | Classification loss: 0.14759 | Regression loss: 0.05725 | Running loss: 0.29682\n",
      "Epoch: 14 | Iteration: 127 | Classification loss: 0.04825 | Regression loss: 0.07791 | Running loss: 0.29644\n",
      "Epoch: 14 | Iteration: 128 | Classification loss: 0.13659 | Regression loss: 0.30626 | Running loss: 0.29692\n",
      "Epoch: 14 | Iteration: 129 | Classification loss: 0.08093 | Regression loss: 0.32370 | Running loss: 0.29720\n",
      "Epoch: 14 | Iteration: 130 | Classification loss: 0.06978 | Regression loss: 0.22260 | Running loss: 0.29726\n",
      "Epoch: 14 | Iteration: 131 | Classification loss: 0.03457 | Regression loss: 0.15907 | Running loss: 0.29703\n",
      "Epoch: 14 | Iteration: 132 | Classification loss: 0.05416 | Regression loss: 0.23416 | Running loss: 0.29741\n",
      "Epoch: 14 | Iteration: 133 | Classification loss: 0.08954 | Regression loss: 0.31626 | Running loss: 0.29784\n",
      "Epoch: 14 | Iteration: 134 | Classification loss: 0.28294 | Regression loss: 0.37417 | Running loss: 0.29877\n",
      "Epoch: 14 | Iteration: 135 | Classification loss: 0.13432 | Regression loss: 0.33409 | Running loss: 0.29909\n",
      "Epoch: 14 | Iteration: 136 | Classification loss: 0.03343 | Regression loss: 0.17522 | Running loss: 0.29902\n",
      "Epoch: 14 | Iteration: 137 | Classification loss: 0.02005 | Regression loss: 0.12453 | Running loss: 0.29832\n",
      "Epoch: 14 | Iteration: 138 | Classification loss: 0.02728 | Regression loss: 0.10350 | Running loss: 0.29803\n",
      "Epoch: 14 | Iteration: 139 | Classification loss: 0.04259 | Regression loss: 0.23551 | Running loss: 0.29834\n",
      "Epoch: 14 | Iteration: 140 | Classification loss: 0.12687 | Regression loss: 0.30045 | Running loss: 0.29885\n",
      "Epoch: 14 | Iteration: 141 | Classification loss: 0.23834 | Regression loss: 0.24016 | Running loss: 0.29935\n",
      "Epoch: 14 | Iteration: 142 | Classification loss: 0.08213 | Regression loss: 0.21063 | Running loss: 0.29952\n",
      "Epoch: 14 | Iteration: 143 | Classification loss: 0.06619 | Regression loss: 0.16158 | Running loss: 0.29923\n",
      "Epoch: 14 | Iteration: 144 | Classification loss: 0.04464 | Regression loss: 0.14886 | Running loss: 0.29920\n",
      "Epoch: 14 | Iteration: 145 | Classification loss: 0.05629 | Regression loss: 0.15131 | Running loss: 0.29836\n",
      "Epoch: 14 | Iteration: 146 | Classification loss: 0.02775 | Regression loss: 0.13444 | Running loss: 0.29830\n",
      "Epoch: 14 | Iteration: 147 | Classification loss: 0.05192 | Regression loss: 0.26069 | Running loss: 0.29840\n",
      "Epoch: 14 | Iteration: 148 | Classification loss: 0.02343 | Regression loss: 0.10186 | Running loss: 0.29743\n",
      "Epoch: 14 | Iteration: 149 | Classification loss: 0.08358 | Regression loss: 0.16293 | Running loss: 0.29731\n",
      "Epoch: 14 | Iteration: 150 | Classification loss: 0.04007 | Regression loss: 0.22678 | Running loss: 0.29717\n",
      "Epoch: 14 | Iteration: 151 | Classification loss: 0.12122 | Regression loss: 0.28245 | Running loss: 0.29738\n",
      "Epoch: 14 | Iteration: 152 | Classification loss: 0.02071 | Regression loss: 0.20364 | Running loss: 0.29727\n",
      "Epoch: 14 | Iteration: 153 | Classification loss: 0.04547 | Regression loss: 0.09875 | Running loss: 0.29726\n",
      "Epoch: 14 | Iteration: 154 | Classification loss: 0.06379 | Regression loss: 0.08824 | Running loss: 0.29654\n",
      "Epoch: 14 | Iteration: 155 | Classification loss: 0.08023 | Regression loss: 0.21339 | Running loss: 0.29676\n",
      "Epoch: 14 | Iteration: 156 | Classification loss: 0.03250 | Regression loss: 0.13253 | Running loss: 0.29671\n",
      "Epoch: 14 | Iteration: 157 | Classification loss: 0.06140 | Regression loss: 0.25535 | Running loss: 0.29643\n",
      "Epoch: 14 | Iteration: 158 | Classification loss: 0.08401 | Regression loss: 0.21734 | Running loss: 0.29650\n",
      "Epoch: 14 | Iteration: 159 | Classification loss: 0.11031 | Regression loss: 0.36226 | Running loss: 0.29692\n",
      "Epoch: 14 | Iteration: 160 | Classification loss: 0.02042 | Regression loss: 0.14397 | Running loss: 0.29665\n",
      "Epoch: 14 | Iteration: 161 | Classification loss: 0.08077 | Regression loss: 0.12686 | Running loss: 0.29618\n",
      "Epoch: 14 | Iteration: 162 | Classification loss: 0.00820 | Regression loss: 0.03902 | Running loss: 0.29542\n",
      "Epoch: 14 | Iteration: 163 | Classification loss: 0.07977 | Regression loss: 0.25505 | Running loss: 0.29532\n",
      "Epoch: 14 | Iteration: 164 | Classification loss: 0.01381 | Regression loss: 0.08523 | Running loss: 0.29424\n",
      "Epoch: 14 | Iteration: 165 | Classification loss: 0.20276 | Regression loss: 0.41944 | Running loss: 0.29476\n",
      "Epoch: 14 | Iteration: 166 | Classification loss: 0.01188 | Regression loss: 0.11063 | Running loss: 0.29386\n",
      "Epoch: 14 | Iteration: 167 | Classification loss: 0.05689 | Regression loss: 0.13981 | Running loss: 0.29399\n",
      "Epoch: 14 | Iteration: 168 | Classification loss: 0.12393 | Regression loss: 0.20627 | Running loss: 0.29428\n",
      "Epoch: 14 | Iteration: 169 | Classification loss: 0.02837 | Regression loss: 0.15848 | Running loss: 0.29374\n",
      "Epoch: 14 | Iteration: 170 | Classification loss: 0.06568 | Regression loss: 0.18386 | Running loss: 0.29371\n",
      "Epoch: 14 | Iteration: 171 | Classification loss: 0.26381 | Regression loss: 0.13410 | Running loss: 0.29384\n",
      "Epoch: 14 | Iteration: 172 | Classification loss: 0.05043 | Regression loss: 0.22575 | Running loss: 0.29404\n",
      "Epoch: 14 | Iteration: 173 | Classification loss: 0.06330 | Regression loss: 0.34392 | Running loss: 0.29446\n",
      "Epoch: 14 | Iteration: 174 | Classification loss: 0.02140 | Regression loss: 0.24999 | Running loss: 0.29447\n",
      "Epoch: 14 | Iteration: 175 | Classification loss: 0.02949 | Regression loss: 0.16356 | Running loss: 0.29445\n",
      "Epoch: 14 | Iteration: 176 | Classification loss: 0.02039 | Regression loss: 0.09395 | Running loss: 0.29330\n",
      "Epoch: 14 | Iteration: 177 | Classification loss: 0.04516 | Regression loss: 0.31602 | Running loss: 0.29370\n",
      "Epoch: 14 | Iteration: 178 | Classification loss: 0.03753 | Regression loss: 0.20573 | Running loss: 0.29383\n",
      "Epoch: 14 | Iteration: 179 | Classification loss: 0.02117 | Regression loss: 0.08092 | Running loss: 0.29374\n",
      "Epoch: 14 | Iteration: 180 | Classification loss: 0.08369 | Regression loss: 0.27769 | Running loss: 0.29417\n",
      "Epoch: 14 | Iteration: 181 | Classification loss: 0.02739 | Regression loss: 0.13819 | Running loss: 0.29421\n",
      "Epoch: 14 | Iteration: 182 | Classification loss: 0.27898 | Regression loss: 0.24502 | Running loss: 0.29475\n",
      "Epoch: 14 | Iteration: 183 | Classification loss: 0.05544 | Regression loss: 0.17232 | Running loss: 0.29441\n",
      "Epoch: 14 | Iteration: 184 | Classification loss: 0.04547 | Regression loss: 0.16911 | Running loss: 0.29437\n",
      "Epoch: 14 | Iteration: 185 | Classification loss: 0.03435 | Regression loss: 0.19057 | Running loss: 0.29420\n",
      "Epoch: 14 | Iteration: 186 | Classification loss: 0.02924 | Regression loss: 0.17703 | Running loss: 0.29398\n",
      "Epoch: 14 | Iteration: 187 | Classification loss: 0.03128 | Regression loss: 0.09728 | Running loss: 0.29370\n",
      "Epoch: 14 | Iteration: 188 | Classification loss: 0.04453 | Regression loss: 0.15691 | Running loss: 0.29287\n",
      "Epoch: 14 | Iteration: 189 | Classification loss: 0.17462 | Regression loss: 0.21631 | Running loss: 0.29310\n",
      "Epoch: 14 | Iteration: 190 | Classification loss: 0.22925 | Regression loss: 0.18813 | Running loss: 0.29369\n",
      "Epoch: 14 | Iteration: 191 | Classification loss: 0.07833 | Regression loss: 0.25880 | Running loss: 0.29359\n",
      "Epoch: 14 | Iteration: 192 | Classification loss: 0.07024 | Regression loss: 0.32198 | Running loss: 0.29410\n",
      "Epoch: 14 | Iteration: 193 | Classification loss: 0.06887 | Regression loss: 0.25748 | Running loss: 0.29447\n",
      "Epoch: 14 | Iteration: 194 | Classification loss: 0.03849 | Regression loss: 0.24122 | Running loss: 0.29480\n",
      "Epoch: 14 | Iteration: 195 | Classification loss: 0.14080 | Regression loss: 0.39259 | Running loss: 0.29534\n",
      "Epoch: 14 | Iteration: 196 | Classification loss: 0.10447 | Regression loss: 0.18808 | Running loss: 0.29562\n",
      "Epoch: 14 | Iteration: 197 | Classification loss: 0.07717 | Regression loss: 0.16821 | Running loss: 0.29545\n",
      "Epoch: 14 | Iteration: 198 | Classification loss: 0.05282 | Regression loss: 0.10967 | Running loss: 0.29534\n",
      "Epoch: 14 | Iteration: 199 | Classification loss: 0.03247 | Regression loss: 0.20783 | Running loss: 0.29506\n",
      "Epoch: 14 | Iteration: 200 | Classification loss: 0.07623 | Regression loss: 0.26559 | Running loss: 0.29502\n",
      "Epoch: 14 | Iteration: 201 | Classification loss: 0.06822 | Regression loss: 0.13095 | Running loss: 0.29477\n",
      "Epoch: 14 | Iteration: 202 | Classification loss: 0.04319 | Regression loss: 0.12830 | Running loss: 0.29461\n",
      "Epoch: 14 | Iteration: 203 | Classification loss: 0.17751 | Regression loss: 0.27089 | Running loss: 0.29491\n",
      "Epoch: 14 | Iteration: 204 | Classification loss: 0.05185 | Regression loss: 0.25902 | Running loss: 0.29503\n",
      "Epoch: 14 | Iteration: 205 | Classification loss: 0.12782 | Regression loss: 0.17606 | Running loss: 0.29528\n",
      "Epoch: 14 | Iteration: 206 | Classification loss: 0.02340 | Regression loss: 0.13838 | Running loss: 0.29506\n",
      "Epoch: 14 | Iteration: 207 | Classification loss: 0.06920 | Regression loss: 0.25670 | Running loss: 0.29524\n",
      "Epoch: 14 | Iteration: 208 | Classification loss: 0.33140 | Regression loss: 0.26199 | Running loss: 0.29611\n",
      "Epoch: 14 | Iteration: 209 | Classification loss: 0.16283 | Regression loss: 0.22804 | Running loss: 0.29655\n",
      "Epoch: 14 | Iteration: 210 | Classification loss: 0.07178 | Regression loss: 0.20637 | Running loss: 0.29658\n",
      "Epoch: 14 | Iteration: 211 | Classification loss: 0.02432 | Regression loss: 0.10012 | Running loss: 0.29654\n",
      "Epoch: 14 | Iteration: 212 | Classification loss: 0.06191 | Regression loss: 0.14810 | Running loss: 0.29647\n",
      "Epoch: 14 | Iteration: 213 | Classification loss: 0.02836 | Regression loss: 0.09774 | Running loss: 0.29594\n",
      "Epoch: 14 | Iteration: 214 | Classification loss: 0.12927 | Regression loss: 0.46371 | Running loss: 0.29650\n",
      "Epoch: 14 | Iteration: 215 | Classification loss: 0.10837 | Regression loss: 0.19636 | Running loss: 0.29628\n",
      "Epoch: 14 | Iteration: 216 | Classification loss: 0.03791 | Regression loss: 0.14442 | Running loss: 0.29599\n",
      "Epoch: 14 | Iteration: 217 | Classification loss: 0.03369 | Regression loss: 0.15626 | Running loss: 0.29609\n",
      "Epoch: 14 | Iteration: 218 | Classification loss: 0.03361 | Regression loss: 0.23874 | Running loss: 0.29618\n",
      "Epoch: 14 | Iteration: 219 | Classification loss: 0.02859 | Regression loss: 0.13106 | Running loss: 0.29604\n",
      "Epoch: 14 | Iteration: 220 | Classification loss: 0.02688 | Regression loss: 0.15761 | Running loss: 0.29608\n",
      "Epoch: 14 | Iteration: 221 | Classification loss: 0.07281 | Regression loss: 0.14947 | Running loss: 0.29585\n",
      "Epoch: 14 | Iteration: 222 | Classification loss: 0.04098 | Regression loss: 0.24631 | Running loss: 0.29508\n",
      "Epoch: 14 | Iteration: 223 | Classification loss: 0.06723 | Regression loss: 0.19596 | Running loss: 0.29498\n",
      "Epoch: 14 | Iteration: 224 | Classification loss: 0.02308 | Regression loss: 0.18814 | Running loss: 0.29540\n",
      "Epoch: 14 | Iteration: 225 | Classification loss: 0.03500 | Regression loss: 0.15571 | Running loss: 0.29529\n",
      "Epoch: 14 | Iteration: 226 | Classification loss: 0.03444 | Regression loss: 0.20776 | Running loss: 0.29506\n",
      "Epoch: 14 | Iteration: 227 | Classification loss: 0.28290 | Regression loss: 0.25895 | Running loss: 0.29547\n",
      "Epoch: 14 | Iteration: 228 | Classification loss: 0.12337 | Regression loss: 0.31314 | Running loss: 0.29553\n",
      "Epoch: 14 | Iteration: 229 | Classification loss: 0.02221 | Regression loss: 0.15881 | Running loss: 0.29503\n",
      "Epoch: 14 | Iteration: 230 | Classification loss: 0.06042 | Regression loss: 0.19870 | Running loss: 0.29476\n",
      "Epoch: 14 | Iteration: 231 | Classification loss: 0.01191 | Regression loss: 0.10804 | Running loss: 0.29444\n",
      "Epoch: 14 | Iteration: 232 | Classification loss: 0.05088 | Regression loss: 0.28568 | Running loss: 0.29431\n",
      "Epoch: 14 | Iteration: 233 | Classification loss: 0.15525 | Regression loss: 0.39502 | Running loss: 0.29450\n",
      "Epoch: 14 | Iteration: 234 | Classification loss: 0.02697 | Regression loss: 0.14571 | Running loss: 0.29406\n",
      "Epoch: 14 | Iteration: 235 | Classification loss: 0.09700 | Regression loss: 0.11032 | Running loss: 0.29375\n",
      "Epoch: 14 | Iteration: 236 | Classification loss: 0.05896 | Regression loss: 0.22936 | Running loss: 0.29399\n",
      "Epoch: 14 | Iteration: 237 | Classification loss: 0.03341 | Regression loss: 0.08564 | Running loss: 0.29375\n",
      "Epoch: 14 | Iteration: 238 | Classification loss: 0.11081 | Regression loss: 0.19325 | Running loss: 0.29362\n",
      "Epoch: 14 | Iteration: 239 | Classification loss: 0.03931 | Regression loss: 0.23954 | Running loss: 0.29346\n",
      "Epoch: 14 | Iteration: 240 | Classification loss: 0.04189 | Regression loss: 0.18564 | Running loss: 0.29348\n",
      "Epoch: 14 | Iteration: 241 | Classification loss: 0.04392 | Regression loss: 0.13869 | Running loss: 0.29338\n",
      "Epoch: 14 | Iteration: 242 | Classification loss: 0.05878 | Regression loss: 0.26364 | Running loss: 0.29352\n",
      "Epoch: 14 | Iteration: 243 | Classification loss: 0.33637 | Regression loss: 0.56435 | Running loss: 0.29496\n",
      "Epoch: 14 | Iteration: 244 | Classification loss: 0.03095 | Regression loss: 0.11418 | Running loss: 0.29464\n",
      "Epoch: 14 | Iteration: 245 | Classification loss: 0.03565 | Regression loss: 0.14937 | Running loss: 0.29409\n",
      "Epoch: 14 | Iteration: 246 | Classification loss: 0.03137 | Regression loss: 0.16191 | Running loss: 0.29407\n",
      "Epoch: 14 | Iteration: 247 | Classification loss: 0.02178 | Regression loss: 0.12514 | Running loss: 0.29390\n",
      "Epoch: 14 | Iteration: 248 | Classification loss: 0.05140 | Regression loss: 0.20800 | Running loss: 0.29316\n",
      "Epoch: 14 | Iteration: 249 | Classification loss: 0.04833 | Regression loss: 0.19446 | Running loss: 0.29270\n",
      "Epoch: 14 | Iteration: 250 | Classification loss: 0.01761 | Regression loss: 0.13839 | Running loss: 0.29259\n",
      "Epoch: 14 | Iteration: 251 | Classification loss: 0.02266 | Regression loss: 0.12369 | Running loss: 0.29179\n",
      "Epoch: 14 | Iteration: 252 | Classification loss: 0.03604 | Regression loss: 0.23342 | Running loss: 0.29192\n",
      "Epoch: 14 | Iteration: 253 | Classification loss: 0.07254 | Regression loss: 0.16427 | Running loss: 0.29156\n",
      "Epoch: 14 | Iteration: 254 | Classification loss: 0.37291 | Regression loss: 0.39260 | Running loss: 0.29173\n",
      "Epoch: 14 | Iteration: 255 | Classification loss: 0.06604 | Regression loss: 0.18020 | Running loss: 0.29136\n",
      "Epoch: 14 | Iteration: 256 | Classification loss: 0.06398 | Regression loss: 0.30686 | Running loss: 0.29121\n",
      "Epoch: 14 | Iteration: 257 | Classification loss: 0.06387 | Regression loss: 0.21602 | Running loss: 0.29106\n",
      "Epoch: 14 | Iteration: 258 | Classification loss: 0.09256 | Regression loss: 0.34394 | Running loss: 0.29133\n",
      "Epoch: 14 | Iteration: 259 | Classification loss: 0.07282 | Regression loss: 0.13840 | Running loss: 0.29145\n",
      "Epoch: 14 | Iteration: 260 | Classification loss: 0.14742 | Regression loss: 0.12792 | Running loss: 0.29157\n",
      "Epoch: 14 | Iteration: 261 | Classification loss: 0.05648 | Regression loss: 0.32521 | Running loss: 0.29181\n",
      "Epoch: 14 | Iteration: 262 | Classification loss: 0.02798 | Regression loss: 0.12788 | Running loss: 0.29182\n",
      "Epoch: 14 | Iteration: 263 | Classification loss: 0.02002 | Regression loss: 0.12960 | Running loss: 0.29090\n",
      "Epoch: 14 | Iteration: 264 | Classification loss: 0.11798 | Regression loss: 0.25693 | Running loss: 0.29131\n",
      "Epoch: 14 | Iteration: 265 | Classification loss: 0.03464 | Regression loss: 0.14173 | Running loss: 0.29082\n",
      "Epoch: 14 | Iteration: 266 | Classification loss: 0.08207 | Regression loss: 0.31866 | Running loss: 0.29120\n",
      "Epoch: 14 | Iteration: 267 | Classification loss: 0.05345 | Regression loss: 0.22378 | Running loss: 0.29086\n",
      "Epoch: 14 | Iteration: 268 | Classification loss: 0.09250 | Regression loss: 0.20535 | Running loss: 0.29066\n",
      "Epoch: 14 | Iteration: 269 | Classification loss: 0.02724 | Regression loss: 0.25397 | Running loss: 0.29065\n",
      "Epoch: 14 | Iteration: 270 | Classification loss: 0.09151 | Regression loss: 0.21013 | Running loss: 0.29075\n",
      "Epoch: 14 | Iteration: 271 | Classification loss: 0.07511 | Regression loss: 0.21576 | Running loss: 0.29060\n",
      "Epoch: 14 | Iteration: 272 | Classification loss: 0.04360 | Regression loss: 0.15479 | Running loss: 0.29061\n",
      "Epoch: 14 | Iteration: 273 | Classification loss: 0.28005 | Regression loss: 0.10919 | Running loss: 0.29094\n",
      "Epoch: 14 | Iteration: 274 | Classification loss: 0.03372 | Regression loss: 0.23019 | Running loss: 0.29029\n",
      "Epoch: 14 | Iteration: 275 | Classification loss: 0.03139 | Regression loss: 0.18991 | Running loss: 0.29016\n",
      "Epoch: 14 | Iteration: 276 | Classification loss: 0.04486 | Regression loss: 0.17572 | Running loss: 0.28998\n",
      "Epoch: 14 | Iteration: 277 | Classification loss: 0.07473 | Regression loss: 0.28194 | Running loss: 0.29025\n",
      "Epoch: 14 | Iteration: 278 | Classification loss: 0.03124 | Regression loss: 0.14347 | Running loss: 0.28977\n",
      "Epoch: 14 | Iteration: 279 | Classification loss: 0.01769 | Regression loss: 0.11651 | Running loss: 0.28946\n",
      "Epoch: 14 | Iteration: 280 | Classification loss: 0.02490 | Regression loss: 0.18538 | Running loss: 0.28954\n",
      "Epoch: 14 | Iteration: 281 | Classification loss: 0.11988 | Regression loss: 0.15580 | Running loss: 0.28944\n",
      "Epoch: 14 | Iteration: 282 | Classification loss: 0.03212 | Regression loss: 0.15080 | Running loss: 0.28890\n",
      "Epoch: 14 | Iteration: 283 | Classification loss: 0.03754 | Regression loss: 0.26813 | Running loss: 0.28886\n",
      "Epoch: 14 | Iteration: 284 | Classification loss: 0.07783 | Regression loss: 0.22389 | Running loss: 0.28891\n",
      "Epoch: 14 | Iteration: 285 | Classification loss: 0.35173 | Regression loss: 0.14477 | Running loss: 0.28956\n",
      "Epoch: 14 | Iteration: 286 | Classification loss: 0.06446 | Regression loss: 0.17080 | Running loss: 0.28974\n",
      "Epoch: 14 | Iteration: 287 | Classification loss: 0.08790 | Regression loss: 0.22496 | Running loss: 0.29010\n",
      "Epoch: 14 | Iteration: 288 | Classification loss: 0.07471 | Regression loss: 0.18362 | Running loss: 0.29000\n",
      "Epoch: 14 | Iteration: 289 | Classification loss: 0.08236 | Regression loss: 0.15215 | Running loss: 0.28939\n",
      "Epoch: 14 | Iteration: 290 | Classification loss: 0.04903 | Regression loss: 0.19053 | Running loss: 0.28869\n",
      "Epoch: 14 | Iteration: 291 | Classification loss: 0.07721 | Regression loss: 0.31578 | Running loss: 0.28878\n",
      "Epoch: 14 | Iteration: 292 | Classification loss: 0.11879 | Regression loss: 0.23332 | Running loss: 0.28919\n",
      "Epoch: 14 | Iteration: 293 | Classification loss: 0.16453 | Regression loss: 0.39822 | Running loss: 0.28971\n",
      "Epoch: 14 | Iteration: 294 | Classification loss: 0.05045 | Regression loss: 0.08985 | Running loss: 0.28963\n",
      "Epoch: 14 | Iteration: 295 | Classification loss: 0.02739 | Regression loss: 0.08999 | Running loss: 0.28924\n",
      "Epoch: 14 | Iteration: 296 | Classification loss: 0.11739 | Regression loss: 0.19798 | Running loss: 0.28928\n",
      "Epoch: 14 | Iteration: 297 | Classification loss: 0.03202 | Regression loss: 0.17432 | Running loss: 0.28921\n",
      "Epoch: 14 | Iteration: 298 | Classification loss: 0.03191 | Regression loss: 0.12668 | Running loss: 0.28866\n",
      "Epoch: 14 | Iteration: 299 | Classification loss: 0.05910 | Regression loss: 0.22780 | Running loss: 0.28881\n",
      "Epoch: 14 | Iteration: 300 | Classification loss: 0.04253 | Regression loss: 0.25538 | Running loss: 0.28837\n",
      "Epoch: 14 | Iteration: 301 | Classification loss: 0.06815 | Regression loss: 0.25278 | Running loss: 0.28831\n",
      "Epoch: 14 | Iteration: 302 | Classification loss: 0.05617 | Regression loss: 0.24851 | Running loss: 0.28861\n",
      "Epoch: 14 | Iteration: 303 | Classification loss: 0.23265 | Regression loss: 0.15093 | Running loss: 0.28845\n",
      "Epoch: 14 | Iteration: 304 | Classification loss: 0.10712 | Regression loss: 0.12444 | Running loss: 0.28842\n",
      "Epoch: 14 | Iteration: 305 | Classification loss: 0.02158 | Regression loss: 0.18966 | Running loss: 0.28785\n",
      "Epoch: 14 | Iteration: 306 | Classification loss: 0.26950 | Regression loss: 0.44882 | Running loss: 0.28886\n",
      "Epoch: 14 | Iteration: 307 | Classification loss: 0.02033 | Regression loss: 0.12552 | Running loss: 0.28855\n",
      "Epoch: 14 | Iteration: 308 | Classification loss: 0.04793 | Regression loss: 0.25810 | Running loss: 0.28850\n",
      "Epoch: 14 | Iteration: 309 | Classification loss: 0.07365 | Regression loss: 0.31068 | Running loss: 0.28874\n",
      "Epoch: 14 | Iteration: 310 | Classification loss: 0.05489 | Regression loss: 0.30265 | Running loss: 0.28879\n",
      "Epoch: 14 | Iteration: 311 | Classification loss: 0.02841 | Regression loss: 0.09950 | Running loss: 0.28866\n",
      "Epoch: 14 | Iteration: 312 | Classification loss: 0.02765 | Regression loss: 0.21301 | Running loss: 0.28857\n",
      "Epoch: 14 | Iteration: 313 | Classification loss: 0.45274 | Regression loss: 0.24630 | Running loss: 0.28957\n",
      "Epoch: 14 | Iteration: 314 | Classification loss: 0.01959 | Regression loss: 0.09387 | Running loss: 0.28936\n",
      "Epoch: 14 | Iteration: 315 | Classification loss: 0.04733 | Regression loss: 0.14480 | Running loss: 0.28906\n",
      "Epoch: 14 | Iteration: 316 | Classification loss: 0.04888 | Regression loss: 0.16862 | Running loss: 0.28909\n",
      "Epoch: 14 | Iteration: 317 | Classification loss: 0.09241 | Regression loss: 0.21821 | Running loss: 0.28906\n",
      "Epoch: 14 | Iteration: 318 | Classification loss: 0.03476 | Regression loss: 0.13382 | Running loss: 0.28861\n",
      "Epoch: 14 | Iteration: 319 | Classification loss: 0.06825 | Regression loss: 0.23425 | Running loss: 0.28873\n",
      "Epoch: 14 | Iteration: 320 | Classification loss: 0.05039 | Regression loss: 0.18830 | Running loss: 0.28894\n",
      "Epoch: 14 | Iteration: 321 | Classification loss: 0.10849 | Regression loss: 0.39145 | Running loss: 0.28957\n",
      "Epoch: 14 | Iteration: 322 | Classification loss: 0.04494 | Regression loss: 0.21620 | Running loss: 0.28975\n",
      "Epoch: 14 | Iteration: 323 | Classification loss: 0.02179 | Regression loss: 0.15598 | Running loss: 0.28976\n",
      "Epoch: 14 | Iteration: 324 | Classification loss: 0.07972 | Regression loss: 0.31046 | Running loss: 0.29006\n",
      "Epoch: 14 | Iteration: 325 | Classification loss: 0.01598 | Regression loss: 0.12251 | Running loss: 0.28986\n",
      "Epoch: 14 | Iteration: 326 | Classification loss: 0.19157 | Regression loss: 0.42520 | Running loss: 0.29070\n",
      "Epoch: 14 | Iteration: 327 | Classification loss: 0.07420 | Regression loss: 0.19025 | Running loss: 0.29077\n",
      "Epoch: 14 | Iteration: 328 | Classification loss: 0.03994 | Regression loss: 0.37437 | Running loss: 0.29121\n",
      "Epoch: 14 | Iteration: 329 | Classification loss: 0.04190 | Regression loss: 0.12379 | Running loss: 0.29112\n",
      "Epoch: 14 | Iteration: 330 | Classification loss: 0.01914 | Regression loss: 0.10576 | Running loss: 0.29086\n",
      "Epoch: 14 | Iteration: 331 | Classification loss: 0.01598 | Regression loss: 0.15258 | Running loss: 0.29070\n",
      "Epoch: 14 | Iteration: 332 | Classification loss: 0.02736 | Regression loss: 0.08612 | Running loss: 0.29054\n",
      "Epoch: 14 | Iteration: 333 | Classification loss: 0.07804 | Regression loss: 0.23190 | Running loss: 0.29060\n",
      "Epoch: 14 | Iteration: 334 | Classification loss: 0.01641 | Regression loss: 0.11965 | Running loss: 0.29041\n",
      "Epoch: 14 | Iteration: 335 | Classification loss: 0.01270 | Regression loss: 0.08562 | Running loss: 0.29018\n",
      "Epoch: 14 | Iteration: 336 | Classification loss: 0.05773 | Regression loss: 0.26341 | Running loss: 0.29031\n",
      "Epoch: 14 | Iteration: 337 | Classification loss: 0.12748 | Regression loss: 0.06989 | Running loss: 0.29049\n",
      "Epoch: 14 | Iteration: 338 | Classification loss: 0.07210 | Regression loss: 0.08504 | Running loss: 0.29040\n",
      "Epoch: 14 | Iteration: 339 | Classification loss: 0.02720 | Regression loss: 0.19404 | Running loss: 0.29085\n",
      "Epoch: 14 | Iteration: 340 | Classification loss: 0.09810 | Regression loss: 0.30169 | Running loss: 0.29102\n",
      "Epoch: 14 | Iteration: 341 | Classification loss: 0.05785 | Regression loss: 0.14349 | Running loss: 0.29094\n",
      "Epoch: 14 | Iteration: 342 | Classification loss: 0.05546 | Regression loss: 0.12670 | Running loss: 0.29083\n",
      "Epoch: 14 | Iteration: 343 | Classification loss: 0.02368 | Regression loss: 0.18564 | Running loss: 0.29074\n",
      "Epoch: 14 | Iteration: 344 | Classification loss: 0.05444 | Regression loss: 0.20322 | Running loss: 0.29086\n",
      "Epoch: 14 | Iteration: 345 | Classification loss: 0.12212 | Regression loss: 0.26950 | Running loss: 0.29126\n",
      "Epoch: 14 | Iteration: 346 | Classification loss: 0.02897 | Regression loss: 0.16556 | Running loss: 0.29128\n",
      "Epoch: 14 | Iteration: 347 | Classification loss: 0.03815 | Regression loss: 0.14433 | Running loss: 0.29133\n",
      "Epoch: 14 | Iteration: 348 | Classification loss: 0.08228 | Regression loss: 0.28401 | Running loss: 0.29138\n",
      "Epoch: 14 | Iteration: 349 | Classification loss: 0.01535 | Regression loss: 0.12082 | Running loss: 0.29100\n",
      "Epoch: 14 | Iteration: 350 | Classification loss: 0.17004 | Regression loss: 0.36026 | Running loss: 0.29106\n",
      "Epoch: 14 | Iteration: 351 | Classification loss: 0.07982 | Regression loss: 0.10353 | Running loss: 0.29067\n",
      "Epoch: 14 | Iteration: 352 | Classification loss: 0.08732 | Regression loss: 0.19191 | Running loss: 0.29087\n",
      "Epoch: 14 | Iteration: 353 | Classification loss: 0.04736 | Regression loss: 0.40080 | Running loss: 0.29134\n",
      "Epoch: 14 | Iteration: 354 | Classification loss: 0.03344 | Regression loss: 0.24369 | Running loss: 0.29149\n",
      "Epoch: 14 | Iteration: 355 | Classification loss: 0.05107 | Regression loss: 0.17449 | Running loss: 0.29161\n",
      "Epoch: 14 | Iteration: 356 | Classification loss: 0.09479 | Regression loss: 0.12581 | Running loss: 0.29097\n",
      "Epoch: 14 | Iteration: 357 | Classification loss: 0.05041 | Regression loss: 0.23380 | Running loss: 0.29072\n",
      "Epoch: 14 | Iteration: 358 | Classification loss: 0.03125 | Regression loss: 0.20735 | Running loss: 0.29004\n",
      "Epoch: 14 | Iteration: 359 | Classification loss: 0.25681 | Regression loss: 0.10512 | Running loss: 0.29055\n",
      "Epoch: 14 | Iteration: 360 | Classification loss: 0.05403 | Regression loss: 0.31253 | Running loss: 0.29072\n",
      "Epoch: 14 | Iteration: 361 | Classification loss: 0.08506 | Regression loss: 0.25933 | Running loss: 0.29093\n",
      "Epoch: 14 | Iteration: 362 | Classification loss: 0.04475 | Regression loss: 0.19155 | Running loss: 0.29115\n",
      "Epoch: 14 | Iteration: 363 | Classification loss: 0.03366 | Regression loss: 0.20355 | Running loss: 0.29027\n",
      "Epoch: 14 | Iteration: 364 | Classification loss: 0.07334 | Regression loss: 0.17877 | Running loss: 0.29050\n",
      "Epoch: 14 | Iteration: 365 | Classification loss: 0.03298 | Regression loss: 0.14833 | Running loss: 0.29028\n",
      "Epoch: 14 | Iteration: 366 | Classification loss: 0.12858 | Regression loss: 0.33077 | Running loss: 0.29028\n",
      "Epoch: 14 | Iteration: 367 | Classification loss: 0.21265 | Regression loss: 0.44428 | Running loss: 0.29041\n",
      "Epoch: 14 | Iteration: 368 | Classification loss: 0.11445 | Regression loss: 0.20591 | Running loss: 0.29069\n",
      "Epoch: 14 | Iteration: 369 | Classification loss: 0.04311 | Regression loss: 0.23212 | Running loss: 0.29050\n",
      "Epoch: 14 | Iteration: 370 | Classification loss: 0.16109 | Regression loss: 0.35168 | Running loss: 0.29120\n",
      "Epoch: 14 | Iteration: 371 | Classification loss: 0.13774 | Regression loss: 0.27394 | Running loss: 0.29173\n",
      "Epoch: 14 | Iteration: 372 | Classification loss: 0.09286 | Regression loss: 0.35716 | Running loss: 0.29246\n",
      "Epoch: 14 | Iteration: 373 | Classification loss: 0.04780 | Regression loss: 0.17278 | Running loss: 0.29258\n",
      "Epoch: 14 | Iteration: 374 | Classification loss: 0.07613 | Regression loss: 0.09178 | Running loss: 0.29241\n",
      "Epoch: 14 | Iteration: 375 | Classification loss: 0.08094 | Regression loss: 0.31426 | Running loss: 0.29277\n",
      "Epoch: 14 | Iteration: 376 | Classification loss: 0.17214 | Regression loss: 0.50351 | Running loss: 0.29352\n",
      "Epoch: 14 | Iteration: 377 | Classification loss: 0.03754 | Regression loss: 0.22085 | Running loss: 0.29199\n",
      "Epoch: 14 | Iteration: 378 | Classification loss: 0.01726 | Regression loss: 0.09748 | Running loss: 0.29146\n",
      "Epoch: 14 | Iteration: 379 | Classification loss: 0.02180 | Regression loss: 0.17223 | Running loss: 0.29122\n",
      "Epoch: 14 | Iteration: 380 | Classification loss: 0.03254 | Regression loss: 0.11272 | Running loss: 0.29095\n",
      "Epoch: 14 | Iteration: 381 | Classification loss: 0.10431 | Regression loss: 0.18346 | Running loss: 0.29076\n",
      "Epoch: 14 | Iteration: 382 | Classification loss: 0.02798 | Regression loss: 0.26659 | Running loss: 0.29091\n",
      "Epoch: 14 | Iteration: 383 | Classification loss: 0.12666 | Regression loss: 0.16801 | Running loss: 0.29113\n",
      "Epoch: 14 | Iteration: 384 | Classification loss: 0.11452 | Regression loss: 0.17157 | Running loss: 0.29142\n",
      "Epoch: 14 | Iteration: 385 | Classification loss: 0.06224 | Regression loss: 0.05795 | Running loss: 0.29076\n",
      "Epoch: 14 | Iteration: 386 | Classification loss: 0.07630 | Regression loss: 0.20083 | Running loss: 0.29085\n",
      "Epoch: 14 | Iteration: 387 | Classification loss: 0.03283 | Regression loss: 0.08514 | Running loss: 0.29066\n",
      "Epoch: 14 | Iteration: 388 | Classification loss: 0.06515 | Regression loss: 0.22491 | Running loss: 0.29050\n",
      "Epoch: 14 | Iteration: 389 | Classification loss: 0.04073 | Regression loss: 0.34338 | Running loss: 0.29040\n",
      "Epoch: 14 | Iteration: 390 | Classification loss: 0.17770 | Regression loss: 0.28096 | Running loss: 0.29070\n",
      "Epoch: 14 | Iteration: 391 | Classification loss: 0.03803 | Regression loss: 0.23547 | Running loss: 0.29057\n",
      "Epoch: 14 | Iteration: 392 | Classification loss: 0.03194 | Regression loss: 0.14902 | Running loss: 0.29033\n",
      "Epoch: 14 | Iteration: 393 | Classification loss: 0.18122 | Regression loss: 0.26591 | Running loss: 0.29084\n",
      "Epoch: 14 | Iteration: 394 | Classification loss: 0.06161 | Regression loss: 0.17398 | Running loss: 0.29024\n",
      "Epoch: 14 | Iteration: 395 | Classification loss: 0.03341 | Regression loss: 0.08979 | Running loss: 0.28980\n",
      "Epoch: 14 | Iteration: 396 | Classification loss: 0.11567 | Regression loss: 0.34476 | Running loss: 0.29037\n",
      "Epoch: 14 | Iteration: 397 | Classification loss: 0.01779 | Regression loss: 0.13399 | Running loss: 0.29017\n",
      "Epoch: 14 | Iteration: 398 | Classification loss: 0.13060 | Regression loss: 0.30795 | Running loss: 0.29068\n",
      "Epoch: 14 | Iteration: 399 | Classification loss: 0.03533 | Regression loss: 0.18017 | Running loss: 0.29048\n",
      "Epoch: 14 | Iteration: 400 | Classification loss: 0.09032 | Regression loss: 0.20986 | Running loss: 0.29049\n",
      "Epoch: 14 | Iteration: 401 | Classification loss: 0.07166 | Regression loss: 0.22836 | Running loss: 0.29080\n",
      "Epoch: 14 | Iteration: 402 | Classification loss: 0.15168 | Regression loss: 0.22253 | Running loss: 0.29108\n",
      "Epoch: 14 | Iteration: 403 | Classification loss: 0.05456 | Regression loss: 0.22397 | Running loss: 0.29121\n",
      "Epoch: 14 | Iteration: 404 | Classification loss: 0.02914 | Regression loss: 0.19006 | Running loss: 0.29111\n",
      "Epoch: 14 | Iteration: 405 | Classification loss: 0.03652 | Regression loss: 0.12333 | Running loss: 0.29064\n",
      "Epoch: 14 | Iteration: 406 | Classification loss: 0.04862 | Regression loss: 0.13087 | Running loss: 0.29047\n",
      "Epoch: 14 | Iteration: 407 | Classification loss: 0.06854 | Regression loss: 0.12273 | Running loss: 0.29028\n",
      "Epoch: 14 | Iteration: 408 | Classification loss: 0.05711 | Regression loss: 0.20850 | Running loss: 0.29046\n",
      "Epoch: 14 | Iteration: 409 | Classification loss: 0.06833 | Regression loss: 0.26270 | Running loss: 0.29071\n",
      "Epoch: 14 | Iteration: 410 | Classification loss: 0.06239 | Regression loss: 0.25640 | Running loss: 0.29059\n",
      "Epoch: 14 | Iteration: 411 | Classification loss: 0.07467 | Regression loss: 0.27453 | Running loss: 0.29089\n",
      "Epoch: 14 | Iteration: 412 | Classification loss: 0.09628 | Regression loss: 0.27099 | Running loss: 0.29103\n",
      "Epoch: 14 | Iteration: 413 | Classification loss: 0.03942 | Regression loss: 0.23703 | Running loss: 0.29112\n",
      "Epoch: 14 | Iteration: 414 | Classification loss: 0.06324 | Regression loss: 0.24355 | Running loss: 0.29103\n",
      "Epoch: 14 | Iteration: 415 | Classification loss: 0.02198 | Regression loss: 0.16288 | Running loss: 0.29053\n",
      "Epoch: 14 | Iteration: 416 | Classification loss: 0.07309 | Regression loss: 0.16197 | Running loss: 0.29050\n",
      "Epoch: 14 | Iteration: 417 | Classification loss: 0.02075 | Regression loss: 0.14860 | Running loss: 0.28970\n",
      "Epoch: 14 | Iteration: 418 | Classification loss: 0.03677 | Regression loss: 0.14305 | Running loss: 0.28953\n",
      "Epoch: 14 | Iteration: 419 | Classification loss: 0.15238 | Regression loss: 0.45426 | Running loss: 0.29024\n",
      "Epoch: 14 | Iteration: 420 | Classification loss: 0.01384 | Regression loss: 0.07245 | Running loss: 0.28962\n",
      "Epoch: 14 | Iteration: 421 | Classification loss: 0.10729 | Regression loss: 0.20373 | Running loss: 0.28920\n",
      "Epoch: 14 | Iteration: 422 | Classification loss: 0.05192 | Regression loss: 0.15975 | Running loss: 0.28901\n",
      "Epoch: 14 | Iteration: 423 | Classification loss: 0.05553 | Regression loss: 0.15893 | Running loss: 0.28839\n",
      "Epoch: 14 | Iteration: 424 | Classification loss: 0.08388 | Regression loss: 0.24615 | Running loss: 0.28832\n",
      "Epoch: 14 | Iteration: 425 | Classification loss: 0.05477 | Regression loss: 0.22346 | Running loss: 0.28845\n",
      "Epoch: 14 | Iteration: 426 | Classification loss: 0.04236 | Regression loss: 0.26945 | Running loss: 0.28854\n",
      "Epoch: 14 | Iteration: 427 | Classification loss: 0.03424 | Regression loss: 0.13668 | Running loss: 0.28847\n",
      "Epoch: 14 | Iteration: 428 | Classification loss: 0.11876 | Regression loss: 0.16599 | Running loss: 0.28856\n",
      "Epoch: 14 | Iteration: 429 | Classification loss: 0.05732 | Regression loss: 0.31473 | Running loss: 0.28777\n",
      "Epoch: 14 | Iteration: 430 | Classification loss: 0.05587 | Regression loss: 0.32786 | Running loss: 0.28813\n",
      "Epoch: 14 | Iteration: 431 | Classification loss: 0.04771 | Regression loss: 0.14496 | Running loss: 0.28756\n",
      "Epoch: 14 | Iteration: 432 | Classification loss: 0.02676 | Regression loss: 0.18375 | Running loss: 0.28704\n",
      "Epoch: 14 | Iteration: 433 | Classification loss: 0.04895 | Regression loss: 0.16039 | Running loss: 0.28656\n",
      "Epoch: 14 | Iteration: 434 | Classification loss: 0.02344 | Regression loss: 0.12289 | Running loss: 0.28646\n",
      "Epoch: 14 | Iteration: 435 | Classification loss: 0.06940 | Regression loss: 0.07181 | Running loss: 0.28636\n",
      "Epoch: 14 | Iteration: 436 | Classification loss: 0.01021 | Regression loss: 0.12564 | Running loss: 0.28612\n",
      "Epoch: 14 | Iteration: 437 | Classification loss: 0.03731 | Regression loss: 0.17467 | Running loss: 0.28612\n",
      "Epoch: 14 | Iteration: 438 | Classification loss: 0.03228 | Regression loss: 0.17977 | Running loss: 0.28589\n",
      "Epoch: 14 | Iteration: 439 | Classification loss: 0.15387 | Regression loss: 0.14614 | Running loss: 0.28598\n",
      "Epoch: 14 | Iteration: 440 | Classification loss: 0.02260 | Regression loss: 0.14123 | Running loss: 0.28580\n",
      "Epoch: 14 | Iteration: 441 | Classification loss: 0.22277 | Regression loss: 0.09330 | Running loss: 0.28593\n",
      "Epoch: 14 | Iteration: 442 | Classification loss: 0.02349 | Regression loss: 0.12109 | Running loss: 0.28576\n",
      "Epoch: 14 | Iteration: 443 | Classification loss: 0.03207 | Regression loss: 0.13032 | Running loss: 0.28546\n",
      "Epoch: 14 | Iteration: 444 | Classification loss: 0.01612 | Regression loss: 0.09337 | Running loss: 0.28507\n",
      "Epoch: 14 | Iteration: 445 | Classification loss: 0.03693 | Regression loss: 0.20882 | Running loss: 0.28528\n",
      "Epoch: 14 | Iteration: 446 | Classification loss: 0.15654 | Regression loss: 0.38545 | Running loss: 0.28558\n",
      "Epoch: 14 | Iteration: 447 | Classification loss: 0.05998 | Regression loss: 0.26571 | Running loss: 0.28605\n",
      "Epoch: 14 | Iteration: 448 | Classification loss: 0.08389 | Regression loss: 0.19720 | Running loss: 0.28617\n",
      "Epoch: 14 | Iteration: 449 | Classification loss: 0.07832 | Regression loss: 0.24008 | Running loss: 0.28627\n",
      "Epoch: 14 | Iteration: 450 | Classification loss: 0.03458 | Regression loss: 0.11212 | Running loss: 0.28559\n",
      "Epoch: 14 | Iteration: 451 | Classification loss: 0.09028 | Regression loss: 0.21603 | Running loss: 0.28437\n",
      "Epoch: 14 | Iteration: 452 | Classification loss: 0.00922 | Regression loss: 0.05982 | Running loss: 0.28345\n",
      "Epoch: 14 | Iteration: 453 | Classification loss: 0.03333 | Regression loss: 0.20797 | Running loss: 0.28339\n",
      "Epoch: 14 | Iteration: 454 | Classification loss: 0.02110 | Regression loss: 0.07452 | Running loss: 0.28238\n",
      "Epoch: 14 | Iteration: 455 | Classification loss: 0.09322 | Regression loss: 0.13011 | Running loss: 0.28241\n",
      "Epoch: 14 | Iteration: 456 | Classification loss: 0.04613 | Regression loss: 0.15768 | Running loss: 0.28232\n",
      "Epoch: 14 | Iteration: 457 | Classification loss: 0.09564 | Regression loss: 0.18920 | Running loss: 0.28220\n",
      "Epoch: 14 | Iteration: 458 | Classification loss: 0.12674 | Regression loss: 0.17047 | Running loss: 0.28158\n",
      "Epoch: 14 | Iteration: 459 | Classification loss: 0.25835 | Regression loss: 0.52387 | Running loss: 0.28226\n",
      "Epoch: 14 | Iteration: 460 | Classification loss: 0.02108 | Regression loss: 0.07405 | Running loss: 0.28151\n",
      "Epoch: 14 | Iteration: 461 | Classification loss: 0.08695 | Regression loss: 0.15056 | Running loss: 0.28167\n",
      "Epoch: 14 | Iteration: 462 | Classification loss: 0.04559 | Regression loss: 0.23101 | Running loss: 0.28160\n",
      "Epoch: 14 | Iteration: 463 | Classification loss: 0.06728 | Regression loss: 0.08786 | Running loss: 0.28111\n",
      "Epoch: 14 | Iteration: 464 | Classification loss: 0.11990 | Regression loss: 0.31916 | Running loss: 0.28130\n",
      "Epoch: 14 | Iteration: 465 | Classification loss: 0.14887 | Regression loss: 0.28158 | Running loss: 0.28158\n",
      "Epoch: 14 | Iteration: 466 | Classification loss: 0.04240 | Regression loss: 0.23635 | Running loss: 0.28167\n",
      "Epoch: 14 | Iteration: 467 | Classification loss: 0.04227 | Regression loss: 0.19795 | Running loss: 0.28173\n",
      "Epoch: 14 | Iteration: 468 | Classification loss: 0.08778 | Regression loss: 0.13833 | Running loss: 0.28100\n",
      "Epoch: 14 | Iteration: 469 | Classification loss: 0.07064 | Regression loss: 0.09826 | Running loss: 0.28048\n",
      "Epoch: 14 | Iteration: 470 | Classification loss: 0.09584 | Regression loss: 0.12661 | Running loss: 0.27998\n",
      "Epoch: 14 | Iteration: 471 | Classification loss: 0.02927 | Regression loss: 0.14352 | Running loss: 0.28002\n",
      "Epoch: 14 | Iteration: 472 | Classification loss: 0.08921 | Regression loss: 0.19422 | Running loss: 0.28006\n",
      "Epoch: 14 | Iteration: 473 | Classification loss: 0.02181 | Regression loss: 0.15467 | Running loss: 0.28004\n",
      "Epoch: 14 | Iteration: 474 | Classification loss: 0.10326 | Regression loss: 0.23707 | Running loss: 0.27988\n",
      "Epoch: 14 | Iteration: 475 | Classification loss: 0.05215 | Regression loss: 0.26411 | Running loss: 0.28007\n",
      "Epoch: 14 | Iteration: 476 | Classification loss: 0.08592 | Regression loss: 0.29879 | Running loss: 0.28009\n",
      "Epoch: 14 | Iteration: 477 | Classification loss: 0.08657 | Regression loss: 0.32873 | Running loss: 0.28016\n",
      "Epoch: 14 | Iteration: 478 | Classification loss: 0.06739 | Regression loss: 0.15558 | Running loss: 0.27971\n",
      "Epoch: 14 | Iteration: 479 | Classification loss: 0.04624 | Regression loss: 0.15791 | Running loss: 0.27895\n",
      "Epoch: 14 | Iteration: 480 | Classification loss: 0.11346 | Regression loss: 0.15769 | Running loss: 0.27904\n",
      "Epoch: 14 | Iteration: 481 | Classification loss: 0.02838 | Regression loss: 0.25016 | Running loss: 0.27903\n",
      "Epoch: 14 | Iteration: 482 | Classification loss: 0.05196 | Regression loss: 0.24804 | Running loss: 0.27911\n",
      "Epoch: 14 | Iteration: 483 | Classification loss: 0.08873 | Regression loss: 0.20069 | Running loss: 0.27823\n",
      "Epoch: 14 | Iteration: 484 | Classification loss: 0.04823 | Regression loss: 0.16224 | Running loss: 0.27800\n",
      "Epoch: 14 | Iteration: 485 | Classification loss: 0.12898 | Regression loss: 0.07828 | Running loss: 0.27786\n",
      "Epoch: 14 | Iteration: 486 | Classification loss: 0.07615 | Regression loss: 0.10482 | Running loss: 0.27777\n",
      "Epoch: 14 | Iteration: 487 | Classification loss: 0.13250 | Regression loss: 0.36417 | Running loss: 0.27824\n",
      "Epoch: 14 | Iteration: 488 | Classification loss: 0.06807 | Regression loss: 0.23635 | Running loss: 0.27812\n",
      "Epoch: 14 | Iteration: 489 | Classification loss: 0.05891 | Regression loss: 0.11285 | Running loss: 0.27778\n",
      "Epoch: 14 | Iteration: 490 | Classification loss: 0.09362 | Regression loss: 0.36161 | Running loss: 0.27844\n",
      "Epoch: 14 | Iteration: 491 | Classification loss: 0.02363 | Regression loss: 0.09424 | Running loss: 0.27795\n",
      "Epoch: 14 | Iteration: 492 | Classification loss: 0.11717 | Regression loss: 0.28617 | Running loss: 0.27834\n",
      "Epoch: 14 | Iteration: 493 | Classification loss: 0.08040 | Regression loss: 0.26104 | Running loss: 0.27826\n",
      "Epoch: 14 | Iteration: 494 | Classification loss: 0.06682 | Regression loss: 0.14000 | Running loss: 0.27827\n",
      "Epoch: 14 | Iteration: 495 | Classification loss: 0.02122 | Regression loss: 0.14534 | Running loss: 0.27814\n",
      "Epoch: 14 | Iteration: 496 | Classification loss: 0.05009 | Regression loss: 0.20387 | Running loss: 0.27824\n",
      "Epoch: 14 | Iteration: 497 | Classification loss: 0.09019 | Regression loss: 0.31510 | Running loss: 0.27821\n",
      "Epoch: 14 | Iteration: 498 | Classification loss: 0.13137 | Regression loss: 0.30862 | Running loss: 0.27859\n",
      "Epoch: 14 | Iteration: 499 | Classification loss: 0.14556 | Regression loss: 0.29680 | Running loss: 0.27884\n",
      "Epoch: 14 | Iteration: 500 | Classification loss: 0.06158 | Regression loss: 0.20227 | Running loss: 0.27867\n",
      "Epoch: 14 | Iteration: 501 | Classification loss: 0.14531 | Regression loss: 0.22158 | Running loss: 0.27889\n",
      "Epoch: 14 | Iteration: 502 | Classification loss: 0.13023 | Regression loss: 0.48750 | Running loss: 0.27955\n",
      "Epoch: 14 | Iteration: 503 | Classification loss: 0.03940 | Regression loss: 0.20094 | Running loss: 0.27974\n",
      "Epoch: 14 | Iteration: 504 | Classification loss: 0.08035 | Regression loss: 0.27490 | Running loss: 0.27978\n",
      "Epoch: 14 | Iteration: 505 | Classification loss: 0.24974 | Regression loss: 0.41327 | Running loss: 0.28061\n",
      "Epoch: 14 | Iteration: 506 | Classification loss: 0.05701 | Regression loss: 0.10527 | Running loss: 0.28060\n",
      "Epoch: 14 | Iteration: 507 | Classification loss: 0.11917 | Regression loss: 0.26681 | Running loss: 0.28090\n",
      "Epoch: 14 | Iteration: 508 | Classification loss: 0.02144 | Regression loss: 0.11471 | Running loss: 0.28055\n",
      "Epoch: 14 | Iteration: 509 | Classification loss: 0.02735 | Regression loss: 0.07641 | Running loss: 0.28040\n",
      "Epoch: 14 | Iteration: 510 | Classification loss: 0.04953 | Regression loss: 0.27628 | Running loss: 0.28070\n",
      "Epoch: 14 | Iteration: 511 | Classification loss: 0.08079 | Regression loss: 0.20190 | Running loss: 0.28083\n",
      "Epoch: 14 | Iteration: 512 | Classification loss: 0.05711 | Regression loss: 0.22587 | Running loss: 0.28019\n",
      "Epoch: 14 | Iteration: 513 | Classification loss: 0.06972 | Regression loss: 0.15449 | Running loss: 0.28033\n",
      "Epoch: 14 | Iteration: 514 | Classification loss: 0.14982 | Regression loss: 0.38959 | Running loss: 0.28102\n",
      "Epoch: 14 | Iteration: 515 | Classification loss: 0.03310 | Regression loss: 0.11114 | Running loss: 0.28011\n",
      "Epoch: 14 | Iteration: 516 | Classification loss: 0.10178 | Regression loss: 0.14173 | Running loss: 0.27877\n",
      "Epoch: 14 | Iteration: 517 | Classification loss: 0.15984 | Regression loss: 0.35554 | Running loss: 0.27953\n",
      "Epoch: 14 | Iteration: 518 | Classification loss: 0.15546 | Regression loss: 0.25458 | Running loss: 0.27997\n",
      "Epoch: 14 | Iteration: 519 | Classification loss: 0.03467 | Regression loss: 0.23288 | Running loss: 0.27998\n",
      "Epoch: 14 | Iteration: 520 | Classification loss: 0.04137 | Regression loss: 0.14972 | Running loss: 0.27979\n",
      "Epoch: 14 | Iteration: 521 | Classification loss: 0.06224 | Regression loss: 0.26495 | Running loss: 0.27962\n",
      "Epoch: 14 | Iteration: 522 | Classification loss: 0.02796 | Regression loss: 0.14871 | Running loss: 0.27876\n",
      "Epoch: 14 | Iteration: 523 | Classification loss: 0.10665 | Regression loss: 0.13458 | Running loss: 0.27888\n",
      "Epoch: 14 | Iteration: 524 | Classification loss: 0.06795 | Regression loss: 0.24224 | Running loss: 0.27891\n",
      "Epoch: 14 | Iteration: 525 | Classification loss: 0.03602 | Regression loss: 0.13646 | Running loss: 0.27884\n",
      "Epoch: 14 | Iteration: 526 | Classification loss: 0.09888 | Regression loss: 0.19945 | Running loss: 0.27906\n",
      "Epoch: 14 | Iteration: 527 | Classification loss: 0.02410 | Regression loss: 0.04142 | Running loss: 0.27841\n",
      "Epoch: 14 | Iteration: 528 | Classification loss: 0.12736 | Regression loss: 0.21729 | Running loss: 0.27820\n",
      "Epoch: 14 | Iteration: 529 | Classification loss: 0.14161 | Regression loss: 0.39177 | Running loss: 0.27846\n",
      "Epoch: 14 | Iteration: 530 | Classification loss: 0.14252 | Regression loss: 0.40115 | Running loss: 0.27880\n",
      "Epoch: 14 | Iteration: 531 | Classification loss: 0.14841 | Regression loss: 0.30929 | Running loss: 0.27909\n",
      "Epoch: 14 | Iteration: 532 | Classification loss: 0.02581 | Regression loss: 0.15632 | Running loss: 0.27892\n",
      "Epoch: 14 | Iteration: 533 | Classification loss: 0.07959 | Regression loss: 0.28776 | Running loss: 0.27932\n",
      "Epoch: 14 | Iteration: 534 | Classification loss: 0.03481 | Regression loss: 0.18330 | Running loss: 0.27877\n",
      "Epoch: 14 | Iteration: 535 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.27829\n",
      "Epoch: 14 | Iteration: 536 | Classification loss: 0.06713 | Regression loss: 0.23292 | Running loss: 0.27849\n",
      "Epoch: 14 | Iteration: 537 | Classification loss: 0.05100 | Regression loss: 0.09617 | Running loss: 0.27838\n",
      "Epoch: 14 | Iteration: 538 | Classification loss: 0.05793 | Regression loss: 0.11273 | Running loss: 0.27824\n",
      "Epoch: 14 | Iteration: 539 | Classification loss: 0.04433 | Regression loss: 0.14763 | Running loss: 0.27770\n",
      "Epoch: 14 | Iteration: 540 | Classification loss: 0.07365 | Regression loss: 0.36602 | Running loss: 0.27819\n",
      "Epoch: 14 | Iteration: 541 | Classification loss: 0.04968 | Regression loss: 0.15349 | Running loss: 0.27786\n",
      "Epoch: 14 | Iteration: 542 | Classification loss: 0.03582 | Regression loss: 0.14497 | Running loss: 0.27761\n",
      "Epoch: 14 | Iteration: 543 | Classification loss: 0.01974 | Regression loss: 0.15393 | Running loss: 0.27759\n",
      "Epoch: 14 | Iteration: 544 | Classification loss: 0.18002 | Regression loss: 0.42481 | Running loss: 0.27781\n",
      "Epoch: 14 | Iteration: 545 | Classification loss: 0.07418 | Regression loss: 0.09866 | Running loss: 0.27754\n",
      "Epoch: 14 | Iteration: 546 | Classification loss: 0.01862 | Regression loss: 0.16713 | Running loss: 0.27741\n",
      "Epoch: 14 | Iteration: 547 | Classification loss: 0.09629 | Regression loss: 0.29470 | Running loss: 0.27771\n",
      "Epoch: 14 | Iteration: 548 | Classification loss: 0.07067 | Regression loss: 0.14203 | Running loss: 0.27780\n",
      "Epoch: 14 | Iteration: 549 | Classification loss: 0.05267 | Regression loss: 0.27688 | Running loss: 0.27794\n",
      "Epoch: 14 | Iteration: 550 | Classification loss: 0.09866 | Regression loss: 0.24253 | Running loss: 0.27823\n",
      "Epoch: 14 | Iteration: 551 | Classification loss: 0.02723 | Regression loss: 0.20969 | Running loss: 0.27835\n",
      "Epoch: 14 | Iteration: 552 | Classification loss: 0.03285 | Regression loss: 0.22085 | Running loss: 0.27857\n",
      "Epoch: 14 | Iteration: 553 | Classification loss: 0.03944 | Regression loss: 0.23165 | Running loss: 0.27872\n",
      "Epoch: 14 | Iteration: 554 | Classification loss: 0.05488 | Regression loss: 0.13344 | Running loss: 0.27842\n",
      "Epoch: 14 | Iteration: 555 | Classification loss: 0.19582 | Regression loss: 0.35191 | Running loss: 0.27831\n",
      "Epoch: 14 | Iteration: 556 | Classification loss: 0.03465 | Regression loss: 0.24473 | Running loss: 0.27814\n",
      "Epoch: 14 | Iteration: 557 | Classification loss: 0.06762 | Regression loss: 0.22473 | Running loss: 0.27797\n",
      "Epoch: 14 | Iteration: 558 | Classification loss: 0.09351 | Regression loss: 0.20449 | Running loss: 0.27739\n",
      "Epoch: 14 | Iteration: 559 | Classification loss: 0.01429 | Regression loss: 0.11017 | Running loss: 0.27726\n",
      "Epoch: 14 | Iteration: 560 | Classification loss: 0.09691 | Regression loss: 0.39082 | Running loss: 0.27767\n",
      "Epoch: 14 | Iteration: 561 | Classification loss: 0.06546 | Regression loss: 0.19593 | Running loss: 0.27750\n",
      "Epoch: 14 | Iteration: 562 | Classification loss: 0.02815 | Regression loss: 0.20621 | Running loss: 0.27737\n",
      "Epoch: 14 | Iteration: 563 | Classification loss: 0.15676 | Regression loss: 0.14585 | Running loss: 0.27756\n",
      "Epoch: 14 | Iteration: 564 | Classification loss: 0.27557 | Regression loss: 0.14218 | Running loss: 0.27796\n",
      "Epoch: 14 | Iteration: 565 | Classification loss: 0.06373 | Regression loss: 0.18080 | Running loss: 0.27800\n",
      "Epoch: 14 | Iteration: 566 | Classification loss: 0.24006 | Regression loss: 0.47458 | Running loss: 0.27886\n",
      "Epoch: 14 | Iteration: 567 | Classification loss: 0.04202 | Regression loss: 0.18110 | Running loss: 0.27866\n",
      "Epoch: 14 | Iteration: 568 | Classification loss: 0.02079 | Regression loss: 0.13599 | Running loss: 0.27836\n",
      "Epoch: 14 | Iteration: 569 | Classification loss: 0.04782 | Regression loss: 0.09975 | Running loss: 0.27757\n",
      "Epoch: 14 | Iteration: 570 | Classification loss: 0.02893 | Regression loss: 0.13201 | Running loss: 0.27763\n",
      "Epoch: 14 | Iteration: 571 | Classification loss: 0.08240 | Regression loss: 0.07424 | Running loss: 0.27693\n",
      "Epoch: 14 | Iteration: 572 | Classification loss: 0.07821 | Regression loss: 0.37124 | Running loss: 0.27646\n",
      "Epoch: 14 | Iteration: 573 | Classification loss: 0.17090 | Regression loss: 0.40605 | Running loss: 0.27653\n",
      "Epoch: 14 | Iteration: 574 | Classification loss: 0.04481 | Regression loss: 0.22623 | Running loss: 0.27608\n",
      "Epoch: 14 | Iteration: 575 | Classification loss: 0.02045 | Regression loss: 0.10885 | Running loss: 0.27568\n",
      "Epoch: 14 | Iteration: 576 | Classification loss: 0.02851 | Regression loss: 0.17276 | Running loss: 0.27540\n",
      "Epoch: 14 | Iteration: 577 | Classification loss: 0.01818 | Regression loss: 0.13721 | Running loss: 0.27510\n",
      "Epoch: 14 | Iteration: 578 | Classification loss: 0.21742 | Regression loss: 0.43412 | Running loss: 0.27595\n",
      "Epoch: 14 | Iteration: 579 | Classification loss: 0.23436 | Regression loss: 0.13123 | Running loss: 0.27651\n",
      "Epoch: 14 | Iteration: 580 | Classification loss: 0.07916 | Regression loss: 0.18449 | Running loss: 0.27679\n",
      "Epoch: 14 | Iteration: 581 | Classification loss: 0.09793 | Regression loss: 0.13040 | Running loss: 0.27654\n",
      "Epoch: 14 | Iteration: 582 | Classification loss: 0.05947 | Regression loss: 0.25466 | Running loss: 0.27688\n",
      "Epoch: 14 | Iteration: 583 | Classification loss: 0.15156 | Regression loss: 0.33943 | Running loss: 0.27752\n",
      "Epoch: 14 | Iteration: 584 | Classification loss: 0.25299 | Regression loss: 0.07660 | Running loss: 0.27782\n",
      "Epoch: 14 | Iteration: 585 | Classification loss: 0.08801 | Regression loss: 0.25333 | Running loss: 0.27783\n",
      "Epoch: 14 | Iteration: 586 | Classification loss: 0.04506 | Regression loss: 0.14539 | Running loss: 0.27776\n",
      "Epoch: 14 | Iteration: 587 | Classification loss: 0.10280 | Regression loss: 0.22309 | Running loss: 0.27801\n",
      "Epoch: 14 | Iteration: 588 | Classification loss: 0.03845 | Regression loss: 0.13280 | Running loss: 0.27772\n",
      "Epoch: 14 | Iteration: 589 | Classification loss: 0.17673 | Regression loss: 0.36797 | Running loss: 0.27807\n",
      "Epoch: 14 | Iteration: 590 | Classification loss: 0.03406 | Regression loss: 0.14169 | Running loss: 0.27805\n",
      "Epoch: 14 | Iteration: 591 | Classification loss: 0.03135 | Regression loss: 0.24195 | Running loss: 0.27792\n",
      "Epoch: 14 | Iteration: 592 | Classification loss: 0.60200 | Regression loss: 0.26195 | Running loss: 0.27924\n",
      "Epoch: 14 | Iteration: 593 | Classification loss: 0.43575 | Regression loss: 0.11749 | Running loss: 0.27996\n",
      "Epoch: 14 | Iteration: 594 | Classification loss: 0.06457 | Regression loss: 0.27814 | Running loss: 0.28010\n",
      "Epoch: 14 | Iteration: 595 | Classification loss: 0.28055 | Regression loss: 0.28420 | Running loss: 0.28072\n",
      "Epoch: 14 | Iteration: 596 | Classification loss: 0.08090 | Regression loss: 0.49473 | Running loss: 0.28159\n",
      "Epoch: 14 | Iteration: 597 | Classification loss: 0.04581 | Regression loss: 0.21112 | Running loss: 0.28133\n",
      "Epoch: 14 | Iteration: 598 | Classification loss: 0.08720 | Regression loss: 0.14310 | Running loss: 0.28135\n",
      "Epoch: 14 | Iteration: 599 | Classification loss: 0.07112 | Regression loss: 0.25198 | Running loss: 0.28137\n",
      "Epoch: 14 | Iteration: 600 | Classification loss: 0.04381 | Regression loss: 0.26814 | Running loss: 0.28152\n",
      "Epoch: 14 | Iteration: 601 | Classification loss: 0.04580 | Regression loss: 0.11277 | Running loss: 0.28152\n",
      "Epoch: 14 | Iteration: 602 | Classification loss: 0.07857 | Regression loss: 0.32948 | Running loss: 0.28200\n",
      "Epoch: 14 | Iteration: 603 | Classification loss: 0.13932 | Regression loss: 0.26541 | Running loss: 0.28257\n",
      "Epoch: 14 | Iteration: 604 | Classification loss: 0.08419 | Regression loss: 0.20286 | Running loss: 0.28253\n",
      "Epoch: 14 | Iteration: 605 | Classification loss: 0.03855 | Regression loss: 0.18072 | Running loss: 0.28267\n",
      "Epoch: 14 | Iteration: 606 | Classification loss: 0.03332 | Regression loss: 0.26122 | Running loss: 0.28279\n",
      "Epoch: 14 | Iteration: 607 | Classification loss: 0.03227 | Regression loss: 0.11949 | Running loss: 0.28279\n",
      "Epoch: 14 | Iteration: 608 | Classification loss: 0.22854 | Regression loss: 0.26162 | Running loss: 0.28349\n",
      "Epoch: 14 | Iteration: 609 | Classification loss: 0.06258 | Regression loss: 0.12502 | Running loss: 0.28352\n",
      "Epoch: 14 | Iteration: 610 | Classification loss: 0.07217 | Regression loss: 0.17150 | Running loss: 0.28346\n",
      "Epoch: 14 | Iteration: 611 | Classification loss: 0.06428 | Regression loss: 0.25128 | Running loss: 0.28357\n",
      "Epoch: 14 | Iteration: 612 | Classification loss: 0.21373 | Regression loss: 0.47782 | Running loss: 0.28472\n",
      "Epoch: 14 | Iteration: 613 | Classification loss: 0.04597 | Regression loss: 0.08602 | Running loss: 0.28440\n",
      "Epoch: 14 | Iteration: 614 | Classification loss: 0.06034 | Regression loss: 0.16956 | Running loss: 0.28422\n",
      "Epoch: 14 | Iteration: 615 | Classification loss: 0.15449 | Regression loss: 0.43224 | Running loss: 0.28487\n",
      "Epoch: 14 | Iteration: 616 | Classification loss: 0.06714 | Regression loss: 0.19795 | Running loss: 0.28502\n",
      "Epoch: 14 | Iteration: 617 | Classification loss: 0.04793 | Regression loss: 0.16646 | Running loss: 0.28463\n",
      "Epoch: 14 | Iteration: 618 | Classification loss: 0.09693 | Regression loss: 0.25805 | Running loss: 0.28488\n",
      "Epoch: 14 | Iteration: 619 | Classification loss: 0.06566 | Regression loss: 0.24662 | Running loss: 0.28516\n",
      "Epoch: 14 | Iteration: 620 | Classification loss: 0.03080 | Regression loss: 0.21464 | Running loss: 0.28527\n",
      "Epoch: 14 | Iteration: 621 | Classification loss: 0.09113 | Regression loss: 0.45181 | Running loss: 0.28595\n",
      "Epoch: 14 | Iteration: 622 | Classification loss: 0.04344 | Regression loss: 0.14830 | Running loss: 0.28595\n",
      "Epoch: 14 | Iteration: 623 | Classification loss: 0.04846 | Regression loss: 0.19711 | Running loss: 0.28617\n",
      "Epoch: 14 | Iteration: 624 | Classification loss: 0.07293 | Regression loss: 0.21873 | Running loss: 0.28643\n",
      "Epoch: 14 | Iteration: 625 | Classification loss: 0.02909 | Regression loss: 0.30185 | Running loss: 0.28657\n",
      "Epoch: 14 | Iteration: 626 | Classification loss: 0.01836 | Regression loss: 0.15586 | Running loss: 0.28651\n",
      "Epoch: 14 | Iteration: 627 | Classification loss: 0.41829 | Regression loss: 0.22433 | Running loss: 0.28754\n",
      "Epoch: 14 | Iteration: 628 | Classification loss: 0.14113 | Regression loss: 0.24346 | Running loss: 0.28743\n",
      "Epoch: 14 | Iteration: 629 | Classification loss: 0.12635 | Regression loss: 0.29443 | Running loss: 0.28746\n",
      "Epoch: 14 | Iteration: 630 | Classification loss: 0.02721 | Regression loss: 0.22960 | Running loss: 0.28739\n",
      "Epoch: 14 | Iteration: 631 | Classification loss: 0.02788 | Regression loss: 0.18683 | Running loss: 0.28743\n",
      "Epoch: 14 | Iteration: 632 | Classification loss: 0.04668 | Regression loss: 0.29739 | Running loss: 0.28754\n",
      "Epoch: 14 | Iteration: 633 | Classification loss: 0.03212 | Regression loss: 0.15826 | Running loss: 0.28711\n",
      "Epoch: 14 | Iteration: 634 | Classification loss: 0.10471 | Regression loss: 0.20353 | Running loss: 0.28641\n",
      "Epoch: 14 | Iteration: 635 | Classification loss: 0.04082 | Regression loss: 0.11950 | Running loss: 0.28580\n",
      "Epoch: 14 | Iteration: 636 | Classification loss: 0.05497 | Regression loss: 0.11927 | Running loss: 0.28573\n",
      "Epoch: 14 | Iteration: 637 | Classification loss: 0.16414 | Regression loss: 0.30685 | Running loss: 0.28638\n",
      "Epoch: 14 | Iteration: 638 | Classification loss: 0.03011 | Regression loss: 0.30277 | Running loss: 0.28679\n",
      "Epoch: 14 | Iteration: 639 | Classification loss: 0.02574 | Regression loss: 0.11577 | Running loss: 0.28651\n",
      "Epoch: 14 | Iteration: 640 | Classification loss: 0.06148 | Regression loss: 0.24797 | Running loss: 0.28628\n",
      "Epoch: 14 | Iteration: 641 | Classification loss: 0.15294 | Regression loss: 0.10402 | Running loss: 0.28583\n",
      "Epoch: 14 | Iteration: 642 | Classification loss: 0.03483 | Regression loss: 0.14168 | Running loss: 0.28560\n",
      "Epoch: 14 | Iteration: 643 | Classification loss: 0.02798 | Regression loss: 0.17191 | Running loss: 0.28554\n",
      "Epoch: 14 | Iteration: 644 | Classification loss: 0.04386 | Regression loss: 0.22238 | Running loss: 0.28569\n",
      "Epoch: 14 | Iteration: 645 | Classification loss: 0.03454 | Regression loss: 0.17440 | Running loss: 0.28569\n",
      "Epoch: 14 | Iteration: 646 | Classification loss: 0.12741 | Regression loss: 0.18238 | Running loss: 0.28599\n",
      "Epoch: 14 | Iteration: 647 | Classification loss: 0.04208 | Regression loss: 0.13808 | Running loss: 0.28572\n",
      "Epoch: 14 | Iteration: 648 | Classification loss: 0.04641 | Regression loss: 0.20013 | Running loss: 0.28597\n",
      "Epoch: 14 | Iteration: 649 | Classification loss: 0.02274 | Regression loss: 0.11131 | Running loss: 0.28574\n",
      "Epoch: 14 | Iteration: 650 | Classification loss: 0.01379 | Regression loss: 0.07361 | Running loss: 0.28538\n",
      "Epoch: 14 | Iteration: 651 | Classification loss: 0.06768 | Regression loss: 0.24857 | Running loss: 0.28521\n",
      "Epoch: 14 | Iteration: 652 | Classification loss: 0.08071 | Regression loss: 0.19106 | Running loss: 0.28530\n",
      "Epoch: 14 | Iteration: 653 | Classification loss: 0.07018 | Regression loss: 0.10384 | Running loss: 0.28536\n",
      "Epoch: 14 | Iteration: 654 | Classification loss: 0.07768 | Regression loss: 0.26406 | Running loss: 0.28574\n",
      "Epoch: 14 | Iteration: 655 | Classification loss: 0.11388 | Regression loss: 0.28333 | Running loss: 0.28595\n",
      "Epoch: 14 | Iteration: 656 | Classification loss: 0.09595 | Regression loss: 0.29239 | Running loss: 0.28639\n",
      "Epoch: 14 | Iteration: 657 | Classification loss: 0.44987 | Regression loss: 0.28112 | Running loss: 0.28722\n",
      "Epoch: 14 | Iteration: 658 | Classification loss: 0.02590 | Regression loss: 0.10876 | Running loss: 0.28689\n",
      "Epoch: 14 | Iteration: 659 | Classification loss: 0.10895 | Regression loss: 0.20676 | Running loss: 0.28658\n",
      "Epoch: 14 | Iteration: 660 | Classification loss: 0.11034 | Regression loss: 0.21228 | Running loss: 0.28689\n",
      "Epoch: 14 | Iteration: 661 | Classification loss: 0.03808 | Regression loss: 0.14774 | Running loss: 0.28685\n",
      "Epoch: 14 | Iteration: 662 | Classification loss: 0.05957 | Regression loss: 0.28004 | Running loss: 0.28743\n",
      "Epoch: 14 | Iteration: 663 | Classification loss: 0.09920 | Regression loss: 0.10009 | Running loss: 0.28716\n",
      "Epoch: 14 | Iteration: 664 | Classification loss: 0.03957 | Regression loss: 0.15076 | Running loss: 0.28735\n",
      "Epoch: 14 | Iteration: 665 | Classification loss: 0.10914 | Regression loss: 0.36616 | Running loss: 0.28705\n",
      "Epoch: 14 | Iteration: 666 | Classification loss: 0.14479 | Regression loss: 0.39348 | Running loss: 0.28788\n",
      "Epoch: 14 | Iteration: 667 | Classification loss: 0.03984 | Regression loss: 0.17160 | Running loss: 0.28791\n",
      "Epoch: 14 | Iteration: 668 | Classification loss: 0.02693 | Regression loss: 0.16368 | Running loss: 0.28763\n",
      "Epoch: 14 | Iteration: 669 | Classification loss: 0.03586 | Regression loss: 0.10703 | Running loss: 0.28755\n",
      "Epoch: 14 | Iteration: 670 | Classification loss: 0.06943 | Regression loss: 0.08539 | Running loss: 0.28736\n",
      "Epoch: 14 | Iteration: 671 | Classification loss: 0.11198 | Regression loss: 0.35501 | Running loss: 0.28749\n",
      "Epoch: 14 | Iteration: 672 | Classification loss: 0.03596 | Regression loss: 0.10538 | Running loss: 0.28722\n",
      "Epoch: 14 | Iteration: 673 | Classification loss: 0.14998 | Regression loss: 0.18708 | Running loss: 0.28708\n",
      "Epoch: 14 | Iteration: 674 | Classification loss: 0.05199 | Regression loss: 0.10980 | Running loss: 0.28687\n",
      "Epoch: 14 | Iteration: 675 | Classification loss: 0.17439 | Regression loss: 0.34076 | Running loss: 0.28751\n",
      "Epoch: 14 | Iteration: 676 | Classification loss: 0.27870 | Regression loss: 0.35601 | Running loss: 0.28855\n",
      "Epoch: 14 | Iteration: 677 | Classification loss: 0.02607 | Regression loss: 0.13294 | Running loss: 0.28815\n",
      "Epoch: 14 | Iteration: 678 | Classification loss: 0.02571 | Regression loss: 0.16239 | Running loss: 0.28804\n",
      "Epoch: 14 | Iteration: 679 | Classification loss: 0.01742 | Regression loss: 0.16100 | Running loss: 0.28819\n",
      "Epoch: 14 | Iteration: 680 | Classification loss: 0.01714 | Regression loss: 0.09875 | Running loss: 0.28770\n",
      "Epoch: 14 | Iteration: 681 | Classification loss: 0.03484 | Regression loss: 0.17967 | Running loss: 0.28779\n",
      "Epoch: 14 | Iteration: 682 | Classification loss: 0.07847 | Regression loss: 0.17831 | Running loss: 0.28726\n",
      "Epoch: 14 | Iteration: 683 | Classification loss: 0.07754 | Regression loss: 0.14394 | Running loss: 0.28725\n",
      "Epoch: 14 | Iteration: 684 | Classification loss: 0.02767 | Regression loss: 0.23254 | Running loss: 0.28734\n",
      "Epoch: 14 | Iteration: 685 | Classification loss: 0.02580 | Regression loss: 0.17049 | Running loss: 0.28728\n",
      "Epoch: 14 | Iteration: 686 | Classification loss: 0.07472 | Regression loss: 0.16166 | Running loss: 0.28734\n",
      "Epoch: 14 | Iteration: 687 | Classification loss: 0.04731 | Regression loss: 0.21624 | Running loss: 0.28761\n",
      "Epoch: 14 | Iteration: 688 | Classification loss: 0.02896 | Regression loss: 0.22592 | Running loss: 0.28772\n",
      "Epoch: 14 | Iteration: 689 | Classification loss: 0.05508 | Regression loss: 0.19670 | Running loss: 0.28744\n",
      "Epoch: 14 | Iteration: 690 | Classification loss: 0.11953 | Regression loss: 0.19599 | Running loss: 0.28724\n",
      "Epoch: 14 | Iteration: 691 | Classification loss: 0.17206 | Regression loss: 0.32711 | Running loss: 0.28756\n",
      "Epoch: 14 | Iteration: 692 | Classification loss: 0.14826 | Regression loss: 0.29579 | Running loss: 0.28766\n",
      "Epoch: 14 | Iteration: 693 | Classification loss: 0.13670 | Regression loss: 0.21558 | Running loss: 0.28772\n",
      "Epoch: 14 | Iteration: 694 | Classification loss: 0.06394 | Regression loss: 0.15615 | Running loss: 0.28760\n",
      "Epoch: 14 | Iteration: 695 | Classification loss: 0.06822 | Regression loss: 0.29355 | Running loss: 0.28725\n",
      "Epoch: 14 | Iteration: 696 | Classification loss: 0.13518 | Regression loss: 0.17484 | Running loss: 0.28729\n",
      "Epoch: 14 | Iteration: 697 | Classification loss: 0.07102 | Regression loss: 0.29151 | Running loss: 0.28752\n",
      "Epoch: 14 | Iteration: 698 | Classification loss: 0.05004 | Regression loss: 0.19001 | Running loss: 0.28768\n",
      "Epoch: 14 | Iteration: 699 | Classification loss: 0.09547 | Regression loss: 0.30439 | Running loss: 0.28800\n",
      "Epoch: 14 | Iteration: 700 | Classification loss: 0.05129 | Regression loss: 0.26248 | Running loss: 0.28794\n",
      "Epoch: 14 | Iteration: 701 | Classification loss: 0.09652 | Regression loss: 0.10917 | Running loss: 0.28795\n",
      "Epoch: 14 | Iteration: 702 | Classification loss: 0.18812 | Regression loss: 0.17883 | Running loss: 0.28835\n",
      "Epoch: 14 | Iteration: 703 | Classification loss: 0.18367 | Regression loss: 0.27457 | Running loss: 0.28836\n",
      "Epoch: 14 | Iteration: 704 | Classification loss: 0.04890 | Regression loss: 0.08295 | Running loss: 0.28801\n",
      "Epoch: 14 | Iteration: 705 | Classification loss: 0.06362 | Regression loss: 0.10345 | Running loss: 0.28773\n",
      "Epoch: 14 | Iteration: 706 | Classification loss: 0.02413 | Regression loss: 0.29260 | Running loss: 0.28804\n",
      "Epoch: 14 | Iteration: 707 | Classification loss: 0.03448 | Regression loss: 0.17284 | Running loss: 0.28781\n",
      "Epoch: 14 | Iteration: 708 | Classification loss: 0.03921 | Regression loss: 0.15684 | Running loss: 0.28701\n",
      "Epoch: 14 | Iteration: 709 | Classification loss: 0.18670 | Regression loss: 0.39683 | Running loss: 0.28740\n",
      "Epoch: 14 | Iteration: 710 | Classification loss: 0.17491 | Regression loss: 0.19763 | Running loss: 0.28759\n",
      "Epoch: 14 | Iteration: 711 | Classification loss: 0.12312 | Regression loss: 0.24076 | Running loss: 0.28806\n",
      "Epoch: 14 | Iteration: 712 | Classification loss: 0.05577 | Regression loss: 0.12360 | Running loss: 0.28800\n",
      "Epoch: 14 | Iteration: 713 | Classification loss: 0.01613 | Regression loss: 0.11793 | Running loss: 0.28802\n",
      "Epoch: 14 | Iteration: 714 | Classification loss: 0.05778 | Regression loss: 0.21387 | Running loss: 0.28738\n",
      "Epoch: 14 | Iteration: 715 | Classification loss: 0.04519 | Regression loss: 0.31402 | Running loss: 0.28749\n",
      "Epoch: 14 | Iteration: 716 | Classification loss: 0.03974 | Regression loss: 0.31319 | Running loss: 0.28783\n",
      "Epoch: 14 | Iteration: 717 | Classification loss: 0.02083 | Regression loss: 0.14333 | Running loss: 0.28777\n",
      "Epoch: 14 | Iteration: 718 | Classification loss: 0.09271 | Regression loss: 0.27929 | Running loss: 0.28797\n",
      "Epoch: 14 | Iteration: 719 | Classification loss: 0.02850 | Regression loss: 0.10108 | Running loss: 0.28791\n",
      "Epoch: 14 | Iteration: 720 | Classification loss: 0.21981 | Regression loss: 0.21026 | Running loss: 0.28841\n",
      "Epoch: 14 | Iteration: 721 | Classification loss: 0.07186 | Regression loss: 0.13412 | Running loss: 0.28837\n",
      "Epoch: 14 | Iteration: 722 | Classification loss: 0.03101 | Regression loss: 0.18553 | Running loss: 0.28823\n",
      "Epoch: 14 | Iteration: 723 | Classification loss: 0.10919 | Regression loss: 0.14891 | Running loss: 0.28822\n",
      "Epoch: 14 | Iteration: 724 | Classification loss: 0.02310 | Regression loss: 0.21583 | Running loss: 0.28828\n",
      "Epoch: 14 | Iteration: 725 | Classification loss: 0.02675 | Regression loss: 0.25841 | Running loss: 0.28847\n",
      "Epoch: 14 | Iteration: 726 | Classification loss: 0.16440 | Regression loss: 0.23559 | Running loss: 0.28878\n",
      "Epoch: 14 | Iteration: 727 | Classification loss: 0.04426 | Regression loss: 0.22284 | Running loss: 0.28823\n",
      "Epoch: 14 | Iteration: 728 | Classification loss: 0.03067 | Regression loss: 0.13784 | Running loss: 0.28770\n",
      "Epoch: 14 | Iteration: 729 | Classification loss: 0.02277 | Regression loss: 0.15237 | Running loss: 0.28768\n",
      "Epoch: 14 | Iteration: 730 | Classification loss: 0.07626 | Regression loss: 0.27916 | Running loss: 0.28788\n",
      "Epoch: 14 | Iteration: 731 | Classification loss: 0.08115 | Regression loss: 0.38742 | Running loss: 0.28857\n",
      "Epoch: 14 | Iteration: 732 | Classification loss: 0.14710 | Regression loss: 0.09468 | Running loss: 0.28838\n",
      "Epoch: 14 | Iteration: 733 | Classification loss: 0.03097 | Regression loss: 0.17474 | Running loss: 0.28769\n",
      "Epoch: 14 | Iteration: 734 | Classification loss: 0.08852 | Regression loss: 0.09518 | Running loss: 0.28772\n",
      "Epoch: 14 | Iteration: 735 | Classification loss: 0.18600 | Regression loss: 0.32495 | Running loss: 0.28832\n",
      "Epoch: 14 | Iteration: 736 | Classification loss: 0.28909 | Regression loss: 0.19409 | Running loss: 0.28871\n",
      "Epoch: 14 | Iteration: 737 | Classification loss: 0.08145 | Regression loss: 0.26394 | Running loss: 0.28917\n",
      "Epoch: 14 | Iteration: 738 | Classification loss: 0.04717 | Regression loss: 0.19107 | Running loss: 0.28903\n",
      "Epoch: 14 | Iteration: 739 | Classification loss: 0.16906 | Regression loss: 0.36050 | Running loss: 0.28954\n",
      "Epoch: 14 | Iteration: 740 | Classification loss: 0.12190 | Regression loss: 0.22371 | Running loss: 0.28977\n",
      "Epoch: 14 | Iteration: 741 | Classification loss: 0.09006 | Regression loss: 0.26344 | Running loss: 0.29011\n",
      "Epoch: 14 | Iteration: 742 | Classification loss: 0.05588 | Regression loss: 0.25036 | Running loss: 0.29008\n",
      "Epoch: 14 | Iteration: 743 | Classification loss: 0.04926 | Regression loss: 0.16191 | Running loss: 0.28870\n",
      "Epoch: 14 | Iteration: 744 | Classification loss: 0.02976 | Regression loss: 0.17575 | Running loss: 0.28882\n",
      "Epoch: 14 | Iteration: 745 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.28845\n",
      "Epoch: 14 | Iteration: 746 | Classification loss: 0.06477 | Regression loss: 0.21492 | Running loss: 0.28863\n",
      "Epoch: 14 | Iteration: 747 | Classification loss: 0.08288 | Regression loss: 0.48923 | Running loss: 0.28948\n",
      "Epoch: 14 | Iteration: 748 | Classification loss: 0.03550 | Regression loss: 0.14911 | Running loss: 0.28933\n",
      "Epoch: 14 | Iteration: 749 | Classification loss: 0.19248 | Regression loss: 0.39891 | Running loss: 0.29002\n",
      "Epoch: 14 | Iteration: 750 | Classification loss: 0.04356 | Regression loss: 0.14824 | Running loss: 0.29010\n",
      "Epoch: 14 | Iteration: 751 | Classification loss: 0.03405 | Regression loss: 0.12899 | Running loss: 0.29013\n",
      "Epoch: 14 | Iteration: 752 | Classification loss: 0.06974 | Regression loss: 0.08901 | Running loss: 0.28991\n",
      "Epoch: 14 | Iteration: 753 | Classification loss: 0.16219 | Regression loss: 0.29204 | Running loss: 0.29034\n",
      "Epoch: 14 | Iteration: 754 | Classification loss: 0.03760 | Regression loss: 0.22651 | Running loss: 0.28934\n",
      "Epoch: 14 | Iteration: 755 | Classification loss: 0.02728 | Regression loss: 0.21434 | Running loss: 0.28933\n",
      "Epoch: 14 | Iteration: 756 | Classification loss: 0.10533 | Regression loss: 0.25237 | Running loss: 0.28930\n",
      "Epoch: 14 | Iteration: 757 | Classification loss: 0.09677 | Regression loss: 0.21144 | Running loss: 0.28936\n",
      "Epoch: 14 | Iteration: 758 | Classification loss: 0.08430 | Regression loss: 0.20887 | Running loss: 0.28907\n",
      "Epoch: 14 | Iteration: 759 | Classification loss: 0.05746 | Regression loss: 0.18464 | Running loss: 0.28914\n",
      "Epoch: 14 | Iteration: 760 | Classification loss: 0.12395 | Regression loss: 0.29669 | Running loss: 0.28943\n",
      "Epoch: 14 | Iteration: 761 | Classification loss: 0.05768 | Regression loss: 0.15482 | Running loss: 0.28909\n",
      "Epoch: 14 | Iteration: 762 | Classification loss: 0.01049 | Regression loss: 0.08718 | Running loss: 0.28897\n",
      "Epoch: 14 | Iteration: 763 | Classification loss: 0.05252 | Regression loss: 0.23110 | Running loss: 0.28924\n",
      "Epoch: 14 | Iteration: 764 | Classification loss: 0.04406 | Regression loss: 0.20722 | Running loss: 0.28899\n",
      "Epoch: 14 | Iteration: 765 | Classification loss: 0.03371 | Regression loss: 0.07565 | Running loss: 0.28886\n",
      "Epoch: 14 | Iteration: 766 | Classification loss: 0.03807 | Regression loss: 0.09892 | Running loss: 0.28833\n",
      "Epoch: 14 | Iteration: 767 | Classification loss: 0.06658 | Regression loss: 0.12197 | Running loss: 0.28815\n",
      "Epoch: 14 | Iteration: 768 | Classification loss: 0.07068 | Regression loss: 0.28164 | Running loss: 0.28826\n",
      "Epoch: 14 | Iteration: 769 | Classification loss: 0.03425 | Regression loss: 0.16262 | Running loss: 0.28809\n",
      "Epoch: 14 | Iteration: 770 | Classification loss: 0.04505 | Regression loss: 0.18587 | Running loss: 0.28795\n",
      "Epoch: 14 | Iteration: 771 | Classification loss: 0.03103 | Regression loss: 0.25284 | Running loss: 0.28794\n",
      "Epoch: 14 | Iteration: 772 | Classification loss: 0.63372 | Regression loss: 0.60401 | Running loss: 0.29002\n",
      "Epoch: 14 | Iteration: 773 | Classification loss: 0.05058 | Regression loss: 0.36298 | Running loss: 0.29007\n",
      "Epoch: 14 | Iteration: 774 | Classification loss: 0.19913 | Regression loss: 0.41459 | Running loss: 0.29077\n",
      "Epoch: 14 | Iteration: 775 | Classification loss: 0.04767 | Regression loss: 0.25172 | Running loss: 0.29092\n",
      "Epoch: 14 | Iteration: 776 | Classification loss: 0.04673 | Regression loss: 0.18870 | Running loss: 0.29095\n",
      "Epoch: 14 | Iteration: 777 | Classification loss: 0.04053 | Regression loss: 0.14878 | Running loss: 0.29062\n",
      "Epoch: 14 | Iteration: 778 | Classification loss: 0.01473 | Regression loss: 0.12423 | Running loss: 0.29055\n",
      "Epoch: 14 | Iteration: 779 | Classification loss: 0.02386 | Regression loss: 0.09935 | Running loss: 0.29052\n",
      "Epoch: 14 | Iteration: 780 | Classification loss: 0.02592 | Regression loss: 0.08522 | Running loss: 0.29033\n",
      "Epoch: 14 | Iteration: 781 | Classification loss: 0.05980 | Regression loss: 0.18292 | Running loss: 0.29026\n",
      "Epoch: 14 | Iteration: 782 | Classification loss: 0.04098 | Regression loss: 0.08499 | Running loss: 0.29015\n",
      "Epoch: 14 | Iteration: 783 | Classification loss: 0.01653 | Regression loss: 0.07195 | Running loss: 0.28971\n",
      "Epoch: 14 | Iteration: 784 | Classification loss: 0.02348 | Regression loss: 0.08377 | Running loss: 0.28932\n",
      "Epoch: 14 | Iteration: 785 | Classification loss: 0.05568 | Regression loss: 0.09888 | Running loss: 0.28864\n",
      "Epoch: 14 | Iteration: 786 | Classification loss: 0.03685 | Regression loss: 0.12837 | Running loss: 0.28850\n",
      "Epoch: 14 | Iteration: 787 | Classification loss: 0.02823 | Regression loss: 0.21849 | Running loss: 0.28837\n",
      "Epoch: 14 | Iteration: 788 | Classification loss: 0.03594 | Regression loss: 0.33658 | Running loss: 0.28859\n",
      "Epoch: 14 | Iteration: 789 | Classification loss: 0.08864 | Regression loss: 0.13288 | Running loss: 0.28857\n",
      "Epoch: 14 | Iteration: 790 | Classification loss: 0.02040 | Regression loss: 0.12828 | Running loss: 0.28839\n",
      "Epoch: 14 | Iteration: 791 | Classification loss: 0.05750 | Regression loss: 0.25110 | Running loss: 0.28822\n",
      "Epoch: 14 | Iteration: 792 | Classification loss: 0.02291 | Regression loss: 0.09545 | Running loss: 0.28775\n",
      "Epoch: 14 | Iteration: 793 | Classification loss: 0.05092 | Regression loss: 0.24054 | Running loss: 0.28721\n",
      "Epoch: 14 | Iteration: 794 | Classification loss: 0.06250 | Regression loss: 0.11824 | Running loss: 0.28729\n",
      "Epoch: 14 | Iteration: 795 | Classification loss: 0.02431 | Regression loss: 0.16068 | Running loss: 0.28742\n",
      "Epoch: 14 | Iteration: 796 | Classification loss: 0.05619 | Regression loss: 0.14091 | Running loss: 0.28719\n",
      "Epoch: 14 | Iteration: 797 | Classification loss: 0.04568 | Regression loss: 0.21601 | Running loss: 0.28730\n",
      "Epoch: 14 | Iteration: 798 | Classification loss: 0.17132 | Regression loss: 0.47674 | Running loss: 0.28828\n",
      "Epoch: 14 | Iteration: 799 | Classification loss: 0.03411 | Regression loss: 0.11757 | Running loss: 0.28801\n",
      "Epoch: 14 | Iteration: 800 | Classification loss: 0.02711 | Regression loss: 0.10005 | Running loss: 0.28766\n",
      "Epoch: 14 | Iteration: 801 | Classification loss: 0.03834 | Regression loss: 0.11672 | Running loss: 0.28733\n",
      "Epoch: 14 | Iteration: 802 | Classification loss: 0.06925 | Regression loss: 0.17858 | Running loss: 0.28722\n",
      "Epoch: 14 | Iteration: 803 | Classification loss: 0.02561 | Regression loss: 0.19143 | Running loss: 0.28689\n",
      "Epoch: 14 | Iteration: 804 | Classification loss: 0.02310 | Regression loss: 0.20700 | Running loss: 0.28688\n",
      "Epoch: 14 | Iteration: 805 | Classification loss: 0.04016 | Regression loss: 0.13188 | Running loss: 0.28680\n",
      "Epoch: 14 | Iteration: 806 | Classification loss: 0.03544 | Regression loss: 0.09487 | Running loss: 0.28563\n",
      "Epoch: 14 | Iteration: 807 | Classification loss: 0.01567 | Regression loss: 0.14590 | Running loss: 0.28566\n",
      "Epoch: 14 | Iteration: 808 | Classification loss: 0.04273 | Regression loss: 0.12147 | Running loss: 0.28538\n",
      "Epoch: 14 | Iteration: 809 | Classification loss: 0.05111 | Regression loss: 0.15968 | Running loss: 0.28503\n",
      "Epoch: 14 | Iteration: 810 | Classification loss: 0.09402 | Regression loss: 0.19354 | Running loss: 0.28489\n",
      "Epoch: 14 | Iteration: 811 | Classification loss: 0.05545 | Regression loss: 0.24167 | Running loss: 0.28523\n",
      "Epoch: 14 | Iteration: 812 | Classification loss: 0.06048 | Regression loss: 0.35147 | Running loss: 0.28557\n",
      "Epoch: 14 | Iteration: 813 | Classification loss: 0.06662 | Regression loss: 0.20931 | Running loss: 0.28472\n",
      "Epoch: 14 | Iteration: 814 | Classification loss: 0.08971 | Regression loss: 0.13326 | Running loss: 0.28494\n",
      "Epoch: 14 | Iteration: 815 | Classification loss: 0.21222 | Regression loss: 0.31940 | Running loss: 0.28562\n",
      "Epoch: 14 | Iteration: 816 | Classification loss: 0.05250 | Regression loss: 0.12335 | Running loss: 0.28554\n",
      "Epoch: 14 | Iteration: 817 | Classification loss: 0.08473 | Regression loss: 0.18572 | Running loss: 0.28546\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 15 | Iteration: 0 | Classification loss: 0.07629 | Regression loss: 0.22614 | Running loss: 0.28573\n",
      "Epoch: 15 | Iteration: 1 | Classification loss: 0.03623 | Regression loss: 0.27048 | Running loss: 0.28573\n",
      "Epoch: 15 | Iteration: 2 | Classification loss: 0.05630 | Regression loss: 0.23353 | Running loss: 0.28584\n",
      "Epoch: 15 | Iteration: 3 | Classification loss: 0.05573 | Regression loss: 0.10888 | Running loss: 0.28517\n",
      "Epoch: 15 | Iteration: 4 | Classification loss: 0.12221 | Regression loss: 0.34372 | Running loss: 0.28558\n",
      "Epoch: 15 | Iteration: 5 | Classification loss: 0.24787 | Regression loss: 0.09752 | Running loss: 0.28591\n",
      "Epoch: 15 | Iteration: 6 | Classification loss: 0.03279 | Regression loss: 0.21729 | Running loss: 0.28563\n",
      "Epoch: 15 | Iteration: 7 | Classification loss: 0.09874 | Regression loss: 0.31036 | Running loss: 0.28617\n",
      "Epoch: 15 | Iteration: 8 | Classification loss: 0.06391 | Regression loss: 0.19884 | Running loss: 0.28546\n",
      "Epoch: 15 | Iteration: 9 | Classification loss: 0.03749 | Regression loss: 0.09670 | Running loss: 0.28520\n",
      "Epoch: 15 | Iteration: 10 | Classification loss: 0.04018 | Regression loss: 0.14608 | Running loss: 0.28475\n",
      "Epoch: 15 | Iteration: 11 | Classification loss: 0.02898 | Regression loss: 0.21861 | Running loss: 0.28491\n",
      "Epoch: 15 | Iteration: 12 | Classification loss: 0.08325 | Regression loss: 0.11366 | Running loss: 0.28506\n",
      "Epoch: 15 | Iteration: 13 | Classification loss: 0.14525 | Regression loss: 0.55465 | Running loss: 0.28612\n",
      "Epoch: 15 | Iteration: 14 | Classification loss: 0.12754 | Regression loss: 0.39082 | Running loss: 0.28693\n",
      "Epoch: 15 | Iteration: 15 | Classification loss: 0.04640 | Regression loss: 0.20760 | Running loss: 0.28682\n",
      "Epoch: 15 | Iteration: 16 | Classification loss: 0.03215 | Regression loss: 0.07634 | Running loss: 0.28676\n",
      "Epoch: 15 | Iteration: 17 | Classification loss: 0.03627 | Regression loss: 0.10560 | Running loss: 0.28685\n",
      "Epoch: 15 | Iteration: 18 | Classification loss: 0.09233 | Regression loss: 0.26526 | Running loss: 0.28692\n",
      "Epoch: 15 | Iteration: 19 | Classification loss: 0.06983 | Regression loss: 0.26780 | Running loss: 0.28720\n",
      "Epoch: 15 | Iteration: 20 | Classification loss: 0.22899 | Regression loss: 0.33269 | Running loss: 0.28801\n",
      "Epoch: 15 | Iteration: 21 | Classification loss: 0.07558 | Regression loss: 0.20268 | Running loss: 0.28812\n",
      "Epoch: 15 | Iteration: 22 | Classification loss: 0.07256 | Regression loss: 0.18288 | Running loss: 0.28784\n",
      "Epoch: 15 | Iteration: 23 | Classification loss: 0.04844 | Regression loss: 0.17668 | Running loss: 0.28788\n",
      "Epoch: 15 | Iteration: 24 | Classification loss: 0.04847 | Regression loss: 0.21793 | Running loss: 0.28805\n",
      "Epoch: 15 | Iteration: 25 | Classification loss: 0.07639 | Regression loss: 0.26500 | Running loss: 0.28832\n",
      "Epoch: 15 | Iteration: 26 | Classification loss: 0.08160 | Regression loss: 0.28551 | Running loss: 0.28854\n",
      "Epoch: 15 | Iteration: 27 | Classification loss: 0.03286 | Regression loss: 0.22353 | Running loss: 0.28826\n",
      "Epoch: 15 | Iteration: 28 | Classification loss: 0.09652 | Regression loss: 0.22818 | Running loss: 0.28852\n",
      "Epoch: 15 | Iteration: 29 | Classification loss: 0.05792 | Regression loss: 0.22616 | Running loss: 0.28873\n",
      "Epoch: 15 | Iteration: 30 | Classification loss: 0.07145 | Regression loss: 0.34328 | Running loss: 0.28882\n",
      "Epoch: 15 | Iteration: 31 | Classification loss: 0.04799 | Regression loss: 0.12355 | Running loss: 0.28890\n",
      "Epoch: 15 | Iteration: 32 | Classification loss: 0.04633 | Regression loss: 0.20053 | Running loss: 0.28833\n",
      "Epoch: 15 | Iteration: 33 | Classification loss: 0.02845 | Regression loss: 0.16827 | Running loss: 0.28836\n",
      "Epoch: 15 | Iteration: 34 | Classification loss: 0.02713 | Regression loss: 0.30944 | Running loss: 0.28847\n",
      "Epoch: 15 | Iteration: 35 | Classification loss: 0.12799 | Regression loss: 0.24413 | Running loss: 0.28832\n",
      "Epoch: 15 | Iteration: 36 | Classification loss: 0.11462 | Regression loss: 0.24061 | Running loss: 0.28847\n",
      "Epoch: 15 | Iteration: 37 | Classification loss: 0.03975 | Regression loss: 0.13083 | Running loss: 0.28836\n",
      "Epoch: 15 | Iteration: 38 | Classification loss: 0.09705 | Regression loss: 0.35939 | Running loss: 0.28884\n",
      "Epoch: 15 | Iteration: 39 | Classification loss: 0.10786 | Regression loss: 0.10327 | Running loss: 0.28869\n",
      "Epoch: 15 | Iteration: 40 | Classification loss: 0.08871 | Regression loss: 0.15070 | Running loss: 0.28869\n",
      "Epoch: 15 | Iteration: 41 | Classification loss: 0.02378 | Regression loss: 0.06595 | Running loss: 0.28815\n",
      "Epoch: 15 | Iteration: 42 | Classification loss: 0.02186 | Regression loss: 0.08069 | Running loss: 0.28762\n",
      "Epoch: 15 | Iteration: 43 | Classification loss: 0.02829 | Regression loss: 0.28212 | Running loss: 0.28755\n",
      "Epoch: 15 | Iteration: 44 | Classification loss: 0.02243 | Regression loss: 0.13602 | Running loss: 0.28740\n",
      "Epoch: 15 | Iteration: 45 | Classification loss: 0.05939 | Regression loss: 0.25272 | Running loss: 0.28755\n",
      "Epoch: 15 | Iteration: 46 | Classification loss: 0.05939 | Regression loss: 0.38677 | Running loss: 0.28793\n",
      "Epoch: 15 | Iteration: 47 | Classification loss: 0.08730 | Regression loss: 0.29692 | Running loss: 0.28834\n",
      "Epoch: 15 | Iteration: 48 | Classification loss: 0.06017 | Regression loss: 0.13735 | Running loss: 0.28782\n",
      "Epoch: 15 | Iteration: 49 | Classification loss: 0.03326 | Regression loss: 0.19213 | Running loss: 0.28695\n",
      "Epoch: 15 | Iteration: 50 | Classification loss: 0.01935 | Regression loss: 0.16522 | Running loss: 0.28668\n",
      "Epoch: 15 | Iteration: 51 | Classification loss: 0.07875 | Regression loss: 0.34412 | Running loss: 0.28698\n",
      "Epoch: 15 | Iteration: 52 | Classification loss: 0.11771 | Regression loss: 0.42462 | Running loss: 0.28704\n",
      "Epoch: 15 | Iteration: 53 | Classification loss: 0.05190 | Regression loss: 0.25304 | Running loss: 0.28682\n",
      "Epoch: 15 | Iteration: 54 | Classification loss: 0.08676 | Regression loss: 0.22262 | Running loss: 0.28654\n",
      "Epoch: 15 | Iteration: 55 | Classification loss: 0.06521 | Regression loss: 0.07862 | Running loss: 0.28639\n",
      "Epoch: 15 | Iteration: 56 | Classification loss: 0.02776 | Regression loss: 0.14491 | Running loss: 0.28640\n",
      "Epoch: 15 | Iteration: 57 | Classification loss: 0.12936 | Regression loss: 0.29913 | Running loss: 0.28646\n",
      "Epoch: 15 | Iteration: 58 | Classification loss: 0.04911 | Regression loss: 0.24933 | Running loss: 0.28571\n",
      "Epoch: 15 | Iteration: 59 | Classification loss: 0.02348 | Regression loss: 0.11150 | Running loss: 0.28546\n",
      "Epoch: 15 | Iteration: 60 | Classification loss: 0.17685 | Regression loss: 0.34354 | Running loss: 0.28627\n",
      "Epoch: 15 | Iteration: 61 | Classification loss: 0.02082 | Regression loss: 0.17260 | Running loss: 0.28627\n",
      "Epoch: 15 | Iteration: 62 | Classification loss: 0.07430 | Regression loss: 0.22266 | Running loss: 0.28658\n",
      "Epoch: 15 | Iteration: 63 | Classification loss: 0.03654 | Regression loss: 0.19508 | Running loss: 0.28646\n",
      "Epoch: 15 | Iteration: 64 | Classification loss: 0.02898 | Regression loss: 0.17211 | Running loss: 0.28628\n",
      "Epoch: 15 | Iteration: 65 | Classification loss: 0.13862 | Regression loss: 0.17678 | Running loss: 0.28632\n",
      "Epoch: 15 | Iteration: 66 | Classification loss: 0.05312 | Regression loss: 0.16394 | Running loss: 0.28618\n",
      "Epoch: 15 | Iteration: 67 | Classification loss: 0.02535 | Regression loss: 0.19027 | Running loss: 0.28637\n",
      "Epoch: 15 | Iteration: 68 | Classification loss: 0.05645 | Regression loss: 0.25287 | Running loss: 0.28643\n",
      "Epoch: 15 | Iteration: 69 | Classification loss: 0.02036 | Regression loss: 0.12360 | Running loss: 0.28649\n",
      "Epoch: 15 | Iteration: 70 | Classification loss: 0.03313 | Regression loss: 0.17640 | Running loss: 0.28633\n",
      "Epoch: 15 | Iteration: 71 | Classification loss: 0.07566 | Regression loss: 0.32053 | Running loss: 0.28635\n",
      "Epoch: 15 | Iteration: 72 | Classification loss: 0.03351 | Regression loss: 0.15608 | Running loss: 0.28581\n",
      "Epoch: 15 | Iteration: 73 | Classification loss: 0.05568 | Regression loss: 0.24060 | Running loss: 0.28586\n",
      "Epoch: 15 | Iteration: 74 | Classification loss: 0.02398 | Regression loss: 0.13449 | Running loss: 0.28581\n",
      "Epoch: 15 | Iteration: 75 | Classification loss: 0.11444 | Regression loss: 0.23473 | Running loss: 0.28562\n",
      "Epoch: 15 | Iteration: 76 | Classification loss: 0.10002 | Regression loss: 0.16091 | Running loss: 0.28567\n",
      "Epoch: 15 | Iteration: 77 | Classification loss: 0.20515 | Regression loss: 0.17467 | Running loss: 0.28618\n",
      "Epoch: 15 | Iteration: 78 | Classification loss: 0.14246 | Regression loss: 0.19817 | Running loss: 0.28594\n",
      "Epoch: 15 | Iteration: 79 | Classification loss: 0.03340 | Regression loss: 0.14529 | Running loss: 0.28599\n",
      "Epoch: 15 | Iteration: 80 | Classification loss: 0.04291 | Regression loss: 0.14894 | Running loss: 0.28550\n",
      "Epoch: 15 | Iteration: 81 | Classification loss: 0.04499 | Regression loss: 0.19637 | Running loss: 0.28555\n",
      "Epoch: 15 | Iteration: 82 | Classification loss: 0.04322 | Regression loss: 0.08799 | Running loss: 0.28521\n",
      "Epoch: 15 | Iteration: 83 | Classification loss: 0.10227 | Regression loss: 0.23695 | Running loss: 0.28529\n",
      "Epoch: 15 | Iteration: 84 | Classification loss: 0.04072 | Regression loss: 0.21475 | Running loss: 0.28506\n",
      "Epoch: 15 | Iteration: 85 | Classification loss: 0.07486 | Regression loss: 0.23103 | Running loss: 0.28511\n",
      "Epoch: 15 | Iteration: 86 | Classification loss: 0.05618 | Regression loss: 0.13220 | Running loss: 0.28505\n",
      "Epoch: 15 | Iteration: 87 | Classification loss: 0.04368 | Regression loss: 0.14738 | Running loss: 0.28511\n",
      "Epoch: 15 | Iteration: 88 | Classification loss: 0.04415 | Regression loss: 0.24420 | Running loss: 0.28533\n",
      "Epoch: 15 | Iteration: 89 | Classification loss: 0.22372 | Regression loss: 0.17293 | Running loss: 0.28574\n",
      "Epoch: 15 | Iteration: 90 | Classification loss: 0.06380 | Regression loss: 0.21043 | Running loss: 0.28576\n",
      "Epoch: 15 | Iteration: 91 | Classification loss: 0.12659 | Regression loss: 0.34604 | Running loss: 0.28604\n",
      "Epoch: 15 | Iteration: 92 | Classification loss: 0.04456 | Regression loss: 0.41360 | Running loss: 0.28632\n",
      "Epoch: 15 | Iteration: 93 | Classification loss: 0.03468 | Regression loss: 0.11007 | Running loss: 0.28591\n",
      "Epoch: 15 | Iteration: 94 | Classification loss: 0.32635 | Regression loss: 0.36255 | Running loss: 0.28655\n",
      "Epoch: 15 | Iteration: 95 | Classification loss: 0.06039 | Regression loss: 0.25141 | Running loss: 0.28662\n",
      "Epoch: 15 | Iteration: 96 | Classification loss: 0.02136 | Regression loss: 0.07552 | Running loss: 0.28620\n",
      "Epoch: 15 | Iteration: 97 | Classification loss: 0.03462 | Regression loss: 0.11865 | Running loss: 0.28614\n",
      "Epoch: 15 | Iteration: 98 | Classification loss: 0.11200 | Regression loss: 0.18424 | Running loss: 0.28626\n",
      "Epoch: 15 | Iteration: 99 | Classification loss: 0.06497 | Regression loss: 0.14869 | Running loss: 0.28635\n",
      "Epoch: 15 | Iteration: 100 | Classification loss: 0.09881 | Regression loss: 0.28112 | Running loss: 0.28675\n",
      "Epoch: 15 | Iteration: 101 | Classification loss: 0.07518 | Regression loss: 0.27799 | Running loss: 0.28625\n",
      "Epoch: 15 | Iteration: 102 | Classification loss: 0.04028 | Regression loss: 0.19150 | Running loss: 0.28654\n",
      "Epoch: 15 | Iteration: 103 | Classification loss: 0.02552 | Regression loss: 0.16917 | Running loss: 0.28630\n",
      "Epoch: 15 | Iteration: 104 | Classification loss: 0.07878 | Regression loss: 0.28431 | Running loss: 0.28661\n",
      "Epoch: 15 | Iteration: 105 | Classification loss: 0.02628 | Regression loss: 0.19363 | Running loss: 0.28662\n",
      "Epoch: 15 | Iteration: 106 | Classification loss: 0.05915 | Regression loss: 0.29664 | Running loss: 0.28667\n",
      "Epoch: 15 | Iteration: 107 | Classification loss: 0.13774 | Regression loss: 0.46812 | Running loss: 0.28732\n",
      "Epoch: 15 | Iteration: 108 | Classification loss: 0.02495 | Regression loss: 0.14498 | Running loss: 0.28704\n",
      "Epoch: 15 | Iteration: 109 | Classification loss: 0.03017 | Regression loss: 0.26123 | Running loss: 0.28728\n",
      "Epoch: 15 | Iteration: 110 | Classification loss: 0.02694 | Regression loss: 0.18916 | Running loss: 0.28714\n",
      "Epoch: 15 | Iteration: 111 | Classification loss: 0.17605 | Regression loss: 0.19416 | Running loss: 0.28714\n",
      "Epoch: 15 | Iteration: 112 | Classification loss: 0.06708 | Regression loss: 0.10255 | Running loss: 0.28671\n",
      "Epoch: 15 | Iteration: 113 | Classification loss: 0.05542 | Regression loss: 0.10299 | Running loss: 0.28664\n",
      "Epoch: 15 | Iteration: 114 | Classification loss: 0.04097 | Regression loss: 0.18414 | Running loss: 0.28667\n",
      "Epoch: 15 | Iteration: 115 | Classification loss: 0.07361 | Regression loss: 0.18550 | Running loss: 0.28677\n",
      "Epoch: 15 | Iteration: 116 | Classification loss: 0.12910 | Regression loss: 0.42886 | Running loss: 0.28760\n",
      "Epoch: 15 | Iteration: 117 | Classification loss: 0.08021 | Regression loss: 0.35657 | Running loss: 0.28819\n",
      "Epoch: 15 | Iteration: 118 | Classification loss: 0.03385 | Regression loss: 0.16141 | Running loss: 0.28831\n",
      "Epoch: 15 | Iteration: 119 | Classification loss: 0.03583 | Regression loss: 0.25227 | Running loss: 0.28846\n",
      "Epoch: 15 | Iteration: 120 | Classification loss: 0.01977 | Regression loss: 0.13945 | Running loss: 0.28835\n",
      "Epoch: 15 | Iteration: 121 | Classification loss: 0.02667 | Regression loss: 0.21174 | Running loss: 0.28823\n",
      "Epoch: 15 | Iteration: 122 | Classification loss: 0.03307 | Regression loss: 0.15509 | Running loss: 0.28828\n",
      "Epoch: 15 | Iteration: 123 | Classification loss: 0.06937 | Regression loss: 0.25003 | Running loss: 0.28828\n",
      "Epoch: 15 | Iteration: 124 | Classification loss: 0.05966 | Regression loss: 0.19547 | Running loss: 0.28851\n",
      "Epoch: 15 | Iteration: 125 | Classification loss: 0.07329 | Regression loss: 0.17675 | Running loss: 0.28868\n",
      "Epoch: 15 | Iteration: 126 | Classification loss: 0.10348 | Regression loss: 0.23998 | Running loss: 0.28915\n",
      "Epoch: 15 | Iteration: 127 | Classification loss: 0.27417 | Regression loss: 0.32893 | Running loss: 0.28986\n",
      "Epoch: 15 | Iteration: 128 | Classification loss: 0.01900 | Regression loss: 0.08699 | Running loss: 0.28899\n",
      "Epoch: 15 | Iteration: 129 | Classification loss: 0.07351 | Regression loss: 0.23284 | Running loss: 0.28895\n",
      "Epoch: 15 | Iteration: 130 | Classification loss: 0.06629 | Regression loss: 0.22637 | Running loss: 0.28898\n",
      "Epoch: 15 | Iteration: 131 | Classification loss: 0.15567 | Regression loss: 0.27084 | Running loss: 0.28919\n",
      "Epoch: 15 | Iteration: 132 | Classification loss: 0.01427 | Regression loss: 0.14344 | Running loss: 0.28921\n",
      "Epoch: 15 | Iteration: 133 | Classification loss: 0.07207 | Regression loss: 0.24446 | Running loss: 0.28923\n",
      "Epoch: 15 | Iteration: 134 | Classification loss: 0.04748 | Regression loss: 0.25936 | Running loss: 0.28971\n",
      "Epoch: 15 | Iteration: 135 | Classification loss: 0.05344 | Regression loss: 0.15176 | Running loss: 0.28964\n",
      "Epoch: 15 | Iteration: 136 | Classification loss: 0.01115 | Regression loss: 0.07611 | Running loss: 0.28962\n",
      "Epoch: 15 | Iteration: 137 | Classification loss: 0.02479 | Regression loss: 0.16234 | Running loss: 0.28955\n",
      "Epoch: 15 | Iteration: 138 | Classification loss: 0.05231 | Regression loss: 0.26599 | Running loss: 0.28978\n",
      "Epoch: 15 | Iteration: 139 | Classification loss: 0.01119 | Regression loss: 0.17590 | Running loss: 0.28958\n",
      "Epoch: 15 | Iteration: 140 | Classification loss: 0.01576 | Regression loss: 0.12452 | Running loss: 0.28927\n",
      "Epoch: 15 | Iteration: 141 | Classification loss: 0.12276 | Regression loss: 0.22926 | Running loss: 0.28841\n",
      "Epoch: 15 | Iteration: 142 | Classification loss: 0.06530 | Regression loss: 0.27413 | Running loss: 0.28890\n",
      "Epoch: 15 | Iteration: 143 | Classification loss: 0.02396 | Regression loss: 0.11069 | Running loss: 0.28869\n",
      "Epoch: 15 | Iteration: 144 | Classification loss: 0.03482 | Regression loss: 0.17301 | Running loss: 0.28855\n",
      "Epoch: 15 | Iteration: 145 | Classification loss: 0.07386 | Regression loss: 0.08851 | Running loss: 0.28857\n",
      "Epoch: 15 | Iteration: 146 | Classification loss: 0.24812 | Regression loss: 0.21448 | Running loss: 0.28861\n",
      "Epoch: 15 | Iteration: 147 | Classification loss: 0.03698 | Regression loss: 0.19704 | Running loss: 0.28822\n",
      "Epoch: 15 | Iteration: 148 | Classification loss: 0.04455 | Regression loss: 0.20456 | Running loss: 0.28816\n",
      "Epoch: 15 | Iteration: 149 | Classification loss: 0.02834 | Regression loss: 0.11584 | Running loss: 0.28797\n",
      "Epoch: 15 | Iteration: 150 | Classification loss: 0.02798 | Regression loss: 0.14057 | Running loss: 0.28786\n",
      "Epoch: 15 | Iteration: 151 | Classification loss: 0.03736 | Regression loss: 0.19252 | Running loss: 0.28798\n",
      "Epoch: 15 | Iteration: 152 | Classification loss: 0.09909 | Regression loss: 0.34795 | Running loss: 0.28843\n",
      "Epoch: 15 | Iteration: 153 | Classification loss: 0.10883 | Regression loss: 0.16795 | Running loss: 0.28863\n",
      "Epoch: 15 | Iteration: 154 | Classification loss: 0.03540 | Regression loss: 0.26581 | Running loss: 0.28867\n",
      "Epoch: 15 | Iteration: 155 | Classification loss: 0.04994 | Regression loss: 0.12550 | Running loss: 0.28867\n",
      "Epoch: 15 | Iteration: 156 | Classification loss: 0.03081 | Regression loss: 0.14788 | Running loss: 0.28834\n",
      "Epoch: 15 | Iteration: 157 | Classification loss: 0.04659 | Regression loss: 0.22012 | Running loss: 0.28825\n",
      "Epoch: 15 | Iteration: 158 | Classification loss: 0.10260 | Regression loss: 0.17189 | Running loss: 0.28803\n",
      "Epoch: 15 | Iteration: 159 | Classification loss: 0.01844 | Regression loss: 0.18626 | Running loss: 0.28760\n",
      "Epoch: 15 | Iteration: 160 | Classification loss: 0.03541 | Regression loss: 0.24864 | Running loss: 0.28773\n",
      "Epoch: 15 | Iteration: 161 | Classification loss: 0.05266 | Regression loss: 0.27569 | Running loss: 0.28797\n",
      "Epoch: 15 | Iteration: 162 | Classification loss: 0.35311 | Regression loss: 0.22906 | Running loss: 0.28860\n",
      "Epoch: 15 | Iteration: 163 | Classification loss: 0.31845 | Regression loss: 0.20117 | Running loss: 0.28908\n",
      "Epoch: 15 | Iteration: 164 | Classification loss: 0.08702 | Regression loss: 0.26555 | Running loss: 0.28918\n",
      "Epoch: 15 | Iteration: 165 | Classification loss: 0.07274 | Regression loss: 0.24196 | Running loss: 0.28923\n",
      "Epoch: 15 | Iteration: 166 | Classification loss: 0.01963 | Regression loss: 0.21100 | Running loss: 0.28927\n",
      "Epoch: 15 | Iteration: 167 | Classification loss: 0.08060 | Regression loss: 0.08153 | Running loss: 0.28918\n",
      "Epoch: 15 | Iteration: 168 | Classification loss: 0.03574 | Regression loss: 0.22028 | Running loss: 0.28933\n",
      "Epoch: 15 | Iteration: 169 | Classification loss: 0.07421 | Regression loss: 0.22270 | Running loss: 0.28894\n",
      "Epoch: 15 | Iteration: 170 | Classification loss: 0.14255 | Regression loss: 0.40506 | Running loss: 0.28942\n",
      "Epoch: 15 | Iteration: 171 | Classification loss: 0.02099 | Regression loss: 0.20909 | Running loss: 0.28954\n",
      "Epoch: 15 | Iteration: 172 | Classification loss: 0.16130 | Regression loss: 0.35068 | Running loss: 0.28965\n",
      "Epoch: 15 | Iteration: 173 | Classification loss: 0.07942 | Regression loss: 0.16139 | Running loss: 0.28990\n",
      "Epoch: 15 | Iteration: 174 | Classification loss: 0.01602 | Regression loss: 0.08146 | Running loss: 0.28929\n",
      "Epoch: 15 | Iteration: 175 | Classification loss: 0.05587 | Regression loss: 0.13391 | Running loss: 0.28898\n",
      "Epoch: 15 | Iteration: 176 | Classification loss: 0.01375 | Regression loss: 0.09479 | Running loss: 0.28879\n",
      "Epoch: 15 | Iteration: 177 | Classification loss: 0.09158 | Regression loss: 0.22031 | Running loss: 0.28908\n",
      "Epoch: 15 | Iteration: 178 | Classification loss: 0.04268 | Regression loss: 0.15672 | Running loss: 0.28897\n",
      "Epoch: 15 | Iteration: 179 | Classification loss: 0.03025 | Regression loss: 0.14508 | Running loss: 0.28851\n",
      "Epoch: 15 | Iteration: 180 | Classification loss: 0.02911 | Regression loss: 0.17813 | Running loss: 0.28804\n",
      "Epoch: 15 | Iteration: 181 | Classification loss: 0.02595 | Regression loss: 0.17740 | Running loss: 0.28756\n",
      "Epoch: 15 | Iteration: 182 | Classification loss: 0.03896 | Regression loss: 0.18554 | Running loss: 0.28749\n",
      "Epoch: 15 | Iteration: 183 | Classification loss: 0.02866 | Regression loss: 0.13843 | Running loss: 0.28709\n",
      "Epoch: 15 | Iteration: 184 | Classification loss: 0.02399 | Regression loss: 0.11674 | Running loss: 0.28613\n",
      "Epoch: 15 | Iteration: 185 | Classification loss: 0.07345 | Regression loss: 0.33244 | Running loss: 0.28646\n",
      "Epoch: 15 | Iteration: 186 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.28575\n",
      "Epoch: 15 | Iteration: 187 | Classification loss: 0.03307 | Regression loss: 0.21718 | Running loss: 0.28493\n",
      "Epoch: 15 | Iteration: 188 | Classification loss: 0.07121 | Regression loss: 0.20388 | Running loss: 0.28515\n",
      "Epoch: 15 | Iteration: 189 | Classification loss: 0.01931 | Regression loss: 0.11205 | Running loss: 0.28464\n",
      "Epoch: 15 | Iteration: 190 | Classification loss: 0.01646 | Regression loss: 0.09757 | Running loss: 0.28460\n",
      "Epoch: 15 | Iteration: 191 | Classification loss: 0.01586 | Regression loss: 0.17821 | Running loss: 0.28478\n",
      "Epoch: 15 | Iteration: 192 | Classification loss: 0.08311 | Regression loss: 0.24666 | Running loss: 0.28479\n",
      "Epoch: 15 | Iteration: 193 | Classification loss: 0.09998 | Regression loss: 0.17756 | Running loss: 0.28478\n",
      "Epoch: 15 | Iteration: 194 | Classification loss: 0.04255 | Regression loss: 0.20008 | Running loss: 0.28470\n",
      "Epoch: 15 | Iteration: 195 | Classification loss: 0.01828 | Regression loss: 0.25850 | Running loss: 0.28480\n",
      "Epoch: 15 | Iteration: 196 | Classification loss: 0.03121 | Regression loss: 0.11300 | Running loss: 0.28401\n",
      "Epoch: 15 | Iteration: 197 | Classification loss: 0.07819 | Regression loss: 0.25674 | Running loss: 0.28439\n",
      "Epoch: 15 | Iteration: 198 | Classification loss: 0.03280 | Regression loss: 0.17254 | Running loss: 0.28432\n",
      "Epoch: 15 | Iteration: 199 | Classification loss: 0.08024 | Regression loss: 0.20901 | Running loss: 0.28386\n",
      "Epoch: 15 | Iteration: 200 | Classification loss: 0.01659 | Regression loss: 0.17422 | Running loss: 0.28343\n",
      "Epoch: 15 | Iteration: 201 | Classification loss: 0.00917 | Regression loss: 0.10200 | Running loss: 0.28311\n",
      "Epoch: 15 | Iteration: 202 | Classification loss: 0.02855 | Regression loss: 0.18901 | Running loss: 0.28317\n",
      "Epoch: 15 | Iteration: 203 | Classification loss: 0.06708 | Regression loss: 0.24075 | Running loss: 0.28313\n",
      "Epoch: 15 | Iteration: 204 | Classification loss: 0.17588 | Regression loss: 0.15788 | Running loss: 0.28344\n",
      "Epoch: 15 | Iteration: 205 | Classification loss: 0.04137 | Regression loss: 0.10167 | Running loss: 0.28324\n",
      "Epoch: 15 | Iteration: 206 | Classification loss: 0.04473 | Regression loss: 0.24901 | Running loss: 0.28321\n",
      "Epoch: 15 | Iteration: 207 | Classification loss: 0.03430 | Regression loss: 0.23582 | Running loss: 0.28341\n",
      "Epoch: 15 | Iteration: 208 | Classification loss: 0.00735 | Regression loss: 0.13874 | Running loss: 0.28310\n",
      "Epoch: 15 | Iteration: 209 | Classification loss: 0.01525 | Regression loss: 0.11965 | Running loss: 0.28324\n",
      "Epoch: 15 | Iteration: 210 | Classification loss: 0.05952 | Regression loss: 0.24448 | Running loss: 0.28316\n",
      "Epoch: 15 | Iteration: 211 | Classification loss: 0.08107 | Regression loss: 0.22867 | Running loss: 0.28271\n",
      "Epoch: 15 | Iteration: 212 | Classification loss: 0.01029 | Regression loss: 0.07807 | Running loss: 0.28180\n",
      "Epoch: 15 | Iteration: 213 | Classification loss: 0.09464 | Regression loss: 0.35368 | Running loss: 0.28178\n",
      "Epoch: 15 | Iteration: 214 | Classification loss: 0.01023 | Regression loss: 0.11120 | Running loss: 0.28166\n",
      "Epoch: 15 | Iteration: 215 | Classification loss: 0.04138 | Regression loss: 0.14770 | Running loss: 0.28131\n",
      "Epoch: 15 | Iteration: 216 | Classification loss: 0.13280 | Regression loss: 0.24416 | Running loss: 0.28162\n",
      "Epoch: 15 | Iteration: 217 | Classification loss: 0.07171 | Regression loss: 0.27571 | Running loss: 0.28232\n",
      "Epoch: 15 | Iteration: 218 | Classification loss: 0.10175 | Regression loss: 0.16729 | Running loss: 0.28226\n",
      "Epoch: 15 | Iteration: 219 | Classification loss: 0.06243 | Regression loss: 0.24482 | Running loss: 0.28258\n",
      "Epoch: 15 | Iteration: 220 | Classification loss: 0.12285 | Regression loss: 0.30941 | Running loss: 0.28310\n",
      "Epoch: 15 | Iteration: 221 | Classification loss: 0.05970 | Regression loss: 0.23069 | Running loss: 0.28330\n",
      "Epoch: 15 | Iteration: 222 | Classification loss: 0.03857 | Regression loss: 0.26028 | Running loss: 0.28301\n",
      "Epoch: 15 | Iteration: 223 | Classification loss: 0.10023 | Regression loss: 0.30142 | Running loss: 0.28341\n",
      "Epoch: 15 | Iteration: 224 | Classification loss: 0.03269 | Regression loss: 0.24077 | Running loss: 0.28360\n",
      "Epoch: 15 | Iteration: 225 | Classification loss: 0.40155 | Regression loss: 0.34257 | Running loss: 0.28474\n",
      "Epoch: 15 | Iteration: 226 | Classification loss: 0.08536 | Regression loss: 0.29881 | Running loss: 0.28430\n",
      "Epoch: 15 | Iteration: 227 | Classification loss: 0.07902 | Regression loss: 0.37191 | Running loss: 0.28485\n",
      "Epoch: 15 | Iteration: 228 | Classification loss: 0.05648 | Regression loss: 0.21667 | Running loss: 0.28503\n",
      "Epoch: 15 | Iteration: 229 | Classification loss: 0.01898 | Regression loss: 0.08910 | Running loss: 0.28446\n",
      "Epoch: 15 | Iteration: 230 | Classification loss: 0.07472 | Regression loss: 0.19623 | Running loss: 0.28458\n",
      "Epoch: 15 | Iteration: 231 | Classification loss: 0.06365 | Regression loss: 0.20224 | Running loss: 0.28445\n",
      "Epoch: 15 | Iteration: 232 | Classification loss: 0.03737 | Regression loss: 0.15986 | Running loss: 0.28416\n",
      "Epoch: 15 | Iteration: 233 | Classification loss: 0.02128 | Regression loss: 0.15619 | Running loss: 0.28404\n",
      "Epoch: 15 | Iteration: 234 | Classification loss: 0.03032 | Regression loss: 0.17855 | Running loss: 0.28395\n",
      "Epoch: 15 | Iteration: 235 | Classification loss: 0.03183 | Regression loss: 0.16089 | Running loss: 0.28380\n",
      "Epoch: 15 | Iteration: 236 | Classification loss: 0.04046 | Regression loss: 0.14908 | Running loss: 0.28380\n",
      "Epoch: 15 | Iteration: 237 | Classification loss: 0.03469 | Regression loss: 0.12898 | Running loss: 0.28303\n",
      "Epoch: 15 | Iteration: 238 | Classification loss: 0.03923 | Regression loss: 0.15846 | Running loss: 0.28287\n",
      "Epoch: 15 | Iteration: 239 | Classification loss: 0.03660 | Regression loss: 0.32379 | Running loss: 0.28300\n",
      "Epoch: 15 | Iteration: 240 | Classification loss: 0.02656 | Regression loss: 0.27099 | Running loss: 0.28300\n",
      "Epoch: 15 | Iteration: 241 | Classification loss: 0.06476 | Regression loss: 0.25361 | Running loss: 0.28339\n",
      "Epoch: 15 | Iteration: 242 | Classification loss: 0.07030 | Regression loss: 0.33107 | Running loss: 0.28322\n",
      "Epoch: 15 | Iteration: 243 | Classification loss: 0.03521 | Regression loss: 0.13188 | Running loss: 0.28303\n",
      "Epoch: 15 | Iteration: 244 | Classification loss: 0.06959 | Regression loss: 0.31462 | Running loss: 0.28333\n",
      "Epoch: 15 | Iteration: 245 | Classification loss: 0.04143 | Regression loss: 0.13893 | Running loss: 0.28309\n",
      "Epoch: 15 | Iteration: 246 | Classification loss: 0.03721 | Regression loss: 0.16157 | Running loss: 0.28265\n",
      "Epoch: 15 | Iteration: 247 | Classification loss: 0.09048 | Regression loss: 0.19453 | Running loss: 0.28273\n",
      "Epoch: 15 | Iteration: 248 | Classification loss: 0.10479 | Regression loss: 0.32992 | Running loss: 0.28217\n",
      "Epoch: 15 | Iteration: 249 | Classification loss: 0.04704 | Regression loss: 0.15523 | Running loss: 0.28213\n",
      "Epoch: 15 | Iteration: 250 | Classification loss: 0.00855 | Regression loss: 0.13460 | Running loss: 0.28210\n",
      "Epoch: 15 | Iteration: 251 | Classification loss: 0.05297 | Regression loss: 0.15167 | Running loss: 0.28221\n",
      "Epoch: 15 | Iteration: 252 | Classification loss: 0.04452 | Regression loss: 0.22526 | Running loss: 0.28243\n",
      "Epoch: 15 | Iteration: 253 | Classification loss: 0.04282 | Regression loss: 0.21296 | Running loss: 0.28263\n",
      "Epoch: 15 | Iteration: 254 | Classification loss: 0.01525 | Regression loss: 0.14621 | Running loss: 0.28205\n",
      "Epoch: 15 | Iteration: 255 | Classification loss: 0.01671 | Regression loss: 0.08543 | Running loss: 0.28110\n",
      "Epoch: 15 | Iteration: 256 | Classification loss: 0.08615 | Regression loss: 0.28607 | Running loss: 0.28131\n",
      "Epoch: 15 | Iteration: 257 | Classification loss: 0.05225 | Regression loss: 0.12242 | Running loss: 0.28140\n",
      "Epoch: 15 | Iteration: 258 | Classification loss: 0.04646 | Regression loss: 0.04963 | Running loss: 0.28119\n",
      "Epoch: 15 | Iteration: 259 | Classification loss: 0.19971 | Regression loss: 0.41886 | Running loss: 0.28211\n",
      "Epoch: 15 | Iteration: 260 | Classification loss: 0.11732 | Regression loss: 0.28881 | Running loss: 0.28162\n",
      "Epoch: 15 | Iteration: 261 | Classification loss: 0.03344 | Regression loss: 0.15106 | Running loss: 0.28126\n",
      "Epoch: 15 | Iteration: 262 | Classification loss: 0.04244 | Regression loss: 0.05326 | Running loss: 0.28092\n",
      "Epoch: 15 | Iteration: 263 | Classification loss: 0.02818 | Regression loss: 0.12754 | Running loss: 0.28078\n",
      "Epoch: 15 | Iteration: 264 | Classification loss: 0.02710 | Regression loss: 0.24787 | Running loss: 0.28070\n",
      "Epoch: 15 | Iteration: 265 | Classification loss: 0.02377 | Regression loss: 0.10180 | Running loss: 0.27997\n",
      "Epoch: 15 | Iteration: 266 | Classification loss: 0.05165 | Regression loss: 0.22793 | Running loss: 0.27987\n",
      "Epoch: 15 | Iteration: 267 | Classification loss: 0.08206 | Regression loss: 0.38711 | Running loss: 0.28013\n",
      "Epoch: 15 | Iteration: 268 | Classification loss: 0.07232 | Regression loss: 0.24762 | Running loss: 0.28038\n",
      "Epoch: 15 | Iteration: 269 | Classification loss: 0.01632 | Regression loss: 0.05229 | Running loss: 0.27987\n",
      "Epoch: 15 | Iteration: 270 | Classification loss: 0.05045 | Regression loss: 0.08883 | Running loss: 0.27981\n",
      "Epoch: 15 | Iteration: 271 | Classification loss: 0.01619 | Regression loss: 0.23627 | Running loss: 0.27922\n",
      "Epoch: 15 | Iteration: 272 | Classification loss: 0.17229 | Regression loss: 0.17907 | Running loss: 0.27957\n",
      "Epoch: 15 | Iteration: 273 | Classification loss: 0.01491 | Regression loss: 0.11091 | Running loss: 0.27928\n",
      "Epoch: 15 | Iteration: 274 | Classification loss: 0.06177 | Regression loss: 0.21017 | Running loss: 0.27809\n",
      "Epoch: 15 | Iteration: 275 | Classification loss: 0.03370 | Regression loss: 0.14890 | Running loss: 0.27735\n",
      "Epoch: 15 | Iteration: 276 | Classification loss: 0.03842 | Regression loss: 0.12661 | Running loss: 0.27700\n",
      "Epoch: 15 | Iteration: 277 | Classification loss: 0.01798 | Regression loss: 0.08646 | Running loss: 0.27608\n",
      "Epoch: 15 | Iteration: 278 | Classification loss: 0.06522 | Regression loss: 0.15914 | Running loss: 0.27537\n",
      "Epoch: 15 | Iteration: 279 | Classification loss: 0.01953 | Regression loss: 0.14996 | Running loss: 0.27520\n",
      "Epoch: 15 | Iteration: 280 | Classification loss: 0.01751 | Regression loss: 0.07269 | Running loss: 0.27492\n",
      "Epoch: 15 | Iteration: 281 | Classification loss: 0.05090 | Regression loss: 0.18291 | Running loss: 0.27474\n",
      "Epoch: 15 | Iteration: 282 | Classification loss: 0.05482 | Regression loss: 0.26348 | Running loss: 0.27475\n",
      "Epoch: 15 | Iteration: 283 | Classification loss: 0.03007 | Regression loss: 0.15743 | Running loss: 0.27481\n",
      "Epoch: 15 | Iteration: 284 | Classification loss: 0.01945 | Regression loss: 0.15034 | Running loss: 0.27433\n",
      "Epoch: 15 | Iteration: 285 | Classification loss: 0.03622 | Regression loss: 0.15880 | Running loss: 0.27392\n",
      "Epoch: 15 | Iteration: 286 | Classification loss: 0.10650 | Regression loss: 0.19681 | Running loss: 0.27395\n",
      "Epoch: 15 | Iteration: 287 | Classification loss: 0.06975 | Regression loss: 0.30423 | Running loss: 0.27426\n",
      "Epoch: 15 | Iteration: 288 | Classification loss: 0.12352 | Regression loss: 0.40962 | Running loss: 0.27473\n",
      "Epoch: 15 | Iteration: 289 | Classification loss: 0.05670 | Regression loss: 0.20533 | Running loss: 0.27495\n",
      "Epoch: 15 | Iteration: 290 | Classification loss: 0.09144 | Regression loss: 0.09238 | Running loss: 0.27434\n",
      "Epoch: 15 | Iteration: 291 | Classification loss: 0.04670 | Regression loss: 0.31850 | Running loss: 0.27470\n",
      "Epoch: 15 | Iteration: 292 | Classification loss: 0.06153 | Regression loss: 0.23731 | Running loss: 0.27481\n",
      "Epoch: 15 | Iteration: 293 | Classification loss: 0.04366 | Regression loss: 0.10718 | Running loss: 0.27448\n",
      "Epoch: 15 | Iteration: 294 | Classification loss: 0.19934 | Regression loss: 0.40527 | Running loss: 0.27430\n",
      "Epoch: 15 | Iteration: 295 | Classification loss: 0.12635 | Regression loss: 0.23289 | Running loss: 0.27476\n",
      "Epoch: 15 | Iteration: 296 | Classification loss: 0.03101 | Regression loss: 0.10638 | Running loss: 0.27457\n",
      "Epoch: 15 | Iteration: 297 | Classification loss: 0.04398 | Regression loss: 0.15882 | Running loss: 0.27381\n",
      "Epoch: 15 | Iteration: 298 | Classification loss: 0.33266 | Regression loss: 0.12029 | Running loss: 0.27418\n",
      "Epoch: 15 | Iteration: 299 | Classification loss: 0.07043 | Regression loss: 0.21327 | Running loss: 0.27432\n",
      "Epoch: 15 | Iteration: 300 | Classification loss: 0.09019 | Regression loss: 0.33640 | Running loss: 0.27446\n",
      "Epoch: 15 | Iteration: 301 | Classification loss: 0.02297 | Regression loss: 0.13660 | Running loss: 0.27416\n",
      "Epoch: 15 | Iteration: 302 | Classification loss: 0.14775 | Regression loss: 0.08623 | Running loss: 0.27414\n",
      "Epoch: 15 | Iteration: 303 | Classification loss: 0.02423 | Regression loss: 0.24705 | Running loss: 0.27359\n",
      "Epoch: 15 | Iteration: 304 | Classification loss: 0.52515 | Regression loss: 0.66500 | Running loss: 0.27559\n",
      "Epoch: 15 | Iteration: 305 | Classification loss: 0.02630 | Regression loss: 0.21031 | Running loss: 0.27557\n",
      "Epoch: 15 | Iteration: 306 | Classification loss: 0.01400 | Regression loss: 0.15890 | Running loss: 0.27533\n",
      "Epoch: 15 | Iteration: 307 | Classification loss: 0.04897 | Regression loss: 0.30715 | Running loss: 0.27538\n",
      "Epoch: 15 | Iteration: 308 | Classification loss: 0.03870 | Regression loss: 0.28263 | Running loss: 0.27568\n",
      "Epoch: 15 | Iteration: 309 | Classification loss: 0.04585 | Regression loss: 0.38054 | Running loss: 0.27525\n",
      "Epoch: 15 | Iteration: 310 | Classification loss: 0.15187 | Regression loss: 0.34373 | Running loss: 0.27547\n",
      "Epoch: 15 | Iteration: 311 | Classification loss: 0.05498 | Regression loss: 0.10218 | Running loss: 0.27494\n",
      "Epoch: 15 | Iteration: 312 | Classification loss: 0.04339 | Regression loss: 0.13028 | Running loss: 0.27477\n",
      "Epoch: 15 | Iteration: 313 | Classification loss: 0.04765 | Regression loss: 0.14013 | Running loss: 0.27472\n",
      "Epoch: 15 | Iteration: 314 | Classification loss: 0.07361 | Regression loss: 0.15639 | Running loss: 0.27449\n",
      "Epoch: 15 | Iteration: 315 | Classification loss: 0.06830 | Regression loss: 0.17689 | Running loss: 0.27460\n",
      "Epoch: 15 | Iteration: 316 | Classification loss: 0.02933 | Regression loss: 0.17895 | Running loss: 0.27440\n",
      "Epoch: 15 | Iteration: 317 | Classification loss: 0.16542 | Regression loss: 0.11243 | Running loss: 0.27464\n",
      "Epoch: 15 | Iteration: 318 | Classification loss: 0.03794 | Regression loss: 0.14010 | Running loss: 0.27464\n",
      "Epoch: 15 | Iteration: 319 | Classification loss: 0.02262 | Regression loss: 0.09600 | Running loss: 0.27394\n",
      "Epoch: 15 | Iteration: 320 | Classification loss: 0.05756 | Regression loss: 0.18888 | Running loss: 0.27377\n",
      "Epoch: 15 | Iteration: 321 | Classification loss: 0.04367 | Regression loss: 0.17195 | Running loss: 0.27391\n",
      "Epoch: 15 | Iteration: 322 | Classification loss: 0.05758 | Regression loss: 0.23561 | Running loss: 0.27388\n",
      "Epoch: 15 | Iteration: 323 | Classification loss: 0.03034 | Regression loss: 0.13877 | Running loss: 0.27371\n",
      "Epoch: 15 | Iteration: 324 | Classification loss: 0.10663 | Regression loss: 0.26920 | Running loss: 0.27411\n",
      "Epoch: 15 | Iteration: 325 | Classification loss: 0.01360 | Regression loss: 0.11535 | Running loss: 0.27396\n",
      "Epoch: 15 | Iteration: 326 | Classification loss: 0.07721 | Regression loss: 0.24722 | Running loss: 0.27408\n",
      "Epoch: 15 | Iteration: 327 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.27366\n",
      "Epoch: 15 | Iteration: 328 | Classification loss: 0.25633 | Regression loss: 0.21386 | Running loss: 0.27398\n",
      "Epoch: 15 | Iteration: 329 | Classification loss: 0.01675 | Regression loss: 0.09160 | Running loss: 0.27384\n",
      "Epoch: 15 | Iteration: 330 | Classification loss: 0.01900 | Regression loss: 0.06251 | Running loss: 0.27351\n",
      "Epoch: 15 | Iteration: 331 | Classification loss: 0.01709 | Regression loss: 0.13971 | Running loss: 0.27355\n",
      "Epoch: 15 | Iteration: 332 | Classification loss: 0.02908 | Regression loss: 0.09392 | Running loss: 0.27363\n",
      "Epoch: 15 | Iteration: 333 | Classification loss: 0.02780 | Regression loss: 0.16919 | Running loss: 0.27339\n",
      "Epoch: 15 | Iteration: 334 | Classification loss: 0.03052 | Regression loss: 0.16137 | Running loss: 0.27323\n",
      "Epoch: 15 | Iteration: 335 | Classification loss: 0.07170 | Regression loss: 0.30845 | Running loss: 0.27364\n",
      "Epoch: 15 | Iteration: 336 | Classification loss: 0.07294 | Regression loss: 0.31447 | Running loss: 0.27373\n",
      "Epoch: 15 | Iteration: 337 | Classification loss: 0.10662 | Regression loss: 0.29542 | Running loss: 0.27374\n",
      "Epoch: 15 | Iteration: 338 | Classification loss: 0.04808 | Regression loss: 0.14203 | Running loss: 0.27334\n",
      "Epoch: 15 | Iteration: 339 | Classification loss: 0.01863 | Regression loss: 0.14845 | Running loss: 0.27222\n",
      "Epoch: 15 | Iteration: 340 | Classification loss: 0.07571 | Regression loss: 0.25838 | Running loss: 0.27262\n",
      "Epoch: 15 | Iteration: 341 | Classification loss: 0.01206 | Regression loss: 0.12883 | Running loss: 0.27227\n",
      "Epoch: 15 | Iteration: 342 | Classification loss: 0.03733 | Regression loss: 0.23248 | Running loss: 0.27216\n",
      "Epoch: 15 | Iteration: 343 | Classification loss: 0.02099 | Regression loss: 0.28171 | Running loss: 0.27239\n",
      "Epoch: 15 | Iteration: 344 | Classification loss: 0.05672 | Regression loss: 0.08871 | Running loss: 0.27201\n",
      "Epoch: 15 | Iteration: 345 | Classification loss: 0.06722 | Regression loss: 0.12869 | Running loss: 0.27200\n",
      "Epoch: 15 | Iteration: 346 | Classification loss: 0.02715 | Regression loss: 0.19063 | Running loss: 0.27205\n",
      "Epoch: 15 | Iteration: 347 | Classification loss: 0.10812 | Regression loss: 0.22398 | Running loss: 0.27177\n",
      "Epoch: 15 | Iteration: 348 | Classification loss: 0.08361 | Regression loss: 0.20139 | Running loss: 0.27126\n",
      "Epoch: 15 | Iteration: 349 | Classification loss: 0.01526 | Regression loss: 0.13765 | Running loss: 0.27114\n",
      "Epoch: 15 | Iteration: 350 | Classification loss: 0.03017 | Regression loss: 0.11257 | Running loss: 0.27105\n",
      "Epoch: 15 | Iteration: 351 | Classification loss: 0.02610 | Regression loss: 0.11954 | Running loss: 0.27105\n",
      "Epoch: 15 | Iteration: 352 | Classification loss: 0.05707 | Regression loss: 0.20393 | Running loss: 0.27127\n",
      "Epoch: 15 | Iteration: 353 | Classification loss: 0.01916 | Regression loss: 0.09102 | Running loss: 0.27055\n",
      "Epoch: 15 | Iteration: 354 | Classification loss: 0.01602 | Regression loss: 0.12286 | Running loss: 0.27055\n",
      "Epoch: 15 | Iteration: 355 | Classification loss: 0.05701 | Regression loss: 0.19862 | Running loss: 0.27038\n",
      "Epoch: 15 | Iteration: 356 | Classification loss: 0.03141 | Regression loss: 0.16805 | Running loss: 0.27046\n",
      "Epoch: 15 | Iteration: 357 | Classification loss: 0.01497 | Regression loss: 0.07630 | Running loss: 0.26961\n",
      "Epoch: 15 | Iteration: 358 | Classification loss: 0.01097 | Regression loss: 0.06414 | Running loss: 0.26849\n",
      "Epoch: 15 | Iteration: 359 | Classification loss: 0.01431 | Regression loss: 0.16613 | Running loss: 0.26854\n",
      "Epoch: 15 | Iteration: 360 | Classification loss: 0.04558 | Regression loss: 0.32221 | Running loss: 0.26890\n",
      "Epoch: 15 | Iteration: 361 | Classification loss: 0.15681 | Regression loss: 0.25182 | Running loss: 0.26936\n",
      "Epoch: 15 | Iteration: 362 | Classification loss: 0.03225 | Regression loss: 0.10199 | Running loss: 0.26939\n",
      "Epoch: 15 | Iteration: 363 | Classification loss: 0.10240 | Regression loss: 0.41081 | Running loss: 0.26999\n",
      "Epoch: 15 | Iteration: 364 | Classification loss: 0.02319 | Regression loss: 0.16236 | Running loss: 0.26985\n",
      "Epoch: 15 | Iteration: 365 | Classification loss: 0.01758 | Regression loss: 0.12031 | Running loss: 0.26968\n",
      "Epoch: 15 | Iteration: 366 | Classification loss: 0.26407 | Regression loss: 0.33105 | Running loss: 0.27035\n",
      "Epoch: 15 | Iteration: 367 | Classification loss: 0.06867 | Regression loss: 0.18259 | Running loss: 0.27046\n",
      "Epoch: 15 | Iteration: 368 | Classification loss: 0.03456 | Regression loss: 0.21787 | Running loss: 0.27049\n",
      "Epoch: 15 | Iteration: 369 | Classification loss: 0.11054 | Regression loss: 0.33499 | Running loss: 0.27086\n",
      "Epoch: 15 | Iteration: 370 | Classification loss: 0.04675 | Regression loss: 0.18834 | Running loss: 0.27082\n",
      "Epoch: 15 | Iteration: 371 | Classification loss: 0.03848 | Regression loss: 0.13843 | Running loss: 0.27067\n",
      "Epoch: 15 | Iteration: 372 | Classification loss: 0.18465 | Regression loss: 0.54211 | Running loss: 0.27149\n",
      "Epoch: 15 | Iteration: 373 | Classification loss: 0.08286 | Regression loss: 0.25389 | Running loss: 0.27116\n",
      "Epoch: 15 | Iteration: 374 | Classification loss: 0.03722 | Regression loss: 0.21701 | Running loss: 0.27078\n",
      "Epoch: 15 | Iteration: 375 | Classification loss: 0.01837 | Regression loss: 0.13225 | Running loss: 0.27038\n",
      "Epoch: 15 | Iteration: 376 | Classification loss: 0.09019 | Regression loss: 0.20556 | Running loss: 0.27053\n",
      "Epoch: 15 | Iteration: 377 | Classification loss: 0.02254 | Regression loss: 0.12260 | Running loss: 0.27010\n",
      "Epoch: 15 | Iteration: 378 | Classification loss: 0.02735 | Regression loss: 0.13424 | Running loss: 0.26980\n",
      "Epoch: 15 | Iteration: 379 | Classification loss: 0.02350 | Regression loss: 0.16220 | Running loss: 0.26945\n",
      "Epoch: 15 | Iteration: 380 | Classification loss: 0.01665 | Regression loss: 0.14121 | Running loss: 0.26928\n",
      "Epoch: 15 | Iteration: 381 | Classification loss: 0.07007 | Regression loss: 0.40311 | Running loss: 0.26943\n",
      "Epoch: 15 | Iteration: 382 | Classification loss: 0.04693 | Regression loss: 0.22014 | Running loss: 0.26934\n",
      "Epoch: 15 | Iteration: 383 | Classification loss: 0.06458 | Regression loss: 0.20853 | Running loss: 0.26947\n",
      "Epoch: 15 | Iteration: 384 | Classification loss: 0.07966 | Regression loss: 0.27420 | Running loss: 0.26945\n",
      "Epoch: 15 | Iteration: 385 | Classification loss: 0.01955 | Regression loss: 0.08831 | Running loss: 0.26875\n",
      "Epoch: 15 | Iteration: 386 | Classification loss: 0.01648 | Regression loss: 0.11911 | Running loss: 0.26875\n",
      "Epoch: 15 | Iteration: 387 | Classification loss: 0.01324 | Regression loss: 0.11908 | Running loss: 0.26868\n",
      "Epoch: 15 | Iteration: 388 | Classification loss: 0.05145 | Regression loss: 0.19746 | Running loss: 0.26855\n",
      "Epoch: 15 | Iteration: 389 | Classification loss: 0.05509 | Regression loss: 0.19205 | Running loss: 0.26863\n",
      "Epoch: 15 | Iteration: 390 | Classification loss: 0.01237 | Regression loss: 0.09878 | Running loss: 0.26846\n",
      "Epoch: 15 | Iteration: 391 | Classification loss: 0.01989 | Regression loss: 0.16322 | Running loss: 0.26766\n",
      "Epoch: 15 | Iteration: 392 | Classification loss: 0.02464 | Regression loss: 0.09707 | Running loss: 0.26716\n",
      "Epoch: 15 | Iteration: 393 | Classification loss: 0.02761 | Regression loss: 0.12654 | Running loss: 0.26674\n",
      "Epoch: 15 | Iteration: 394 | Classification loss: 0.02113 | Regression loss: 0.15947 | Running loss: 0.26674\n",
      "Epoch: 15 | Iteration: 395 | Classification loss: 0.01650 | Regression loss: 0.09378 | Running loss: 0.26669\n",
      "Epoch: 15 | Iteration: 396 | Classification loss: 0.04308 | Regression loss: 0.09529 | Running loss: 0.26642\n",
      "Epoch: 15 | Iteration: 397 | Classification loss: 0.04891 | Regression loss: 0.22393 | Running loss: 0.26625\n",
      "Epoch: 15 | Iteration: 398 | Classification loss: 0.07842 | Regression loss: 0.19870 | Running loss: 0.26610\n",
      "Epoch: 15 | Iteration: 399 | Classification loss: 0.01608 | Regression loss: 0.07615 | Running loss: 0.26596\n",
      "Epoch: 15 | Iteration: 400 | Classification loss: 0.07283 | Regression loss: 0.28157 | Running loss: 0.26592\n",
      "Epoch: 15 | Iteration: 401 | Classification loss: 0.03300 | Regression loss: 0.12945 | Running loss: 0.26599\n",
      "Epoch: 15 | Iteration: 402 | Classification loss: 0.12717 | Regression loss: 0.29492 | Running loss: 0.26597\n",
      "Epoch: 15 | Iteration: 403 | Classification loss: 0.02194 | Regression loss: 0.19544 | Running loss: 0.26599\n",
      "Epoch: 15 | Iteration: 404 | Classification loss: 0.06404 | Regression loss: 0.12257 | Running loss: 0.26593\n",
      "Epoch: 15 | Iteration: 405 | Classification loss: 0.03844 | Regression loss: 0.18379 | Running loss: 0.26586\n",
      "Epoch: 15 | Iteration: 406 | Classification loss: 0.04349 | Regression loss: 0.21673 | Running loss: 0.26590\n",
      "Epoch: 15 | Iteration: 407 | Classification loss: 0.02091 | Regression loss: 0.11179 | Running loss: 0.26560\n",
      "Epoch: 15 | Iteration: 408 | Classification loss: 0.03586 | Regression loss: 0.18722 | Running loss: 0.26525\n",
      "Epoch: 15 | Iteration: 409 | Classification loss: 0.04815 | Regression loss: 0.10896 | Running loss: 0.26503\n",
      "Epoch: 15 | Iteration: 410 | Classification loss: 0.06905 | Regression loss: 0.12048 | Running loss: 0.26507\n",
      "Epoch: 15 | Iteration: 411 | Classification loss: 0.03706 | Regression loss: 0.17522 | Running loss: 0.26514\n",
      "Epoch: 15 | Iteration: 412 | Classification loss: 0.02344 | Regression loss: 0.10815 | Running loss: 0.26469\n",
      "Epoch: 15 | Iteration: 413 | Classification loss: 0.05908 | Regression loss: 0.29540 | Running loss: 0.26447\n",
      "Epoch: 15 | Iteration: 414 | Classification loss: 0.17134 | Regression loss: 0.45383 | Running loss: 0.26523\n",
      "Epoch: 15 | Iteration: 415 | Classification loss: 0.04567 | Regression loss: 0.22859 | Running loss: 0.26537\n",
      "Epoch: 15 | Iteration: 416 | Classification loss: 0.04943 | Regression loss: 0.18139 | Running loss: 0.26546\n",
      "Epoch: 15 | Iteration: 417 | Classification loss: 0.05311 | Regression loss: 0.12789 | Running loss: 0.26480\n",
      "Epoch: 15 | Iteration: 418 | Classification loss: 0.03459 | Regression loss: 0.19905 | Running loss: 0.26431\n",
      "Epoch: 15 | Iteration: 419 | Classification loss: 0.05594 | Regression loss: 0.17613 | Running loss: 0.26408\n",
      "Epoch: 15 | Iteration: 420 | Classification loss: 0.15059 | Regression loss: 0.28841 | Running loss: 0.26448\n",
      "Epoch: 15 | Iteration: 421 | Classification loss: 0.04366 | Regression loss: 0.20422 | Running loss: 0.26392\n",
      "Epoch: 15 | Iteration: 422 | Classification loss: 0.03564 | Regression loss: 0.15861 | Running loss: 0.26361\n",
      "Epoch: 15 | Iteration: 423 | Classification loss: 0.03151 | Regression loss: 0.17695 | Running loss: 0.26332\n",
      "Epoch: 15 | Iteration: 424 | Classification loss: 0.02804 | Regression loss: 0.15960 | Running loss: 0.26309\n",
      "Epoch: 15 | Iteration: 425 | Classification loss: 0.01342 | Regression loss: 0.14841 | Running loss: 0.26299\n",
      "Epoch: 15 | Iteration: 426 | Classification loss: 0.02525 | Regression loss: 0.12645 | Running loss: 0.26288\n",
      "Epoch: 15 | Iteration: 427 | Classification loss: 0.02801 | Regression loss: 0.09647 | Running loss: 0.26313\n",
      "Epoch: 15 | Iteration: 428 | Classification loss: 0.05919 | Regression loss: 0.10529 | Running loss: 0.26290\n",
      "Epoch: 15 | Iteration: 429 | Classification loss: 0.02504 | Regression loss: 0.16041 | Running loss: 0.26213\n",
      "Epoch: 15 | Iteration: 430 | Classification loss: 0.01562 | Regression loss: 0.11036 | Running loss: 0.26201\n",
      "Epoch: 15 | Iteration: 431 | Classification loss: 0.06793 | Regression loss: 0.17499 | Running loss: 0.26131\n",
      "Epoch: 15 | Iteration: 432 | Classification loss: 0.06962 | Regression loss: 0.28866 | Running loss: 0.26164\n",
      "Epoch: 15 | Iteration: 433 | Classification loss: 0.05281 | Regression loss: 0.05497 | Running loss: 0.26153\n",
      "Epoch: 15 | Iteration: 434 | Classification loss: 0.01717 | Regression loss: 0.14014 | Running loss: 0.26153\n",
      "Epoch: 15 | Iteration: 435 | Classification loss: 0.01371 | Regression loss: 0.13843 | Running loss: 0.26093\n",
      "Epoch: 15 | Iteration: 436 | Classification loss: 0.02235 | Regression loss: 0.14742 | Running loss: 0.26074\n",
      "Epoch: 15 | Iteration: 437 | Classification loss: 0.02955 | Regression loss: 0.16151 | Running loss: 0.26064\n",
      "Epoch: 15 | Iteration: 438 | Classification loss: 0.03556 | Regression loss: 0.08256 | Running loss: 0.26016\n",
      "Epoch: 15 | Iteration: 439 | Classification loss: 0.11850 | Regression loss: 0.24650 | Running loss: 0.26027\n",
      "Epoch: 15 | Iteration: 440 | Classification loss: 0.07665 | Regression loss: 0.41485 | Running loss: 0.26067\n",
      "Epoch: 15 | Iteration: 441 | Classification loss: 0.01299 | Regression loss: 0.16275 | Running loss: 0.26054\n",
      "Epoch: 15 | Iteration: 442 | Classification loss: 0.07040 | Regression loss: 0.20092 | Running loss: 0.26024\n",
      "Epoch: 15 | Iteration: 443 | Classification loss: 0.00958 | Regression loss: 0.03266 | Running loss: 0.25990\n",
      "Epoch: 15 | Iteration: 444 | Classification loss: 0.10569 | Regression loss: 0.17842 | Running loss: 0.26027\n",
      "Epoch: 15 | Iteration: 445 | Classification loss: 0.05543 | Regression loss: 0.21496 | Running loss: 0.26024\n",
      "Epoch: 15 | Iteration: 446 | Classification loss: 0.10088 | Regression loss: 0.14441 | Running loss: 0.26023\n",
      "Epoch: 15 | Iteration: 447 | Classification loss: 0.06906 | Regression loss: 0.15577 | Running loss: 0.26046\n",
      "Epoch: 15 | Iteration: 448 | Classification loss: 0.02714 | Regression loss: 0.24478 | Running loss: 0.26073\n",
      "Epoch: 15 | Iteration: 449 | Classification loss: 0.03007 | Regression loss: 0.16150 | Running loss: 0.26074\n",
      "Epoch: 15 | Iteration: 450 | Classification loss: 0.01742 | Regression loss: 0.16587 | Running loss: 0.26040\n",
      "Epoch: 15 | Iteration: 451 | Classification loss: 0.01888 | Regression loss: 0.11042 | Running loss: 0.26026\n",
      "Epoch: 15 | Iteration: 452 | Classification loss: 0.05386 | Regression loss: 0.20647 | Running loss: 0.26032\n",
      "Epoch: 15 | Iteration: 453 | Classification loss: 0.08087 | Regression loss: 0.25781 | Running loss: 0.26043\n",
      "Epoch: 15 | Iteration: 454 | Classification loss: 0.03086 | Regression loss: 0.17511 | Running loss: 0.25837\n",
      "Epoch: 15 | Iteration: 455 | Classification loss: 0.02121 | Regression loss: 0.14585 | Running loss: 0.25788\n",
      "Epoch: 15 | Iteration: 456 | Classification loss: 0.04304 | Regression loss: 0.14853 | Running loss: 0.25703\n",
      "Epoch: 15 | Iteration: 457 | Classification loss: 0.08639 | Regression loss: 0.31776 | Running loss: 0.25724\n",
      "Epoch: 15 | Iteration: 458 | Classification loss: 0.15527 | Regression loss: 0.43658 | Running loss: 0.25795\n",
      "Epoch: 15 | Iteration: 459 | Classification loss: 0.05068 | Regression loss: 0.22014 | Running loss: 0.25812\n",
      "Epoch: 15 | Iteration: 460 | Classification loss: 0.02737 | Regression loss: 0.22013 | Running loss: 0.25833\n",
      "Epoch: 15 | Iteration: 461 | Classification loss: 0.01886 | Regression loss: 0.17755 | Running loss: 0.25848\n",
      "Epoch: 15 | Iteration: 462 | Classification loss: 0.03734 | Regression loss: 0.21894 | Running loss: 0.25877\n",
      "Epoch: 15 | Iteration: 463 | Classification loss: 0.02479 | Regression loss: 0.23426 | Running loss: 0.25880\n",
      "Epoch: 15 | Iteration: 464 | Classification loss: 0.08011 | Regression loss: 0.14005 | Running loss: 0.25899\n",
      "Epoch: 15 | Iteration: 465 | Classification loss: 0.04450 | Regression loss: 0.12349 | Running loss: 0.25915\n",
      "Epoch: 15 | Iteration: 466 | Classification loss: 0.04889 | Regression loss: 0.21147 | Running loss: 0.25946\n",
      "Epoch: 15 | Iteration: 467 | Classification loss: 0.01448 | Regression loss: 0.07811 | Running loss: 0.25933\n",
      "Epoch: 15 | Iteration: 468 | Classification loss: 0.04464 | Regression loss: 0.08685 | Running loss: 0.25927\n",
      "Epoch: 15 | Iteration: 469 | Classification loss: 0.06730 | Regression loss: 0.09097 | Running loss: 0.25909\n",
      "Epoch: 15 | Iteration: 470 | Classification loss: 0.04621 | Regression loss: 0.19348 | Running loss: 0.25882\n",
      "Epoch: 15 | Iteration: 471 | Classification loss: 0.02210 | Regression loss: 0.09878 | Running loss: 0.25862\n",
      "Epoch: 15 | Iteration: 472 | Classification loss: 0.04117 | Regression loss: 0.30571 | Running loss: 0.25902\n",
      "Epoch: 15 | Iteration: 473 | Classification loss: 0.04425 | Regression loss: 0.15649 | Running loss: 0.25880\n",
      "Epoch: 15 | Iteration: 474 | Classification loss: 0.03993 | Regression loss: 0.08856 | Running loss: 0.25882\n",
      "Epoch: 15 | Iteration: 475 | Classification loss: 0.06990 | Regression loss: 0.24576 | Running loss: 0.25887\n",
      "Epoch: 15 | Iteration: 476 | Classification loss: 0.02745 | Regression loss: 0.07608 | Running loss: 0.25872\n",
      "Epoch: 15 | Iteration: 477 | Classification loss: 0.02743 | Regression loss: 0.11457 | Running loss: 0.25863\n",
      "Epoch: 15 | Iteration: 478 | Classification loss: 0.08708 | Regression loss: 0.24407 | Running loss: 0.25890\n",
      "Epoch: 15 | Iteration: 479 | Classification loss: 0.04342 | Regression loss: 0.26014 | Running loss: 0.25898\n",
      "Epoch: 15 | Iteration: 480 | Classification loss: 0.02671 | Regression loss: 0.16718 | Running loss: 0.25807\n",
      "Epoch: 15 | Iteration: 481 | Classification loss: 0.12094 | Regression loss: 0.28419 | Running loss: 0.25858\n",
      "Epoch: 15 | Iteration: 482 | Classification loss: 0.02823 | Regression loss: 0.17484 | Running loss: 0.25873\n",
      "Epoch: 15 | Iteration: 483 | Classification loss: 0.02924 | Regression loss: 0.14087 | Running loss: 0.25876\n",
      "Epoch: 15 | Iteration: 484 | Classification loss: 0.14319 | Regression loss: 0.26343 | Running loss: 0.25908\n",
      "Epoch: 15 | Iteration: 485 | Classification loss: 0.04542 | Regression loss: 0.14596 | Running loss: 0.25903\n",
      "Epoch: 15 | Iteration: 486 | Classification loss: 0.11847 | Regression loss: 0.34006 | Running loss: 0.25949\n",
      "Epoch: 15 | Iteration: 487 | Classification loss: 0.02601 | Regression loss: 0.10679 | Running loss: 0.25941\n",
      "Epoch: 15 | Iteration: 488 | Classification loss: 0.03400 | Regression loss: 0.15781 | Running loss: 0.25953\n",
      "Epoch: 15 | Iteration: 489 | Classification loss: 0.05407 | Regression loss: 0.25819 | Running loss: 0.25983\n",
      "Epoch: 15 | Iteration: 490 | Classification loss: 0.05191 | Regression loss: 0.19712 | Running loss: 0.26000\n",
      "Epoch: 15 | Iteration: 491 | Classification loss: 0.03103 | Regression loss: 0.13031 | Running loss: 0.25990\n",
      "Epoch: 15 | Iteration: 492 | Classification loss: 0.08275 | Regression loss: 0.19486 | Running loss: 0.25988\n",
      "Epoch: 15 | Iteration: 493 | Classification loss: 0.04274 | Regression loss: 0.28942 | Running loss: 0.25995\n",
      "Epoch: 15 | Iteration: 494 | Classification loss: 0.06715 | Regression loss: 0.14304 | Running loss: 0.25955\n",
      "Epoch: 15 | Iteration: 495 | Classification loss: 0.03784 | Regression loss: 0.18281 | Running loss: 0.25944\n",
      "Epoch: 15 | Iteration: 496 | Classification loss: 0.06125 | Regression loss: 0.25545 | Running loss: 0.25963\n",
      "Epoch: 15 | Iteration: 497 | Classification loss: 0.04534 | Regression loss: 0.21397 | Running loss: 0.25908\n",
      "Epoch: 15 | Iteration: 498 | Classification loss: 0.02760 | Regression loss: 0.14112 | Running loss: 0.25907\n",
      "Epoch: 15 | Iteration: 499 | Classification loss: 0.06970 | Regression loss: 0.21057 | Running loss: 0.25909\n",
      "Epoch: 15 | Iteration: 500 | Classification loss: 0.04388 | Regression loss: 0.25473 | Running loss: 0.25908\n",
      "Epoch: 15 | Iteration: 501 | Classification loss: 0.04134 | Regression loss: 0.29607 | Running loss: 0.25914\n",
      "Epoch: 15 | Iteration: 502 | Classification loss: 0.04111 | Regression loss: 0.07168 | Running loss: 0.25879\n",
      "Epoch: 15 | Iteration: 503 | Classification loss: 0.10834 | Regression loss: 0.30299 | Running loss: 0.25928\n",
      "Epoch: 15 | Iteration: 504 | Classification loss: 0.03506 | Regression loss: 0.16942 | Running loss: 0.25876\n",
      "Epoch: 15 | Iteration: 505 | Classification loss: 0.02274 | Regression loss: 0.17087 | Running loss: 0.25845\n",
      "Epoch: 15 | Iteration: 506 | Classification loss: 0.02592 | Regression loss: 0.13559 | Running loss: 0.25828\n",
      "Epoch: 15 | Iteration: 507 | Classification loss: 0.03752 | Regression loss: 0.18361 | Running loss: 0.25790\n",
      "Epoch: 15 | Iteration: 508 | Classification loss: 0.03063 | Regression loss: 0.22987 | Running loss: 0.25790\n",
      "Epoch: 15 | Iteration: 509 | Classification loss: 0.02356 | Regression loss: 0.12114 | Running loss: 0.25792\n",
      "Epoch: 15 | Iteration: 510 | Classification loss: 0.03344 | Regression loss: 0.15852 | Running loss: 0.25793\n",
      "Epoch: 15 | Iteration: 511 | Classification loss: 0.26456 | Regression loss: 0.48293 | Running loss: 0.25893\n",
      "Epoch: 15 | Iteration: 512 | Classification loss: 0.03592 | Regression loss: 0.11310 | Running loss: 0.25883\n",
      "Epoch: 15 | Iteration: 513 | Classification loss: 0.06519 | Regression loss: 0.21248 | Running loss: 0.25799\n",
      "Epoch: 15 | Iteration: 514 | Classification loss: 0.05951 | Regression loss: 0.20352 | Running loss: 0.25748\n",
      "Epoch: 15 | Iteration: 515 | Classification loss: 0.10991 | Regression loss: 0.17284 | Running loss: 0.25754\n",
      "Epoch: 15 | Iteration: 516 | Classification loss: 0.09151 | Regression loss: 0.42436 | Running loss: 0.25835\n",
      "Epoch: 15 | Iteration: 517 | Classification loss: 0.06525 | Regression loss: 0.22526 | Running loss: 0.25865\n",
      "Epoch: 15 | Iteration: 518 | Classification loss: 0.06492 | Regression loss: 0.20089 | Running loss: 0.25846\n",
      "Epoch: 15 | Iteration: 519 | Classification loss: 0.01114 | Regression loss: 0.08475 | Running loss: 0.25798\n",
      "Epoch: 15 | Iteration: 520 | Classification loss: 0.03561 | Regression loss: 0.21617 | Running loss: 0.25736\n",
      "Epoch: 15 | Iteration: 521 | Classification loss: 0.03965 | Regression loss: 0.13653 | Running loss: 0.25716\n",
      "Epoch: 15 | Iteration: 522 | Classification loss: 0.08024 | Regression loss: 0.22443 | Running loss: 0.25725\n",
      "Epoch: 15 | Iteration: 523 | Classification loss: 0.02498 | Regression loss: 0.14143 | Running loss: 0.25714\n",
      "Epoch: 15 | Iteration: 524 | Classification loss: 0.15579 | Regression loss: 0.29222 | Running loss: 0.25750\n",
      "Epoch: 15 | Iteration: 525 | Classification loss: 0.03834 | Regression loss: 0.15749 | Running loss: 0.25721\n",
      "Epoch: 15 | Iteration: 526 | Classification loss: 0.01725 | Regression loss: 0.16913 | Running loss: 0.25685\n",
      "Epoch: 15 | Iteration: 527 | Classification loss: 0.03874 | Regression loss: 0.13566 | Running loss: 0.25668\n",
      "Epoch: 15 | Iteration: 528 | Classification loss: 0.03031 | Regression loss: 0.21047 | Running loss: 0.25652\n",
      "Epoch: 15 | Iteration: 529 | Classification loss: 0.02730 | Regression loss: 0.17732 | Running loss: 0.25636\n",
      "Epoch: 15 | Iteration: 530 | Classification loss: 0.02056 | Regression loss: 0.06409 | Running loss: 0.25570\n",
      "Epoch: 15 | Iteration: 531 | Classification loss: 0.06861 | Regression loss: 0.23544 | Running loss: 0.25596\n",
      "Epoch: 15 | Iteration: 532 | Classification loss: 0.09816 | Regression loss: 0.22367 | Running loss: 0.25611\n",
      "Epoch: 15 | Iteration: 533 | Classification loss: 0.03463 | Regression loss: 0.15483 | Running loss: 0.25610\n",
      "Epoch: 15 | Iteration: 534 | Classification loss: 0.05647 | Regression loss: 0.13474 | Running loss: 0.25581\n",
      "Epoch: 15 | Iteration: 535 | Classification loss: 0.01287 | Regression loss: 0.13187 | Running loss: 0.25535\n",
      "Epoch: 15 | Iteration: 536 | Classification loss: 0.04181 | Regression loss: 0.16709 | Running loss: 0.25506\n",
      "Epoch: 15 | Iteration: 537 | Classification loss: 0.17053 | Regression loss: 0.21769 | Running loss: 0.25549\n",
      "Epoch: 15 | Iteration: 538 | Classification loss: 0.05603 | Regression loss: 0.29382 | Running loss: 0.25528\n",
      "Epoch: 15 | Iteration: 539 | Classification loss: 0.02974 | Regression loss: 0.12224 | Running loss: 0.25516\n",
      "Epoch: 15 | Iteration: 540 | Classification loss: 0.14684 | Regression loss: 0.34311 | Running loss: 0.25566\n",
      "Epoch: 15 | Iteration: 541 | Classification loss: 0.01507 | Regression loss: 0.18754 | Running loss: 0.25589\n",
      "Epoch: 15 | Iteration: 542 | Classification loss: 0.05750 | Regression loss: 0.21275 | Running loss: 0.25623\n",
      "Epoch: 15 | Iteration: 543 | Classification loss: 0.04409 | Regression loss: 0.13656 | Running loss: 0.25597\n",
      "Epoch: 15 | Iteration: 544 | Classification loss: 0.06972 | Regression loss: 0.15672 | Running loss: 0.25610\n",
      "Epoch: 15 | Iteration: 545 | Classification loss: 0.10948 | Regression loss: 0.17837 | Running loss: 0.25605\n",
      "Epoch: 15 | Iteration: 546 | Classification loss: 0.02317 | Regression loss: 0.14176 | Running loss: 0.25549\n",
      "Epoch: 15 | Iteration: 547 | Classification loss: 0.02705 | Regression loss: 0.11957 | Running loss: 0.25502\n",
      "Epoch: 15 | Iteration: 548 | Classification loss: 0.01093 | Regression loss: 0.10279 | Running loss: 0.25485\n",
      "Epoch: 15 | Iteration: 549 | Classification loss: 0.03091 | Regression loss: 0.09262 | Running loss: 0.25464\n",
      "Epoch: 15 | Iteration: 550 | Classification loss: 0.06836 | Regression loss: 0.21187 | Running loss: 0.25484\n",
      "Epoch: 15 | Iteration: 551 | Classification loss: 0.03341 | Regression loss: 0.17092 | Running loss: 0.25440\n",
      "Epoch: 15 | Iteration: 552 | Classification loss: 0.09314 | Regression loss: 0.42939 | Running loss: 0.25436\n",
      "Epoch: 15 | Iteration: 553 | Classification loss: 0.02135 | Regression loss: 0.17194 | Running loss: 0.25414\n",
      "Epoch: 15 | Iteration: 554 | Classification loss: 0.05760 | Regression loss: 0.17453 | Running loss: 0.25398\n",
      "Epoch: 15 | Iteration: 555 | Classification loss: 0.03509 | Regression loss: 0.12198 | Running loss: 0.25401\n",
      "Epoch: 15 | Iteration: 556 | Classification loss: 0.03993 | Regression loss: 0.13019 | Running loss: 0.25400\n",
      "Epoch: 15 | Iteration: 557 | Classification loss: 0.02369 | Regression loss: 0.18777 | Running loss: 0.25357\n",
      "Epoch: 15 | Iteration: 558 | Classification loss: 0.07219 | Regression loss: 0.21677 | Running loss: 0.25355\n",
      "Epoch: 15 | Iteration: 559 | Classification loss: 0.03474 | Regression loss: 0.24240 | Running loss: 0.25383\n",
      "Epoch: 15 | Iteration: 560 | Classification loss: 0.01335 | Regression loss: 0.08721 | Running loss: 0.25299\n",
      "Epoch: 15 | Iteration: 561 | Classification loss: 0.01646 | Regression loss: 0.10835 | Running loss: 0.25286\n",
      "Epoch: 15 | Iteration: 562 | Classification loss: 0.05532 | Regression loss: 0.22090 | Running loss: 0.25282\n",
      "Epoch: 15 | Iteration: 563 | Classification loss: 0.01025 | Regression loss: 0.07092 | Running loss: 0.25251\n",
      "Epoch: 15 | Iteration: 564 | Classification loss: 0.01858 | Regression loss: 0.11601 | Running loss: 0.25238\n",
      "Epoch: 15 | Iteration: 565 | Classification loss: 0.03515 | Regression loss: 0.10897 | Running loss: 0.25204\n",
      "Epoch: 15 | Iteration: 566 | Classification loss: 0.01518 | Regression loss: 0.12463 | Running loss: 0.25188\n",
      "Epoch: 15 | Iteration: 567 | Classification loss: 0.04813 | Regression loss: 0.23557 | Running loss: 0.25202\n",
      "Epoch: 15 | Iteration: 568 | Classification loss: 0.14130 | Regression loss: 0.52442 | Running loss: 0.25273\n",
      "Epoch: 15 | Iteration: 569 | Classification loss: 0.02132 | Regression loss: 0.17891 | Running loss: 0.25285\n",
      "Epoch: 15 | Iteration: 570 | Classification loss: 0.06870 | Regression loss: 0.23290 | Running loss: 0.25303\n",
      "Epoch: 15 | Iteration: 571 | Classification loss: 0.04769 | Regression loss: 0.13694 | Running loss: 0.25261\n",
      "Epoch: 15 | Iteration: 572 | Classification loss: 0.08411 | Regression loss: 0.24466 | Running loss: 0.25289\n",
      "Epoch: 15 | Iteration: 573 | Classification loss: 0.05481 | Regression loss: 0.24455 | Running loss: 0.25289\n",
      "Epoch: 15 | Iteration: 574 | Classification loss: 0.10392 | Regression loss: 0.23000 | Running loss: 0.25324\n",
      "Epoch: 15 | Iteration: 575 | Classification loss: 0.04215 | Regression loss: 0.22173 | Running loss: 0.25307\n",
      "Epoch: 15 | Iteration: 576 | Classification loss: 0.05723 | Regression loss: 0.22697 | Running loss: 0.25312\n",
      "Epoch: 15 | Iteration: 577 | Classification loss: 0.00663 | Regression loss: 0.12426 | Running loss: 0.25262\n",
      "Epoch: 15 | Iteration: 578 | Classification loss: 0.01157 | Regression loss: 0.10042 | Running loss: 0.25216\n",
      "Epoch: 15 | Iteration: 579 | Classification loss: 0.03294 | Regression loss: 0.34362 | Running loss: 0.25256\n",
      "Epoch: 15 | Iteration: 580 | Classification loss: 0.01415 | Regression loss: 0.18497 | Running loss: 0.25257\n",
      "Epoch: 15 | Iteration: 581 | Classification loss: 0.06075 | Regression loss: 0.37342 | Running loss: 0.25296\n",
      "Epoch: 15 | Iteration: 582 | Classification loss: 0.04422 | Regression loss: 0.26252 | Running loss: 0.25331\n",
      "Epoch: 15 | Iteration: 583 | Classification loss: 0.02395 | Regression loss: 0.18357 | Running loss: 0.25305\n",
      "Epoch: 15 | Iteration: 584 | Classification loss: 0.02902 | Regression loss: 0.23651 | Running loss: 0.25307\n",
      "Epoch: 15 | Iteration: 585 | Classification loss: 0.07025 | Regression loss: 0.14355 | Running loss: 0.25288\n",
      "Epoch: 15 | Iteration: 586 | Classification loss: 0.04529 | Regression loss: 0.08837 | Running loss: 0.25277\n",
      "Epoch: 15 | Iteration: 587 | Classification loss: 0.04568 | Regression loss: 0.34990 | Running loss: 0.25318\n",
      "Epoch: 15 | Iteration: 588 | Classification loss: 0.16688 | Regression loss: 0.42823 | Running loss: 0.25380\n",
      "Epoch: 15 | Iteration: 589 | Classification loss: 0.09535 | Regression loss: 0.14648 | Running loss: 0.25349\n",
      "Epoch: 15 | Iteration: 590 | Classification loss: 0.03198 | Regression loss: 0.13276 | Running loss: 0.25327\n",
      "Epoch: 15 | Iteration: 591 | Classification loss: 0.15727 | Regression loss: 0.16229 | Running loss: 0.25296\n",
      "Epoch: 15 | Iteration: 592 | Classification loss: 0.03805 | Regression loss: 0.14459 | Running loss: 0.25241\n",
      "Epoch: 15 | Iteration: 593 | Classification loss: 0.07977 | Regression loss: 0.21813 | Running loss: 0.25272\n",
      "Epoch: 15 | Iteration: 594 | Classification loss: 0.01643 | Regression loss: 0.09790 | Running loss: 0.25157\n",
      "Epoch: 15 | Iteration: 595 | Classification loss: 0.02574 | Regression loss: 0.21992 | Running loss: 0.25143\n",
      "Epoch: 15 | Iteration: 596 | Classification loss: 0.10913 | Regression loss: 0.05791 | Running loss: 0.25158\n",
      "Epoch: 15 | Iteration: 597 | Classification loss: 0.03656 | Regression loss: 0.13245 | Running loss: 0.25161\n",
      "Epoch: 15 | Iteration: 598 | Classification loss: 0.03074 | Regression loss: 0.24756 | Running loss: 0.25157\n",
      "Epoch: 15 | Iteration: 599 | Classification loss: 0.04148 | Regression loss: 0.15568 | Running loss: 0.25154\n",
      "Epoch: 15 | Iteration: 600 | Classification loss: 0.04869 | Regression loss: 0.09790 | Running loss: 0.25107\n",
      "Epoch: 15 | Iteration: 601 | Classification loss: 0.13265 | Regression loss: 0.22638 | Running loss: 0.25108\n",
      "Epoch: 15 | Iteration: 602 | Classification loss: 0.01750 | Regression loss: 0.21265 | Running loss: 0.25108\n",
      "Epoch: 15 | Iteration: 603 | Classification loss: 0.02733 | Regression loss: 0.15214 | Running loss: 0.25105\n",
      "Epoch: 15 | Iteration: 604 | Classification loss: 0.06345 | Regression loss: 0.25773 | Running loss: 0.25097\n",
      "Epoch: 15 | Iteration: 605 | Classification loss: 0.00596 | Regression loss: 0.08771 | Running loss: 0.25071\n",
      "Epoch: 15 | Iteration: 606 | Classification loss: 0.01961 | Regression loss: 0.14342 | Running loss: 0.25033\n",
      "Epoch: 15 | Iteration: 607 | Classification loss: 0.03112 | Regression loss: 0.09437 | Running loss: 0.24937\n",
      "Epoch: 15 | Iteration: 608 | Classification loss: 0.02753 | Regression loss: 0.11655 | Running loss: 0.24931\n",
      "Epoch: 15 | Iteration: 609 | Classification loss: 0.05298 | Regression loss: 0.17919 | Running loss: 0.24920\n",
      "Epoch: 15 | Iteration: 610 | Classification loss: 0.29322 | Regression loss: 0.19749 | Running loss: 0.24975\n",
      "Epoch: 15 | Iteration: 611 | Classification loss: 0.02787 | Regression loss: 0.09118 | Running loss: 0.24924\n",
      "Epoch: 15 | Iteration: 612 | Classification loss: 0.16331 | Regression loss: 0.26416 | Running loss: 0.24976\n",
      "Epoch: 15 | Iteration: 613 | Classification loss: 0.04578 | Regression loss: 0.12540 | Running loss: 0.24978\n",
      "Epoch: 15 | Iteration: 614 | Classification loss: 0.03228 | Regression loss: 0.12278 | Running loss: 0.24964\n",
      "Epoch: 15 | Iteration: 615 | Classification loss: 0.04938 | Regression loss: 0.27313 | Running loss: 0.24977\n",
      "Epoch: 15 | Iteration: 616 | Classification loss: 0.26561 | Regression loss: 0.17246 | Running loss: 0.24953\n",
      "Epoch: 15 | Iteration: 617 | Classification loss: 0.01460 | Regression loss: 0.07273 | Running loss: 0.24883\n",
      "Epoch: 15 | Iteration: 618 | Classification loss: 0.02259 | Regression loss: 0.14023 | Running loss: 0.24877\n",
      "Epoch: 15 | Iteration: 619 | Classification loss: 0.07700 | Regression loss: 0.27300 | Running loss: 0.24889\n",
      "Epoch: 15 | Iteration: 620 | Classification loss: 0.05406 | Regression loss: 0.17519 | Running loss: 0.24903\n",
      "Epoch: 15 | Iteration: 621 | Classification loss: 0.01406 | Regression loss: 0.15320 | Running loss: 0.24889\n",
      "Epoch: 15 | Iteration: 622 | Classification loss: 0.07179 | Regression loss: 0.21100 | Running loss: 0.24908\n",
      "Epoch: 15 | Iteration: 623 | Classification loss: 0.19185 | Regression loss: 0.41138 | Running loss: 0.24965\n",
      "Epoch: 15 | Iteration: 624 | Classification loss: 0.18495 | Regression loss: 0.07468 | Running loss: 0.24966\n",
      "Epoch: 15 | Iteration: 625 | Classification loss: 0.04233 | Regression loss: 0.11959 | Running loss: 0.24948\n",
      "Epoch: 15 | Iteration: 626 | Classification loss: 0.00900 | Regression loss: 0.07213 | Running loss: 0.24895\n",
      "Epoch: 15 | Iteration: 627 | Classification loss: 0.09294 | Regression loss: 0.21835 | Running loss: 0.24837\n",
      "Epoch: 15 | Iteration: 628 | Classification loss: 0.11121 | Regression loss: 0.18502 | Running loss: 0.24875\n",
      "Epoch: 15 | Iteration: 629 | Classification loss: 0.14890 | Regression loss: 0.14484 | Running loss: 0.24873\n",
      "Epoch: 15 | Iteration: 630 | Classification loss: 0.06299 | Regression loss: 0.33028 | Running loss: 0.24893\n",
      "Epoch: 15 | Iteration: 631 | Classification loss: 0.04578 | Regression loss: 0.13068 | Running loss: 0.24843\n",
      "Epoch: 15 | Iteration: 632 | Classification loss: 0.04067 | Regression loss: 0.27311 | Running loss: 0.24874\n",
      "Epoch: 15 | Iteration: 633 | Classification loss: 0.01062 | Regression loss: 0.10061 | Running loss: 0.24833\n",
      "Epoch: 15 | Iteration: 634 | Classification loss: 0.02292 | Regression loss: 0.21059 | Running loss: 0.24818\n",
      "Epoch: 15 | Iteration: 635 | Classification loss: 0.03823 | Regression loss: 0.09246 | Running loss: 0.24803\n",
      "Epoch: 15 | Iteration: 636 | Classification loss: 0.01874 | Regression loss: 0.12228 | Running loss: 0.24814\n",
      "Epoch: 15 | Iteration: 637 | Classification loss: 0.07430 | Regression loss: 0.29102 | Running loss: 0.24850\n",
      "Epoch: 15 | Iteration: 638 | Classification loss: 0.08129 | Regression loss: 0.29051 | Running loss: 0.24860\n",
      "Epoch: 15 | Iteration: 639 | Classification loss: 0.07776 | Regression loss: 0.09794 | Running loss: 0.24858\n",
      "Epoch: 15 | Iteration: 640 | Classification loss: 0.01700 | Regression loss: 0.12108 | Running loss: 0.24858\n",
      "Epoch: 15 | Iteration: 641 | Classification loss: 0.14043 | Regression loss: 0.38549 | Running loss: 0.24892\n",
      "Epoch: 15 | Iteration: 642 | Classification loss: 0.02926 | Regression loss: 0.12469 | Running loss: 0.24855\n",
      "Epoch: 15 | Iteration: 643 | Classification loss: 0.01920 | Regression loss: 0.28323 | Running loss: 0.24889\n",
      "Epoch: 15 | Iteration: 644 | Classification loss: 0.02977 | Regression loss: 0.12394 | Running loss: 0.24878\n",
      "Epoch: 15 | Iteration: 645 | Classification loss: 0.02228 | Regression loss: 0.17140 | Running loss: 0.24884\n",
      "Epoch: 15 | Iteration: 646 | Classification loss: 0.05454 | Regression loss: 0.13085 | Running loss: 0.24829\n",
      "Epoch: 15 | Iteration: 647 | Classification loss: 0.15343 | Regression loss: 0.27645 | Running loss: 0.24868\n",
      "Epoch: 15 | Iteration: 648 | Classification loss: 0.12614 | Regression loss: 0.41311 | Running loss: 0.24926\n",
      "Epoch: 15 | Iteration: 649 | Classification loss: 0.08473 | Regression loss: 0.16537 | Running loss: 0.24947\n",
      "Epoch: 15 | Iteration: 650 | Classification loss: 0.06705 | Regression loss: 0.25292 | Running loss: 0.24978\n",
      "Epoch: 15 | Iteration: 651 | Classification loss: 0.15094 | Regression loss: 0.28153 | Running loss: 0.25018\n",
      "Epoch: 15 | Iteration: 652 | Classification loss: 0.12616 | Regression loss: 0.37276 | Running loss: 0.25028\n",
      "Epoch: 15 | Iteration: 653 | Classification loss: 0.25943 | Regression loss: 0.29142 | Running loss: 0.25083\n",
      "Epoch: 15 | Iteration: 654 | Classification loss: 0.03837 | Regression loss: 0.27790 | Running loss: 0.25086\n",
      "Epoch: 15 | Iteration: 655 | Classification loss: 0.03073 | Regression loss: 0.15246 | Running loss: 0.25088\n",
      "Epoch: 15 | Iteration: 656 | Classification loss: 0.04427 | Regression loss: 0.26302 | Running loss: 0.25114\n",
      "Epoch: 15 | Iteration: 657 | Classification loss: 0.12895 | Regression loss: 0.30591 | Running loss: 0.25147\n",
      "Epoch: 15 | Iteration: 658 | Classification loss: 0.09419 | Regression loss: 0.47691 | Running loss: 0.25207\n",
      "Epoch: 15 | Iteration: 659 | Classification loss: 0.19735 | Regression loss: 0.34072 | Running loss: 0.25273\n",
      "Epoch: 15 | Iteration: 660 | Classification loss: 0.02722 | Regression loss: 0.19585 | Running loss: 0.25261\n",
      "Epoch: 15 | Iteration: 661 | Classification loss: 0.01443 | Regression loss: 0.14725 | Running loss: 0.25228\n",
      "Epoch: 15 | Iteration: 662 | Classification loss: 0.07178 | Regression loss: 0.28224 | Running loss: 0.25182\n",
      "Epoch: 15 | Iteration: 663 | Classification loss: 0.04047 | Regression loss: 0.13129 | Running loss: 0.25112\n",
      "Epoch: 15 | Iteration: 664 | Classification loss: 0.04673 | Regression loss: 0.29575 | Running loss: 0.25110\n",
      "Epoch: 15 | Iteration: 665 | Classification loss: 0.02529 | Regression loss: 0.17972 | Running loss: 0.25088\n",
      "Epoch: 15 | Iteration: 666 | Classification loss: 0.05630 | Regression loss: 0.14229 | Running loss: 0.25082\n",
      "Epoch: 15 | Iteration: 667 | Classification loss: 0.05768 | Regression loss: 0.21439 | Running loss: 0.25104\n",
      "Epoch: 15 | Iteration: 668 | Classification loss: 0.06081 | Regression loss: 0.19535 | Running loss: 0.25104\n",
      "Epoch: 15 | Iteration: 669 | Classification loss: 0.04601 | Regression loss: 0.12870 | Running loss: 0.25080\n",
      "Epoch: 15 | Iteration: 670 | Classification loss: 0.04845 | Regression loss: 0.14873 | Running loss: 0.25010\n",
      "Epoch: 15 | Iteration: 671 | Classification loss: 0.06090 | Regression loss: 0.22198 | Running loss: 0.25020\n",
      "Epoch: 15 | Iteration: 672 | Classification loss: 0.05588 | Regression loss: 0.19475 | Running loss: 0.24968\n",
      "Epoch: 15 | Iteration: 673 | Classification loss: 0.03706 | Regression loss: 0.18677 | Running loss: 0.24964\n",
      "Epoch: 15 | Iteration: 674 | Classification loss: 0.01550 | Regression loss: 0.16458 | Running loss: 0.24981\n",
      "Epoch: 15 | Iteration: 675 | Classification loss: 0.05505 | Regression loss: 0.20997 | Running loss: 0.24996\n",
      "Epoch: 15 | Iteration: 676 | Classification loss: 0.08101 | Regression loss: 0.21366 | Running loss: 0.25033\n",
      "Epoch: 15 | Iteration: 677 | Classification loss: 0.01671 | Regression loss: 0.13115 | Running loss: 0.25000\n",
      "Epoch: 15 | Iteration: 678 | Classification loss: 0.08776 | Regression loss: 0.19467 | Running loss: 0.25017\n",
      "Epoch: 15 | Iteration: 679 | Classification loss: 0.02636 | Regression loss: 0.20070 | Running loss: 0.25027\n",
      "Epoch: 15 | Iteration: 680 | Classification loss: 0.02461 | Regression loss: 0.15183 | Running loss: 0.25021\n",
      "Epoch: 15 | Iteration: 681 | Classification loss: 0.05524 | Regression loss: 0.19882 | Running loss: 0.25031\n",
      "Epoch: 15 | Iteration: 682 | Classification loss: 0.14353 | Regression loss: 0.36906 | Running loss: 0.25089\n",
      "Epoch: 15 | Iteration: 683 | Classification loss: 0.08428 | Regression loss: 0.24472 | Running loss: 0.25121\n",
      "Epoch: 15 | Iteration: 684 | Classification loss: 0.02649 | Regression loss: 0.20440 | Running loss: 0.25139\n",
      "Epoch: 15 | Iteration: 685 | Classification loss: 0.02955 | Regression loss: 0.11656 | Running loss: 0.25087\n",
      "Epoch: 15 | Iteration: 686 | Classification loss: 0.07429 | Regression loss: 0.45141 | Running loss: 0.25193\n",
      "Epoch: 15 | Iteration: 687 | Classification loss: 0.01750 | Regression loss: 0.10099 | Running loss: 0.25166\n",
      "Epoch: 15 | Iteration: 688 | Classification loss: 0.02326 | Regression loss: 0.13423 | Running loss: 0.25143\n",
      "Epoch: 15 | Iteration: 689 | Classification loss: 0.12608 | Regression loss: 0.24446 | Running loss: 0.25191\n",
      "Epoch: 15 | Iteration: 690 | Classification loss: 0.02050 | Regression loss: 0.15095 | Running loss: 0.25202\n",
      "Epoch: 15 | Iteration: 691 | Classification loss: 0.02673 | Regression loss: 0.13509 | Running loss: 0.25196\n",
      "Epoch: 15 | Iteration: 692 | Classification loss: 0.05509 | Regression loss: 0.11247 | Running loss: 0.25163\n",
      "Epoch: 15 | Iteration: 693 | Classification loss: 0.03590 | Regression loss: 0.25191 | Running loss: 0.25165\n",
      "Epoch: 15 | Iteration: 694 | Classification loss: 0.01823 | Regression loss: 0.19478 | Running loss: 0.25159\n",
      "Epoch: 15 | Iteration: 695 | Classification loss: 0.03324 | Regression loss: 0.15805 | Running loss: 0.25142\n",
      "Epoch: 15 | Iteration: 696 | Classification loss: 0.06957 | Regression loss: 0.26890 | Running loss: 0.25181\n",
      "Epoch: 15 | Iteration: 697 | Classification loss: 0.02988 | Regression loss: 0.17306 | Running loss: 0.25155\n",
      "Epoch: 15 | Iteration: 698 | Classification loss: 0.03536 | Regression loss: 0.11315 | Running loss: 0.25143\n",
      "Epoch: 15 | Iteration: 699 | Classification loss: 0.17471 | Regression loss: 0.32446 | Running loss: 0.25185\n",
      "Epoch: 15 | Iteration: 700 | Classification loss: 0.05876 | Regression loss: 0.23980 | Running loss: 0.25207\n",
      "Epoch: 15 | Iteration: 701 | Classification loss: 0.08810 | Regression loss: 0.08746 | Running loss: 0.25220\n",
      "Epoch: 15 | Iteration: 702 | Classification loss: 0.03871 | Regression loss: 0.22985 | Running loss: 0.25230\n",
      "Epoch: 15 | Iteration: 703 | Classification loss: 0.04473 | Regression loss: 0.20434 | Running loss: 0.25218\n",
      "Epoch: 15 | Iteration: 704 | Classification loss: 0.02155 | Regression loss: 0.09532 | Running loss: 0.25175\n",
      "Epoch: 15 | Iteration: 705 | Classification loss: 0.03522 | Regression loss: 0.12613 | Running loss: 0.25178\n",
      "Epoch: 15 | Iteration: 706 | Classification loss: 0.17572 | Regression loss: 0.18657 | Running loss: 0.25192\n",
      "Epoch: 15 | Iteration: 707 | Classification loss: 0.07976 | Regression loss: 0.14709 | Running loss: 0.25183\n",
      "Epoch: 15 | Iteration: 708 | Classification loss: 0.06749 | Regression loss: 0.27070 | Running loss: 0.25222\n",
      "Epoch: 15 | Iteration: 709 | Classification loss: 0.02136 | Regression loss: 0.14143 | Running loss: 0.25227\n",
      "Epoch: 15 | Iteration: 710 | Classification loss: 0.07033 | Regression loss: 0.22550 | Running loss: 0.25226\n",
      "Epoch: 15 | Iteration: 711 | Classification loss: 0.05588 | Regression loss: 0.20104 | Running loss: 0.25215\n",
      "Epoch: 15 | Iteration: 712 | Classification loss: 0.03830 | Regression loss: 0.13483 | Running loss: 0.25232\n",
      "Epoch: 15 | Iteration: 713 | Classification loss: 0.01390 | Regression loss: 0.08218 | Running loss: 0.25162\n",
      "Epoch: 15 | Iteration: 714 | Classification loss: 0.04850 | Regression loss: 0.20621 | Running loss: 0.25188\n",
      "Epoch: 15 | Iteration: 715 | Classification loss: 0.02105 | Regression loss: 0.14181 | Running loss: 0.25183\n",
      "Epoch: 15 | Iteration: 716 | Classification loss: 0.01012 | Regression loss: 0.10304 | Running loss: 0.25130\n",
      "Epoch: 15 | Iteration: 717 | Classification loss: 0.05590 | Regression loss: 0.24519 | Running loss: 0.25121\n",
      "Epoch: 15 | Iteration: 718 | Classification loss: 0.02833 | Regression loss: 0.22036 | Running loss: 0.25117\n",
      "Epoch: 15 | Iteration: 719 | Classification loss: 0.14638 | Regression loss: 0.37015 | Running loss: 0.25159\n",
      "Epoch: 15 | Iteration: 720 | Classification loss: 0.02433 | Regression loss: 0.23968 | Running loss: 0.25125\n",
      "Epoch: 15 | Iteration: 721 | Classification loss: 0.05178 | Regression loss: 0.22698 | Running loss: 0.25123\n",
      "Epoch: 15 | Iteration: 722 | Classification loss: 0.03057 | Regression loss: 0.11431 | Running loss: 0.25092\n",
      "Epoch: 15 | Iteration: 723 | Classification loss: 0.02548 | Regression loss: 0.17301 | Running loss: 0.25052\n",
      "Epoch: 15 | Iteration: 724 | Classification loss: 0.31480 | Regression loss: 0.44824 | Running loss: 0.25149\n",
      "Epoch: 15 | Iteration: 725 | Classification loss: 0.04787 | Regression loss: 0.21121 | Running loss: 0.25052\n",
      "Epoch: 15 | Iteration: 726 | Classification loss: 0.04025 | Regression loss: 0.18736 | Running loss: 0.25021\n",
      "Epoch: 15 | Iteration: 727 | Classification loss: 0.01479 | Regression loss: 0.13628 | Running loss: 0.24961\n",
      "Epoch: 15 | Iteration: 728 | Classification loss: 0.06297 | Regression loss: 0.18684 | Running loss: 0.24957\n",
      "Epoch: 15 | Iteration: 729 | Classification loss: 0.02902 | Regression loss: 0.11713 | Running loss: 0.24964\n",
      "Epoch: 15 | Iteration: 730 | Classification loss: 0.01702 | Regression loss: 0.13925 | Running loss: 0.24941\n",
      "Epoch: 15 | Iteration: 731 | Classification loss: 0.09947 | Regression loss: 0.26026 | Running loss: 0.24960\n",
      "Epoch: 15 | Iteration: 732 | Classification loss: 0.08822 | Regression loss: 0.17650 | Running loss: 0.24973\n",
      "Epoch: 15 | Iteration: 733 | Classification loss: 0.03069 | Regression loss: 0.26392 | Running loss: 0.24997\n",
      "Epoch: 15 | Iteration: 734 | Classification loss: 0.03712 | Regression loss: 0.19066 | Running loss: 0.25001\n",
      "Epoch: 15 | Iteration: 735 | Classification loss: 0.04064 | Regression loss: 0.25366 | Running loss: 0.25021\n",
      "Epoch: 15 | Iteration: 736 | Classification loss: 0.05952 | Regression loss: 0.17629 | Running loss: 0.25030\n",
      "Epoch: 15 | Iteration: 737 | Classification loss: 0.02190 | Regression loss: 0.12950 | Running loss: 0.25028\n",
      "Epoch: 15 | Iteration: 738 | Classification loss: 0.04400 | Regression loss: 0.28571 | Running loss: 0.25054\n",
      "Epoch: 15 | Iteration: 739 | Classification loss: 0.15025 | Regression loss: 0.38868 | Running loss: 0.25090\n",
      "Epoch: 15 | Iteration: 740 | Classification loss: 0.01198 | Regression loss: 0.08804 | Running loss: 0.25050\n",
      "Epoch: 15 | Iteration: 741 | Classification loss: 0.09662 | Regression loss: 0.34537 | Running loss: 0.25075\n",
      "Epoch: 15 | Iteration: 742 | Classification loss: 0.07628 | Regression loss: 0.25688 | Running loss: 0.25061\n",
      "Epoch: 15 | Iteration: 743 | Classification loss: 0.01933 | Regression loss: 0.12332 | Running loss: 0.25057\n",
      "Epoch: 15 | Iteration: 744 | Classification loss: 0.05464 | Regression loss: 0.21756 | Running loss: 0.25034\n",
      "Epoch: 15 | Iteration: 745 | Classification loss: 0.02599 | Regression loss: 0.17039 | Running loss: 0.25037\n",
      "Epoch: 15 | Iteration: 746 | Classification loss: 0.04225 | Regression loss: 0.18601 | Running loss: 0.25043\n",
      "Epoch: 15 | Iteration: 747 | Classification loss: 0.06173 | Regression loss: 0.11088 | Running loss: 0.25021\n",
      "Epoch: 15 | Iteration: 748 | Classification loss: 0.11762 | Regression loss: 0.21407 | Running loss: 0.25000\n",
      "Epoch: 15 | Iteration: 749 | Classification loss: 0.03833 | Regression loss: 0.19385 | Running loss: 0.25006\n",
      "Epoch: 15 | Iteration: 750 | Classification loss: 0.16675 | Regression loss: 0.40700 | Running loss: 0.25092\n",
      "Epoch: 15 | Iteration: 751 | Classification loss: 0.03424 | Regression loss: 0.19828 | Running loss: 0.25098\n",
      "Epoch: 15 | Iteration: 752 | Classification loss: 0.03020 | Regression loss: 0.16398 | Running loss: 0.25083\n",
      "Epoch: 15 | Iteration: 753 | Classification loss: 0.05213 | Regression loss: 0.22426 | Running loss: 0.25087\n",
      "Epoch: 15 | Iteration: 754 | Classification loss: 0.04912 | Regression loss: 0.18826 | Running loss: 0.25102\n",
      "Epoch: 15 | Iteration: 755 | Classification loss: 0.02926 | Regression loss: 0.30462 | Running loss: 0.25148\n",
      "Epoch: 15 | Iteration: 756 | Classification loss: 0.01613 | Regression loss: 0.04554 | Running loss: 0.25086\n",
      "Epoch: 15 | Iteration: 757 | Classification loss: 0.07984 | Regression loss: 0.19420 | Running loss: 0.25106\n",
      "Epoch: 15 | Iteration: 758 | Classification loss: 0.11429 | Regression loss: 0.11532 | Running loss: 0.25133\n",
      "Epoch: 15 | Iteration: 759 | Classification loss: 0.04056 | Regression loss: 0.10543 | Running loss: 0.25038\n",
      "Epoch: 15 | Iteration: 760 | Classification loss: 0.01667 | Regression loss: 0.16588 | Running loss: 0.24994\n",
      "Epoch: 15 | Iteration: 761 | Classification loss: 0.02547 | Regression loss: 0.15416 | Running loss: 0.24993\n",
      "Epoch: 15 | Iteration: 762 | Classification loss: 0.03387 | Regression loss: 0.24400 | Running loss: 0.25029\n",
      "Epoch: 15 | Iteration: 763 | Classification loss: 0.03237 | Regression loss: 0.18610 | Running loss: 0.25042\n",
      "Epoch: 15 | Iteration: 764 | Classification loss: 0.04008 | Regression loss: 0.23346 | Running loss: 0.25041\n",
      "Epoch: 15 | Iteration: 765 | Classification loss: 0.02921 | Regression loss: 0.16253 | Running loss: 0.25055\n",
      "Epoch: 15 | Iteration: 766 | Classification loss: 0.05569 | Regression loss: 0.37530 | Running loss: 0.25085\n",
      "Epoch: 15 | Iteration: 767 | Classification loss: 0.06236 | Regression loss: 0.16296 | Running loss: 0.25036\n",
      "Epoch: 15 | Iteration: 768 | Classification loss: 0.07254 | Regression loss: 0.13459 | Running loss: 0.25014\n",
      "Epoch: 15 | Iteration: 769 | Classification loss: 0.01820 | Regression loss: 0.10776 | Running loss: 0.25025\n",
      "Epoch: 15 | Iteration: 770 | Classification loss: 0.03245 | Regression loss: 0.17160 | Running loss: 0.25038\n",
      "Epoch: 15 | Iteration: 771 | Classification loss: 0.13609 | Regression loss: 0.23957 | Running loss: 0.25063\n",
      "Epoch: 15 | Iteration: 772 | Classification loss: 0.02089 | Regression loss: 0.18528 | Running loss: 0.25034\n",
      "Epoch: 15 | Iteration: 773 | Classification loss: 0.01960 | Regression loss: 0.16290 | Running loss: 0.25045\n",
      "Epoch: 15 | Iteration: 774 | Classification loss: 0.21208 | Regression loss: 0.18640 | Running loss: 0.25070\n",
      "Epoch: 15 | Iteration: 775 | Classification loss: 0.10853 | Regression loss: 0.35308 | Running loss: 0.25126\n",
      "Epoch: 15 | Iteration: 776 | Classification loss: 0.06439 | Regression loss: 0.18607 | Running loss: 0.25143\n",
      "Epoch: 15 | Iteration: 777 | Classification loss: 0.06790 | Regression loss: 0.10725 | Running loss: 0.25157\n",
      "Epoch: 15 | Iteration: 778 | Classification loss: 0.01336 | Regression loss: 0.17790 | Running loss: 0.25151\n",
      "Epoch: 15 | Iteration: 779 | Classification loss: 0.03378 | Regression loss: 0.16238 | Running loss: 0.25156\n",
      "Epoch: 15 | Iteration: 780 | Classification loss: 0.09258 | Regression loss: 0.40827 | Running loss: 0.25238\n",
      "Epoch: 15 | Iteration: 781 | Classification loss: 0.04155 | Regression loss: 0.10451 | Running loss: 0.25221\n",
      "Epoch: 15 | Iteration: 782 | Classification loss: 0.02718 | Regression loss: 0.16353 | Running loss: 0.25195\n",
      "Epoch: 15 | Iteration: 783 | Classification loss: 0.04844 | Regression loss: 0.11946 | Running loss: 0.25191\n",
      "Epoch: 15 | Iteration: 784 | Classification loss: 0.71417 | Regression loss: 0.22881 | Running loss: 0.25346\n",
      "Epoch: 15 | Iteration: 785 | Classification loss: 0.27237 | Regression loss: 0.26310 | Running loss: 0.25414\n",
      "Epoch: 15 | Iteration: 786 | Classification loss: 0.25206 | Regression loss: 0.14157 | Running loss: 0.25432\n",
      "Epoch: 15 | Iteration: 787 | Classification loss: 0.04024 | Regression loss: 0.25275 | Running loss: 0.25416\n",
      "Epoch: 15 | Iteration: 788 | Classification loss: 0.02920 | Regression loss: 0.22996 | Running loss: 0.25361\n",
      "Epoch: 15 | Iteration: 789 | Classification loss: 0.02697 | Regression loss: 0.16298 | Running loss: 0.25346\n",
      "Epoch: 15 | Iteration: 790 | Classification loss: 0.04605 | Regression loss: 0.21795 | Running loss: 0.25363\n",
      "Epoch: 15 | Iteration: 791 | Classification loss: 0.02251 | Regression loss: 0.13185 | Running loss: 0.25320\n",
      "Epoch: 15 | Iteration: 792 | Classification loss: 0.02233 | Regression loss: 0.19820 | Running loss: 0.25305\n",
      "Epoch: 15 | Iteration: 793 | Classification loss: 0.22281 | Regression loss: 0.22556 | Running loss: 0.25364\n",
      "Epoch: 15 | Iteration: 794 | Classification loss: 0.04489 | Regression loss: 0.19908 | Running loss: 0.25292\n",
      "Epoch: 15 | Iteration: 795 | Classification loss: 0.08930 | Regression loss: 0.22059 | Running loss: 0.25282\n",
      "Epoch: 15 | Iteration: 796 | Classification loss: 0.15057 | Regression loss: 0.20160 | Running loss: 0.25325\n",
      "Epoch: 15 | Iteration: 797 | Classification loss: 0.08717 | Regression loss: 0.20093 | Running loss: 0.25342\n",
      "Epoch: 15 | Iteration: 798 | Classification loss: 0.02538 | Regression loss: 0.20019 | Running loss: 0.25297\n",
      "Epoch: 15 | Iteration: 799 | Classification loss: 0.05627 | Regression loss: 0.28031 | Running loss: 0.25307\n",
      "Epoch: 15 | Iteration: 800 | Classification loss: 0.13215 | Regression loss: 0.39174 | Running loss: 0.25327\n",
      "Epoch: 15 | Iteration: 801 | Classification loss: 0.02282 | Regression loss: 0.12431 | Running loss: 0.25324\n",
      "Epoch: 15 | Iteration: 802 | Classification loss: 0.06128 | Regression loss: 0.19073 | Running loss: 0.25328\n",
      "Epoch: 15 | Iteration: 803 | Classification loss: 0.03592 | Regression loss: 0.17255 | Running loss: 0.25315\n",
      "Epoch: 15 | Iteration: 804 | Classification loss: 0.02247 | Regression loss: 0.22198 | Running loss: 0.25126\n",
      "Epoch: 15 | Iteration: 805 | Classification loss: 0.02087 | Regression loss: 0.23828 | Running loss: 0.25131\n",
      "Epoch: 15 | Iteration: 806 | Classification loss: 0.88960 | Regression loss: 0.27571 | Running loss: 0.25329\n",
      "Epoch: 15 | Iteration: 807 | Classification loss: 0.08766 | Regression loss: 0.07325 | Running loss: 0.25290\n",
      "Epoch: 15 | Iteration: 808 | Classification loss: 0.13210 | Regression loss: 0.22373 | Running loss: 0.25297\n",
      "Epoch: 15 | Iteration: 809 | Classification loss: 0.03067 | Regression loss: 0.19873 | Running loss: 0.25258\n",
      "Epoch: 15 | Iteration: 810 | Classification loss: 0.04203 | Regression loss: 0.14096 | Running loss: 0.25195\n",
      "Epoch: 15 | Iteration: 811 | Classification loss: 0.05083 | Regression loss: 0.14933 | Running loss: 0.25204\n",
      "Epoch: 15 | Iteration: 812 | Classification loss: 0.04320 | Regression loss: 0.14984 | Running loss: 0.25208\n",
      "Epoch: 15 | Iteration: 813 | Classification loss: 0.03992 | Regression loss: 0.15392 | Running loss: 0.25209\n",
      "Epoch: 15 | Iteration: 814 | Classification loss: 0.11958 | Regression loss: 0.26905 | Running loss: 0.25241\n",
      "Epoch: 15 | Iteration: 815 | Classification loss: 0.08547 | Regression loss: 0.21754 | Running loss: 0.25252\n",
      "Epoch: 15 | Iteration: 816 | Classification loss: 0.13629 | Regression loss: 0.23295 | Running loss: 0.25284\n",
      "Epoch: 15 | Iteration: 817 | Classification loss: 0.11432 | Regression loss: 0.28509 | Running loss: 0.25309\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.39s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.599\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 16 | Iteration: 0 | Classification loss: 0.01100 | Regression loss: 0.10940 | Running loss: 0.25297\n",
      "Epoch: 16 | Iteration: 1 | Classification loss: 0.03647 | Regression loss: 0.23560 | Running loss: 0.25328\n",
      "Epoch: 16 | Iteration: 2 | Classification loss: 0.00849 | Regression loss: 0.07300 | Running loss: 0.25295\n",
      "Epoch: 16 | Iteration: 3 | Classification loss: 0.02346 | Regression loss: 0.12383 | Running loss: 0.25281\n",
      "Epoch: 16 | Iteration: 4 | Classification loss: 0.05326 | Regression loss: 0.25951 | Running loss: 0.25285\n",
      "Epoch: 16 | Iteration: 5 | Classification loss: 0.08071 | Regression loss: 0.20892 | Running loss: 0.25309\n",
      "Epoch: 16 | Iteration: 6 | Classification loss: 0.03583 | Regression loss: 0.24632 | Running loss: 0.25290\n",
      "Epoch: 16 | Iteration: 7 | Classification loss: 0.27584 | Regression loss: 0.26873 | Running loss: 0.25374\n",
      "Epoch: 16 | Iteration: 8 | Classification loss: 0.03920 | Regression loss: 0.23842 | Running loss: 0.25364\n",
      "Epoch: 16 | Iteration: 9 | Classification loss: 0.09707 | Regression loss: 0.20884 | Running loss: 0.25425\n",
      "Epoch: 16 | Iteration: 10 | Classification loss: 0.02242 | Regression loss: 0.20809 | Running loss: 0.25377\n",
      "Epoch: 16 | Iteration: 11 | Classification loss: 0.08077 | Regression loss: 0.41787 | Running loss: 0.25455\n",
      "Epoch: 16 | Iteration: 12 | Classification loss: 0.04811 | Regression loss: 0.23549 | Running loss: 0.25496\n",
      "Epoch: 16 | Iteration: 13 | Classification loss: 0.06875 | Regression loss: 0.24951 | Running loss: 0.25528\n",
      "Epoch: 16 | Iteration: 14 | Classification loss: 0.01537 | Regression loss: 0.12463 | Running loss: 0.25532\n",
      "Epoch: 16 | Iteration: 15 | Classification loss: 0.03005 | Regression loss: 0.11757 | Running loss: 0.25522\n",
      "Epoch: 16 | Iteration: 16 | Classification loss: 0.02577 | Regression loss: 0.22770 | Running loss: 0.25534\n",
      "Epoch: 16 | Iteration: 17 | Classification loss: 0.08479 | Regression loss: 0.24814 | Running loss: 0.25525\n",
      "Epoch: 16 | Iteration: 18 | Classification loss: 0.01858 | Regression loss: 0.13805 | Running loss: 0.25478\n",
      "Epoch: 16 | Iteration: 19 | Classification loss: 0.02423 | Regression loss: 0.14429 | Running loss: 0.25432\n",
      "Epoch: 16 | Iteration: 20 | Classification loss: 0.05001 | Regression loss: 0.27545 | Running loss: 0.25459\n",
      "Epoch: 16 | Iteration: 21 | Classification loss: 0.03415 | Regression loss: 0.23645 | Running loss: 0.25479\n",
      "Epoch: 16 | Iteration: 22 | Classification loss: 0.06259 | Regression loss: 0.18476 | Running loss: 0.25462\n",
      "Epoch: 16 | Iteration: 23 | Classification loss: 0.04023 | Regression loss: 0.20946 | Running loss: 0.25484\n",
      "Epoch: 16 | Iteration: 24 | Classification loss: 0.07813 | Regression loss: 0.18999 | Running loss: 0.25484\n",
      "Epoch: 16 | Iteration: 25 | Classification loss: 0.02555 | Regression loss: 0.17013 | Running loss: 0.25462\n",
      "Epoch: 16 | Iteration: 26 | Classification loss: 0.01293 | Regression loss: 0.15007 | Running loss: 0.25466\n",
      "Epoch: 16 | Iteration: 27 | Classification loss: 0.05994 | Regression loss: 0.11479 | Running loss: 0.25461\n",
      "Epoch: 16 | Iteration: 28 | Classification loss: 0.03726 | Regression loss: 0.22209 | Running loss: 0.25470\n",
      "Epoch: 16 | Iteration: 29 | Classification loss: 0.19163 | Regression loss: 0.41631 | Running loss: 0.25525\n",
      "Epoch: 16 | Iteration: 30 | Classification loss: 0.18830 | Regression loss: 0.36033 | Running loss: 0.25578\n",
      "Epoch: 16 | Iteration: 31 | Classification loss: 0.06629 | Regression loss: 0.26603 | Running loss: 0.25614\n",
      "Epoch: 16 | Iteration: 32 | Classification loss: 0.01815 | Regression loss: 0.10166 | Running loss: 0.25609\n",
      "Epoch: 16 | Iteration: 33 | Classification loss: 0.02915 | Regression loss: 0.15078 | Running loss: 0.25616\n",
      "Epoch: 16 | Iteration: 34 | Classification loss: 0.03820 | Regression loss: 0.19919 | Running loss: 0.25611\n",
      "Epoch: 16 | Iteration: 35 | Classification loss: 0.02825 | Regression loss: 0.14191 | Running loss: 0.25623\n",
      "Epoch: 16 | Iteration: 36 | Classification loss: 0.04931 | Regression loss: 0.17957 | Running loss: 0.25641\n",
      "Epoch: 16 | Iteration: 37 | Classification loss: 0.01514 | Regression loss: 0.11918 | Running loss: 0.25617\n",
      "Epoch: 16 | Iteration: 38 | Classification loss: 0.00627 | Regression loss: 0.04385 | Running loss: 0.25587\n",
      "Epoch: 16 | Iteration: 39 | Classification loss: 0.09863 | Regression loss: 0.39971 | Running loss: 0.25668\n",
      "Epoch: 16 | Iteration: 40 | Classification loss: 0.02051 | Regression loss: 0.05806 | Running loss: 0.25669\n",
      "Epoch: 16 | Iteration: 41 | Classification loss: 0.05995 | Regression loss: 0.17417 | Running loss: 0.25680\n",
      "Epoch: 16 | Iteration: 42 | Classification loss: 0.02390 | Regression loss: 0.09294 | Running loss: 0.25630\n",
      "Epoch: 16 | Iteration: 43 | Classification loss: 0.02482 | Regression loss: 0.18051 | Running loss: 0.25589\n",
      "Epoch: 16 | Iteration: 44 | Classification loss: 0.02903 | Regression loss: 0.16938 | Running loss: 0.25602\n",
      "Epoch: 16 | Iteration: 45 | Classification loss: 0.31002 | Regression loss: 0.49591 | Running loss: 0.25660\n",
      "Epoch: 16 | Iteration: 46 | Classification loss: 0.01969 | Regression loss: 0.10845 | Running loss: 0.25649\n",
      "Epoch: 16 | Iteration: 47 | Classification loss: 0.23200 | Regression loss: 0.29008 | Running loss: 0.25726\n",
      "Epoch: 16 | Iteration: 48 | Classification loss: 0.09956 | Regression loss: 0.28883 | Running loss: 0.25684\n",
      "Epoch: 16 | Iteration: 49 | Classification loss: 0.02094 | Regression loss: 0.09272 | Running loss: 0.25657\n",
      "Epoch: 16 | Iteration: 50 | Classification loss: 0.13371 | Regression loss: 0.35077 | Running loss: 0.25703\n",
      "Epoch: 16 | Iteration: 51 | Classification loss: 0.03222 | Regression loss: 0.20300 | Running loss: 0.25661\n",
      "Epoch: 16 | Iteration: 52 | Classification loss: 0.02207 | Regression loss: 0.18124 | Running loss: 0.25655\n",
      "Epoch: 16 | Iteration: 53 | Classification loss: 0.06548 | Regression loss: 0.23219 | Running loss: 0.25679\n",
      "Epoch: 16 | Iteration: 54 | Classification loss: 0.03267 | Regression loss: 0.10570 | Running loss: 0.25561\n",
      "Epoch: 16 | Iteration: 55 | Classification loss: 0.01202 | Regression loss: 0.05674 | Running loss: 0.25508\n",
      "Epoch: 16 | Iteration: 56 | Classification loss: 0.03003 | Regression loss: 0.18162 | Running loss: 0.25499\n",
      "Epoch: 16 | Iteration: 57 | Classification loss: 0.03188 | Regression loss: 0.22578 | Running loss: 0.25521\n",
      "Epoch: 16 | Iteration: 58 | Classification loss: 0.17529 | Regression loss: 0.33679 | Running loss: 0.25564\n",
      "Epoch: 16 | Iteration: 59 | Classification loss: 0.05295 | Regression loss: 0.20653 | Running loss: 0.25587\n",
      "Epoch: 16 | Iteration: 60 | Classification loss: 0.01889 | Regression loss: 0.15157 | Running loss: 0.25588\n",
      "Epoch: 16 | Iteration: 61 | Classification loss: 0.03131 | Regression loss: 0.25001 | Running loss: 0.25608\n",
      "Epoch: 16 | Iteration: 62 | Classification loss: 0.06953 | Regression loss: 0.29646 | Running loss: 0.25649\n",
      "Epoch: 16 | Iteration: 63 | Classification loss: 0.03071 | Regression loss: 0.20607 | Running loss: 0.25602\n",
      "Epoch: 16 | Iteration: 64 | Classification loss: 0.11972 | Regression loss: 0.50574 | Running loss: 0.25674\n",
      "Epoch: 16 | Iteration: 65 | Classification loss: 0.02154 | Regression loss: 0.12006 | Running loss: 0.25647\n",
      "Epoch: 16 | Iteration: 66 | Classification loss: 0.06398 | Regression loss: 0.21291 | Running loss: 0.25632\n",
      "Epoch: 16 | Iteration: 67 | Classification loss: 0.05327 | Regression loss: 0.14068 | Running loss: 0.25649\n",
      "Epoch: 16 | Iteration: 68 | Classification loss: 0.01255 | Regression loss: 0.12488 | Running loss: 0.25649\n",
      "Epoch: 16 | Iteration: 69 | Classification loss: 0.01174 | Regression loss: 0.11382 | Running loss: 0.25648\n",
      "Epoch: 16 | Iteration: 70 | Classification loss: 0.07568 | Regression loss: 0.35658 | Running loss: 0.25685\n",
      "Epoch: 16 | Iteration: 71 | Classification loss: 0.01483 | Regression loss: 0.09475 | Running loss: 0.25657\n",
      "Epoch: 16 | Iteration: 72 | Classification loss: 0.05837 | Regression loss: 0.30120 | Running loss: 0.25707\n",
      "Epoch: 16 | Iteration: 73 | Classification loss: 0.01067 | Regression loss: 0.13153 | Running loss: 0.25699\n",
      "Epoch: 16 | Iteration: 74 | Classification loss: 0.03988 | Regression loss: 0.15569 | Running loss: 0.25714\n",
      "Epoch: 16 | Iteration: 75 | Classification loss: 0.03444 | Regression loss: 0.20556 | Running loss: 0.25731\n",
      "Epoch: 16 | Iteration: 76 | Classification loss: 0.09022 | Regression loss: 0.24709 | Running loss: 0.25762\n",
      "Epoch: 16 | Iteration: 77 | Classification loss: 0.02622 | Regression loss: 0.12165 | Running loss: 0.25770\n",
      "Epoch: 16 | Iteration: 78 | Classification loss: 0.07983 | Regression loss: 0.29388 | Running loss: 0.25817\n",
      "Epoch: 16 | Iteration: 79 | Classification loss: 0.01388 | Regression loss: 0.11827 | Running loss: 0.25789\n",
      "Epoch: 16 | Iteration: 80 | Classification loss: 0.02178 | Regression loss: 0.15872 | Running loss: 0.25769\n",
      "Epoch: 16 | Iteration: 81 | Classification loss: 0.05576 | Regression loss: 0.26152 | Running loss: 0.25814\n",
      "Epoch: 16 | Iteration: 82 | Classification loss: 0.03095 | Regression loss: 0.17258 | Running loss: 0.25784\n",
      "Epoch: 16 | Iteration: 83 | Classification loss: 0.02101 | Regression loss: 0.08359 | Running loss: 0.25772\n",
      "Epoch: 16 | Iteration: 84 | Classification loss: 0.02550 | Regression loss: 0.18442 | Running loss: 0.25730\n",
      "Epoch: 16 | Iteration: 85 | Classification loss: 0.15132 | Regression loss: 0.22815 | Running loss: 0.25762\n",
      "Epoch: 16 | Iteration: 86 | Classification loss: 0.02191 | Regression loss: 0.13914 | Running loss: 0.25757\n",
      "Epoch: 16 | Iteration: 87 | Classification loss: 0.03120 | Regression loss: 0.13990 | Running loss: 0.25747\n",
      "Epoch: 16 | Iteration: 88 | Classification loss: 0.09983 | Regression loss: 0.16237 | Running loss: 0.25748\n",
      "Epoch: 16 | Iteration: 89 | Classification loss: 0.05401 | Regression loss: 0.15792 | Running loss: 0.25763\n",
      "Epoch: 16 | Iteration: 90 | Classification loss: 0.04519 | Regression loss: 0.07803 | Running loss: 0.25743\n",
      "Epoch: 16 | Iteration: 91 | Classification loss: 0.12930 | Regression loss: 0.19918 | Running loss: 0.25778\n",
      "Epoch: 16 | Iteration: 92 | Classification loss: 0.01568 | Regression loss: 0.12719 | Running loss: 0.25768\n",
      "Epoch: 16 | Iteration: 93 | Classification loss: 0.09127 | Regression loss: 0.27357 | Running loss: 0.25799\n",
      "Epoch: 16 | Iteration: 94 | Classification loss: 0.15443 | Regression loss: 0.09146 | Running loss: 0.25822\n",
      "Epoch: 16 | Iteration: 95 | Classification loss: 0.02371 | Regression loss: 0.18081 | Running loss: 0.25792\n",
      "Epoch: 16 | Iteration: 96 | Classification loss: 0.02062 | Regression loss: 0.17058 | Running loss: 0.25705\n",
      "Epoch: 16 | Iteration: 97 | Classification loss: 0.01594 | Regression loss: 0.14707 | Running loss: 0.25683\n",
      "Epoch: 16 | Iteration: 98 | Classification loss: 0.12096 | Regression loss: 0.22739 | Running loss: 0.25706\n",
      "Epoch: 16 | Iteration: 99 | Classification loss: 0.01788 | Regression loss: 0.11285 | Running loss: 0.25696\n",
      "Epoch: 16 | Iteration: 100 | Classification loss: 0.15572 | Regression loss: 0.19667 | Running loss: 0.25720\n",
      "Epoch: 16 | Iteration: 101 | Classification loss: 0.02500 | Regression loss: 0.19395 | Running loss: 0.25717\n",
      "Epoch: 16 | Iteration: 102 | Classification loss: 0.02307 | Regression loss: 0.07639 | Running loss: 0.25649\n",
      "Epoch: 16 | Iteration: 103 | Classification loss: 0.00951 | Regression loss: 0.08075 | Running loss: 0.25618\n",
      "Epoch: 16 | Iteration: 104 | Classification loss: 0.08358 | Regression loss: 0.16068 | Running loss: 0.25628\n",
      "Epoch: 16 | Iteration: 105 | Classification loss: 0.00771 | Regression loss: 0.10437 | Running loss: 0.25609\n",
      "Epoch: 16 | Iteration: 106 | Classification loss: 0.02979 | Regression loss: 0.25590 | Running loss: 0.25628\n",
      "Epoch: 16 | Iteration: 107 | Classification loss: 0.04783 | Regression loss: 0.13312 | Running loss: 0.25632\n",
      "Epoch: 16 | Iteration: 108 | Classification loss: 0.02150 | Regression loss: 0.16750 | Running loss: 0.25639\n",
      "Epoch: 16 | Iteration: 109 | Classification loss: 0.02909 | Regression loss: 0.13095 | Running loss: 0.25647\n",
      "Epoch: 16 | Iteration: 110 | Classification loss: 0.05011 | Regression loss: 0.13826 | Running loss: 0.25651\n",
      "Epoch: 16 | Iteration: 111 | Classification loss: 0.05202 | Regression loss: 0.19750 | Running loss: 0.25664\n",
      "Epoch: 16 | Iteration: 112 | Classification loss: 0.14118 | Regression loss: 0.20498 | Running loss: 0.25708\n",
      "Epoch: 16 | Iteration: 113 | Classification loss: 0.02114 | Regression loss: 0.16971 | Running loss: 0.25698\n",
      "Epoch: 16 | Iteration: 114 | Classification loss: 0.12667 | Regression loss: 0.34086 | Running loss: 0.25720\n",
      "Epoch: 16 | Iteration: 115 | Classification loss: 0.01317 | Regression loss: 0.08304 | Running loss: 0.25717\n",
      "Epoch: 16 | Iteration: 116 | Classification loss: 0.03063 | Regression loss: 0.23845 | Running loss: 0.25740\n",
      "Epoch: 16 | Iteration: 117 | Classification loss: 0.01600 | Regression loss: 0.11760 | Running loss: 0.25736\n",
      "Epoch: 16 | Iteration: 118 | Classification loss: 0.03658 | Regression loss: 0.24230 | Running loss: 0.25758\n",
      "Epoch: 16 | Iteration: 119 | Classification loss: 0.08803 | Regression loss: 0.33196 | Running loss: 0.25804\n",
      "Epoch: 16 | Iteration: 120 | Classification loss: 0.36110 | Regression loss: 0.35434 | Running loss: 0.25923\n",
      "Epoch: 16 | Iteration: 121 | Classification loss: 0.06063 | Regression loss: 0.26360 | Running loss: 0.25915\n",
      "Epoch: 16 | Iteration: 122 | Classification loss: 0.08311 | Regression loss: 0.28915 | Running loss: 0.25891\n",
      "Epoch: 16 | Iteration: 123 | Classification loss: 0.06168 | Regression loss: 0.23312 | Running loss: 0.25915\n",
      "Epoch: 16 | Iteration: 124 | Classification loss: 0.09748 | Regression loss: 0.33365 | Running loss: 0.25947\n",
      "Epoch: 16 | Iteration: 125 | Classification loss: 0.04352 | Regression loss: 0.27510 | Running loss: 0.26002\n",
      "Epoch: 16 | Iteration: 126 | Classification loss: 0.08529 | Regression loss: 0.14228 | Running loss: 0.25991\n",
      "Epoch: 16 | Iteration: 127 | Classification loss: 0.01618 | Regression loss: 0.14663 | Running loss: 0.25969\n",
      "Epoch: 16 | Iteration: 128 | Classification loss: 0.02404 | Regression loss: 0.20633 | Running loss: 0.25966\n",
      "Epoch: 16 | Iteration: 129 | Classification loss: 0.10406 | Regression loss: 0.22202 | Running loss: 0.25986\n",
      "Epoch: 16 | Iteration: 130 | Classification loss: 0.04677 | Regression loss: 0.15169 | Running loss: 0.25972\n",
      "Epoch: 16 | Iteration: 131 | Classification loss: 0.02978 | Regression loss: 0.07371 | Running loss: 0.25954\n",
      "Epoch: 16 | Iteration: 132 | Classification loss: 0.07702 | Regression loss: 0.08762 | Running loss: 0.25950\n",
      "Epoch: 16 | Iteration: 133 | Classification loss: 0.01888 | Regression loss: 0.18326 | Running loss: 0.25965\n",
      "Epoch: 16 | Iteration: 134 | Classification loss: 0.08305 | Regression loss: 0.26446 | Running loss: 0.25982\n",
      "Epoch: 16 | Iteration: 135 | Classification loss: 0.02698 | Regression loss: 0.13585 | Running loss: 0.25947\n",
      "Epoch: 16 | Iteration: 136 | Classification loss: 0.10428 | Regression loss: 0.30465 | Running loss: 0.25988\n",
      "Epoch: 16 | Iteration: 137 | Classification loss: 0.01974 | Regression loss: 0.09733 | Running loss: 0.25978\n",
      "Epoch: 16 | Iteration: 138 | Classification loss: 0.03724 | Regression loss: 0.14215 | Running loss: 0.25975\n",
      "Epoch: 16 | Iteration: 139 | Classification loss: 0.07978 | Regression loss: 0.30236 | Running loss: 0.25971\n",
      "Epoch: 16 | Iteration: 140 | Classification loss: 0.02081 | Regression loss: 0.13079 | Running loss: 0.25883\n",
      "Epoch: 16 | Iteration: 141 | Classification loss: 0.09208 | Regression loss: 0.21526 | Running loss: 0.25890\n",
      "Epoch: 16 | Iteration: 142 | Classification loss: 0.02905 | Regression loss: 0.20950 | Running loss: 0.25889\n",
      "Epoch: 16 | Iteration: 143 | Classification loss: 0.03873 | Regression loss: 0.19333 | Running loss: 0.25896\n",
      "Epoch: 16 | Iteration: 144 | Classification loss: 0.02264 | Regression loss: 0.08886 | Running loss: 0.25867\n",
      "Epoch: 16 | Iteration: 145 | Classification loss: 0.07419 | Regression loss: 0.21739 | Running loss: 0.25873\n",
      "Epoch: 16 | Iteration: 146 | Classification loss: 0.03923 | Regression loss: 0.11463 | Running loss: 0.25860\n",
      "Epoch: 16 | Iteration: 147 | Classification loss: 0.03959 | Regression loss: 0.22834 | Running loss: 0.25880\n",
      "Epoch: 16 | Iteration: 148 | Classification loss: 0.03888 | Regression loss: 0.20311 | Running loss: 0.25876\n",
      "Epoch: 16 | Iteration: 149 | Classification loss: 0.01597 | Regression loss: 0.10451 | Running loss: 0.25882\n",
      "Epoch: 16 | Iteration: 150 | Classification loss: 0.04004 | Regression loss: 0.19835 | Running loss: 0.25903\n",
      "Epoch: 16 | Iteration: 151 | Classification loss: 0.02557 | Regression loss: 0.17435 | Running loss: 0.25912\n",
      "Epoch: 16 | Iteration: 152 | Classification loss: 0.03866 | Regression loss: 0.14281 | Running loss: 0.25900\n",
      "Epoch: 16 | Iteration: 153 | Classification loss: 0.02905 | Regression loss: 0.14720 | Running loss: 0.25911\n",
      "Epoch: 16 | Iteration: 154 | Classification loss: 0.21536 | Regression loss: 0.56586 | Running loss: 0.25998\n",
      "Epoch: 16 | Iteration: 155 | Classification loss: 0.06473 | Regression loss: 0.26781 | Running loss: 0.26024\n",
      "Epoch: 16 | Iteration: 156 | Classification loss: 0.03392 | Regression loss: 0.22080 | Running loss: 0.26049\n",
      "Epoch: 16 | Iteration: 157 | Classification loss: 0.02133 | Regression loss: 0.17163 | Running loss: 0.26025\n",
      "Epoch: 16 | Iteration: 158 | Classification loss: 0.02541 | Regression loss: 0.16053 | Running loss: 0.26041\n",
      "Epoch: 16 | Iteration: 159 | Classification loss: 0.02841 | Regression loss: 0.15632 | Running loss: 0.26050\n",
      "Epoch: 16 | Iteration: 160 | Classification loss: 0.03257 | Regression loss: 0.19783 | Running loss: 0.26030\n",
      "Epoch: 16 | Iteration: 161 | Classification loss: 0.00009 | Regression loss: 0.00000 | Running loss: 0.25969\n",
      "Epoch: 16 | Iteration: 162 | Classification loss: 0.10058 | Regression loss: 0.33381 | Running loss: 0.26017\n",
      "Epoch: 16 | Iteration: 163 | Classification loss: 0.15757 | Regression loss: 0.32599 | Running loss: 0.26033\n",
      "Epoch: 16 | Iteration: 164 | Classification loss: 0.06735 | Regression loss: 0.16776 | Running loss: 0.26039\n",
      "Epoch: 16 | Iteration: 165 | Classification loss: 0.06167 | Regression loss: 0.42074 | Running loss: 0.26102\n",
      "Epoch: 16 | Iteration: 166 | Classification loss: 0.03965 | Regression loss: 0.15242 | Running loss: 0.26059\n",
      "Epoch: 16 | Iteration: 167 | Classification loss: 0.06365 | Regression loss: 0.15556 | Running loss: 0.26064\n",
      "Epoch: 16 | Iteration: 168 | Classification loss: 0.06990 | Regression loss: 0.13289 | Running loss: 0.26013\n",
      "Epoch: 16 | Iteration: 169 | Classification loss: 0.14370 | Regression loss: 0.20544 | Running loss: 0.26057\n",
      "Epoch: 16 | Iteration: 170 | Classification loss: 0.05024 | Regression loss: 0.12894 | Running loss: 0.26054\n",
      "Epoch: 16 | Iteration: 171 | Classification loss: 0.02332 | Regression loss: 0.16428 | Running loss: 0.26029\n",
      "Epoch: 16 | Iteration: 172 | Classification loss: 0.07653 | Regression loss: 0.13851 | Running loss: 0.26022\n",
      "Epoch: 16 | Iteration: 173 | Classification loss: 0.06312 | Regression loss: 0.09295 | Running loss: 0.26021\n",
      "Epoch: 16 | Iteration: 174 | Classification loss: 0.00649 | Regression loss: 0.06135 | Running loss: 0.25979\n",
      "Epoch: 16 | Iteration: 175 | Classification loss: 0.05270 | Regression loss: 0.30424 | Running loss: 0.25984\n",
      "Epoch: 16 | Iteration: 176 | Classification loss: 0.07562 | Regression loss: 0.15247 | Running loss: 0.25988\n",
      "Epoch: 16 | Iteration: 177 | Classification loss: 0.09417 | Regression loss: 0.17574 | Running loss: 0.25998\n",
      "Epoch: 16 | Iteration: 178 | Classification loss: 0.05872 | Regression loss: 0.24694 | Running loss: 0.25995\n",
      "Epoch: 16 | Iteration: 179 | Classification loss: 0.04222 | Regression loss: 0.18511 | Running loss: 0.25989\n",
      "Epoch: 16 | Iteration: 180 | Classification loss: 0.02375 | Regression loss: 0.12439 | Running loss: 0.25985\n",
      "Epoch: 16 | Iteration: 181 | Classification loss: 0.01617 | Regression loss: 0.15582 | Running loss: 0.25963\n",
      "Epoch: 16 | Iteration: 182 | Classification loss: 0.09481 | Regression loss: 0.25050 | Running loss: 0.25973\n",
      "Epoch: 16 | Iteration: 183 | Classification loss: 0.31536 | Regression loss: 0.39646 | Running loss: 0.26047\n",
      "Epoch: 16 | Iteration: 184 | Classification loss: 0.04233 | Regression loss: 0.19075 | Running loss: 0.26072\n",
      "Epoch: 16 | Iteration: 185 | Classification loss: 0.01559 | Regression loss: 0.11369 | Running loss: 0.26015\n",
      "Epoch: 16 | Iteration: 186 | Classification loss: 0.02894 | Regression loss: 0.17639 | Running loss: 0.26015\n",
      "Epoch: 16 | Iteration: 187 | Classification loss: 0.01735 | Regression loss: 0.11029 | Running loss: 0.26002\n",
      "Epoch: 16 | Iteration: 188 | Classification loss: 0.07258 | Regression loss: 0.29552 | Running loss: 0.26043\n",
      "Epoch: 16 | Iteration: 189 | Classification loss: 0.05298 | Regression loss: 0.15351 | Running loss: 0.26041\n",
      "Epoch: 16 | Iteration: 190 | Classification loss: 0.10622 | Regression loss: 0.22137 | Running loss: 0.26054\n",
      "Epoch: 16 | Iteration: 191 | Classification loss: 0.04066 | Regression loss: 0.15154 | Running loss: 0.26063\n",
      "Epoch: 16 | Iteration: 192 | Classification loss: 0.20982 | Regression loss: 0.33499 | Running loss: 0.26134\n",
      "Epoch: 16 | Iteration: 193 | Classification loss: 0.12176 | Regression loss: 0.29214 | Running loss: 0.26067\n",
      "Epoch: 16 | Iteration: 194 | Classification loss: 0.05357 | Regression loss: 0.18796 | Running loss: 0.26086\n",
      "Epoch: 16 | Iteration: 195 | Classification loss: 0.06207 | Regression loss: 0.18245 | Running loss: 0.26079\n",
      "Epoch: 16 | Iteration: 196 | Classification loss: 0.03712 | Regression loss: 0.25668 | Running loss: 0.26085\n",
      "Epoch: 16 | Iteration: 197 | Classification loss: 0.18873 | Regression loss: 0.36317 | Running loss: 0.26139\n",
      "Epoch: 16 | Iteration: 198 | Classification loss: 0.28504 | Regression loss: 0.31500 | Running loss: 0.26156\n",
      "Epoch: 16 | Iteration: 199 | Classification loss: 0.14932 | Regression loss: 0.36499 | Running loss: 0.26201\n",
      "Epoch: 16 | Iteration: 200 | Classification loss: 0.12024 | Regression loss: 0.31958 | Running loss: 0.26236\n",
      "Epoch: 16 | Iteration: 201 | Classification loss: 0.12098 | Regression loss: 0.31813 | Running loss: 0.26304\n",
      "Epoch: 16 | Iteration: 202 | Classification loss: 0.11214 | Regression loss: 0.34803 | Running loss: 0.26346\n",
      "Epoch: 16 | Iteration: 203 | Classification loss: 0.02640 | Regression loss: 0.14131 | Running loss: 0.26344\n",
      "Epoch: 16 | Iteration: 204 | Classification loss: 0.04593 | Regression loss: 0.17188 | Running loss: 0.26327\n",
      "Epoch: 16 | Iteration: 205 | Classification loss: 0.04077 | Regression loss: 0.31799 | Running loss: 0.26365\n",
      "Epoch: 16 | Iteration: 206 | Classification loss: 0.17393 | Regression loss: 0.30809 | Running loss: 0.26372\n",
      "Epoch: 16 | Iteration: 207 | Classification loss: 0.01105 | Regression loss: 0.21351 | Running loss: 0.26378\n",
      "Epoch: 16 | Iteration: 208 | Classification loss: 0.02199 | Regression loss: 0.14426 | Running loss: 0.26374\n",
      "Epoch: 16 | Iteration: 209 | Classification loss: 0.03370 | Regression loss: 0.29255 | Running loss: 0.26404\n",
      "Epoch: 16 | Iteration: 210 | Classification loss: 0.23668 | Regression loss: 0.28433 | Running loss: 0.26460\n",
      "Epoch: 16 | Iteration: 211 | Classification loss: 0.05355 | Regression loss: 0.22043 | Running loss: 0.26474\n",
      "Epoch: 16 | Iteration: 212 | Classification loss: 0.01442 | Regression loss: 0.07622 | Running loss: 0.26475\n",
      "Epoch: 16 | Iteration: 213 | Classification loss: 0.00838 | Regression loss: 0.06120 | Running loss: 0.26428\n",
      "Epoch: 16 | Iteration: 214 | Classification loss: 0.22614 | Regression loss: 0.39790 | Running loss: 0.26489\n",
      "Epoch: 16 | Iteration: 215 | Classification loss: 0.07070 | Regression loss: 0.20079 | Running loss: 0.26505\n",
      "Epoch: 16 | Iteration: 216 | Classification loss: 0.03123 | Regression loss: 0.11826 | Running loss: 0.26497\n",
      "Epoch: 16 | Iteration: 217 | Classification loss: 0.04983 | Regression loss: 0.16500 | Running loss: 0.26511\n",
      "Epoch: 16 | Iteration: 218 | Classification loss: 0.00727 | Regression loss: 0.09225 | Running loss: 0.26489\n",
      "Epoch: 16 | Iteration: 219 | Classification loss: 0.01696 | Regression loss: 0.05533 | Running loss: 0.26426\n",
      "Epoch: 16 | Iteration: 220 | Classification loss: 0.02932 | Regression loss: 0.13689 | Running loss: 0.26389\n",
      "Epoch: 16 | Iteration: 221 | Classification loss: 0.08021 | Regression loss: 0.20840 | Running loss: 0.26416\n",
      "Epoch: 16 | Iteration: 222 | Classification loss: 0.03897 | Regression loss: 0.19233 | Running loss: 0.26365\n",
      "Epoch: 16 | Iteration: 223 | Classification loss: 0.12970 | Regression loss: 0.28701 | Running loss: 0.26408\n",
      "Epoch: 16 | Iteration: 224 | Classification loss: 0.06815 | Regression loss: 0.21322 | Running loss: 0.26410\n",
      "Epoch: 16 | Iteration: 225 | Classification loss: 0.01576 | Regression loss: 0.13787 | Running loss: 0.26404\n",
      "Epoch: 16 | Iteration: 226 | Classification loss: 0.13930 | Regression loss: 0.19622 | Running loss: 0.26426\n",
      "Epoch: 16 | Iteration: 227 | Classification loss: 0.02491 | Regression loss: 0.15072 | Running loss: 0.26404\n",
      "Epoch: 16 | Iteration: 228 | Classification loss: 0.19539 | Regression loss: 0.21450 | Running loss: 0.26453\n",
      "Epoch: 16 | Iteration: 229 | Classification loss: 0.06833 | Regression loss: 0.23267 | Running loss: 0.26484\n",
      "Epoch: 16 | Iteration: 230 | Classification loss: 0.03366 | Regression loss: 0.21253 | Running loss: 0.26510\n",
      "Epoch: 16 | Iteration: 231 | Classification loss: 0.01797 | Regression loss: 0.14344 | Running loss: 0.26518\n",
      "Epoch: 16 | Iteration: 232 | Classification loss: 0.06277 | Regression loss: 0.26317 | Running loss: 0.26527\n",
      "Epoch: 16 | Iteration: 233 | Classification loss: 0.05746 | Regression loss: 0.27705 | Running loss: 0.26553\n",
      "Epoch: 16 | Iteration: 234 | Classification loss: 0.06783 | Regression loss: 0.27963 | Running loss: 0.26518\n",
      "Epoch: 16 | Iteration: 235 | Classification loss: 0.08395 | Regression loss: 0.25152 | Running loss: 0.26546\n",
      "Epoch: 16 | Iteration: 236 | Classification loss: 0.05778 | Regression loss: 0.41802 | Running loss: 0.26595\n",
      "Epoch: 16 | Iteration: 237 | Classification loss: 0.01635 | Regression loss: 0.19782 | Running loss: 0.26606\n",
      "Epoch: 16 | Iteration: 238 | Classification loss: 0.05356 | Regression loss: 0.13504 | Running loss: 0.26610\n",
      "Epoch: 16 | Iteration: 239 | Classification loss: 0.01356 | Regression loss: 0.12319 | Running loss: 0.26595\n",
      "Epoch: 16 | Iteration: 240 | Classification loss: 0.07326 | Regression loss: 0.19281 | Running loss: 0.26591\n",
      "Epoch: 16 | Iteration: 241 | Classification loss: 0.03538 | Regression loss: 0.06448 | Running loss: 0.26555\n",
      "Epoch: 16 | Iteration: 242 | Classification loss: 0.03148 | Regression loss: 0.13483 | Running loss: 0.26568\n",
      "Epoch: 16 | Iteration: 243 | Classification loss: 0.06597 | Regression loss: 0.19722 | Running loss: 0.26596\n",
      "Epoch: 16 | Iteration: 244 | Classification loss: 0.06291 | Regression loss: 0.18764 | Running loss: 0.26591\n",
      "Epoch: 16 | Iteration: 245 | Classification loss: 0.07667 | Regression loss: 0.20502 | Running loss: 0.26631\n",
      "Epoch: 16 | Iteration: 246 | Classification loss: 0.04680 | Regression loss: 0.16169 | Running loss: 0.26646\n",
      "Epoch: 16 | Iteration: 247 | Classification loss: 0.12722 | Regression loss: 0.21661 | Running loss: 0.26686\n",
      "Epoch: 16 | Iteration: 248 | Classification loss: 0.03124 | Regression loss: 0.28304 | Running loss: 0.26721\n",
      "Epoch: 16 | Iteration: 249 | Classification loss: 0.05595 | Regression loss: 0.22837 | Running loss: 0.26721\n",
      "Epoch: 16 | Iteration: 250 | Classification loss: 0.08918 | Regression loss: 0.06562 | Running loss: 0.26618\n",
      "Epoch: 16 | Iteration: 251 | Classification loss: 0.24161 | Regression loss: 0.22105 | Running loss: 0.26671\n",
      "Epoch: 16 | Iteration: 252 | Classification loss: 0.03421 | Regression loss: 0.20159 | Running loss: 0.26658\n",
      "Epoch: 16 | Iteration: 253 | Classification loss: 0.09576 | Regression loss: 0.37539 | Running loss: 0.26715\n",
      "Epoch: 16 | Iteration: 254 | Classification loss: 0.04062 | Regression loss: 0.14893 | Running loss: 0.26687\n",
      "Epoch: 16 | Iteration: 255 | Classification loss: 0.02037 | Regression loss: 0.15820 | Running loss: 0.26663\n",
      "Epoch: 16 | Iteration: 256 | Classification loss: 0.07288 | Regression loss: 0.22398 | Running loss: 0.26656\n",
      "Epoch: 16 | Iteration: 257 | Classification loss: 0.04354 | Regression loss: 0.06891 | Running loss: 0.26625\n",
      "Epoch: 16 | Iteration: 258 | Classification loss: 0.12441 | Regression loss: 0.29463 | Running loss: 0.26652\n",
      "Epoch: 16 | Iteration: 259 | Classification loss: 0.18987 | Regression loss: 0.20228 | Running loss: 0.26705\n",
      "Epoch: 16 | Iteration: 260 | Classification loss: 0.03497 | Regression loss: 0.15192 | Running loss: 0.26720\n",
      "Epoch: 16 | Iteration: 261 | Classification loss: 0.10087 | Regression loss: 0.35583 | Running loss: 0.26736\n",
      "Epoch: 16 | Iteration: 262 | Classification loss: 0.04061 | Regression loss: 0.28574 | Running loss: 0.26761\n",
      "Epoch: 16 | Iteration: 263 | Classification loss: 0.09696 | Regression loss: 0.21294 | Running loss: 0.26736\n",
      "Epoch: 16 | Iteration: 264 | Classification loss: 0.02220 | Regression loss: 0.14560 | Running loss: 0.26708\n",
      "Epoch: 16 | Iteration: 265 | Classification loss: 0.03030 | Regression loss: 0.17745 | Running loss: 0.26708\n",
      "Epoch: 16 | Iteration: 266 | Classification loss: 0.06510 | Regression loss: 0.26526 | Running loss: 0.26721\n",
      "Epoch: 16 | Iteration: 267 | Classification loss: 0.03669 | Regression loss: 0.12959 | Running loss: 0.26712\n",
      "Epoch: 16 | Iteration: 268 | Classification loss: 0.01183 | Regression loss: 0.20010 | Running loss: 0.26728\n",
      "Epoch: 16 | Iteration: 269 | Classification loss: 0.03146 | Regression loss: 0.11113 | Running loss: 0.26677\n",
      "Epoch: 16 | Iteration: 270 | Classification loss: 0.16511 | Regression loss: 0.37217 | Running loss: 0.26665\n",
      "Epoch: 16 | Iteration: 271 | Classification loss: 0.03424 | Regression loss: 0.13912 | Running loss: 0.26652\n",
      "Epoch: 16 | Iteration: 272 | Classification loss: 0.14903 | Regression loss: 0.19139 | Running loss: 0.26687\n",
      "Epoch: 16 | Iteration: 273 | Classification loss: 0.03908 | Regression loss: 0.19146 | Running loss: 0.26669\n",
      "Epoch: 16 | Iteration: 274 | Classification loss: 0.04465 | Regression loss: 0.23084 | Running loss: 0.26688\n",
      "Epoch: 16 | Iteration: 275 | Classification loss: 0.05148 | Regression loss: 0.21994 | Running loss: 0.26682\n",
      "Epoch: 16 | Iteration: 276 | Classification loss: 0.04346 | Regression loss: 0.16856 | Running loss: 0.26702\n",
      "Epoch: 16 | Iteration: 277 | Classification loss: 0.03507 | Regression loss: 0.24159 | Running loss: 0.26708\n",
      "Epoch: 16 | Iteration: 278 | Classification loss: 0.03708 | Regression loss: 0.17344 | Running loss: 0.26717\n",
      "Epoch: 16 | Iteration: 279 | Classification loss: 0.16074 | Regression loss: 0.37941 | Running loss: 0.26791\n",
      "Epoch: 16 | Iteration: 280 | Classification loss: 0.02888 | Regression loss: 0.19644 | Running loss: 0.26780\n",
      "Epoch: 16 | Iteration: 281 | Classification loss: 0.03789 | Regression loss: 0.09912 | Running loss: 0.26768\n",
      "Epoch: 16 | Iteration: 282 | Classification loss: 0.03885 | Regression loss: 0.13485 | Running loss: 0.26774\n",
      "Epoch: 16 | Iteration: 283 | Classification loss: 0.12393 | Regression loss: 0.30009 | Running loss: 0.26787\n",
      "Epoch: 16 | Iteration: 284 | Classification loss: 0.02631 | Regression loss: 0.27331 | Running loss: 0.26801\n",
      "Epoch: 16 | Iteration: 285 | Classification loss: 0.08322 | Regression loss: 0.24479 | Running loss: 0.26830\n",
      "Epoch: 16 | Iteration: 286 | Classification loss: 0.03696 | Regression loss: 0.19745 | Running loss: 0.26813\n",
      "Epoch: 16 | Iteration: 287 | Classification loss: 0.04117 | Regression loss: 0.19132 | Running loss: 0.26841\n",
      "Epoch: 16 | Iteration: 288 | Classification loss: 0.04185 | Regression loss: 0.16605 | Running loss: 0.26850\n",
      "Epoch: 16 | Iteration: 289 | Classification loss: 0.12220 | Regression loss: 0.17795 | Running loss: 0.26885\n",
      "Epoch: 16 | Iteration: 290 | Classification loss: 0.03463 | Regression loss: 0.21133 | Running loss: 0.26905\n",
      "Epoch: 16 | Iteration: 291 | Classification loss: 0.06715 | Regression loss: 0.22412 | Running loss: 0.26917\n",
      "Epoch: 16 | Iteration: 292 | Classification loss: 0.06073 | Regression loss: 0.28975 | Running loss: 0.26889\n",
      "Epoch: 16 | Iteration: 293 | Classification loss: 0.03634 | Regression loss: 0.11180 | Running loss: 0.26895\n",
      "Epoch: 16 | Iteration: 294 | Classification loss: 0.04828 | Regression loss: 0.13925 | Running loss: 0.26847\n",
      "Epoch: 16 | Iteration: 295 | Classification loss: 0.17727 | Regression loss: 0.06605 | Running loss: 0.26861\n",
      "Epoch: 16 | Iteration: 296 | Classification loss: 0.02963 | Regression loss: 0.16342 | Running loss: 0.26869\n",
      "Epoch: 16 | Iteration: 297 | Classification loss: 0.01848 | Regression loss: 0.11913 | Running loss: 0.26832\n",
      "Epoch: 16 | Iteration: 298 | Classification loss: 0.11033 | Regression loss: 0.30365 | Running loss: 0.26827\n",
      "Epoch: 16 | Iteration: 299 | Classification loss: 0.05437 | Regression loss: 0.22053 | Running loss: 0.26864\n",
      "Epoch: 16 | Iteration: 300 | Classification loss: 0.04067 | Regression loss: 0.16567 | Running loss: 0.26873\n",
      "Epoch: 16 | Iteration: 301 | Classification loss: 0.05529 | Regression loss: 0.12981 | Running loss: 0.26840\n",
      "Epoch: 16 | Iteration: 302 | Classification loss: 0.02360 | Regression loss: 0.10322 | Running loss: 0.26820\n",
      "Epoch: 16 | Iteration: 303 | Classification loss: 0.08617 | Regression loss: 0.39966 | Running loss: 0.26883\n",
      "Epoch: 16 | Iteration: 304 | Classification loss: 0.13821 | Regression loss: 0.16267 | Running loss: 0.26887\n",
      "Epoch: 16 | Iteration: 305 | Classification loss: 0.04757 | Regression loss: 0.20613 | Running loss: 0.26817\n",
      "Epoch: 16 | Iteration: 306 | Classification loss: 0.04884 | Regression loss: 0.07220 | Running loss: 0.26789\n",
      "Epoch: 16 | Iteration: 307 | Classification loss: 0.01698 | Regression loss: 0.06349 | Running loss: 0.26773\n",
      "Epoch: 16 | Iteration: 308 | Classification loss: 0.02584 | Regression loss: 0.18179 | Running loss: 0.26798\n",
      "Epoch: 16 | Iteration: 309 | Classification loss: 0.05584 | Regression loss: 0.20547 | Running loss: 0.26788\n",
      "Epoch: 16 | Iteration: 310 | Classification loss: 0.15080 | Regression loss: 0.34863 | Running loss: 0.26829\n",
      "Epoch: 16 | Iteration: 311 | Classification loss: 0.03798 | Regression loss: 0.32778 | Running loss: 0.26843\n",
      "Epoch: 16 | Iteration: 312 | Classification loss: 0.03261 | Regression loss: 0.25360 | Running loss: 0.26822\n",
      "Epoch: 16 | Iteration: 313 | Classification loss: 0.09221 | Regression loss: 0.17931 | Running loss: 0.26841\n",
      "Epoch: 16 | Iteration: 314 | Classification loss: 0.13708 | Regression loss: 0.25643 | Running loss: 0.26857\n",
      "Epoch: 16 | Iteration: 315 | Classification loss: 0.06957 | Regression loss: 0.30840 | Running loss: 0.26910\n",
      "Epoch: 16 | Iteration: 316 | Classification loss: 0.06208 | Regression loss: 0.03141 | Running loss: 0.26882\n",
      "Epoch: 16 | Iteration: 317 | Classification loss: 0.06225 | Regression loss: 0.32185 | Running loss: 0.26933\n",
      "Epoch: 16 | Iteration: 318 | Classification loss: 0.03157 | Regression loss: 0.13644 | Running loss: 0.26938\n",
      "Epoch: 16 | Iteration: 319 | Classification loss: 0.02596 | Regression loss: 0.12675 | Running loss: 0.26896\n",
      "Epoch: 16 | Iteration: 320 | Classification loss: 0.04980 | Regression loss: 0.07700 | Running loss: 0.26847\n",
      "Epoch: 16 | Iteration: 321 | Classification loss: 0.07382 | Regression loss: 0.17677 | Running loss: 0.26862\n",
      "Epoch: 16 | Iteration: 322 | Classification loss: 0.06806 | Regression loss: 0.19386 | Running loss: 0.26887\n",
      "Epoch: 16 | Iteration: 323 | Classification loss: 0.07319 | Regression loss: 0.12506 | Running loss: 0.26821\n",
      "Epoch: 16 | Iteration: 324 | Classification loss: 0.07780 | Regression loss: 0.28902 | Running loss: 0.26864\n",
      "Epoch: 16 | Iteration: 325 | Classification loss: 0.04453 | Regression loss: 0.13178 | Running loss: 0.26838\n",
      "Epoch: 16 | Iteration: 326 | Classification loss: 0.05484 | Regression loss: 0.12799 | Running loss: 0.26844\n",
      "Epoch: 16 | Iteration: 327 | Classification loss: 0.02718 | Regression loss: 0.16010 | Running loss: 0.26843\n",
      "Epoch: 16 | Iteration: 328 | Classification loss: 0.01948 | Regression loss: 0.12093 | Running loss: 0.26834\n",
      "Epoch: 16 | Iteration: 329 | Classification loss: 0.06915 | Regression loss: 0.31280 | Running loss: 0.26824\n",
      "Epoch: 16 | Iteration: 330 | Classification loss: 0.06455 | Regression loss: 0.27521 | Running loss: 0.26785\n",
      "Epoch: 16 | Iteration: 331 | Classification loss: 0.18460 | Regression loss: 0.35442 | Running loss: 0.26842\n",
      "Epoch: 16 | Iteration: 332 | Classification loss: 0.02844 | Regression loss: 0.12882 | Running loss: 0.26810\n",
      "Epoch: 16 | Iteration: 333 | Classification loss: 0.01889 | Regression loss: 0.12869 | Running loss: 0.26753\n",
      "Epoch: 16 | Iteration: 334 | Classification loss: 0.06048 | Regression loss: 0.09515 | Running loss: 0.26684\n",
      "Epoch: 16 | Iteration: 335 | Classification loss: 0.09449 | Regression loss: 0.35612 | Running loss: 0.26664\n",
      "Epoch: 16 | Iteration: 336 | Classification loss: 0.08197 | Regression loss: 0.11741 | Running loss: 0.26641\n",
      "Epoch: 16 | Iteration: 337 | Classification loss: 0.05284 | Regression loss: 0.30859 | Running loss: 0.26676\n",
      "Epoch: 16 | Iteration: 338 | Classification loss: 0.08651 | Regression loss: 0.31776 | Running loss: 0.26696\n",
      "Epoch: 16 | Iteration: 339 | Classification loss: 0.03755 | Regression loss: 0.20044 | Running loss: 0.26656\n",
      "Epoch: 16 | Iteration: 340 | Classification loss: 0.03424 | Regression loss: 0.12830 | Running loss: 0.26575\n",
      "Epoch: 16 | Iteration: 341 | Classification loss: 0.01986 | Regression loss: 0.11764 | Running loss: 0.26495\n",
      "Epoch: 16 | Iteration: 342 | Classification loss: 0.03755 | Regression loss: 0.21494 | Running loss: 0.26500\n",
      "Epoch: 16 | Iteration: 343 | Classification loss: 0.04221 | Regression loss: 0.11496 | Running loss: 0.26500\n",
      "Epoch: 16 | Iteration: 344 | Classification loss: 0.06596 | Regression loss: 0.20486 | Running loss: 0.26483\n",
      "Epoch: 16 | Iteration: 345 | Classification loss: 0.04752 | Regression loss: 0.30041 | Running loss: 0.26518\n",
      "Epoch: 16 | Iteration: 346 | Classification loss: 0.03560 | Regression loss: 0.13575 | Running loss: 0.26484\n",
      "Epoch: 16 | Iteration: 347 | Classification loss: 0.11942 | Regression loss: 0.22864 | Running loss: 0.26512\n",
      "Epoch: 16 | Iteration: 348 | Classification loss: 0.08638 | Regression loss: 0.17456 | Running loss: 0.26525\n",
      "Epoch: 16 | Iteration: 349 | Classification loss: 0.60464 | Regression loss: 0.49571 | Running loss: 0.26691\n",
      "Epoch: 16 | Iteration: 350 | Classification loss: 0.02664 | Regression loss: 0.15289 | Running loss: 0.26675\n",
      "Epoch: 16 | Iteration: 351 | Classification loss: 0.03405 | Regression loss: 0.26115 | Running loss: 0.26699\n",
      "Epoch: 16 | Iteration: 352 | Classification loss: 0.03897 | Regression loss: 0.14452 | Running loss: 0.26697\n",
      "Epoch: 16 | Iteration: 353 | Classification loss: 0.05139 | Regression loss: 0.18344 | Running loss: 0.26687\n",
      "Epoch: 16 | Iteration: 354 | Classification loss: 0.11014 | Regression loss: 0.18385 | Running loss: 0.26696\n",
      "Epoch: 16 | Iteration: 355 | Classification loss: 0.00587 | Regression loss: 0.03893 | Running loss: 0.26660\n",
      "Epoch: 16 | Iteration: 356 | Classification loss: 0.05413 | Regression loss: 0.10570 | Running loss: 0.26656\n",
      "Epoch: 16 | Iteration: 357 | Classification loss: 0.19035 | Regression loss: 0.27429 | Running loss: 0.26696\n",
      "Epoch: 16 | Iteration: 358 | Classification loss: 0.00697 | Regression loss: 0.07038 | Running loss: 0.26652\n",
      "Epoch: 16 | Iteration: 359 | Classification loss: 0.16811 | Regression loss: 0.33436 | Running loss: 0.26723\n",
      "Epoch: 16 | Iteration: 360 | Classification loss: 0.09593 | Regression loss: 0.26302 | Running loss: 0.26739\n",
      "Epoch: 16 | Iteration: 361 | Classification loss: 0.06759 | Regression loss: 0.19211 | Running loss: 0.26745\n",
      "Epoch: 16 | Iteration: 362 | Classification loss: 0.19966 | Regression loss: 0.35349 | Running loss: 0.26820\n",
      "Epoch: 16 | Iteration: 363 | Classification loss: 0.10617 | Regression loss: 0.14873 | Running loss: 0.26821\n",
      "Epoch: 16 | Iteration: 364 | Classification loss: 0.07349 | Regression loss: 0.26123 | Running loss: 0.26785\n",
      "Epoch: 16 | Iteration: 365 | Classification loss: 0.03803 | Regression loss: 0.11226 | Running loss: 0.26749\n",
      "Epoch: 16 | Iteration: 366 | Classification loss: 0.06001 | Regression loss: 0.24539 | Running loss: 0.26764\n",
      "Epoch: 16 | Iteration: 367 | Classification loss: 0.02284 | Regression loss: 0.11880 | Running loss: 0.26763\n",
      "Epoch: 16 | Iteration: 368 | Classification loss: 0.07853 | Regression loss: 0.27531 | Running loss: 0.26729\n",
      "Epoch: 16 | Iteration: 369 | Classification loss: 0.07752 | Regression loss: 0.14586 | Running loss: 0.26750\n",
      "Epoch: 16 | Iteration: 370 | Classification loss: 0.04265 | Regression loss: 0.20022 | Running loss: 0.26767\n",
      "Epoch: 16 | Iteration: 371 | Classification loss: 0.02614 | Regression loss: 0.11899 | Running loss: 0.26722\n",
      "Epoch: 16 | Iteration: 372 | Classification loss: 0.08534 | Regression loss: 0.25762 | Running loss: 0.26756\n",
      "Epoch: 16 | Iteration: 373 | Classification loss: 0.07830 | Regression loss: 0.25524 | Running loss: 0.26791\n",
      "Epoch: 16 | Iteration: 374 | Classification loss: 0.06011 | Regression loss: 0.08494 | Running loss: 0.26786\n",
      "Epoch: 16 | Iteration: 375 | Classification loss: 0.01570 | Regression loss: 0.14596 | Running loss: 0.26761\n",
      "Epoch: 16 | Iteration: 376 | Classification loss: 0.02131 | Regression loss: 0.13279 | Running loss: 0.26749\n",
      "Epoch: 16 | Iteration: 377 | Classification loss: 0.01947 | Regression loss: 0.12892 | Running loss: 0.26740\n",
      "Epoch: 16 | Iteration: 378 | Classification loss: 0.03309 | Regression loss: 0.15873 | Running loss: 0.26711\n",
      "Epoch: 16 | Iteration: 379 | Classification loss: 0.03057 | Regression loss: 0.13290 | Running loss: 0.26703\n",
      "Epoch: 16 | Iteration: 380 | Classification loss: 0.01810 | Regression loss: 0.09460 | Running loss: 0.26696\n",
      "Epoch: 16 | Iteration: 381 | Classification loss: 0.01425 | Regression loss: 0.09118 | Running loss: 0.26617\n",
      "Epoch: 16 | Iteration: 382 | Classification loss: 0.04254 | Regression loss: 0.23401 | Running loss: 0.26613\n",
      "Epoch: 16 | Iteration: 383 | Classification loss: 0.02198 | Regression loss: 0.13295 | Running loss: 0.26609\n",
      "Epoch: 16 | Iteration: 384 | Classification loss: 0.05077 | Regression loss: 0.17187 | Running loss: 0.26600\n",
      "Epoch: 16 | Iteration: 385 | Classification loss: 0.06279 | Regression loss: 0.27418 | Running loss: 0.26617\n",
      "Epoch: 16 | Iteration: 386 | Classification loss: 0.08358 | Regression loss: 0.22128 | Running loss: 0.26655\n",
      "Epoch: 16 | Iteration: 387 | Classification loss: 0.02302 | Regression loss: 0.14852 | Running loss: 0.26657\n",
      "Epoch: 16 | Iteration: 388 | Classification loss: 0.05852 | Regression loss: 0.31265 | Running loss: 0.26659\n",
      "Epoch: 16 | Iteration: 389 | Classification loss: 0.02211 | Regression loss: 0.15890 | Running loss: 0.26649\n",
      "Epoch: 16 | Iteration: 390 | Classification loss: 0.01634 | Regression loss: 0.16026 | Running loss: 0.26617\n",
      "Epoch: 16 | Iteration: 391 | Classification loss: 0.05521 | Regression loss: 0.25707 | Running loss: 0.26647\n",
      "Epoch: 16 | Iteration: 392 | Classification loss: 0.04964 | Regression loss: 0.11807 | Running loss: 0.26621\n",
      "Epoch: 16 | Iteration: 393 | Classification loss: 0.04606 | Regression loss: 0.25351 | Running loss: 0.26630\n",
      "Epoch: 16 | Iteration: 394 | Classification loss: 0.00740 | Regression loss: 0.08183 | Running loss: 0.26613\n",
      "Epoch: 16 | Iteration: 395 | Classification loss: 0.06835 | Regression loss: 0.28252 | Running loss: 0.26664\n",
      "Epoch: 16 | Iteration: 396 | Classification loss: 0.01846 | Regression loss: 0.12057 | Running loss: 0.26641\n",
      "Epoch: 16 | Iteration: 397 | Classification loss: 0.05625 | Regression loss: 0.20331 | Running loss: 0.26660\n",
      "Epoch: 16 | Iteration: 398 | Classification loss: 0.01622 | Regression loss: 0.05871 | Running loss: 0.26653\n",
      "Epoch: 16 | Iteration: 399 | Classification loss: 0.04276 | Regression loss: 0.22577 | Running loss: 0.26646\n",
      "Epoch: 16 | Iteration: 400 | Classification loss: 0.03081 | Regression loss: 0.23164 | Running loss: 0.26649\n",
      "Epoch: 16 | Iteration: 401 | Classification loss: 0.02767 | Regression loss: 0.23751 | Running loss: 0.26599\n",
      "Epoch: 16 | Iteration: 402 | Classification loss: 0.02684 | Regression loss: 0.09427 | Running loss: 0.26570\n",
      "Epoch: 16 | Iteration: 403 | Classification loss: 0.02521 | Regression loss: 0.12137 | Running loss: 0.26544\n",
      "Epoch: 16 | Iteration: 404 | Classification loss: 0.01918 | Regression loss: 0.18669 | Running loss: 0.26556\n",
      "Epoch: 16 | Iteration: 405 | Classification loss: 0.02938 | Regression loss: 0.13884 | Running loss: 0.26550\n",
      "Epoch: 16 | Iteration: 406 | Classification loss: 0.03217 | Regression loss: 0.29965 | Running loss: 0.26463\n",
      "Epoch: 16 | Iteration: 407 | Classification loss: 0.13627 | Regression loss: 0.36814 | Running loss: 0.26513\n",
      "Epoch: 16 | Iteration: 408 | Classification loss: 0.07532 | Regression loss: 0.16942 | Running loss: 0.26516\n",
      "Epoch: 16 | Iteration: 409 | Classification loss: 0.03374 | Regression loss: 0.21707 | Running loss: 0.26536\n",
      "Epoch: 16 | Iteration: 410 | Classification loss: 0.10871 | Regression loss: 0.21139 | Running loss: 0.26550\n",
      "Epoch: 16 | Iteration: 411 | Classification loss: 0.03213 | Regression loss: 0.27760 | Running loss: 0.26583\n",
      "Epoch: 16 | Iteration: 412 | Classification loss: 0.01687 | Regression loss: 0.18968 | Running loss: 0.26593\n",
      "Epoch: 16 | Iteration: 413 | Classification loss: 0.01150 | Regression loss: 0.10970 | Running loss: 0.26545\n",
      "Epoch: 16 | Iteration: 414 | Classification loss: 0.07024 | Regression loss: 0.13002 | Running loss: 0.26532\n",
      "Epoch: 16 | Iteration: 415 | Classification loss: 0.05647 | Regression loss: 0.23634 | Running loss: 0.26532\n",
      "Epoch: 16 | Iteration: 416 | Classification loss: 0.01538 | Regression loss: 0.14423 | Running loss: 0.26518\n",
      "Epoch: 16 | Iteration: 417 | Classification loss: 0.01559 | Regression loss: 0.11277 | Running loss: 0.26485\n",
      "Epoch: 16 | Iteration: 418 | Classification loss: 0.01205 | Regression loss: 0.10913 | Running loss: 0.26462\n",
      "Epoch: 16 | Iteration: 419 | Classification loss: 0.10697 | Regression loss: 0.38280 | Running loss: 0.26530\n",
      "Epoch: 16 | Iteration: 420 | Classification loss: 0.01313 | Regression loss: 0.13417 | Running loss: 0.26493\n",
      "Epoch: 16 | Iteration: 421 | Classification loss: 0.03437 | Regression loss: 0.14739 | Running loss: 0.26422\n",
      "Epoch: 16 | Iteration: 422 | Classification loss: 0.01193 | Regression loss: 0.10240 | Running loss: 0.26425\n",
      "Epoch: 16 | Iteration: 423 | Classification loss: 0.11158 | Regression loss: 0.31576 | Running loss: 0.26422\n",
      "Epoch: 16 | Iteration: 424 | Classification loss: 0.17995 | Regression loss: 0.27538 | Running loss: 0.26446\n",
      "Epoch: 16 | Iteration: 425 | Classification loss: 0.07418 | Regression loss: 0.16752 | Running loss: 0.26466\n",
      "Epoch: 16 | Iteration: 426 | Classification loss: 0.05844 | Regression loss: 0.23710 | Running loss: 0.26471\n",
      "Epoch: 16 | Iteration: 427 | Classification loss: 0.04802 | Regression loss: 0.22761 | Running loss: 0.26486\n",
      "Epoch: 16 | Iteration: 428 | Classification loss: 0.05666 | Regression loss: 0.31225 | Running loss: 0.26515\n",
      "Epoch: 16 | Iteration: 429 | Classification loss: 0.02915 | Regression loss: 0.16657 | Running loss: 0.26519\n",
      "Epoch: 16 | Iteration: 430 | Classification loss: 0.01312 | Regression loss: 0.15217 | Running loss: 0.26486\n",
      "Epoch: 16 | Iteration: 431 | Classification loss: 0.04865 | Regression loss: 0.10037 | Running loss: 0.26469\n",
      "Epoch: 16 | Iteration: 432 | Classification loss: 0.06124 | Regression loss: 0.30716 | Running loss: 0.26428\n",
      "Epoch: 16 | Iteration: 433 | Classification loss: 0.02084 | Regression loss: 0.13952 | Running loss: 0.26414\n",
      "Epoch: 16 | Iteration: 434 | Classification loss: 0.03991 | Regression loss: 0.13298 | Running loss: 0.26410\n",
      "Epoch: 16 | Iteration: 435 | Classification loss: 0.02101 | Regression loss: 0.14724 | Running loss: 0.26388\n",
      "Epoch: 16 | Iteration: 436 | Classification loss: 0.03846 | Regression loss: 0.16570 | Running loss: 0.26381\n",
      "Epoch: 16 | Iteration: 437 | Classification loss: 0.07674 | Regression loss: 0.32474 | Running loss: 0.26395\n",
      "Epoch: 16 | Iteration: 438 | Classification loss: 0.14764 | Regression loss: 0.22066 | Running loss: 0.26456\n",
      "Epoch: 16 | Iteration: 439 | Classification loss: 0.03843 | Regression loss: 0.18423 | Running loss: 0.26446\n",
      "Epoch: 16 | Iteration: 440 | Classification loss: 0.04379 | Regression loss: 0.17675 | Running loss: 0.26444\n",
      "Epoch: 16 | Iteration: 441 | Classification loss: 0.02270 | Regression loss: 0.18372 | Running loss: 0.26456\n",
      "Epoch: 16 | Iteration: 442 | Classification loss: 0.13701 | Regression loss: 0.09913 | Running loss: 0.26467\n",
      "Epoch: 16 | Iteration: 443 | Classification loss: 0.02425 | Regression loss: 0.15528 | Running loss: 0.26467\n",
      "Epoch: 16 | Iteration: 444 | Classification loss: 0.04162 | Regression loss: 0.11408 | Running loss: 0.26442\n",
      "Epoch: 16 | Iteration: 445 | Classification loss: 0.01636 | Regression loss: 0.17490 | Running loss: 0.26437\n",
      "Epoch: 16 | Iteration: 446 | Classification loss: 0.04330 | Regression loss: 0.11873 | Running loss: 0.26415\n",
      "Epoch: 16 | Iteration: 447 | Classification loss: 0.01806 | Regression loss: 0.12214 | Running loss: 0.26404\n",
      "Epoch: 16 | Iteration: 448 | Classification loss: 0.06464 | Regression loss: 0.15970 | Running loss: 0.26363\n",
      "Epoch: 16 | Iteration: 449 | Classification loss: 0.05256 | Regression loss: 0.11963 | Running loss: 0.26352\n",
      "Epoch: 16 | Iteration: 450 | Classification loss: 0.03668 | Regression loss: 0.12233 | Running loss: 0.26343\n",
      "Epoch: 16 | Iteration: 451 | Classification loss: 0.01900 | Regression loss: 0.15458 | Running loss: 0.26352\n",
      "Epoch: 16 | Iteration: 452 | Classification loss: 0.01031 | Regression loss: 0.16612 | Running loss: 0.26347\n",
      "Epoch: 16 | Iteration: 453 | Classification loss: 0.06074 | Regression loss: 0.19375 | Running loss: 0.26323\n",
      "Epoch: 16 | Iteration: 454 | Classification loss: 0.04709 | Regression loss: 0.16826 | Running loss: 0.26324\n",
      "Epoch: 16 | Iteration: 455 | Classification loss: 0.05457 | Regression loss: 0.27139 | Running loss: 0.26353\n",
      "Epoch: 16 | Iteration: 456 | Classification loss: 0.11202 | Regression loss: 0.40331 | Running loss: 0.26376\n",
      "Epoch: 16 | Iteration: 457 | Classification loss: 0.00791 | Regression loss: 0.09862 | Running loss: 0.26305\n",
      "Epoch: 16 | Iteration: 458 | Classification loss: 0.01871 | Regression loss: 0.07862 | Running loss: 0.26275\n",
      "Epoch: 16 | Iteration: 459 | Classification loss: 0.08589 | Regression loss: 0.04797 | Running loss: 0.26267\n",
      "Epoch: 16 | Iteration: 460 | Classification loss: 0.04400 | Regression loss: 0.08011 | Running loss: 0.26253\n",
      "Epoch: 16 | Iteration: 461 | Classification loss: 0.01957 | Regression loss: 0.14280 | Running loss: 0.26246\n",
      "Epoch: 16 | Iteration: 462 | Classification loss: 0.05549 | Regression loss: 0.21828 | Running loss: 0.26201\n",
      "Epoch: 16 | Iteration: 463 | Classification loss: 0.01986 | Regression loss: 0.13592 | Running loss: 0.26203\n",
      "Epoch: 16 | Iteration: 464 | Classification loss: 0.02628 | Regression loss: 0.10420 | Running loss: 0.26191\n",
      "Epoch: 16 | Iteration: 465 | Classification loss: 0.15838 | Regression loss: 0.36678 | Running loss: 0.26262\n",
      "Epoch: 16 | Iteration: 466 | Classification loss: 0.02488 | Regression loss: 0.13036 | Running loss: 0.26105\n",
      "Epoch: 16 | Iteration: 467 | Classification loss: 0.03970 | Regression loss: 0.19970 | Running loss: 0.26046\n",
      "Epoch: 16 | Iteration: 468 | Classification loss: 0.03272 | Regression loss: 0.19965 | Running loss: 0.26013\n",
      "Epoch: 16 | Iteration: 469 | Classification loss: 0.02514 | Regression loss: 0.14696 | Running loss: 0.25989\n",
      "Epoch: 16 | Iteration: 470 | Classification loss: 0.02987 | Regression loss: 0.21752 | Running loss: 0.25987\n",
      "Epoch: 16 | Iteration: 471 | Classification loss: 0.01324 | Regression loss: 0.16500 | Running loss: 0.25984\n",
      "Epoch: 16 | Iteration: 472 | Classification loss: 0.06737 | Regression loss: 0.32273 | Running loss: 0.26010\n",
      "Epoch: 16 | Iteration: 473 | Classification loss: 0.01526 | Regression loss: 0.09538 | Running loss: 0.26001\n",
      "Epoch: 16 | Iteration: 474 | Classification loss: 0.01178 | Regression loss: 0.12285 | Running loss: 0.25984\n",
      "Epoch: 16 | Iteration: 475 | Classification loss: 0.02319 | Regression loss: 0.14156 | Running loss: 0.25927\n",
      "Epoch: 16 | Iteration: 476 | Classification loss: 0.24419 | Regression loss: 0.35097 | Running loss: 0.25997\n",
      "Epoch: 16 | Iteration: 477 | Classification loss: 0.02508 | Regression loss: 0.13822 | Running loss: 0.25968\n",
      "Epoch: 16 | Iteration: 478 | Classification loss: 0.03213 | Regression loss: 0.19945 | Running loss: 0.25944\n",
      "Epoch: 16 | Iteration: 479 | Classification loss: 0.02049 | Regression loss: 0.11730 | Running loss: 0.25914\n",
      "Epoch: 16 | Iteration: 480 | Classification loss: 0.07790 | Regression loss: 0.24221 | Running loss: 0.25933\n",
      "Epoch: 16 | Iteration: 481 | Classification loss: 0.01068 | Regression loss: 0.13270 | Running loss: 0.25894\n",
      "Epoch: 16 | Iteration: 482 | Classification loss: 0.08801 | Regression loss: 0.28929 | Running loss: 0.25865\n",
      "Epoch: 16 | Iteration: 483 | Classification loss: 0.10838 | Regression loss: 0.10052 | Running loss: 0.25877\n",
      "Epoch: 16 | Iteration: 484 | Classification loss: 0.11727 | Regression loss: 0.20954 | Running loss: 0.25892\n",
      "Epoch: 16 | Iteration: 485 | Classification loss: 0.06943 | Regression loss: 0.15611 | Running loss: 0.25895\n",
      "Epoch: 16 | Iteration: 486 | Classification loss: 0.04937 | Regression loss: 0.18268 | Running loss: 0.25893\n",
      "Epoch: 16 | Iteration: 487 | Classification loss: 0.01427 | Regression loss: 0.16742 | Running loss: 0.25877\n",
      "Epoch: 16 | Iteration: 488 | Classification loss: 0.04665 | Regression loss: 0.24344 | Running loss: 0.25702\n",
      "Epoch: 16 | Iteration: 489 | Classification loss: 0.00900 | Regression loss: 0.12601 | Running loss: 0.25697\n",
      "Epoch: 16 | Iteration: 490 | Classification loss: 0.18663 | Regression loss: 0.20721 | Running loss: 0.25705\n",
      "Epoch: 16 | Iteration: 491 | Classification loss: 0.07813 | Regression loss: 0.32149 | Running loss: 0.25739\n",
      "Epoch: 16 | Iteration: 492 | Classification loss: 0.03603 | Regression loss: 0.17720 | Running loss: 0.25745\n",
      "Epoch: 16 | Iteration: 493 | Classification loss: 0.03880 | Regression loss: 0.13037 | Running loss: 0.25739\n",
      "Epoch: 16 | Iteration: 494 | Classification loss: 0.01325 | Regression loss: 0.10651 | Running loss: 0.25724\n",
      "Epoch: 16 | Iteration: 495 | Classification loss: 0.09253 | Regression loss: 0.43893 | Running loss: 0.25792\n",
      "Epoch: 16 | Iteration: 496 | Classification loss: 0.02445 | Regression loss: 0.34468 | Running loss: 0.25788\n",
      "Epoch: 16 | Iteration: 497 | Classification loss: 0.03824 | Regression loss: 0.09965 | Running loss: 0.25755\n",
      "Epoch: 16 | Iteration: 498 | Classification loss: 0.02688 | Regression loss: 0.13961 | Running loss: 0.25714\n",
      "Epoch: 16 | Iteration: 499 | Classification loss: 0.21101 | Regression loss: 0.14342 | Running loss: 0.25705\n",
      "Epoch: 16 | Iteration: 500 | Classification loss: 0.02866 | Regression loss: 0.19637 | Running loss: 0.25726\n",
      "Epoch: 16 | Iteration: 501 | Classification loss: 0.00560 | Regression loss: 0.06948 | Running loss: 0.25687\n",
      "Epoch: 16 | Iteration: 502 | Classification loss: 0.01633 | Regression loss: 0.13496 | Running loss: 0.25701\n",
      "Epoch: 16 | Iteration: 503 | Classification loss: 0.08155 | Regression loss: 0.30819 | Running loss: 0.25749\n",
      "Epoch: 16 | Iteration: 504 | Classification loss: 0.01882 | Regression loss: 0.06296 | Running loss: 0.25703\n",
      "Epoch: 16 | Iteration: 505 | Classification loss: 0.03658 | Regression loss: 0.13813 | Running loss: 0.25680\n",
      "Epoch: 16 | Iteration: 506 | Classification loss: 0.06608 | Regression loss: 0.20761 | Running loss: 0.25678\n",
      "Epoch: 16 | Iteration: 507 | Classification loss: 0.03586 | Regression loss: 0.08357 | Running loss: 0.25593\n",
      "Epoch: 16 | Iteration: 508 | Classification loss: 0.01857 | Regression loss: 0.35157 | Running loss: 0.25612\n",
      "Epoch: 16 | Iteration: 509 | Classification loss: 0.09443 | Regression loss: 0.22734 | Running loss: 0.25615\n",
      "Epoch: 16 | Iteration: 510 | Classification loss: 0.04757 | Regression loss: 0.24639 | Running loss: 0.25628\n",
      "Epoch: 16 | Iteration: 511 | Classification loss: 0.04511 | Regression loss: 0.25681 | Running loss: 0.25588\n",
      "Epoch: 16 | Iteration: 512 | Classification loss: 0.01230 | Regression loss: 0.15514 | Running loss: 0.25565\n",
      "Epoch: 16 | Iteration: 513 | Classification loss: 0.02807 | Regression loss: 0.19749 | Running loss: 0.25546\n",
      "Epoch: 16 | Iteration: 514 | Classification loss: 0.01088 | Regression loss: 0.09933 | Running loss: 0.25540\n",
      "Epoch: 16 | Iteration: 515 | Classification loss: 0.09235 | Regression loss: 0.08208 | Running loss: 0.25546\n",
      "Epoch: 16 | Iteration: 516 | Classification loss: 0.02696 | Regression loss: 0.13263 | Running loss: 0.25527\n",
      "Epoch: 16 | Iteration: 517 | Classification loss: 0.04751 | Regression loss: 0.20640 | Running loss: 0.25511\n",
      "Epoch: 16 | Iteration: 518 | Classification loss: 0.06909 | Regression loss: 0.22351 | Running loss: 0.25538\n",
      "Epoch: 16 | Iteration: 519 | Classification loss: 0.05824 | Regression loss: 0.29231 | Running loss: 0.25575\n",
      "Epoch: 16 | Iteration: 520 | Classification loss: 0.01774 | Regression loss: 0.20281 | Running loss: 0.25554\n",
      "Epoch: 16 | Iteration: 521 | Classification loss: 0.08000 | Regression loss: 0.38165 | Running loss: 0.25592\n",
      "Epoch: 16 | Iteration: 522 | Classification loss: 0.03026 | Regression loss: 0.14715 | Running loss: 0.25578\n",
      "Epoch: 16 | Iteration: 523 | Classification loss: 0.02389 | Regression loss: 0.09507 | Running loss: 0.25552\n",
      "Epoch: 16 | Iteration: 524 | Classification loss: 0.03513 | Regression loss: 0.22636 | Running loss: 0.25551\n",
      "Epoch: 16 | Iteration: 525 | Classification loss: 0.07732 | Regression loss: 0.27441 | Running loss: 0.25582\n",
      "Epoch: 16 | Iteration: 526 | Classification loss: 0.01227 | Regression loss: 0.11051 | Running loss: 0.25574\n",
      "Epoch: 16 | Iteration: 527 | Classification loss: 0.04142 | Regression loss: 0.17149 | Running loss: 0.25581\n",
      "Epoch: 16 | Iteration: 528 | Classification loss: 0.07961 | Regression loss: 0.23855 | Running loss: 0.25593\n",
      "Epoch: 16 | Iteration: 529 | Classification loss: 0.03369 | Regression loss: 0.17589 | Running loss: 0.25513\n",
      "Epoch: 16 | Iteration: 530 | Classification loss: 0.28983 | Regression loss: 0.20675 | Running loss: 0.25503\n",
      "Epoch: 16 | Iteration: 531 | Classification loss: 0.16483 | Regression loss: 0.24176 | Running loss: 0.25518\n",
      "Epoch: 16 | Iteration: 532 | Classification loss: 0.08248 | Regression loss: 0.22935 | Running loss: 0.25556\n",
      "Epoch: 16 | Iteration: 533 | Classification loss: 0.02864 | Regression loss: 0.10922 | Running loss: 0.25548\n",
      "Epoch: 16 | Iteration: 534 | Classification loss: 0.03008 | Regression loss: 0.12068 | Running loss: 0.25531\n",
      "Epoch: 16 | Iteration: 535 | Classification loss: 0.04916 | Regression loss: 0.30638 | Running loss: 0.25568\n",
      "Epoch: 16 | Iteration: 536 | Classification loss: 0.08880 | Regression loss: 0.17083 | Running loss: 0.25574\n",
      "Epoch: 16 | Iteration: 537 | Classification loss: 0.05922 | Regression loss: 0.21528 | Running loss: 0.25602\n",
      "Epoch: 16 | Iteration: 538 | Classification loss: 0.03333 | Regression loss: 0.16139 | Running loss: 0.25631\n",
      "Epoch: 16 | Iteration: 539 | Classification loss: 0.06158 | Regression loss: 0.39407 | Running loss: 0.25622\n",
      "Epoch: 16 | Iteration: 540 | Classification loss: 0.08035 | Regression loss: 0.38645 | Running loss: 0.25700\n",
      "Epoch: 16 | Iteration: 541 | Classification loss: 0.05661 | Regression loss: 0.14013 | Running loss: 0.25692\n",
      "Epoch: 16 | Iteration: 542 | Classification loss: 0.10048 | Regression loss: 0.22766 | Running loss: 0.25735\n",
      "Epoch: 16 | Iteration: 543 | Classification loss: 0.02191 | Regression loss: 0.21153 | Running loss: 0.25740\n",
      "Epoch: 16 | Iteration: 544 | Classification loss: 0.09822 | Regression loss: 0.12700 | Running loss: 0.25746\n",
      "Epoch: 16 | Iteration: 545 | Classification loss: 0.08181 | Regression loss: 0.20777 | Running loss: 0.25642\n",
      "Epoch: 16 | Iteration: 546 | Classification loss: 0.11460 | Regression loss: 0.48814 | Running loss: 0.25737\n",
      "Epoch: 16 | Iteration: 547 | Classification loss: 0.13788 | Regression loss: 0.13119 | Running loss: 0.25687\n",
      "Epoch: 16 | Iteration: 548 | Classification loss: 0.05662 | Regression loss: 0.24044 | Running loss: 0.25668\n",
      "Epoch: 16 | Iteration: 549 | Classification loss: 0.05471 | Regression loss: 0.15687 | Running loss: 0.25688\n",
      "Epoch: 16 | Iteration: 550 | Classification loss: 0.07400 | Regression loss: 0.43337 | Running loss: 0.25693\n",
      "Epoch: 16 | Iteration: 551 | Classification loss: 0.13918 | Regression loss: 0.27076 | Running loss: 0.25728\n",
      "Epoch: 16 | Iteration: 552 | Classification loss: 0.06802 | Regression loss: 0.14647 | Running loss: 0.25730\n",
      "Epoch: 16 | Iteration: 553 | Classification loss: 0.03150 | Regression loss: 0.25807 | Running loss: 0.25728\n",
      "Epoch: 16 | Iteration: 554 | Classification loss: 0.04910 | Regression loss: 0.10280 | Running loss: 0.25731\n",
      "Epoch: 16 | Iteration: 555 | Classification loss: 0.04327 | Regression loss: 0.07263 | Running loss: 0.25740\n",
      "Epoch: 16 | Iteration: 556 | Classification loss: 0.05138 | Regression loss: 0.16200 | Running loss: 0.25741\n",
      "Epoch: 16 | Iteration: 557 | Classification loss: 0.07140 | Regression loss: 0.18882 | Running loss: 0.25741\n",
      "Epoch: 16 | Iteration: 558 | Classification loss: 0.04514 | Regression loss: 0.26096 | Running loss: 0.25700\n",
      "Epoch: 16 | Iteration: 559 | Classification loss: 0.02779 | Regression loss: 0.14348 | Running loss: 0.25682\n",
      "Epoch: 16 | Iteration: 560 | Classification loss: 0.06049 | Regression loss: 0.14640 | Running loss: 0.25690\n",
      "Epoch: 16 | Iteration: 561 | Classification loss: 0.03110 | Regression loss: 0.12230 | Running loss: 0.25664\n",
      "Epoch: 16 | Iteration: 562 | Classification loss: 0.01464 | Regression loss: 0.14860 | Running loss: 0.25623\n",
      "Epoch: 16 | Iteration: 563 | Classification loss: 0.02585 | Regression loss: 0.09172 | Running loss: 0.25600\n",
      "Epoch: 16 | Iteration: 564 | Classification loss: 0.06188 | Regression loss: 0.13344 | Running loss: 0.25514\n",
      "Epoch: 16 | Iteration: 565 | Classification loss: 0.02541 | Regression loss: 0.15635 | Running loss: 0.25522\n",
      "Epoch: 16 | Iteration: 566 | Classification loss: 0.01908 | Regression loss: 0.28085 | Running loss: 0.25526\n",
      "Epoch: 16 | Iteration: 567 | Classification loss: 0.09729 | Regression loss: 0.22854 | Running loss: 0.25553\n",
      "Epoch: 16 | Iteration: 568 | Classification loss: 0.08650 | Regression loss: 0.07579 | Running loss: 0.25558\n",
      "Epoch: 16 | Iteration: 569 | Classification loss: 0.14442 | Regression loss: 0.47410 | Running loss: 0.25656\n",
      "Epoch: 16 | Iteration: 570 | Classification loss: 0.05755 | Regression loss: 0.23600 | Running loss: 0.25628\n",
      "Epoch: 16 | Iteration: 571 | Classification loss: 0.08127 | Regression loss: 0.27327 | Running loss: 0.25677\n",
      "Epoch: 16 | Iteration: 572 | Classification loss: 0.03523 | Regression loss: 0.12333 | Running loss: 0.25637\n",
      "Epoch: 16 | Iteration: 573 | Classification loss: 0.11774 | Regression loss: 0.36180 | Running loss: 0.25705\n",
      "Epoch: 16 | Iteration: 574 | Classification loss: 0.06586 | Regression loss: 0.21373 | Running loss: 0.25722\n",
      "Epoch: 16 | Iteration: 575 | Classification loss: 0.07093 | Regression loss: 0.22758 | Running loss: 0.25733\n",
      "Epoch: 16 | Iteration: 576 | Classification loss: 0.06117 | Regression loss: 0.23208 | Running loss: 0.25724\n",
      "Epoch: 16 | Iteration: 577 | Classification loss: 0.06796 | Regression loss: 0.17968 | Running loss: 0.25744\n",
      "Epoch: 16 | Iteration: 578 | Classification loss: 0.05006 | Regression loss: 0.23027 | Running loss: 0.25726\n",
      "Epoch: 16 | Iteration: 579 | Classification loss: 0.06191 | Regression loss: 0.16550 | Running loss: 0.25745\n",
      "Epoch: 16 | Iteration: 580 | Classification loss: 0.01028 | Regression loss: 0.13814 | Running loss: 0.25738\n",
      "Epoch: 16 | Iteration: 581 | Classification loss: 0.03081 | Regression loss: 0.19017 | Running loss: 0.25719\n",
      "Epoch: 16 | Iteration: 582 | Classification loss: 0.03243 | Regression loss: 0.18674 | Running loss: 0.25722\n",
      "Epoch: 16 | Iteration: 583 | Classification loss: 0.01030 | Regression loss: 0.11336 | Running loss: 0.25726\n",
      "Epoch: 16 | Iteration: 584 | Classification loss: 0.02549 | Regression loss: 0.09950 | Running loss: 0.25709\n",
      "Epoch: 16 | Iteration: 585 | Classification loss: 0.01102 | Regression loss: 0.12704 | Running loss: 0.25661\n",
      "Epoch: 16 | Iteration: 586 | Classification loss: 0.09890 | Regression loss: 0.19408 | Running loss: 0.25687\n",
      "Epoch: 16 | Iteration: 587 | Classification loss: 0.04301 | Regression loss: 0.15417 | Running loss: 0.25692\n",
      "Epoch: 16 | Iteration: 588 | Classification loss: 0.04804 | Regression loss: 0.19440 | Running loss: 0.25688\n",
      "Epoch: 16 | Iteration: 589 | Classification loss: 0.01691 | Regression loss: 0.11559 | Running loss: 0.25672\n",
      "Epoch: 16 | Iteration: 590 | Classification loss: 0.00623 | Regression loss: 0.07635 | Running loss: 0.25664\n",
      "Epoch: 16 | Iteration: 591 | Classification loss: 0.18302 | Regression loss: 0.32710 | Running loss: 0.25701\n",
      "Epoch: 16 | Iteration: 592 | Classification loss: 0.04840 | Regression loss: 0.14683 | Running loss: 0.25711\n",
      "Epoch: 16 | Iteration: 593 | Classification loss: 0.06759 | Regression loss: 0.08995 | Running loss: 0.25670\n",
      "Epoch: 16 | Iteration: 594 | Classification loss: 0.18212 | Regression loss: 0.36589 | Running loss: 0.25730\n",
      "Epoch: 16 | Iteration: 595 | Classification loss: 0.04342 | Regression loss: 0.16875 | Running loss: 0.25732\n",
      "Epoch: 16 | Iteration: 596 | Classification loss: 0.07208 | Regression loss: 0.16510 | Running loss: 0.25741\n",
      "Epoch: 16 | Iteration: 597 | Classification loss: 0.00499 | Regression loss: 0.14092 | Running loss: 0.25737\n",
      "Epoch: 16 | Iteration: 598 | Classification loss: 0.07489 | Regression loss: 0.27160 | Running loss: 0.25737\n",
      "Epoch: 16 | Iteration: 599 | Classification loss: 0.08134 | Regression loss: 0.29825 | Running loss: 0.25787\n",
      "Epoch: 16 | Iteration: 600 | Classification loss: 0.02231 | Regression loss: 0.19915 | Running loss: 0.25761\n",
      "Epoch: 16 | Iteration: 601 | Classification loss: 0.01477 | Regression loss: 0.13354 | Running loss: 0.25747\n",
      "Epoch: 16 | Iteration: 602 | Classification loss: 0.11093 | Regression loss: 0.25928 | Running loss: 0.25801\n",
      "Epoch: 16 | Iteration: 603 | Classification loss: 0.03201 | Regression loss: 0.20175 | Running loss: 0.25829\n",
      "Epoch: 16 | Iteration: 604 | Classification loss: 0.05359 | Regression loss: 0.14074 | Running loss: 0.25819\n",
      "Epoch: 16 | Iteration: 605 | Classification loss: 0.03202 | Regression loss: 0.11018 | Running loss: 0.25825\n",
      "Epoch: 16 | Iteration: 606 | Classification loss: 0.02639 | Regression loss: 0.24450 | Running loss: 0.25822\n",
      "Epoch: 16 | Iteration: 607 | Classification loss: 0.02511 | Regression loss: 0.14787 | Running loss: 0.25821\n",
      "Epoch: 16 | Iteration: 608 | Classification loss: 0.04034 | Regression loss: 0.05541 | Running loss: 0.25802\n",
      "Epoch: 16 | Iteration: 609 | Classification loss: 0.03190 | Regression loss: 0.12228 | Running loss: 0.25801\n",
      "Epoch: 16 | Iteration: 610 | Classification loss: 0.07904 | Regression loss: 0.22919 | Running loss: 0.25825\n",
      "Epoch: 16 | Iteration: 611 | Classification loss: 0.11844 | Regression loss: 0.29014 | Running loss: 0.25857\n",
      "Epoch: 16 | Iteration: 612 | Classification loss: 0.01887 | Regression loss: 0.14391 | Running loss: 0.25820\n",
      "Epoch: 16 | Iteration: 613 | Classification loss: 0.01712 | Regression loss: 0.15142 | Running loss: 0.25816\n",
      "Epoch: 16 | Iteration: 614 | Classification loss: 0.02969 | Regression loss: 0.15110 | Running loss: 0.25758\n",
      "Epoch: 16 | Iteration: 615 | Classification loss: 0.02611 | Regression loss: 0.21673 | Running loss: 0.25788\n",
      "Epoch: 16 | Iteration: 616 | Classification loss: 0.12064 | Regression loss: 0.11798 | Running loss: 0.25782\n",
      "Epoch: 16 | Iteration: 617 | Classification loss: 0.00993 | Regression loss: 0.11806 | Running loss: 0.25780\n",
      "Epoch: 16 | Iteration: 618 | Classification loss: 0.04412 | Regression loss: 0.11888 | Running loss: 0.25757\n",
      "Epoch: 16 | Iteration: 619 | Classification loss: 0.01673 | Regression loss: 0.10515 | Running loss: 0.25698\n",
      "Epoch: 16 | Iteration: 620 | Classification loss: 0.05984 | Regression loss: 0.29317 | Running loss: 0.25625\n",
      "Epoch: 16 | Iteration: 621 | Classification loss: 0.03661 | Regression loss: 0.13974 | Running loss: 0.25596\n",
      "Epoch: 16 | Iteration: 622 | Classification loss: 0.01927 | Regression loss: 0.11277 | Running loss: 0.25548\n",
      "Epoch: 16 | Iteration: 623 | Classification loss: 0.04276 | Regression loss: 0.28376 | Running loss: 0.25554\n",
      "Epoch: 16 | Iteration: 624 | Classification loss: 0.01131 | Regression loss: 0.12195 | Running loss: 0.25494\n",
      "Epoch: 16 | Iteration: 625 | Classification loss: 0.14593 | Regression loss: 0.25575 | Running loss: 0.25511\n",
      "Epoch: 16 | Iteration: 626 | Classification loss: 0.02428 | Regression loss: 0.15525 | Running loss: 0.25501\n",
      "Epoch: 16 | Iteration: 627 | Classification loss: 0.06659 | Regression loss: 0.24678 | Running loss: 0.25531\n",
      "Epoch: 16 | Iteration: 628 | Classification loss: 0.03792 | Regression loss: 0.18545 | Running loss: 0.25530\n",
      "Epoch: 16 | Iteration: 629 | Classification loss: 0.00498 | Regression loss: 0.10753 | Running loss: 0.25487\n",
      "Epoch: 16 | Iteration: 630 | Classification loss: 0.03045 | Regression loss: 0.25662 | Running loss: 0.25505\n",
      "Epoch: 16 | Iteration: 631 | Classification loss: 0.03972 | Regression loss: 0.23765 | Running loss: 0.25540\n",
      "Epoch: 16 | Iteration: 632 | Classification loss: 0.02992 | Regression loss: 0.23255 | Running loss: 0.25559\n",
      "Epoch: 16 | Iteration: 633 | Classification loss: 0.02303 | Regression loss: 0.10313 | Running loss: 0.25544\n",
      "Epoch: 16 | Iteration: 634 | Classification loss: 0.12677 | Regression loss: 0.31846 | Running loss: 0.25564\n",
      "Epoch: 16 | Iteration: 635 | Classification loss: 0.02245 | Regression loss: 0.22549 | Running loss: 0.25581\n",
      "Epoch: 16 | Iteration: 636 | Classification loss: 0.05636 | Regression loss: 0.17228 | Running loss: 0.25545\n",
      "Epoch: 16 | Iteration: 637 | Classification loss: 0.03345 | Regression loss: 0.07811 | Running loss: 0.25544\n",
      "Epoch: 16 | Iteration: 638 | Classification loss: 0.01378 | Regression loss: 0.10275 | Running loss: 0.25531\n",
      "Epoch: 16 | Iteration: 639 | Classification loss: 0.11425 | Regression loss: 0.22710 | Running loss: 0.25523\n",
      "Epoch: 16 | Iteration: 640 | Classification loss: 0.03410 | Regression loss: 0.24434 | Running loss: 0.25548\n",
      "Epoch: 16 | Iteration: 641 | Classification loss: 0.01469 | Regression loss: 0.11786 | Running loss: 0.25513\n",
      "Epoch: 16 | Iteration: 642 | Classification loss: 0.09559 | Regression loss: 0.28981 | Running loss: 0.25543\n",
      "Epoch: 16 | Iteration: 643 | Classification loss: 0.09719 | Regression loss: 0.24372 | Running loss: 0.25564\n",
      "Epoch: 16 | Iteration: 644 | Classification loss: 0.05055 | Regression loss: 0.16952 | Running loss: 0.25586\n",
      "Epoch: 16 | Iteration: 645 | Classification loss: 0.02496 | Regression loss: 0.16769 | Running loss: 0.25566\n",
      "Epoch: 16 | Iteration: 646 | Classification loss: 0.01795 | Regression loss: 0.11315 | Running loss: 0.25562\n",
      "Epoch: 16 | Iteration: 647 | Classification loss: 0.02861 | Regression loss: 0.18908 | Running loss: 0.25552\n",
      "Epoch: 16 | Iteration: 648 | Classification loss: 0.06018 | Regression loss: 0.33214 | Running loss: 0.25582\n",
      "Epoch: 16 | Iteration: 649 | Classification loss: 0.02630 | Regression loss: 0.21263 | Running loss: 0.25605\n",
      "Epoch: 16 | Iteration: 650 | Classification loss: 0.02359 | Regression loss: 0.09937 | Running loss: 0.25582\n",
      "Epoch: 16 | Iteration: 651 | Classification loss: 0.02486 | Regression loss: 0.15262 | Running loss: 0.25578\n",
      "Epoch: 16 | Iteration: 652 | Classification loss: 0.02205 | Regression loss: 0.13871 | Running loss: 0.25574\n",
      "Epoch: 16 | Iteration: 653 | Classification loss: 0.20442 | Regression loss: 0.39788 | Running loss: 0.25659\n",
      "Epoch: 16 | Iteration: 654 | Classification loss: 0.00954 | Regression loss: 0.10570 | Running loss: 0.25526\n",
      "Epoch: 16 | Iteration: 655 | Classification loss: 0.01365 | Regression loss: 0.15625 | Running loss: 0.25493\n",
      "Epoch: 16 | Iteration: 656 | Classification loss: 0.03307 | Regression loss: 0.09754 | Running loss: 0.25468\n",
      "Epoch: 16 | Iteration: 657 | Classification loss: 0.05967 | Regression loss: 0.21073 | Running loss: 0.25484\n",
      "Epoch: 16 | Iteration: 658 | Classification loss: 0.01653 | Regression loss: 0.09087 | Running loss: 0.25468\n",
      "Epoch: 16 | Iteration: 659 | Classification loss: 0.01440 | Regression loss: 0.14315 | Running loss: 0.25463\n",
      "Epoch: 16 | Iteration: 660 | Classification loss: 0.00742 | Regression loss: 0.07401 | Running loss: 0.25433\n",
      "Epoch: 16 | Iteration: 661 | Classification loss: 0.03917 | Regression loss: 0.08414 | Running loss: 0.25458\n",
      "Epoch: 16 | Iteration: 662 | Classification loss: 0.02267 | Regression loss: 0.12593 | Running loss: 0.25400\n",
      "Epoch: 16 | Iteration: 663 | Classification loss: 0.01287 | Regression loss: 0.09894 | Running loss: 0.25326\n",
      "Epoch: 16 | Iteration: 664 | Classification loss: 0.12291 | Regression loss: 0.10598 | Running loss: 0.25325\n",
      "Epoch: 16 | Iteration: 665 | Classification loss: 0.05790 | Regression loss: 0.18261 | Running loss: 0.25276\n",
      "Epoch: 16 | Iteration: 666 | Classification loss: 0.01374 | Regression loss: 0.13402 | Running loss: 0.25268\n",
      "Epoch: 16 | Iteration: 667 | Classification loss: 0.04729 | Regression loss: 0.19889 | Running loss: 0.25273\n",
      "Epoch: 16 | Iteration: 668 | Classification loss: 0.07035 | Regression loss: 0.29899 | Running loss: 0.25306\n",
      "Epoch: 16 | Iteration: 669 | Classification loss: 0.21615 | Regression loss: 0.37119 | Running loss: 0.25354\n",
      "Epoch: 16 | Iteration: 670 | Classification loss: 0.01862 | Regression loss: 0.18755 | Running loss: 0.25359\n",
      "Epoch: 16 | Iteration: 671 | Classification loss: 0.03639 | Regression loss: 0.18115 | Running loss: 0.25365\n",
      "Epoch: 16 | Iteration: 672 | Classification loss: 0.07106 | Regression loss: 0.25762 | Running loss: 0.25388\n",
      "Epoch: 16 | Iteration: 673 | Classification loss: 0.03788 | Regression loss: 0.15169 | Running loss: 0.25395\n",
      "Epoch: 16 | Iteration: 674 | Classification loss: 0.04265 | Regression loss: 0.24681 | Running loss: 0.25439\n",
      "Epoch: 16 | Iteration: 675 | Classification loss: 0.11403 | Regression loss: 0.28624 | Running loss: 0.25448\n",
      "Epoch: 16 | Iteration: 676 | Classification loss: 0.09513 | Regression loss: 0.15233 | Running loss: 0.25452\n",
      "Epoch: 16 | Iteration: 677 | Classification loss: 0.07371 | Regression loss: 0.11695 | Running loss: 0.25436\n",
      "Epoch: 16 | Iteration: 678 | Classification loss: 0.03223 | Regression loss: 0.12220 | Running loss: 0.25406\n",
      "Epoch: 16 | Iteration: 679 | Classification loss: 0.02932 | Regression loss: 0.15614 | Running loss: 0.25397\n",
      "Epoch: 16 | Iteration: 680 | Classification loss: 0.01540 | Regression loss: 0.09376 | Running loss: 0.25389\n",
      "Epoch: 16 | Iteration: 681 | Classification loss: 0.02884 | Regression loss: 0.12353 | Running loss: 0.25385\n",
      "Epoch: 16 | Iteration: 682 | Classification loss: 0.01927 | Regression loss: 0.19239 | Running loss: 0.25359\n",
      "Epoch: 16 | Iteration: 683 | Classification loss: 0.04551 | Regression loss: 0.19617 | Running loss: 0.25265\n",
      "Epoch: 16 | Iteration: 684 | Classification loss: 0.02654 | Regression loss: 0.23253 | Running loss: 0.25270\n",
      "Epoch: 16 | Iteration: 685 | Classification loss: 0.08002 | Regression loss: 0.28504 | Running loss: 0.25317\n",
      "Epoch: 16 | Iteration: 686 | Classification loss: 0.01933 | Regression loss: 0.08475 | Running loss: 0.25297\n",
      "Epoch: 16 | Iteration: 687 | Classification loss: 0.04407 | Regression loss: 0.10761 | Running loss: 0.25302\n",
      "Epoch: 16 | Iteration: 688 | Classification loss: 0.01367 | Regression loss: 0.10769 | Running loss: 0.25252\n",
      "Epoch: 16 | Iteration: 689 | Classification loss: 0.02325 | Regression loss: 0.13922 | Running loss: 0.25243\n",
      "Epoch: 16 | Iteration: 690 | Classification loss: 0.03368 | Regression loss: 0.08700 | Running loss: 0.25202\n",
      "Epoch: 16 | Iteration: 691 | Classification loss: 0.05491 | Regression loss: 0.19773 | Running loss: 0.25214\n",
      "Epoch: 16 | Iteration: 692 | Classification loss: 0.04031 | Regression loss: 0.13079 | Running loss: 0.25139\n",
      "Epoch: 16 | Iteration: 693 | Classification loss: 0.01775 | Regression loss: 0.09097 | Running loss: 0.25078\n",
      "Epoch: 16 | Iteration: 694 | Classification loss: 0.05339 | Regression loss: 0.17986 | Running loss: 0.25077\n",
      "Epoch: 16 | Iteration: 695 | Classification loss: 0.01474 | Regression loss: 0.15174 | Running loss: 0.25061\n",
      "Epoch: 16 | Iteration: 696 | Classification loss: 0.03506 | Regression loss: 0.17509 | Running loss: 0.25044\n",
      "Epoch: 16 | Iteration: 697 | Classification loss: 0.02443 | Regression loss: 0.09091 | Running loss: 0.24957\n",
      "Epoch: 16 | Iteration: 698 | Classification loss: 0.04068 | Regression loss: 0.11990 | Running loss: 0.24869\n",
      "Epoch: 16 | Iteration: 699 | Classification loss: 0.02369 | Regression loss: 0.15158 | Running loss: 0.24801\n",
      "Epoch: 16 | Iteration: 700 | Classification loss: 0.03931 | Regression loss: 0.20991 | Running loss: 0.24763\n",
      "Epoch: 16 | Iteration: 701 | Classification loss: 0.10491 | Regression loss: 0.25399 | Running loss: 0.24747\n",
      "Epoch: 16 | Iteration: 702 | Classification loss: 0.10799 | Regression loss: 0.35538 | Running loss: 0.24748\n",
      "Epoch: 16 | Iteration: 703 | Classification loss: 0.07244 | Regression loss: 0.24537 | Running loss: 0.24778\n",
      "Epoch: 16 | Iteration: 704 | Classification loss: 0.06032 | Regression loss: 0.27848 | Running loss: 0.24802\n",
      "Epoch: 16 | Iteration: 705 | Classification loss: 0.04555 | Regression loss: 0.15504 | Running loss: 0.24770\n",
      "Epoch: 16 | Iteration: 706 | Classification loss: 0.07045 | Regression loss: 0.23164 | Running loss: 0.24734\n",
      "Epoch: 16 | Iteration: 707 | Classification loss: 0.01797 | Regression loss: 0.14281 | Running loss: 0.24722\n",
      "Epoch: 16 | Iteration: 708 | Classification loss: 0.01634 | Regression loss: 0.11998 | Running loss: 0.24716\n",
      "Epoch: 16 | Iteration: 709 | Classification loss: 0.04591 | Regression loss: 0.11112 | Running loss: 0.24682\n",
      "Epoch: 16 | Iteration: 710 | Classification loss: 0.02506 | Regression loss: 0.18898 | Running loss: 0.24620\n",
      "Epoch: 16 | Iteration: 711 | Classification loss: 0.05552 | Regression loss: 0.15878 | Running loss: 0.24609\n",
      "Epoch: 16 | Iteration: 712 | Classification loss: 0.01497 | Regression loss: 0.18821 | Running loss: 0.24631\n",
      "Epoch: 16 | Iteration: 713 | Classification loss: 0.04228 | Regression loss: 0.18868 | Running loss: 0.24663\n",
      "Epoch: 16 | Iteration: 714 | Classification loss: 0.05740 | Regression loss: 0.12038 | Running loss: 0.24574\n",
      "Epoch: 16 | Iteration: 715 | Classification loss: 0.01021 | Regression loss: 0.12173 | Running loss: 0.24546\n",
      "Epoch: 16 | Iteration: 716 | Classification loss: 0.04962 | Regression loss: 0.11227 | Running loss: 0.24549\n",
      "Epoch: 16 | Iteration: 717 | Classification loss: 0.10650 | Regression loss: 0.31656 | Running loss: 0.24590\n",
      "Epoch: 16 | Iteration: 718 | Classification loss: 0.02584 | Regression loss: 0.12505 | Running loss: 0.24601\n",
      "Epoch: 16 | Iteration: 719 | Classification loss: 0.01413 | Regression loss: 0.16711 | Running loss: 0.24622\n",
      "Epoch: 16 | Iteration: 720 | Classification loss: 0.02174 | Regression loss: 0.19726 | Running loss: 0.24633\n",
      "Epoch: 16 | Iteration: 721 | Classification loss: 0.01135 | Regression loss: 0.15954 | Running loss: 0.24609\n",
      "Epoch: 16 | Iteration: 722 | Classification loss: 0.05696 | Regression loss: 0.21300 | Running loss: 0.24617\n",
      "Epoch: 16 | Iteration: 723 | Classification loss: 0.04820 | Regression loss: 0.17846 | Running loss: 0.24579\n",
      "Epoch: 16 | Iteration: 724 | Classification loss: 0.04369 | Regression loss: 0.14692 | Running loss: 0.24561\n",
      "Epoch: 16 | Iteration: 725 | Classification loss: 0.08526 | Regression loss: 0.12250 | Running loss: 0.24572\n",
      "Epoch: 16 | Iteration: 726 | Classification loss: 0.01327 | Regression loss: 0.16747 | Running loss: 0.24541\n",
      "Epoch: 16 | Iteration: 727 | Classification loss: 0.05060 | Regression loss: 0.23135 | Running loss: 0.24562\n",
      "Epoch: 16 | Iteration: 728 | Classification loss: 0.01749 | Regression loss: 0.10793 | Running loss: 0.24505\n",
      "Epoch: 16 | Iteration: 729 | Classification loss: 0.00721 | Regression loss: 0.08236 | Running loss: 0.24463\n",
      "Epoch: 16 | Iteration: 730 | Classification loss: 0.00457 | Regression loss: 0.07941 | Running loss: 0.24430\n",
      "Epoch: 16 | Iteration: 731 | Classification loss: 0.01461 | Regression loss: 0.19175 | Running loss: 0.24439\n",
      "Epoch: 16 | Iteration: 732 | Classification loss: 0.06373 | Regression loss: 0.10685 | Running loss: 0.24408\n",
      "Epoch: 16 | Iteration: 733 | Classification loss: 0.05082 | Regression loss: 0.26362 | Running loss: 0.24404\n",
      "Epoch: 16 | Iteration: 734 | Classification loss: 0.02603 | Regression loss: 0.18869 | Running loss: 0.24378\n",
      "Epoch: 16 | Iteration: 735 | Classification loss: 0.01932 | Regression loss: 0.10282 | Running loss: 0.24335\n",
      "Epoch: 16 | Iteration: 736 | Classification loss: 0.14045 | Regression loss: 0.17034 | Running loss: 0.24302\n",
      "Epoch: 16 | Iteration: 737 | Classification loss: 0.05141 | Regression loss: 0.06394 | Running loss: 0.24282\n",
      "Epoch: 16 | Iteration: 738 | Classification loss: 0.06621 | Regression loss: 0.17866 | Running loss: 0.24294\n",
      "Epoch: 16 | Iteration: 739 | Classification loss: 0.00916 | Regression loss: 0.08731 | Running loss: 0.24286\n",
      "Epoch: 16 | Iteration: 740 | Classification loss: 0.01391 | Regression loss: 0.15923 | Running loss: 0.24267\n",
      "Epoch: 16 | Iteration: 741 | Classification loss: 0.01599 | Regression loss: 0.08656 | Running loss: 0.24268\n",
      "Epoch: 16 | Iteration: 742 | Classification loss: 0.09974 | Regression loss: 0.27320 | Running loss: 0.24309\n",
      "Epoch: 16 | Iteration: 743 | Classification loss: 0.08296 | Regression loss: 0.16841 | Running loss: 0.24307\n",
      "Epoch: 16 | Iteration: 744 | Classification loss: 0.15920 | Regression loss: 0.13828 | Running loss: 0.24316\n",
      "Epoch: 16 | Iteration: 745 | Classification loss: 0.07405 | Regression loss: 0.28198 | Running loss: 0.24331\n",
      "Epoch: 16 | Iteration: 746 | Classification loss: 0.04864 | Regression loss: 0.16912 | Running loss: 0.24333\n",
      "Epoch: 16 | Iteration: 747 | Classification loss: 0.21261 | Regression loss: 0.16520 | Running loss: 0.24339\n",
      "Epoch: 16 | Iteration: 748 | Classification loss: 0.02128 | Regression loss: 0.31736 | Running loss: 0.24344\n",
      "Epoch: 16 | Iteration: 749 | Classification loss: 0.02953 | Regression loss: 0.12174 | Running loss: 0.24318\n",
      "Epoch: 16 | Iteration: 750 | Classification loss: 0.03348 | Regression loss: 0.15497 | Running loss: 0.24324\n",
      "Epoch: 16 | Iteration: 751 | Classification loss: 0.05069 | Regression loss: 0.16672 | Running loss: 0.24275\n",
      "Epoch: 16 | Iteration: 752 | Classification loss: 0.14490 | Regression loss: 0.39728 | Running loss: 0.24337\n",
      "Epoch: 16 | Iteration: 753 | Classification loss: 0.06126 | Regression loss: 0.23469 | Running loss: 0.24302\n",
      "Epoch: 16 | Iteration: 754 | Classification loss: 0.03269 | Regression loss: 0.11574 | Running loss: 0.24293\n",
      "Epoch: 16 | Iteration: 755 | Classification loss: 0.03187 | Regression loss: 0.15640 | Running loss: 0.24295\n",
      "Epoch: 16 | Iteration: 756 | Classification loss: 0.10911 | Regression loss: 0.08827 | Running loss: 0.24275\n",
      "Epoch: 16 | Iteration: 757 | Classification loss: 0.03502 | Regression loss: 0.12371 | Running loss: 0.24285\n",
      "Epoch: 16 | Iteration: 758 | Classification loss: 0.04725 | Regression loss: 0.17228 | Running loss: 0.24245\n",
      "Epoch: 16 | Iteration: 759 | Classification loss: 0.01297 | Regression loss: 0.11157 | Running loss: 0.24191\n",
      "Epoch: 16 | Iteration: 760 | Classification loss: 0.13244 | Regression loss: 0.27248 | Running loss: 0.24235\n",
      "Epoch: 16 | Iteration: 761 | Classification loss: 0.01225 | Regression loss: 0.08098 | Running loss: 0.24162\n",
      "Epoch: 16 | Iteration: 762 | Classification loss: 0.02028 | Regression loss: 0.21268 | Running loss: 0.24143\n",
      "Epoch: 16 | Iteration: 763 | Classification loss: 0.07977 | Regression loss: 0.32437 | Running loss: 0.24162\n",
      "Epoch: 16 | Iteration: 764 | Classification loss: 0.05225 | Regression loss: 0.31127 | Running loss: 0.24201\n",
      "Epoch: 16 | Iteration: 765 | Classification loss: 0.02122 | Regression loss: 0.10244 | Running loss: 0.24185\n",
      "Epoch: 16 | Iteration: 766 | Classification loss: 0.02174 | Regression loss: 0.18646 | Running loss: 0.24160\n",
      "Epoch: 16 | Iteration: 767 | Classification loss: 0.02960 | Regression loss: 0.18929 | Running loss: 0.24171\n",
      "Epoch: 16 | Iteration: 768 | Classification loss: 0.03402 | Regression loss: 0.20046 | Running loss: 0.24175\n",
      "Epoch: 16 | Iteration: 769 | Classification loss: 0.12190 | Regression loss: 0.15834 | Running loss: 0.24203\n",
      "Epoch: 16 | Iteration: 770 | Classification loss: 0.02347 | Regression loss: 0.14114 | Running loss: 0.24128\n",
      "Epoch: 16 | Iteration: 771 | Classification loss: 0.07533 | Regression loss: 0.15859 | Running loss: 0.24140\n",
      "Epoch: 16 | Iteration: 772 | Classification loss: 0.17762 | Regression loss: 0.24848 | Running loss: 0.24157\n",
      "Epoch: 16 | Iteration: 773 | Classification loss: 0.02711 | Regression loss: 0.19291 | Running loss: 0.24155\n",
      "Epoch: 16 | Iteration: 774 | Classification loss: 0.08294 | Regression loss: 0.27840 | Running loss: 0.24173\n",
      "Epoch: 16 | Iteration: 775 | Classification loss: 0.03733 | Regression loss: 0.16930 | Running loss: 0.24160\n",
      "Epoch: 16 | Iteration: 776 | Classification loss: 0.04093 | Regression loss: 0.28814 | Running loss: 0.24183\n",
      "Epoch: 16 | Iteration: 777 | Classification loss: 0.04924 | Regression loss: 0.26905 | Running loss: 0.24191\n",
      "Epoch: 16 | Iteration: 778 | Classification loss: 0.04150 | Regression loss: 0.18207 | Running loss: 0.24194\n",
      "Epoch: 16 | Iteration: 779 | Classification loss: 0.02766 | Regression loss: 0.13130 | Running loss: 0.24118\n",
      "Epoch: 16 | Iteration: 780 | Classification loss: 0.12738 | Regression loss: 0.27049 | Running loss: 0.24152\n",
      "Epoch: 16 | Iteration: 781 | Classification loss: 0.02950 | Regression loss: 0.18645 | Running loss: 0.24168\n",
      "Epoch: 16 | Iteration: 782 | Classification loss: 0.01654 | Regression loss: 0.12041 | Running loss: 0.24161\n",
      "Epoch: 16 | Iteration: 783 | Classification loss: 0.46278 | Regression loss: 0.11080 | Running loss: 0.24191\n",
      "Epoch: 16 | Iteration: 784 | Classification loss: 0.05251 | Regression loss: 0.17385 | Running loss: 0.24176\n",
      "Epoch: 16 | Iteration: 785 | Classification loss: 0.03018 | Regression loss: 0.27252 | Running loss: 0.24171\n",
      "Epoch: 16 | Iteration: 786 | Classification loss: 0.15434 | Regression loss: 0.39946 | Running loss: 0.24235\n",
      "Epoch: 16 | Iteration: 787 | Classification loss: 0.15546 | Regression loss: 0.85942 | Running loss: 0.24391\n",
      "Epoch: 16 | Iteration: 788 | Classification loss: 0.04709 | Regression loss: 0.08983 | Running loss: 0.24377\n",
      "Epoch: 16 | Iteration: 789 | Classification loss: 0.04432 | Regression loss: 0.18745 | Running loss: 0.24363\n",
      "Epoch: 16 | Iteration: 790 | Classification loss: 0.02604 | Regression loss: 0.11571 | Running loss: 0.24342\n",
      "Epoch: 16 | Iteration: 791 | Classification loss: 0.02635 | Regression loss: 0.19689 | Running loss: 0.24329\n",
      "Epoch: 16 | Iteration: 792 | Classification loss: 0.04981 | Regression loss: 0.15935 | Running loss: 0.24301\n",
      "Epoch: 16 | Iteration: 793 | Classification loss: 0.04089 | Regression loss: 0.15382 | Running loss: 0.24310\n",
      "Epoch: 16 | Iteration: 794 | Classification loss: 0.02543 | Regression loss: 0.20305 | Running loss: 0.24318\n",
      "Epoch: 16 | Iteration: 795 | Classification loss: 0.13052 | Regression loss: 0.25383 | Running loss: 0.24346\n",
      "Epoch: 16 | Iteration: 796 | Classification loss: 0.05487 | Regression loss: 0.20200 | Running loss: 0.24359\n",
      "Epoch: 16 | Iteration: 797 | Classification loss: 0.03034 | Regression loss: 0.20008 | Running loss: 0.24378\n",
      "Epoch: 16 | Iteration: 798 | Classification loss: 0.16106 | Regression loss: 0.45605 | Running loss: 0.24418\n",
      "Epoch: 16 | Iteration: 799 | Classification loss: 0.06309 | Regression loss: 0.13918 | Running loss: 0.24404\n",
      "Epoch: 16 | Iteration: 800 | Classification loss: 0.03383 | Regression loss: 0.09733 | Running loss: 0.24389\n",
      "Epoch: 16 | Iteration: 801 | Classification loss: 0.03673 | Regression loss: 0.09731 | Running loss: 0.24379\n",
      "Epoch: 16 | Iteration: 802 | Classification loss: 0.01397 | Regression loss: 0.14640 | Running loss: 0.24385\n",
      "Epoch: 16 | Iteration: 803 | Classification loss: 0.08553 | Regression loss: 0.26635 | Running loss: 0.24358\n",
      "Epoch: 16 | Iteration: 804 | Classification loss: 0.05066 | Regression loss: 0.23846 | Running loss: 0.24356\n",
      "Epoch: 16 | Iteration: 805 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.24305\n",
      "Epoch: 16 | Iteration: 806 | Classification loss: 0.09771 | Regression loss: 0.26831 | Running loss: 0.24354\n",
      "Epoch: 16 | Iteration: 807 | Classification loss: 0.04189 | Regression loss: 0.19647 | Running loss: 0.24386\n",
      "Epoch: 16 | Iteration: 808 | Classification loss: 0.20230 | Regression loss: 0.17578 | Running loss: 0.24420\n",
      "Epoch: 16 | Iteration: 809 | Classification loss: 0.01685 | Regression loss: 0.09196 | Running loss: 0.24390\n",
      "Epoch: 16 | Iteration: 810 | Classification loss: 0.06599 | Regression loss: 0.21463 | Running loss: 0.24346\n",
      "Epoch: 16 | Iteration: 811 | Classification loss: 0.03898 | Regression loss: 0.21167 | Running loss: 0.24323\n",
      "Epoch: 16 | Iteration: 812 | Classification loss: 0.04887 | Regression loss: 0.17866 | Running loss: 0.24311\n",
      "Epoch: 16 | Iteration: 813 | Classification loss: 0.02901 | Regression loss: 0.17251 | Running loss: 0.24297\n",
      "Epoch: 16 | Iteration: 814 | Classification loss: 0.06083 | Regression loss: 0.15955 | Running loss: 0.24262\n",
      "Epoch: 16 | Iteration: 815 | Classification loss: 0.52417 | Regression loss: 0.31692 | Running loss: 0.24355\n",
      "Epoch: 16 | Iteration: 816 | Classification loss: 0.17205 | Regression loss: 0.26624 | Running loss: 0.24424\n",
      "Epoch: 16 | Iteration: 817 | Classification loss: 0.13325 | Regression loss: 0.26145 | Running loss: 0.24426\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.609\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 17 | Iteration: 0 | Classification loss: 0.02566 | Regression loss: 0.04932 | Running loss: 0.24407\n",
      "Epoch: 17 | Iteration: 1 | Classification loss: 0.01251 | Regression loss: 0.08356 | Running loss: 0.24396\n",
      "Epoch: 17 | Iteration: 2 | Classification loss: 0.05717 | Regression loss: 0.26513 | Running loss: 0.24435\n",
      "Epoch: 17 | Iteration: 3 | Classification loss: 0.02261 | Regression loss: 0.09918 | Running loss: 0.24409\n",
      "Epoch: 17 | Iteration: 4 | Classification loss: 0.09663 | Regression loss: 0.16527 | Running loss: 0.24409\n",
      "Epoch: 17 | Iteration: 5 | Classification loss: 0.06864 | Regression loss: 0.14273 | Running loss: 0.24412\n",
      "Epoch: 17 | Iteration: 6 | Classification loss: 0.04322 | Regression loss: 0.15234 | Running loss: 0.24378\n",
      "Epoch: 17 | Iteration: 7 | Classification loss: 0.05563 | Regression loss: 0.10196 | Running loss: 0.24374\n",
      "Epoch: 17 | Iteration: 8 | Classification loss: 0.03465 | Regression loss: 0.18069 | Running loss: 0.24381\n",
      "Epoch: 17 | Iteration: 9 | Classification loss: 0.15438 | Regression loss: 0.14350 | Running loss: 0.24403\n",
      "Epoch: 17 | Iteration: 10 | Classification loss: 0.02457 | Regression loss: 0.22286 | Running loss: 0.24424\n",
      "Epoch: 17 | Iteration: 11 | Classification loss: 0.07435 | Regression loss: 0.17599 | Running loss: 0.24398\n",
      "Epoch: 17 | Iteration: 12 | Classification loss: 0.01258 | Regression loss: 0.11632 | Running loss: 0.24356\n",
      "Epoch: 17 | Iteration: 13 | Classification loss: 0.03516 | Regression loss: 0.16462 | Running loss: 0.24288\n",
      "Epoch: 17 | Iteration: 14 | Classification loss: 0.08566 | Regression loss: 0.17638 | Running loss: 0.24309\n",
      "Epoch: 17 | Iteration: 15 | Classification loss: 0.23012 | Regression loss: 0.15235 | Running loss: 0.24356\n",
      "Epoch: 17 | Iteration: 16 | Classification loss: 0.02934 | Regression loss: 0.09843 | Running loss: 0.24350\n",
      "Epoch: 17 | Iteration: 17 | Classification loss: 0.04531 | Regression loss: 0.24524 | Running loss: 0.24318\n",
      "Epoch: 17 | Iteration: 18 | Classification loss: 0.03919 | Regression loss: 0.08246 | Running loss: 0.24303\n",
      "Epoch: 17 | Iteration: 19 | Classification loss: 0.03159 | Regression loss: 0.10523 | Running loss: 0.24258\n",
      "Epoch: 17 | Iteration: 20 | Classification loss: 0.01853 | Regression loss: 0.10594 | Running loss: 0.24202\n",
      "Epoch: 17 | Iteration: 21 | Classification loss: 0.11872 | Regression loss: 0.26586 | Running loss: 0.24231\n",
      "Epoch: 17 | Iteration: 22 | Classification loss: 0.18427 | Regression loss: 0.12368 | Running loss: 0.24260\n",
      "Epoch: 17 | Iteration: 23 | Classification loss: 0.01833 | Regression loss: 0.10284 | Running loss: 0.24257\n",
      "Epoch: 17 | Iteration: 24 | Classification loss: 0.05906 | Regression loss: 0.34734 | Running loss: 0.24288\n",
      "Epoch: 17 | Iteration: 25 | Classification loss: 0.00969 | Regression loss: 0.19721 | Running loss: 0.24298\n",
      "Epoch: 17 | Iteration: 26 | Classification loss: 0.01740 | Regression loss: 0.14310 | Running loss: 0.24276\n",
      "Epoch: 17 | Iteration: 27 | Classification loss: 0.04010 | Regression loss: 0.22018 | Running loss: 0.24258\n",
      "Epoch: 17 | Iteration: 28 | Classification loss: 0.12394 | Regression loss: 0.40005 | Running loss: 0.24329\n",
      "Epoch: 17 | Iteration: 29 | Classification loss: 0.08276 | Regression loss: 0.25980 | Running loss: 0.24327\n",
      "Epoch: 17 | Iteration: 30 | Classification loss: 0.04383 | Regression loss: 0.17689 | Running loss: 0.24319\n",
      "Epoch: 17 | Iteration: 31 | Classification loss: 0.02809 | Regression loss: 0.10622 | Running loss: 0.24126\n",
      "Epoch: 17 | Iteration: 32 | Classification loss: 0.03242 | Regression loss: 0.10787 | Running loss: 0.24118\n",
      "Epoch: 17 | Iteration: 33 | Classification loss: 0.05296 | Regression loss: 0.11415 | Running loss: 0.24093\n",
      "Epoch: 17 | Iteration: 34 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.24056\n",
      "Epoch: 17 | Iteration: 35 | Classification loss: 0.39336 | Regression loss: 0.70899 | Running loss: 0.24230\n",
      "Epoch: 17 | Iteration: 36 | Classification loss: 0.01536 | Regression loss: 0.16383 | Running loss: 0.24207\n",
      "Epoch: 17 | Iteration: 37 | Classification loss: 0.04632 | Regression loss: 0.34143 | Running loss: 0.24275\n",
      "Epoch: 17 | Iteration: 38 | Classification loss: 0.49854 | Regression loss: 0.16277 | Running loss: 0.24375\n",
      "Epoch: 17 | Iteration: 39 | Classification loss: 0.02060 | Regression loss: 0.16797 | Running loss: 0.24320\n",
      "Epoch: 17 | Iteration: 40 | Classification loss: 0.01858 | Regression loss: 0.13989 | Running loss: 0.24336\n",
      "Epoch: 17 | Iteration: 41 | Classification loss: 0.04630 | Regression loss: 0.13131 | Running loss: 0.24271\n",
      "Epoch: 17 | Iteration: 42 | Classification loss: 0.05412 | Regression loss: 0.20121 | Running loss: 0.24251\n",
      "Epoch: 17 | Iteration: 43 | Classification loss: 0.05357 | Regression loss: 0.15084 | Running loss: 0.24240\n",
      "Epoch: 17 | Iteration: 44 | Classification loss: 0.01543 | Regression loss: 0.13414 | Running loss: 0.24159\n",
      "Epoch: 17 | Iteration: 45 | Classification loss: 0.04143 | Regression loss: 0.25535 | Running loss: 0.24167\n",
      "Epoch: 17 | Iteration: 46 | Classification loss: 0.02860 | Regression loss: 0.10756 | Running loss: 0.24128\n",
      "Epoch: 17 | Iteration: 47 | Classification loss: 0.14275 | Regression loss: 0.23130 | Running loss: 0.24172\n",
      "Epoch: 17 | Iteration: 48 | Classification loss: 0.08994 | Regression loss: 0.24101 | Running loss: 0.24178\n",
      "Epoch: 17 | Iteration: 49 | Classification loss: 0.09066 | Regression loss: 0.28350 | Running loss: 0.24224\n",
      "Epoch: 17 | Iteration: 50 | Classification loss: 0.01702 | Regression loss: 0.13593 | Running loss: 0.24184\n",
      "Epoch: 17 | Iteration: 51 | Classification loss: 0.04440 | Regression loss: 0.24550 | Running loss: 0.24197\n",
      "Epoch: 17 | Iteration: 52 | Classification loss: 0.00975 | Regression loss: 0.09908 | Running loss: 0.24170\n",
      "Epoch: 17 | Iteration: 53 | Classification loss: 0.02672 | Regression loss: 0.14042 | Running loss: 0.24175\n",
      "Epoch: 17 | Iteration: 54 | Classification loss: 0.02661 | Regression loss: 0.14114 | Running loss: 0.24140\n",
      "Epoch: 17 | Iteration: 55 | Classification loss: 0.04885 | Regression loss: 0.12208 | Running loss: 0.24107\n",
      "Epoch: 17 | Iteration: 56 | Classification loss: 0.15560 | Regression loss: 0.27668 | Running loss: 0.24165\n",
      "Epoch: 17 | Iteration: 57 | Classification loss: 0.07517 | Regression loss: 0.18815 | Running loss: 0.24185\n",
      "Epoch: 17 | Iteration: 58 | Classification loss: 0.01112 | Regression loss: 0.07093 | Running loss: 0.24171\n",
      "Epoch: 17 | Iteration: 59 | Classification loss: 0.06074 | Regression loss: 0.16794 | Running loss: 0.24187\n",
      "Epoch: 17 | Iteration: 60 | Classification loss: 0.01172 | Regression loss: 0.07561 | Running loss: 0.24166\n",
      "Epoch: 17 | Iteration: 61 | Classification loss: 0.04312 | Regression loss: 0.16614 | Running loss: 0.24175\n",
      "Epoch: 17 | Iteration: 62 | Classification loss: 0.02201 | Regression loss: 0.16888 | Running loss: 0.24190\n",
      "Epoch: 17 | Iteration: 63 | Classification loss: 0.08791 | Regression loss: 0.34008 | Running loss: 0.24255\n",
      "Epoch: 17 | Iteration: 64 | Classification loss: 0.05497 | Regression loss: 0.27347 | Running loss: 0.24265\n",
      "Epoch: 17 | Iteration: 65 | Classification loss: 0.09563 | Regression loss: 0.21176 | Running loss: 0.24296\n",
      "Epoch: 17 | Iteration: 66 | Classification loss: 0.17428 | Regression loss: 0.26044 | Running loss: 0.24338\n",
      "Epoch: 17 | Iteration: 67 | Classification loss: 0.10344 | Regression loss: 0.40111 | Running loss: 0.24372\n",
      "Epoch: 17 | Iteration: 68 | Classification loss: 0.12921 | Regression loss: 0.21359 | Running loss: 0.24379\n",
      "Epoch: 17 | Iteration: 69 | Classification loss: 0.05721 | Regression loss: 0.20260 | Running loss: 0.24397\n",
      "Epoch: 17 | Iteration: 70 | Classification loss: 0.02341 | Regression loss: 0.15373 | Running loss: 0.24358\n",
      "Epoch: 17 | Iteration: 71 | Classification loss: 0.00797 | Regression loss: 0.09091 | Running loss: 0.24342\n",
      "Epoch: 17 | Iteration: 72 | Classification loss: 0.03521 | Regression loss: 0.13570 | Running loss: 0.24341\n",
      "Epoch: 17 | Iteration: 73 | Classification loss: 0.10968 | Regression loss: 0.26638 | Running loss: 0.24353\n",
      "Epoch: 17 | Iteration: 74 | Classification loss: 0.03293 | Regression loss: 0.14148 | Running loss: 0.24355\n",
      "Epoch: 17 | Iteration: 75 | Classification loss: 0.02544 | Regression loss: 0.13227 | Running loss: 0.24326\n",
      "Epoch: 17 | Iteration: 76 | Classification loss: 0.04424 | Regression loss: 0.15093 | Running loss: 0.24348\n",
      "Epoch: 17 | Iteration: 77 | Classification loss: 0.02185 | Regression loss: 0.15845 | Running loss: 0.24313\n",
      "Epoch: 17 | Iteration: 78 | Classification loss: 0.03692 | Regression loss: 0.22672 | Running loss: 0.24338\n",
      "Epoch: 17 | Iteration: 79 | Classification loss: 0.01154 | Regression loss: 0.12562 | Running loss: 0.24314\n",
      "Epoch: 17 | Iteration: 80 | Classification loss: 0.00857 | Regression loss: 0.13004 | Running loss: 0.24327\n",
      "Epoch: 17 | Iteration: 81 | Classification loss: 0.16172 | Regression loss: 0.29759 | Running loss: 0.24365\n",
      "Epoch: 17 | Iteration: 82 | Classification loss: 0.06785 | Regression loss: 0.14778 | Running loss: 0.24355\n",
      "Epoch: 17 | Iteration: 83 | Classification loss: 0.04545 | Regression loss: 0.23437 | Running loss: 0.24358\n",
      "Epoch: 17 | Iteration: 84 | Classification loss: 0.03264 | Regression loss: 0.15957 | Running loss: 0.24373\n",
      "Epoch: 17 | Iteration: 85 | Classification loss: 0.03660 | Regression loss: 0.09544 | Running loss: 0.24370\n",
      "Epoch: 17 | Iteration: 86 | Classification loss: 0.12987 | Regression loss: 0.27845 | Running loss: 0.24410\n",
      "Epoch: 17 | Iteration: 87 | Classification loss: 0.01867 | Regression loss: 0.17656 | Running loss: 0.24416\n",
      "Epoch: 17 | Iteration: 88 | Classification loss: 0.04196 | Regression loss: 0.11826 | Running loss: 0.24381\n",
      "Epoch: 17 | Iteration: 89 | Classification loss: 0.09601 | Regression loss: 0.24894 | Running loss: 0.24349\n",
      "Epoch: 17 | Iteration: 90 | Classification loss: 0.03676 | Regression loss: 0.21119 | Running loss: 0.24350\n",
      "Epoch: 17 | Iteration: 91 | Classification loss: 0.01226 | Regression loss: 0.10174 | Running loss: 0.24323\n",
      "Epoch: 17 | Iteration: 92 | Classification loss: 0.02519 | Regression loss: 0.13219 | Running loss: 0.24290\n",
      "Epoch: 17 | Iteration: 93 | Classification loss: 0.02793 | Regression loss: 0.08630 | Running loss: 0.24251\n",
      "Epoch: 17 | Iteration: 94 | Classification loss: 0.07850 | Regression loss: 0.20743 | Running loss: 0.24267\n",
      "Epoch: 17 | Iteration: 95 | Classification loss: 0.03295 | Regression loss: 0.25034 | Running loss: 0.24299\n",
      "Epoch: 17 | Iteration: 96 | Classification loss: 0.02346 | Regression loss: 0.12412 | Running loss: 0.24289\n",
      "Epoch: 17 | Iteration: 97 | Classification loss: 0.06490 | Regression loss: 0.30079 | Running loss: 0.24303\n",
      "Epoch: 17 | Iteration: 98 | Classification loss: 0.02676 | Regression loss: 0.07731 | Running loss: 0.24292\n",
      "Epoch: 17 | Iteration: 99 | Classification loss: 0.03354 | Regression loss: 0.17188 | Running loss: 0.24308\n",
      "Epoch: 17 | Iteration: 100 | Classification loss: 0.02278 | Regression loss: 0.21656 | Running loss: 0.24331\n",
      "Epoch: 17 | Iteration: 101 | Classification loss: 0.02213 | Regression loss: 0.12643 | Running loss: 0.24263\n",
      "Epoch: 17 | Iteration: 102 | Classification loss: 0.04032 | Regression loss: 0.29077 | Running loss: 0.24300\n",
      "Epoch: 17 | Iteration: 103 | Classification loss: 0.07912 | Regression loss: 0.19773 | Running loss: 0.24319\n",
      "Epoch: 17 | Iteration: 104 | Classification loss: 0.02612 | Regression loss: 0.10329 | Running loss: 0.24322\n",
      "Epoch: 17 | Iteration: 105 | Classification loss: 0.03570 | Regression loss: 0.19775 | Running loss: 0.24283\n",
      "Epoch: 17 | Iteration: 106 | Classification loss: 0.01150 | Regression loss: 0.12441 | Running loss: 0.24219\n",
      "Epoch: 17 | Iteration: 107 | Classification loss: 0.03081 | Regression loss: 0.16104 | Running loss: 0.24209\n",
      "Epoch: 17 | Iteration: 108 | Classification loss: 0.03695 | Regression loss: 0.18596 | Running loss: 0.24195\n",
      "Epoch: 17 | Iteration: 109 | Classification loss: 0.02100 | Regression loss: 0.13971 | Running loss: 0.24172\n",
      "Epoch: 17 | Iteration: 110 | Classification loss: 0.01915 | Regression loss: 0.14140 | Running loss: 0.24130\n",
      "Epoch: 17 | Iteration: 111 | Classification loss: 0.06909 | Regression loss: 0.38539 | Running loss: 0.24182\n",
      "Epoch: 17 | Iteration: 112 | Classification loss: 0.04634 | Regression loss: 0.19591 | Running loss: 0.24197\n",
      "Epoch: 17 | Iteration: 113 | Classification loss: 0.02229 | Regression loss: 0.16714 | Running loss: 0.24205\n",
      "Epoch: 17 | Iteration: 114 | Classification loss: 0.01852 | Regression loss: 0.14369 | Running loss: 0.24164\n",
      "Epoch: 17 | Iteration: 115 | Classification loss: 0.03991 | Regression loss: 0.17664 | Running loss: 0.24175\n",
      "Epoch: 17 | Iteration: 116 | Classification loss: 0.04761 | Regression loss: 0.21554 | Running loss: 0.24193\n",
      "Epoch: 17 | Iteration: 117 | Classification loss: 0.01833 | Regression loss: 0.10351 | Running loss: 0.24184\n",
      "Epoch: 17 | Iteration: 118 | Classification loss: 0.01432 | Regression loss: 0.11889 | Running loss: 0.24170\n",
      "Epoch: 17 | Iteration: 119 | Classification loss: 0.11494 | Regression loss: 0.22302 | Running loss: 0.24157\n",
      "Epoch: 17 | Iteration: 120 | Classification loss: 0.03067 | Regression loss: 0.20709 | Running loss: 0.24131\n",
      "Epoch: 17 | Iteration: 121 | Classification loss: 0.01506 | Regression loss: 0.17612 | Running loss: 0.24125\n",
      "Epoch: 17 | Iteration: 122 | Classification loss: 0.02779 | Regression loss: 0.20296 | Running loss: 0.24127\n",
      "Epoch: 17 | Iteration: 123 | Classification loss: 0.02800 | Regression loss: 0.26640 | Running loss: 0.24144\n",
      "Epoch: 17 | Iteration: 124 | Classification loss: 0.02980 | Regression loss: 0.14466 | Running loss: 0.24132\n",
      "Epoch: 17 | Iteration: 125 | Classification loss: 0.02097 | Regression loss: 0.08763 | Running loss: 0.24118\n",
      "Epoch: 17 | Iteration: 126 | Classification loss: 0.01922 | Regression loss: 0.12888 | Running loss: 0.24116\n",
      "Epoch: 17 | Iteration: 127 | Classification loss: 0.02163 | Regression loss: 0.12380 | Running loss: 0.24107\n",
      "Epoch: 17 | Iteration: 128 | Classification loss: 0.04841 | Regression loss: 0.22538 | Running loss: 0.24129\n",
      "Epoch: 17 | Iteration: 129 | Classification loss: 0.01860 | Regression loss: 0.09953 | Running loss: 0.24125\n",
      "Epoch: 17 | Iteration: 130 | Classification loss: 0.08605 | Regression loss: 0.30653 | Running loss: 0.24159\n",
      "Epoch: 17 | Iteration: 131 | Classification loss: 0.03944 | Regression loss: 0.26653 | Running loss: 0.24185\n",
      "Epoch: 17 | Iteration: 132 | Classification loss: 0.00926 | Regression loss: 0.07034 | Running loss: 0.24170\n",
      "Epoch: 17 | Iteration: 133 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.24135\n",
      "Epoch: 17 | Iteration: 134 | Classification loss: 0.06466 | Regression loss: 0.29719 | Running loss: 0.24172\n",
      "Epoch: 17 | Iteration: 135 | Classification loss: 0.01325 | Regression loss: 0.08547 | Running loss: 0.24141\n",
      "Epoch: 17 | Iteration: 136 | Classification loss: 0.04226 | Regression loss: 0.22621 | Running loss: 0.24151\n",
      "Epoch: 17 | Iteration: 137 | Classification loss: 0.04207 | Regression loss: 0.09456 | Running loss: 0.24114\n",
      "Epoch: 17 | Iteration: 138 | Classification loss: 0.04458 | Regression loss: 0.13558 | Running loss: 0.24047\n",
      "Epoch: 17 | Iteration: 139 | Classification loss: 0.07932 | Regression loss: 0.25497 | Running loss: 0.24092\n",
      "Epoch: 17 | Iteration: 140 | Classification loss: 0.00900 | Regression loss: 0.08160 | Running loss: 0.24091\n",
      "Epoch: 17 | Iteration: 141 | Classification loss: 0.09325 | Regression loss: 0.30173 | Running loss: 0.24143\n",
      "Epoch: 17 | Iteration: 142 | Classification loss: 0.01374 | Regression loss: 0.09997 | Running loss: 0.24141\n",
      "Epoch: 17 | Iteration: 143 | Classification loss: 0.06811 | Regression loss: 0.22671 | Running loss: 0.24167\n",
      "Epoch: 17 | Iteration: 144 | Classification loss: 0.17002 | Regression loss: 0.28338 | Running loss: 0.24203\n",
      "Epoch: 17 | Iteration: 145 | Classification loss: 0.09828 | Regression loss: 0.26087 | Running loss: 0.24244\n",
      "Epoch: 17 | Iteration: 146 | Classification loss: 0.02007 | Regression loss: 0.15036 | Running loss: 0.24252\n",
      "Epoch: 17 | Iteration: 147 | Classification loss: 0.04068 | Regression loss: 0.15827 | Running loss: 0.24187\n",
      "Epoch: 17 | Iteration: 148 | Classification loss: 0.03487 | Regression loss: 0.15512 | Running loss: 0.24194\n",
      "Epoch: 17 | Iteration: 149 | Classification loss: 0.12428 | Regression loss: 0.32268 | Running loss: 0.24235\n",
      "Epoch: 17 | Iteration: 150 | Classification loss: 0.01220 | Regression loss: 0.16642 | Running loss: 0.24224\n",
      "Epoch: 17 | Iteration: 151 | Classification loss: 0.02316 | Regression loss: 0.17377 | Running loss: 0.24229\n",
      "Epoch: 17 | Iteration: 152 | Classification loss: 0.16254 | Regression loss: 0.15806 | Running loss: 0.24244\n",
      "Epoch: 17 | Iteration: 153 | Classification loss: 0.02582 | Regression loss: 0.19016 | Running loss: 0.24252\n",
      "Epoch: 17 | Iteration: 154 | Classification loss: 0.07622 | Regression loss: 0.18599 | Running loss: 0.24226\n",
      "Epoch: 17 | Iteration: 155 | Classification loss: 0.02644 | Regression loss: 0.06557 | Running loss: 0.24222\n",
      "Epoch: 17 | Iteration: 156 | Classification loss: 0.01492 | Regression loss: 0.09034 | Running loss: 0.24216\n",
      "Epoch: 17 | Iteration: 157 | Classification loss: 0.11296 | Regression loss: 0.19417 | Running loss: 0.24245\n",
      "Epoch: 17 | Iteration: 158 | Classification loss: 0.03785 | Regression loss: 0.11749 | Running loss: 0.24157\n",
      "Epoch: 17 | Iteration: 159 | Classification loss: 0.02276 | Regression loss: 0.13911 | Running loss: 0.24157\n",
      "Epoch: 17 | Iteration: 160 | Classification loss: 0.01379 | Regression loss: 0.07766 | Running loss: 0.24129\n",
      "Epoch: 17 | Iteration: 161 | Classification loss: 0.05609 | Regression loss: 0.09345 | Running loss: 0.24131\n",
      "Epoch: 17 | Iteration: 162 | Classification loss: 0.01736 | Regression loss: 0.20693 | Running loss: 0.24112\n",
      "Epoch: 17 | Iteration: 163 | Classification loss: 0.05414 | Regression loss: 0.30640 | Running loss: 0.24155\n",
      "Epoch: 17 | Iteration: 164 | Classification loss: 0.01872 | Regression loss: 0.08613 | Running loss: 0.24101\n",
      "Epoch: 17 | Iteration: 165 | Classification loss: 0.00765 | Regression loss: 0.08794 | Running loss: 0.24078\n",
      "Epoch: 17 | Iteration: 166 | Classification loss: 0.03811 | Regression loss: 0.17918 | Running loss: 0.24056\n",
      "Epoch: 17 | Iteration: 167 | Classification loss: 0.02099 | Regression loss: 0.16244 | Running loss: 0.24048\n",
      "Epoch: 17 | Iteration: 168 | Classification loss: 0.03186 | Regression loss: 0.29106 | Running loss: 0.24066\n",
      "Epoch: 17 | Iteration: 169 | Classification loss: 0.01773 | Regression loss: 0.13422 | Running loss: 0.24060\n",
      "Epoch: 17 | Iteration: 170 | Classification loss: 0.07401 | Regression loss: 0.31550 | Running loss: 0.24080\n",
      "Epoch: 17 | Iteration: 171 | Classification loss: 0.04661 | Regression loss: 0.20253 | Running loss: 0.24103\n",
      "Epoch: 17 | Iteration: 172 | Classification loss: 0.04108 | Regression loss: 0.16289 | Running loss: 0.24065\n",
      "Epoch: 17 | Iteration: 173 | Classification loss: 0.01493 | Regression loss: 0.10002 | Running loss: 0.24008\n",
      "Epoch: 17 | Iteration: 174 | Classification loss: 0.03148 | Regression loss: 0.21319 | Running loss: 0.24014\n",
      "Epoch: 17 | Iteration: 175 | Classification loss: 0.02113 | Regression loss: 0.18825 | Running loss: 0.24022\n",
      "Epoch: 17 | Iteration: 176 | Classification loss: 0.01724 | Regression loss: 0.16031 | Running loss: 0.24034\n",
      "Epoch: 17 | Iteration: 177 | Classification loss: 0.01477 | Regression loss: 0.24334 | Running loss: 0.23979\n",
      "Epoch: 17 | Iteration: 178 | Classification loss: 0.05545 | Regression loss: 0.23158 | Running loss: 0.23963\n",
      "Epoch: 17 | Iteration: 179 | Classification loss: 0.03690 | Regression loss: 0.24218 | Running loss: 0.23991\n",
      "Epoch: 17 | Iteration: 180 | Classification loss: 0.02408 | Regression loss: 0.12266 | Running loss: 0.23987\n",
      "Epoch: 17 | Iteration: 181 | Classification loss: 0.05494 | Regression loss: 0.21362 | Running loss: 0.23970\n",
      "Epoch: 17 | Iteration: 182 | Classification loss: 0.02375 | Regression loss: 0.15450 | Running loss: 0.23960\n",
      "Epoch: 17 | Iteration: 183 | Classification loss: 0.02984 | Regression loss: 0.07472 | Running loss: 0.23966\n",
      "Epoch: 17 | Iteration: 184 | Classification loss: 0.01306 | Regression loss: 0.11983 | Running loss: 0.23963\n",
      "Epoch: 17 | Iteration: 185 | Classification loss: 0.01977 | Regression loss: 0.12725 | Running loss: 0.23914\n",
      "Epoch: 17 | Iteration: 186 | Classification loss: 0.11320 | Regression loss: 0.31342 | Running loss: 0.23983\n",
      "Epoch: 17 | Iteration: 187 | Classification loss: 0.01642 | Regression loss: 0.16675 | Running loss: 0.23985\n",
      "Epoch: 17 | Iteration: 188 | Classification loss: 0.04505 | Regression loss: 0.32173 | Running loss: 0.24003\n",
      "Epoch: 17 | Iteration: 189 | Classification loss: 0.02045 | Regression loss: 0.08341 | Running loss: 0.24000\n",
      "Epoch: 17 | Iteration: 190 | Classification loss: 0.01693 | Regression loss: 0.13537 | Running loss: 0.23957\n",
      "Epoch: 17 | Iteration: 191 | Classification loss: 0.03105 | Regression loss: 0.16730 | Running loss: 0.23932\n",
      "Epoch: 17 | Iteration: 192 | Classification loss: 0.02586 | Regression loss: 0.12473 | Running loss: 0.23903\n",
      "Epoch: 17 | Iteration: 193 | Classification loss: 0.04101 | Regression loss: 0.35108 | Running loss: 0.23921\n",
      "Epoch: 17 | Iteration: 194 | Classification loss: 0.01394 | Regression loss: 0.07769 | Running loss: 0.23906\n",
      "Epoch: 17 | Iteration: 195 | Classification loss: 0.00917 | Regression loss: 0.14453 | Running loss: 0.23892\n",
      "Epoch: 17 | Iteration: 196 | Classification loss: 0.02491 | Regression loss: 0.23021 | Running loss: 0.23921\n",
      "Epoch: 17 | Iteration: 197 | Classification loss: 0.03586 | Regression loss: 0.11037 | Running loss: 0.23915\n",
      "Epoch: 17 | Iteration: 198 | Classification loss: 0.05720 | Regression loss: 0.11564 | Running loss: 0.23918\n",
      "Epoch: 17 | Iteration: 199 | Classification loss: 0.05197 | Regression loss: 0.18170 | Running loss: 0.23914\n",
      "Epoch: 17 | Iteration: 200 | Classification loss: 0.05354 | Regression loss: 0.21288 | Running loss: 0.23908\n",
      "Epoch: 17 | Iteration: 201 | Classification loss: 0.00784 | Regression loss: 0.10345 | Running loss: 0.23861\n",
      "Epoch: 17 | Iteration: 202 | Classification loss: 0.03097 | Regression loss: 0.24337 | Running loss: 0.23871\n",
      "Epoch: 17 | Iteration: 203 | Classification loss: 0.06744 | Regression loss: 0.12803 | Running loss: 0.23818\n",
      "Epoch: 17 | Iteration: 204 | Classification loss: 0.01454 | Regression loss: 0.15260 | Running loss: 0.23816\n",
      "Epoch: 17 | Iteration: 205 | Classification loss: 0.10067 | Regression loss: 0.36576 | Running loss: 0.23886\n",
      "Epoch: 17 | Iteration: 206 | Classification loss: 0.03683 | Regression loss: 0.10698 | Running loss: 0.23862\n",
      "Epoch: 17 | Iteration: 207 | Classification loss: 0.02865 | Regression loss: 0.15451 | Running loss: 0.23828\n",
      "Epoch: 17 | Iteration: 208 | Classification loss: 0.02250 | Regression loss: 0.19930 | Running loss: 0.23848\n",
      "Epoch: 17 | Iteration: 209 | Classification loss: 0.13133 | Regression loss: 0.16942 | Running loss: 0.23866\n",
      "Epoch: 17 | Iteration: 210 | Classification loss: 0.05600 | Regression loss: 0.20224 | Running loss: 0.23854\n",
      "Epoch: 17 | Iteration: 211 | Classification loss: 0.00436 | Regression loss: 0.09762 | Running loss: 0.23832\n",
      "Epoch: 17 | Iteration: 212 | Classification loss: 0.03212 | Regression loss: 0.13054 | Running loss: 0.23765\n",
      "Epoch: 17 | Iteration: 213 | Classification loss: 0.03529 | Regression loss: 0.12405 | Running loss: 0.23716\n",
      "Epoch: 17 | Iteration: 214 | Classification loss: 0.11298 | Regression loss: 0.15207 | Running loss: 0.23707\n",
      "Epoch: 17 | Iteration: 215 | Classification loss: 0.02310 | Regression loss: 0.18088 | Running loss: 0.23720\n",
      "Epoch: 17 | Iteration: 216 | Classification loss: 0.02290 | Regression loss: 0.10903 | Running loss: 0.23716\n",
      "Epoch: 17 | Iteration: 217 | Classification loss: 0.07004 | Regression loss: 0.29258 | Running loss: 0.23717\n",
      "Epoch: 17 | Iteration: 218 | Classification loss: 0.01588 | Regression loss: 0.15923 | Running loss: 0.23701\n",
      "Epoch: 17 | Iteration: 219 | Classification loss: 0.01681 | Regression loss: 0.11781 | Running loss: 0.23673\n",
      "Epoch: 17 | Iteration: 220 | Classification loss: 0.02495 | Regression loss: 0.14558 | Running loss: 0.23668\n",
      "Epoch: 17 | Iteration: 221 | Classification loss: 0.01431 | Regression loss: 0.14380 | Running loss: 0.23608\n",
      "Epoch: 17 | Iteration: 222 | Classification loss: 0.03656 | Regression loss: 0.18903 | Running loss: 0.23560\n",
      "Epoch: 17 | Iteration: 223 | Classification loss: 0.16620 | Regression loss: 0.43444 | Running loss: 0.23641\n",
      "Epoch: 17 | Iteration: 224 | Classification loss: 0.01822 | Regression loss: 0.08498 | Running loss: 0.23596\n",
      "Epoch: 17 | Iteration: 225 | Classification loss: 0.10086 | Regression loss: 0.25720 | Running loss: 0.23621\n",
      "Epoch: 17 | Iteration: 226 | Classification loss: 0.02054 | Regression loss: 0.17703 | Running loss: 0.23615\n",
      "Epoch: 17 | Iteration: 227 | Classification loss: 0.05392 | Regression loss: 0.30835 | Running loss: 0.23630\n",
      "Epoch: 17 | Iteration: 228 | Classification loss: 0.06779 | Regression loss: 0.37546 | Running loss: 0.23598\n",
      "Epoch: 17 | Iteration: 229 | Classification loss: 0.01828 | Regression loss: 0.16707 | Running loss: 0.23581\n",
      "Epoch: 17 | Iteration: 230 | Classification loss: 0.02576 | Regression loss: 0.22039 | Running loss: 0.23571\n",
      "Epoch: 17 | Iteration: 231 | Classification loss: 0.06806 | Regression loss: 0.37889 | Running loss: 0.23618\n",
      "Epoch: 17 | Iteration: 232 | Classification loss: 0.04179 | Regression loss: 0.14692 | Running loss: 0.23554\n",
      "Epoch: 17 | Iteration: 233 | Classification loss: 0.03917 | Regression loss: 0.17843 | Running loss: 0.23516\n",
      "Epoch: 17 | Iteration: 234 | Classification loss: 0.02335 | Regression loss: 0.07718 | Running loss: 0.23493\n",
      "Epoch: 17 | Iteration: 235 | Classification loss: 0.12070 | Regression loss: 0.39462 | Running loss: 0.23538\n",
      "Epoch: 17 | Iteration: 236 | Classification loss: 0.23905 | Regression loss: 0.37528 | Running loss: 0.23631\n",
      "Epoch: 17 | Iteration: 237 | Classification loss: 0.04762 | Regression loss: 0.25161 | Running loss: 0.23667\n",
      "Epoch: 17 | Iteration: 238 | Classification loss: 0.09384 | Regression loss: 0.13799 | Running loss: 0.23671\n",
      "Epoch: 17 | Iteration: 239 | Classification loss: 0.00870 | Regression loss: 0.08467 | Running loss: 0.23638\n",
      "Epoch: 17 | Iteration: 240 | Classification loss: 0.09258 | Regression loss: 0.29499 | Running loss: 0.23654\n",
      "Epoch: 17 | Iteration: 241 | Classification loss: 0.02988 | Regression loss: 0.19137 | Running loss: 0.23664\n",
      "Epoch: 17 | Iteration: 242 | Classification loss: 0.03255 | Regression loss: 0.15961 | Running loss: 0.23661\n",
      "Epoch: 17 | Iteration: 243 | Classification loss: 0.03923 | Regression loss: 0.16640 | Running loss: 0.23671\n",
      "Epoch: 17 | Iteration: 244 | Classification loss: 0.03252 | Regression loss: 0.12542 | Running loss: 0.23670\n",
      "Epoch: 17 | Iteration: 245 | Classification loss: 0.06521 | Regression loss: 0.15429 | Running loss: 0.23691\n",
      "Epoch: 17 | Iteration: 246 | Classification loss: 0.03491 | Regression loss: 0.12745 | Running loss: 0.23684\n",
      "Epoch: 17 | Iteration: 247 | Classification loss: 0.06214 | Regression loss: 0.17106 | Running loss: 0.23694\n",
      "Epoch: 17 | Iteration: 248 | Classification loss: 0.06785 | Regression loss: 0.17730 | Running loss: 0.23683\n",
      "Epoch: 17 | Iteration: 249 | Classification loss: 0.05301 | Regression loss: 0.07891 | Running loss: 0.23645\n",
      "Epoch: 17 | Iteration: 250 | Classification loss: 0.03526 | Regression loss: 0.11535 | Running loss: 0.23642\n",
      "Epoch: 17 | Iteration: 251 | Classification loss: 0.02881 | Regression loss: 0.14476 | Running loss: 0.23553\n",
      "Epoch: 17 | Iteration: 252 | Classification loss: 0.05125 | Regression loss: 0.14584 | Running loss: 0.23534\n",
      "Epoch: 17 | Iteration: 253 | Classification loss: 0.04485 | Regression loss: 0.22731 | Running loss: 0.23518\n",
      "Epoch: 17 | Iteration: 254 | Classification loss: 0.05403 | Regression loss: 0.21148 | Running loss: 0.23539\n",
      "Epoch: 17 | Iteration: 255 | Classification loss: 0.01869 | Regression loss: 0.06963 | Running loss: 0.23461\n",
      "Epoch: 17 | Iteration: 256 | Classification loss: 0.05082 | Regression loss: 0.10030 | Running loss: 0.23435\n",
      "Epoch: 17 | Iteration: 257 | Classification loss: 0.04728 | Regression loss: 0.10610 | Running loss: 0.23406\n",
      "Epoch: 17 | Iteration: 258 | Classification loss: 0.05143 | Regression loss: 0.16460 | Running loss: 0.23391\n",
      "Epoch: 17 | Iteration: 259 | Classification loss: 0.02908 | Regression loss: 0.16399 | Running loss: 0.23380\n",
      "Epoch: 17 | Iteration: 260 | Classification loss: 0.01685 | Regression loss: 0.20583 | Running loss: 0.23368\n",
      "Epoch: 17 | Iteration: 261 | Classification loss: 0.03213 | Regression loss: 0.23140 | Running loss: 0.23375\n",
      "Epoch: 17 | Iteration: 262 | Classification loss: 0.04840 | Regression loss: 0.21467 | Running loss: 0.23398\n",
      "Epoch: 17 | Iteration: 263 | Classification loss: 0.19896 | Regression loss: 0.32038 | Running loss: 0.23458\n",
      "Epoch: 17 | Iteration: 264 | Classification loss: 0.00960 | Regression loss: 0.17303 | Running loss: 0.23451\n",
      "Epoch: 17 | Iteration: 265 | Classification loss: 0.02047 | Regression loss: 0.08797 | Running loss: 0.23448\n",
      "Epoch: 17 | Iteration: 266 | Classification loss: 0.01842 | Regression loss: 0.14133 | Running loss: 0.23455\n",
      "Epoch: 17 | Iteration: 267 | Classification loss: 0.00596 | Regression loss: 0.08289 | Running loss: 0.23445\n",
      "Epoch: 17 | Iteration: 268 | Classification loss: 0.06061 | Regression loss: 0.19464 | Running loss: 0.23437\n",
      "Epoch: 17 | Iteration: 269 | Classification loss: 0.02658 | Regression loss: 0.18726 | Running loss: 0.23440\n",
      "Epoch: 17 | Iteration: 270 | Classification loss: 0.03196 | Regression loss: 0.19895 | Running loss: 0.23438\n",
      "Epoch: 17 | Iteration: 271 | Classification loss: 0.08342 | Regression loss: 0.08665 | Running loss: 0.23446\n",
      "Epoch: 17 | Iteration: 272 | Classification loss: 0.09219 | Regression loss: 0.18358 | Running loss: 0.23484\n",
      "Epoch: 17 | Iteration: 273 | Classification loss: 0.02460 | Regression loss: 0.17790 | Running loss: 0.23423\n",
      "Epoch: 17 | Iteration: 274 | Classification loss: 0.02901 | Regression loss: 0.15698 | Running loss: 0.23421\n",
      "Epoch: 17 | Iteration: 275 | Classification loss: 0.02500 | Regression loss: 0.14315 | Running loss: 0.23423\n",
      "Epoch: 17 | Iteration: 276 | Classification loss: 0.03143 | Regression loss: 0.12687 | Running loss: 0.23345\n",
      "Epoch: 17 | Iteration: 277 | Classification loss: 0.01535 | Regression loss: 0.09978 | Running loss: 0.23326\n",
      "Epoch: 17 | Iteration: 278 | Classification loss: 0.11815 | Regression loss: 0.33899 | Running loss: 0.23370\n",
      "Epoch: 17 | Iteration: 279 | Classification loss: 0.07843 | Regression loss: 0.20974 | Running loss: 0.23398\n",
      "Epoch: 17 | Iteration: 280 | Classification loss: 0.05016 | Regression loss: 0.15319 | Running loss: 0.23370\n",
      "Epoch: 17 | Iteration: 281 | Classification loss: 0.05277 | Regression loss: 0.24778 | Running loss: 0.23354\n",
      "Epoch: 17 | Iteration: 282 | Classification loss: 0.03044 | Regression loss: 0.22131 | Running loss: 0.23360\n",
      "Epoch: 17 | Iteration: 283 | Classification loss: 0.05394 | Regression loss: 0.23496 | Running loss: 0.23388\n",
      "Epoch: 17 | Iteration: 284 | Classification loss: 0.05061 | Regression loss: 0.08270 | Running loss: 0.23341\n",
      "Epoch: 17 | Iteration: 285 | Classification loss: 0.01643 | Regression loss: 0.09247 | Running loss: 0.23316\n",
      "Epoch: 17 | Iteration: 286 | Classification loss: 0.03426 | Regression loss: 0.16330 | Running loss: 0.23316\n",
      "Epoch: 17 | Iteration: 287 | Classification loss: 0.09697 | Regression loss: 0.24948 | Running loss: 0.23357\n",
      "Epoch: 17 | Iteration: 288 | Classification loss: 0.06999 | Regression loss: 0.20009 | Running loss: 0.23357\n",
      "Epoch: 17 | Iteration: 289 | Classification loss: 0.05494 | Regression loss: 0.18220 | Running loss: 0.23370\n",
      "Epoch: 17 | Iteration: 290 | Classification loss: 0.06792 | Regression loss: 0.26801 | Running loss: 0.23418\n",
      "Epoch: 17 | Iteration: 291 | Classification loss: 0.03468 | Regression loss: 0.15242 | Running loss: 0.23424\n",
      "Epoch: 17 | Iteration: 292 | Classification loss: 0.15563 | Regression loss: 0.34626 | Running loss: 0.23463\n",
      "Epoch: 17 | Iteration: 293 | Classification loss: 0.04110 | Regression loss: 0.20530 | Running loss: 0.23431\n",
      "Epoch: 17 | Iteration: 294 | Classification loss: 0.02213 | Regression loss: 0.09092 | Running loss: 0.23421\n",
      "Epoch: 17 | Iteration: 295 | Classification loss: 0.08951 | Regression loss: 0.34524 | Running loss: 0.23474\n",
      "Epoch: 17 | Iteration: 296 | Classification loss: 0.05914 | Regression loss: 0.21099 | Running loss: 0.23492\n",
      "Epoch: 17 | Iteration: 297 | Classification loss: 0.03230 | Regression loss: 0.17903 | Running loss: 0.23485\n",
      "Epoch: 17 | Iteration: 298 | Classification loss: 0.03380 | Regression loss: 0.20418 | Running loss: 0.23485\n",
      "Epoch: 17 | Iteration: 299 | Classification loss: 0.01107 | Regression loss: 0.09234 | Running loss: 0.23480\n",
      "Epoch: 17 | Iteration: 300 | Classification loss: 0.10375 | Regression loss: 0.19404 | Running loss: 0.23507\n",
      "Epoch: 17 | Iteration: 301 | Classification loss: 0.03305 | Regression loss: 0.11419 | Running loss: 0.23512\n",
      "Epoch: 17 | Iteration: 302 | Classification loss: 0.04365 | Regression loss: 0.21835 | Running loss: 0.23494\n",
      "Epoch: 17 | Iteration: 303 | Classification loss: 0.10230 | Regression loss: 0.05023 | Running loss: 0.23490\n",
      "Epoch: 17 | Iteration: 304 | Classification loss: 0.00931 | Regression loss: 0.06295 | Running loss: 0.23478\n",
      "Epoch: 17 | Iteration: 305 | Classification loss: 0.05529 | Regression loss: 0.07051 | Running loss: 0.23437\n",
      "Epoch: 17 | Iteration: 306 | Classification loss: 0.07410 | Regression loss: 0.22160 | Running loss: 0.23470\n",
      "Epoch: 17 | Iteration: 307 | Classification loss: 0.01725 | Regression loss: 0.10296 | Running loss: 0.23414\n",
      "Epoch: 17 | Iteration: 308 | Classification loss: 0.01364 | Regression loss: 0.13171 | Running loss: 0.23407\n",
      "Epoch: 17 | Iteration: 309 | Classification loss: 0.03681 | Regression loss: 0.23514 | Running loss: 0.23398\n",
      "Epoch: 17 | Iteration: 310 | Classification loss: 0.03227 | Regression loss: 0.12522 | Running loss: 0.23385\n",
      "Epoch: 17 | Iteration: 311 | Classification loss: 0.01847 | Regression loss: 0.19956 | Running loss: 0.23406\n",
      "Epoch: 17 | Iteration: 312 | Classification loss: 0.02163 | Regression loss: 0.19028 | Running loss: 0.23391\n",
      "Epoch: 17 | Iteration: 313 | Classification loss: 0.03897 | Regression loss: 0.21268 | Running loss: 0.23386\n",
      "Epoch: 17 | Iteration: 314 | Classification loss: 0.01094 | Regression loss: 0.17097 | Running loss: 0.23370\n",
      "Epoch: 17 | Iteration: 315 | Classification loss: 0.09554 | Regression loss: 0.26050 | Running loss: 0.23416\n",
      "Epoch: 17 | Iteration: 316 | Classification loss: 0.06133 | Regression loss: 0.19870 | Running loss: 0.23379\n",
      "Epoch: 17 | Iteration: 317 | Classification loss: 0.02686 | Regression loss: 0.18969 | Running loss: 0.23373\n",
      "Epoch: 17 | Iteration: 318 | Classification loss: 0.02132 | Regression loss: 0.16139 | Running loss: 0.23364\n",
      "Epoch: 17 | Iteration: 319 | Classification loss: 0.04118 | Regression loss: 0.23986 | Running loss: 0.23397\n",
      "Epoch: 17 | Iteration: 320 | Classification loss: 0.01967 | Regression loss: 0.13474 | Running loss: 0.23405\n",
      "Epoch: 17 | Iteration: 321 | Classification loss: 0.01814 | Regression loss: 0.14086 | Running loss: 0.23369\n",
      "Epoch: 17 | Iteration: 322 | Classification loss: 0.01846 | Regression loss: 0.14575 | Running loss: 0.23346\n",
      "Epoch: 17 | Iteration: 323 | Classification loss: 0.03170 | Regression loss: 0.27667 | Running loss: 0.23381\n",
      "Epoch: 17 | Iteration: 324 | Classification loss: 0.01871 | Regression loss: 0.18787 | Running loss: 0.23345\n",
      "Epoch: 17 | Iteration: 325 | Classification loss: 0.04043 | Regression loss: 0.24428 | Running loss: 0.23334\n",
      "Epoch: 17 | Iteration: 326 | Classification loss: 0.01596 | Regression loss: 0.17111 | Running loss: 0.23327\n",
      "Epoch: 17 | Iteration: 327 | Classification loss: 0.01919 | Regression loss: 0.22457 | Running loss: 0.23338\n",
      "Epoch: 17 | Iteration: 328 | Classification loss: 0.05035 | Regression loss: 0.15161 | Running loss: 0.23352\n",
      "Epoch: 17 | Iteration: 329 | Classification loss: 0.13449 | Regression loss: 0.32883 | Running loss: 0.23401\n",
      "Epoch: 17 | Iteration: 330 | Classification loss: 0.02178 | Regression loss: 0.15298 | Running loss: 0.23357\n",
      "Epoch: 17 | Iteration: 331 | Classification loss: 0.03804 | Regression loss: 0.13375 | Running loss: 0.23344\n",
      "Epoch: 17 | Iteration: 332 | Classification loss: 0.03704 | Regression loss: 0.15714 | Running loss: 0.23358\n",
      "Epoch: 17 | Iteration: 333 | Classification loss: 0.01085 | Regression loss: 0.11306 | Running loss: 0.23347\n",
      "Epoch: 17 | Iteration: 334 | Classification loss: 0.04396 | Regression loss: 0.23237 | Running loss: 0.23371\n",
      "Epoch: 17 | Iteration: 335 | Classification loss: 0.39131 | Regression loss: 0.46883 | Running loss: 0.23422\n",
      "Epoch: 17 | Iteration: 336 | Classification loss: 0.02649 | Regression loss: 0.21830 | Running loss: 0.23448\n",
      "Epoch: 17 | Iteration: 337 | Classification loss: 0.01586 | Regression loss: 0.11728 | Running loss: 0.23441\n",
      "Epoch: 17 | Iteration: 338 | Classification loss: 0.07189 | Regression loss: 0.32457 | Running loss: 0.23494\n",
      "Epoch: 17 | Iteration: 339 | Classification loss: 0.03057 | Regression loss: 0.20774 | Running loss: 0.23487\n",
      "Epoch: 17 | Iteration: 340 | Classification loss: 0.02517 | Regression loss: 0.18919 | Running loss: 0.23509\n",
      "Epoch: 17 | Iteration: 341 | Classification loss: 0.02860 | Regression loss: 0.03935 | Running loss: 0.23491\n",
      "Epoch: 17 | Iteration: 342 | Classification loss: 0.02639 | Regression loss: 0.17667 | Running loss: 0.23515\n",
      "Epoch: 17 | Iteration: 343 | Classification loss: 0.08602 | Regression loss: 0.14156 | Running loss: 0.23536\n",
      "Epoch: 17 | Iteration: 344 | Classification loss: 0.01971 | Regression loss: 0.18035 | Running loss: 0.23546\n",
      "Epoch: 17 | Iteration: 345 | Classification loss: 0.02250 | Regression loss: 0.14413 | Running loss: 0.23557\n",
      "Epoch: 17 | Iteration: 346 | Classification loss: 0.02171 | Regression loss: 0.15930 | Running loss: 0.23548\n",
      "Epoch: 17 | Iteration: 347 | Classification loss: 0.02110 | Regression loss: 0.14291 | Running loss: 0.23532\n",
      "Epoch: 17 | Iteration: 348 | Classification loss: 0.01221 | Regression loss: 0.15466 | Running loss: 0.23536\n",
      "Epoch: 17 | Iteration: 349 | Classification loss: 0.01119 | Regression loss: 0.08970 | Running loss: 0.23507\n",
      "Epoch: 17 | Iteration: 350 | Classification loss: 0.01073 | Regression loss: 0.10461 | Running loss: 0.23456\n",
      "Epoch: 17 | Iteration: 351 | Classification loss: 0.03607 | Regression loss: 0.18048 | Running loss: 0.23382\n",
      "Epoch: 17 | Iteration: 352 | Classification loss: 0.02644 | Regression loss: 0.14041 | Running loss: 0.23374\n",
      "Epoch: 17 | Iteration: 353 | Classification loss: 0.01664 | Regression loss: 0.15115 | Running loss: 0.23364\n",
      "Epoch: 17 | Iteration: 354 | Classification loss: 0.15176 | Regression loss: 0.40534 | Running loss: 0.23410\n",
      "Epoch: 17 | Iteration: 355 | Classification loss: 0.04601 | Regression loss: 0.21942 | Running loss: 0.23425\n",
      "Epoch: 17 | Iteration: 356 | Classification loss: 0.02935 | Regression loss: 0.14899 | Running loss: 0.23403\n",
      "Epoch: 17 | Iteration: 357 | Classification loss: 0.05368 | Regression loss: 0.19491 | Running loss: 0.23373\n",
      "Epoch: 17 | Iteration: 358 | Classification loss: 0.00943 | Regression loss: 0.06595 | Running loss: 0.23338\n",
      "Epoch: 17 | Iteration: 359 | Classification loss: 0.04431 | Regression loss: 0.06737 | Running loss: 0.23323\n",
      "Epoch: 17 | Iteration: 360 | Classification loss: 0.02564 | Regression loss: 0.22394 | Running loss: 0.23342\n",
      "Epoch: 17 | Iteration: 361 | Classification loss: 0.01051 | Regression loss: 0.13361 | Running loss: 0.23333\n",
      "Epoch: 17 | Iteration: 362 | Classification loss: 0.07353 | Regression loss: 0.24551 | Running loss: 0.23375\n",
      "Epoch: 17 | Iteration: 363 | Classification loss: 0.03668 | Regression loss: 0.17389 | Running loss: 0.23387\n",
      "Epoch: 17 | Iteration: 364 | Classification loss: 0.02349 | Regression loss: 0.21274 | Running loss: 0.23392\n",
      "Epoch: 17 | Iteration: 365 | Classification loss: 0.02716 | Regression loss: 0.12774 | Running loss: 0.23374\n",
      "Epoch: 17 | Iteration: 366 | Classification loss: 0.04051 | Regression loss: 0.21063 | Running loss: 0.23373\n",
      "Epoch: 17 | Iteration: 367 | Classification loss: 0.04137 | Regression loss: 0.25545 | Running loss: 0.23359\n",
      "Epoch: 17 | Iteration: 368 | Classification loss: 0.08232 | Regression loss: 0.23210 | Running loss: 0.23401\n",
      "Epoch: 17 | Iteration: 369 | Classification loss: 0.05028 | Regression loss: 0.24024 | Running loss: 0.23429\n",
      "Epoch: 17 | Iteration: 370 | Classification loss: 0.02387 | Regression loss: 0.14617 | Running loss: 0.23439\n",
      "Epoch: 17 | Iteration: 371 | Classification loss: 0.07873 | Regression loss: 0.29753 | Running loss: 0.23482\n",
      "Epoch: 17 | Iteration: 372 | Classification loss: 0.01192 | Regression loss: 0.15268 | Running loss: 0.23490\n",
      "Epoch: 17 | Iteration: 373 | Classification loss: 0.02186 | Regression loss: 0.12937 | Running loss: 0.23470\n",
      "Epoch: 17 | Iteration: 374 | Classification loss: 0.04701 | Regression loss: 0.15179 | Running loss: 0.23476\n",
      "Epoch: 17 | Iteration: 375 | Classification loss: 0.17491 | Regression loss: 0.43321 | Running loss: 0.23575\n",
      "Epoch: 17 | Iteration: 376 | Classification loss: 0.01278 | Regression loss: 0.10050 | Running loss: 0.23551\n",
      "Epoch: 17 | Iteration: 377 | Classification loss: 0.02931 | Regression loss: 0.14718 | Running loss: 0.23553\n",
      "Epoch: 17 | Iteration: 378 | Classification loss: 0.01812 | Regression loss: 0.14562 | Running loss: 0.23544\n",
      "Epoch: 17 | Iteration: 379 | Classification loss: 0.05644 | Regression loss: 0.23071 | Running loss: 0.23579\n",
      "Epoch: 17 | Iteration: 380 | Classification loss: 0.15917 | Regression loss: 0.38432 | Running loss: 0.23655\n",
      "Epoch: 17 | Iteration: 381 | Classification loss: 0.05762 | Regression loss: 0.24379 | Running loss: 0.23680\n",
      "Epoch: 17 | Iteration: 382 | Classification loss: 0.09723 | Regression loss: 0.29078 | Running loss: 0.23708\n",
      "Epoch: 17 | Iteration: 383 | Classification loss: 0.01035 | Regression loss: 0.08729 | Running loss: 0.23656\n",
      "Epoch: 17 | Iteration: 384 | Classification loss: 0.18512 | Regression loss: 0.38546 | Running loss: 0.23677\n",
      "Epoch: 17 | Iteration: 385 | Classification loss: 0.00892 | Regression loss: 0.06977 | Running loss: 0.23629\n",
      "Epoch: 17 | Iteration: 386 | Classification loss: 0.06128 | Regression loss: 0.21662 | Running loss: 0.23617\n",
      "Epoch: 17 | Iteration: 387 | Classification loss: 0.04718 | Regression loss: 0.18219 | Running loss: 0.23623\n",
      "Epoch: 17 | Iteration: 388 | Classification loss: 0.03726 | Regression loss: 0.18278 | Running loss: 0.23607\n",
      "Epoch: 17 | Iteration: 389 | Classification loss: 0.04012 | Regression loss: 0.12945 | Running loss: 0.23608\n",
      "Epoch: 17 | Iteration: 390 | Classification loss: 0.03011 | Regression loss: 0.20243 | Running loss: 0.23628\n",
      "Epoch: 17 | Iteration: 391 | Classification loss: 0.00505 | Regression loss: 0.11493 | Running loss: 0.23620\n",
      "Epoch: 17 | Iteration: 392 | Classification loss: 0.05811 | Regression loss: 0.16013 | Running loss: 0.23621\n",
      "Epoch: 17 | Iteration: 393 | Classification loss: 0.07016 | Regression loss: 0.19228 | Running loss: 0.23631\n",
      "Epoch: 17 | Iteration: 394 | Classification loss: 0.12786 | Regression loss: 0.25692 | Running loss: 0.23667\n",
      "Epoch: 17 | Iteration: 395 | Classification loss: 0.01471 | Regression loss: 0.30364 | Running loss: 0.23685\n",
      "Epoch: 17 | Iteration: 396 | Classification loss: 0.03905 | Regression loss: 0.13378 | Running loss: 0.23684\n",
      "Epoch: 17 | Iteration: 397 | Classification loss: 0.29716 | Regression loss: 0.40203 | Running loss: 0.23797\n",
      "Epoch: 17 | Iteration: 398 | Classification loss: 0.01957 | Regression loss: 0.25123 | Running loss: 0.23819\n",
      "Epoch: 17 | Iteration: 399 | Classification loss: 0.05753 | Regression loss: 0.22801 | Running loss: 0.23791\n",
      "Epoch: 17 | Iteration: 400 | Classification loss: 0.01315 | Regression loss: 0.09222 | Running loss: 0.23782\n",
      "Epoch: 17 | Iteration: 401 | Classification loss: 0.22265 | Regression loss: 0.07917 | Running loss: 0.23806\n",
      "Epoch: 17 | Iteration: 402 | Classification loss: 0.04066 | Regression loss: 0.10919 | Running loss: 0.23792\n",
      "Epoch: 17 | Iteration: 403 | Classification loss: 0.08505 | Regression loss: 0.19448 | Running loss: 0.23814\n",
      "Epoch: 17 | Iteration: 404 | Classification loss: 0.02861 | Regression loss: 0.20720 | Running loss: 0.23807\n",
      "Epoch: 17 | Iteration: 405 | Classification loss: 0.02750 | Regression loss: 0.21735 | Running loss: 0.23811\n",
      "Epoch: 17 | Iteration: 406 | Classification loss: 0.02652 | Regression loss: 0.12484 | Running loss: 0.23803\n",
      "Epoch: 17 | Iteration: 407 | Classification loss: 0.03410 | Regression loss: 0.17983 | Running loss: 0.23804\n",
      "Epoch: 17 | Iteration: 408 | Classification loss: 0.01992 | Regression loss: 0.14420 | Running loss: 0.23801\n",
      "Epoch: 17 | Iteration: 409 | Classification loss: 0.14547 | Regression loss: 0.16341 | Running loss: 0.23806\n",
      "Epoch: 17 | Iteration: 410 | Classification loss: 0.06709 | Regression loss: 0.20995 | Running loss: 0.23837\n",
      "Epoch: 17 | Iteration: 411 | Classification loss: 0.26496 | Regression loss: 0.32892 | Running loss: 0.23938\n",
      "Epoch: 17 | Iteration: 412 | Classification loss: 0.08990 | Regression loss: 0.40069 | Running loss: 0.24019\n",
      "Epoch: 17 | Iteration: 413 | Classification loss: 0.01810 | Regression loss: 0.19786 | Running loss: 0.24021\n",
      "Epoch: 17 | Iteration: 414 | Classification loss: 0.01682 | Regression loss: 0.16254 | Running loss: 0.24023\n",
      "Epoch: 17 | Iteration: 415 | Classification loss: 0.86716 | Regression loss: 0.08618 | Running loss: 0.24150\n",
      "Epoch: 17 | Iteration: 416 | Classification loss: 0.02171 | Regression loss: 0.09590 | Running loss: 0.24131\n",
      "Epoch: 17 | Iteration: 417 | Classification loss: 0.03228 | Regression loss: 0.16417 | Running loss: 0.24146\n",
      "Epoch: 17 | Iteration: 418 | Classification loss: 0.06350 | Regression loss: 0.14545 | Running loss: 0.24125\n",
      "Epoch: 17 | Iteration: 419 | Classification loss: 0.01347 | Regression loss: 0.10989 | Running loss: 0.24127\n",
      "Epoch: 17 | Iteration: 420 | Classification loss: 0.23187 | Regression loss: 0.19226 | Running loss: 0.24163\n",
      "Epoch: 17 | Iteration: 421 | Classification loss: 0.06520 | Regression loss: 0.15454 | Running loss: 0.24188\n",
      "Epoch: 17 | Iteration: 422 | Classification loss: 0.06517 | Regression loss: 0.26694 | Running loss: 0.24219\n",
      "Epoch: 17 | Iteration: 423 | Classification loss: 0.05673 | Regression loss: 0.23799 | Running loss: 0.24258\n",
      "Epoch: 17 | Iteration: 424 | Classification loss: 0.04196 | Regression loss: 0.16370 | Running loss: 0.24224\n",
      "Epoch: 17 | Iteration: 425 | Classification loss: 0.00717 | Regression loss: 0.04913 | Running loss: 0.24185\n",
      "Epoch: 17 | Iteration: 426 | Classification loss: 0.00675 | Regression loss: 0.09413 | Running loss: 0.24146\n",
      "Epoch: 17 | Iteration: 427 | Classification loss: 0.02399 | Regression loss: 0.11577 | Running loss: 0.24103\n",
      "Epoch: 17 | Iteration: 428 | Classification loss: 0.04727 | Regression loss: 0.09917 | Running loss: 0.24088\n",
      "Epoch: 17 | Iteration: 429 | Classification loss: 0.04506 | Regression loss: 0.20136 | Running loss: 0.24062\n",
      "Epoch: 17 | Iteration: 430 | Classification loss: 0.10919 | Regression loss: 0.32135 | Running loss: 0.24081\n",
      "Epoch: 17 | Iteration: 431 | Classification loss: 0.02654 | Regression loss: 0.18908 | Running loss: 0.24093\n",
      "Epoch: 17 | Iteration: 432 | Classification loss: 0.04913 | Regression loss: 0.21942 | Running loss: 0.24109\n",
      "Epoch: 17 | Iteration: 433 | Classification loss: 0.11487 | Regression loss: 0.10818 | Running loss: 0.24111\n",
      "Epoch: 17 | Iteration: 434 | Classification loss: 0.01555 | Regression loss: 0.09649 | Running loss: 0.24025\n",
      "Epoch: 17 | Iteration: 435 | Classification loss: 0.04877 | Regression loss: 0.10135 | Running loss: 0.23995\n",
      "Epoch: 17 | Iteration: 436 | Classification loss: 0.02045 | Regression loss: 0.13516 | Running loss: 0.23997\n",
      "Epoch: 17 | Iteration: 437 | Classification loss: 0.03451 | Regression loss: 0.22026 | Running loss: 0.24010\n",
      "Epoch: 17 | Iteration: 438 | Classification loss: 0.04061 | Regression loss: 0.12324 | Running loss: 0.24003\n",
      "Epoch: 17 | Iteration: 439 | Classification loss: 0.04903 | Regression loss: 0.11132 | Running loss: 0.24004\n",
      "Epoch: 17 | Iteration: 440 | Classification loss: 0.06247 | Regression loss: 0.22411 | Running loss: 0.24017\n",
      "Epoch: 17 | Iteration: 441 | Classification loss: 0.01880 | Regression loss: 0.08653 | Running loss: 0.24013\n",
      "Epoch: 17 | Iteration: 442 | Classification loss: 0.03418 | Regression loss: 0.22522 | Running loss: 0.23984\n",
      "Epoch: 17 | Iteration: 443 | Classification loss: 0.01013 | Regression loss: 0.04607 | Running loss: 0.23977\n",
      "Epoch: 17 | Iteration: 444 | Classification loss: 0.05840 | Regression loss: 0.20567 | Running loss: 0.23983\n",
      "Epoch: 17 | Iteration: 445 | Classification loss: 0.01392 | Regression loss: 0.12496 | Running loss: 0.23930\n",
      "Epoch: 17 | Iteration: 446 | Classification loss: 0.03983 | Regression loss: 0.27417 | Running loss: 0.23920\n",
      "Epoch: 17 | Iteration: 447 | Classification loss: 0.00412 | Regression loss: 0.07486 | Running loss: 0.23911\n",
      "Epoch: 17 | Iteration: 448 | Classification loss: 0.18105 | Regression loss: 0.20141 | Running loss: 0.23946\n",
      "Epoch: 17 | Iteration: 449 | Classification loss: 0.07535 | Regression loss: 0.14896 | Running loss: 0.23947\n",
      "Epoch: 17 | Iteration: 450 | Classification loss: 0.04167 | Regression loss: 0.15051 | Running loss: 0.23939\n",
      "Epoch: 17 | Iteration: 451 | Classification loss: 0.01525 | Regression loss: 0.11907 | Running loss: 0.23909\n",
      "Epoch: 17 | Iteration: 452 | Classification loss: 0.01236 | Regression loss: 0.13857 | Running loss: 0.23907\n",
      "Epoch: 17 | Iteration: 453 | Classification loss: 0.13186 | Regression loss: 0.18217 | Running loss: 0.23923\n",
      "Epoch: 17 | Iteration: 454 | Classification loss: 0.01890 | Regression loss: 0.15450 | Running loss: 0.23872\n",
      "Epoch: 17 | Iteration: 455 | Classification loss: 0.04564 | Regression loss: 0.09843 | Running loss: 0.23857\n",
      "Epoch: 17 | Iteration: 456 | Classification loss: 0.04335 | Regression loss: 0.20172 | Running loss: 0.23834\n",
      "Epoch: 17 | Iteration: 457 | Classification loss: 0.11330 | Regression loss: 0.26750 | Running loss: 0.23869\n",
      "Epoch: 17 | Iteration: 458 | Classification loss: 0.05203 | Regression loss: 0.14514 | Running loss: 0.23842\n",
      "Epoch: 17 | Iteration: 459 | Classification loss: 0.04762 | Regression loss: 0.19168 | Running loss: 0.23826\n",
      "Epoch: 17 | Iteration: 460 | Classification loss: 0.08841 | Regression loss: 0.06741 | Running loss: 0.23813\n",
      "Epoch: 17 | Iteration: 461 | Classification loss: 0.06282 | Regression loss: 0.35443 | Running loss: 0.23865\n",
      "Epoch: 17 | Iteration: 462 | Classification loss: 0.03861 | Regression loss: 0.17077 | Running loss: 0.23827\n",
      "Epoch: 17 | Iteration: 463 | Classification loss: 0.04135 | Regression loss: 0.14888 | Running loss: 0.23822\n",
      "Epoch: 17 | Iteration: 464 | Classification loss: 0.04537 | Regression loss: 0.12364 | Running loss: 0.23828\n",
      "Epoch: 17 | Iteration: 465 | Classification loss: 0.04432 | Regression loss: 0.11454 | Running loss: 0.23745\n",
      "Epoch: 17 | Iteration: 466 | Classification loss: 0.04505 | Regression loss: 0.30051 | Running loss: 0.23769\n",
      "Epoch: 17 | Iteration: 467 | Classification loss: 0.02224 | Regression loss: 0.13327 | Running loss: 0.23740\n",
      "Epoch: 17 | Iteration: 468 | Classification loss: 0.01394 | Regression loss: 0.05979 | Running loss: 0.23644\n",
      "Epoch: 17 | Iteration: 469 | Classification loss: 0.02483 | Regression loss: 0.08214 | Running loss: 0.23462\n",
      "Epoch: 17 | Iteration: 470 | Classification loss: 0.02567 | Regression loss: 0.15548 | Running loss: 0.23471\n",
      "Epoch: 17 | Iteration: 471 | Classification loss: 0.04670 | Regression loss: 0.23789 | Running loss: 0.23481\n",
      "Epoch: 17 | Iteration: 472 | Classification loss: 0.15157 | Regression loss: 0.10086 | Running loss: 0.23503\n",
      "Epoch: 17 | Iteration: 473 | Classification loss: 0.00618 | Regression loss: 0.08955 | Running loss: 0.23478\n",
      "Epoch: 17 | Iteration: 474 | Classification loss: 0.11209 | Regression loss: 0.39900 | Running loss: 0.23538\n",
      "Epoch: 17 | Iteration: 475 | Classification loss: 0.02959 | Regression loss: 0.12973 | Running loss: 0.23531\n",
      "Epoch: 17 | Iteration: 476 | Classification loss: 0.07255 | Regression loss: 0.23294 | Running loss: 0.23547\n",
      "Epoch: 17 | Iteration: 477 | Classification loss: 0.12001 | Regression loss: 0.19670 | Running loss: 0.23533\n",
      "Epoch: 17 | Iteration: 478 | Classification loss: 0.02384 | Regression loss: 0.17731 | Running loss: 0.23522\n",
      "Epoch: 17 | Iteration: 479 | Classification loss: 0.03057 | Regression loss: 0.19465 | Running loss: 0.23521\n",
      "Epoch: 17 | Iteration: 480 | Classification loss: 0.03567 | Regression loss: 0.19167 | Running loss: 0.23443\n",
      "Epoch: 17 | Iteration: 481 | Classification loss: 0.03289 | Regression loss: 0.21174 | Running loss: 0.23452\n",
      "Epoch: 17 | Iteration: 482 | Classification loss: 0.01581 | Regression loss: 0.11985 | Running loss: 0.23452\n",
      "Epoch: 17 | Iteration: 483 | Classification loss: 0.01414 | Regression loss: 0.12070 | Running loss: 0.23453\n",
      "Epoch: 17 | Iteration: 484 | Classification loss: 0.01875 | Regression loss: 0.11035 | Running loss: 0.23446\n",
      "Epoch: 17 | Iteration: 485 | Classification loss: 0.05633 | Regression loss: 0.10763 | Running loss: 0.23409\n",
      "Epoch: 17 | Iteration: 486 | Classification loss: 0.03488 | Regression loss: 0.24357 | Running loss: 0.23407\n",
      "Epoch: 17 | Iteration: 487 | Classification loss: 0.03317 | Regression loss: 0.10958 | Running loss: 0.23435\n",
      "Epoch: 17 | Iteration: 488 | Classification loss: 0.04204 | Regression loss: 0.32112 | Running loss: 0.23435\n",
      "Epoch: 17 | Iteration: 489 | Classification loss: 0.01279 | Regression loss: 0.17700 | Running loss: 0.23425\n",
      "Epoch: 17 | Iteration: 490 | Classification loss: 0.03655 | Regression loss: 0.17512 | Running loss: 0.23392\n",
      "Epoch: 17 | Iteration: 491 | Classification loss: 0.01994 | Regression loss: 0.16057 | Running loss: 0.23406\n",
      "Epoch: 17 | Iteration: 492 | Classification loss: 0.04263 | Regression loss: 0.14468 | Running loss: 0.23387\n",
      "Epoch: 17 | Iteration: 493 | Classification loss: 0.05348 | Regression loss: 0.09638 | Running loss: 0.23367\n",
      "Epoch: 17 | Iteration: 494 | Classification loss: 0.02216 | Regression loss: 0.17925 | Running loss: 0.23362\n",
      "Epoch: 17 | Iteration: 495 | Classification loss: 0.07058 | Regression loss: 0.26397 | Running loss: 0.23388\n",
      "Epoch: 17 | Iteration: 496 | Classification loss: 0.02591 | Regression loss: 0.13912 | Running loss: 0.23377\n",
      "Epoch: 17 | Iteration: 497 | Classification loss: 0.02479 | Regression loss: 0.14399 | Running loss: 0.23243\n",
      "Epoch: 17 | Iteration: 498 | Classification loss: 0.00936 | Regression loss: 0.12819 | Running loss: 0.23183\n",
      "Epoch: 17 | Iteration: 499 | Classification loss: 0.01307 | Regression loss: 0.11429 | Running loss: 0.23129\n",
      "Epoch: 17 | Iteration: 500 | Classification loss: 0.03170 | Regression loss: 0.22260 | Running loss: 0.23165\n",
      "Epoch: 17 | Iteration: 501 | Classification loss: 0.02005 | Regression loss: 0.14961 | Running loss: 0.23180\n",
      "Epoch: 17 | Iteration: 502 | Classification loss: 0.04894 | Regression loss: 0.24448 | Running loss: 0.23174\n",
      "Epoch: 17 | Iteration: 503 | Classification loss: 0.10867 | Regression loss: 0.22307 | Running loss: 0.23216\n",
      "Epoch: 17 | Iteration: 504 | Classification loss: 0.02071 | Regression loss: 0.18997 | Running loss: 0.23206\n",
      "Epoch: 17 | Iteration: 505 | Classification loss: 0.06906 | Regression loss: 0.27024 | Running loss: 0.23231\n",
      "Epoch: 17 | Iteration: 506 | Classification loss: 0.02489 | Regression loss: 0.17151 | Running loss: 0.23232\n",
      "Epoch: 17 | Iteration: 507 | Classification loss: 0.02647 | Regression loss: 0.14963 | Running loss: 0.23235\n",
      "Epoch: 17 | Iteration: 508 | Classification loss: 0.03065 | Regression loss: 0.17805 | Running loss: 0.23234\n",
      "Epoch: 17 | Iteration: 509 | Classification loss: 0.04422 | Regression loss: 0.12571 | Running loss: 0.23208\n",
      "Epoch: 17 | Iteration: 510 | Classification loss: 0.19431 | Regression loss: 0.39318 | Running loss: 0.23276\n",
      "Epoch: 17 | Iteration: 511 | Classification loss: 0.00558 | Regression loss: 0.06263 | Running loss: 0.23240\n",
      "Epoch: 17 | Iteration: 512 | Classification loss: 0.07854 | Regression loss: 0.32243 | Running loss: 0.23294\n",
      "Epoch: 17 | Iteration: 513 | Classification loss: 0.01857 | Regression loss: 0.11879 | Running loss: 0.23282\n",
      "Epoch: 17 | Iteration: 514 | Classification loss: 0.09799 | Regression loss: 0.11923 | Running loss: 0.23273\n",
      "Epoch: 17 | Iteration: 515 | Classification loss: 0.01877 | Regression loss: 0.12302 | Running loss: 0.23225\n",
      "Epoch: 17 | Iteration: 516 | Classification loss: 0.05916 | Regression loss: 0.33158 | Running loss: 0.23277\n",
      "Epoch: 17 | Iteration: 517 | Classification loss: 0.02636 | Regression loss: 0.07819 | Running loss: 0.23240\n",
      "Epoch: 17 | Iteration: 518 | Classification loss: 0.01491 | Regression loss: 0.04907 | Running loss: 0.23229\n",
      "Epoch: 17 | Iteration: 519 | Classification loss: 0.02759 | Regression loss: 0.23889 | Running loss: 0.23255\n",
      "Epoch: 17 | Iteration: 520 | Classification loss: 0.07021 | Regression loss: 0.27483 | Running loss: 0.23299\n",
      "Epoch: 17 | Iteration: 521 | Classification loss: 0.01064 | Regression loss: 0.09000 | Running loss: 0.23242\n",
      "Epoch: 17 | Iteration: 522 | Classification loss: 0.04310 | Regression loss: 0.07156 | Running loss: 0.23203\n",
      "Epoch: 17 | Iteration: 523 | Classification loss: 0.04189 | Regression loss: 0.11195 | Running loss: 0.23210\n",
      "Epoch: 17 | Iteration: 524 | Classification loss: 0.01634 | Regression loss: 0.18364 | Running loss: 0.23169\n",
      "Epoch: 17 | Iteration: 525 | Classification loss: 0.02092 | Regression loss: 0.10110 | Running loss: 0.23152\n",
      "Epoch: 17 | Iteration: 526 | Classification loss: 0.01410 | Regression loss: 0.10681 | Running loss: 0.23144\n",
      "Epoch: 17 | Iteration: 527 | Classification loss: 0.01598 | Regression loss: 0.13356 | Running loss: 0.23121\n",
      "Epoch: 17 | Iteration: 528 | Classification loss: 0.06787 | Regression loss: 0.31495 | Running loss: 0.23093\n",
      "Epoch: 17 | Iteration: 529 | Classification loss: 0.22873 | Regression loss: 0.39328 | Running loss: 0.23149\n",
      "Epoch: 17 | Iteration: 530 | Classification loss: 0.02363 | Regression loss: 0.12953 | Running loss: 0.23136\n",
      "Epoch: 17 | Iteration: 531 | Classification loss: 0.02316 | Regression loss: 0.14727 | Running loss: 0.23143\n",
      "Epoch: 17 | Iteration: 532 | Classification loss: 0.02940 | Regression loss: 0.20692 | Running loss: 0.23162\n",
      "Epoch: 17 | Iteration: 533 | Classification loss: 0.01258 | Regression loss: 0.13015 | Running loss: 0.23157\n",
      "Epoch: 17 | Iteration: 534 | Classification loss: 0.11028 | Regression loss: 0.45650 | Running loss: 0.23271\n",
      "Epoch: 17 | Iteration: 535 | Classification loss: 0.03987 | Regression loss: 0.23833 | Running loss: 0.23106\n",
      "Epoch: 17 | Iteration: 536 | Classification loss: 0.03446 | Regression loss: 0.12940 | Running loss: 0.23103\n",
      "Epoch: 17 | Iteration: 537 | Classification loss: 0.16947 | Regression loss: 0.25691 | Running loss: 0.23110\n",
      "Epoch: 17 | Iteration: 538 | Classification loss: 0.04058 | Regression loss: 0.18119 | Running loss: 0.23022\n",
      "Epoch: 17 | Iteration: 539 | Classification loss: 0.02292 | Regression loss: 0.23507 | Running loss: 0.23036\n",
      "Epoch: 17 | Iteration: 540 | Classification loss: 0.01076 | Regression loss: 0.11672 | Running loss: 0.23030\n",
      "Epoch: 17 | Iteration: 541 | Classification loss: 0.05432 | Regression loss: 0.34001 | Running loss: 0.23074\n",
      "Epoch: 17 | Iteration: 542 | Classification loss: 0.03275 | Regression loss: 0.14154 | Running loss: 0.23057\n",
      "Epoch: 17 | Iteration: 543 | Classification loss: 0.40378 | Regression loss: 0.19332 | Running loss: 0.23136\n",
      "Epoch: 17 | Iteration: 544 | Classification loss: 0.04336 | Regression loss: 0.21558 | Running loss: 0.23158\n",
      "Epoch: 17 | Iteration: 545 | Classification loss: 0.01122 | Regression loss: 0.11570 | Running loss: 0.23124\n",
      "Epoch: 17 | Iteration: 546 | Classification loss: 0.03042 | Regression loss: 0.08305 | Running loss: 0.23119\n",
      "Epoch: 17 | Iteration: 547 | Classification loss: 0.11604 | Regression loss: 0.29568 | Running loss: 0.23127\n",
      "Epoch: 17 | Iteration: 548 | Classification loss: 0.06319 | Regression loss: 0.10601 | Running loss: 0.23094\n",
      "Epoch: 17 | Iteration: 549 | Classification loss: 0.02565 | Regression loss: 0.21127 | Running loss: 0.23067\n",
      "Epoch: 17 | Iteration: 550 | Classification loss: 0.03082 | Regression loss: 0.19961 | Running loss: 0.23082\n",
      "Epoch: 17 | Iteration: 551 | Classification loss: 0.08123 | Regression loss: 0.17928 | Running loss: 0.23077\n",
      "Epoch: 17 | Iteration: 552 | Classification loss: 0.14245 | Regression loss: 0.28139 | Running loss: 0.23140\n",
      "Epoch: 17 | Iteration: 553 | Classification loss: 0.01311 | Regression loss: 0.11315 | Running loss: 0.23131\n",
      "Epoch: 17 | Iteration: 554 | Classification loss: 0.02739 | Regression loss: 0.12587 | Running loss: 0.23128\n",
      "Epoch: 17 | Iteration: 555 | Classification loss: 0.01074 | Regression loss: 0.17291 | Running loss: 0.23131\n",
      "Epoch: 17 | Iteration: 556 | Classification loss: 0.02065 | Regression loss: 0.12224 | Running loss: 0.23073\n",
      "Epoch: 17 | Iteration: 557 | Classification loss: 0.02961 | Regression loss: 0.15448 | Running loss: 0.23057\n",
      "Epoch: 17 | Iteration: 558 | Classification loss: 0.01993 | Regression loss: 0.11886 | Running loss: 0.23069\n",
      "Epoch: 17 | Iteration: 559 | Classification loss: 0.02068 | Regression loss: 0.07895 | Running loss: 0.23043\n",
      "Epoch: 17 | Iteration: 560 | Classification loss: 0.06421 | Regression loss: 0.26102 | Running loss: 0.23090\n",
      "Epoch: 17 | Iteration: 561 | Classification loss: 0.05925 | Regression loss: 0.34208 | Running loss: 0.23129\n",
      "Epoch: 17 | Iteration: 562 | Classification loss: 0.01696 | Regression loss: 0.09034 | Running loss: 0.23112\n",
      "Epoch: 17 | Iteration: 563 | Classification loss: 0.37373 | Regression loss: 0.23633 | Running loss: 0.23149\n",
      "Epoch: 17 | Iteration: 564 | Classification loss: 0.01903 | Regression loss: 0.13774 | Running loss: 0.23114\n",
      "Epoch: 17 | Iteration: 565 | Classification loss: 0.05486 | Regression loss: 0.20624 | Running loss: 0.23105\n",
      "Epoch: 17 | Iteration: 566 | Classification loss: 0.00736 | Regression loss: 0.09749 | Running loss: 0.23039\n",
      "Epoch: 17 | Iteration: 567 | Classification loss: 0.03084 | Regression loss: 0.15273 | Running loss: 0.22975\n",
      "Epoch: 17 | Iteration: 568 | Classification loss: 0.01546 | Regression loss: 0.14588 | Running loss: 0.22938\n",
      "Epoch: 17 | Iteration: 569 | Classification loss: 0.02874 | Regression loss: 0.19152 | Running loss: 0.22931\n",
      "Epoch: 17 | Iteration: 570 | Classification loss: 0.02809 | Regression loss: 0.10085 | Running loss: 0.22921\n",
      "Epoch: 17 | Iteration: 571 | Classification loss: 0.03850 | Regression loss: 0.24822 | Running loss: 0.22958\n",
      "Epoch: 17 | Iteration: 572 | Classification loss: 0.03383 | Regression loss: 0.16661 | Running loss: 0.22964\n",
      "Epoch: 17 | Iteration: 573 | Classification loss: 0.03418 | Regression loss: 0.15157 | Running loss: 0.22926\n",
      "Epoch: 17 | Iteration: 574 | Classification loss: 0.04915 | Regression loss: 0.10679 | Running loss: 0.22923\n",
      "Epoch: 17 | Iteration: 575 | Classification loss: 0.06784 | Regression loss: 0.23132 | Running loss: 0.22951\n",
      "Epoch: 17 | Iteration: 576 | Classification loss: 0.02881 | Regression loss: 0.27325 | Running loss: 0.22972\n",
      "Epoch: 17 | Iteration: 577 | Classification loss: 0.01101 | Regression loss: 0.14282 | Running loss: 0.22967\n",
      "Epoch: 17 | Iteration: 578 | Classification loss: 0.05624 | Regression loss: 0.10955 | Running loss: 0.22947\n",
      "Epoch: 17 | Iteration: 579 | Classification loss: 0.03391 | Regression loss: 0.15187 | Running loss: 0.22957\n",
      "Epoch: 17 | Iteration: 580 | Classification loss: 0.05766 | Regression loss: 0.29815 | Running loss: 0.23001\n",
      "Epoch: 17 | Iteration: 581 | Classification loss: 0.03335 | Regression loss: 0.31869 | Running loss: 0.22979\n",
      "Epoch: 17 | Iteration: 582 | Classification loss: 0.21244 | Regression loss: 0.41315 | Running loss: 0.23061\n",
      "Epoch: 17 | Iteration: 583 | Classification loss: 0.04049 | Regression loss: 0.24661 | Running loss: 0.23063\n",
      "Epoch: 17 | Iteration: 584 | Classification loss: 0.03943 | Regression loss: 0.15689 | Running loss: 0.23063\n",
      "Epoch: 17 | Iteration: 585 | Classification loss: 0.03866 | Regression loss: 0.25235 | Running loss: 0.23095\n",
      "Epoch: 17 | Iteration: 586 | Classification loss: 0.06702 | Regression loss: 0.08252 | Running loss: 0.23043\n",
      "Epoch: 17 | Iteration: 587 | Classification loss: 0.19277 | Regression loss: 0.10348 | Running loss: 0.23064\n",
      "Epoch: 17 | Iteration: 588 | Classification loss: 0.12516 | Regression loss: 0.19838 | Running loss: 0.23096\n",
      "Epoch: 17 | Iteration: 589 | Classification loss: 0.01593 | Regression loss: 0.08977 | Running loss: 0.23048\n",
      "Epoch: 17 | Iteration: 590 | Classification loss: 0.00434 | Regression loss: 0.03995 | Running loss: 0.23008\n",
      "Epoch: 17 | Iteration: 591 | Classification loss: 0.03773 | Regression loss: 0.12432 | Running loss: 0.23017\n",
      "Epoch: 17 | Iteration: 592 | Classification loss: 0.03884 | Regression loss: 0.25374 | Running loss: 0.23044\n",
      "Epoch: 17 | Iteration: 593 | Classification loss: 0.05895 | Regression loss: 0.10381 | Running loss: 0.23054\n",
      "Epoch: 17 | Iteration: 594 | Classification loss: 0.05791 | Regression loss: 0.34295 | Running loss: 0.23077\n",
      "Epoch: 17 | Iteration: 595 | Classification loss: 0.02569 | Regression loss: 0.10044 | Running loss: 0.23046\n",
      "Epoch: 17 | Iteration: 596 | Classification loss: 0.06393 | Regression loss: 0.12741 | Running loss: 0.23054\n",
      "Epoch: 17 | Iteration: 597 | Classification loss: 0.02413 | Regression loss: 0.14256 | Running loss: 0.23015\n",
      "Epoch: 17 | Iteration: 598 | Classification loss: 0.03700 | Regression loss: 0.40851 | Running loss: 0.23083\n",
      "Epoch: 17 | Iteration: 599 | Classification loss: 0.03171 | Regression loss: 0.10867 | Running loss: 0.23070\n",
      "Epoch: 17 | Iteration: 600 | Classification loss: 0.04478 | Regression loss: 0.27739 | Running loss: 0.23086\n",
      "Epoch: 17 | Iteration: 601 | Classification loss: 0.03417 | Regression loss: 0.08253 | Running loss: 0.23080\n",
      "Epoch: 17 | Iteration: 602 | Classification loss: 0.03297 | Regression loss: 0.20733 | Running loss: 0.23062\n",
      "Epoch: 17 | Iteration: 603 | Classification loss: 0.12647 | Regression loss: 0.31511 | Running loss: 0.23095\n",
      "Epoch: 17 | Iteration: 604 | Classification loss: 0.13431 | Regression loss: 0.25418 | Running loss: 0.23147\n",
      "Epoch: 17 | Iteration: 605 | Classification loss: 0.10108 | Regression loss: 0.36638 | Running loss: 0.23193\n",
      "Epoch: 17 | Iteration: 606 | Classification loss: 0.04094 | Regression loss: 0.09994 | Running loss: 0.23194\n",
      "Epoch: 17 | Iteration: 607 | Classification loss: 0.25743 | Regression loss: 0.11430 | Running loss: 0.23230\n",
      "Epoch: 17 | Iteration: 608 | Classification loss: 0.04095 | Regression loss: 0.20562 | Running loss: 0.23235\n",
      "Epoch: 17 | Iteration: 609 | Classification loss: 0.02392 | Regression loss: 0.11185 | Running loss: 0.23230\n",
      "Epoch: 17 | Iteration: 610 | Classification loss: 0.02220 | Regression loss: 0.20375 | Running loss: 0.23243\n",
      "Epoch: 17 | Iteration: 611 | Classification loss: 0.11936 | Regression loss: 0.36067 | Running loss: 0.23248\n",
      "Epoch: 17 | Iteration: 612 | Classification loss: 0.04035 | Regression loss: 0.14841 | Running loss: 0.23238\n",
      "Epoch: 17 | Iteration: 613 | Classification loss: 0.02928 | Regression loss: 0.16337 | Running loss: 0.23238\n",
      "Epoch: 17 | Iteration: 614 | Classification loss: 0.01751 | Regression loss: 0.14888 | Running loss: 0.23239\n",
      "Epoch: 17 | Iteration: 615 | Classification loss: 0.16092 | Regression loss: 0.26803 | Running loss: 0.23282\n",
      "Epoch: 17 | Iteration: 616 | Classification loss: 0.91035 | Regression loss: 0.05125 | Running loss: 0.23421\n",
      "Epoch: 17 | Iteration: 617 | Classification loss: 0.04750 | Regression loss: 0.18987 | Running loss: 0.23444\n",
      "Epoch: 17 | Iteration: 618 | Classification loss: 0.08198 | Regression loss: 0.18756 | Running loss: 0.23472\n",
      "Epoch: 17 | Iteration: 619 | Classification loss: 0.06061 | Regression loss: 0.17256 | Running loss: 0.23451\n",
      "Epoch: 17 | Iteration: 620 | Classification loss: 0.03950 | Regression loss: 0.16578 | Running loss: 0.23444\n",
      "Epoch: 17 | Iteration: 621 | Classification loss: 0.01913 | Regression loss: 0.17238 | Running loss: 0.23444\n",
      "Epoch: 17 | Iteration: 622 | Classification loss: 0.02102 | Regression loss: 0.07536 | Running loss: 0.23417\n",
      "Epoch: 17 | Iteration: 623 | Classification loss: 0.03404 | Regression loss: 0.14327 | Running loss: 0.23394\n",
      "Epoch: 17 | Iteration: 624 | Classification loss: 0.08050 | Regression loss: 0.30330 | Running loss: 0.23436\n",
      "Epoch: 17 | Iteration: 625 | Classification loss: 0.06283 | Regression loss: 0.21183 | Running loss: 0.23469\n",
      "Epoch: 17 | Iteration: 626 | Classification loss: 0.03040 | Regression loss: 0.28514 | Running loss: 0.23503\n",
      "Epoch: 17 | Iteration: 627 | Classification loss: 0.03932 | Regression loss: 0.10236 | Running loss: 0.23502\n",
      "Epoch: 17 | Iteration: 628 | Classification loss: 0.09320 | Regression loss: 0.18314 | Running loss: 0.23502\n",
      "Epoch: 17 | Iteration: 629 | Classification loss: 0.16183 | Regression loss: 0.17746 | Running loss: 0.23547\n",
      "Epoch: 17 | Iteration: 630 | Classification loss: 0.03127 | Regression loss: 0.09865 | Running loss: 0.23494\n",
      "Epoch: 17 | Iteration: 631 | Classification loss: 0.00817 | Regression loss: 0.07010 | Running loss: 0.23449\n",
      "Epoch: 17 | Iteration: 632 | Classification loss: 0.04960 | Regression loss: 0.13989 | Running loss: 0.23471\n",
      "Epoch: 17 | Iteration: 633 | Classification loss: 0.01269 | Regression loss: 0.14245 | Running loss: 0.23502\n",
      "Epoch: 17 | Iteration: 634 | Classification loss: 0.06440 | Regression loss: 0.18579 | Running loss: 0.23479\n",
      "Epoch: 17 | Iteration: 635 | Classification loss: 0.10931 | Regression loss: 0.11120 | Running loss: 0.23504\n",
      "Epoch: 17 | Iteration: 636 | Classification loss: 0.08302 | Regression loss: 0.24531 | Running loss: 0.23516\n",
      "Epoch: 17 | Iteration: 637 | Classification loss: 0.03827 | Regression loss: 0.14392 | Running loss: 0.23525\n",
      "Epoch: 17 | Iteration: 638 | Classification loss: 0.25466 | Regression loss: 0.12180 | Running loss: 0.23564\n",
      "Epoch: 17 | Iteration: 639 | Classification loss: 0.05264 | Regression loss: 0.20383 | Running loss: 0.23548\n",
      "Epoch: 17 | Iteration: 640 | Classification loss: 0.02865 | Regression loss: 0.18381 | Running loss: 0.23573\n",
      "Epoch: 17 | Iteration: 641 | Classification loss: 0.11582 | Regression loss: 0.32372 | Running loss: 0.23582\n",
      "Epoch: 17 | Iteration: 642 | Classification loss: 0.02167 | Regression loss: 0.12627 | Running loss: 0.23588\n",
      "Epoch: 17 | Iteration: 643 | Classification loss: 0.07803 | Regression loss: 0.23367 | Running loss: 0.23592\n",
      "Epoch: 17 | Iteration: 644 | Classification loss: 0.02301 | Regression loss: 0.15742 | Running loss: 0.23537\n",
      "Epoch: 17 | Iteration: 645 | Classification loss: 0.10309 | Regression loss: 0.18345 | Running loss: 0.23523\n",
      "Epoch: 17 | Iteration: 646 | Classification loss: 0.04049 | Regression loss: 0.16267 | Running loss: 0.23529\n",
      "Epoch: 17 | Iteration: 647 | Classification loss: 0.93688 | Regression loss: 0.20930 | Running loss: 0.23719\n",
      "Epoch: 17 | Iteration: 648 | Classification loss: 0.08897 | Regression loss: 0.15638 | Running loss: 0.23730\n",
      "Epoch: 17 | Iteration: 649 | Classification loss: 0.02609 | Regression loss: 0.22137 | Running loss: 0.23690\n",
      "Epoch: 17 | Iteration: 650 | Classification loss: 0.00465 | Regression loss: 0.09682 | Running loss: 0.23674\n",
      "Epoch: 17 | Iteration: 651 | Classification loss: 0.02140 | Regression loss: 0.24574 | Running loss: 0.23689\n",
      "Epoch: 17 | Iteration: 652 | Classification loss: 0.02857 | Regression loss: 0.22093 | Running loss: 0.23674\n",
      "Epoch: 17 | Iteration: 653 | Classification loss: 0.01842 | Regression loss: 0.09000 | Running loss: 0.23653\n",
      "Epoch: 17 | Iteration: 654 | Classification loss: 0.08463 | Regression loss: 0.05457 | Running loss: 0.23628\n",
      "Epoch: 17 | Iteration: 655 | Classification loss: 0.02034 | Regression loss: 0.11875 | Running loss: 0.23638\n",
      "Epoch: 17 | Iteration: 656 | Classification loss: 0.01466 | Regression loss: 0.13008 | Running loss: 0.23645\n",
      "Epoch: 17 | Iteration: 657 | Classification loss: 0.02000 | Regression loss: 0.14682 | Running loss: 0.23617\n",
      "Epoch: 17 | Iteration: 658 | Classification loss: 0.04131 | Regression loss: 0.25180 | Running loss: 0.23645\n",
      "Epoch: 17 | Iteration: 659 | Classification loss: 0.03129 | Regression loss: 0.20018 | Running loss: 0.23659\n",
      "Epoch: 17 | Iteration: 660 | Classification loss: 0.01451 | Regression loss: 0.07183 | Running loss: 0.23658\n",
      "Epoch: 17 | Iteration: 661 | Classification loss: 0.01103 | Regression loss: 0.13178 | Running loss: 0.23657\n",
      "Epoch: 17 | Iteration: 662 | Classification loss: 0.02966 | Regression loss: 0.13011 | Running loss: 0.23644\n",
      "Epoch: 17 | Iteration: 663 | Classification loss: 0.03409 | Regression loss: 0.13550 | Running loss: 0.23605\n",
      "Epoch: 17 | Iteration: 664 | Classification loss: 0.06697 | Regression loss: 0.19500 | Running loss: 0.23637\n",
      "Epoch: 17 | Iteration: 665 | Classification loss: 0.08890 | Regression loss: 0.36588 | Running loss: 0.23709\n",
      "Epoch: 17 | Iteration: 666 | Classification loss: 0.02178 | Regression loss: 0.17822 | Running loss: 0.23705\n",
      "Epoch: 17 | Iteration: 667 | Classification loss: 0.04645 | Regression loss: 0.16326 | Running loss: 0.23710\n",
      "Epoch: 17 | Iteration: 668 | Classification loss: 0.00637 | Regression loss: 0.09360 | Running loss: 0.23666\n",
      "Epoch: 17 | Iteration: 669 | Classification loss: 0.04473 | Regression loss: 0.15510 | Running loss: 0.23675\n",
      "Epoch: 17 | Iteration: 670 | Classification loss: 0.00681 | Regression loss: 0.06653 | Running loss: 0.23612\n",
      "Epoch: 17 | Iteration: 671 | Classification loss: 0.02654 | Regression loss: 0.07744 | Running loss: 0.23583\n",
      "Epoch: 17 | Iteration: 672 | Classification loss: 0.01853 | Regression loss: 0.11800 | Running loss: 0.23570\n",
      "Epoch: 17 | Iteration: 673 | Classification loss: 0.01735 | Regression loss: 0.20929 | Running loss: 0.23592\n",
      "Epoch: 17 | Iteration: 674 | Classification loss: 0.09489 | Regression loss: 0.19978 | Running loss: 0.23602\n",
      "Epoch: 17 | Iteration: 675 | Classification loss: 0.01396 | Regression loss: 0.07147 | Running loss: 0.23577\n",
      "Epoch: 17 | Iteration: 676 | Classification loss: 0.01766 | Regression loss: 0.15987 | Running loss: 0.23577\n",
      "Epoch: 17 | Iteration: 677 | Classification loss: 0.05177 | Regression loss: 0.17817 | Running loss: 0.23572\n",
      "Epoch: 17 | Iteration: 678 | Classification loss: 0.01599 | Regression loss: 0.17454 | Running loss: 0.23552\n",
      "Epoch: 17 | Iteration: 679 | Classification loss: 0.04320 | Regression loss: 0.17756 | Running loss: 0.23541\n",
      "Epoch: 17 | Iteration: 680 | Classification loss: 0.07421 | Regression loss: 0.33566 | Running loss: 0.23593\n",
      "Epoch: 17 | Iteration: 681 | Classification loss: 0.11768 | Regression loss: 0.18479 | Running loss: 0.23600\n",
      "Epoch: 17 | Iteration: 682 | Classification loss: 0.03357 | Regression loss: 0.12641 | Running loss: 0.23596\n",
      "Epoch: 17 | Iteration: 683 | Classification loss: 0.03670 | Regression loss: 0.21711 | Running loss: 0.23626\n",
      "Epoch: 17 | Iteration: 684 | Classification loss: 0.05560 | Regression loss: 0.16249 | Running loss: 0.23643\n",
      "Epoch: 17 | Iteration: 685 | Classification loss: 0.02860 | Regression loss: 0.20308 | Running loss: 0.23660\n",
      "Epoch: 17 | Iteration: 686 | Classification loss: 0.01804 | Regression loss: 0.13098 | Running loss: 0.23605\n",
      "Epoch: 17 | Iteration: 687 | Classification loss: 0.03384 | Regression loss: 0.10694 | Running loss: 0.23596\n",
      "Epoch: 17 | Iteration: 688 | Classification loss: 0.05438 | Regression loss: 0.20780 | Running loss: 0.23575\n",
      "Epoch: 17 | Iteration: 689 | Classification loss: 0.00961 | Regression loss: 0.11744 | Running loss: 0.23580\n",
      "Epoch: 17 | Iteration: 690 | Classification loss: 0.11342 | Regression loss: 0.21572 | Running loss: 0.23615\n",
      "Epoch: 17 | Iteration: 691 | Classification loss: 0.04208 | Regression loss: 0.15628 | Running loss: 0.23615\n",
      "Epoch: 17 | Iteration: 692 | Classification loss: 0.00402 | Regression loss: 0.10351 | Running loss: 0.23607\n",
      "Epoch: 17 | Iteration: 693 | Classification loss: 0.25540 | Regression loss: 0.16052 | Running loss: 0.23611\n",
      "Epoch: 17 | Iteration: 694 | Classification loss: 0.11188 | Regression loss: 0.28542 | Running loss: 0.23673\n",
      "Epoch: 17 | Iteration: 695 | Classification loss: 0.05119 | Regression loss: 0.17086 | Running loss: 0.23686\n",
      "Epoch: 17 | Iteration: 696 | Classification loss: 0.05303 | Regression loss: 0.17802 | Running loss: 0.23681\n",
      "Epoch: 17 | Iteration: 697 | Classification loss: 0.04777 | Regression loss: 0.14425 | Running loss: 0.23691\n",
      "Epoch: 17 | Iteration: 698 | Classification loss: 0.01399 | Regression loss: 0.11682 | Running loss: 0.23682\n",
      "Epoch: 17 | Iteration: 699 | Classification loss: 0.05795 | Regression loss: 0.21158 | Running loss: 0.23689\n",
      "Epoch: 17 | Iteration: 700 | Classification loss: 0.04071 | Regression loss: 0.10002 | Running loss: 0.23664\n",
      "Epoch: 17 | Iteration: 701 | Classification loss: 0.20491 | Regression loss: 0.36829 | Running loss: 0.23757\n",
      "Epoch: 17 | Iteration: 702 | Classification loss: 0.03934 | Regression loss: 0.10732 | Running loss: 0.23731\n",
      "Epoch: 17 | Iteration: 703 | Classification loss: 0.01817 | Regression loss: 0.15464 | Running loss: 0.23727\n",
      "Epoch: 17 | Iteration: 704 | Classification loss: 0.01749 | Regression loss: 0.14891 | Running loss: 0.23726\n",
      "Epoch: 17 | Iteration: 705 | Classification loss: 0.05562 | Regression loss: 0.22077 | Running loss: 0.23688\n",
      "Epoch: 17 | Iteration: 706 | Classification loss: 0.08072 | Regression loss: 0.19702 | Running loss: 0.23715\n",
      "Epoch: 17 | Iteration: 707 | Classification loss: 0.17825 | Regression loss: 0.34500 | Running loss: 0.23783\n",
      "Epoch: 17 | Iteration: 708 | Classification loss: 0.00935 | Regression loss: 0.07207 | Running loss: 0.23755\n",
      "Epoch: 17 | Iteration: 709 | Classification loss: 0.08654 | Regression loss: 0.14976 | Running loss: 0.23742\n",
      "Epoch: 17 | Iteration: 710 | Classification loss: 0.01519 | Regression loss: 0.17787 | Running loss: 0.23729\n",
      "Epoch: 17 | Iteration: 711 | Classification loss: 0.03927 | Regression loss: 0.21995 | Running loss: 0.23761\n",
      "Epoch: 17 | Iteration: 712 | Classification loss: 0.01117 | Regression loss: 0.08078 | Running loss: 0.23747\n",
      "Epoch: 17 | Iteration: 713 | Classification loss: 0.11084 | Regression loss: 0.29740 | Running loss: 0.23796\n",
      "Epoch: 17 | Iteration: 714 | Classification loss: 0.01250 | Regression loss: 0.10588 | Running loss: 0.23767\n",
      "Epoch: 17 | Iteration: 715 | Classification loss: 0.04526 | Regression loss: 0.26110 | Running loss: 0.23787\n",
      "Epoch: 17 | Iteration: 716 | Classification loss: 0.06996 | Regression loss: 0.22579 | Running loss: 0.23820\n",
      "Epoch: 17 | Iteration: 717 | Classification loss: 0.10099 | Regression loss: 0.24745 | Running loss: 0.23817\n",
      "Epoch: 17 | Iteration: 718 | Classification loss: 0.01747 | Regression loss: 0.09479 | Running loss: 0.23805\n",
      "Epoch: 17 | Iteration: 719 | Classification loss: 0.05584 | Regression loss: 0.18094 | Running loss: 0.23825\n",
      "Epoch: 17 | Iteration: 720 | Classification loss: 0.10007 | Regression loss: 0.35824 | Running loss: 0.23883\n",
      "Epoch: 17 | Iteration: 721 | Classification loss: 0.05064 | Regression loss: 0.15877 | Running loss: 0.23893\n",
      "Epoch: 17 | Iteration: 722 | Classification loss: 0.05322 | Regression loss: 0.22113 | Running loss: 0.23903\n",
      "Epoch: 17 | Iteration: 723 | Classification loss: 0.04528 | Regression loss: 0.22304 | Running loss: 0.23836\n",
      "Epoch: 17 | Iteration: 724 | Classification loss: 0.10223 | Regression loss: 0.35339 | Running loss: 0.23907\n",
      "Epoch: 17 | Iteration: 725 | Classification loss: 0.02942 | Regression loss: 0.11371 | Running loss: 0.23864\n",
      "Epoch: 17 | Iteration: 726 | Classification loss: 0.07846 | Regression loss: 0.24108 | Running loss: 0.23888\n",
      "Epoch: 17 | Iteration: 727 | Classification loss: 0.05835 | Regression loss: 0.16446 | Running loss: 0.23860\n",
      "Epoch: 17 | Iteration: 728 | Classification loss: 0.02300 | Regression loss: 0.23591 | Running loss: 0.23823\n",
      "Epoch: 17 | Iteration: 729 | Classification loss: 0.02567 | Regression loss: 0.29392 | Running loss: 0.23850\n",
      "Epoch: 17 | Iteration: 730 | Classification loss: 0.04354 | Regression loss: 0.26188 | Running loss: 0.23862\n",
      "Epoch: 17 | Iteration: 731 | Classification loss: 0.02119 | Regression loss: 0.22414 | Running loss: 0.23822\n",
      "Epoch: 17 | Iteration: 732 | Classification loss: 0.08848 | Regression loss: 0.15108 | Running loss: 0.23832\n",
      "Epoch: 17 | Iteration: 733 | Classification loss: 0.13919 | Regression loss: 0.14970 | Running loss: 0.23846\n",
      "Epoch: 17 | Iteration: 734 | Classification loss: 0.05180 | Regression loss: 0.32551 | Running loss: 0.23902\n",
      "Epoch: 17 | Iteration: 735 | Classification loss: 0.15611 | Regression loss: 0.34836 | Running loss: 0.23899\n",
      "Epoch: 17 | Iteration: 736 | Classification loss: 0.04526 | Regression loss: 0.31672 | Running loss: 0.23849\n",
      "Epoch: 17 | Iteration: 737 | Classification loss: 0.03709 | Regression loss: 0.09124 | Running loss: 0.23815\n",
      "Epoch: 17 | Iteration: 738 | Classification loss: 0.02774 | Regression loss: 0.23066 | Running loss: 0.23820\n",
      "Epoch: 17 | Iteration: 739 | Classification loss: 0.01454 | Regression loss: 0.13004 | Running loss: 0.23830\n",
      "Epoch: 17 | Iteration: 740 | Classification loss: 0.03690 | Regression loss: 0.12672 | Running loss: 0.23786\n",
      "Epoch: 17 | Iteration: 741 | Classification loss: 0.06830 | Regression loss: 0.20904 | Running loss: 0.23797\n",
      "Epoch: 17 | Iteration: 742 | Classification loss: 0.19211 | Regression loss: 0.41185 | Running loss: 0.23879\n",
      "Epoch: 17 | Iteration: 743 | Classification loss: 0.02242 | Regression loss: 0.27622 | Running loss: 0.23898\n",
      "Epoch: 17 | Iteration: 744 | Classification loss: 0.03008 | Regression loss: 0.16589 | Running loss: 0.23905\n",
      "Epoch: 17 | Iteration: 745 | Classification loss: 0.33082 | Regression loss: 0.18935 | Running loss: 0.23966\n",
      "Epoch: 17 | Iteration: 746 | Classification loss: 0.07467 | Regression loss: 0.19107 | Running loss: 0.23986\n",
      "Epoch: 17 | Iteration: 747 | Classification loss: 0.09412 | Regression loss: 0.27823 | Running loss: 0.24014\n",
      "Epoch: 17 | Iteration: 748 | Classification loss: 0.06997 | Regression loss: 0.31346 | Running loss: 0.24042\n",
      "Epoch: 17 | Iteration: 749 | Classification loss: 0.03843 | Regression loss: 0.15598 | Running loss: 0.24054\n",
      "Epoch: 17 | Iteration: 750 | Classification loss: 0.10464 | Regression loss: 0.26817 | Running loss: 0.24099\n",
      "Epoch: 17 | Iteration: 751 | Classification loss: 0.02839 | Regression loss: 0.16588 | Running loss: 0.24103\n",
      "Epoch: 17 | Iteration: 752 | Classification loss: 0.13820 | Regression loss: 0.31725 | Running loss: 0.24154\n",
      "Epoch: 17 | Iteration: 753 | Classification loss: 0.07646 | Regression loss: 0.19160 | Running loss: 0.24154\n",
      "Epoch: 17 | Iteration: 754 | Classification loss: 0.07079 | Regression loss: 0.25263 | Running loss: 0.24165\n",
      "Epoch: 17 | Iteration: 755 | Classification loss: 0.01028 | Regression loss: 0.07188 | Running loss: 0.24164\n",
      "Epoch: 17 | Iteration: 756 | Classification loss: 0.03700 | Regression loss: 0.22977 | Running loss: 0.24187\n",
      "Epoch: 17 | Iteration: 757 | Classification loss: 0.02302 | Regression loss: 0.11753 | Running loss: 0.24185\n",
      "Epoch: 17 | Iteration: 758 | Classification loss: 0.03431 | Regression loss: 0.16123 | Running loss: 0.24180\n",
      "Epoch: 17 | Iteration: 759 | Classification loss: 0.06754 | Regression loss: 0.13761 | Running loss: 0.24183\n",
      "Epoch: 17 | Iteration: 760 | Classification loss: 0.02322 | Regression loss: 0.13317 | Running loss: 0.24170\n",
      "Epoch: 17 | Iteration: 761 | Classification loss: 0.11054 | Regression loss: 0.15407 | Running loss: 0.24170\n",
      "Epoch: 17 | Iteration: 762 | Classification loss: 0.03711 | Regression loss: 0.13796 | Running loss: 0.24152\n",
      "Epoch: 17 | Iteration: 763 | Classification loss: 0.05964 | Regression loss: 0.20438 | Running loss: 0.24101\n",
      "Epoch: 17 | Iteration: 764 | Classification loss: 0.05296 | Regression loss: 0.20142 | Running loss: 0.24115\n",
      "Epoch: 17 | Iteration: 765 | Classification loss: 0.05759 | Regression loss: 0.20793 | Running loss: 0.24147\n",
      "Epoch: 17 | Iteration: 766 | Classification loss: 0.04607 | Regression loss: 0.27692 | Running loss: 0.24180\n",
      "Epoch: 17 | Iteration: 767 | Classification loss: 0.06437 | Regression loss: 0.23206 | Running loss: 0.24221\n",
      "Epoch: 17 | Iteration: 768 | Classification loss: 0.00723 | Regression loss: 0.10416 | Running loss: 0.24192\n",
      "Epoch: 17 | Iteration: 769 | Classification loss: 0.04197 | Regression loss: 0.21423 | Running loss: 0.24201\n",
      "Epoch: 17 | Iteration: 770 | Classification loss: 0.30827 | Regression loss: 0.07705 | Running loss: 0.24232\n",
      "Epoch: 17 | Iteration: 771 | Classification loss: 0.04166 | Regression loss: 0.24872 | Running loss: 0.24256\n",
      "Epoch: 17 | Iteration: 772 | Classification loss: 0.02245 | Regression loss: 0.18350 | Running loss: 0.24242\n",
      "Epoch: 17 | Iteration: 773 | Classification loss: 0.07061 | Regression loss: 0.13380 | Running loss: 0.24242\n",
      "Epoch: 17 | Iteration: 774 | Classification loss: 0.01031 | Regression loss: 0.12562 | Running loss: 0.24232\n",
      "Epoch: 17 | Iteration: 775 | Classification loss: 0.15247 | Regression loss: 0.50059 | Running loss: 0.24329\n",
      "Epoch: 17 | Iteration: 776 | Classification loss: 0.01822 | Regression loss: 0.11923 | Running loss: 0.24325\n",
      "Epoch: 17 | Iteration: 777 | Classification loss: 0.03050 | Regression loss: 0.12929 | Running loss: 0.24334\n",
      "Epoch: 17 | Iteration: 778 | Classification loss: 0.01690 | Regression loss: 0.22210 | Running loss: 0.24290\n",
      "Epoch: 17 | Iteration: 779 | Classification loss: 0.02186 | Regression loss: 0.21596 | Running loss: 0.24280\n",
      "Epoch: 17 | Iteration: 780 | Classification loss: 0.01565 | Regression loss: 0.09912 | Running loss: 0.24262\n",
      "Epoch: 17 | Iteration: 781 | Classification loss: 0.04836 | Regression loss: 0.22047 | Running loss: 0.24256\n",
      "Epoch: 17 | Iteration: 782 | Classification loss: 0.06075 | Regression loss: 0.19891 | Running loss: 0.24258\n",
      "Epoch: 17 | Iteration: 783 | Classification loss: 0.01685 | Regression loss: 0.08058 | Running loss: 0.24219\n",
      "Epoch: 17 | Iteration: 784 | Classification loss: 0.04024 | Regression loss: 0.14458 | Running loss: 0.24230\n",
      "Epoch: 17 | Iteration: 785 | Classification loss: 0.12664 | Regression loss: 0.42655 | Running loss: 0.24319\n",
      "Epoch: 17 | Iteration: 786 | Classification loss: 0.02066 | Regression loss: 0.19587 | Running loss: 0.24322\n",
      "Epoch: 17 | Iteration: 787 | Classification loss: 0.01607 | Regression loss: 0.12584 | Running loss: 0.24281\n",
      "Epoch: 17 | Iteration: 788 | Classification loss: 0.05621 | Regression loss: 0.12087 | Running loss: 0.24263\n",
      "Epoch: 17 | Iteration: 789 | Classification loss: 0.01606 | Regression loss: 0.20148 | Running loss: 0.24259\n",
      "Epoch: 17 | Iteration: 790 | Classification loss: 0.20349 | Regression loss: 0.33212 | Running loss: 0.24299\n",
      "Epoch: 17 | Iteration: 791 | Classification loss: 0.01283 | Regression loss: 0.15674 | Running loss: 0.24295\n",
      "Epoch: 17 | Iteration: 792 | Classification loss: 0.03749 | Regression loss: 0.17304 | Running loss: 0.24237\n",
      "Epoch: 17 | Iteration: 793 | Classification loss: 0.04500 | Regression loss: 0.07927 | Running loss: 0.24213\n",
      "Epoch: 17 | Iteration: 794 | Classification loss: 0.11261 | Regression loss: 0.39276 | Running loss: 0.24291\n",
      "Epoch: 17 | Iteration: 795 | Classification loss: 0.06133 | Regression loss: 0.17182 | Running loss: 0.24251\n",
      "Epoch: 17 | Iteration: 796 | Classification loss: 0.05033 | Regression loss: 0.09468 | Running loss: 0.24226\n",
      "Epoch: 17 | Iteration: 797 | Classification loss: 0.03565 | Regression loss: 0.21057 | Running loss: 0.24233\n",
      "Epoch: 17 | Iteration: 798 | Classification loss: 0.08523 | Regression loss: 0.27790 | Running loss: 0.24258\n",
      "Epoch: 17 | Iteration: 799 | Classification loss: 0.02204 | Regression loss: 0.12502 | Running loss: 0.24266\n",
      "Epoch: 17 | Iteration: 800 | Classification loss: 0.02268 | Regression loss: 0.13458 | Running loss: 0.24238\n",
      "Epoch: 17 | Iteration: 801 | Classification loss: 0.02764 | Regression loss: 0.11856 | Running loss: 0.24238\n",
      "Epoch: 17 | Iteration: 802 | Classification loss: 0.04061 | Regression loss: 0.19195 | Running loss: 0.24232\n",
      "Epoch: 17 | Iteration: 803 | Classification loss: 0.06305 | Regression loss: 0.24953 | Running loss: 0.24264\n",
      "Epoch: 17 | Iteration: 804 | Classification loss: 0.13747 | Regression loss: 0.23990 | Running loss: 0.24325\n",
      "Epoch: 17 | Iteration: 805 | Classification loss: 0.00726 | Regression loss: 0.17854 | Running loss: 0.24337\n",
      "Epoch: 17 | Iteration: 806 | Classification loss: 0.02940 | Regression loss: 0.13806 | Running loss: 0.24312\n",
      "Epoch: 17 | Iteration: 807 | Classification loss: 0.15156 | Regression loss: 0.19997 | Running loss: 0.24358\n",
      "Epoch: 17 | Iteration: 808 | Classification loss: 0.04859 | Regression loss: 0.24286 | Running loss: 0.24387\n",
      "Epoch: 17 | Iteration: 809 | Classification loss: 0.05141 | Regression loss: 0.12568 | Running loss: 0.24368\n",
      "Epoch: 17 | Iteration: 810 | Classification loss: 0.04016 | Regression loss: 0.12378 | Running loss: 0.24369\n",
      "Epoch: 17 | Iteration: 811 | Classification loss: 0.14555 | Regression loss: 0.40881 | Running loss: 0.24437\n",
      "Epoch: 17 | Iteration: 812 | Classification loss: 0.09372 | Regression loss: 0.24375 | Running loss: 0.24462\n",
      "Epoch: 17 | Iteration: 813 | Classification loss: 0.04888 | Regression loss: 0.24269 | Running loss: 0.24470\n",
      "Epoch: 17 | Iteration: 814 | Classification loss: 0.05797 | Regression loss: 0.11823 | Running loss: 0.24469\n",
      "Epoch: 17 | Iteration: 815 | Classification loss: 0.02983 | Regression loss: 0.14512 | Running loss: 0.24432\n",
      "Epoch: 17 | Iteration: 816 | Classification loss: 0.02237 | Regression loss: 0.06872 | Running loss: 0.24399\n",
      "Epoch: 17 | Iteration: 817 | Classification loss: 0.02369 | Regression loss: 0.10787 | Running loss: 0.24382\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.591\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 18 | Iteration: 0 | Classification loss: 0.05501 | Regression loss: 0.18630 | Running loss: 0.24393\n",
      "Epoch: 18 | Iteration: 1 | Classification loss: 0.01639 | Regression loss: 0.12465 | Running loss: 0.24365\n",
      "Epoch: 18 | Iteration: 2 | Classification loss: 0.08332 | Regression loss: 0.19959 | Running loss: 0.24391\n",
      "Epoch: 18 | Iteration: 3 | Classification loss: 0.01954 | Regression loss: 0.18809 | Running loss: 0.24401\n",
      "Epoch: 18 | Iteration: 4 | Classification loss: 0.02389 | Regression loss: 0.13766 | Running loss: 0.24400\n",
      "Epoch: 18 | Iteration: 5 | Classification loss: 0.02575 | Regression loss: 0.17159 | Running loss: 0.24378\n",
      "Epoch: 18 | Iteration: 6 | Classification loss: 0.06119 | Regression loss: 0.44889 | Running loss: 0.24439\n",
      "Epoch: 18 | Iteration: 7 | Classification loss: 0.04889 | Regression loss: 0.16310 | Running loss: 0.24424\n",
      "Epoch: 18 | Iteration: 8 | Classification loss: 0.03675 | Regression loss: 0.21162 | Running loss: 0.24437\n",
      "Epoch: 18 | Iteration: 9 | Classification loss: 0.05226 | Regression loss: 0.30393 | Running loss: 0.24459\n",
      "Epoch: 18 | Iteration: 10 | Classification loss: 0.07856 | Regression loss: 0.13444 | Running loss: 0.24461\n",
      "Epoch: 18 | Iteration: 11 | Classification loss: 0.00335 | Regression loss: 0.05438 | Running loss: 0.24380\n",
      "Epoch: 18 | Iteration: 12 | Classification loss: 0.01452 | Regression loss: 0.12634 | Running loss: 0.24373\n",
      "Epoch: 18 | Iteration: 13 | Classification loss: 0.01457 | Regression loss: 0.13326 | Running loss: 0.24369\n",
      "Epoch: 18 | Iteration: 14 | Classification loss: 0.03220 | Regression loss: 0.21618 | Running loss: 0.24379\n",
      "Epoch: 18 | Iteration: 15 | Classification loss: 0.05936 | Regression loss: 0.22608 | Running loss: 0.24412\n",
      "Epoch: 18 | Iteration: 16 | Classification loss: 0.02605 | Regression loss: 0.11398 | Running loss: 0.24384\n",
      "Epoch: 18 | Iteration: 17 | Classification loss: 0.06057 | Regression loss: 0.14412 | Running loss: 0.24253\n",
      "Epoch: 18 | Iteration: 18 | Classification loss: 0.02234 | Regression loss: 0.17260 | Running loss: 0.24243\n",
      "Epoch: 18 | Iteration: 19 | Classification loss: 0.03127 | Regression loss: 0.18341 | Running loss: 0.24260\n",
      "Epoch: 18 | Iteration: 20 | Classification loss: 0.01840 | Regression loss: 0.16466 | Running loss: 0.24217\n",
      "Epoch: 18 | Iteration: 21 | Classification loss: 0.01202 | Regression loss: 0.13853 | Running loss: 0.24199\n",
      "Epoch: 18 | Iteration: 22 | Classification loss: 0.02327 | Regression loss: 0.21052 | Running loss: 0.24203\n",
      "Epoch: 18 | Iteration: 23 | Classification loss: 0.06959 | Regression loss: 0.25595 | Running loss: 0.24255\n",
      "Epoch: 18 | Iteration: 24 | Classification loss: 0.00999 | Regression loss: 0.23480 | Running loss: 0.24263\n",
      "Epoch: 18 | Iteration: 25 | Classification loss: 0.02085 | Regression loss: 0.22240 | Running loss: 0.24266\n",
      "Epoch: 18 | Iteration: 26 | Classification loss: 0.03630 | Regression loss: 0.17323 | Running loss: 0.24268\n",
      "Epoch: 18 | Iteration: 27 | Classification loss: 0.02125 | Regression loss: 0.14103 | Running loss: 0.24267\n",
      "Epoch: 18 | Iteration: 28 | Classification loss: 0.02345 | Regression loss: 0.12303 | Running loss: 0.24260\n",
      "Epoch: 18 | Iteration: 29 | Classification loss: 0.05403 | Regression loss: 0.19786 | Running loss: 0.24278\n",
      "Epoch: 18 | Iteration: 30 | Classification loss: 0.06556 | Regression loss: 0.18373 | Running loss: 0.24294\n",
      "Epoch: 18 | Iteration: 31 | Classification loss: 0.17430 | Regression loss: 0.12392 | Running loss: 0.24334\n",
      "Epoch: 18 | Iteration: 32 | Classification loss: 0.01968 | Regression loss: 0.15645 | Running loss: 0.24346\n",
      "Epoch: 18 | Iteration: 33 | Classification loss: 0.02095 | Regression loss: 0.15561 | Running loss: 0.24338\n",
      "Epoch: 18 | Iteration: 34 | Classification loss: 0.08532 | Regression loss: 0.36254 | Running loss: 0.24394\n",
      "Epoch: 18 | Iteration: 35 | Classification loss: 0.02074 | Regression loss: 0.12962 | Running loss: 0.24391\n",
      "Epoch: 18 | Iteration: 36 | Classification loss: 0.07008 | Regression loss: 0.29758 | Running loss: 0.24353\n",
      "Epoch: 18 | Iteration: 37 | Classification loss: 0.00847 | Regression loss: 0.09864 | Running loss: 0.24321\n",
      "Epoch: 18 | Iteration: 38 | Classification loss: 0.10113 | Regression loss: 0.13998 | Running loss: 0.24334\n",
      "Epoch: 18 | Iteration: 39 | Classification loss: 0.02579 | Regression loss: 0.28065 | Running loss: 0.24345\n",
      "Epoch: 18 | Iteration: 40 | Classification loss: 0.02138 | Regression loss: 0.14215 | Running loss: 0.24363\n",
      "Epoch: 18 | Iteration: 41 | Classification loss: 0.03775 | Regression loss: 0.17833 | Running loss: 0.24384\n",
      "Epoch: 18 | Iteration: 42 | Classification loss: 0.02813 | Regression loss: 0.21351 | Running loss: 0.24382\n",
      "Epoch: 18 | Iteration: 43 | Classification loss: 0.01124 | Regression loss: 0.08294 | Running loss: 0.24372\n",
      "Epoch: 18 | Iteration: 44 | Classification loss: 0.04910 | Regression loss: 0.23202 | Running loss: 0.24365\n",
      "Epoch: 18 | Iteration: 45 | Classification loss: 0.02138 | Regression loss: 0.17077 | Running loss: 0.24361\n",
      "Epoch: 18 | Iteration: 46 | Classification loss: 0.08767 | Regression loss: 0.23603 | Running loss: 0.24379\n",
      "Epoch: 18 | Iteration: 47 | Classification loss: 0.01752 | Regression loss: 0.10558 | Running loss: 0.24372\n",
      "Epoch: 18 | Iteration: 48 | Classification loss: 0.05562 | Regression loss: 0.37739 | Running loss: 0.24409\n",
      "Epoch: 18 | Iteration: 49 | Classification loss: 0.08208 | Regression loss: 0.26860 | Running loss: 0.24419\n",
      "Epoch: 18 | Iteration: 50 | Classification loss: 0.01138 | Regression loss: 0.13676 | Running loss: 0.24386\n",
      "Epoch: 18 | Iteration: 51 | Classification loss: 0.04166 | Regression loss: 0.15799 | Running loss: 0.24368\n",
      "Epoch: 18 | Iteration: 52 | Classification loss: 0.19756 | Regression loss: 0.12719 | Running loss: 0.24399\n",
      "Epoch: 18 | Iteration: 53 | Classification loss: 0.33916 | Regression loss: 0.19809 | Running loss: 0.24431\n",
      "Epoch: 18 | Iteration: 54 | Classification loss: 0.03647 | Regression loss: 0.14713 | Running loss: 0.24435\n",
      "Epoch: 18 | Iteration: 55 | Classification loss: 0.00664 | Regression loss: 0.08057 | Running loss: 0.24422\n",
      "Epoch: 18 | Iteration: 56 | Classification loss: 0.08129 | Regression loss: 0.19237 | Running loss: 0.24437\n",
      "Epoch: 18 | Iteration: 57 | Classification loss: 0.05139 | Regression loss: 0.20328 | Running loss: 0.24366\n",
      "Epoch: 18 | Iteration: 58 | Classification loss: 0.02178 | Regression loss: 0.22212 | Running loss: 0.24392\n",
      "Epoch: 18 | Iteration: 59 | Classification loss: 0.14704 | Regression loss: 0.17512 | Running loss: 0.24422\n",
      "Epoch: 18 | Iteration: 60 | Classification loss: 0.03183 | Regression loss: 0.19872 | Running loss: 0.24435\n",
      "Epoch: 18 | Iteration: 61 | Classification loss: 0.04513 | Regression loss: 0.18829 | Running loss: 0.24424\n",
      "Epoch: 18 | Iteration: 62 | Classification loss: 0.01139 | Regression loss: 0.09833 | Running loss: 0.24337\n",
      "Epoch: 18 | Iteration: 63 | Classification loss: 0.04991 | Regression loss: 0.08495 | Running loss: 0.24304\n",
      "Epoch: 18 | Iteration: 64 | Classification loss: 0.03130 | Regression loss: 0.14194 | Running loss: 0.24261\n",
      "Epoch: 18 | Iteration: 65 | Classification loss: 0.02788 | Regression loss: 0.15028 | Running loss: 0.24277\n",
      "Epoch: 18 | Iteration: 66 | Classification loss: 0.02298 | Regression loss: 0.06329 | Running loss: 0.24180\n",
      "Epoch: 18 | Iteration: 67 | Classification loss: 0.05344 | Regression loss: 0.26118 | Running loss: 0.24228\n",
      "Epoch: 18 | Iteration: 68 | Classification loss: 0.01156 | Regression loss: 0.07233 | Running loss: 0.24189\n",
      "Epoch: 18 | Iteration: 69 | Classification loss: 0.09635 | Regression loss: 0.24230 | Running loss: 0.24211\n",
      "Epoch: 18 | Iteration: 70 | Classification loss: 0.04023 | Regression loss: 0.13020 | Running loss: 0.24201\n",
      "Epoch: 18 | Iteration: 71 | Classification loss: 0.01521 | Regression loss: 0.11058 | Running loss: 0.24192\n",
      "Epoch: 18 | Iteration: 72 | Classification loss: 0.03364 | Regression loss: 0.16549 | Running loss: 0.24185\n",
      "Epoch: 18 | Iteration: 73 | Classification loss: 0.03143 | Regression loss: 0.11248 | Running loss: 0.24190\n",
      "Epoch: 18 | Iteration: 74 | Classification loss: 0.02798 | Regression loss: 0.18615 | Running loss: 0.24189\n",
      "Epoch: 18 | Iteration: 75 | Classification loss: 0.02579 | Regression loss: 0.10409 | Running loss: 0.24163\n",
      "Epoch: 18 | Iteration: 76 | Classification loss: 0.01466 | Regression loss: 0.11408 | Running loss: 0.24112\n",
      "Epoch: 18 | Iteration: 77 | Classification loss: 0.05109 | Regression loss: 0.26355 | Running loss: 0.24111\n",
      "Epoch: 18 | Iteration: 78 | Classification loss: 0.03774 | Regression loss: 0.08182 | Running loss: 0.24100\n",
      "Epoch: 18 | Iteration: 79 | Classification loss: 0.02169 | Regression loss: 0.19386 | Running loss: 0.24003\n",
      "Epoch: 18 | Iteration: 80 | Classification loss: 0.01657 | Regression loss: 0.10680 | Running loss: 0.23974\n",
      "Epoch: 18 | Iteration: 81 | Classification loss: 0.07143 | Regression loss: 0.26295 | Running loss: 0.23984\n",
      "Epoch: 18 | Iteration: 82 | Classification loss: 0.04861 | Regression loss: 0.28916 | Running loss: 0.24030\n",
      "Epoch: 18 | Iteration: 83 | Classification loss: 0.01155 | Regression loss: 0.09583 | Running loss: 0.23991\n",
      "Epoch: 18 | Iteration: 84 | Classification loss: 0.04686 | Regression loss: 0.11524 | Running loss: 0.23994\n",
      "Epoch: 18 | Iteration: 85 | Classification loss: 0.07253 | Regression loss: 0.24581 | Running loss: 0.24002\n",
      "Epoch: 18 | Iteration: 86 | Classification loss: 0.02701 | Regression loss: 0.21681 | Running loss: 0.24003\n",
      "Epoch: 18 | Iteration: 87 | Classification loss: 0.02772 | Regression loss: 0.21160 | Running loss: 0.24002\n",
      "Epoch: 18 | Iteration: 88 | Classification loss: 0.01742 | Regression loss: 0.20153 | Running loss: 0.24016\n",
      "Epoch: 18 | Iteration: 89 | Classification loss: 0.11474 | Regression loss: 0.28548 | Running loss: 0.24053\n",
      "Epoch: 18 | Iteration: 90 | Classification loss: 0.02471 | Regression loss: 0.12369 | Running loss: 0.24050\n",
      "Epoch: 18 | Iteration: 91 | Classification loss: 0.03445 | Regression loss: 0.13661 | Running loss: 0.24022\n",
      "Epoch: 18 | Iteration: 92 | Classification loss: 0.06546 | Regression loss: 0.21469 | Running loss: 0.24023\n",
      "Epoch: 18 | Iteration: 93 | Classification loss: 0.01826 | Regression loss: 0.21099 | Running loss: 0.23950\n",
      "Epoch: 18 | Iteration: 94 | Classification loss: 0.03268 | Regression loss: 0.15295 | Running loss: 0.23889\n",
      "Epoch: 18 | Iteration: 95 | Classification loss: 0.01421 | Regression loss: 0.17981 | Running loss: 0.23884\n",
      "Epoch: 18 | Iteration: 96 | Classification loss: 0.02387 | Regression loss: 0.16945 | Running loss: 0.23887\n",
      "Epoch: 18 | Iteration: 97 | Classification loss: 0.04498 | Regression loss: 0.12850 | Running loss: 0.23731\n",
      "Epoch: 18 | Iteration: 98 | Classification loss: 0.01508 | Regression loss: 0.12771 | Running loss: 0.23736\n",
      "Epoch: 18 | Iteration: 99 | Classification loss: 0.01436 | Regression loss: 0.17687 | Running loss: 0.23735\n",
      "Epoch: 18 | Iteration: 100 | Classification loss: 0.03528 | Regression loss: 0.06269 | Running loss: 0.23713\n",
      "Epoch: 18 | Iteration: 101 | Classification loss: 0.01003 | Regression loss: 0.07216 | Running loss: 0.23705\n",
      "Epoch: 18 | Iteration: 102 | Classification loss: 0.01303 | Regression loss: 0.11439 | Running loss: 0.23645\n",
      "Epoch: 18 | Iteration: 103 | Classification loss: 0.01656 | Regression loss: 0.09574 | Running loss: 0.23624\n",
      "Epoch: 18 | Iteration: 104 | Classification loss: 0.04775 | Regression loss: 0.17870 | Running loss: 0.23603\n",
      "Epoch: 18 | Iteration: 105 | Classification loss: 0.02146 | Regression loss: 0.12648 | Running loss: 0.23573\n",
      "Epoch: 18 | Iteration: 106 | Classification loss: 0.04565 | Regression loss: 0.23516 | Running loss: 0.23588\n",
      "Epoch: 18 | Iteration: 107 | Classification loss: 0.01127 | Regression loss: 0.14882 | Running loss: 0.23609\n",
      "Epoch: 18 | Iteration: 108 | Classification loss: 0.01493 | Regression loss: 0.10111 | Running loss: 0.23612\n",
      "Epoch: 18 | Iteration: 109 | Classification loss: 0.04232 | Regression loss: 0.17388 | Running loss: 0.23628\n",
      "Epoch: 18 | Iteration: 110 | Classification loss: 0.02222 | Regression loss: 0.08353 | Running loss: 0.23619\n",
      "Epoch: 18 | Iteration: 111 | Classification loss: 0.03175 | Regression loss: 0.15122 | Running loss: 0.23607\n",
      "Epoch: 18 | Iteration: 112 | Classification loss: 0.03229 | Regression loss: 0.17941 | Running loss: 0.23563\n",
      "Epoch: 18 | Iteration: 113 | Classification loss: 0.04644 | Regression loss: 0.21910 | Running loss: 0.23573\n",
      "Epoch: 18 | Iteration: 114 | Classification loss: 0.00991 | Regression loss: 0.09630 | Running loss: 0.23540\n",
      "Epoch: 18 | Iteration: 115 | Classification loss: 0.01575 | Regression loss: 0.09427 | Running loss: 0.23518\n",
      "Epoch: 18 | Iteration: 116 | Classification loss: 0.01823 | Regression loss: 0.11418 | Running loss: 0.23522\n",
      "Epoch: 18 | Iteration: 117 | Classification loss: 0.02443 | Regression loss: 0.19226 | Running loss: 0.23535\n",
      "Epoch: 18 | Iteration: 118 | Classification loss: 0.01588 | Regression loss: 0.11421 | Running loss: 0.23530\n",
      "Epoch: 18 | Iteration: 119 | Classification loss: 0.02549 | Regression loss: 0.13169 | Running loss: 0.23511\n",
      "Epoch: 18 | Iteration: 120 | Classification loss: 0.02143 | Regression loss: 0.03162 | Running loss: 0.23488\n",
      "Epoch: 18 | Iteration: 121 | Classification loss: 0.00883 | Regression loss: 0.09079 | Running loss: 0.23476\n",
      "Epoch: 18 | Iteration: 122 | Classification loss: 0.02398 | Regression loss: 0.28367 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 123 | Classification loss: 0.09348 | Regression loss: 0.06595 | Running loss: 0.23491\n",
      "Epoch: 18 | Iteration: 124 | Classification loss: 0.04973 | Regression loss: 0.24422 | Running loss: 0.23498\n",
      "Epoch: 18 | Iteration: 125 | Classification loss: 0.05190 | Regression loss: 0.19481 | Running loss: 0.23536\n",
      "Epoch: 18 | Iteration: 126 | Classification loss: 0.07216 | Regression loss: 0.10388 | Running loss: 0.23519\n",
      "Epoch: 18 | Iteration: 127 | Classification loss: 0.04858 | Regression loss: 0.08064 | Running loss: 0.23517\n",
      "Epoch: 18 | Iteration: 128 | Classification loss: 0.02398 | Regression loss: 0.19408 | Running loss: 0.23498\n",
      "Epoch: 18 | Iteration: 129 | Classification loss: 0.01926 | Regression loss: 0.12113 | Running loss: 0.23510\n",
      "Epoch: 18 | Iteration: 130 | Classification loss: 0.03040 | Regression loss: 0.20576 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 131 | Classification loss: 0.01900 | Regression loss: 0.20830 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 132 | Classification loss: 0.03547 | Regression loss: 0.14235 | Running loss: 0.23478\n",
      "Epoch: 18 | Iteration: 133 | Classification loss: 0.03937 | Regression loss: 0.10908 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 134 | Classification loss: 0.01229 | Regression loss: 0.10192 | Running loss: 0.23474\n",
      "Epoch: 18 | Iteration: 135 | Classification loss: 0.11570 | Regression loss: 0.32994 | Running loss: 0.23500\n",
      "Epoch: 18 | Iteration: 136 | Classification loss: 0.04111 | Regression loss: 0.09820 | Running loss: 0.23493\n",
      "Epoch: 18 | Iteration: 137 | Classification loss: 0.00553 | Regression loss: 0.07702 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 138 | Classification loss: 0.05740 | Regression loss: 0.25146 | Running loss: 0.23494\n",
      "Epoch: 18 | Iteration: 139 | Classification loss: 0.01460 | Regression loss: 0.10299 | Running loss: 0.23441\n",
      "Epoch: 18 | Iteration: 140 | Classification loss: 0.02544 | Regression loss: 0.05737 | Running loss: 0.23418\n",
      "Epoch: 18 | Iteration: 141 | Classification loss: 0.02223 | Regression loss: 0.20662 | Running loss: 0.23416\n",
      "Epoch: 18 | Iteration: 142 | Classification loss: 0.06646 | Regression loss: 0.17926 | Running loss: 0.23434\n",
      "Epoch: 18 | Iteration: 143 | Classification loss: 0.03735 | Regression loss: 0.24334 | Running loss: 0.23407\n",
      "Epoch: 18 | Iteration: 144 | Classification loss: 0.04789 | Regression loss: 0.15337 | Running loss: 0.23405\n",
      "Epoch: 18 | Iteration: 145 | Classification loss: 0.00801 | Regression loss: 0.08783 | Running loss: 0.23386\n",
      "Epoch: 18 | Iteration: 146 | Classification loss: 0.01895 | Regression loss: 0.07228 | Running loss: 0.23371\n",
      "Epoch: 18 | Iteration: 147 | Classification loss: 0.01339 | Regression loss: 0.09788 | Running loss: 0.23361\n",
      "Epoch: 18 | Iteration: 148 | Classification loss: 0.06141 | Regression loss: 0.35628 | Running loss: 0.23376\n",
      "Epoch: 18 | Iteration: 149 | Classification loss: 0.01584 | Regression loss: 0.19898 | Running loss: 0.23388\n",
      "Epoch: 18 | Iteration: 150 | Classification loss: 0.09541 | Regression loss: 0.26306 | Running loss: 0.23445\n",
      "Epoch: 18 | Iteration: 151 | Classification loss: 0.10474 | Regression loss: 0.18577 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 152 | Classification loss: 0.03139 | Regression loss: 0.16650 | Running loss: 0.23485\n",
      "Epoch: 18 | Iteration: 153 | Classification loss: 0.03980 | Regression loss: 0.24239 | Running loss: 0.23484\n",
      "Epoch: 18 | Iteration: 154 | Classification loss: 0.01037 | Regression loss: 0.13385 | Running loss: 0.23463\n",
      "Epoch: 18 | Iteration: 155 | Classification loss: 0.02358 | Regression loss: 0.12631 | Running loss: 0.23473\n",
      "Epoch: 18 | Iteration: 156 | Classification loss: 0.01645 | Regression loss: 0.11420 | Running loss: 0.23397\n",
      "Epoch: 18 | Iteration: 157 | Classification loss: 0.13424 | Regression loss: 0.28040 | Running loss: 0.23448\n",
      "Epoch: 18 | Iteration: 158 | Classification loss: 0.00700 | Regression loss: 0.12869 | Running loss: 0.23414\n",
      "Epoch: 18 | Iteration: 159 | Classification loss: 0.03778 | Regression loss: 0.25010 | Running loss: 0.23409\n",
      "Epoch: 18 | Iteration: 160 | Classification loss: 0.10669 | Regression loss: 0.24121 | Running loss: 0.23438\n",
      "Epoch: 18 | Iteration: 161 | Classification loss: 0.02158 | Regression loss: 0.14870 | Running loss: 0.23427\n",
      "Epoch: 18 | Iteration: 162 | Classification loss: 0.12205 | Regression loss: 0.41440 | Running loss: 0.23489\n",
      "Epoch: 18 | Iteration: 163 | Classification loss: 0.02126 | Regression loss: 0.07323 | Running loss: 0.23459\n",
      "Epoch: 18 | Iteration: 164 | Classification loss: 0.05302 | Regression loss: 0.14190 | Running loss: 0.23471\n",
      "Epoch: 18 | Iteration: 165 | Classification loss: 0.03288 | Regression loss: 0.13709 | Running loss: 0.23478\n",
      "Epoch: 18 | Iteration: 166 | Classification loss: 0.02249 | Regression loss: 0.13375 | Running loss: 0.23483\n",
      "Epoch: 18 | Iteration: 167 | Classification loss: 0.03061 | Regression loss: 0.13931 | Running loss: 0.23484\n",
      "Epoch: 18 | Iteration: 168 | Classification loss: 0.05707 | Regression loss: 0.16036 | Running loss: 0.23472\n",
      "Epoch: 18 | Iteration: 169 | Classification loss: 0.07375 | Regression loss: 0.20412 | Running loss: 0.23499\n",
      "Epoch: 18 | Iteration: 170 | Classification loss: 0.16503 | Regression loss: 0.36012 | Running loss: 0.23531\n",
      "Epoch: 18 | Iteration: 171 | Classification loss: 0.06180 | Regression loss: 0.22206 | Running loss: 0.23550\n",
      "Epoch: 18 | Iteration: 172 | Classification loss: 0.00806 | Regression loss: 0.10399 | Running loss: 0.23530\n",
      "Epoch: 18 | Iteration: 173 | Classification loss: 0.02493 | Regression loss: 0.07612 | Running loss: 0.23514\n",
      "Epoch: 18 | Iteration: 174 | Classification loss: 0.02101 | Regression loss: 0.09017 | Running loss: 0.23499\n",
      "Epoch: 18 | Iteration: 175 | Classification loss: 0.07343 | Regression loss: 0.27607 | Running loss: 0.23539\n",
      "Epoch: 18 | Iteration: 176 | Classification loss: 0.03602 | Regression loss: 0.13265 | Running loss: 0.23533\n",
      "Epoch: 18 | Iteration: 177 | Classification loss: 0.05182 | Regression loss: 0.12749 | Running loss: 0.23502\n",
      "Epoch: 18 | Iteration: 178 | Classification loss: 0.07483 | Regression loss: 0.17834 | Running loss: 0.23519\n",
      "Epoch: 18 | Iteration: 179 | Classification loss: 0.50471 | Regression loss: 0.36476 | Running loss: 0.23659\n",
      "Epoch: 18 | Iteration: 180 | Classification loss: 0.01895 | Regression loss: 0.12821 | Running loss: 0.23661\n",
      "Epoch: 18 | Iteration: 181 | Classification loss: 0.02564 | Regression loss: 0.11614 | Running loss: 0.23664\n",
      "Epoch: 18 | Iteration: 182 | Classification loss: 0.03170 | Regression loss: 0.26457 | Running loss: 0.23673\n",
      "Epoch: 18 | Iteration: 183 | Classification loss: 0.02908 | Regression loss: 0.26096 | Running loss: 0.23697\n",
      "Epoch: 18 | Iteration: 184 | Classification loss: 0.02864 | Regression loss: 0.13097 | Running loss: 0.23670\n",
      "Epoch: 18 | Iteration: 185 | Classification loss: 0.03059 | Regression loss: 0.15836 | Running loss: 0.23641\n",
      "Epoch: 18 | Iteration: 186 | Classification loss: 0.01173 | Regression loss: 0.10475 | Running loss: 0.23622\n",
      "Epoch: 18 | Iteration: 187 | Classification loss: 0.02338 | Regression loss: 0.16215 | Running loss: 0.23592\n",
      "Epoch: 18 | Iteration: 188 | Classification loss: 0.01715 | Regression loss: 0.15627 | Running loss: 0.23587\n",
      "Epoch: 18 | Iteration: 189 | Classification loss: 0.02254 | Regression loss: 0.15965 | Running loss: 0.23588\n",
      "Epoch: 18 | Iteration: 190 | Classification loss: 0.04280 | Regression loss: 0.13652 | Running loss: 0.23582\n",
      "Epoch: 18 | Iteration: 191 | Classification loss: 0.04572 | Regression loss: 0.25538 | Running loss: 0.23609\n",
      "Epoch: 18 | Iteration: 192 | Classification loss: 0.01731 | Regression loss: 0.12069 | Running loss: 0.23519\n",
      "Epoch: 18 | Iteration: 193 | Classification loss: 0.01959 | Regression loss: 0.09351 | Running loss: 0.23528\n",
      "Epoch: 18 | Iteration: 194 | Classification loss: 0.01021 | Regression loss: 0.16213 | Running loss: 0.23482\n",
      "Epoch: 18 | Iteration: 195 | Classification loss: 0.02906 | Regression loss: 0.16135 | Running loss: 0.23493\n",
      "Epoch: 18 | Iteration: 196 | Classification loss: 0.14695 | Regression loss: 0.37895 | Running loss: 0.23554\n",
      "Epoch: 18 | Iteration: 197 | Classification loss: 0.01992 | Regression loss: 0.14293 | Running loss: 0.23559\n",
      "Epoch: 18 | Iteration: 198 | Classification loss: 0.06455 | Regression loss: 0.25314 | Running loss: 0.23544\n",
      "Epoch: 18 | Iteration: 199 | Classification loss: 0.03244 | Regression loss: 0.09269 | Running loss: 0.23548\n",
      "Epoch: 18 | Iteration: 200 | Classification loss: 0.01813 | Regression loss: 0.15560 | Running loss: 0.23570\n",
      "Epoch: 18 | Iteration: 201 | Classification loss: 0.05886 | Regression loss: 0.29687 | Running loss: 0.23588\n",
      "Epoch: 18 | Iteration: 202 | Classification loss: 0.17005 | Regression loss: 0.25804 | Running loss: 0.23605\n",
      "Epoch: 18 | Iteration: 203 | Classification loss: 0.04839 | Regression loss: 0.16531 | Running loss: 0.23627\n",
      "Epoch: 18 | Iteration: 204 | Classification loss: 0.09612 | Regression loss: 0.09712 | Running loss: 0.23643\n",
      "Epoch: 18 | Iteration: 205 | Classification loss: 0.05144 | Regression loss: 0.16241 | Running loss: 0.23655\n",
      "Epoch: 18 | Iteration: 206 | Classification loss: 0.09524 | Regression loss: 0.07733 | Running loss: 0.23649\n",
      "Epoch: 18 | Iteration: 207 | Classification loss: 0.01824 | Regression loss: 0.14049 | Running loss: 0.23657\n",
      "Epoch: 18 | Iteration: 208 | Classification loss: 0.02256 | Regression loss: 0.14680 | Running loss: 0.23666\n",
      "Epoch: 18 | Iteration: 209 | Classification loss: 0.01951 | Regression loss: 0.09962 | Running loss: 0.23660\n",
      "Epoch: 18 | Iteration: 210 | Classification loss: 0.04702 | Regression loss: 0.17541 | Running loss: 0.23628\n",
      "Epoch: 18 | Iteration: 211 | Classification loss: 0.00758 | Regression loss: 0.10000 | Running loss: 0.23525\n",
      "Epoch: 18 | Iteration: 212 | Classification loss: 0.01059 | Regression loss: 0.11530 | Running loss: 0.23520\n",
      "Epoch: 18 | Iteration: 213 | Classification loss: 0.01828 | Regression loss: 0.18476 | Running loss: 0.23526\n",
      "Epoch: 18 | Iteration: 214 | Classification loss: 0.03571 | Regression loss: 0.18563 | Running loss: 0.23523\n",
      "Epoch: 18 | Iteration: 215 | Classification loss: 0.14836 | Regression loss: 0.18852 | Running loss: 0.23562\n",
      "Epoch: 18 | Iteration: 216 | Classification loss: 0.05898 | Regression loss: 0.26375 | Running loss: 0.23513\n",
      "Epoch: 18 | Iteration: 217 | Classification loss: 0.09140 | Regression loss: 0.29651 | Running loss: 0.23535\n",
      "Epoch: 18 | Iteration: 218 | Classification loss: 0.01704 | Regression loss: 0.18474 | Running loss: 0.23543\n",
      "Epoch: 18 | Iteration: 219 | Classification loss: 0.03090 | Regression loss: 0.14675 | Running loss: 0.23493\n",
      "Epoch: 18 | Iteration: 220 | Classification loss: 0.04381 | Regression loss: 0.17969 | Running loss: 0.23494\n",
      "Epoch: 18 | Iteration: 221 | Classification loss: 0.03198 | Regression loss: 0.14891 | Running loss: 0.23478\n",
      "Epoch: 18 | Iteration: 222 | Classification loss: 0.01575 | Regression loss: 0.17464 | Running loss: 0.23491\n",
      "Epoch: 18 | Iteration: 223 | Classification loss: 0.02516 | Regression loss: 0.22696 | Running loss: 0.23462\n",
      "Epoch: 18 | Iteration: 224 | Classification loss: 0.02313 | Regression loss: 0.10772 | Running loss: 0.23454\n",
      "Epoch: 18 | Iteration: 225 | Classification loss: 0.02775 | Regression loss: 0.12719 | Running loss: 0.23365\n",
      "Epoch: 18 | Iteration: 226 | Classification loss: 0.11623 | Regression loss: 0.38233 | Running loss: 0.23413\n",
      "Epoch: 18 | Iteration: 227 | Classification loss: 0.01498 | Regression loss: 0.15496 | Running loss: 0.23422\n",
      "Epoch: 18 | Iteration: 228 | Classification loss: 0.02394 | Regression loss: 0.05826 | Running loss: 0.23415\n",
      "Epoch: 18 | Iteration: 229 | Classification loss: 0.10011 | Regression loss: 0.45126 | Running loss: 0.23443\n",
      "Epoch: 18 | Iteration: 230 | Classification loss: 0.10094 | Regression loss: 0.25889 | Running loss: 0.23481\n",
      "Epoch: 18 | Iteration: 231 | Classification loss: 0.09227 | Regression loss: 0.17289 | Running loss: 0.23487\n",
      "Epoch: 18 | Iteration: 232 | Classification loss: 0.02916 | Regression loss: 0.15411 | Running loss: 0.23478\n",
      "Epoch: 18 | Iteration: 233 | Classification loss: 0.06134 | Regression loss: 0.17205 | Running loss: 0.23472\n",
      "Epoch: 18 | Iteration: 234 | Classification loss: 0.06954 | Regression loss: 0.27298 | Running loss: 0.23456\n",
      "Epoch: 18 | Iteration: 235 | Classification loss: 0.02474 | Regression loss: 0.15321 | Running loss: 0.23466\n",
      "Epoch: 18 | Iteration: 236 | Classification loss: 0.01002 | Regression loss: 0.10318 | Running loss: 0.23458\n",
      "Epoch: 18 | Iteration: 237 | Classification loss: 0.03453 | Regression loss: 0.12335 | Running loss: 0.23453\n",
      "Epoch: 18 | Iteration: 238 | Classification loss: 0.02277 | Regression loss: 0.12812 | Running loss: 0.23455\n",
      "Epoch: 18 | Iteration: 239 | Classification loss: 0.06215 | Regression loss: 0.17100 | Running loss: 0.23465\n",
      "Epoch: 18 | Iteration: 240 | Classification loss: 0.09796 | Regression loss: 0.24127 | Running loss: 0.23505\n",
      "Epoch: 18 | Iteration: 241 | Classification loss: 0.03428 | Regression loss: 0.13470 | Running loss: 0.23519\n",
      "Epoch: 18 | Iteration: 242 | Classification loss: 0.03262 | Regression loss: 0.17091 | Running loss: 0.23494\n",
      "Epoch: 18 | Iteration: 243 | Classification loss: 0.15660 | Regression loss: 0.11899 | Running loss: 0.23469\n",
      "Epoch: 18 | Iteration: 244 | Classification loss: 0.26085 | Regression loss: 0.24099 | Running loss: 0.23548\n",
      "Epoch: 18 | Iteration: 245 | Classification loss: 0.11538 | Regression loss: 0.32292 | Running loss: 0.23514\n",
      "Epoch: 18 | Iteration: 246 | Classification loss: 0.05437 | Regression loss: 0.19396 | Running loss: 0.23532\n",
      "Epoch: 18 | Iteration: 247 | Classification loss: 0.01578 | Regression loss: 0.08889 | Running loss: 0.23501\n",
      "Epoch: 18 | Iteration: 248 | Classification loss: 0.03376 | Regression loss: 0.16270 | Running loss: 0.23519\n",
      "Epoch: 18 | Iteration: 249 | Classification loss: 0.02831 | Regression loss: 0.12986 | Running loss: 0.23514\n",
      "Epoch: 18 | Iteration: 250 | Classification loss: 0.01900 | Regression loss: 0.10505 | Running loss: 0.23506\n",
      "Epoch: 18 | Iteration: 251 | Classification loss: 0.10333 | Regression loss: 0.07544 | Running loss: 0.23498\n",
      "Epoch: 18 | Iteration: 252 | Classification loss: 0.03904 | Regression loss: 0.19210 | Running loss: 0.23519\n",
      "Epoch: 18 | Iteration: 253 | Classification loss: 0.01828 | Regression loss: 0.16002 | Running loss: 0.23497\n",
      "Epoch: 18 | Iteration: 254 | Classification loss: 0.02070 | Regression loss: 0.12586 | Running loss: 0.23486\n",
      "Epoch: 18 | Iteration: 255 | Classification loss: 0.01338 | Regression loss: 0.07583 | Running loss: 0.23467\n",
      "Epoch: 18 | Iteration: 256 | Classification loss: 0.00751 | Regression loss: 0.14200 | Running loss: 0.23466\n",
      "Epoch: 18 | Iteration: 257 | Classification loss: 0.01810 | Regression loss: 0.15602 | Running loss: 0.23441\n",
      "Epoch: 18 | Iteration: 258 | Classification loss: 0.11421 | Regression loss: 0.29246 | Running loss: 0.23461\n",
      "Epoch: 18 | Iteration: 259 | Classification loss: 0.01991 | Regression loss: 0.11184 | Running loss: 0.23457\n",
      "Epoch: 18 | Iteration: 260 | Classification loss: 0.00897 | Regression loss: 0.10384 | Running loss: 0.23446\n",
      "Epoch: 18 | Iteration: 261 | Classification loss: 0.17506 | Regression loss: 0.25589 | Running loss: 0.23495\n",
      "Epoch: 18 | Iteration: 262 | Classification loss: 0.17117 | Regression loss: 0.42006 | Running loss: 0.23543\n",
      "Epoch: 18 | Iteration: 263 | Classification loss: 0.01908 | Regression loss: 0.21202 | Running loss: 0.23518\n",
      "Epoch: 18 | Iteration: 264 | Classification loss: 0.03101 | Regression loss: 0.23844 | Running loss: 0.23447\n",
      "Epoch: 18 | Iteration: 265 | Classification loss: 0.07824 | Regression loss: 0.23758 | Running loss: 0.23453\n",
      "Epoch: 18 | Iteration: 266 | Classification loss: 0.03788 | Regression loss: 0.09492 | Running loss: 0.23440\n",
      "Epoch: 18 | Iteration: 267 | Classification loss: 0.22532 | Regression loss: 0.19874 | Running loss: 0.23467\n",
      "Epoch: 18 | Iteration: 268 | Classification loss: 0.02120 | Regression loss: 0.10255 | Running loss: 0.23462\n",
      "Epoch: 18 | Iteration: 269 | Classification loss: 0.07011 | Regression loss: 0.15922 | Running loss: 0.23448\n",
      "Epoch: 18 | Iteration: 270 | Classification loss: 0.10367 | Regression loss: 0.18588 | Running loss: 0.23441\n",
      "Epoch: 18 | Iteration: 271 | Classification loss: 0.01049 | Regression loss: 0.09072 | Running loss: 0.23441\n",
      "Epoch: 18 | Iteration: 272 | Classification loss: 0.03035 | Regression loss: 0.15230 | Running loss: 0.23468\n",
      "Epoch: 18 | Iteration: 273 | Classification loss: 0.01143 | Regression loss: 0.26033 | Running loss: 0.23490\n",
      "Epoch: 18 | Iteration: 274 | Classification loss: 0.03428 | Regression loss: 0.20321 | Running loss: 0.23479\n",
      "Epoch: 18 | Iteration: 275 | Classification loss: 0.02146 | Regression loss: 0.13456 | Running loss: 0.23478\n",
      "Epoch: 18 | Iteration: 276 | Classification loss: 0.01161 | Regression loss: 0.13758 | Running loss: 0.23427\n",
      "Epoch: 18 | Iteration: 277 | Classification loss: 0.00843 | Regression loss: 0.10693 | Running loss: 0.23425\n",
      "Epoch: 18 | Iteration: 278 | Classification loss: 0.01289 | Regression loss: 0.06207 | Running loss: 0.23402\n",
      "Epoch: 18 | Iteration: 279 | Classification loss: 0.05954 | Regression loss: 0.11254 | Running loss: 0.23403\n",
      "Epoch: 18 | Iteration: 280 | Classification loss: 0.07755 | Regression loss: 0.07651 | Running loss: 0.23345\n",
      "Epoch: 18 | Iteration: 281 | Classification loss: 0.01847 | Regression loss: 0.14700 | Running loss: 0.23350\n",
      "Epoch: 18 | Iteration: 282 | Classification loss: 0.09352 | Regression loss: 0.11144 | Running loss: 0.23326\n",
      "Epoch: 18 | Iteration: 283 | Classification loss: 0.01791 | Regression loss: 0.15183 | Running loss: 0.23337\n",
      "Epoch: 18 | Iteration: 284 | Classification loss: 0.01400 | Regression loss: 0.25511 | Running loss: 0.23343\n",
      "Epoch: 18 | Iteration: 285 | Classification loss: 0.42455 | Regression loss: 0.58657 | Running loss: 0.23457\n",
      "Epoch: 18 | Iteration: 286 | Classification loss: 0.02932 | Regression loss: 0.11360 | Running loss: 0.23408\n",
      "Epoch: 18 | Iteration: 287 | Classification loss: 0.02809 | Regression loss: 0.21910 | Running loss: 0.23363\n",
      "Epoch: 18 | Iteration: 288 | Classification loss: 0.12488 | Regression loss: 0.12584 | Running loss: 0.23385\n",
      "Epoch: 18 | Iteration: 289 | Classification loss: 0.01807 | Regression loss: 0.12233 | Running loss: 0.23339\n",
      "Epoch: 18 | Iteration: 290 | Classification loss: 0.04645 | Regression loss: 0.12315 | Running loss: 0.23324\n",
      "Epoch: 18 | Iteration: 291 | Classification loss: 0.08272 | Regression loss: 0.18942 | Running loss: 0.23351\n",
      "Epoch: 18 | Iteration: 292 | Classification loss: 0.05067 | Regression loss: 0.13197 | Running loss: 0.23342\n",
      "Epoch: 18 | Iteration: 293 | Classification loss: 0.02857 | Regression loss: 0.18490 | Running loss: 0.23289\n",
      "Epoch: 18 | Iteration: 294 | Classification loss: 0.03265 | Regression loss: 0.15882 | Running loss: 0.23290\n",
      "Epoch: 18 | Iteration: 295 | Classification loss: 0.02941 | Regression loss: 0.20890 | Running loss: 0.23299\n",
      "Epoch: 18 | Iteration: 296 | Classification loss: 0.11200 | Regression loss: 0.23379 | Running loss: 0.23335\n",
      "Epoch: 18 | Iteration: 297 | Classification loss: 0.02178 | Regression loss: 0.12201 | Running loss: 0.23278\n",
      "Epoch: 18 | Iteration: 298 | Classification loss: 0.02163 | Regression loss: 0.13130 | Running loss: 0.23116\n",
      "Epoch: 18 | Iteration: 299 | Classification loss: 0.01711 | Regression loss: 0.22618 | Running loss: 0.23117\n",
      "Epoch: 18 | Iteration: 300 | Classification loss: 0.02282 | Regression loss: 0.14721 | Running loss: 0.23097\n",
      "Epoch: 18 | Iteration: 301 | Classification loss: 0.02948 | Regression loss: 0.16960 | Running loss: 0.23090\n",
      "Epoch: 18 | Iteration: 302 | Classification loss: 0.08186 | Regression loss: 0.20744 | Running loss: 0.23107\n",
      "Epoch: 18 | Iteration: 303 | Classification loss: 0.03878 | Regression loss: 0.20786 | Running loss: 0.23118\n",
      "Epoch: 18 | Iteration: 304 | Classification loss: 0.08718 | Regression loss: 0.36228 | Running loss: 0.23189\n",
      "Epoch: 18 | Iteration: 305 | Classification loss: 0.07261 | Regression loss: 0.30306 | Running loss: 0.23228\n",
      "Epoch: 18 | Iteration: 306 | Classification loss: 0.01162 | Regression loss: 0.04508 | Running loss: 0.23163\n",
      "Epoch: 18 | Iteration: 307 | Classification loss: 0.02407 | Regression loss: 0.13725 | Running loss: 0.23140\n",
      "Epoch: 18 | Iteration: 308 | Classification loss: 0.06510 | Regression loss: 0.33100 | Running loss: 0.23156\n",
      "Epoch: 18 | Iteration: 309 | Classification loss: 0.07917 | Regression loss: 0.31474 | Running loss: 0.23207\n",
      "Epoch: 18 | Iteration: 310 | Classification loss: 0.02869 | Regression loss: 0.10200 | Running loss: 0.23178\n",
      "Epoch: 18 | Iteration: 311 | Classification loss: 0.05357 | Regression loss: 0.22406 | Running loss: 0.23165\n",
      "Epoch: 18 | Iteration: 312 | Classification loss: 0.02814 | Regression loss: 0.25564 | Running loss: 0.23196\n",
      "Epoch: 18 | Iteration: 313 | Classification loss: 0.04353 | Regression loss: 0.27720 | Running loss: 0.23245\n",
      "Epoch: 18 | Iteration: 314 | Classification loss: 0.05527 | Regression loss: 0.26032 | Running loss: 0.23270\n",
      "Epoch: 18 | Iteration: 315 | Classification loss: 0.07173 | Regression loss: 0.20803 | Running loss: 0.23295\n",
      "Epoch: 18 | Iteration: 316 | Classification loss: 0.10884 | Regression loss: 0.19695 | Running loss: 0.23306\n",
      "Epoch: 18 | Iteration: 317 | Classification loss: 0.02523 | Regression loss: 0.12143 | Running loss: 0.23291\n",
      "Epoch: 18 | Iteration: 318 | Classification loss: 0.00864 | Regression loss: 0.09959 | Running loss: 0.23247\n",
      "Epoch: 18 | Iteration: 319 | Classification loss: 0.00611 | Regression loss: 0.06420 | Running loss: 0.23225\n",
      "Epoch: 18 | Iteration: 320 | Classification loss: 0.05120 | Regression loss: 0.24634 | Running loss: 0.23209\n",
      "Epoch: 18 | Iteration: 321 | Classification loss: 0.09682 | Regression loss: 0.29790 | Running loss: 0.23237\n",
      "Epoch: 18 | Iteration: 322 | Classification loss: 0.02718 | Regression loss: 0.13082 | Running loss: 0.23226\n",
      "Epoch: 18 | Iteration: 323 | Classification loss: 0.02770 | Regression loss: 0.12713 | Running loss: 0.23169\n",
      "Epoch: 18 | Iteration: 324 | Classification loss: 0.06841 | Regression loss: 0.20136 | Running loss: 0.23193\n",
      "Epoch: 18 | Iteration: 325 | Classification loss: 0.00894 | Regression loss: 0.15712 | Running loss: 0.23164\n",
      "Epoch: 18 | Iteration: 326 | Classification loss: 0.01385 | Regression loss: 0.14824 | Running loss: 0.23160\n",
      "Epoch: 18 | Iteration: 327 | Classification loss: 0.02813 | Regression loss: 0.16701 | Running loss: 0.23142\n",
      "Epoch: 18 | Iteration: 328 | Classification loss: 0.04224 | Regression loss: 0.24049 | Running loss: 0.23158\n",
      "Epoch: 18 | Iteration: 329 | Classification loss: 0.03434 | Regression loss: 0.06287 | Running loss: 0.22948\n",
      "Epoch: 18 | Iteration: 330 | Classification loss: 0.06897 | Regression loss: 0.17291 | Running loss: 0.22948\n",
      "Epoch: 18 | Iteration: 331 | Classification loss: 0.02814 | Regression loss: 0.11865 | Running loss: 0.22927\n",
      "Epoch: 18 | Iteration: 332 | Classification loss: 0.04695 | Regression loss: 0.05611 | Running loss: 0.22928\n",
      "Epoch: 18 | Iteration: 333 | Classification loss: 0.02183 | Regression loss: 0.12005 | Running loss: 0.22903\n",
      "Epoch: 18 | Iteration: 334 | Classification loss: 0.17908 | Regression loss: 0.37017 | Running loss: 0.22963\n",
      "Epoch: 18 | Iteration: 335 | Classification loss: 0.07624 | Regression loss: 0.26904 | Running loss: 0.23010\n",
      "Epoch: 18 | Iteration: 336 | Classification loss: 0.03636 | Regression loss: 0.26386 | Running loss: 0.23042\n",
      "Epoch: 18 | Iteration: 337 | Classification loss: 0.06317 | Regression loss: 0.28297 | Running loss: 0.23084\n",
      "Epoch: 18 | Iteration: 338 | Classification loss: 0.01306 | Regression loss: 0.12152 | Running loss: 0.23082\n",
      "Epoch: 18 | Iteration: 339 | Classification loss: 0.03773 | Regression loss: 0.14832 | Running loss: 0.23085\n",
      "Epoch: 18 | Iteration: 340 | Classification loss: 0.02575 | Regression loss: 0.23903 | Running loss: 0.23080\n",
      "Epoch: 18 | Iteration: 341 | Classification loss: 0.09127 | Regression loss: 0.28590 | Running loss: 0.23109\n",
      "Epoch: 18 | Iteration: 342 | Classification loss: 0.03153 | Regression loss: 0.10836 | Running loss: 0.23120\n",
      "Epoch: 18 | Iteration: 343 | Classification loss: 0.05511 | Regression loss: 0.20092 | Running loss: 0.23142\n",
      "Epoch: 18 | Iteration: 344 | Classification loss: 0.02166 | Regression loss: 0.10056 | Running loss: 0.23135\n",
      "Epoch: 18 | Iteration: 345 | Classification loss: 0.01173 | Regression loss: 0.13092 | Running loss: 0.23129\n",
      "Epoch: 18 | Iteration: 346 | Classification loss: 0.05387 | Regression loss: 0.16785 | Running loss: 0.23121\n",
      "Epoch: 18 | Iteration: 347 | Classification loss: 0.04480 | Regression loss: 0.18208 | Running loss: 0.23076\n",
      "Epoch: 18 | Iteration: 348 | Classification loss: 0.02522 | Regression loss: 0.19330 | Running loss: 0.23079\n",
      "Epoch: 18 | Iteration: 349 | Classification loss: 0.06929 | Regression loss: 0.28420 | Running loss: 0.23108\n",
      "Epoch: 18 | Iteration: 350 | Classification loss: 0.05387 | Regression loss: 0.21901 | Running loss: 0.23143\n",
      "Epoch: 18 | Iteration: 351 | Classification loss: 0.06316 | Regression loss: 0.29724 | Running loss: 0.23175\n",
      "Epoch: 18 | Iteration: 352 | Classification loss: 0.02435 | Regression loss: 0.21726 | Running loss: 0.23209\n",
      "Epoch: 18 | Iteration: 353 | Classification loss: 0.24889 | Regression loss: 0.21256 | Running loss: 0.23280\n",
      "Epoch: 18 | Iteration: 354 | Classification loss: 0.04641 | Regression loss: 0.31221 | Running loss: 0.23325\n",
      "Epoch: 18 | Iteration: 355 | Classification loss: 0.02939 | Regression loss: 0.15100 | Running loss: 0.23315\n",
      "Epoch: 18 | Iteration: 356 | Classification loss: 0.05843 | Regression loss: 0.24082 | Running loss: 0.23316\n",
      "Epoch: 18 | Iteration: 357 | Classification loss: 0.07372 | Regression loss: 0.22160 | Running loss: 0.23358\n",
      "Epoch: 18 | Iteration: 358 | Classification loss: 0.06249 | Regression loss: 0.23388 | Running loss: 0.23382\n",
      "Epoch: 18 | Iteration: 359 | Classification loss: 0.11064 | Regression loss: 0.13741 | Running loss: 0.23386\n",
      "Epoch: 18 | Iteration: 360 | Classification loss: 0.11832 | Regression loss: 0.29119 | Running loss: 0.23429\n",
      "Epoch: 18 | Iteration: 361 | Classification loss: 0.01053 | Regression loss: 0.12931 | Running loss: 0.23413\n",
      "Epoch: 18 | Iteration: 362 | Classification loss: 0.01605 | Regression loss: 0.15171 | Running loss: 0.23365\n",
      "Epoch: 18 | Iteration: 363 | Classification loss: 0.05058 | Regression loss: 0.29154 | Running loss: 0.23373\n",
      "Epoch: 18 | Iteration: 364 | Classification loss: 0.13682 | Regression loss: 0.43650 | Running loss: 0.23455\n",
      "Epoch: 18 | Iteration: 365 | Classification loss: 0.04275 | Regression loss: 0.16404 | Running loss: 0.23446\n",
      "Epoch: 18 | Iteration: 366 | Classification loss: 0.02604 | Regression loss: 0.16601 | Running loss: 0.23441\n",
      "Epoch: 18 | Iteration: 367 | Classification loss: 0.02851 | Regression loss: 0.25270 | Running loss: 0.23451\n",
      "Epoch: 18 | Iteration: 368 | Classification loss: 0.04830 | Regression loss: 0.26601 | Running loss: 0.23484\n",
      "Epoch: 18 | Iteration: 369 | Classification loss: 0.05230 | Regression loss: 0.17804 | Running loss: 0.23502\n",
      "Epoch: 18 | Iteration: 370 | Classification loss: 0.29024 | Regression loss: 0.43751 | Running loss: 0.23595\n",
      "Epoch: 18 | Iteration: 371 | Classification loss: 0.01194 | Regression loss: 0.14882 | Running loss: 0.23601\n",
      "Epoch: 18 | Iteration: 372 | Classification loss: 0.03602 | Regression loss: 0.22346 | Running loss: 0.23588\n",
      "Epoch: 18 | Iteration: 373 | Classification loss: 0.07798 | Regression loss: 0.28606 | Running loss: 0.23621\n",
      "Epoch: 18 | Iteration: 374 | Classification loss: 0.05183 | Regression loss: 0.13754 | Running loss: 0.23637\n",
      "Epoch: 18 | Iteration: 375 | Classification loss: 0.03124 | Regression loss: 0.27261 | Running loss: 0.23615\n",
      "Epoch: 18 | Iteration: 376 | Classification loss: 0.06816 | Regression loss: 0.12931 | Running loss: 0.23575\n",
      "Epoch: 18 | Iteration: 377 | Classification loss: 0.01482 | Regression loss: 0.10489 | Running loss: 0.23554\n",
      "Epoch: 18 | Iteration: 378 | Classification loss: 0.05488 | Regression loss: 0.24191 | Running loss: 0.23567\n",
      "Epoch: 18 | Iteration: 379 | Classification loss: 0.02323 | Regression loss: 0.13092 | Running loss: 0.23560\n",
      "Epoch: 18 | Iteration: 380 | Classification loss: 0.01666 | Regression loss: 0.16600 | Running loss: 0.23570\n",
      "Epoch: 18 | Iteration: 381 | Classification loss: 0.03155 | Regression loss: 0.25767 | Running loss: 0.23574\n",
      "Epoch: 18 | Iteration: 382 | Classification loss: 0.05350 | Regression loss: 0.15439 | Running loss: 0.23587\n",
      "Epoch: 18 | Iteration: 383 | Classification loss: 0.01372 | Regression loss: 0.12244 | Running loss: 0.23500\n",
      "Epoch: 18 | Iteration: 384 | Classification loss: 0.02810 | Regression loss: 0.13265 | Running loss: 0.23503\n",
      "Epoch: 18 | Iteration: 385 | Classification loss: 0.14815 | Regression loss: 0.13678 | Running loss: 0.23525\n",
      "Epoch: 18 | Iteration: 386 | Classification loss: 0.01421 | Regression loss: 0.19956 | Running loss: 0.23535\n",
      "Epoch: 18 | Iteration: 387 | Classification loss: 0.01966 | Regression loss: 0.13343 | Running loss: 0.23510\n",
      "Epoch: 18 | Iteration: 388 | Classification loss: 0.06580 | Regression loss: 0.43501 | Running loss: 0.23555\n",
      "Epoch: 18 | Iteration: 389 | Classification loss: 0.02129 | Regression loss: 0.15795 | Running loss: 0.23486\n",
      "Epoch: 18 | Iteration: 390 | Classification loss: 0.02104 | Regression loss: 0.20836 | Running loss: 0.23516\n",
      "Epoch: 18 | Iteration: 391 | Classification loss: 0.03804 | Regression loss: 0.17968 | Running loss: 0.23512\n",
      "Epoch: 18 | Iteration: 392 | Classification loss: 0.12136 | Regression loss: 0.25530 | Running loss: 0.23549\n",
      "Epoch: 18 | Iteration: 393 | Classification loss: 0.27838 | Regression loss: 0.31462 | Running loss: 0.23615\n",
      "Epoch: 18 | Iteration: 394 | Classification loss: 0.01966 | Regression loss: 0.23384 | Running loss: 0.23648\n",
      "Epoch: 18 | Iteration: 395 | Classification loss: 0.05315 | Regression loss: 0.20221 | Running loss: 0.23617\n",
      "Epoch: 18 | Iteration: 396 | Classification loss: 0.01635 | Regression loss: 0.21332 | Running loss: 0.23639\n",
      "Epoch: 18 | Iteration: 397 | Classification loss: 0.03281 | Regression loss: 0.16897 | Running loss: 0.23618\n",
      "Epoch: 18 | Iteration: 398 | Classification loss: 0.02167 | Regression loss: 0.10198 | Running loss: 0.23584\n",
      "Epoch: 18 | Iteration: 399 | Classification loss: 0.04874 | Regression loss: 0.20742 | Running loss: 0.23566\n",
      "Epoch: 18 | Iteration: 400 | Classification loss: 0.03373 | Regression loss: 0.22647 | Running loss: 0.23595\n",
      "Epoch: 18 | Iteration: 401 | Classification loss: 0.00874 | Regression loss: 0.05618 | Running loss: 0.23561\n",
      "Epoch: 18 | Iteration: 402 | Classification loss: 0.06629 | Regression loss: 0.07360 | Running loss: 0.23497\n",
      "Epoch: 18 | Iteration: 403 | Classification loss: 0.15495 | Regression loss: 0.10217 | Running loss: 0.23507\n",
      "Epoch: 18 | Iteration: 404 | Classification loss: 0.05687 | Regression loss: 0.13110 | Running loss: 0.23489\n",
      "Epoch: 18 | Iteration: 405 | Classification loss: 0.00619 | Regression loss: 0.14355 | Running loss: 0.23466\n",
      "Epoch: 18 | Iteration: 406 | Classification loss: 0.06498 | Regression loss: 0.11837 | Running loss: 0.23411\n",
      "Epoch: 18 | Iteration: 407 | Classification loss: 0.05370 | Regression loss: 0.17177 | Running loss: 0.23428\n",
      "Epoch: 18 | Iteration: 408 | Classification loss: 0.00628 | Regression loss: 0.07755 | Running loss: 0.23380\n",
      "Epoch: 18 | Iteration: 409 | Classification loss: 0.01839 | Regression loss: 0.18458 | Running loss: 0.23377\n",
      "Epoch: 18 | Iteration: 410 | Classification loss: 0.03803 | Regression loss: 0.11060 | Running loss: 0.23354\n",
      "Epoch: 18 | Iteration: 411 | Classification loss: 0.01114 | Regression loss: 0.07156 | Running loss: 0.23307\n",
      "Epoch: 18 | Iteration: 412 | Classification loss: 0.09378 | Regression loss: 0.28903 | Running loss: 0.23323\n",
      "Epoch: 18 | Iteration: 413 | Classification loss: 0.04552 | Regression loss: 0.27336 | Running loss: 0.23337\n",
      "Epoch: 18 | Iteration: 414 | Classification loss: 0.02776 | Regression loss: 0.11194 | Running loss: 0.23317\n",
      "Epoch: 18 | Iteration: 415 | Classification loss: 0.01720 | Regression loss: 0.13683 | Running loss: 0.23290\n",
      "Epoch: 18 | Iteration: 416 | Classification loss: 0.00864 | Regression loss: 0.11633 | Running loss: 0.23240\n",
      "Epoch: 18 | Iteration: 417 | Classification loss: 0.03895 | Regression loss: 0.17146 | Running loss: 0.23181\n",
      "Epoch: 18 | Iteration: 418 | Classification loss: 0.03728 | Regression loss: 0.19363 | Running loss: 0.23155\n",
      "Epoch: 18 | Iteration: 419 | Classification loss: 0.03590 | Regression loss: 0.17192 | Running loss: 0.23171\n",
      "Epoch: 18 | Iteration: 420 | Classification loss: 0.04943 | Regression loss: 0.23118 | Running loss: 0.23175\n",
      "Epoch: 18 | Iteration: 421 | Classification loss: 0.02796 | Regression loss: 0.10098 | Running loss: 0.23172\n",
      "Epoch: 18 | Iteration: 422 | Classification loss: 0.02293 | Regression loss: 0.19130 | Running loss: 0.23182\n",
      "Epoch: 18 | Iteration: 423 | Classification loss: 0.02670 | Regression loss: 0.17176 | Running loss: 0.23166\n",
      "Epoch: 18 | Iteration: 424 | Classification loss: 0.03136 | Regression loss: 0.13416 | Running loss: 0.23079\n",
      "Epoch: 18 | Iteration: 425 | Classification loss: 0.05763 | Regression loss: 0.23155 | Running loss: 0.23077\n",
      "Epoch: 18 | Iteration: 426 | Classification loss: 0.01760 | Regression loss: 0.10625 | Running loss: 0.23062\n",
      "Epoch: 18 | Iteration: 427 | Classification loss: 0.01641 | Regression loss: 0.09004 | Running loss: 0.22980\n",
      "Epoch: 18 | Iteration: 428 | Classification loss: 0.08380 | Regression loss: 0.41492 | Running loss: 0.23026\n",
      "Epoch: 18 | Iteration: 429 | Classification loss: 0.03665 | Regression loss: 0.15000 | Running loss: 0.22989\n",
      "Epoch: 18 | Iteration: 430 | Classification loss: 0.05437 | Regression loss: 0.12022 | Running loss: 0.22947\n",
      "Epoch: 18 | Iteration: 431 | Classification loss: 0.03234 | Regression loss: 0.17670 | Running loss: 0.22950\n",
      "Epoch: 18 | Iteration: 432 | Classification loss: 0.01801 | Regression loss: 0.14660 | Running loss: 0.22909\n",
      "Epoch: 18 | Iteration: 433 | Classification loss: 0.03031 | Regression loss: 0.11422 | Running loss: 0.22899\n",
      "Epoch: 18 | Iteration: 434 | Classification loss: 0.03120 | Regression loss: 0.18081 | Running loss: 0.22850\n",
      "Epoch: 18 | Iteration: 435 | Classification loss: 0.03012 | Regression loss: 0.21991 | Running loss: 0.22846\n",
      "Epoch: 18 | Iteration: 436 | Classification loss: 0.03550 | Regression loss: 0.20892 | Running loss: 0.22831\n",
      "Epoch: 18 | Iteration: 437 | Classification loss: 0.00564 | Regression loss: 0.04979 | Running loss: 0.22825\n",
      "Epoch: 18 | Iteration: 438 | Classification loss: 0.01315 | Regression loss: 0.14873 | Running loss: 0.22804\n",
      "Epoch: 18 | Iteration: 439 | Classification loss: 0.04020 | Regression loss: 0.13772 | Running loss: 0.22812\n",
      "Epoch: 18 | Iteration: 440 | Classification loss: 0.38785 | Regression loss: 0.19641 | Running loss: 0.22889\n",
      "Epoch: 18 | Iteration: 441 | Classification loss: 0.03260 | Regression loss: 0.26617 | Running loss: 0.22908\n",
      "Epoch: 18 | Iteration: 442 | Classification loss: 0.02893 | Regression loss: 0.16243 | Running loss: 0.22915\n",
      "Epoch: 18 | Iteration: 443 | Classification loss: 0.03406 | Regression loss: 0.19181 | Running loss: 0.22907\n",
      "Epoch: 18 | Iteration: 444 | Classification loss: 0.03190 | Regression loss: 0.14916 | Running loss: 0.22909\n",
      "Epoch: 18 | Iteration: 445 | Classification loss: 0.02193 | Regression loss: 0.15726 | Running loss: 0.22892\n",
      "Epoch: 18 | Iteration: 446 | Classification loss: 0.01376 | Regression loss: 0.08530 | Running loss: 0.22861\n",
      "Epoch: 18 | Iteration: 447 | Classification loss: 0.06669 | Regression loss: 0.29162 | Running loss: 0.22879\n",
      "Epoch: 18 | Iteration: 448 | Classification loss: 0.01232 | Regression loss: 0.17431 | Running loss: 0.22852\n",
      "Epoch: 18 | Iteration: 449 | Classification loss: 0.02572 | Regression loss: 0.12008 | Running loss: 0.22822\n",
      "Epoch: 18 | Iteration: 450 | Classification loss: 0.04818 | Regression loss: 0.34428 | Running loss: 0.22878\n",
      "Epoch: 18 | Iteration: 451 | Classification loss: 0.03789 | Regression loss: 0.19472 | Running loss: 0.22873\n",
      "Epoch: 18 | Iteration: 452 | Classification loss: 0.05373 | Regression loss: 0.09969 | Running loss: 0.22827\n",
      "Epoch: 18 | Iteration: 453 | Classification loss: 0.01520 | Regression loss: 0.21438 | Running loss: 0.22815\n",
      "Epoch: 18 | Iteration: 454 | Classification loss: 0.02850 | Regression loss: 0.15641 | Running loss: 0.22810\n",
      "Epoch: 18 | Iteration: 455 | Classification loss: 0.02331 | Regression loss: 0.09327 | Running loss: 0.22793\n",
      "Epoch: 18 | Iteration: 456 | Classification loss: 0.03211 | Regression loss: 0.11535 | Running loss: 0.22795\n",
      "Epoch: 18 | Iteration: 457 | Classification loss: 0.01492 | Regression loss: 0.14919 | Running loss: 0.22697\n",
      "Epoch: 18 | Iteration: 458 | Classification loss: 0.03773 | Regression loss: 0.18865 | Running loss: 0.22715\n",
      "Epoch: 18 | Iteration: 459 | Classification loss: 0.03511 | Regression loss: 0.09090 | Running loss: 0.22708\n",
      "Epoch: 18 | Iteration: 460 | Classification loss: 0.01076 | Regression loss: 0.13096 | Running loss: 0.22689\n",
      "Epoch: 18 | Iteration: 461 | Classification loss: 0.01535 | Regression loss: 0.20838 | Running loss: 0.22686\n",
      "Epoch: 18 | Iteration: 462 | Classification loss: 0.02659 | Regression loss: 0.20509 | Running loss: 0.22710\n",
      "Epoch: 18 | Iteration: 463 | Classification loss: 0.02330 | Regression loss: 0.11398 | Running loss: 0.22683\n",
      "Epoch: 18 | Iteration: 464 | Classification loss: 0.07524 | Regression loss: 0.42143 | Running loss: 0.22731\n",
      "Epoch: 18 | Iteration: 465 | Classification loss: 0.03808 | Regression loss: 0.11200 | Running loss: 0.22741\n",
      "Epoch: 18 | Iteration: 466 | Classification loss: 0.01002 | Regression loss: 0.07264 | Running loss: 0.22721\n",
      "Epoch: 18 | Iteration: 467 | Classification loss: 0.01255 | Regression loss: 0.15338 | Running loss: 0.22643\n",
      "Epoch: 18 | Iteration: 468 | Classification loss: 0.04818 | Regression loss: 0.14315 | Running loss: 0.22638\n",
      "Epoch: 18 | Iteration: 469 | Classification loss: 0.02552 | Regression loss: 0.20051 | Running loss: 0.22655\n",
      "Epoch: 18 | Iteration: 470 | Classification loss: 0.13705 | Regression loss: 0.43637 | Running loss: 0.22734\n",
      "Epoch: 18 | Iteration: 471 | Classification loss: 0.04240 | Regression loss: 0.13820 | Running loss: 0.22727\n",
      "Epoch: 18 | Iteration: 472 | Classification loss: 0.04369 | Regression loss: 0.14369 | Running loss: 0.22657\n",
      "Epoch: 18 | Iteration: 473 | Classification loss: 0.03438 | Regression loss: 0.26772 | Running loss: 0.22684\n",
      "Epoch: 18 | Iteration: 474 | Classification loss: 0.06759 | Regression loss: 0.23933 | Running loss: 0.22703\n",
      "Epoch: 18 | Iteration: 475 | Classification loss: 0.04779 | Regression loss: 0.20727 | Running loss: 0.22729\n",
      "Epoch: 18 | Iteration: 476 | Classification loss: 0.03056 | Regression loss: 0.23510 | Running loss: 0.22681\n",
      "Epoch: 18 | Iteration: 477 | Classification loss: 0.02428 | Regression loss: 0.09635 | Running loss: 0.22659\n",
      "Epoch: 18 | Iteration: 478 | Classification loss: 0.02612 | Regression loss: 0.15896 | Running loss: 0.22667\n",
      "Epoch: 18 | Iteration: 479 | Classification loss: 0.06397 | Regression loss: 0.24905 | Running loss: 0.22680\n",
      "Epoch: 18 | Iteration: 480 | Classification loss: 0.00789 | Regression loss: 0.08049 | Running loss: 0.22625\n",
      "Epoch: 18 | Iteration: 481 | Classification loss: 0.02311 | Regression loss: 0.16590 | Running loss: 0.22634\n",
      "Epoch: 18 | Iteration: 482 | Classification loss: 0.11179 | Regression loss: 0.24463 | Running loss: 0.22673\n",
      "Epoch: 18 | Iteration: 483 | Classification loss: 0.26905 | Regression loss: 0.46790 | Running loss: 0.22792\n",
      "Epoch: 18 | Iteration: 484 | Classification loss: 0.21628 | Regression loss: 0.17773 | Running loss: 0.22824\n",
      "Epoch: 18 | Iteration: 485 | Classification loss: 0.02022 | Regression loss: 0.13932 | Running loss: 0.22793\n",
      "Epoch: 18 | Iteration: 486 | Classification loss: 0.06232 | Regression loss: 0.14399 | Running loss: 0.22759\n",
      "Epoch: 18 | Iteration: 487 | Classification loss: 0.07305 | Regression loss: 0.28118 | Running loss: 0.22793\n",
      "Epoch: 18 | Iteration: 488 | Classification loss: 0.14765 | Regression loss: 0.31550 | Running loss: 0.22852\n",
      "Epoch: 18 | Iteration: 489 | Classification loss: 0.06500 | Regression loss: 0.29097 | Running loss: 0.22853\n",
      "Epoch: 18 | Iteration: 490 | Classification loss: 0.06121 | Regression loss: 0.18272 | Running loss: 0.22843\n",
      "Epoch: 18 | Iteration: 491 | Classification loss: 0.05132 | Regression loss: 0.22160 | Running loss: 0.22862\n",
      "Epoch: 18 | Iteration: 492 | Classification loss: 0.04834 | Regression loss: 0.19935 | Running loss: 0.22879\n",
      "Epoch: 18 | Iteration: 493 | Classification loss: 0.04787 | Regression loss: 0.11999 | Running loss: 0.22802\n",
      "Epoch: 18 | Iteration: 494 | Classification loss: 0.02098 | Regression loss: 0.10432 | Running loss: 0.22759\n",
      "Epoch: 18 | Iteration: 495 | Classification loss: 0.13916 | Regression loss: 0.22648 | Running loss: 0.22774\n",
      "Epoch: 18 | Iteration: 496 | Classification loss: 0.05364 | Regression loss: 0.22744 | Running loss: 0.22795\n",
      "Epoch: 18 | Iteration: 497 | Classification loss: 0.02131 | Regression loss: 0.07925 | Running loss: 0.22780\n",
      "Epoch: 18 | Iteration: 498 | Classification loss: 0.03008 | Regression loss: 0.09496 | Running loss: 0.22787\n",
      "Epoch: 18 | Iteration: 499 | Classification loss: 0.02874 | Regression loss: 0.18126 | Running loss: 0.22803\n",
      "Epoch: 18 | Iteration: 500 | Classification loss: 0.04760 | Regression loss: 0.21301 | Running loss: 0.22807\n",
      "Epoch: 18 | Iteration: 501 | Classification loss: 0.04402 | Regression loss: 0.16443 | Running loss: 0.22820\n",
      "Epoch: 18 | Iteration: 502 | Classification loss: 0.01398 | Regression loss: 0.09418 | Running loss: 0.22785\n",
      "Epoch: 18 | Iteration: 503 | Classification loss: 0.03936 | Regression loss: 0.14000 | Running loss: 0.22780\n",
      "Epoch: 18 | Iteration: 504 | Classification loss: 0.00632 | Regression loss: 0.13240 | Running loss: 0.22775\n",
      "Epoch: 18 | Iteration: 505 | Classification loss: 0.09664 | Regression loss: 0.27009 | Running loss: 0.22809\n",
      "Epoch: 18 | Iteration: 506 | Classification loss: 0.02346 | Regression loss: 0.16255 | Running loss: 0.22744\n",
      "Epoch: 18 | Iteration: 507 | Classification loss: 0.08554 | Regression loss: 0.34318 | Running loss: 0.22787\n",
      "Epoch: 18 | Iteration: 508 | Classification loss: 0.01495 | Regression loss: 0.10245 | Running loss: 0.22761\n",
      "Epoch: 18 | Iteration: 509 | Classification loss: 0.01698 | Regression loss: 0.24866 | Running loss: 0.22743\n",
      "Epoch: 18 | Iteration: 510 | Classification loss: 0.01956 | Regression loss: 0.26342 | Running loss: 0.22757\n",
      "Epoch: 18 | Iteration: 511 | Classification loss: 0.02406 | Regression loss: 0.17566 | Running loss: 0.22786\n",
      "Epoch: 18 | Iteration: 512 | Classification loss: 0.04111 | Regression loss: 0.15190 | Running loss: 0.22796\n",
      "Epoch: 18 | Iteration: 513 | Classification loss: 0.04355 | Regression loss: 0.20128 | Running loss: 0.22815\n",
      "Epoch: 18 | Iteration: 514 | Classification loss: 0.01853 | Regression loss: 0.07505 | Running loss: 0.22784\n",
      "Epoch: 18 | Iteration: 515 | Classification loss: 0.02742 | Regression loss: 0.20516 | Running loss: 0.22774\n",
      "Epoch: 18 | Iteration: 516 | Classification loss: 0.01374 | Regression loss: 0.14627 | Running loss: 0.22778\n",
      "Epoch: 18 | Iteration: 517 | Classification loss: 0.02299 | Regression loss: 0.10944 | Running loss: 0.22763\n",
      "Epoch: 18 | Iteration: 518 | Classification loss: 0.04237 | Regression loss: 0.20582 | Running loss: 0.22774\n",
      "Epoch: 18 | Iteration: 519 | Classification loss: 0.02656 | Regression loss: 0.11911 | Running loss: 0.22760\n",
      "Epoch: 18 | Iteration: 520 | Classification loss: 0.02219 | Regression loss: 0.15311 | Running loss: 0.22759\n",
      "Epoch: 18 | Iteration: 521 | Classification loss: 0.01909 | Regression loss: 0.06717 | Running loss: 0.22746\n",
      "Epoch: 18 | Iteration: 522 | Classification loss: 0.02682 | Regression loss: 0.17206 | Running loss: 0.22739\n",
      "Epoch: 18 | Iteration: 523 | Classification loss: 0.01607 | Regression loss: 0.14079 | Running loss: 0.22705\n",
      "Epoch: 18 | Iteration: 524 | Classification loss: 0.02469 | Regression loss: 0.12677 | Running loss: 0.22686\n",
      "Epoch: 18 | Iteration: 525 | Classification loss: 0.07136 | Regression loss: 0.30177 | Running loss: 0.22712\n",
      "Epoch: 18 | Iteration: 526 | Classification loss: 0.01491 | Regression loss: 0.07297 | Running loss: 0.22688\n",
      "Epoch: 18 | Iteration: 527 | Classification loss: 0.02448 | Regression loss: 0.25977 | Running loss: 0.22712\n",
      "Epoch: 18 | Iteration: 528 | Classification loss: 0.07476 | Regression loss: 0.24239 | Running loss: 0.22747\n",
      "Epoch: 18 | Iteration: 529 | Classification loss: 0.12685 | Regression loss: 0.17194 | Running loss: 0.22756\n",
      "Epoch: 18 | Iteration: 530 | Classification loss: 0.04951 | Regression loss: 0.31435 | Running loss: 0.22779\n",
      "Epoch: 18 | Iteration: 531 | Classification loss: 0.03493 | Regression loss: 0.17267 | Running loss: 0.22761\n",
      "Epoch: 18 | Iteration: 532 | Classification loss: 0.00887 | Regression loss: 0.08522 | Running loss: 0.22744\n",
      "Epoch: 18 | Iteration: 533 | Classification loss: 0.06155 | Regression loss: 0.25241 | Running loss: 0.22772\n",
      "Epoch: 18 | Iteration: 534 | Classification loss: 0.01969 | Regression loss: 0.19427 | Running loss: 0.22725\n",
      "Epoch: 18 | Iteration: 535 | Classification loss: 0.02018 | Regression loss: 0.12342 | Running loss: 0.22724\n",
      "Epoch: 18 | Iteration: 536 | Classification loss: 0.03525 | Regression loss: 0.18299 | Running loss: 0.22694\n",
      "Epoch: 18 | Iteration: 537 | Classification loss: 0.06206 | Regression loss: 0.23258 | Running loss: 0.22731\n",
      "Epoch: 18 | Iteration: 538 | Classification loss: 0.02933 | Regression loss: 0.16576 | Running loss: 0.22722\n",
      "Epoch: 18 | Iteration: 539 | Classification loss: 0.03120 | Regression loss: 0.18010 | Running loss: 0.22703\n",
      "Epoch: 18 | Iteration: 540 | Classification loss: 0.06639 | Regression loss: 0.15923 | Running loss: 0.22716\n",
      "Epoch: 18 | Iteration: 541 | Classification loss: 0.10352 | Regression loss: 0.14808 | Running loss: 0.22723\n",
      "Epoch: 18 | Iteration: 542 | Classification loss: 0.09910 | Regression loss: 0.21425 | Running loss: 0.22737\n",
      "Epoch: 18 | Iteration: 543 | Classification loss: 0.09145 | Regression loss: 0.24518 | Running loss: 0.22785\n",
      "Epoch: 18 | Iteration: 544 | Classification loss: 0.08148 | Regression loss: 0.19361 | Running loss: 0.22784\n",
      "Epoch: 18 | Iteration: 545 | Classification loss: 0.07536 | Regression loss: 0.13825 | Running loss: 0.22789\n",
      "Epoch: 18 | Iteration: 546 | Classification loss: 0.01560 | Regression loss: 0.10670 | Running loss: 0.22748\n",
      "Epoch: 18 | Iteration: 547 | Classification loss: 0.03133 | Regression loss: 0.12327 | Running loss: 0.22755\n",
      "Epoch: 18 | Iteration: 548 | Classification loss: 0.32115 | Regression loss: 0.94699 | Running loss: 0.22922\n",
      "Epoch: 18 | Iteration: 549 | Classification loss: 0.01781 | Regression loss: 0.12727 | Running loss: 0.22880\n",
      "Epoch: 18 | Iteration: 550 | Classification loss: 0.05102 | Regression loss: 0.23251 | Running loss: 0.22908\n",
      "Epoch: 18 | Iteration: 551 | Classification loss: 0.02061 | Regression loss: 0.16777 | Running loss: 0.22905\n",
      "Epoch: 18 | Iteration: 552 | Classification loss: 0.02167 | Regression loss: 0.17321 | Running loss: 0.22879\n",
      "Epoch: 18 | Iteration: 553 | Classification loss: 0.03779 | Regression loss: 0.23816 | Running loss: 0.22827\n",
      "Epoch: 18 | Iteration: 554 | Classification loss: 0.04769 | Regression loss: 0.16311 | Running loss: 0.22833\n",
      "Epoch: 18 | Iteration: 555 | Classification loss: 0.00912 | Regression loss: 0.11313 | Running loss: 0.22840\n",
      "Epoch: 18 | Iteration: 556 | Classification loss: 0.02641 | Regression loss: 0.14680 | Running loss: 0.22819\n",
      "Epoch: 18 | Iteration: 557 | Classification loss: 0.07571 | Regression loss: 0.20880 | Running loss: 0.22825\n",
      "Epoch: 18 | Iteration: 558 | Classification loss: 0.03481 | Regression loss: 0.27828 | Running loss: 0.22839\n",
      "Epoch: 18 | Iteration: 559 | Classification loss: 0.03950 | Regression loss: 0.17351 | Running loss: 0.22817\n",
      "Epoch: 18 | Iteration: 560 | Classification loss: 0.02043 | Regression loss: 0.12322 | Running loss: 0.22800\n",
      "Epoch: 18 | Iteration: 561 | Classification loss: 0.06214 | Regression loss: 0.23662 | Running loss: 0.22813\n",
      "Epoch: 18 | Iteration: 562 | Classification loss: 0.08018 | Regression loss: 0.28055 | Running loss: 0.22863\n",
      "Epoch: 18 | Iteration: 563 | Classification loss: 0.00772 | Regression loss: 0.07915 | Running loss: 0.22854\n",
      "Epoch: 18 | Iteration: 564 | Classification loss: 0.01109 | Regression loss: 0.08317 | Running loss: 0.22838\n",
      "Epoch: 18 | Iteration: 565 | Classification loss: 0.01361 | Regression loss: 0.14606 | Running loss: 0.22834\n",
      "Epoch: 18 | Iteration: 566 | Classification loss: 0.02126 | Regression loss: 0.06743 | Running loss: 0.22835\n",
      "Epoch: 18 | Iteration: 567 | Classification loss: 0.08509 | Regression loss: 0.18057 | Running loss: 0.22825\n",
      "Epoch: 18 | Iteration: 568 | Classification loss: 0.02859 | Regression loss: 0.11154 | Running loss: 0.22836\n",
      "Epoch: 18 | Iteration: 569 | Classification loss: 0.03553 | Regression loss: 0.15217 | Running loss: 0.22806\n",
      "Epoch: 18 | Iteration: 570 | Classification loss: 0.03014 | Regression loss: 0.15346 | Running loss: 0.22809\n",
      "Epoch: 18 | Iteration: 571 | Classification loss: 0.01399 | Regression loss: 0.11617 | Running loss: 0.22809\n",
      "Epoch: 18 | Iteration: 572 | Classification loss: 0.02735 | Regression loss: 0.16686 | Running loss: 0.22808\n",
      "Epoch: 18 | Iteration: 573 | Classification loss: 0.02008 | Regression loss: 0.08045 | Running loss: 0.22800\n",
      "Epoch: 18 | Iteration: 574 | Classification loss: 0.02254 | Regression loss: 0.15446 | Running loss: 0.22792\n",
      "Epoch: 18 | Iteration: 575 | Classification loss: 0.04242 | Regression loss: 0.18907 | Running loss: 0.22813\n",
      "Epoch: 18 | Iteration: 576 | Classification loss: 0.07730 | Regression loss: 0.33560 | Running loss: 0.22870\n",
      "Epoch: 18 | Iteration: 577 | Classification loss: 0.03788 | Regression loss: 0.16272 | Running loss: 0.22847\n",
      "Epoch: 18 | Iteration: 578 | Classification loss: 0.10069 | Regression loss: 0.25208 | Running loss: 0.22893\n",
      "Epoch: 18 | Iteration: 579 | Classification loss: 0.04622 | Regression loss: 0.30466 | Running loss: 0.22920\n",
      "Epoch: 18 | Iteration: 580 | Classification loss: 0.01395 | Regression loss: 0.11827 | Running loss: 0.22922\n",
      "Epoch: 18 | Iteration: 581 | Classification loss: 0.01191 | Regression loss: 0.09956 | Running loss: 0.22878\n",
      "Epoch: 18 | Iteration: 582 | Classification loss: 0.01158 | Regression loss: 0.18265 | Running loss: 0.22849\n",
      "Epoch: 18 | Iteration: 583 | Classification loss: 0.03632 | Regression loss: 0.13153 | Running loss: 0.22861\n",
      "Epoch: 18 | Iteration: 584 | Classification loss: 0.02982 | Regression loss: 0.13820 | Running loss: 0.22862\n",
      "Epoch: 18 | Iteration: 585 | Classification loss: 0.05014 | Regression loss: 0.27798 | Running loss: 0.22864\n",
      "Epoch: 18 | Iteration: 586 | Classification loss: 0.00803 | Regression loss: 0.14716 | Running loss: 0.22846\n",
      "Epoch: 18 | Iteration: 587 | Classification loss: 0.01484 | Regression loss: 0.16681 | Running loss: 0.22835\n",
      "Epoch: 18 | Iteration: 588 | Classification loss: 0.01358 | Regression loss: 0.07631 | Running loss: 0.22809\n",
      "Epoch: 18 | Iteration: 589 | Classification loss: 0.04440 | Regression loss: 0.30269 | Running loss: 0.22798\n",
      "Epoch: 18 | Iteration: 590 | Classification loss: 0.02478 | Regression loss: 0.14221 | Running loss: 0.22802\n",
      "Epoch: 18 | Iteration: 591 | Classification loss: 0.03790 | Regression loss: 0.21157 | Running loss: 0.22818\n",
      "Epoch: 18 | Iteration: 592 | Classification loss: 0.02290 | Regression loss: 0.21824 | Running loss: 0.22810\n",
      "Epoch: 18 | Iteration: 593 | Classification loss: 0.02945 | Regression loss: 0.23308 | Running loss: 0.22817\n",
      "Epoch: 18 | Iteration: 594 | Classification loss: 0.02837 | Regression loss: 0.16925 | Running loss: 0.22819\n",
      "Epoch: 18 | Iteration: 595 | Classification loss: 0.02891 | Regression loss: 0.14414 | Running loss: 0.22815\n",
      "Epoch: 18 | Iteration: 596 | Classification loss: 0.02542 | Regression loss: 0.20678 | Running loss: 0.22823\n",
      "Epoch: 18 | Iteration: 597 | Classification loss: 0.10957 | Regression loss: 0.34437 | Running loss: 0.22879\n",
      "Epoch: 18 | Iteration: 598 | Classification loss: 0.04062 | Regression loss: 0.21185 | Running loss: 0.22901\n",
      "Epoch: 18 | Iteration: 599 | Classification loss: 0.07209 | Regression loss: 0.28020 | Running loss: 0.22933\n",
      "Epoch: 18 | Iteration: 600 | Classification loss: 0.02291 | Regression loss: 0.18517 | Running loss: 0.22955\n",
      "Epoch: 18 | Iteration: 601 | Classification loss: 0.01693 | Regression loss: 0.12079 | Running loss: 0.22966\n",
      "Epoch: 18 | Iteration: 602 | Classification loss: 0.04358 | Regression loss: 0.18339 | Running loss: 0.22986\n",
      "Epoch: 18 | Iteration: 603 | Classification loss: 0.01877 | Regression loss: 0.08864 | Running loss: 0.22985\n",
      "Epoch: 18 | Iteration: 604 | Classification loss: 0.00985 | Regression loss: 0.13237 | Running loss: 0.22968\n",
      "Epoch: 18 | Iteration: 605 | Classification loss: 0.05284 | Regression loss: 0.34755 | Running loss: 0.23019\n",
      "Epoch: 18 | Iteration: 606 | Classification loss: 0.06450 | Regression loss: 0.19529 | Running loss: 0.23014\n",
      "Epoch: 18 | Iteration: 607 | Classification loss: 0.01131 | Regression loss: 0.10873 | Running loss: 0.23006\n",
      "Epoch: 18 | Iteration: 608 | Classification loss: 0.03200 | Regression loss: 0.20996 | Running loss: 0.23032\n",
      "Epoch: 18 | Iteration: 609 | Classification loss: 0.03058 | Regression loss: 0.14595 | Running loss: 0.23024\n",
      "Epoch: 18 | Iteration: 610 | Classification loss: 0.03691 | Regression loss: 0.22981 | Running loss: 0.23056\n",
      "Epoch: 18 | Iteration: 611 | Classification loss: 0.01277 | Regression loss: 0.13322 | Running loss: 0.23048\n",
      "Epoch: 18 | Iteration: 612 | Classification loss: 0.02313 | Regression loss: 0.12783 | Running loss: 0.23036\n",
      "Epoch: 18 | Iteration: 613 | Classification loss: 0.02650 | Regression loss: 0.16312 | Running loss: 0.23021\n",
      "Epoch: 18 | Iteration: 614 | Classification loss: 0.03184 | Regression loss: 0.24159 | Running loss: 0.23055\n",
      "Epoch: 18 | Iteration: 615 | Classification loss: 0.01381 | Regression loss: 0.10152 | Running loss: 0.23056\n",
      "Epoch: 18 | Iteration: 616 | Classification loss: 0.04015 | Regression loss: 0.28287 | Running loss: 0.23094\n",
      "Epoch: 18 | Iteration: 617 | Classification loss: 0.05287 | Regression loss: 0.17220 | Running loss: 0.23095\n",
      "Epoch: 18 | Iteration: 618 | Classification loss: 0.05960 | Regression loss: 0.08413 | Running loss: 0.23098\n",
      "Epoch: 18 | Iteration: 619 | Classification loss: 0.01392 | Regression loss: 0.12027 | Running loss: 0.23094\n",
      "Epoch: 18 | Iteration: 620 | Classification loss: 0.02158 | Regression loss: 0.15162 | Running loss: 0.23118\n",
      "Epoch: 18 | Iteration: 621 | Classification loss: 0.01926 | Regression loss: 0.15076 | Running loss: 0.23132\n",
      "Epoch: 18 | Iteration: 622 | Classification loss: 0.06176 | Regression loss: 0.23716 | Running loss: 0.23130\n",
      "Epoch: 18 | Iteration: 623 | Classification loss: 0.11947 | Regression loss: 0.28819 | Running loss: 0.23180\n",
      "Epoch: 18 | Iteration: 624 | Classification loss: 0.06023 | Regression loss: 0.20809 | Running loss: 0.23174\n",
      "Epoch: 18 | Iteration: 625 | Classification loss: 0.03441 | Regression loss: 0.09360 | Running loss: 0.23151\n",
      "Epoch: 18 | Iteration: 626 | Classification loss: 0.02471 | Regression loss: 0.21445 | Running loss: 0.23163\n",
      "Epoch: 18 | Iteration: 627 | Classification loss: 0.01596 | Regression loss: 0.19300 | Running loss: 0.23179\n",
      "Epoch: 18 | Iteration: 628 | Classification loss: 0.05690 | Regression loss: 0.27789 | Running loss: 0.23203\n",
      "Epoch: 18 | Iteration: 629 | Classification loss: 0.03217 | Regression loss: 0.14634 | Running loss: 0.23210\n",
      "Epoch: 18 | Iteration: 630 | Classification loss: 0.05262 | Regression loss: 0.27111 | Running loss: 0.23228\n",
      "Epoch: 18 | Iteration: 631 | Classification loss: 0.02484 | Regression loss: 0.10211 | Running loss: 0.23208\n",
      "Epoch: 18 | Iteration: 632 | Classification loss: 0.09219 | Regression loss: 0.22686 | Running loss: 0.23236\n",
      "Epoch: 18 | Iteration: 633 | Classification loss: 0.14676 | Regression loss: 0.29811 | Running loss: 0.23295\n",
      "Epoch: 18 | Iteration: 634 | Classification loss: 0.00542 | Regression loss: 0.10358 | Running loss: 0.23294\n",
      "Epoch: 18 | Iteration: 635 | Classification loss: 0.08288 | Regression loss: 0.23044 | Running loss: 0.23268\n",
      "Epoch: 18 | Iteration: 636 | Classification loss: 0.05772 | Regression loss: 0.16146 | Running loss: 0.23284\n",
      "Epoch: 18 | Iteration: 637 | Classification loss: 0.02982 | Regression loss: 0.23821 | Running loss: 0.23321\n",
      "Epoch: 18 | Iteration: 638 | Classification loss: 0.03156 | Regression loss: 0.13817 | Running loss: 0.23293\n",
      "Epoch: 18 | Iteration: 639 | Classification loss: 0.03502 | Regression loss: 0.14938 | Running loss: 0.23306\n",
      "Epoch: 18 | Iteration: 640 | Classification loss: 0.06455 | Regression loss: 0.16382 | Running loss: 0.23335\n",
      "Epoch: 18 | Iteration: 641 | Classification loss: 0.02179 | Regression loss: 0.15061 | Running loss: 0.23324\n",
      "Epoch: 18 | Iteration: 642 | Classification loss: 0.00648 | Regression loss: 0.05060 | Running loss: 0.23286\n",
      "Epoch: 18 | Iteration: 643 | Classification loss: 0.14709 | Regression loss: 0.28019 | Running loss: 0.23316\n",
      "Epoch: 18 | Iteration: 644 | Classification loss: 0.09528 | Regression loss: 0.09614 | Running loss: 0.23314\n",
      "Epoch: 18 | Iteration: 645 | Classification loss: 0.00804 | Regression loss: 0.06545 | Running loss: 0.23309\n",
      "Epoch: 18 | Iteration: 646 | Classification loss: 0.01886 | Regression loss: 0.15168 | Running loss: 0.23325\n",
      "Epoch: 18 | Iteration: 647 | Classification loss: 0.06287 | Regression loss: 0.17950 | Running loss: 0.23351\n",
      "Epoch: 18 | Iteration: 648 | Classification loss: 0.02472 | Regression loss: 0.19582 | Running loss: 0.23312\n",
      "Epoch: 18 | Iteration: 649 | Classification loss: 0.14343 | Regression loss: 0.42116 | Running loss: 0.23382\n",
      "Epoch: 18 | Iteration: 650 | Classification loss: 0.08424 | Regression loss: 0.14810 | Running loss: 0.23357\n",
      "Epoch: 18 | Iteration: 651 | Classification loss: 0.02449 | Regression loss: 0.13889 | Running loss: 0.23331\n",
      "Epoch: 18 | Iteration: 652 | Classification loss: 0.03962 | Regression loss: 0.20993 | Running loss: 0.23342\n",
      "Epoch: 18 | Iteration: 653 | Classification loss: 0.01505 | Regression loss: 0.21175 | Running loss: 0.23330\n",
      "Epoch: 18 | Iteration: 654 | Classification loss: 0.04310 | Regression loss: 0.20846 | Running loss: 0.23352\n",
      "Epoch: 18 | Iteration: 655 | Classification loss: 0.03688 | Regression loss: 0.13633 | Running loss: 0.23357\n",
      "Epoch: 18 | Iteration: 656 | Classification loss: 0.01262 | Regression loss: 0.10517 | Running loss: 0.23354\n",
      "Epoch: 18 | Iteration: 657 | Classification loss: 0.02028 | Regression loss: 0.13464 | Running loss: 0.23302\n",
      "Epoch: 18 | Iteration: 658 | Classification loss: 0.01061 | Regression loss: 0.09605 | Running loss: 0.23296\n",
      "Epoch: 18 | Iteration: 659 | Classification loss: 0.20133 | Regression loss: 0.41478 | Running loss: 0.23362\n",
      "Epoch: 18 | Iteration: 660 | Classification loss: 0.05461 | Regression loss: 0.26514 | Running loss: 0.23356\n",
      "Epoch: 18 | Iteration: 661 | Classification loss: 0.03822 | Regression loss: 0.21337 | Running loss: 0.23373\n",
      "Epoch: 18 | Iteration: 662 | Classification loss: 0.00727 | Regression loss: 0.13937 | Running loss: 0.23295\n",
      "Epoch: 18 | Iteration: 663 | Classification loss: 0.09169 | Regression loss: 0.25380 | Running loss: 0.23345\n",
      "Epoch: 18 | Iteration: 664 | Classification loss: 0.05352 | Regression loss: 0.21853 | Running loss: 0.23360\n",
      "Epoch: 18 | Iteration: 665 | Classification loss: 0.01756 | Regression loss: 0.15127 | Running loss: 0.23360\n",
      "Epoch: 18 | Iteration: 666 | Classification loss: 0.04261 | Regression loss: 0.16846 | Running loss: 0.23371\n",
      "Epoch: 18 | Iteration: 667 | Classification loss: 0.04018 | Regression loss: 0.18865 | Running loss: 0.23383\n",
      "Epoch: 18 | Iteration: 668 | Classification loss: 0.02452 | Regression loss: 0.24588 | Running loss: 0.23393\n",
      "Epoch: 18 | Iteration: 669 | Classification loss: 0.05676 | Regression loss: 0.23410 | Running loss: 0.23396\n",
      "Epoch: 18 | Iteration: 670 | Classification loss: 0.01533 | Regression loss: 0.14810 | Running loss: 0.23324\n",
      "Epoch: 18 | Iteration: 671 | Classification loss: 0.02877 | Regression loss: 0.13724 | Running loss: 0.23300\n",
      "Epoch: 18 | Iteration: 672 | Classification loss: 0.00687 | Regression loss: 0.07684 | Running loss: 0.23294\n",
      "Epoch: 18 | Iteration: 673 | Classification loss: 0.14471 | Regression loss: 0.20016 | Running loss: 0.23343\n",
      "Epoch: 18 | Iteration: 674 | Classification loss: 0.02267 | Regression loss: 0.10052 | Running loss: 0.23346\n",
      "Epoch: 18 | Iteration: 675 | Classification loss: 0.02151 | Regression loss: 0.16396 | Running loss: 0.23313\n",
      "Epoch: 18 | Iteration: 676 | Classification loss: 0.01491 | Regression loss: 0.15583 | Running loss: 0.23313\n",
      "Epoch: 18 | Iteration: 677 | Classification loss: 0.14967 | Regression loss: 0.36033 | Running loss: 0.23379\n",
      "Epoch: 18 | Iteration: 678 | Classification loss: 0.00862 | Regression loss: 0.10862 | Running loss: 0.23352\n",
      "Epoch: 18 | Iteration: 679 | Classification loss: 0.01556 | Regression loss: 0.12396 | Running loss: 0.23206\n",
      "Epoch: 18 | Iteration: 680 | Classification loss: 0.12043 | Regression loss: 0.26226 | Running loss: 0.23253\n",
      "Epoch: 18 | Iteration: 681 | Classification loss: 0.03100 | Regression loss: 0.05364 | Running loss: 0.23242\n",
      "Epoch: 18 | Iteration: 682 | Classification loss: 0.06694 | Regression loss: 0.30959 | Running loss: 0.23258\n",
      "Epoch: 18 | Iteration: 683 | Classification loss: 0.10434 | Regression loss: 0.32882 | Running loss: 0.23286\n",
      "Epoch: 18 | Iteration: 684 | Classification loss: 0.04253 | Regression loss: 0.20056 | Running loss: 0.23303\n",
      "Epoch: 18 | Iteration: 685 | Classification loss: 0.05777 | Regression loss: 0.23918 | Running loss: 0.23325\n",
      "Epoch: 18 | Iteration: 686 | Classification loss: 0.01336 | Regression loss: 0.12214 | Running loss: 0.23329\n",
      "Epoch: 18 | Iteration: 687 | Classification loss: 0.05351 | Regression loss: 0.20174 | Running loss: 0.23342\n",
      "Epoch: 18 | Iteration: 688 | Classification loss: 0.01714 | Regression loss: 0.13442 | Running loss: 0.23338\n",
      "Epoch: 18 | Iteration: 689 | Classification loss: 0.02634 | Regression loss: 0.20800 | Running loss: 0.23349\n",
      "Epoch: 18 | Iteration: 690 | Classification loss: 0.00515 | Regression loss: 0.07237 | Running loss: 0.23328\n",
      "Epoch: 18 | Iteration: 691 | Classification loss: 0.07468 | Regression loss: 0.13906 | Running loss: 0.23311\n",
      "Epoch: 18 | Iteration: 692 | Classification loss: 0.05221 | Regression loss: 0.13781 | Running loss: 0.23321\n",
      "Epoch: 18 | Iteration: 693 | Classification loss: 0.02872 | Regression loss: 0.20428 | Running loss: 0.23345\n",
      "Epoch: 18 | Iteration: 694 | Classification loss: 0.03096 | Regression loss: 0.17063 | Running loss: 0.23351\n",
      "Epoch: 18 | Iteration: 695 | Classification loss: 0.02113 | Regression loss: 0.06716 | Running loss: 0.23331\n",
      "Epoch: 18 | Iteration: 696 | Classification loss: 0.01604 | Regression loss: 0.11079 | Running loss: 0.23251\n",
      "Epoch: 18 | Iteration: 697 | Classification loss: 0.01603 | Regression loss: 0.12283 | Running loss: 0.23246\n",
      "Epoch: 18 | Iteration: 698 | Classification loss: 0.01952 | Regression loss: 0.15147 | Running loss: 0.23217\n",
      "Epoch: 18 | Iteration: 699 | Classification loss: 0.01312 | Regression loss: 0.08582 | Running loss: 0.23211\n",
      "Epoch: 18 | Iteration: 700 | Classification loss: 0.06018 | Regression loss: 0.12916 | Running loss: 0.23214\n",
      "Epoch: 18 | Iteration: 701 | Classification loss: 0.01323 | Regression loss: 0.11617 | Running loss: 0.23169\n",
      "Epoch: 18 | Iteration: 702 | Classification loss: 0.17063 | Regression loss: 0.46005 | Running loss: 0.23210\n",
      "Epoch: 18 | Iteration: 703 | Classification loss: 0.06718 | Regression loss: 0.37966 | Running loss: 0.23256\n",
      "Epoch: 18 | Iteration: 704 | Classification loss: 0.05830 | Regression loss: 0.15440 | Running loss: 0.23260\n",
      "Epoch: 18 | Iteration: 705 | Classification loss: 0.01168 | Regression loss: 0.12297 | Running loss: 0.23244\n",
      "Epoch: 18 | Iteration: 706 | Classification loss: 0.02688 | Regression loss: 0.20192 | Running loss: 0.23256\n",
      "Epoch: 18 | Iteration: 707 | Classification loss: 0.09609 | Regression loss: 0.30114 | Running loss: 0.23303\n",
      "Epoch: 18 | Iteration: 708 | Classification loss: 0.01475 | Regression loss: 0.20221 | Running loss: 0.23313\n",
      "Epoch: 18 | Iteration: 709 | Classification loss: 0.01778 | Regression loss: 0.14501 | Running loss: 0.23322\n",
      "Epoch: 18 | Iteration: 710 | Classification loss: 0.01484 | Regression loss: 0.05402 | Running loss: 0.23291\n",
      "Epoch: 18 | Iteration: 711 | Classification loss: 0.15611 | Regression loss: 0.31938 | Running loss: 0.23364\n",
      "Epoch: 18 | Iteration: 712 | Classification loss: 0.05739 | Regression loss: 0.19587 | Running loss: 0.23390\n",
      "Epoch: 18 | Iteration: 713 | Classification loss: 0.07719 | Regression loss: 0.19536 | Running loss: 0.23404\n",
      "Epoch: 18 | Iteration: 714 | Classification loss: 0.01556 | Regression loss: 0.14714 | Running loss: 0.23392\n",
      "Epoch: 18 | Iteration: 715 | Classification loss: 0.01440 | Regression loss: 0.07649 | Running loss: 0.23343\n",
      "Epoch: 18 | Iteration: 716 | Classification loss: 0.00931 | Regression loss: 0.08717 | Running loss: 0.23298\n",
      "Epoch: 18 | Iteration: 717 | Classification loss: 0.06279 | Regression loss: 0.11530 | Running loss: 0.23256\n",
      "Epoch: 18 | Iteration: 718 | Classification loss: 0.02893 | Regression loss: 0.14504 | Running loss: 0.23250\n",
      "Epoch: 18 | Iteration: 719 | Classification loss: 0.06451 | Regression loss: 0.29920 | Running loss: 0.23287\n",
      "Epoch: 18 | Iteration: 720 | Classification loss: 0.01183 | Regression loss: 0.13130 | Running loss: 0.23271\n",
      "Epoch: 18 | Iteration: 721 | Classification loss: 0.18923 | Regression loss: 0.16728 | Running loss: 0.23306\n",
      "Epoch: 18 | Iteration: 722 | Classification loss: 0.13651 | Regression loss: 0.37437 | Running loss: 0.23371\n",
      "Epoch: 18 | Iteration: 723 | Classification loss: 0.01836 | Regression loss: 0.19545 | Running loss: 0.23363\n",
      "Epoch: 18 | Iteration: 724 | Classification loss: 0.01759 | Regression loss: 0.14471 | Running loss: 0.23369\n",
      "Epoch: 18 | Iteration: 725 | Classification loss: 0.00981 | Regression loss: 0.10642 | Running loss: 0.23361\n",
      "Epoch: 18 | Iteration: 726 | Classification loss: 0.02784 | Regression loss: 0.19941 | Running loss: 0.23307\n",
      "Epoch: 18 | Iteration: 727 | Classification loss: 0.02905 | Regression loss: 0.09912 | Running loss: 0.23299\n",
      "Epoch: 18 | Iteration: 728 | Classification loss: 0.07297 | Regression loss: 0.38504 | Running loss: 0.23374\n",
      "Epoch: 18 | Iteration: 729 | Classification loss: 0.02039 | Regression loss: 0.12601 | Running loss: 0.23293\n",
      "Epoch: 18 | Iteration: 730 | Classification loss: 0.02217 | Regression loss: 0.14493 | Running loss: 0.23254\n",
      "Epoch: 18 | Iteration: 731 | Classification loss: 0.03500 | Regression loss: 0.28333 | Running loss: 0.23265\n",
      "Epoch: 18 | Iteration: 732 | Classification loss: 0.06023 | Regression loss: 0.21187 | Running loss: 0.23283\n",
      "Epoch: 18 | Iteration: 733 | Classification loss: 0.01149 | Regression loss: 0.13343 | Running loss: 0.23265\n",
      "Epoch: 18 | Iteration: 734 | Classification loss: 0.02313 | Regression loss: 0.20729 | Running loss: 0.23243\n",
      "Epoch: 18 | Iteration: 735 | Classification loss: 0.02338 | Regression loss: 0.17566 | Running loss: 0.23247\n",
      "Epoch: 18 | Iteration: 736 | Classification loss: 0.03534 | Regression loss: 0.19867 | Running loss: 0.23271\n",
      "Epoch: 18 | Iteration: 737 | Classification loss: 0.06000 | Regression loss: 0.15828 | Running loss: 0.23283\n",
      "Epoch: 18 | Iteration: 738 | Classification loss: 0.02209 | Regression loss: 0.12963 | Running loss: 0.23283\n",
      "Epoch: 18 | Iteration: 739 | Classification loss: 0.05194 | Regression loss: 0.21506 | Running loss: 0.23290\n",
      "Epoch: 18 | Iteration: 740 | Classification loss: 0.04467 | Regression loss: 0.30077 | Running loss: 0.23291\n",
      "Epoch: 18 | Iteration: 741 | Classification loss: 0.02361 | Regression loss: 0.16415 | Running loss: 0.23295\n",
      "Epoch: 18 | Iteration: 742 | Classification loss: 0.01401 | Regression loss: 0.08699 | Running loss: 0.23275\n",
      "Epoch: 18 | Iteration: 743 | Classification loss: 0.01986 | Regression loss: 0.10939 | Running loss: 0.23245\n",
      "Epoch: 18 | Iteration: 744 | Classification loss: 0.01361 | Regression loss: 0.09286 | Running loss: 0.23166\n",
      "Epoch: 18 | Iteration: 745 | Classification loss: 0.05381 | Regression loss: 0.17282 | Running loss: 0.23124\n",
      "Epoch: 18 | Iteration: 746 | Classification loss: 0.03927 | Regression loss: 0.17346 | Running loss: 0.23117\n",
      "Epoch: 18 | Iteration: 747 | Classification loss: 0.00823 | Regression loss: 0.14528 | Running loss: 0.23127\n",
      "Epoch: 18 | Iteration: 748 | Classification loss: 0.09606 | Regression loss: 0.32798 | Running loss: 0.23172\n",
      "Epoch: 18 | Iteration: 749 | Classification loss: 0.02116 | Regression loss: 0.16495 | Running loss: 0.23178\n",
      "Epoch: 18 | Iteration: 750 | Classification loss: 0.08678 | Regression loss: 0.23092 | Running loss: 0.23216\n",
      "Epoch: 18 | Iteration: 751 | Classification loss: 0.01451 | Regression loss: 0.12317 | Running loss: 0.23208\n",
      "Epoch: 18 | Iteration: 752 | Classification loss: 0.01776 | Regression loss: 0.12773 | Running loss: 0.23191\n",
      "Epoch: 18 | Iteration: 753 | Classification loss: 0.01531 | Regression loss: 0.09273 | Running loss: 0.23177\n",
      "Epoch: 18 | Iteration: 754 | Classification loss: 0.08174 | Regression loss: 0.39108 | Running loss: 0.23242\n",
      "Epoch: 18 | Iteration: 755 | Classification loss: 0.07207 | Regression loss: 0.16854 | Running loss: 0.23272\n",
      "Epoch: 18 | Iteration: 756 | Classification loss: 0.08348 | Regression loss: 0.27366 | Running loss: 0.23314\n",
      "Epoch: 18 | Iteration: 757 | Classification loss: 0.02342 | Regression loss: 0.15330 | Running loss: 0.23315\n",
      "Epoch: 18 | Iteration: 758 | Classification loss: 0.01348 | Regression loss: 0.15100 | Running loss: 0.23266\n",
      "Epoch: 18 | Iteration: 759 | Classification loss: 0.04713 | Regression loss: 0.31324 | Running loss: 0.23312\n",
      "Epoch: 18 | Iteration: 760 | Classification loss: 0.01576 | Regression loss: 0.15937 | Running loss: 0.23324\n",
      "Epoch: 18 | Iteration: 761 | Classification loss: 0.07562 | Regression loss: 0.22488 | Running loss: 0.23298\n",
      "Epoch: 18 | Iteration: 762 | Classification loss: 0.06056 | Regression loss: 0.17076 | Running loss: 0.23226\n",
      "Epoch: 18 | Iteration: 763 | Classification loss: 0.01530 | Regression loss: 0.08734 | Running loss: 0.23201\n",
      "Epoch: 18 | Iteration: 764 | Classification loss: 0.00371 | Regression loss: 0.07564 | Running loss: 0.23163\n",
      "Epoch: 18 | Iteration: 765 | Classification loss: 0.02710 | Regression loss: 0.16902 | Running loss: 0.23139\n",
      "Epoch: 18 | Iteration: 766 | Classification loss: 0.01389 | Regression loss: 0.08799 | Running loss: 0.23132\n",
      "Epoch: 18 | Iteration: 767 | Classification loss: 0.08781 | Regression loss: 0.25603 | Running loss: 0.23116\n",
      "Epoch: 18 | Iteration: 768 | Classification loss: 0.03165 | Regression loss: 0.11761 | Running loss: 0.23121\n",
      "Epoch: 18 | Iteration: 769 | Classification loss: 0.09503 | Regression loss: 0.20039 | Running loss: 0.23135\n",
      "Epoch: 18 | Iteration: 770 | Classification loss: 0.02448 | Regression loss: 0.18016 | Running loss: 0.23118\n",
      "Epoch: 18 | Iteration: 771 | Classification loss: 0.01014 | Regression loss: 0.11957 | Running loss: 0.23123\n",
      "Epoch: 18 | Iteration: 772 | Classification loss: 0.04930 | Regression loss: 0.13015 | Running loss: 0.23123\n",
      "Epoch: 18 | Iteration: 773 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.23068\n",
      "Epoch: 18 | Iteration: 774 | Classification loss: 0.05079 | Regression loss: 0.26276 | Running loss: 0.23084\n",
      "Epoch: 18 | Iteration: 775 | Classification loss: 0.02092 | Regression loss: 0.15191 | Running loss: 0.23087\n",
      "Epoch: 18 | Iteration: 776 | Classification loss: 0.03572 | Regression loss: 0.36216 | Running loss: 0.23137\n",
      "Epoch: 18 | Iteration: 777 | Classification loss: 0.03356 | Regression loss: 0.22832 | Running loss: 0.23166\n",
      "Epoch: 18 | Iteration: 778 | Classification loss: 0.01615 | Regression loss: 0.17769 | Running loss: 0.23190\n",
      "Epoch: 18 | Iteration: 779 | Classification loss: 0.02207 | Regression loss: 0.09802 | Running loss: 0.23179\n",
      "Epoch: 18 | Iteration: 780 | Classification loss: 0.03300 | Regression loss: 0.34272 | Running loss: 0.23224\n",
      "Epoch: 18 | Iteration: 781 | Classification loss: 0.05698 | Regression loss: 0.11920 | Running loss: 0.23226\n",
      "Epoch: 18 | Iteration: 782 | Classification loss: 0.02387 | Regression loss: 0.19729 | Running loss: 0.23229\n",
      "Epoch: 18 | Iteration: 783 | Classification loss: 0.01723 | Regression loss: 0.07061 | Running loss: 0.23213\n",
      "Epoch: 18 | Iteration: 784 | Classification loss: 0.01666 | Regression loss: 0.14559 | Running loss: 0.23191\n",
      "Epoch: 18 | Iteration: 785 | Classification loss: 0.06430 | Regression loss: 0.29129 | Running loss: 0.23060\n",
      "Epoch: 18 | Iteration: 786 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.23032\n",
      "Epoch: 18 | Iteration: 787 | Classification loss: 0.10054 | Regression loss: 0.11631 | Running loss: 0.23026\n",
      "Epoch: 18 | Iteration: 788 | Classification loss: 0.02815 | Regression loss: 0.22487 | Running loss: 0.23026\n",
      "Epoch: 18 | Iteration: 789 | Classification loss: 0.03152 | Regression loss: 0.17022 | Running loss: 0.23038\n",
      "Epoch: 18 | Iteration: 790 | Classification loss: 0.04807 | Regression loss: 0.16154 | Running loss: 0.23046\n",
      "Epoch: 18 | Iteration: 791 | Classification loss: 0.13545 | Regression loss: 0.13051 | Running loss: 0.23045\n",
      "Epoch: 18 | Iteration: 792 | Classification loss: 0.15239 | Regression loss: 0.38853 | Running loss: 0.23117\n",
      "Epoch: 18 | Iteration: 793 | Classification loss: 0.02789 | Regression loss: 0.18308 | Running loss: 0.23116\n",
      "Epoch: 18 | Iteration: 794 | Classification loss: 0.02070 | Regression loss: 0.08809 | Running loss: 0.23100\n",
      "Epoch: 18 | Iteration: 795 | Classification loss: 0.02406 | Regression loss: 0.09866 | Running loss: 0.23077\n",
      "Epoch: 18 | Iteration: 796 | Classification loss: 0.02308 | Regression loss: 0.15475 | Running loss: 0.23043\n",
      "Epoch: 18 | Iteration: 797 | Classification loss: 0.02383 | Regression loss: 0.11503 | Running loss: 0.23042\n",
      "Epoch: 18 | Iteration: 798 | Classification loss: 0.02080 | Regression loss: 0.11805 | Running loss: 0.23039\n",
      "Epoch: 18 | Iteration: 799 | Classification loss: 0.03156 | Regression loss: 0.16263 | Running loss: 0.23029\n",
      "Epoch: 18 | Iteration: 800 | Classification loss: 0.02270 | Regression loss: 0.10425 | Running loss: 0.23021\n",
      "Epoch: 18 | Iteration: 801 | Classification loss: 0.07579 | Regression loss: 0.19351 | Running loss: 0.23035\n",
      "Epoch: 18 | Iteration: 802 | Classification loss: 0.01980 | Regression loss: 0.10698 | Running loss: 0.23002\n",
      "Epoch: 18 | Iteration: 803 | Classification loss: 0.03334 | Regression loss: 0.17946 | Running loss: 0.22996\n",
      "Epoch: 18 | Iteration: 804 | Classification loss: 0.05102 | Regression loss: 0.22926 | Running loss: 0.22962\n",
      "Epoch: 18 | Iteration: 805 | Classification loss: 0.01527 | Regression loss: 0.19145 | Running loss: 0.22928\n",
      "Epoch: 18 | Iteration: 806 | Classification loss: 0.01174 | Regression loss: 0.13164 | Running loss: 0.22945\n",
      "Epoch: 18 | Iteration: 807 | Classification loss: 0.06527 | Regression loss: 0.20299 | Running loss: 0.22967\n",
      "Epoch: 18 | Iteration: 808 | Classification loss: 0.04177 | Regression loss: 0.27006 | Running loss: 0.22950\n",
      "Epoch: 18 | Iteration: 809 | Classification loss: 0.00768 | Regression loss: 0.10741 | Running loss: 0.22894\n",
      "Epoch: 18 | Iteration: 810 | Classification loss: 0.10801 | Regression loss: 0.12969 | Running loss: 0.22915\n",
      "Epoch: 18 | Iteration: 811 | Classification loss: 0.01769 | Regression loss: 0.16995 | Running loss: 0.22897\n",
      "Epoch: 18 | Iteration: 812 | Classification loss: 0.07270 | Regression loss: 0.35619 | Running loss: 0.22926\n",
      "Epoch: 18 | Iteration: 813 | Classification loss: 0.06319 | Regression loss: 0.20461 | Running loss: 0.22916\n",
      "Epoch: 18 | Iteration: 814 | Classification loss: 0.01998 | Regression loss: 0.16075 | Running loss: 0.22889\n",
      "Epoch: 18 | Iteration: 815 | Classification loss: 0.05069 | Regression loss: 0.18525 | Running loss: 0.22880\n",
      "Epoch: 18 | Iteration: 816 | Classification loss: 0.01458 | Regression loss: 0.11565 | Running loss: 0.22845\n",
      "Epoch: 18 | Iteration: 817 | Classification loss: 0.02148 | Regression loss: 0.15262 | Running loss: 0.22850\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.18s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.299\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.450\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 19 | Iteration: 0 | Classification loss: 0.01598 | Regression loss: 0.14771 | Running loss: 0.22862\n",
      "Epoch: 19 | Iteration: 1 | Classification loss: 0.05345 | Regression loss: 0.18973 | Running loss: 0.22896\n",
      "Epoch: 19 | Iteration: 2 | Classification loss: 0.06979 | Regression loss: 0.18263 | Running loss: 0.22887\n",
      "Epoch: 19 | Iteration: 3 | Classification loss: 0.02885 | Regression loss: 0.16019 | Running loss: 0.22846\n",
      "Epoch: 19 | Iteration: 4 | Classification loss: 0.03554 | Regression loss: 0.23013 | Running loss: 0.22868\n",
      "Epoch: 19 | Iteration: 5 | Classification loss: 0.03822 | Regression loss: 0.21747 | Running loss: 0.22888\n",
      "Epoch: 19 | Iteration: 6 | Classification loss: 0.05578 | Regression loss: 0.20901 | Running loss: 0.22887\n",
      "Epoch: 19 | Iteration: 7 | Classification loss: 0.02345 | Regression loss: 0.10457 | Running loss: 0.22879\n",
      "Epoch: 19 | Iteration: 8 | Classification loss: 0.01082 | Regression loss: 0.10125 | Running loss: 0.22869\n",
      "Epoch: 19 | Iteration: 9 | Classification loss: 0.01654 | Regression loss: 0.16417 | Running loss: 0.22866\n",
      "Epoch: 19 | Iteration: 10 | Classification loss: 0.03336 | Regression loss: 0.12153 | Running loss: 0.22841\n",
      "Epoch: 19 | Iteration: 11 | Classification loss: 0.03000 | Regression loss: 0.16037 | Running loss: 0.22859\n",
      "Epoch: 19 | Iteration: 12 | Classification loss: 0.03189 | Regression loss: 0.13187 | Running loss: 0.22844\n",
      "Epoch: 19 | Iteration: 13 | Classification loss: 0.04244 | Regression loss: 0.27989 | Running loss: 0.22879\n",
      "Epoch: 19 | Iteration: 14 | Classification loss: 0.02737 | Regression loss: 0.28087 | Running loss: 0.22920\n",
      "Epoch: 19 | Iteration: 15 | Classification loss: 0.00676 | Regression loss: 0.03692 | Running loss: 0.22900\n",
      "Epoch: 19 | Iteration: 16 | Classification loss: 0.04784 | Regression loss: 0.23215 | Running loss: 0.22846\n",
      "Epoch: 19 | Iteration: 17 | Classification loss: 0.16328 | Regression loss: 0.41856 | Running loss: 0.22894\n",
      "Epoch: 19 | Iteration: 18 | Classification loss: 0.00948 | Regression loss: 0.09666 | Running loss: 0.22855\n",
      "Epoch: 19 | Iteration: 19 | Classification loss: 0.02511 | Regression loss: 0.15190 | Running loss: 0.22821\n",
      "Epoch: 19 | Iteration: 20 | Classification loss: 0.05239 | Regression loss: 0.16301 | Running loss: 0.22837\n",
      "Epoch: 19 | Iteration: 21 | Classification loss: 0.02718 | Regression loss: 0.13026 | Running loss: 0.22831\n",
      "Epoch: 19 | Iteration: 22 | Classification loss: 0.03794 | Regression loss: 0.16705 | Running loss: 0.22819\n",
      "Epoch: 19 | Iteration: 23 | Classification loss: 0.03246 | Regression loss: 0.18052 | Running loss: 0.22787\n",
      "Epoch: 19 | Iteration: 24 | Classification loss: 0.02648 | Regression loss: 0.12063 | Running loss: 0.22788\n",
      "Epoch: 19 | Iteration: 25 | Classification loss: 0.08484 | Regression loss: 0.23156 | Running loss: 0.22800\n",
      "Epoch: 19 | Iteration: 26 | Classification loss: 0.00853 | Regression loss: 0.10025 | Running loss: 0.22797\n",
      "Epoch: 19 | Iteration: 27 | Classification loss: 0.02335 | Regression loss: 0.18110 | Running loss: 0.22810\n",
      "Epoch: 19 | Iteration: 28 | Classification loss: 0.07769 | Regression loss: 0.16179 | Running loss: 0.22813\n",
      "Epoch: 19 | Iteration: 29 | Classification loss: 0.01136 | Regression loss: 0.12914 | Running loss: 0.22796\n",
      "Epoch: 19 | Iteration: 30 | Classification loss: 0.02148 | Regression loss: 0.16553 | Running loss: 0.22790\n",
      "Epoch: 19 | Iteration: 31 | Classification loss: 0.03687 | Regression loss: 0.21121 | Running loss: 0.22769\n",
      "Epoch: 19 | Iteration: 32 | Classification loss: 0.14234 | Regression loss: 0.22521 | Running loss: 0.22788\n",
      "Epoch: 19 | Iteration: 33 | Classification loss: 0.03116 | Regression loss: 0.09232 | Running loss: 0.22740\n",
      "Epoch: 19 | Iteration: 34 | Classification loss: 0.03690 | Regression loss: 0.27452 | Running loss: 0.22754\n",
      "Epoch: 19 | Iteration: 35 | Classification loss: 0.05776 | Regression loss: 0.14009 | Running loss: 0.22701\n",
      "Epoch: 19 | Iteration: 36 | Classification loss: 0.01942 | Regression loss: 0.15018 | Running loss: 0.22664\n",
      "Epoch: 19 | Iteration: 37 | Classification loss: 0.01657 | Regression loss: 0.16260 | Running loss: 0.22663\n",
      "Epoch: 19 | Iteration: 38 | Classification loss: 0.05906 | Regression loss: 0.33931 | Running loss: 0.22683\n",
      "Epoch: 19 | Iteration: 39 | Classification loss: 0.04396 | Regression loss: 0.21311 | Running loss: 0.22676\n",
      "Epoch: 19 | Iteration: 40 | Classification loss: 0.01759 | Regression loss: 0.13758 | Running loss: 0.22647\n",
      "Epoch: 19 | Iteration: 41 | Classification loss: 0.05615 | Regression loss: 0.24692 | Running loss: 0.22658\n",
      "Epoch: 19 | Iteration: 42 | Classification loss: 0.10285 | Regression loss: 0.25249 | Running loss: 0.22648\n",
      "Epoch: 19 | Iteration: 43 | Classification loss: 0.04725 | Regression loss: 0.22425 | Running loss: 0.22674\n",
      "Epoch: 19 | Iteration: 44 | Classification loss: 0.00680 | Regression loss: 0.13476 | Running loss: 0.22669\n",
      "Epoch: 19 | Iteration: 45 | Classification loss: 0.20105 | Regression loss: 0.40084 | Running loss: 0.22721\n",
      "Epoch: 19 | Iteration: 46 | Classification loss: 0.03516 | Regression loss: 0.12650 | Running loss: 0.22638\n",
      "Epoch: 19 | Iteration: 47 | Classification loss: 0.04417 | Regression loss: 0.21779 | Running loss: 0.22649\n",
      "Epoch: 19 | Iteration: 48 | Classification loss: 0.09057 | Regression loss: 0.19577 | Running loss: 0.22668\n",
      "Epoch: 19 | Iteration: 49 | Classification loss: 0.15769 | Regression loss: 0.29142 | Running loss: 0.22702\n",
      "Epoch: 19 | Iteration: 50 | Classification loss: 0.08682 | Regression loss: 0.15923 | Running loss: 0.22688\n",
      "Epoch: 19 | Iteration: 51 | Classification loss: 0.00562 | Regression loss: 0.07130 | Running loss: 0.22657\n",
      "Epoch: 19 | Iteration: 52 | Classification loss: 0.04096 | Regression loss: 0.18217 | Running loss: 0.22556\n",
      "Epoch: 19 | Iteration: 53 | Classification loss: 0.07390 | Regression loss: 0.29043 | Running loss: 0.22597\n",
      "Epoch: 19 | Iteration: 54 | Classification loss: 0.03458 | Regression loss: 0.18766 | Running loss: 0.22590\n",
      "Epoch: 19 | Iteration: 55 | Classification loss: 0.02701 | Regression loss: 0.18232 | Running loss: 0.22559\n",
      "Epoch: 19 | Iteration: 56 | Classification loss: 0.01175 | Regression loss: 0.18499 | Running loss: 0.22560\n",
      "Epoch: 19 | Iteration: 57 | Classification loss: 0.03162 | Regression loss: 0.26045 | Running loss: 0.22558\n",
      "Epoch: 19 | Iteration: 58 | Classification loss: 0.01170 | Regression loss: 0.08423 | Running loss: 0.22538\n",
      "Epoch: 19 | Iteration: 59 | Classification loss: 0.02253 | Regression loss: 0.13123 | Running loss: 0.22544\n",
      "Epoch: 19 | Iteration: 60 | Classification loss: 0.06019 | Regression loss: 0.28802 | Running loss: 0.22555\n",
      "Epoch: 19 | Iteration: 61 | Classification loss: 0.09882 | Regression loss: 0.23379 | Running loss: 0.22590\n",
      "Epoch: 19 | Iteration: 62 | Classification loss: 0.01244 | Regression loss: 0.11811 | Running loss: 0.22580\n",
      "Epoch: 19 | Iteration: 63 | Classification loss: 0.15017 | Regression loss: 0.39334 | Running loss: 0.22631\n",
      "Epoch: 19 | Iteration: 64 | Classification loss: 0.20211 | Regression loss: 0.37996 | Running loss: 0.22706\n",
      "Epoch: 19 | Iteration: 65 | Classification loss: 0.02997 | Regression loss: 0.17587 | Running loss: 0.22720\n",
      "Epoch: 19 | Iteration: 66 | Classification loss: 0.07236 | Regression loss: 0.15965 | Running loss: 0.22734\n",
      "Epoch: 19 | Iteration: 67 | Classification loss: 0.02496 | Regression loss: 0.34592 | Running loss: 0.22751\n",
      "Epoch: 19 | Iteration: 68 | Classification loss: 0.01211 | Regression loss: 0.12840 | Running loss: 0.22736\n",
      "Epoch: 19 | Iteration: 69 | Classification loss: 0.02389 | Regression loss: 0.20475 | Running loss: 0.22751\n",
      "Epoch: 19 | Iteration: 70 | Classification loss: 0.01859 | Regression loss: 0.11564 | Running loss: 0.22678\n",
      "Epoch: 19 | Iteration: 71 | Classification loss: 0.08885 | Regression loss: 0.16644 | Running loss: 0.22693\n",
      "Epoch: 19 | Iteration: 72 | Classification loss: 0.01770 | Regression loss: 0.08312 | Running loss: 0.22668\n",
      "Epoch: 19 | Iteration: 73 | Classification loss: 0.03403 | Regression loss: 0.20632 | Running loss: 0.22672\n",
      "Epoch: 19 | Iteration: 74 | Classification loss: 0.01721 | Regression loss: 0.14414 | Running loss: 0.22629\n",
      "Epoch: 19 | Iteration: 75 | Classification loss: 0.01834 | Regression loss: 0.16941 | Running loss: 0.22548\n",
      "Epoch: 19 | Iteration: 76 | Classification loss: 0.02518 | Regression loss: 0.16070 | Running loss: 0.22535\n",
      "Epoch: 19 | Iteration: 77 | Classification loss: 0.06157 | Regression loss: 0.14689 | Running loss: 0.22525\n",
      "Epoch: 19 | Iteration: 78 | Classification loss: 0.02411 | Regression loss: 0.20386 | Running loss: 0.22525\n",
      "Epoch: 19 | Iteration: 79 | Classification loss: 0.01781 | Regression loss: 0.09415 | Running loss: 0.22507\n",
      "Epoch: 19 | Iteration: 80 | Classification loss: 0.01662 | Regression loss: 0.15823 | Running loss: 0.22517\n",
      "Epoch: 19 | Iteration: 81 | Classification loss: 0.00956 | Regression loss: 0.06510 | Running loss: 0.22481\n",
      "Epoch: 19 | Iteration: 82 | Classification loss: 0.04520 | Regression loss: 0.11291 | Running loss: 0.22460\n",
      "Epoch: 19 | Iteration: 83 | Classification loss: 0.06308 | Regression loss: 0.19797 | Running loss: 0.22500\n",
      "Epoch: 19 | Iteration: 84 | Classification loss: 0.00910 | Regression loss: 0.13832 | Running loss: 0.22501\n",
      "Epoch: 19 | Iteration: 85 | Classification loss: 0.02634 | Regression loss: 0.10514 | Running loss: 0.22476\n",
      "Epoch: 19 | Iteration: 86 | Classification loss: 0.01152 | Regression loss: 0.11878 | Running loss: 0.22464\n",
      "Epoch: 19 | Iteration: 87 | Classification loss: 0.40033 | Regression loss: 0.31087 | Running loss: 0.22577\n",
      "Epoch: 19 | Iteration: 88 | Classification loss: 0.01431 | Regression loss: 0.13257 | Running loss: 0.22569\n",
      "Epoch: 19 | Iteration: 89 | Classification loss: 0.01536 | Regression loss: 0.13306 | Running loss: 0.22554\n",
      "Epoch: 19 | Iteration: 90 | Classification loss: 0.03538 | Regression loss: 0.11824 | Running loss: 0.22568\n",
      "Epoch: 19 | Iteration: 91 | Classification loss: 0.00669 | Regression loss: 0.06181 | Running loss: 0.22541\n",
      "Epoch: 19 | Iteration: 92 | Classification loss: 0.01562 | Regression loss: 0.14874 | Running loss: 0.22544\n",
      "Epoch: 19 | Iteration: 93 | Classification loss: 0.01797 | Regression loss: 0.25540 | Running loss: 0.22582\n",
      "Epoch: 19 | Iteration: 94 | Classification loss: 0.01236 | Regression loss: 0.17456 | Running loss: 0.22543\n",
      "Epoch: 19 | Iteration: 95 | Classification loss: 0.00779 | Regression loss: 0.09161 | Running loss: 0.22499\n",
      "Epoch: 19 | Iteration: 96 | Classification loss: 0.03916 | Regression loss: 0.25713 | Running loss: 0.22531\n",
      "Epoch: 19 | Iteration: 97 | Classification loss: 0.02425 | Regression loss: 0.17961 | Running loss: 0.22541\n",
      "Epoch: 19 | Iteration: 98 | Classification loss: 0.20722 | Regression loss: 0.13238 | Running loss: 0.22584\n",
      "Epoch: 19 | Iteration: 99 | Classification loss: 0.03753 | Regression loss: 0.12860 | Running loss: 0.22575\n",
      "Epoch: 19 | Iteration: 100 | Classification loss: 0.03187 | Regression loss: 0.19849 | Running loss: 0.22575\n",
      "Epoch: 19 | Iteration: 101 | Classification loss: 0.01306 | Regression loss: 0.21884 | Running loss: 0.22579\n",
      "Epoch: 19 | Iteration: 102 | Classification loss: 0.02496 | Regression loss: 0.12386 | Running loss: 0.22553\n",
      "Epoch: 19 | Iteration: 103 | Classification loss: 0.01761 | Regression loss: 0.15286 | Running loss: 0.22561\n",
      "Epoch: 19 | Iteration: 104 | Classification loss: 0.02642 | Regression loss: 0.13381 | Running loss: 0.22551\n",
      "Epoch: 19 | Iteration: 105 | Classification loss: 0.02755 | Regression loss: 0.26091 | Running loss: 0.22569\n",
      "Epoch: 19 | Iteration: 106 | Classification loss: 0.03698 | Regression loss: 0.14908 | Running loss: 0.22573\n",
      "Epoch: 19 | Iteration: 107 | Classification loss: 0.07829 | Regression loss: 0.21898 | Running loss: 0.22574\n",
      "Epoch: 19 | Iteration: 108 | Classification loss: 0.03284 | Regression loss: 0.15046 | Running loss: 0.22586\n",
      "Epoch: 19 | Iteration: 109 | Classification loss: 0.01495 | Regression loss: 0.15129 | Running loss: 0.22598\n",
      "Epoch: 19 | Iteration: 110 | Classification loss: 0.02276 | Regression loss: 0.12915 | Running loss: 0.22529\n",
      "Epoch: 19 | Iteration: 111 | Classification loss: 0.02777 | Regression loss: 0.25324 | Running loss: 0.22548\n",
      "Epoch: 19 | Iteration: 112 | Classification loss: 0.02303 | Regression loss: 0.14537 | Running loss: 0.22546\n",
      "Epoch: 19 | Iteration: 113 | Classification loss: 0.06576 | Regression loss: 0.27596 | Running loss: 0.22573\n",
      "Epoch: 19 | Iteration: 114 | Classification loss: 0.03859 | Regression loss: 0.21851 | Running loss: 0.22591\n",
      "Epoch: 19 | Iteration: 115 | Classification loss: 0.02858 | Regression loss: 0.15885 | Running loss: 0.22600\n",
      "Epoch: 19 | Iteration: 116 | Classification loss: 0.13639 | Regression loss: 0.13043 | Running loss: 0.22611\n",
      "Epoch: 19 | Iteration: 117 | Classification loss: 0.01897 | Regression loss: 0.26737 | Running loss: 0.22618\n",
      "Epoch: 19 | Iteration: 118 | Classification loss: 0.00502 | Regression loss: 0.12790 | Running loss: 0.22596\n",
      "Epoch: 19 | Iteration: 119 | Classification loss: 0.07023 | Regression loss: 0.27494 | Running loss: 0.22654\n",
      "Epoch: 19 | Iteration: 120 | Classification loss: 0.03216 | Regression loss: 0.19385 | Running loss: 0.22667\n",
      "Epoch: 19 | Iteration: 121 | Classification loss: 0.01374 | Regression loss: 0.13659 | Running loss: 0.22661\n",
      "Epoch: 19 | Iteration: 122 | Classification loss: 0.01209 | Regression loss: 0.14044 | Running loss: 0.22575\n",
      "Epoch: 19 | Iteration: 123 | Classification loss: 0.04283 | Regression loss: 0.16400 | Running loss: 0.22556\n",
      "Epoch: 19 | Iteration: 124 | Classification loss: 0.09553 | Regression loss: 0.17706 | Running loss: 0.22573\n",
      "Epoch: 19 | Iteration: 125 | Classification loss: 0.01782 | Regression loss: 0.13015 | Running loss: 0.22557\n",
      "Epoch: 19 | Iteration: 126 | Classification loss: 0.01952 | Regression loss: 0.12134 | Running loss: 0.22549\n",
      "Epoch: 19 | Iteration: 127 | Classification loss: 0.02291 | Regression loss: 0.24681 | Running loss: 0.22567\n",
      "Epoch: 19 | Iteration: 128 | Classification loss: 0.02749 | Regression loss: 0.07956 | Running loss: 0.22569\n",
      "Epoch: 19 | Iteration: 129 | Classification loss: 0.05721 | Regression loss: 0.29877 | Running loss: 0.22568\n",
      "Epoch: 19 | Iteration: 130 | Classification loss: 0.06043 | Regression loss: 0.20419 | Running loss: 0.22584\n",
      "Epoch: 19 | Iteration: 131 | Classification loss: 0.06149 | Regression loss: 0.22853 | Running loss: 0.22613\n",
      "Epoch: 19 | Iteration: 132 | Classification loss: 0.00589 | Regression loss: 0.17481 | Running loss: 0.22570\n",
      "Epoch: 19 | Iteration: 133 | Classification loss: 0.02325 | Regression loss: 0.16627 | Running loss: 0.22562\n",
      "Epoch: 19 | Iteration: 134 | Classification loss: 0.03599 | Regression loss: 0.12422 | Running loss: 0.22563\n",
      "Epoch: 19 | Iteration: 135 | Classification loss: 0.02548 | Regression loss: 0.16840 | Running loss: 0.22556\n",
      "Epoch: 19 | Iteration: 136 | Classification loss: 0.18206 | Regression loss: 0.33730 | Running loss: 0.22623\n",
      "Epoch: 19 | Iteration: 137 | Classification loss: 0.01322 | Regression loss: 0.10783 | Running loss: 0.22624\n",
      "Epoch: 19 | Iteration: 138 | Classification loss: 0.08913 | Regression loss: 0.12702 | Running loss: 0.22638\n",
      "Epoch: 19 | Iteration: 139 | Classification loss: 0.04588 | Regression loss: 0.20503 | Running loss: 0.22655\n",
      "Epoch: 19 | Iteration: 140 | Classification loss: 0.02213 | Regression loss: 0.12307 | Running loss: 0.22639\n",
      "Epoch: 19 | Iteration: 141 | Classification loss: 0.02044 | Regression loss: 0.19943 | Running loss: 0.22657\n",
      "Epoch: 19 | Iteration: 142 | Classification loss: 0.02103 | Regression loss: 0.28909 | Running loss: 0.22691\n",
      "Epoch: 19 | Iteration: 143 | Classification loss: 0.01747 | Regression loss: 0.19001 | Running loss: 0.22688\n",
      "Epoch: 19 | Iteration: 144 | Classification loss: 0.02166 | Regression loss: 0.10553 | Running loss: 0.22667\n",
      "Epoch: 19 | Iteration: 145 | Classification loss: 0.01079 | Regression loss: 0.10157 | Running loss: 0.22662\n",
      "Epoch: 19 | Iteration: 146 | Classification loss: 0.07165 | Regression loss: 0.19350 | Running loss: 0.22616\n",
      "Epoch: 19 | Iteration: 147 | Classification loss: 0.02556 | Regression loss: 0.09671 | Running loss: 0.22610\n",
      "Epoch: 19 | Iteration: 148 | Classification loss: 0.01548 | Regression loss: 0.10676 | Running loss: 0.22618\n",
      "Epoch: 19 | Iteration: 149 | Classification loss: 0.03559 | Regression loss: 0.26374 | Running loss: 0.22645\n",
      "Epoch: 19 | Iteration: 150 | Classification loss: 0.01249 | Regression loss: 0.06926 | Running loss: 0.22623\n",
      "Epoch: 19 | Iteration: 151 | Classification loss: 0.02357 | Regression loss: 0.16804 | Running loss: 0.22616\n",
      "Epoch: 19 | Iteration: 152 | Classification loss: 0.01403 | Regression loss: 0.10983 | Running loss: 0.22526\n",
      "Epoch: 19 | Iteration: 153 | Classification loss: 0.03560 | Regression loss: 0.14021 | Running loss: 0.22525\n",
      "Epoch: 19 | Iteration: 154 | Classification loss: 0.00866 | Regression loss: 0.13079 | Running loss: 0.22515\n",
      "Epoch: 19 | Iteration: 155 | Classification loss: 0.05904 | Regression loss: 0.13580 | Running loss: 0.22494\n",
      "Epoch: 19 | Iteration: 156 | Classification loss: 0.01249 | Regression loss: 0.13521 | Running loss: 0.22462\n",
      "Epoch: 19 | Iteration: 157 | Classification loss: 0.13416 | Regression loss: 0.28052 | Running loss: 0.22494\n",
      "Epoch: 19 | Iteration: 158 | Classification loss: 0.01110 | Regression loss: 0.09488 | Running loss: 0.22462\n",
      "Epoch: 19 | Iteration: 159 | Classification loss: 0.01481 | Regression loss: 0.15576 | Running loss: 0.22472\n",
      "Epoch: 19 | Iteration: 160 | Classification loss: 0.17331 | Regression loss: 0.10033 | Running loss: 0.22490\n",
      "Epoch: 19 | Iteration: 161 | Classification loss: 0.00839 | Regression loss: 0.10913 | Running loss: 0.22451\n",
      "Epoch: 19 | Iteration: 162 | Classification loss: 0.02053 | Regression loss: 0.14617 | Running loss: 0.22466\n",
      "Epoch: 19 | Iteration: 163 | Classification loss: 0.01192 | Regression loss: 0.06811 | Running loss: 0.22445\n",
      "Epoch: 19 | Iteration: 164 | Classification loss: 0.01497 | Regression loss: 0.10248 | Running loss: 0.22397\n",
      "Epoch: 19 | Iteration: 165 | Classification loss: 0.03523 | Regression loss: 0.15113 | Running loss: 0.22287\n",
      "Epoch: 19 | Iteration: 166 | Classification loss: 0.02607 | Regression loss: 0.31037 | Running loss: 0.22275\n",
      "Epoch: 19 | Iteration: 167 | Classification loss: 0.00549 | Regression loss: 0.08952 | Running loss: 0.22262\n",
      "Epoch: 19 | Iteration: 168 | Classification loss: 0.01286 | Regression loss: 0.14296 | Running loss: 0.22252\n",
      "Epoch: 19 | Iteration: 169 | Classification loss: 0.02425 | Regression loss: 0.15510 | Running loss: 0.22217\n",
      "Epoch: 19 | Iteration: 170 | Classification loss: 0.11078 | Regression loss: 0.15016 | Running loss: 0.22177\n",
      "Epoch: 19 | Iteration: 171 | Classification loss: 0.02002 | Regression loss: 0.18053 | Running loss: 0.22146\n",
      "Epoch: 19 | Iteration: 172 | Classification loss: 0.03476 | Regression loss: 0.08932 | Running loss: 0.22122\n",
      "Epoch: 19 | Iteration: 173 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.22067\n",
      "Epoch: 19 | Iteration: 174 | Classification loss: 0.05475 | Regression loss: 0.12998 | Running loss: 0.22055\n",
      "Epoch: 19 | Iteration: 175 | Classification loss: 0.01254 | Regression loss: 0.09531 | Running loss: 0.22043\n",
      "Epoch: 19 | Iteration: 176 | Classification loss: 0.11344 | Regression loss: 0.13205 | Running loss: 0.22067\n",
      "Epoch: 19 | Iteration: 177 | Classification loss: 0.04293 | Regression loss: 0.21580 | Running loss: 0.22045\n",
      "Epoch: 19 | Iteration: 178 | Classification loss: 0.02969 | Regression loss: 0.05726 | Running loss: 0.22006\n",
      "Epoch: 19 | Iteration: 179 | Classification loss: 0.12934 | Regression loss: 0.11275 | Running loss: 0.22035\n",
      "Epoch: 19 | Iteration: 180 | Classification loss: 0.02075 | Regression loss: 0.10981 | Running loss: 0.22036\n",
      "Epoch: 19 | Iteration: 181 | Classification loss: 0.13405 | Regression loss: 0.08410 | Running loss: 0.22037\n",
      "Epoch: 19 | Iteration: 182 | Classification loss: 0.05255 | Regression loss: 0.16402 | Running loss: 0.22029\n",
      "Epoch: 19 | Iteration: 183 | Classification loss: 0.01964 | Regression loss: 0.10116 | Running loss: 0.22011\n",
      "Epoch: 19 | Iteration: 184 | Classification loss: 0.01948 | Regression loss: 0.16918 | Running loss: 0.22027\n",
      "Epoch: 19 | Iteration: 185 | Classification loss: 0.02183 | Regression loss: 0.16597 | Running loss: 0.22029\n",
      "Epoch: 19 | Iteration: 186 | Classification loss: 0.00949 | Regression loss: 0.11165 | Running loss: 0.22025\n",
      "Epoch: 19 | Iteration: 187 | Classification loss: 0.03036 | Regression loss: 0.19929 | Running loss: 0.21998\n",
      "Epoch: 19 | Iteration: 188 | Classification loss: 0.07211 | Regression loss: 0.30691 | Running loss: 0.22037\n",
      "Epoch: 19 | Iteration: 189 | Classification loss: 0.07835 | Regression loss: 0.39822 | Running loss: 0.22046\n",
      "Epoch: 19 | Iteration: 190 | Classification loss: 0.00895 | Regression loss: 0.10491 | Running loss: 0.22045\n",
      "Epoch: 19 | Iteration: 191 | Classification loss: 0.01336 | Regression loss: 0.11744 | Running loss: 0.22018\n",
      "Epoch: 19 | Iteration: 192 | Classification loss: 0.03310 | Regression loss: 0.16827 | Running loss: 0.22002\n",
      "Epoch: 19 | Iteration: 193 | Classification loss: 0.01268 | Regression loss: 0.12133 | Running loss: 0.21989\n",
      "Epoch: 19 | Iteration: 194 | Classification loss: 0.01236 | Regression loss: 0.14549 | Running loss: 0.21982\n",
      "Epoch: 19 | Iteration: 195 | Classification loss: 0.07720 | Regression loss: 0.09725 | Running loss: 0.21968\n",
      "Epoch: 19 | Iteration: 196 | Classification loss: 0.00930 | Regression loss: 0.17388 | Running loss: 0.21986\n",
      "Epoch: 19 | Iteration: 197 | Classification loss: 0.10544 | Regression loss: 0.33012 | Running loss: 0.22026\n",
      "Epoch: 19 | Iteration: 198 | Classification loss: 0.04083 | Regression loss: 0.09831 | Running loss: 0.22022\n",
      "Epoch: 19 | Iteration: 199 | Classification loss: 0.08897 | Regression loss: 0.25073 | Running loss: 0.22064\n",
      "Epoch: 19 | Iteration: 200 | Classification loss: 0.07303 | Regression loss: 0.14152 | Running loss: 0.22057\n",
      "Epoch: 19 | Iteration: 201 | Classification loss: 0.04414 | Regression loss: 0.15510 | Running loss: 0.22068\n",
      "Epoch: 19 | Iteration: 202 | Classification loss: 0.01677 | Regression loss: 0.11026 | Running loss: 0.22058\n",
      "Epoch: 19 | Iteration: 203 | Classification loss: 0.03054 | Regression loss: 0.18796 | Running loss: 0.22084\n",
      "Epoch: 19 | Iteration: 204 | Classification loss: 0.02426 | Regression loss: 0.17053 | Running loss: 0.22084\n",
      "Epoch: 19 | Iteration: 205 | Classification loss: 0.01658 | Regression loss: 0.22894 | Running loss: 0.22101\n",
      "Epoch: 19 | Iteration: 206 | Classification loss: 0.01351 | Regression loss: 0.12057 | Running loss: 0.22098\n",
      "Epoch: 19 | Iteration: 207 | Classification loss: 0.02473 | Regression loss: 0.14929 | Running loss: 0.22058\n",
      "Epoch: 19 | Iteration: 208 | Classification loss: 0.02224 | Regression loss: 0.17407 | Running loss: 0.22080\n",
      "Epoch: 19 | Iteration: 209 | Classification loss: 0.00374 | Regression loss: 0.07306 | Running loss: 0.22038\n",
      "Epoch: 19 | Iteration: 210 | Classification loss: 0.01115 | Regression loss: 0.13369 | Running loss: 0.22004\n",
      "Epoch: 19 | Iteration: 211 | Classification loss: 0.01574 | Regression loss: 0.10211 | Running loss: 0.21968\n",
      "Epoch: 19 | Iteration: 212 | Classification loss: 0.17312 | Regression loss: 0.27652 | Running loss: 0.21985\n",
      "Epoch: 19 | Iteration: 213 | Classification loss: 0.05840 | Regression loss: 0.07391 | Running loss: 0.21970\n",
      "Epoch: 19 | Iteration: 214 | Classification loss: 0.04160 | Regression loss: 0.09668 | Running loss: 0.21979\n",
      "Epoch: 19 | Iteration: 215 | Classification loss: 0.03258 | Regression loss: 0.13115 | Running loss: 0.21948\n",
      "Epoch: 19 | Iteration: 216 | Classification loss: 0.02099 | Regression loss: 0.15934 | Running loss: 0.21942\n",
      "Epoch: 19 | Iteration: 217 | Classification loss: 0.00825 | Regression loss: 0.21871 | Running loss: 0.21958\n",
      "Epoch: 19 | Iteration: 218 | Classification loss: 0.00515 | Regression loss: 0.08634 | Running loss: 0.21933\n",
      "Epoch: 19 | Iteration: 219 | Classification loss: 0.02017 | Regression loss: 0.16470 | Running loss: 0.21911\n",
      "Epoch: 19 | Iteration: 220 | Classification loss: 0.01826 | Regression loss: 0.17686 | Running loss: 0.21911\n",
      "Epoch: 19 | Iteration: 221 | Classification loss: 0.03594 | Regression loss: 0.14137 | Running loss: 0.21904\n",
      "Epoch: 19 | Iteration: 222 | Classification loss: 0.01700 | Regression loss: 0.11339 | Running loss: 0.21885\n",
      "Epoch: 19 | Iteration: 223 | Classification loss: 0.01561 | Regression loss: 0.18466 | Running loss: 0.21875\n",
      "Epoch: 19 | Iteration: 224 | Classification loss: 0.05718 | Regression loss: 0.34632 | Running loss: 0.21893\n",
      "Epoch: 19 | Iteration: 225 | Classification loss: 0.05757 | Regression loss: 0.24456 | Running loss: 0.21886\n",
      "Epoch: 19 | Iteration: 226 | Classification loss: 0.01204 | Regression loss: 0.09760 | Running loss: 0.21853\n",
      "Epoch: 19 | Iteration: 227 | Classification loss: 0.00985 | Regression loss: 0.11677 | Running loss: 0.21836\n",
      "Epoch: 19 | Iteration: 228 | Classification loss: 0.04311 | Regression loss: 0.14173 | Running loss: 0.21848\n",
      "Epoch: 19 | Iteration: 229 | Classification loss: 0.07577 | Regression loss: 0.19193 | Running loss: 0.21871\n",
      "Epoch: 19 | Iteration: 230 | Classification loss: 0.01978 | Regression loss: 0.14720 | Running loss: 0.21651\n",
      "Epoch: 19 | Iteration: 231 | Classification loss: 0.02637 | Regression loss: 0.18034 | Running loss: 0.21663\n",
      "Epoch: 19 | Iteration: 232 | Classification loss: 0.02032 | Regression loss: 0.34963 | Running loss: 0.21680\n",
      "Epoch: 19 | Iteration: 233 | Classification loss: 0.01683 | Regression loss: 0.23692 | Running loss: 0.21693\n",
      "Epoch: 19 | Iteration: 234 | Classification loss: 0.15787 | Regression loss: 0.36576 | Running loss: 0.21759\n",
      "Epoch: 19 | Iteration: 235 | Classification loss: 0.02792 | Regression loss: 0.27615 | Running loss: 0.21765\n",
      "Epoch: 19 | Iteration: 236 | Classification loss: 0.02848 | Regression loss: 0.13447 | Running loss: 0.21755\n",
      "Epoch: 19 | Iteration: 237 | Classification loss: 0.05253 | Regression loss: 0.21384 | Running loss: 0.21784\n",
      "Epoch: 19 | Iteration: 238 | Classification loss: 0.06362 | Regression loss: 0.23945 | Running loss: 0.21810\n",
      "Epoch: 19 | Iteration: 239 | Classification loss: 0.02984 | Regression loss: 0.20619 | Running loss: 0.21800\n",
      "Epoch: 19 | Iteration: 240 | Classification loss: 0.00330 | Regression loss: 0.13444 | Running loss: 0.21765\n",
      "Epoch: 19 | Iteration: 241 | Classification loss: 0.02289 | Regression loss: 0.12896 | Running loss: 0.21753\n",
      "Epoch: 19 | Iteration: 242 | Classification loss: 0.02527 | Regression loss: 0.10479 | Running loss: 0.21750\n",
      "Epoch: 19 | Iteration: 243 | Classification loss: 0.01235 | Regression loss: 0.16314 | Running loss: 0.21725\n",
      "Epoch: 19 | Iteration: 244 | Classification loss: 0.02902 | Regression loss: 0.14333 | Running loss: 0.21688\n",
      "Epoch: 19 | Iteration: 245 | Classification loss: 0.15078 | Regression loss: 0.18822 | Running loss: 0.21738\n",
      "Epoch: 19 | Iteration: 246 | Classification loss: 0.01758 | Regression loss: 0.15864 | Running loss: 0.21755\n",
      "Epoch: 19 | Iteration: 247 | Classification loss: 0.01180 | Regression loss: 0.11349 | Running loss: 0.21748\n",
      "Epoch: 19 | Iteration: 248 | Classification loss: 0.02301 | Regression loss: 0.14017 | Running loss: 0.21763\n",
      "Epoch: 19 | Iteration: 249 | Classification loss: 0.02848 | Regression loss: 0.13483 | Running loss: 0.21742\n",
      "Epoch: 19 | Iteration: 250 | Classification loss: 0.05475 | Regression loss: 0.25320 | Running loss: 0.21776\n",
      "Epoch: 19 | Iteration: 251 | Classification loss: 0.01098 | Regression loss: 0.07374 | Running loss: 0.21755\n",
      "Epoch: 19 | Iteration: 252 | Classification loss: 0.02427 | Regression loss: 0.12482 | Running loss: 0.21748\n",
      "Epoch: 19 | Iteration: 253 | Classification loss: 0.01633 | Regression loss: 0.09811 | Running loss: 0.21745\n",
      "Epoch: 19 | Iteration: 254 | Classification loss: 0.01786 | Regression loss: 0.10785 | Running loss: 0.21731\n",
      "Epoch: 19 | Iteration: 255 | Classification loss: 0.02508 | Regression loss: 0.17639 | Running loss: 0.21752\n",
      "Epoch: 19 | Iteration: 256 | Classification loss: 0.01258 | Regression loss: 0.10708 | Running loss: 0.21740\n",
      "Epoch: 19 | Iteration: 257 | Classification loss: 0.05477 | Regression loss: 0.25295 | Running loss: 0.21755\n",
      "Epoch: 19 | Iteration: 258 | Classification loss: 0.02731 | Regression loss: 0.15776 | Running loss: 0.21710\n",
      "Epoch: 19 | Iteration: 259 | Classification loss: 0.08219 | Regression loss: 0.16464 | Running loss: 0.21719\n",
      "Epoch: 19 | Iteration: 260 | Classification loss: 0.01342 | Regression loss: 0.11615 | Running loss: 0.21674\n",
      "Epoch: 19 | Iteration: 261 | Classification loss: 0.01536 | Regression loss: 0.13255 | Running loss: 0.21634\n",
      "Epoch: 19 | Iteration: 262 | Classification loss: 0.01352 | Regression loss: 0.12081 | Running loss: 0.21634\n",
      "Epoch: 19 | Iteration: 263 | Classification loss: 0.02843 | Regression loss: 0.20490 | Running loss: 0.21659\n",
      "Epoch: 19 | Iteration: 264 | Classification loss: 0.01667 | Regression loss: 0.26308 | Running loss: 0.21676\n",
      "Epoch: 19 | Iteration: 265 | Classification loss: 0.00567 | Regression loss: 0.08082 | Running loss: 0.21659\n",
      "Epoch: 19 | Iteration: 266 | Classification loss: 0.03099 | Regression loss: 0.14792 | Running loss: 0.21662\n",
      "Epoch: 19 | Iteration: 267 | Classification loss: 0.08463 | Regression loss: 0.27286 | Running loss: 0.21667\n",
      "Epoch: 19 | Iteration: 268 | Classification loss: 0.08665 | Regression loss: 0.25533 | Running loss: 0.21705\n",
      "Epoch: 19 | Iteration: 269 | Classification loss: 0.02650 | Regression loss: 0.25847 | Running loss: 0.21725\n",
      "Epoch: 19 | Iteration: 270 | Classification loss: 0.02808 | Regression loss: 0.29974 | Running loss: 0.21773\n",
      "Epoch: 19 | Iteration: 271 | Classification loss: 0.01718 | Regression loss: 0.11103 | Running loss: 0.21729\n",
      "Epoch: 19 | Iteration: 272 | Classification loss: 0.05843 | Regression loss: 0.24632 | Running loss: 0.21757\n",
      "Epoch: 19 | Iteration: 273 | Classification loss: 0.00810 | Regression loss: 0.12720 | Running loss: 0.21734\n",
      "Epoch: 19 | Iteration: 274 | Classification loss: 0.01512 | Regression loss: 0.15069 | Running loss: 0.21719\n",
      "Epoch: 19 | Iteration: 275 | Classification loss: 0.00860 | Regression loss: 0.14205 | Running loss: 0.21697\n",
      "Epoch: 19 | Iteration: 276 | Classification loss: 0.05440 | Regression loss: 0.29247 | Running loss: 0.21726\n",
      "Epoch: 19 | Iteration: 277 | Classification loss: 0.00902 | Regression loss: 0.08309 | Running loss: 0.21710\n",
      "Epoch: 19 | Iteration: 278 | Classification loss: 0.02122 | Regression loss: 0.11276 | Running loss: 0.21691\n",
      "Epoch: 19 | Iteration: 279 | Classification loss: 0.04013 | Regression loss: 0.06887 | Running loss: 0.21622\n",
      "Epoch: 19 | Iteration: 280 | Classification loss: 0.02799 | Regression loss: 0.14264 | Running loss: 0.21605\n",
      "Epoch: 19 | Iteration: 281 | Classification loss: 0.01278 | Regression loss: 0.10817 | Running loss: 0.21559\n",
      "Epoch: 19 | Iteration: 282 | Classification loss: 0.06805 | Regression loss: 0.18933 | Running loss: 0.21569\n",
      "Epoch: 19 | Iteration: 283 | Classification loss: 0.11501 | Regression loss: 0.20054 | Running loss: 0.21604\n",
      "Epoch: 19 | Iteration: 284 | Classification loss: 0.01245 | Regression loss: 0.17942 | Running loss: 0.21597\n",
      "Epoch: 19 | Iteration: 285 | Classification loss: 0.01389 | Regression loss: 0.10679 | Running loss: 0.21600\n",
      "Epoch: 19 | Iteration: 286 | Classification loss: 0.02536 | Regression loss: 0.20528 | Running loss: 0.21618\n",
      "Epoch: 19 | Iteration: 287 | Classification loss: 0.05618 | Regression loss: 0.20612 | Running loss: 0.21590\n",
      "Epoch: 19 | Iteration: 288 | Classification loss: 0.00835 | Regression loss: 0.14328 | Running loss: 0.21568\n",
      "Epoch: 19 | Iteration: 289 | Classification loss: 0.00800 | Regression loss: 0.14944 | Running loss: 0.21576\n",
      "Epoch: 19 | Iteration: 290 | Classification loss: 0.01051 | Regression loss: 0.09116 | Running loss: 0.21548\n",
      "Epoch: 19 | Iteration: 291 | Classification loss: 0.02307 | Regression loss: 0.11364 | Running loss: 0.21540\n",
      "Epoch: 19 | Iteration: 292 | Classification loss: 0.02983 | Regression loss: 0.17148 | Running loss: 0.21527\n",
      "Epoch: 19 | Iteration: 293 | Classification loss: 0.02289 | Regression loss: 0.14404 | Running loss: 0.21531\n",
      "Epoch: 19 | Iteration: 294 | Classification loss: 0.00319 | Regression loss: 0.08487 | Running loss: 0.21518\n",
      "Epoch: 19 | Iteration: 295 | Classification loss: 0.01751 | Regression loss: 0.17674 | Running loss: 0.21519\n",
      "Epoch: 19 | Iteration: 296 | Classification loss: 0.02932 | Regression loss: 0.13979 | Running loss: 0.21498\n",
      "Epoch: 19 | Iteration: 297 | Classification loss: 0.11392 | Regression loss: 0.28618 | Running loss: 0.21555\n",
      "Epoch: 19 | Iteration: 298 | Classification loss: 0.02704 | Regression loss: 0.25433 | Running loss: 0.21547\n",
      "Epoch: 19 | Iteration: 299 | Classification loss: 0.06856 | Regression loss: 0.23486 | Running loss: 0.21563\n",
      "Epoch: 19 | Iteration: 300 | Classification loss: 0.01606 | Regression loss: 0.12441 | Running loss: 0.21562\n",
      "Epoch: 19 | Iteration: 301 | Classification loss: 0.03183 | Regression loss: 0.22408 | Running loss: 0.21586\n",
      "Epoch: 19 | Iteration: 302 | Classification loss: 0.01989 | Regression loss: 0.18462 | Running loss: 0.21593\n",
      "Epoch: 19 | Iteration: 303 | Classification loss: 0.01603 | Regression loss: 0.12384 | Running loss: 0.21587\n",
      "Epoch: 19 | Iteration: 304 | Classification loss: 0.05896 | Regression loss: 0.24969 | Running loss: 0.21589\n",
      "Epoch: 19 | Iteration: 305 | Classification loss: 0.00851 | Regression loss: 0.05879 | Running loss: 0.21521\n",
      "Epoch: 19 | Iteration: 306 | Classification loss: 0.00785 | Regression loss: 0.10255 | Running loss: 0.21489\n",
      "Epoch: 19 | Iteration: 307 | Classification loss: 0.05162 | Regression loss: 0.21098 | Running loss: 0.21516\n",
      "Epoch: 19 | Iteration: 308 | Classification loss: 0.01236 | Regression loss: 0.11483 | Running loss: 0.21494\n",
      "Epoch: 19 | Iteration: 309 | Classification loss: 0.01361 | Regression loss: 0.14814 | Running loss: 0.21484\n",
      "Epoch: 19 | Iteration: 310 | Classification loss: 0.03247 | Regression loss: 0.15706 | Running loss: 0.21455\n",
      "Epoch: 19 | Iteration: 311 | Classification loss: 0.14790 | Regression loss: 0.24711 | Running loss: 0.21498\n",
      "Epoch: 19 | Iteration: 312 | Classification loss: 0.00816 | Regression loss: 0.13636 | Running loss: 0.21462\n",
      "Epoch: 19 | Iteration: 313 | Classification loss: 0.02137 | Regression loss: 0.10880 | Running loss: 0.21463\n",
      "Epoch: 19 | Iteration: 314 | Classification loss: 0.02389 | Regression loss: 0.09297 | Running loss: 0.21423\n",
      "Epoch: 19 | Iteration: 315 | Classification loss: 0.00734 | Regression loss: 0.11022 | Running loss: 0.21357\n",
      "Epoch: 19 | Iteration: 316 | Classification loss: 0.05611 | Regression loss: 0.13680 | Running loss: 0.21374\n",
      "Epoch: 19 | Iteration: 317 | Classification loss: 0.00940 | Regression loss: 0.13919 | Running loss: 0.21341\n",
      "Epoch: 19 | Iteration: 318 | Classification loss: 0.03684 | Regression loss: 0.14146 | Running loss: 0.21333\n",
      "Epoch: 19 | Iteration: 319 | Classification loss: 0.01085 | Regression loss: 0.14607 | Running loss: 0.21311\n",
      "Epoch: 19 | Iteration: 320 | Classification loss: 0.01441 | Regression loss: 0.18330 | Running loss: 0.21316\n",
      "Epoch: 19 | Iteration: 321 | Classification loss: 0.00953 | Regression loss: 0.15374 | Running loss: 0.21312\n",
      "Epoch: 19 | Iteration: 322 | Classification loss: 0.07245 | Regression loss: 0.41429 | Running loss: 0.21364\n",
      "Epoch: 19 | Iteration: 323 | Classification loss: 0.04552 | Regression loss: 0.16435 | Running loss: 0.21371\n",
      "Epoch: 19 | Iteration: 324 | Classification loss: 0.01602 | Regression loss: 0.14844 | Running loss: 0.21393\n",
      "Epoch: 19 | Iteration: 325 | Classification loss: 0.02025 | Regression loss: 0.11611 | Running loss: 0.21335\n",
      "Epoch: 19 | Iteration: 326 | Classification loss: 0.00572 | Regression loss: 0.12608 | Running loss: 0.21323\n",
      "Epoch: 19 | Iteration: 327 | Classification loss: 0.01509 | Regression loss: 0.08659 | Running loss: 0.21328\n",
      "Epoch: 19 | Iteration: 328 | Classification loss: 0.01142 | Regression loss: 0.06930 | Running loss: 0.21310\n",
      "Epoch: 19 | Iteration: 329 | Classification loss: 0.00584 | Regression loss: 0.06945 | Running loss: 0.21277\n",
      "Epoch: 19 | Iteration: 330 | Classification loss: 0.00975 | Regression loss: 0.14966 | Running loss: 0.21265\n",
      "Epoch: 19 | Iteration: 331 | Classification loss: 0.08442 | Regression loss: 0.20387 | Running loss: 0.21209\n",
      "Epoch: 19 | Iteration: 332 | Classification loss: 0.06190 | Regression loss: 0.32336 | Running loss: 0.21240\n",
      "Epoch: 19 | Iteration: 333 | Classification loss: 0.13080 | Regression loss: 0.33825 | Running loss: 0.21301\n",
      "Epoch: 19 | Iteration: 334 | Classification loss: 0.01980 | Regression loss: 0.22438 | Running loss: 0.21300\n",
      "Epoch: 19 | Iteration: 335 | Classification loss: 0.05929 | Regression loss: 0.29139 | Running loss: 0.21325\n",
      "Epoch: 19 | Iteration: 336 | Classification loss: 0.01131 | Regression loss: 0.12357 | Running loss: 0.21301\n",
      "Epoch: 19 | Iteration: 337 | Classification loss: 0.03553 | Regression loss: 0.15554 | Running loss: 0.21305\n",
      "Epoch: 19 | Iteration: 338 | Classification loss: 0.01829 | Regression loss: 0.25550 | Running loss: 0.21336\n",
      "Epoch: 19 | Iteration: 339 | Classification loss: 0.06844 | Regression loss: 0.25139 | Running loss: 0.21369\n",
      "Epoch: 19 | Iteration: 340 | Classification loss: 0.01116 | Regression loss: 0.14849 | Running loss: 0.21380\n",
      "Epoch: 19 | Iteration: 341 | Classification loss: 0.17571 | Regression loss: 0.42466 | Running loss: 0.21377\n",
      "Epoch: 19 | Iteration: 342 | Classification loss: 0.06258 | Regression loss: 0.23102 | Running loss: 0.21371\n",
      "Epoch: 19 | Iteration: 343 | Classification loss: 0.08327 | Regression loss: 0.24438 | Running loss: 0.21387\n",
      "Epoch: 19 | Iteration: 344 | Classification loss: 0.01845 | Regression loss: 0.14862 | Running loss: 0.21391\n",
      "Epoch: 19 | Iteration: 345 | Classification loss: 0.04261 | Regression loss: 0.20790 | Running loss: 0.21372\n",
      "Epoch: 19 | Iteration: 346 | Classification loss: 0.02594 | Regression loss: 0.18794 | Running loss: 0.21360\n",
      "Epoch: 19 | Iteration: 347 | Classification loss: 0.01069 | Regression loss: 0.21138 | Running loss: 0.21371\n",
      "Epoch: 19 | Iteration: 348 | Classification loss: 0.03103 | Regression loss: 0.11239 | Running loss: 0.21357\n",
      "Epoch: 19 | Iteration: 349 | Classification loss: 0.03038 | Regression loss: 0.19925 | Running loss: 0.21357\n",
      "Epoch: 19 | Iteration: 350 | Classification loss: 0.05611 | Regression loss: 0.29642 | Running loss: 0.21374\n",
      "Epoch: 19 | Iteration: 351 | Classification loss: 0.19338 | Regression loss: 0.23604 | Running loss: 0.21402\n",
      "Epoch: 19 | Iteration: 352 | Classification loss: 0.05850 | Regression loss: 0.20872 | Running loss: 0.21422\n",
      "Epoch: 19 | Iteration: 353 | Classification loss: 0.07245 | Regression loss: 0.27016 | Running loss: 0.21458\n",
      "Epoch: 19 | Iteration: 354 | Classification loss: 0.02664 | Regression loss: 0.20716 | Running loss: 0.21488\n",
      "Epoch: 19 | Iteration: 355 | Classification loss: 0.00714 | Regression loss: 0.05868 | Running loss: 0.21432\n",
      "Epoch: 19 | Iteration: 356 | Classification loss: 0.02180 | Regression loss: 0.15476 | Running loss: 0.21442\n",
      "Epoch: 19 | Iteration: 357 | Classification loss: 0.06625 | Regression loss: 0.14482 | Running loss: 0.21448\n",
      "Epoch: 19 | Iteration: 358 | Classification loss: 0.02448 | Regression loss: 0.10785 | Running loss: 0.21440\n",
      "Epoch: 19 | Iteration: 359 | Classification loss: 0.04168 | Regression loss: 0.23816 | Running loss: 0.21394\n",
      "Epoch: 19 | Iteration: 360 | Classification loss: 0.04874 | Regression loss: 0.07870 | Running loss: 0.21396\n",
      "Epoch: 19 | Iteration: 361 | Classification loss: 0.08419 | Regression loss: 0.30474 | Running loss: 0.21446\n",
      "Epoch: 19 | Iteration: 362 | Classification loss: 0.03921 | Regression loss: 0.12146 | Running loss: 0.21401\n",
      "Epoch: 19 | Iteration: 363 | Classification loss: 0.04071 | Regression loss: 0.16667 | Running loss: 0.21426\n",
      "Epoch: 19 | Iteration: 364 | Classification loss: 0.06304 | Regression loss: 0.30422 | Running loss: 0.21424\n",
      "Epoch: 19 | Iteration: 365 | Classification loss: 0.01406 | Regression loss: 0.10665 | Running loss: 0.21362\n",
      "Epoch: 19 | Iteration: 366 | Classification loss: 0.05469 | Regression loss: 0.19582 | Running loss: 0.21363\n",
      "Epoch: 19 | Iteration: 367 | Classification loss: 0.07526 | Regression loss: 0.09357 | Running loss: 0.21337\n",
      "Epoch: 19 | Iteration: 368 | Classification loss: 0.01661 | Regression loss: 0.13897 | Running loss: 0.21341\n",
      "Epoch: 19 | Iteration: 369 | Classification loss: 0.01423 | Regression loss: 0.12863 | Running loss: 0.21319\n",
      "Epoch: 19 | Iteration: 370 | Classification loss: 0.11289 | Regression loss: 0.31891 | Running loss: 0.21375\n",
      "Epoch: 19 | Iteration: 371 | Classification loss: 0.03990 | Regression loss: 0.10488 | Running loss: 0.21357\n",
      "Epoch: 19 | Iteration: 372 | Classification loss: 0.02872 | Regression loss: 0.12439 | Running loss: 0.21372\n",
      "Epoch: 19 | Iteration: 373 | Classification loss: 0.03993 | Regression loss: 0.19002 | Running loss: 0.21375\n",
      "Epoch: 19 | Iteration: 374 | Classification loss: 0.14299 | Regression loss: 0.25161 | Running loss: 0.21416\n",
      "Epoch: 19 | Iteration: 375 | Classification loss: 0.04402 | Regression loss: 0.22152 | Running loss: 0.21423\n",
      "Epoch: 19 | Iteration: 376 | Classification loss: 0.01995 | Regression loss: 0.08927 | Running loss: 0.21404\n",
      "Epoch: 19 | Iteration: 377 | Classification loss: 0.12843 | Regression loss: 0.12166 | Running loss: 0.21437\n",
      "Epoch: 19 | Iteration: 378 | Classification loss: 0.02329 | Regression loss: 0.05320 | Running loss: 0.21427\n",
      "Epoch: 19 | Iteration: 379 | Classification loss: 0.01108 | Regression loss: 0.07319 | Running loss: 0.21416\n",
      "Epoch: 19 | Iteration: 380 | Classification loss: 0.01555 | Regression loss: 0.09569 | Running loss: 0.21404\n",
      "Epoch: 19 | Iteration: 381 | Classification loss: 0.06873 | Regression loss: 0.23244 | Running loss: 0.21444\n",
      "Epoch: 19 | Iteration: 382 | Classification loss: 0.00848 | Regression loss: 0.20058 | Running loss: 0.21448\n",
      "Epoch: 19 | Iteration: 383 | Classification loss: 0.02373 | Regression loss: 0.15744 | Running loss: 0.21459\n",
      "Epoch: 19 | Iteration: 384 | Classification loss: 0.02387 | Regression loss: 0.14052 | Running loss: 0.21365\n",
      "Epoch: 19 | Iteration: 385 | Classification loss: 0.01345 | Regression loss: 0.10128 | Running loss: 0.21299\n",
      "Epoch: 19 | Iteration: 386 | Classification loss: 0.03591 | Regression loss: 0.11402 | Running loss: 0.21286\n",
      "Epoch: 19 | Iteration: 387 | Classification loss: 0.05984 | Regression loss: 0.14300 | Running loss: 0.21300\n",
      "Epoch: 19 | Iteration: 388 | Classification loss: 0.02350 | Regression loss: 0.15141 | Running loss: 0.21289\n",
      "Epoch: 19 | Iteration: 389 | Classification loss: 0.01188 | Regression loss: 0.14315 | Running loss: 0.21241\n",
      "Epoch: 19 | Iteration: 390 | Classification loss: 0.03825 | Regression loss: 0.14409 | Running loss: 0.21234\n",
      "Epoch: 19 | Iteration: 391 | Classification loss: 0.03065 | Regression loss: 0.18952 | Running loss: 0.21245\n",
      "Epoch: 19 | Iteration: 392 | Classification loss: 0.09928 | Regression loss: 0.27431 | Running loss: 0.21306\n",
      "Epoch: 19 | Iteration: 393 | Classification loss: 0.08485 | Regression loss: 0.17466 | Running loss: 0.21263\n",
      "Epoch: 19 | Iteration: 394 | Classification loss: 0.13336 | Regression loss: 0.26842 | Running loss: 0.21293\n",
      "Epoch: 19 | Iteration: 395 | Classification loss: 0.00739 | Regression loss: 0.14104 | Running loss: 0.21268\n",
      "Epoch: 19 | Iteration: 396 | Classification loss: 0.05413 | Regression loss: 0.16265 | Running loss: 0.21279\n",
      "Epoch: 19 | Iteration: 397 | Classification loss: 0.01038 | Regression loss: 0.14276 | Running loss: 0.21291\n",
      "Epoch: 19 | Iteration: 398 | Classification loss: 0.02781 | Regression loss: 0.22036 | Running loss: 0.21322\n",
      "Epoch: 19 | Iteration: 399 | Classification loss: 0.06858 | Regression loss: 0.19858 | Running loss: 0.21339\n",
      "Epoch: 19 | Iteration: 400 | Classification loss: 0.04322 | Regression loss: 0.08121 | Running loss: 0.21329\n",
      "Epoch: 19 | Iteration: 401 | Classification loss: 0.03858 | Regression loss: 0.11506 | Running loss: 0.21287\n",
      "Epoch: 19 | Iteration: 402 | Classification loss: 0.02681 | Regression loss: 0.15733 | Running loss: 0.21296\n",
      "Epoch: 19 | Iteration: 403 | Classification loss: 0.04780 | Regression loss: 0.11605 | Running loss: 0.21257\n",
      "Epoch: 19 | Iteration: 404 | Classification loss: 0.04272 | Regression loss: 0.23173 | Running loss: 0.21210\n",
      "Epoch: 19 | Iteration: 405 | Classification loss: 0.04184 | Regression loss: 0.08630 | Running loss: 0.21193\n",
      "Epoch: 19 | Iteration: 406 | Classification loss: 0.01606 | Regression loss: 0.06256 | Running loss: 0.21176\n",
      "Epoch: 19 | Iteration: 407 | Classification loss: 0.03006 | Regression loss: 0.19016 | Running loss: 0.21197\n",
      "Epoch: 19 | Iteration: 408 | Classification loss: 0.03218 | Regression loss: 0.12563 | Running loss: 0.21183\n",
      "Epoch: 19 | Iteration: 409 | Classification loss: 0.01797 | Regression loss: 0.11628 | Running loss: 0.21184\n",
      "Epoch: 19 | Iteration: 410 | Classification loss: 0.04610 | Regression loss: 0.27953 | Running loss: 0.21158\n",
      "Epoch: 19 | Iteration: 411 | Classification loss: 0.04573 | Regression loss: 0.05587 | Running loss: 0.21149\n",
      "Epoch: 19 | Iteration: 412 | Classification loss: 0.05194 | Regression loss: 0.21191 | Running loss: 0.21168\n",
      "Epoch: 19 | Iteration: 413 | Classification loss: 0.04000 | Regression loss: 0.19899 | Running loss: 0.21152\n",
      "Epoch: 19 | Iteration: 414 | Classification loss: 0.01357 | Regression loss: 0.16896 | Running loss: 0.21134\n",
      "Epoch: 19 | Iteration: 415 | Classification loss: 0.03435 | Regression loss: 0.11543 | Running loss: 0.21135\n",
      "Epoch: 19 | Iteration: 416 | Classification loss: 0.05918 | Regression loss: 0.12144 | Running loss: 0.21125\n",
      "Epoch: 19 | Iteration: 417 | Classification loss: 0.01996 | Regression loss: 0.13130 | Running loss: 0.21116\n",
      "Epoch: 19 | Iteration: 418 | Classification loss: 0.02816 | Regression loss: 0.10868 | Running loss: 0.21096\n",
      "Epoch: 19 | Iteration: 419 | Classification loss: 0.03982 | Regression loss: 0.29019 | Running loss: 0.21119\n",
      "Epoch: 19 | Iteration: 420 | Classification loss: 0.03129 | Regression loss: 0.08792 | Running loss: 0.21112\n",
      "Epoch: 19 | Iteration: 421 | Classification loss: 0.07410 | Regression loss: 0.29583 | Running loss: 0.21133\n",
      "Epoch: 19 | Iteration: 422 | Classification loss: 0.04519 | Regression loss: 0.21407 | Running loss: 0.21115\n",
      "Epoch: 19 | Iteration: 423 | Classification loss: 0.13286 | Regression loss: 0.20351 | Running loss: 0.21145\n",
      "Epoch: 19 | Iteration: 424 | Classification loss: 0.08678 | Regression loss: 0.20485 | Running loss: 0.21183\n",
      "Epoch: 19 | Iteration: 425 | Classification loss: 0.06614 | Regression loss: 0.22698 | Running loss: 0.21216\n",
      "Epoch: 19 | Iteration: 426 | Classification loss: 0.01270 | Regression loss: 0.14710 | Running loss: 0.21227\n",
      "Epoch: 19 | Iteration: 427 | Classification loss: 0.04038 | Regression loss: 0.20800 | Running loss: 0.21231\n",
      "Epoch: 19 | Iteration: 428 | Classification loss: 0.12727 | Regression loss: 0.33073 | Running loss: 0.21280\n",
      "Epoch: 19 | Iteration: 429 | Classification loss: 0.08323 | Regression loss: 0.18303 | Running loss: 0.21303\n",
      "Epoch: 19 | Iteration: 430 | Classification loss: 0.02457 | Regression loss: 0.11748 | Running loss: 0.21246\n",
      "Epoch: 19 | Iteration: 431 | Classification loss: 0.01639 | Regression loss: 0.12893 | Running loss: 0.21238\n",
      "Epoch: 19 | Iteration: 432 | Classification loss: 0.03309 | Regression loss: 0.07576 | Running loss: 0.21196\n",
      "Epoch: 19 | Iteration: 433 | Classification loss: 0.04940 | Regression loss: 0.13390 | Running loss: 0.21206\n",
      "Epoch: 19 | Iteration: 434 | Classification loss: 0.04173 | Regression loss: 0.27883 | Running loss: 0.21241\n",
      "Epoch: 19 | Iteration: 435 | Classification loss: 0.06546 | Regression loss: 0.15412 | Running loss: 0.21263\n",
      "Epoch: 19 | Iteration: 436 | Classification loss: 0.02125 | Regression loss: 0.09744 | Running loss: 0.21192\n",
      "Epoch: 19 | Iteration: 437 | Classification loss: 0.12601 | Regression loss: 0.21610 | Running loss: 0.21212\n",
      "Epoch: 19 | Iteration: 438 | Classification loss: 0.04366 | Regression loss: 0.15885 | Running loss: 0.21181\n",
      "Epoch: 19 | Iteration: 439 | Classification loss: 0.06066 | Regression loss: 0.12550 | Running loss: 0.21183\n",
      "Epoch: 19 | Iteration: 440 | Classification loss: 0.01628 | Regression loss: 0.15091 | Running loss: 0.21184\n",
      "Epoch: 19 | Iteration: 441 | Classification loss: 0.01306 | Regression loss: 0.08413 | Running loss: 0.21131\n",
      "Epoch: 19 | Iteration: 442 | Classification loss: 0.01644 | Regression loss: 0.13893 | Running loss: 0.21127\n",
      "Epoch: 19 | Iteration: 443 | Classification loss: 0.05222 | Regression loss: 0.14326 | Running loss: 0.21106\n",
      "Epoch: 19 | Iteration: 444 | Classification loss: 0.02956 | Regression loss: 0.18062 | Running loss: 0.21102\n",
      "Epoch: 19 | Iteration: 445 | Classification loss: 0.01617 | Regression loss: 0.17459 | Running loss: 0.21120\n",
      "Epoch: 19 | Iteration: 446 | Classification loss: 0.16785 | Regression loss: 0.14630 | Running loss: 0.21167\n",
      "Epoch: 19 | Iteration: 447 | Classification loss: 0.01880 | Regression loss: 0.17059 | Running loss: 0.21165\n",
      "Epoch: 19 | Iteration: 448 | Classification loss: 0.02235 | Regression loss: 0.12430 | Running loss: 0.21174\n",
      "Epoch: 19 | Iteration: 449 | Classification loss: 0.05373 | Regression loss: 0.20686 | Running loss: 0.21158\n",
      "Epoch: 19 | Iteration: 450 | Classification loss: 0.01984 | Regression loss: 0.17048 | Running loss: 0.21166\n",
      "Epoch: 19 | Iteration: 451 | Classification loss: 0.02016 | Regression loss: 0.11141 | Running loss: 0.21133\n",
      "Epoch: 19 | Iteration: 452 | Classification loss: 0.01724 | Regression loss: 0.15862 | Running loss: 0.21127\n",
      "Epoch: 19 | Iteration: 453 | Classification loss: 0.08316 | Regression loss: 0.38403 | Running loss: 0.21195\n",
      "Epoch: 19 | Iteration: 454 | Classification loss: 0.10813 | Regression loss: 0.31834 | Running loss: 0.21244\n",
      "Epoch: 19 | Iteration: 455 | Classification loss: 0.04138 | Regression loss: 0.18009 | Running loss: 0.21288\n",
      "Epoch: 19 | Iteration: 456 | Classification loss: 0.01001 | Regression loss: 0.09567 | Running loss: 0.21247\n",
      "Epoch: 19 | Iteration: 457 | Classification loss: 0.02282 | Regression loss: 0.22373 | Running loss: 0.21262\n",
      "Epoch: 19 | Iteration: 458 | Classification loss: 0.03269 | Regression loss: 0.17941 | Running loss: 0.21224\n",
      "Epoch: 19 | Iteration: 459 | Classification loss: 0.02283 | Regression loss: 0.17498 | Running loss: 0.21212\n",
      "Epoch: 19 | Iteration: 460 | Classification loss: 0.03642 | Regression loss: 0.29604 | Running loss: 0.21239\n",
      "Epoch: 19 | Iteration: 461 | Classification loss: 0.01333 | Regression loss: 0.20750 | Running loss: 0.21259\n",
      "Epoch: 19 | Iteration: 462 | Classification loss: 0.02072 | Regression loss: 0.13880 | Running loss: 0.21216\n",
      "Epoch: 19 | Iteration: 463 | Classification loss: 0.00839 | Regression loss: 0.09531 | Running loss: 0.21202\n",
      "Epoch: 19 | Iteration: 464 | Classification loss: 0.04054 | Regression loss: 0.16359 | Running loss: 0.21198\n",
      "Epoch: 19 | Iteration: 465 | Classification loss: 0.01567 | Regression loss: 0.18262 | Running loss: 0.21220\n",
      "Epoch: 19 | Iteration: 466 | Classification loss: 0.01920 | Regression loss: 0.07537 | Running loss: 0.21207\n",
      "Epoch: 19 | Iteration: 467 | Classification loss: 0.08333 | Regression loss: 0.25240 | Running loss: 0.21203\n",
      "Epoch: 19 | Iteration: 468 | Classification loss: 0.04192 | Regression loss: 0.21239 | Running loss: 0.21254\n",
      "Epoch: 19 | Iteration: 469 | Classification loss: 0.03147 | Regression loss: 0.15927 | Running loss: 0.21249\n",
      "Epoch: 19 | Iteration: 470 | Classification loss: 0.01316 | Regression loss: 0.09180 | Running loss: 0.21219\n",
      "Epoch: 19 | Iteration: 471 | Classification loss: 0.02149 | Regression loss: 0.10190 | Running loss: 0.21203\n",
      "Epoch: 19 | Iteration: 472 | Classification loss: 0.02105 | Regression loss: 0.10104 | Running loss: 0.21186\n",
      "Epoch: 19 | Iteration: 473 | Classification loss: 0.01309 | Regression loss: 0.05237 | Running loss: 0.21146\n",
      "Epoch: 19 | Iteration: 474 | Classification loss: 0.01498 | Regression loss: 0.16310 | Running loss: 0.21073\n",
      "Epoch: 19 | Iteration: 475 | Classification loss: 0.02987 | Regression loss: 0.12930 | Running loss: 0.21063\n",
      "Epoch: 19 | Iteration: 476 | Classification loss: 0.02008 | Regression loss: 0.14160 | Running loss: 0.21073\n",
      "Epoch: 19 | Iteration: 477 | Classification loss: 0.03381 | Regression loss: 0.31261 | Running loss: 0.21118\n",
      "Epoch: 19 | Iteration: 478 | Classification loss: 0.02626 | Regression loss: 0.11519 | Running loss: 0.21111\n",
      "Epoch: 19 | Iteration: 479 | Classification loss: 0.03107 | Regression loss: 0.08560 | Running loss: 0.21106\n",
      "Epoch: 19 | Iteration: 480 | Classification loss: 0.01899 | Regression loss: 0.30259 | Running loss: 0.21143\n",
      "Epoch: 19 | Iteration: 481 | Classification loss: 0.03135 | Regression loss: 0.22036 | Running loss: 0.21154\n",
      "Epoch: 19 | Iteration: 482 | Classification loss: 0.03071 | Regression loss: 0.11365 | Running loss: 0.21158\n",
      "Epoch: 19 | Iteration: 483 | Classification loss: 0.04703 | Regression loss: 0.25049 | Running loss: 0.21164\n",
      "Epoch: 19 | Iteration: 484 | Classification loss: 0.05240 | Regression loss: 0.10542 | Running loss: 0.21170\n",
      "Epoch: 19 | Iteration: 485 | Classification loss: 0.00595 | Regression loss: 0.08616 | Running loss: 0.21146\n",
      "Epoch: 19 | Iteration: 486 | Classification loss: 0.00418 | Regression loss: 0.08429 | Running loss: 0.21107\n",
      "Epoch: 19 | Iteration: 487 | Classification loss: 0.05485 | Regression loss: 0.27073 | Running loss: 0.21131\n",
      "Epoch: 19 | Iteration: 488 | Classification loss: 0.00749 | Regression loss: 0.08845 | Running loss: 0.21122\n",
      "Epoch: 19 | Iteration: 489 | Classification loss: 0.01175 | Regression loss: 0.11076 | Running loss: 0.21092\n",
      "Epoch: 19 | Iteration: 490 | Classification loss: 0.06339 | Regression loss: 0.22107 | Running loss: 0.21087\n",
      "Epoch: 19 | Iteration: 491 | Classification loss: 0.02792 | Regression loss: 0.22460 | Running loss: 0.21114\n",
      "Epoch: 19 | Iteration: 492 | Classification loss: 0.01163 | Regression loss: 0.12702 | Running loss: 0.21095\n",
      "Epoch: 19 | Iteration: 493 | Classification loss: 0.05042 | Regression loss: 0.07099 | Running loss: 0.21081\n",
      "Epoch: 19 | Iteration: 494 | Classification loss: 0.05722 | Regression loss: 0.28718 | Running loss: 0.21064\n",
      "Epoch: 19 | Iteration: 495 | Classification loss: 0.00399 | Regression loss: 0.07490 | Running loss: 0.21027\n",
      "Epoch: 19 | Iteration: 496 | Classification loss: 0.03415 | Regression loss: 0.17320 | Running loss: 0.21032\n",
      "Epoch: 19 | Iteration: 497 | Classification loss: 0.02549 | Regression loss: 0.16575 | Running loss: 0.21023\n",
      "Epoch: 19 | Iteration: 498 | Classification loss: 0.10328 | Regression loss: 0.36886 | Running loss: 0.21091\n",
      "Epoch: 19 | Iteration: 499 | Classification loss: 0.01753 | Regression loss: 0.09750 | Running loss: 0.21080\n",
      "Epoch: 19 | Iteration: 500 | Classification loss: 0.08926 | Regression loss: 0.30972 | Running loss: 0.21127\n",
      "Epoch: 19 | Iteration: 501 | Classification loss: 0.03181 | Regression loss: 0.18902 | Running loss: 0.21122\n",
      "Epoch: 19 | Iteration: 502 | Classification loss: 0.02526 | Regression loss: 0.11096 | Running loss: 0.21099\n",
      "Epoch: 19 | Iteration: 503 | Classification loss: 0.00426 | Regression loss: 0.07919 | Running loss: 0.21078\n",
      "Epoch: 19 | Iteration: 504 | Classification loss: 0.02858 | Regression loss: 0.14382 | Running loss: 0.21059\n",
      "Epoch: 19 | Iteration: 505 | Classification loss: 0.04073 | Regression loss: 0.09916 | Running loss: 0.21036\n",
      "Epoch: 19 | Iteration: 506 | Classification loss: 0.01124 | Regression loss: 0.17102 | Running loss: 0.21020\n",
      "Epoch: 19 | Iteration: 507 | Classification loss: 0.07665 | Regression loss: 0.30364 | Running loss: 0.21070\n",
      "Epoch: 19 | Iteration: 508 | Classification loss: 0.01427 | Regression loss: 0.10447 | Running loss: 0.21071\n",
      "Epoch: 19 | Iteration: 509 | Classification loss: 0.01599 | Regression loss: 0.14551 | Running loss: 0.21067\n",
      "Epoch: 19 | Iteration: 510 | Classification loss: 0.03273 | Regression loss: 0.17291 | Running loss: 0.21078\n",
      "Epoch: 19 | Iteration: 511 | Classification loss: 0.01229 | Regression loss: 0.13732 | Running loss: 0.21069\n",
      "Epoch: 19 | Iteration: 512 | Classification loss: 0.00857 | Regression loss: 0.11046 | Running loss: 0.21061\n",
      "Epoch: 19 | Iteration: 513 | Classification loss: 0.08168 | Regression loss: 0.15249 | Running loss: 0.21043\n",
      "Epoch: 19 | Iteration: 514 | Classification loss: 0.04165 | Regression loss: 0.16962 | Running loss: 0.21023\n",
      "Epoch: 19 | Iteration: 515 | Classification loss: 0.04646 | Regression loss: 0.12423 | Running loss: 0.21049\n",
      "Epoch: 19 | Iteration: 516 | Classification loss: 0.05007 | Regression loss: 0.25340 | Running loss: 0.21054\n",
      "Epoch: 19 | Iteration: 517 | Classification loss: 0.01248 | Regression loss: 0.06653 | Running loss: 0.20953\n",
      "Epoch: 19 | Iteration: 518 | Classification loss: 0.01525 | Regression loss: 0.18667 | Running loss: 0.20972\n",
      "Epoch: 19 | Iteration: 519 | Classification loss: 0.00934 | Regression loss: 0.12220 | Running loss: 0.20963\n",
      "Epoch: 19 | Iteration: 520 | Classification loss: 0.00942 | Regression loss: 0.03155 | Running loss: 0.20928\n",
      "Epoch: 19 | Iteration: 521 | Classification loss: 0.01036 | Regression loss: 0.14470 | Running loss: 0.20928\n",
      "Epoch: 19 | Iteration: 522 | Classification loss: 0.01404 | Regression loss: 0.13275 | Running loss: 0.20916\n",
      "Epoch: 19 | Iteration: 523 | Classification loss: 0.10064 | Regression loss: 0.23275 | Running loss: 0.20940\n",
      "Epoch: 19 | Iteration: 524 | Classification loss: 0.02387 | Regression loss: 0.10040 | Running loss: 0.20936\n",
      "Epoch: 19 | Iteration: 525 | Classification loss: 0.15192 | Regression loss: 0.50888 | Running loss: 0.21004\n",
      "Epoch: 19 | Iteration: 526 | Classification loss: 0.11443 | Regression loss: 0.22875 | Running loss: 0.21051\n",
      "Epoch: 19 | Iteration: 527 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.21010\n",
      "Epoch: 19 | Iteration: 528 | Classification loss: 0.09670 | Regression loss: 0.22642 | Running loss: 0.21027\n",
      "Epoch: 19 | Iteration: 529 | Classification loss: 0.11174 | Regression loss: 0.34143 | Running loss: 0.21090\n",
      "Epoch: 19 | Iteration: 530 | Classification loss: 0.01553 | Regression loss: 0.10086 | Running loss: 0.21076\n",
      "Epoch: 19 | Iteration: 531 | Classification loss: 0.04475 | Regression loss: 0.16878 | Running loss: 0.21069\n",
      "Epoch: 19 | Iteration: 532 | Classification loss: 0.02792 | Regression loss: 0.22262 | Running loss: 0.21045\n",
      "Epoch: 19 | Iteration: 533 | Classification loss: 0.01992 | Regression loss: 0.23140 | Running loss: 0.21071\n",
      "Epoch: 19 | Iteration: 534 | Classification loss: 0.01028 | Regression loss: 0.11586 | Running loss: 0.21034\n",
      "Epoch: 19 | Iteration: 535 | Classification loss: 0.08268 | Regression loss: 0.25705 | Running loss: 0.21062\n",
      "Epoch: 19 | Iteration: 536 | Classification loss: 0.02499 | Regression loss: 0.25067 | Running loss: 0.21083\n",
      "Epoch: 19 | Iteration: 537 | Classification loss: 0.01919 | Regression loss: 0.09884 | Running loss: 0.21071\n",
      "Epoch: 19 | Iteration: 538 | Classification loss: 0.01217 | Regression loss: 0.08905 | Running loss: 0.21012\n",
      "Epoch: 19 | Iteration: 539 | Classification loss: 0.05523 | Regression loss: 0.21822 | Running loss: 0.21015\n",
      "Epoch: 19 | Iteration: 540 | Classification loss: 0.03767 | Regression loss: 0.08707 | Running loss: 0.21009\n",
      "Epoch: 19 | Iteration: 541 | Classification loss: 0.01794 | Regression loss: 0.16127 | Running loss: 0.20984\n",
      "Epoch: 19 | Iteration: 542 | Classification loss: 0.02272 | Regression loss: 0.09256 | Running loss: 0.20936\n",
      "Epoch: 19 | Iteration: 543 | Classification loss: 0.05628 | Regression loss: 0.19841 | Running loss: 0.20933\n",
      "Epoch: 19 | Iteration: 544 | Classification loss: 0.10590 | Regression loss: 0.12834 | Running loss: 0.20951\n",
      "Epoch: 19 | Iteration: 545 | Classification loss: 0.02324 | Regression loss: 0.15142 | Running loss: 0.20866\n",
      "Epoch: 19 | Iteration: 546 | Classification loss: 0.03256 | Regression loss: 0.12241 | Running loss: 0.20865\n",
      "Epoch: 19 | Iteration: 547 | Classification loss: 0.02307 | Regression loss: 0.12444 | Running loss: 0.20842\n",
      "Epoch: 19 | Iteration: 548 | Classification loss: 0.05502 | Regression loss: 0.26505 | Running loss: 0.20848\n",
      "Epoch: 19 | Iteration: 549 | Classification loss: 0.03116 | Regression loss: 0.15213 | Running loss: 0.20795\n",
      "Epoch: 19 | Iteration: 550 | Classification loss: 0.02238 | Regression loss: 0.22317 | Running loss: 0.20795\n",
      "Epoch: 19 | Iteration: 551 | Classification loss: 0.02583 | Regression loss: 0.13150 | Running loss: 0.20811\n",
      "Epoch: 19 | Iteration: 552 | Classification loss: 0.02568 | Regression loss: 0.10532 | Running loss: 0.20793\n",
      "Epoch: 19 | Iteration: 553 | Classification loss: 0.01034 | Regression loss: 0.14756 | Running loss: 0.20751\n",
      "Epoch: 19 | Iteration: 554 | Classification loss: 0.14590 | Regression loss: 0.31191 | Running loss: 0.20799\n",
      "Epoch: 19 | Iteration: 555 | Classification loss: 0.02726 | Regression loss: 0.35735 | Running loss: 0.20834\n",
      "Epoch: 19 | Iteration: 556 | Classification loss: 0.02391 | Regression loss: 0.16354 | Running loss: 0.20832\n",
      "Epoch: 19 | Iteration: 557 | Classification loss: 0.01754 | Regression loss: 0.13176 | Running loss: 0.20803\n",
      "Epoch: 19 | Iteration: 558 | Classification loss: 0.07875 | Regression loss: 0.20129 | Running loss: 0.20840\n",
      "Epoch: 19 | Iteration: 559 | Classification loss: 0.02196 | Regression loss: 0.14373 | Running loss: 0.20842\n",
      "Epoch: 19 | Iteration: 560 | Classification loss: 0.01074 | Regression loss: 0.08008 | Running loss: 0.20791\n",
      "Epoch: 19 | Iteration: 561 | Classification loss: 0.01954 | Regression loss: 0.24527 | Running loss: 0.20777\n",
      "Epoch: 19 | Iteration: 562 | Classification loss: 0.10080 | Regression loss: 0.17724 | Running loss: 0.20807\n",
      "Epoch: 19 | Iteration: 563 | Classification loss: 0.06976 | Regression loss: 0.38450 | Running loss: 0.20789\n",
      "Epoch: 19 | Iteration: 564 | Classification loss: 0.01081 | Regression loss: 0.13829 | Running loss: 0.20702\n",
      "Epoch: 19 | Iteration: 565 | Classification loss: 0.02112 | Regression loss: 0.19562 | Running loss: 0.20705\n",
      "Epoch: 19 | Iteration: 566 | Classification loss: 0.07197 | Regression loss: 0.24485 | Running loss: 0.20722\n",
      "Epoch: 19 | Iteration: 567 | Classification loss: 0.05335 | Regression loss: 0.26569 | Running loss: 0.20711\n",
      "Epoch: 19 | Iteration: 568 | Classification loss: 0.06958 | Regression loss: 0.24087 | Running loss: 0.20745\n",
      "Epoch: 19 | Iteration: 569 | Classification loss: 0.01435 | Regression loss: 0.12981 | Running loss: 0.20728\n",
      "Epoch: 19 | Iteration: 570 | Classification loss: 0.06353 | Regression loss: 0.17749 | Running loss: 0.20750\n",
      "Epoch: 19 | Iteration: 571 | Classification loss: 0.01399 | Regression loss: 0.13512 | Running loss: 0.20728\n",
      "Epoch: 19 | Iteration: 572 | Classification loss: 0.06241 | Regression loss: 0.35044 | Running loss: 0.20791\n",
      "Epoch: 19 | Iteration: 573 | Classification loss: 0.02629 | Regression loss: 0.17405 | Running loss: 0.20783\n",
      "Epoch: 19 | Iteration: 574 | Classification loss: 0.03384 | Regression loss: 0.20826 | Running loss: 0.20799\n",
      "Epoch: 19 | Iteration: 575 | Classification loss: 0.04704 | Regression loss: 0.19906 | Running loss: 0.20811\n",
      "Epoch: 19 | Iteration: 576 | Classification loss: 0.03901 | Regression loss: 0.17608 | Running loss: 0.20817\n",
      "Epoch: 19 | Iteration: 577 | Classification loss: 0.01821 | Regression loss: 0.15282 | Running loss: 0.20809\n",
      "Epoch: 19 | Iteration: 578 | Classification loss: 0.00967 | Regression loss: 0.10420 | Running loss: 0.20786\n",
      "Epoch: 19 | Iteration: 579 | Classification loss: 0.12498 | Regression loss: 0.24070 | Running loss: 0.20837\n",
      "Epoch: 19 | Iteration: 580 | Classification loss: 0.05757 | Regression loss: 0.19012 | Running loss: 0.20852\n",
      "Epoch: 19 | Iteration: 581 | Classification loss: 0.04005 | Regression loss: 0.16244 | Running loss: 0.20877\n",
      "Epoch: 19 | Iteration: 582 | Classification loss: 0.00988 | Regression loss: 0.08786 | Running loss: 0.20865\n",
      "Epoch: 19 | Iteration: 583 | Classification loss: 0.01616 | Regression loss: 0.06981 | Running loss: 0.20830\n",
      "Epoch: 19 | Iteration: 584 | Classification loss: 0.06472 | Regression loss: 0.24582 | Running loss: 0.20863\n",
      "Epoch: 19 | Iteration: 585 | Classification loss: 0.02709 | Regression loss: 0.11851 | Running loss: 0.20865\n",
      "Epoch: 19 | Iteration: 586 | Classification loss: 0.06520 | Regression loss: 0.22100 | Running loss: 0.20897\n",
      "Epoch: 19 | Iteration: 587 | Classification loss: 0.08539 | Regression loss: 0.11203 | Running loss: 0.20794\n",
      "Epoch: 19 | Iteration: 588 | Classification loss: 0.01348 | Regression loss: 0.14812 | Running loss: 0.20797\n",
      "Epoch: 19 | Iteration: 589 | Classification loss: 0.01804 | Regression loss: 0.13032 | Running loss: 0.20797\n",
      "Epoch: 19 | Iteration: 590 | Classification loss: 0.01782 | Regression loss: 0.12402 | Running loss: 0.20794\n",
      "Epoch: 19 | Iteration: 591 | Classification loss: 0.01119 | Regression loss: 0.11170 | Running loss: 0.20805\n",
      "Epoch: 19 | Iteration: 592 | Classification loss: 0.02458 | Regression loss: 0.07900 | Running loss: 0.20793\n",
      "Epoch: 19 | Iteration: 593 | Classification loss: 0.03206 | Regression loss: 0.23174 | Running loss: 0.20791\n",
      "Epoch: 19 | Iteration: 594 | Classification loss: 0.07482 | Regression loss: 0.27154 | Running loss: 0.20823\n",
      "Epoch: 19 | Iteration: 595 | Classification loss: 0.07322 | Regression loss: 0.09168 | Running loss: 0.20836\n",
      "Epoch: 19 | Iteration: 596 | Classification loss: 0.01158 | Regression loss: 0.10082 | Running loss: 0.20799\n",
      "Epoch: 19 | Iteration: 597 | Classification loss: 0.00582 | Regression loss: 0.16196 | Running loss: 0.20792\n",
      "Epoch: 19 | Iteration: 598 | Classification loss: 0.03511 | Regression loss: 0.09940 | Running loss: 0.20751\n",
      "Epoch: 19 | Iteration: 599 | Classification loss: 0.21444 | Regression loss: 0.42684 | Running loss: 0.20846\n",
      "Epoch: 19 | Iteration: 600 | Classification loss: 0.10397 | Regression loss: 0.24755 | Running loss: 0.20871\n",
      "Epoch: 19 | Iteration: 601 | Classification loss: 0.00835 | Regression loss: 0.08949 | Running loss: 0.20844\n",
      "Epoch: 19 | Iteration: 602 | Classification loss: 0.18202 | Regression loss: 0.21622 | Running loss: 0.20894\n",
      "Epoch: 19 | Iteration: 603 | Classification loss: 0.00920 | Regression loss: 0.07380 | Running loss: 0.20876\n",
      "Epoch: 19 | Iteration: 604 | Classification loss: 0.04445 | Regression loss: 0.20716 | Running loss: 0.20894\n",
      "Epoch: 19 | Iteration: 605 | Classification loss: 0.00762 | Regression loss: 0.10155 | Running loss: 0.20859\n",
      "Epoch: 19 | Iteration: 606 | Classification loss: 0.00605 | Regression loss: 0.06091 | Running loss: 0.20835\n",
      "Epoch: 19 | Iteration: 607 | Classification loss: 0.06912 | Regression loss: 0.17472 | Running loss: 0.20824\n",
      "Epoch: 19 | Iteration: 608 | Classification loss: 0.00994 | Regression loss: 0.15420 | Running loss: 0.20820\n",
      "Epoch: 19 | Iteration: 609 | Classification loss: 0.05581 | Regression loss: 0.20575 | Running loss: 0.20839\n",
      "Epoch: 19 | Iteration: 610 | Classification loss: 0.01224 | Regression loss: 0.11798 | Running loss: 0.20835\n",
      "Epoch: 19 | Iteration: 611 | Classification loss: 0.02168 | Regression loss: 0.23584 | Running loss: 0.20830\n",
      "Epoch: 19 | Iteration: 612 | Classification loss: 0.04273 | Regression loss: 0.24139 | Running loss: 0.20853\n",
      "Epoch: 19 | Iteration: 613 | Classification loss: 0.08048 | Regression loss: 0.18589 | Running loss: 0.20838\n",
      "Epoch: 19 | Iteration: 614 | Classification loss: 0.02208 | Regression loss: 0.08573 | Running loss: 0.20808\n",
      "Epoch: 19 | Iteration: 615 | Classification loss: 0.07402 | Regression loss: 0.40005 | Running loss: 0.20866\n",
      "Epoch: 19 | Iteration: 616 | Classification loss: 0.00706 | Regression loss: 0.09674 | Running loss: 0.20833\n",
      "Epoch: 19 | Iteration: 617 | Classification loss: 0.00889 | Regression loss: 0.15326 | Running loss: 0.20808\n",
      "Epoch: 19 | Iteration: 618 | Classification loss: 0.04533 | Regression loss: 0.15567 | Running loss: 0.20822\n",
      "Epoch: 19 | Iteration: 619 | Classification loss: 0.03091 | Regression loss: 0.22945 | Running loss: 0.20805\n",
      "Epoch: 19 | Iteration: 620 | Classification loss: 0.02576 | Regression loss: 0.12573 | Running loss: 0.20790\n",
      "Epoch: 19 | Iteration: 621 | Classification loss: 0.00953 | Regression loss: 0.11249 | Running loss: 0.20784\n",
      "Epoch: 19 | Iteration: 622 | Classification loss: 0.01231 | Regression loss: 0.07490 | Running loss: 0.20771\n",
      "Epoch: 19 | Iteration: 623 | Classification loss: 0.01892 | Regression loss: 0.23351 | Running loss: 0.20780\n",
      "Epoch: 19 | Iteration: 624 | Classification loss: 0.02546 | Regression loss: 0.26743 | Running loss: 0.20784\n",
      "Epoch: 19 | Iteration: 625 | Classification loss: 0.05684 | Regression loss: 0.17317 | Running loss: 0.20801\n",
      "Epoch: 19 | Iteration: 626 | Classification loss: 0.02524 | Regression loss: 0.19944 | Running loss: 0.20818\n",
      "Epoch: 19 | Iteration: 627 | Classification loss: 0.01082 | Regression loss: 0.11975 | Running loss: 0.20790\n",
      "Epoch: 19 | Iteration: 628 | Classification loss: 0.02089 | Regression loss: 0.13936 | Running loss: 0.20800\n",
      "Epoch: 19 | Iteration: 629 | Classification loss: 0.00620 | Regression loss: 0.04367 | Running loss: 0.20739\n",
      "Epoch: 19 | Iteration: 630 | Classification loss: 0.03343 | Regression loss: 0.20590 | Running loss: 0.20734\n",
      "Epoch: 19 | Iteration: 631 | Classification loss: 0.01925 | Regression loss: 0.13878 | Running loss: 0.20708\n",
      "Epoch: 19 | Iteration: 632 | Classification loss: 0.03515 | Regression loss: 0.14738 | Running loss: 0.20708\n",
      "Epoch: 19 | Iteration: 633 | Classification loss: 0.11086 | Regression loss: 0.28930 | Running loss: 0.20750\n",
      "Epoch: 19 | Iteration: 634 | Classification loss: 0.03152 | Regression loss: 0.15772 | Running loss: 0.20756\n",
      "Epoch: 19 | Iteration: 635 | Classification loss: 0.07338 | Regression loss: 0.28155 | Running loss: 0.20788\n",
      "Epoch: 19 | Iteration: 636 | Classification loss: 0.09941 | Regression loss: 0.19167 | Running loss: 0.20743\n",
      "Epoch: 19 | Iteration: 637 | Classification loss: 0.08199 | Regression loss: 0.08153 | Running loss: 0.20751\n",
      "Epoch: 19 | Iteration: 638 | Classification loss: 0.01611 | Regression loss: 0.07196 | Running loss: 0.20726\n",
      "Epoch: 19 | Iteration: 639 | Classification loss: 0.02926 | Regression loss: 0.20552 | Running loss: 0.20722\n",
      "Epoch: 19 | Iteration: 640 | Classification loss: 0.02021 | Regression loss: 0.17494 | Running loss: 0.20732\n",
      "Epoch: 19 | Iteration: 641 | Classification loss: 0.14005 | Regression loss: 0.33820 | Running loss: 0.20784\n",
      "Epoch: 19 | Iteration: 642 | Classification loss: 0.09655 | Regression loss: 0.26386 | Running loss: 0.20794\n",
      "Epoch: 19 | Iteration: 643 | Classification loss: 0.01085 | Regression loss: 0.07622 | Running loss: 0.20770\n",
      "Epoch: 19 | Iteration: 644 | Classification loss: 0.01640 | Regression loss: 0.11244 | Running loss: 0.20770\n",
      "Epoch: 19 | Iteration: 645 | Classification loss: 0.04647 | Regression loss: 0.17087 | Running loss: 0.20791\n",
      "Epoch: 19 | Iteration: 646 | Classification loss: 0.03349 | Regression loss: 0.14191 | Running loss: 0.20773\n",
      "Epoch: 19 | Iteration: 647 | Classification loss: 0.16715 | Regression loss: 0.10133 | Running loss: 0.20803\n",
      "Epoch: 19 | Iteration: 648 | Classification loss: 0.02112 | Regression loss: 0.13367 | Running loss: 0.20809\n",
      "Epoch: 19 | Iteration: 649 | Classification loss: 0.03226 | Regression loss: 0.14467 | Running loss: 0.20785\n",
      "Epoch: 19 | Iteration: 650 | Classification loss: 0.01276 | Regression loss: 0.11561 | Running loss: 0.20794\n",
      "Epoch: 19 | Iteration: 651 | Classification loss: 0.01123 | Regression loss: 0.11372 | Running loss: 0.20781\n",
      "Epoch: 19 | Iteration: 652 | Classification loss: 0.06424 | Regression loss: 0.23158 | Running loss: 0.20815\n",
      "Epoch: 19 | Iteration: 653 | Classification loss: 0.02728 | Regression loss: 0.12213 | Running loss: 0.20810\n",
      "Epoch: 19 | Iteration: 654 | Classification loss: 0.03556 | Regression loss: 0.15956 | Running loss: 0.20821\n",
      "Epoch: 19 | Iteration: 655 | Classification loss: 0.05350 | Regression loss: 0.11785 | Running loss: 0.20816\n",
      "Epoch: 19 | Iteration: 656 | Classification loss: 0.01860 | Regression loss: 0.16106 | Running loss: 0.20823\n",
      "Epoch: 19 | Iteration: 657 | Classification loss: 0.03382 | Regression loss: 0.25355 | Running loss: 0.20797\n",
      "Epoch: 19 | Iteration: 658 | Classification loss: 0.01569 | Regression loss: 0.10602 | Running loss: 0.20800\n",
      "Epoch: 19 | Iteration: 659 | Classification loss: 0.04966 | Regression loss: 0.19817 | Running loss: 0.20816\n",
      "Epoch: 19 | Iteration: 660 | Classification loss: 0.01896 | Regression loss: 0.12527 | Running loss: 0.20790\n",
      "Epoch: 19 | Iteration: 661 | Classification loss: 0.00381 | Regression loss: 0.09901 | Running loss: 0.20787\n",
      "Epoch: 19 | Iteration: 662 | Classification loss: 0.07596 | Regression loss: 0.17882 | Running loss: 0.20804\n",
      "Epoch: 19 | Iteration: 663 | Classification loss: 0.05328 | Regression loss: 0.16041 | Running loss: 0.20831\n",
      "Epoch: 19 | Iteration: 664 | Classification loss: 0.04984 | Regression loss: 0.26208 | Running loss: 0.20870\n",
      "Epoch: 19 | Iteration: 665 | Classification loss: 0.02202 | Regression loss: 0.15551 | Running loss: 0.20868\n",
      "Epoch: 19 | Iteration: 666 | Classification loss: 0.03349 | Regression loss: 0.32570 | Running loss: 0.20873\n",
      "Epoch: 19 | Iteration: 667 | Classification loss: 0.00823 | Regression loss: 0.09945 | Running loss: 0.20875\n",
      "Epoch: 19 | Iteration: 668 | Classification loss: 0.04354 | Regression loss: 0.06737 | Running loss: 0.20866\n",
      "Epoch: 19 | Iteration: 669 | Classification loss: 0.01774 | Regression loss: 0.06704 | Running loss: 0.20848\n",
      "Epoch: 19 | Iteration: 670 | Classification loss: 0.01324 | Regression loss: 0.06615 | Running loss: 0.20811\n",
      "Epoch: 19 | Iteration: 671 | Classification loss: 0.02200 | Regression loss: 0.14025 | Running loss: 0.20804\n",
      "Epoch: 19 | Iteration: 672 | Classification loss: 0.01104 | Regression loss: 0.14151 | Running loss: 0.20809\n",
      "Epoch: 19 | Iteration: 673 | Classification loss: 0.01367 | Regression loss: 0.11380 | Running loss: 0.20835\n",
      "Epoch: 19 | Iteration: 674 | Classification loss: 0.00586 | Regression loss: 0.08331 | Running loss: 0.20816\n",
      "Epoch: 19 | Iteration: 675 | Classification loss: 0.01034 | Regression loss: 0.10863 | Running loss: 0.20818\n",
      "Epoch: 19 | Iteration: 676 | Classification loss: 0.14439 | Regression loss: 0.23914 | Running loss: 0.20845\n",
      "Epoch: 19 | Iteration: 677 | Classification loss: 0.01099 | Regression loss: 0.12349 | Running loss: 0.20821\n",
      "Epoch: 19 | Iteration: 678 | Classification loss: 0.02780 | Regression loss: 0.15542 | Running loss: 0.20840\n",
      "Epoch: 19 | Iteration: 679 | Classification loss: 0.12945 | Regression loss: 0.25132 | Running loss: 0.20868\n",
      "Epoch: 19 | Iteration: 680 | Classification loss: 0.00256 | Regression loss: 0.06767 | Running loss: 0.20856\n",
      "Epoch: 19 | Iteration: 681 | Classification loss: 0.07176 | Regression loss: 0.29404 | Running loss: 0.20885\n",
      "Epoch: 19 | Iteration: 682 | Classification loss: 0.09488 | Regression loss: 0.34692 | Running loss: 0.20930\n",
      "Epoch: 19 | Iteration: 683 | Classification loss: 0.04991 | Regression loss: 0.23533 | Running loss: 0.20963\n",
      "Epoch: 19 | Iteration: 684 | Classification loss: 0.04701 | Regression loss: 0.16190 | Running loss: 0.20967\n",
      "Epoch: 19 | Iteration: 685 | Classification loss: 0.05148 | Regression loss: 0.14228 | Running loss: 0.20968\n",
      "Epoch: 19 | Iteration: 686 | Classification loss: 0.02556 | Regression loss: 0.18891 | Running loss: 0.20987\n",
      "Epoch: 19 | Iteration: 687 | Classification loss: 0.01567 | Regression loss: 0.13551 | Running loss: 0.20971\n",
      "Epoch: 19 | Iteration: 688 | Classification loss: 0.05831 | Regression loss: 0.12549 | Running loss: 0.20932\n",
      "Epoch: 19 | Iteration: 689 | Classification loss: 0.02105 | Regression loss: 0.16429 | Running loss: 0.20874\n",
      "Epoch: 19 | Iteration: 690 | Classification loss: 0.00546 | Regression loss: 0.08030 | Running loss: 0.20868\n",
      "Epoch: 19 | Iteration: 691 | Classification loss: 0.06765 | Regression loss: 0.21854 | Running loss: 0.20899\n",
      "Epoch: 19 | Iteration: 692 | Classification loss: 0.09508 | Regression loss: 0.13694 | Running loss: 0.20906\n",
      "Epoch: 19 | Iteration: 693 | Classification loss: 0.07076 | Regression loss: 0.21107 | Running loss: 0.20935\n",
      "Epoch: 19 | Iteration: 694 | Classification loss: 0.01991 | Regression loss: 0.15106 | Running loss: 0.20938\n",
      "Epoch: 19 | Iteration: 695 | Classification loss: 0.03811 | Regression loss: 0.25876 | Running loss: 0.20962\n",
      "Epoch: 19 | Iteration: 696 | Classification loss: 0.03458 | Regression loss: 0.29119 | Running loss: 0.20991\n",
      "Epoch: 19 | Iteration: 697 | Classification loss: 0.05200 | Regression loss: 0.08947 | Running loss: 0.20932\n",
      "Epoch: 19 | Iteration: 698 | Classification loss: 0.13291 | Regression loss: 0.43110 | Running loss: 0.21017\n",
      "Epoch: 19 | Iteration: 699 | Classification loss: 0.04570 | Regression loss: 0.14637 | Running loss: 0.20987\n",
      "Epoch: 19 | Iteration: 700 | Classification loss: 0.10799 | Regression loss: 0.23929 | Running loss: 0.21014\n",
      "Epoch: 19 | Iteration: 701 | Classification loss: 0.01923 | Regression loss: 0.17884 | Running loss: 0.21014\n",
      "Epoch: 19 | Iteration: 702 | Classification loss: 0.09765 | Regression loss: 0.17338 | Running loss: 0.21042\n",
      "Epoch: 19 | Iteration: 703 | Classification loss: 0.08068 | Regression loss: 0.28635 | Running loss: 0.21072\n",
      "Epoch: 19 | Iteration: 704 | Classification loss: 0.02951 | Regression loss: 0.09750 | Running loss: 0.21059\n",
      "Epoch: 19 | Iteration: 705 | Classification loss: 0.02752 | Regression loss: 0.19652 | Running loss: 0.21054\n",
      "Epoch: 19 | Iteration: 706 | Classification loss: 0.03547 | Regression loss: 0.33928 | Running loss: 0.21102\n",
      "Epoch: 19 | Iteration: 707 | Classification loss: 0.03744 | Regression loss: 0.20929 | Running loss: 0.21117\n",
      "Epoch: 19 | Iteration: 708 | Classification loss: 0.00961 | Regression loss: 0.13100 | Running loss: 0.21106\n",
      "Epoch: 19 | Iteration: 709 | Classification loss: 0.03064 | Regression loss: 0.18294 | Running loss: 0.21133\n",
      "Epoch: 19 | Iteration: 710 | Classification loss: 0.09345 | Regression loss: 0.33631 | Running loss: 0.21190\n",
      "Epoch: 19 | Iteration: 711 | Classification loss: 0.07364 | Regression loss: 0.18565 | Running loss: 0.21218\n",
      "Epoch: 19 | Iteration: 712 | Classification loss: 0.04235 | Regression loss: 0.14084 | Running loss: 0.21165\n",
      "Epoch: 19 | Iteration: 713 | Classification loss: 0.01542 | Regression loss: 0.12843 | Running loss: 0.21167\n",
      "Epoch: 19 | Iteration: 714 | Classification loss: 0.06356 | Regression loss: 0.34104 | Running loss: 0.21221\n",
      "Epoch: 19 | Iteration: 715 | Classification loss: 0.03515 | Regression loss: 0.15038 | Running loss: 0.21225\n",
      "Epoch: 19 | Iteration: 716 | Classification loss: 0.05420 | Regression loss: 0.27190 | Running loss: 0.21254\n",
      "Epoch: 19 | Iteration: 717 | Classification loss: 0.03045 | Regression loss: 0.08357 | Running loss: 0.21232\n",
      "Epoch: 19 | Iteration: 718 | Classification loss: 0.00906 | Regression loss: 0.05971 | Running loss: 0.21227\n",
      "Epoch: 19 | Iteration: 719 | Classification loss: 0.01867 | Regression loss: 0.12988 | Running loss: 0.21220\n",
      "Epoch: 19 | Iteration: 720 | Classification loss: 0.04671 | Regression loss: 0.27555 | Running loss: 0.21245\n",
      "Epoch: 19 | Iteration: 721 | Classification loss: 0.17795 | Regression loss: 0.34150 | Running loss: 0.21314\n",
      "Epoch: 19 | Iteration: 722 | Classification loss: 0.01563 | Regression loss: 0.05987 | Running loss: 0.21303\n",
      "Epoch: 19 | Iteration: 723 | Classification loss: 0.00759 | Regression loss: 0.06227 | Running loss: 0.21277\n",
      "Epoch: 19 | Iteration: 724 | Classification loss: 0.02226 | Regression loss: 0.16909 | Running loss: 0.21234\n",
      "Epoch: 19 | Iteration: 725 | Classification loss: 0.04886 | Regression loss: 0.21553 | Running loss: 0.21227\n",
      "Epoch: 19 | Iteration: 726 | Classification loss: 0.05571 | Regression loss: 0.20226 | Running loss: 0.21256\n",
      "Epoch: 19 | Iteration: 727 | Classification loss: 0.06160 | Regression loss: 0.10222 | Running loss: 0.21264\n",
      "Epoch: 19 | Iteration: 728 | Classification loss: 0.04779 | Regression loss: 0.13196 | Running loss: 0.21263\n",
      "Epoch: 19 | Iteration: 729 | Classification loss: 0.03166 | Regression loss: 0.08084 | Running loss: 0.21232\n",
      "Epoch: 19 | Iteration: 730 | Classification loss: 0.01401 | Regression loss: 0.08957 | Running loss: 0.21219\n",
      "Epoch: 19 | Iteration: 731 | Classification loss: 0.03399 | Regression loss: 0.26704 | Running loss: 0.21238\n",
      "Epoch: 19 | Iteration: 732 | Classification loss: 0.02250 | Regression loss: 0.15319 | Running loss: 0.21199\n",
      "Epoch: 19 | Iteration: 733 | Classification loss: 0.10332 | Regression loss: 0.29201 | Running loss: 0.21227\n",
      "Epoch: 19 | Iteration: 734 | Classification loss: 0.01474 | Regression loss: 0.22757 | Running loss: 0.21171\n",
      "Epoch: 19 | Iteration: 735 | Classification loss: 0.00320 | Regression loss: 0.03906 | Running loss: 0.21119\n",
      "Epoch: 19 | Iteration: 736 | Classification loss: 0.00754 | Regression loss: 0.10089 | Running loss: 0.21108\n",
      "Epoch: 19 | Iteration: 737 | Classification loss: 0.03151 | Regression loss: 0.20871 | Running loss: 0.21103\n",
      "Epoch: 19 | Iteration: 738 | Classification loss: 0.06262 | Regression loss: 0.11757 | Running loss: 0.21078\n",
      "Epoch: 19 | Iteration: 739 | Classification loss: 0.01669 | Regression loss: 0.10761 | Running loss: 0.21056\n",
      "Epoch: 19 | Iteration: 740 | Classification loss: 0.16086 | Regression loss: 0.24233 | Running loss: 0.21109\n",
      "Epoch: 19 | Iteration: 741 | Classification loss: 0.03935 | Regression loss: 0.17440 | Running loss: 0.21121\n",
      "Epoch: 19 | Iteration: 742 | Classification loss: 0.02105 | Regression loss: 0.17451 | Running loss: 0.21134\n",
      "Epoch: 19 | Iteration: 743 | Classification loss: 0.02644 | Regression loss: 0.13740 | Running loss: 0.21132\n",
      "Epoch: 19 | Iteration: 744 | Classification loss: 0.01952 | Regression loss: 0.08847 | Running loss: 0.21119\n",
      "Epoch: 19 | Iteration: 745 | Classification loss: 0.08970 | Regression loss: 0.12855 | Running loss: 0.21095\n",
      "Epoch: 19 | Iteration: 746 | Classification loss: 0.00957 | Regression loss: 0.16091 | Running loss: 0.21094\n",
      "Epoch: 19 | Iteration: 747 | Classification loss: 0.02852 | Regression loss: 0.17854 | Running loss: 0.21110\n",
      "Epoch: 19 | Iteration: 748 | Classification loss: 0.01720 | Regression loss: 0.14031 | Running loss: 0.21109\n",
      "Epoch: 19 | Iteration: 749 | Classification loss: 0.00589 | Regression loss: 0.08023 | Running loss: 0.21094\n",
      "Epoch: 19 | Iteration: 750 | Classification loss: 0.01564 | Regression loss: 0.08419 | Running loss: 0.21052\n",
      "Epoch: 19 | Iteration: 751 | Classification loss: 0.03020 | Regression loss: 0.17102 | Running loss: 0.21075\n",
      "Epoch: 19 | Iteration: 752 | Classification loss: 0.02940 | Regression loss: 0.18790 | Running loss: 0.21089\n",
      "Epoch: 19 | Iteration: 753 | Classification loss: 0.01398 | Regression loss: 0.12976 | Running loss: 0.21095\n",
      "Epoch: 19 | Iteration: 754 | Classification loss: 0.02641 | Regression loss: 0.20284 | Running loss: 0.21115\n",
      "Epoch: 19 | Iteration: 755 | Classification loss: 0.38854 | Regression loss: 0.40842 | Running loss: 0.21235\n",
      "Epoch: 19 | Iteration: 756 | Classification loss: 0.03080 | Regression loss: 0.14297 | Running loss: 0.21245\n",
      "Epoch: 19 | Iteration: 757 | Classification loss: 0.02577 | Regression loss: 0.06961 | Running loss: 0.21203\n",
      "Epoch: 19 | Iteration: 758 | Classification loss: 0.06667 | Regression loss: 0.17721 | Running loss: 0.21215\n",
      "Epoch: 19 | Iteration: 759 | Classification loss: 0.12345 | Regression loss: 0.28655 | Running loss: 0.21247\n",
      "Epoch: 19 | Iteration: 760 | Classification loss: 0.08084 | Regression loss: 0.24277 | Running loss: 0.21286\n",
      "Epoch: 19 | Iteration: 761 | Classification loss: 0.39357 | Regression loss: 0.13703 | Running loss: 0.21363\n",
      "Epoch: 19 | Iteration: 762 | Classification loss: 0.01803 | Regression loss: 0.13928 | Running loss: 0.21367\n",
      "Epoch: 19 | Iteration: 763 | Classification loss: 0.06605 | Regression loss: 0.16769 | Running loss: 0.21367\n",
      "Epoch: 19 | Iteration: 764 | Classification loss: 0.01667 | Regression loss: 0.10735 | Running loss: 0.21336\n",
      "Epoch: 19 | Iteration: 765 | Classification loss: 0.03274 | Regression loss: 0.06864 | Running loss: 0.21339\n",
      "Epoch: 19 | Iteration: 766 | Classification loss: 0.06656 | Regression loss: 0.25580 | Running loss: 0.21368\n",
      "Epoch: 19 | Iteration: 767 | Classification loss: 0.08983 | Regression loss: 0.19280 | Running loss: 0.21353\n",
      "Epoch: 19 | Iteration: 768 | Classification loss: 0.01225 | Regression loss: 0.11887 | Running loss: 0.21311\n",
      "Epoch: 19 | Iteration: 769 | Classification loss: 0.02887 | Regression loss: 0.10539 | Running loss: 0.21281\n",
      "Epoch: 19 | Iteration: 770 | Classification loss: 0.06246 | Regression loss: 0.20515 | Running loss: 0.21268\n",
      "Epoch: 19 | Iteration: 771 | Classification loss: 0.00686 | Regression loss: 0.10426 | Running loss: 0.21265\n",
      "Epoch: 19 | Iteration: 772 | Classification loss: 0.01761 | Regression loss: 0.12765 | Running loss: 0.21233\n",
      "Epoch: 19 | Iteration: 773 | Classification loss: 0.04474 | Regression loss: 0.22334 | Running loss: 0.21260\n",
      "Epoch: 19 | Iteration: 774 | Classification loss: 0.04158 | Regression loss: 0.15823 | Running loss: 0.21267\n",
      "Epoch: 19 | Iteration: 775 | Classification loss: 0.01286 | Regression loss: 0.15775 | Running loss: 0.21271\n",
      "Epoch: 19 | Iteration: 776 | Classification loss: 0.06412 | Regression loss: 0.25401 | Running loss: 0.21265\n",
      "Epoch: 19 | Iteration: 777 | Classification loss: 0.03828 | Regression loss: 0.23987 | Running loss: 0.21302\n",
      "Epoch: 19 | Iteration: 778 | Classification loss: 0.00441 | Regression loss: 0.03209 | Running loss: 0.21282\n",
      "Epoch: 19 | Iteration: 779 | Classification loss: 0.05288 | Regression loss: 0.15172 | Running loss: 0.21302\n",
      "Epoch: 19 | Iteration: 780 | Classification loss: 0.02270 | Regression loss: 0.19055 | Running loss: 0.21310\n",
      "Epoch: 19 | Iteration: 781 | Classification loss: 0.09080 | Regression loss: 0.20879 | Running loss: 0.21346\n",
      "Epoch: 19 | Iteration: 782 | Classification loss: 0.00748 | Regression loss: 0.09932 | Running loss: 0.21316\n",
      "Epoch: 19 | Iteration: 783 | Classification loss: 0.02471 | Regression loss: 0.15585 | Running loss: 0.21289\n",
      "Epoch: 19 | Iteration: 784 | Classification loss: 0.00992 | Regression loss: 0.06052 | Running loss: 0.21264\n",
      "Epoch: 19 | Iteration: 785 | Classification loss: 0.05789 | Regression loss: 0.23608 | Running loss: 0.21299\n",
      "Epoch: 19 | Iteration: 786 | Classification loss: 0.13629 | Regression loss: 0.20615 | Running loss: 0.21321\n",
      "Epoch: 19 | Iteration: 787 | Classification loss: 0.04449 | Regression loss: 0.12048 | Running loss: 0.21302\n",
      "Epoch: 19 | Iteration: 788 | Classification loss: 0.15626 | Regression loss: 0.09258 | Running loss: 0.21321\n",
      "Epoch: 19 | Iteration: 789 | Classification loss: 0.01140 | Regression loss: 0.09456 | Running loss: 0.21311\n",
      "Epoch: 19 | Iteration: 790 | Classification loss: 0.02353 | Regression loss: 0.11936 | Running loss: 0.21319\n",
      "Epoch: 19 | Iteration: 791 | Classification loss: 0.01992 | Regression loss: 0.18948 | Running loss: 0.21334\n",
      "Epoch: 19 | Iteration: 792 | Classification loss: 0.05464 | Regression loss: 0.19304 | Running loss: 0.21343\n",
      "Epoch: 19 | Iteration: 793 | Classification loss: 0.07342 | Regression loss: 0.14724 | Running loss: 0.21354\n",
      "Epoch: 19 | Iteration: 794 | Classification loss: 0.09321 | Regression loss: 0.21137 | Running loss: 0.21397\n",
      "Epoch: 19 | Iteration: 795 | Classification loss: 0.11461 | Regression loss: 0.09713 | Running loss: 0.21401\n",
      "Epoch: 19 | Iteration: 796 | Classification loss: 0.04655 | Regression loss: 0.15168 | Running loss: 0.21407\n",
      "Epoch: 19 | Iteration: 797 | Classification loss: 0.05885 | Regression loss: 0.13089 | Running loss: 0.21365\n",
      "Epoch: 19 | Iteration: 798 | Classification loss: 0.37382 | Regression loss: 0.18048 | Running loss: 0.21419\n",
      "Epoch: 19 | Iteration: 799 | Classification loss: 0.10727 | Regression loss: 0.25447 | Running loss: 0.21431\n",
      "Epoch: 19 | Iteration: 800 | Classification loss: 0.02372 | Regression loss: 0.14035 | Running loss: 0.21435\n",
      "Epoch: 19 | Iteration: 801 | Classification loss: 0.08427 | Regression loss: 0.09270 | Running loss: 0.21420\n",
      "Epoch: 19 | Iteration: 802 | Classification loss: 0.14479 | Regression loss: 0.31012 | Running loss: 0.21470\n",
      "Epoch: 19 | Iteration: 803 | Classification loss: 0.00718 | Regression loss: 0.04941 | Running loss: 0.21453\n",
      "Epoch: 19 | Iteration: 804 | Classification loss: 0.04241 | Regression loss: 0.10888 | Running loss: 0.21422\n",
      "Epoch: 19 | Iteration: 805 | Classification loss: 0.03174 | Regression loss: 0.16801 | Running loss: 0.21448\n",
      "Epoch: 19 | Iteration: 806 | Classification loss: 0.06516 | Regression loss: 0.09614 | Running loss: 0.21458\n",
      "Epoch: 19 | Iteration: 807 | Classification loss: 0.01854 | Regression loss: 0.20549 | Running loss: 0.21451\n",
      "Epoch: 19 | Iteration: 808 | Classification loss: 0.04581 | Regression loss: 0.14903 | Running loss: 0.21464\n",
      "Epoch: 19 | Iteration: 809 | Classification loss: 0.43098 | Regression loss: 0.22209 | Running loss: 0.21562\n",
      "Epoch: 19 | Iteration: 810 | Classification loss: 0.06856 | Regression loss: 0.24717 | Running loss: 0.21588\n",
      "Epoch: 19 | Iteration: 811 | Classification loss: 0.01531 | Regression loss: 0.04717 | Running loss: 0.21521\n",
      "Epoch: 19 | Iteration: 812 | Classification loss: 0.02117 | Regression loss: 0.11489 | Running loss: 0.21519\n",
      "Epoch: 19 | Iteration: 813 | Classification loss: 0.06091 | Regression loss: 0.20484 | Running loss: 0.21547\n",
      "Epoch: 19 | Iteration: 814 | Classification loss: 0.05680 | Regression loss: 0.36473 | Running loss: 0.21607\n",
      "Epoch: 19 | Iteration: 815 | Classification loss: 0.02519 | Regression loss: 0.13262 | Running loss: 0.21616\n",
      "Epoch: 19 | Iteration: 816 | Classification loss: 0.02043 | Regression loss: 0.15996 | Running loss: 0.21613\n",
      "Epoch: 19 | Iteration: 817 | Classification loss: 0.00704 | Regression loss: 0.09973 | Running loss: 0.21605\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.618\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 20 | Iteration: 0 | Classification loss: 0.01482 | Regression loss: 0.18685 | Running loss: 0.21609\n",
      "Epoch: 20 | Iteration: 1 | Classification loss: 0.01247 | Regression loss: 0.10174 | Running loss: 0.21601\n",
      "Epoch: 20 | Iteration: 2 | Classification loss: 0.02070 | Regression loss: 0.14992 | Running loss: 0.21595\n",
      "Epoch: 20 | Iteration: 3 | Classification loss: 0.20862 | Regression loss: 0.36600 | Running loss: 0.21678\n",
      "Epoch: 20 | Iteration: 4 | Classification loss: 0.04805 | Regression loss: 0.18119 | Running loss: 0.21626\n",
      "Epoch: 20 | Iteration: 5 | Classification loss: 0.03156 | Regression loss: 0.16603 | Running loss: 0.21624\n",
      "Epoch: 20 | Iteration: 6 | Classification loss: 0.01221 | Regression loss: 0.06648 | Running loss: 0.21607\n",
      "Epoch: 20 | Iteration: 7 | Classification loss: 0.01001 | Regression loss: 0.12014 | Running loss: 0.21605\n",
      "Epoch: 20 | Iteration: 8 | Classification loss: 0.00872 | Regression loss: 0.14448 | Running loss: 0.21610\n",
      "Epoch: 20 | Iteration: 9 | Classification loss: 0.04038 | Regression loss: 0.34434 | Running loss: 0.21666\n",
      "Epoch: 20 | Iteration: 10 | Classification loss: 0.01707 | Regression loss: 0.10932 | Running loss: 0.21675\n",
      "Epoch: 20 | Iteration: 11 | Classification loss: 0.05887 | Regression loss: 0.10915 | Running loss: 0.21694\n",
      "Epoch: 20 | Iteration: 12 | Classification loss: 0.03787 | Regression loss: 0.21827 | Running loss: 0.21713\n",
      "Epoch: 20 | Iteration: 13 | Classification loss: 0.01331 | Regression loss: 0.09768 | Running loss: 0.21678\n",
      "Epoch: 20 | Iteration: 14 | Classification loss: 0.00745 | Regression loss: 0.12599 | Running loss: 0.21627\n",
      "Epoch: 20 | Iteration: 15 | Classification loss: 0.04550 | Regression loss: 0.09552 | Running loss: 0.21562\n",
      "Epoch: 20 | Iteration: 16 | Classification loss: 0.04700 | Regression loss: 0.17074 | Running loss: 0.21556\n",
      "Epoch: 20 | Iteration: 17 | Classification loss: 0.03007 | Regression loss: 0.10488 | Running loss: 0.21513\n",
      "Epoch: 20 | Iteration: 18 | Classification loss: 0.01746 | Regression loss: 0.13772 | Running loss: 0.21517\n",
      "Epoch: 20 | Iteration: 19 | Classification loss: 0.02578 | Regression loss: 0.17270 | Running loss: 0.21519\n",
      "Epoch: 20 | Iteration: 20 | Classification loss: 0.17136 | Regression loss: 0.14201 | Running loss: 0.21527\n",
      "Epoch: 20 | Iteration: 21 | Classification loss: 0.02589 | Regression loss: 0.17267 | Running loss: 0.21503\n",
      "Epoch: 20 | Iteration: 22 | Classification loss: 0.02711 | Regression loss: 0.19067 | Running loss: 0.21514\n",
      "Epoch: 20 | Iteration: 23 | Classification loss: 0.03135 | Regression loss: 0.26890 | Running loss: 0.21454\n",
      "Epoch: 20 | Iteration: 24 | Classification loss: 0.14235 | Regression loss: 0.31685 | Running loss: 0.21487\n",
      "Epoch: 20 | Iteration: 25 | Classification loss: 0.01389 | Regression loss: 0.10007 | Running loss: 0.21445\n",
      "Epoch: 20 | Iteration: 26 | Classification loss: 0.02957 | Regression loss: 0.21199 | Running loss: 0.21459\n",
      "Epoch: 20 | Iteration: 27 | Classification loss: 0.01579 | Regression loss: 0.15225 | Running loss: 0.21443\n",
      "Epoch: 20 | Iteration: 28 | Classification loss: 0.02423 | Regression loss: 0.26142 | Running loss: 0.21457\n",
      "Epoch: 20 | Iteration: 29 | Classification loss: 0.02184 | Regression loss: 0.16732 | Running loss: 0.21451\n",
      "Epoch: 20 | Iteration: 30 | Classification loss: 0.03447 | Regression loss: 0.12624 | Running loss: 0.21454\n",
      "Epoch: 20 | Iteration: 31 | Classification loss: 0.06920 | Regression loss: 0.28633 | Running loss: 0.21479\n",
      "Epoch: 20 | Iteration: 32 | Classification loss: 0.03868 | Regression loss: 0.19605 | Running loss: 0.21456\n",
      "Epoch: 20 | Iteration: 33 | Classification loss: 0.03169 | Regression loss: 0.12650 | Running loss: 0.21402\n",
      "Epoch: 20 | Iteration: 34 | Classification loss: 0.02980 | Regression loss: 0.28292 | Running loss: 0.21411\n",
      "Epoch: 20 | Iteration: 35 | Classification loss: 0.05244 | Regression loss: 0.28005 | Running loss: 0.21409\n",
      "Epoch: 20 | Iteration: 36 | Classification loss: 0.03187 | Regression loss: 0.12141 | Running loss: 0.21393\n",
      "Epoch: 20 | Iteration: 37 | Classification loss: 0.21657 | Regression loss: 0.07601 | Running loss: 0.21438\n",
      "Epoch: 20 | Iteration: 38 | Classification loss: 0.03109 | Regression loss: 0.18329 | Running loss: 0.21445\n",
      "Epoch: 20 | Iteration: 39 | Classification loss: 0.02559 | Regression loss: 0.16449 | Running loss: 0.21441\n",
      "Epoch: 20 | Iteration: 40 | Classification loss: 0.01985 | Regression loss: 0.07146 | Running loss: 0.21433\n",
      "Epoch: 20 | Iteration: 41 | Classification loss: 0.00936 | Regression loss: 0.08060 | Running loss: 0.21395\n",
      "Epoch: 20 | Iteration: 42 | Classification loss: 0.01974 | Regression loss: 0.15918 | Running loss: 0.21405\n",
      "Epoch: 20 | Iteration: 43 | Classification loss: 0.03468 | Regression loss: 0.11509 | Running loss: 0.21358\n",
      "Epoch: 20 | Iteration: 44 | Classification loss: 0.07944 | Regression loss: 0.10140 | Running loss: 0.21362\n",
      "Epoch: 20 | Iteration: 45 | Classification loss: 0.08190 | Regression loss: 0.14926 | Running loss: 0.21366\n",
      "Epoch: 20 | Iteration: 46 | Classification loss: 0.07622 | Regression loss: 0.18611 | Running loss: 0.21345\n",
      "Epoch: 20 | Iteration: 47 | Classification loss: 0.01718 | Regression loss: 0.20734 | Running loss: 0.21366\n",
      "Epoch: 20 | Iteration: 48 | Classification loss: 0.00672 | Regression loss: 0.06187 | Running loss: 0.21330\n",
      "Epoch: 20 | Iteration: 49 | Classification loss: 0.04605 | Regression loss: 0.16895 | Running loss: 0.21339\n",
      "Epoch: 20 | Iteration: 50 | Classification loss: 0.02102 | Regression loss: 0.23188 | Running loss: 0.21358\n",
      "Epoch: 20 | Iteration: 51 | Classification loss: 0.01324 | Regression loss: 0.11076 | Running loss: 0.21355\n",
      "Epoch: 20 | Iteration: 52 | Classification loss: 0.04198 | Regression loss: 0.13243 | Running loss: 0.21303\n",
      "Epoch: 20 | Iteration: 53 | Classification loss: 0.01363 | Regression loss: 0.26637 | Running loss: 0.21330\n",
      "Epoch: 20 | Iteration: 54 | Classification loss: 0.02801 | Regression loss: 0.25307 | Running loss: 0.21356\n",
      "Epoch: 20 | Iteration: 55 | Classification loss: 0.03630 | Regression loss: 0.18536 | Running loss: 0.21354\n",
      "Epoch: 20 | Iteration: 56 | Classification loss: 0.03706 | Regression loss: 0.19139 | Running loss: 0.21321\n",
      "Epoch: 20 | Iteration: 57 | Classification loss: 0.03570 | Regression loss: 0.26576 | Running loss: 0.21328\n",
      "Epoch: 20 | Iteration: 58 | Classification loss: 0.00884 | Regression loss: 0.07364 | Running loss: 0.21323\n",
      "Epoch: 20 | Iteration: 59 | Classification loss: 0.02641 | Regression loss: 0.08478 | Running loss: 0.21295\n",
      "Epoch: 20 | Iteration: 60 | Classification loss: 0.03857 | Regression loss: 0.29392 | Running loss: 0.21346\n",
      "Epoch: 20 | Iteration: 61 | Classification loss: 0.01313 | Regression loss: 0.09754 | Running loss: 0.21351\n",
      "Epoch: 20 | Iteration: 62 | Classification loss: 0.19523 | Regression loss: 0.45069 | Running loss: 0.21458\n",
      "Epoch: 20 | Iteration: 63 | Classification loss: 0.01092 | Regression loss: 0.08081 | Running loss: 0.21416\n",
      "Epoch: 20 | Iteration: 64 | Classification loss: 0.01343 | Regression loss: 0.09679 | Running loss: 0.21397\n",
      "Epoch: 20 | Iteration: 65 | Classification loss: 0.10810 | Regression loss: 0.30019 | Running loss: 0.21442\n",
      "Epoch: 20 | Iteration: 66 | Classification loss: 0.04507 | Regression loss: 0.19244 | Running loss: 0.21457\n",
      "Epoch: 20 | Iteration: 67 | Classification loss: 0.01287 | Regression loss: 0.09441 | Running loss: 0.21455\n",
      "Epoch: 20 | Iteration: 68 | Classification loss: 0.03135 | Regression loss: 0.10911 | Running loss: 0.21453\n",
      "Epoch: 20 | Iteration: 69 | Classification loss: 0.01524 | Regression loss: 0.12633 | Running loss: 0.21441\n",
      "Epoch: 20 | Iteration: 70 | Classification loss: 0.01072 | Regression loss: 0.26999 | Running loss: 0.21462\n",
      "Epoch: 20 | Iteration: 71 | Classification loss: 0.00227 | Regression loss: 0.05691 | Running loss: 0.21443\n",
      "Epoch: 20 | Iteration: 72 | Classification loss: 0.02044 | Regression loss: 0.11586 | Running loss: 0.21434\n",
      "Epoch: 20 | Iteration: 73 | Classification loss: 0.01758 | Regression loss: 0.09113 | Running loss: 0.21412\n",
      "Epoch: 20 | Iteration: 74 | Classification loss: 0.07592 | Regression loss: 0.20830 | Running loss: 0.21394\n",
      "Epoch: 20 | Iteration: 75 | Classification loss: 0.03762 | Regression loss: 0.26261 | Running loss: 0.21402\n",
      "Epoch: 20 | Iteration: 76 | Classification loss: 0.04229 | Regression loss: 0.11112 | Running loss: 0.21352\n",
      "Epoch: 20 | Iteration: 77 | Classification loss: 0.00213 | Regression loss: 0.06906 | Running loss: 0.21337\n",
      "Epoch: 20 | Iteration: 78 | Classification loss: 0.10206 | Regression loss: 0.27193 | Running loss: 0.21368\n",
      "Epoch: 20 | Iteration: 79 | Classification loss: 0.01926 | Regression loss: 0.17466 | Running loss: 0.21376\n",
      "Epoch: 20 | Iteration: 80 | Classification loss: 0.03719 | Regression loss: 0.23949 | Running loss: 0.21382\n",
      "Epoch: 20 | Iteration: 81 | Classification loss: 0.01920 | Regression loss: 0.11813 | Running loss: 0.21356\n",
      "Epoch: 20 | Iteration: 82 | Classification loss: 0.14529 | Regression loss: 0.15237 | Running loss: 0.21391\n",
      "Epoch: 20 | Iteration: 83 | Classification loss: 0.14262 | Regression loss: 0.33968 | Running loss: 0.21456\n",
      "Epoch: 20 | Iteration: 84 | Classification loss: 0.11131 | Regression loss: 0.33099 | Running loss: 0.21508\n",
      "Epoch: 20 | Iteration: 85 | Classification loss: 0.19993 | Regression loss: 0.40484 | Running loss: 0.21596\n",
      "Epoch: 20 | Iteration: 86 | Classification loss: 0.00507 | Regression loss: 0.10296 | Running loss: 0.21563\n",
      "Epoch: 20 | Iteration: 87 | Classification loss: 0.07488 | Regression loss: 0.19494 | Running loss: 0.21591\n",
      "Epoch: 20 | Iteration: 88 | Classification loss: 0.03459 | Regression loss: 0.10432 | Running loss: 0.21603\n",
      "Epoch: 20 | Iteration: 89 | Classification loss: 0.01440 | Regression loss: 0.13528 | Running loss: 0.21589\n",
      "Epoch: 20 | Iteration: 90 | Classification loss: 0.01600 | Regression loss: 0.09712 | Running loss: 0.21580\n",
      "Epoch: 20 | Iteration: 91 | Classification loss: 0.01049 | Regression loss: 0.07904 | Running loss: 0.21571\n",
      "Epoch: 20 | Iteration: 92 | Classification loss: 0.02246 | Regression loss: 0.22565 | Running loss: 0.21556\n",
      "Epoch: 20 | Iteration: 93 | Classification loss: 0.04687 | Regression loss: 0.20350 | Running loss: 0.21586\n",
      "Epoch: 20 | Iteration: 94 | Classification loss: 0.01857 | Regression loss: 0.19049 | Running loss: 0.21575\n",
      "Epoch: 20 | Iteration: 95 | Classification loss: 0.18851 | Regression loss: 0.33075 | Running loss: 0.21631\n",
      "Epoch: 20 | Iteration: 96 | Classification loss: 0.03362 | Regression loss: 0.09311 | Running loss: 0.21620\n",
      "Epoch: 20 | Iteration: 97 | Classification loss: 0.08905 | Regression loss: 0.18608 | Running loss: 0.21645\n",
      "Epoch: 20 | Iteration: 98 | Classification loss: 0.14249 | Regression loss: 0.36328 | Running loss: 0.21710\n",
      "Epoch: 20 | Iteration: 99 | Classification loss: 0.03613 | Regression loss: 0.15192 | Running loss: 0.21717\n",
      "Epoch: 20 | Iteration: 100 | Classification loss: 0.02661 | Regression loss: 0.14807 | Running loss: 0.21725\n",
      "Epoch: 20 | Iteration: 101 | Classification loss: 0.04250 | Regression loss: 0.11803 | Running loss: 0.21691\n",
      "Epoch: 20 | Iteration: 102 | Classification loss: 0.05899 | Regression loss: 0.24845 | Running loss: 0.21728\n",
      "Epoch: 20 | Iteration: 103 | Classification loss: 0.01557 | Regression loss: 0.20527 | Running loss: 0.21699\n",
      "Epoch: 20 | Iteration: 104 | Classification loss: 0.03831 | Regression loss: 0.12095 | Running loss: 0.21679\n",
      "Epoch: 20 | Iteration: 105 | Classification loss: 0.03256 | Regression loss: 0.19480 | Running loss: 0.21657\n",
      "Epoch: 20 | Iteration: 106 | Classification loss: 0.05179 | Regression loss: 0.13868 | Running loss: 0.21637\n",
      "Epoch: 20 | Iteration: 107 | Classification loss: 0.05258 | Regression loss: 0.19465 | Running loss: 0.21627\n",
      "Epoch: 20 | Iteration: 108 | Classification loss: 0.01599 | Regression loss: 0.07152 | Running loss: 0.21613\n",
      "Epoch: 20 | Iteration: 109 | Classification loss: 0.00796 | Regression loss: 0.14764 | Running loss: 0.21594\n",
      "Epoch: 20 | Iteration: 110 | Classification loss: 0.05017 | Regression loss: 0.21913 | Running loss: 0.21557\n",
      "Epoch: 20 | Iteration: 111 | Classification loss: 0.00529 | Regression loss: 0.06530 | Running loss: 0.21517\n",
      "Epoch: 20 | Iteration: 112 | Classification loss: 0.03248 | Regression loss: 0.10826 | Running loss: 0.21517\n",
      "Epoch: 20 | Iteration: 113 | Classification loss: 0.05289 | Regression loss: 0.20586 | Running loss: 0.21540\n",
      "Epoch: 20 | Iteration: 114 | Classification loss: 0.06788 | Regression loss: 0.18959 | Running loss: 0.21570\n",
      "Epoch: 20 | Iteration: 115 | Classification loss: 0.07448 | Regression loss: 0.28423 | Running loss: 0.21605\n",
      "Epoch: 20 | Iteration: 116 | Classification loss: 0.00495 | Regression loss: 0.07542 | Running loss: 0.21557\n",
      "Epoch: 20 | Iteration: 117 | Classification loss: 0.05070 | Regression loss: 0.30730 | Running loss: 0.21584\n",
      "Epoch: 20 | Iteration: 118 | Classification loss: 0.03560 | Regression loss: 0.12654 | Running loss: 0.21593\n",
      "Epoch: 20 | Iteration: 119 | Classification loss: 0.01589 | Regression loss: 0.18750 | Running loss: 0.21565\n",
      "Epoch: 20 | Iteration: 120 | Classification loss: 0.05014 | Regression loss: 0.13045 | Running loss: 0.21561\n",
      "Epoch: 20 | Iteration: 121 | Classification loss: 0.04867 | Regression loss: 0.24040 | Running loss: 0.21581\n",
      "Epoch: 20 | Iteration: 122 | Classification loss: 0.05193 | Regression loss: 0.20179 | Running loss: 0.21599\n",
      "Epoch: 20 | Iteration: 123 | Classification loss: 0.05767 | Regression loss: 0.23096 | Running loss: 0.21637\n",
      "Epoch: 20 | Iteration: 124 | Classification loss: 0.06259 | Regression loss: 0.15739 | Running loss: 0.21650\n",
      "Epoch: 20 | Iteration: 125 | Classification loss: 0.16741 | Regression loss: 0.15199 | Running loss: 0.21675\n",
      "Epoch: 20 | Iteration: 126 | Classification loss: 0.09903 | Regression loss: 0.34558 | Running loss: 0.21722\n",
      "Epoch: 20 | Iteration: 127 | Classification loss: 0.01096 | Regression loss: 0.17337 | Running loss: 0.21720\n",
      "Epoch: 20 | Iteration: 128 | Classification loss: 0.02138 | Regression loss: 0.12363 | Running loss: 0.21687\n",
      "Epoch: 20 | Iteration: 129 | Classification loss: 0.03258 | Regression loss: 0.07801 | Running loss: 0.21671\n",
      "Epoch: 20 | Iteration: 130 | Classification loss: 0.01147 | Regression loss: 0.11942 | Running loss: 0.21668\n",
      "Epoch: 20 | Iteration: 131 | Classification loss: 0.05935 | Regression loss: 0.47665 | Running loss: 0.21723\n",
      "Epoch: 20 | Iteration: 132 | Classification loss: 0.08423 | Regression loss: 0.34871 | Running loss: 0.21771\n",
      "Epoch: 20 | Iteration: 133 | Classification loss: 0.02206 | Regression loss: 0.13497 | Running loss: 0.21776\n",
      "Epoch: 20 | Iteration: 134 | Classification loss: 0.02946 | Regression loss: 0.22782 | Running loss: 0.21793\n",
      "Epoch: 20 | Iteration: 135 | Classification loss: 0.19547 | Regression loss: 0.33830 | Running loss: 0.21806\n",
      "Epoch: 20 | Iteration: 136 | Classification loss: 0.02938 | Regression loss: 0.23325 | Running loss: 0.21773\n",
      "Epoch: 20 | Iteration: 137 | Classification loss: 0.02663 | Regression loss: 0.16893 | Running loss: 0.21768\n",
      "Epoch: 20 | Iteration: 138 | Classification loss: 0.02867 | Regression loss: 0.12934 | Running loss: 0.21778\n",
      "Epoch: 20 | Iteration: 139 | Classification loss: 0.02190 | Regression loss: 0.20365 | Running loss: 0.21774\n",
      "Epoch: 20 | Iteration: 140 | Classification loss: 0.03055 | Regression loss: 0.16862 | Running loss: 0.21772\n",
      "Epoch: 20 | Iteration: 141 | Classification loss: 0.01450 | Regression loss: 0.13102 | Running loss: 0.21761\n",
      "Epoch: 20 | Iteration: 142 | Classification loss: 0.02687 | Regression loss: 0.12705 | Running loss: 0.21725\n",
      "Epoch: 20 | Iteration: 143 | Classification loss: 0.03173 | Regression loss: 0.19699 | Running loss: 0.21727\n",
      "Epoch: 20 | Iteration: 144 | Classification loss: 0.05786 | Regression loss: 0.30230 | Running loss: 0.21767\n",
      "Epoch: 20 | Iteration: 145 | Classification loss: 0.03678 | Regression loss: 0.19295 | Running loss: 0.21792\n",
      "Epoch: 20 | Iteration: 146 | Classification loss: 0.02911 | Regression loss: 0.10021 | Running loss: 0.21777\n",
      "Epoch: 20 | Iteration: 147 | Classification loss: 0.02583 | Regression loss: 0.09097 | Running loss: 0.21761\n",
      "Epoch: 20 | Iteration: 148 | Classification loss: 0.00002 | Regression loss: 0.00000 | Running loss: 0.21742\n",
      "Epoch: 20 | Iteration: 149 | Classification loss: 0.01275 | Regression loss: 0.09180 | Running loss: 0.21696\n",
      "Epoch: 20 | Iteration: 150 | Classification loss: 0.10264 | Regression loss: 0.28566 | Running loss: 0.21723\n",
      "Epoch: 20 | Iteration: 151 | Classification loss: 0.07305 | Regression loss: 0.24697 | Running loss: 0.21749\n",
      "Epoch: 20 | Iteration: 152 | Classification loss: 0.01502 | Regression loss: 0.25588 | Running loss: 0.21782\n",
      "Epoch: 20 | Iteration: 153 | Classification loss: 0.01875 | Regression loss: 0.13874 | Running loss: 0.21789\n",
      "Epoch: 20 | Iteration: 154 | Classification loss: 0.03718 | Regression loss: 0.23628 | Running loss: 0.21819\n",
      "Epoch: 20 | Iteration: 155 | Classification loss: 0.18467 | Regression loss: 0.43034 | Running loss: 0.21929\n",
      "Epoch: 20 | Iteration: 156 | Classification loss: 0.06844 | Regression loss: 0.16960 | Running loss: 0.21941\n",
      "Epoch: 20 | Iteration: 157 | Classification loss: 0.10597 | Regression loss: 0.08105 | Running loss: 0.21946\n",
      "Epoch: 20 | Iteration: 158 | Classification loss: 0.05666 | Regression loss: 0.22154 | Running loss: 0.21970\n",
      "Epoch: 20 | Iteration: 159 | Classification loss: 0.04495 | Regression loss: 0.19183 | Running loss: 0.21948\n",
      "Epoch: 20 | Iteration: 160 | Classification loss: 0.04839 | Regression loss: 0.12594 | Running loss: 0.21954\n",
      "Epoch: 20 | Iteration: 161 | Classification loss: 0.02303 | Regression loss: 0.11432 | Running loss: 0.21958\n",
      "Epoch: 20 | Iteration: 162 | Classification loss: 0.00978 | Regression loss: 0.11026 | Running loss: 0.21918\n",
      "Epoch: 20 | Iteration: 163 | Classification loss: 0.01835 | Regression loss: 0.13681 | Running loss: 0.21899\n",
      "Epoch: 20 | Iteration: 164 | Classification loss: 0.02628 | Regression loss: 0.09721 | Running loss: 0.21895\n",
      "Epoch: 20 | Iteration: 165 | Classification loss: 0.01202 | Regression loss: 0.21130 | Running loss: 0.21880\n",
      "Epoch: 20 | Iteration: 166 | Classification loss: 0.03637 | Regression loss: 0.06401 | Running loss: 0.21868\n",
      "Epoch: 20 | Iteration: 167 | Classification loss: 0.05978 | Regression loss: 0.32594 | Running loss: 0.21927\n",
      "Epoch: 20 | Iteration: 168 | Classification loss: 0.03209 | Regression loss: 0.17221 | Running loss: 0.21950\n",
      "Epoch: 20 | Iteration: 169 | Classification loss: 0.03242 | Regression loss: 0.14421 | Running loss: 0.21920\n",
      "Epoch: 20 | Iteration: 170 | Classification loss: 0.02602 | Regression loss: 0.10740 | Running loss: 0.21928\n",
      "Epoch: 20 | Iteration: 171 | Classification loss: 0.07498 | Regression loss: 0.06256 | Running loss: 0.21931\n",
      "Epoch: 20 | Iteration: 172 | Classification loss: 0.00897 | Regression loss: 0.07010 | Running loss: 0.21890\n",
      "Epoch: 20 | Iteration: 173 | Classification loss: 0.01248 | Regression loss: 0.06213 | Running loss: 0.21854\n",
      "Epoch: 20 | Iteration: 174 | Classification loss: 0.05298 | Regression loss: 0.19858 | Running loss: 0.21877\n",
      "Epoch: 20 | Iteration: 175 | Classification loss: 0.01970 | Regression loss: 0.08945 | Running loss: 0.21874\n",
      "Epoch: 20 | Iteration: 176 | Classification loss: 0.01139 | Regression loss: 0.09545 | Running loss: 0.21827\n",
      "Epoch: 20 | Iteration: 177 | Classification loss: 0.05680 | Regression loss: 0.21130 | Running loss: 0.21865\n",
      "Epoch: 20 | Iteration: 178 | Classification loss: 0.03469 | Regression loss: 0.21126 | Running loss: 0.21872\n",
      "Epoch: 20 | Iteration: 179 | Classification loss: 0.00647 | Regression loss: 0.12793 | Running loss: 0.21861\n",
      "Epoch: 20 | Iteration: 180 | Classification loss: 0.01198 | Regression loss: 0.10394 | Running loss: 0.21790\n",
      "Epoch: 20 | Iteration: 181 | Classification loss: 0.03939 | Regression loss: 0.18642 | Running loss: 0.21812\n",
      "Epoch: 20 | Iteration: 182 | Classification loss: 0.02879 | Regression loss: 0.15480 | Running loss: 0.21769\n",
      "Epoch: 20 | Iteration: 183 | Classification loss: 0.02770 | Regression loss: 0.16604 | Running loss: 0.21764\n",
      "Epoch: 20 | Iteration: 184 | Classification loss: 0.05713 | Regression loss: 0.24456 | Running loss: 0.21797\n",
      "Epoch: 20 | Iteration: 185 | Classification loss: 0.02585 | Regression loss: 0.10393 | Running loss: 0.21806\n",
      "Epoch: 20 | Iteration: 186 | Classification loss: 0.03800 | Regression loss: 0.26796 | Running loss: 0.21833\n",
      "Epoch: 20 | Iteration: 187 | Classification loss: 0.08981 | Regression loss: 0.23767 | Running loss: 0.21870\n",
      "Epoch: 20 | Iteration: 188 | Classification loss: 0.01584 | Regression loss: 0.11530 | Running loss: 0.21860\n",
      "Epoch: 20 | Iteration: 189 | Classification loss: 0.03855 | Regression loss: 0.24844 | Running loss: 0.21841\n",
      "Epoch: 20 | Iteration: 190 | Classification loss: 0.03335 | Regression loss: 0.13209 | Running loss: 0.21851\n",
      "Epoch: 20 | Iteration: 191 | Classification loss: 0.03100 | Regression loss: 0.15599 | Running loss: 0.21856\n",
      "Epoch: 20 | Iteration: 192 | Classification loss: 0.01570 | Regression loss: 0.16515 | Running loss: 0.21851\n",
      "Epoch: 20 | Iteration: 193 | Classification loss: 0.01056 | Regression loss: 0.17678 | Running loss: 0.21858\n",
      "Epoch: 20 | Iteration: 194 | Classification loss: 0.00891 | Regression loss: 0.11519 | Running loss: 0.21859\n",
      "Epoch: 20 | Iteration: 195 | Classification loss: 0.00898 | Regression loss: 0.07045 | Running loss: 0.21828\n",
      "Epoch: 20 | Iteration: 196 | Classification loss: 0.01552 | Regression loss: 0.14034 | Running loss: 0.21817\n",
      "Epoch: 20 | Iteration: 197 | Classification loss: 0.01988 | Regression loss: 0.12612 | Running loss: 0.21812\n",
      "Epoch: 20 | Iteration: 198 | Classification loss: 0.04741 | Regression loss: 0.25112 | Running loss: 0.21811\n",
      "Epoch: 20 | Iteration: 199 | Classification loss: 0.01186 | Regression loss: 0.17332 | Running loss: 0.21833\n",
      "Epoch: 20 | Iteration: 200 | Classification loss: 0.00765 | Regression loss: 0.05239 | Running loss: 0.21804\n",
      "Epoch: 20 | Iteration: 201 | Classification loss: 0.00931 | Regression loss: 0.11651 | Running loss: 0.21803\n",
      "Epoch: 20 | Iteration: 202 | Classification loss: 0.01231 | Regression loss: 0.10333 | Running loss: 0.21818\n",
      "Epoch: 20 | Iteration: 203 | Classification loss: 0.06355 | Regression loss: 0.09801 | Running loss: 0.21819\n",
      "Epoch: 20 | Iteration: 204 | Classification loss: 0.01077 | Regression loss: 0.12905 | Running loss: 0.21818\n",
      "Epoch: 20 | Iteration: 205 | Classification loss: 0.01841 | Regression loss: 0.16329 | Running loss: 0.21788\n",
      "Epoch: 20 | Iteration: 206 | Classification loss: 0.00735 | Regression loss: 0.08146 | Running loss: 0.21780\n",
      "Epoch: 20 | Iteration: 207 | Classification loss: 0.04694 | Regression loss: 0.17280 | Running loss: 0.21692\n",
      "Epoch: 20 | Iteration: 208 | Classification loss: 0.02651 | Regression loss: 0.29088 | Running loss: 0.21687\n",
      "Epoch: 20 | Iteration: 209 | Classification loss: 0.01313 | Regression loss: 0.13135 | Running loss: 0.21716\n",
      "Epoch: 20 | Iteration: 210 | Classification loss: 0.02034 | Regression loss: 0.11431 | Running loss: 0.21678\n",
      "Epoch: 20 | Iteration: 211 | Classification loss: 0.00650 | Regression loss: 0.10179 | Running loss: 0.21609\n",
      "Epoch: 20 | Iteration: 212 | Classification loss: 0.00990 | Regression loss: 0.09649 | Running loss: 0.21607\n",
      "Epoch: 20 | Iteration: 213 | Classification loss: 0.01392 | Regression loss: 0.19486 | Running loss: 0.21606\n",
      "Epoch: 20 | Iteration: 214 | Classification loss: 0.01367 | Regression loss: 0.16982 | Running loss: 0.21593\n",
      "Epoch: 20 | Iteration: 215 | Classification loss: 0.03675 | Regression loss: 0.17002 | Running loss: 0.21584\n",
      "Epoch: 20 | Iteration: 216 | Classification loss: 0.05070 | Regression loss: 0.26099 | Running loss: 0.21621\n",
      "Epoch: 20 | Iteration: 217 | Classification loss: 0.04077 | Regression loss: 0.14491 | Running loss: 0.21590\n",
      "Epoch: 20 | Iteration: 218 | Classification loss: 0.02282 | Regression loss: 0.18822 | Running loss: 0.21577\n",
      "Epoch: 20 | Iteration: 219 | Classification loss: 0.03077 | Regression loss: 0.07858 | Running loss: 0.21576\n",
      "Epoch: 20 | Iteration: 220 | Classification loss: 0.01167 | Regression loss: 0.17008 | Running loss: 0.21592\n",
      "Epoch: 20 | Iteration: 221 | Classification loss: 0.02391 | Regression loss: 0.13217 | Running loss: 0.21568\n",
      "Epoch: 20 | Iteration: 222 | Classification loss: 0.01015 | Regression loss: 0.15597 | Running loss: 0.21577\n",
      "Epoch: 20 | Iteration: 223 | Classification loss: 0.01098 | Regression loss: 0.19682 | Running loss: 0.21582\n",
      "Epoch: 20 | Iteration: 224 | Classification loss: 0.02681 | Regression loss: 0.15590 | Running loss: 0.21596\n",
      "Epoch: 20 | Iteration: 225 | Classification loss: 0.03559 | Regression loss: 0.15702 | Running loss: 0.21583\n",
      "Epoch: 20 | Iteration: 226 | Classification loss: 0.03888 | Regression loss: 0.18743 | Running loss: 0.21582\n",
      "Epoch: 20 | Iteration: 227 | Classification loss: 0.08033 | Regression loss: 0.10308 | Running loss: 0.21584\n",
      "Epoch: 20 | Iteration: 228 | Classification loss: 0.02419 | Regression loss: 0.14712 | Running loss: 0.21587\n",
      "Epoch: 20 | Iteration: 229 | Classification loss: 0.04590 | Regression loss: 0.09822 | Running loss: 0.21586\n",
      "Epoch: 20 | Iteration: 230 | Classification loss: 0.00591 | Regression loss: 0.02559 | Running loss: 0.21528\n",
      "Epoch: 20 | Iteration: 231 | Classification loss: 0.01445 | Regression loss: 0.16011 | Running loss: 0.21527\n",
      "Epoch: 20 | Iteration: 232 | Classification loss: 0.01416 | Regression loss: 0.14702 | Running loss: 0.21510\n",
      "Epoch: 20 | Iteration: 233 | Classification loss: 0.03228 | Regression loss: 0.15356 | Running loss: 0.21515\n",
      "Epoch: 20 | Iteration: 234 | Classification loss: 0.08925 | Regression loss: 0.25088 | Running loss: 0.21557\n",
      "Epoch: 20 | Iteration: 235 | Classification loss: 0.01868 | Regression loss: 0.10879 | Running loss: 0.21551\n",
      "Epoch: 20 | Iteration: 236 | Classification loss: 0.21033 | Regression loss: 0.15426 | Running loss: 0.21533\n",
      "Epoch: 20 | Iteration: 237 | Classification loss: 0.08009 | Regression loss: 0.18002 | Running loss: 0.21508\n",
      "Epoch: 20 | Iteration: 238 | Classification loss: 0.35379 | Regression loss: 0.76092 | Running loss: 0.21693\n",
      "Epoch: 20 | Iteration: 239 | Classification loss: 0.02522 | Regression loss: 0.10564 | Running loss: 0.21689\n",
      "Epoch: 20 | Iteration: 240 | Classification loss: 0.13150 | Regression loss: 0.27888 | Running loss: 0.21716\n",
      "Epoch: 20 | Iteration: 241 | Classification loss: 0.05316 | Regression loss: 0.20388 | Running loss: 0.21734\n",
      "Epoch: 20 | Iteration: 242 | Classification loss: 0.03545 | Regression loss: 0.14915 | Running loss: 0.21753\n",
      "Epoch: 20 | Iteration: 243 | Classification loss: 0.04267 | Regression loss: 0.15986 | Running loss: 0.21740\n",
      "Epoch: 20 | Iteration: 244 | Classification loss: 0.02546 | Regression loss: 0.20860 | Running loss: 0.21731\n",
      "Epoch: 20 | Iteration: 245 | Classification loss: 0.00780 | Regression loss: 0.04257 | Running loss: 0.21650\n",
      "Epoch: 20 | Iteration: 246 | Classification loss: 0.02466 | Regression loss: 0.13990 | Running loss: 0.21654\n",
      "Epoch: 20 | Iteration: 247 | Classification loss: 0.02359 | Regression loss: 0.09379 | Running loss: 0.21634\n",
      "Epoch: 20 | Iteration: 248 | Classification loss: 0.02738 | Regression loss: 0.08090 | Running loss: 0.21592\n",
      "Epoch: 20 | Iteration: 249 | Classification loss: 0.00562 | Regression loss: 0.13543 | Running loss: 0.21556\n",
      "Epoch: 20 | Iteration: 250 | Classification loss: 0.03958 | Regression loss: 0.11458 | Running loss: 0.21525\n",
      "Epoch: 20 | Iteration: 251 | Classification loss: 0.01409 | Regression loss: 0.17430 | Running loss: 0.21534\n",
      "Epoch: 20 | Iteration: 252 | Classification loss: 0.06705 | Regression loss: 0.12031 | Running loss: 0.21523\n",
      "Epoch: 20 | Iteration: 253 | Classification loss: 0.08449 | Regression loss: 0.23670 | Running loss: 0.21558\n",
      "Epoch: 20 | Iteration: 254 | Classification loss: 0.02612 | Regression loss: 0.09400 | Running loss: 0.21499\n",
      "Epoch: 20 | Iteration: 255 | Classification loss: 0.03524 | Regression loss: 0.15291 | Running loss: 0.21497\n",
      "Epoch: 20 | Iteration: 256 | Classification loss: 0.02363 | Regression loss: 0.10702 | Running loss: 0.21474\n",
      "Epoch: 20 | Iteration: 257 | Classification loss: 0.02097 | Regression loss: 0.15370 | Running loss: 0.21460\n",
      "Epoch: 20 | Iteration: 258 | Classification loss: 0.08926 | Regression loss: 0.20486 | Running loss: 0.21476\n",
      "Epoch: 20 | Iteration: 259 | Classification loss: 0.01653 | Regression loss: 0.10491 | Running loss: 0.21466\n",
      "Epoch: 20 | Iteration: 260 | Classification loss: 0.02821 | Regression loss: 0.12539 | Running loss: 0.21474\n",
      "Epoch: 20 | Iteration: 261 | Classification loss: 0.15101 | Regression loss: 0.30170 | Running loss: 0.21491\n",
      "Epoch: 20 | Iteration: 262 | Classification loss: 0.04020 | Regression loss: 0.13279 | Running loss: 0.21476\n",
      "Epoch: 20 | Iteration: 263 | Classification loss: 0.01633 | Regression loss: 0.14680 | Running loss: 0.21469\n",
      "Epoch: 20 | Iteration: 264 | Classification loss: 0.03973 | Regression loss: 0.15461 | Running loss: 0.21488\n",
      "Epoch: 20 | Iteration: 265 | Classification loss: 0.02557 | Regression loss: 0.14545 | Running loss: 0.21505\n",
      "Epoch: 20 | Iteration: 266 | Classification loss: 0.04883 | Regression loss: 0.10638 | Running loss: 0.21474\n",
      "Epoch: 20 | Iteration: 267 | Classification loss: 0.00935 | Regression loss: 0.16046 | Running loss: 0.21479\n",
      "Epoch: 20 | Iteration: 268 | Classification loss: 0.07262 | Regression loss: 0.19942 | Running loss: 0.21476\n",
      "Epoch: 20 | Iteration: 269 | Classification loss: 0.03799 | Regression loss: 0.18335 | Running loss: 0.21481\n",
      "Epoch: 20 | Iteration: 270 | Classification loss: 0.14668 | Regression loss: 0.18608 | Running loss: 0.21515\n",
      "Epoch: 20 | Iteration: 271 | Classification loss: 0.00961 | Regression loss: 0.12501 | Running loss: 0.21512\n",
      "Epoch: 20 | Iteration: 272 | Classification loss: 0.01199 | Regression loss: 0.18231 | Running loss: 0.21523\n",
      "Epoch: 20 | Iteration: 273 | Classification loss: 0.01926 | Regression loss: 0.14102 | Running loss: 0.21530\n",
      "Epoch: 20 | Iteration: 274 | Classification loss: 0.02893 | Regression loss: 0.19423 | Running loss: 0.21554\n",
      "Epoch: 20 | Iteration: 275 | Classification loss: 0.01132 | Regression loss: 0.07546 | Running loss: 0.21519\n",
      "Epoch: 20 | Iteration: 276 | Classification loss: 0.08245 | Regression loss: 0.21494 | Running loss: 0.21509\n",
      "Epoch: 20 | Iteration: 277 | Classification loss: 0.05880 | Regression loss: 0.14586 | Running loss: 0.21517\n",
      "Epoch: 20 | Iteration: 278 | Classification loss: 0.09700 | Regression loss: 0.16868 | Running loss: 0.21547\n",
      "Epoch: 20 | Iteration: 279 | Classification loss: 0.01456 | Regression loss: 0.04882 | Running loss: 0.21527\n",
      "Epoch: 20 | Iteration: 280 | Classification loss: 0.03115 | Regression loss: 0.15739 | Running loss: 0.21537\n",
      "Epoch: 20 | Iteration: 281 | Classification loss: 0.01761 | Regression loss: 0.12185 | Running loss: 0.21437\n",
      "Epoch: 20 | Iteration: 282 | Classification loss: 0.01410 | Regression loss: 0.10977 | Running loss: 0.21391\n",
      "Epoch: 20 | Iteration: 283 | Classification loss: 0.02011 | Regression loss: 0.15147 | Running loss: 0.21406\n",
      "Epoch: 20 | Iteration: 284 | Classification loss: 0.03039 | Regression loss: 0.21907 | Running loss: 0.21376\n",
      "Epoch: 20 | Iteration: 285 | Classification loss: 0.02240 | Regression loss: 0.17041 | Running loss: 0.21398\n",
      "Epoch: 20 | Iteration: 286 | Classification loss: 0.00908 | Regression loss: 0.30024 | Running loss: 0.21410\n",
      "Epoch: 20 | Iteration: 287 | Classification loss: 0.01816 | Regression loss: 0.09578 | Running loss: 0.21411\n",
      "Epoch: 20 | Iteration: 288 | Classification loss: 0.00492 | Regression loss: 0.11401 | Running loss: 0.21421\n",
      "Epoch: 20 | Iteration: 289 | Classification loss: 0.00865 | Regression loss: 0.11210 | Running loss: 0.21397\n",
      "Epoch: 20 | Iteration: 290 | Classification loss: 0.03344 | Regression loss: 0.23275 | Running loss: 0.21417\n",
      "Epoch: 20 | Iteration: 291 | Classification loss: 0.01368 | Regression loss: 0.08378 | Running loss: 0.21384\n",
      "Epoch: 20 | Iteration: 292 | Classification loss: 0.04665 | Regression loss: 0.25089 | Running loss: 0.21418\n",
      "Epoch: 20 | Iteration: 293 | Classification loss: 0.02769 | Regression loss: 0.09714 | Running loss: 0.21391\n",
      "Epoch: 20 | Iteration: 294 | Classification loss: 0.10316 | Regression loss: 0.35851 | Running loss: 0.21427\n",
      "Epoch: 20 | Iteration: 295 | Classification loss: 0.08660 | Regression loss: 0.31068 | Running loss: 0.21453\n",
      "Epoch: 20 | Iteration: 296 | Classification loss: 0.04057 | Regression loss: 0.27945 | Running loss: 0.21495\n",
      "Epoch: 20 | Iteration: 297 | Classification loss: 0.07265 | Regression loss: 0.14110 | Running loss: 0.21443\n",
      "Epoch: 20 | Iteration: 298 | Classification loss: 0.03075 | Regression loss: 0.08314 | Running loss: 0.21445\n",
      "Epoch: 20 | Iteration: 299 | Classification loss: 0.06404 | Regression loss: 0.10150 | Running loss: 0.21446\n",
      "Epoch: 20 | Iteration: 300 | Classification loss: 0.02153 | Regression loss: 0.11531 | Running loss: 0.21433\n",
      "Epoch: 20 | Iteration: 301 | Classification loss: 0.04466 | Regression loss: 0.17584 | Running loss: 0.21425\n",
      "Epoch: 20 | Iteration: 302 | Classification loss: 0.07032 | Regression loss: 0.14985 | Running loss: 0.21439\n",
      "Epoch: 20 | Iteration: 303 | Classification loss: 0.04967 | Regression loss: 0.14706 | Running loss: 0.21454\n",
      "Epoch: 20 | Iteration: 304 | Classification loss: 0.23794 | Regression loss: 0.21007 | Running loss: 0.21526\n",
      "Epoch: 20 | Iteration: 305 | Classification loss: 0.04147 | Regression loss: 0.11301 | Running loss: 0.21506\n",
      "Epoch: 20 | Iteration: 306 | Classification loss: 0.41880 | Regression loss: 0.10042 | Running loss: 0.21552\n",
      "Epoch: 20 | Iteration: 307 | Classification loss: 0.04764 | Regression loss: 0.14146 | Running loss: 0.21543\n",
      "Epoch: 20 | Iteration: 308 | Classification loss: 0.08997 | Regression loss: 0.23386 | Running loss: 0.21563\n",
      "Epoch: 20 | Iteration: 309 | Classification loss: 0.06893 | Regression loss: 0.18780 | Running loss: 0.21589\n",
      "Epoch: 20 | Iteration: 310 | Classification loss: 0.05810 | Regression loss: 0.26267 | Running loss: 0.21621\n",
      "Epoch: 20 | Iteration: 311 | Classification loss: 0.00872 | Regression loss: 0.11538 | Running loss: 0.21635\n",
      "Epoch: 20 | Iteration: 312 | Classification loss: 0.01653 | Regression loss: 0.13825 | Running loss: 0.21619\n",
      "Epoch: 20 | Iteration: 313 | Classification loss: 0.02858 | Regression loss: 0.13361 | Running loss: 0.21619\n",
      "Epoch: 20 | Iteration: 314 | Classification loss: 0.26250 | Regression loss: 0.19475 | Running loss: 0.21674\n",
      "Epoch: 20 | Iteration: 315 | Classification loss: 0.04017 | Regression loss: 0.21566 | Running loss: 0.21645\n",
      "Epoch: 20 | Iteration: 316 | Classification loss: 0.03116 | Regression loss: 0.19533 | Running loss: 0.21653\n",
      "Epoch: 20 | Iteration: 317 | Classification loss: 0.01065 | Regression loss: 0.06887 | Running loss: 0.21598\n",
      "Epoch: 20 | Iteration: 318 | Classification loss: 0.01638 | Regression loss: 0.12254 | Running loss: 0.21567\n",
      "Epoch: 20 | Iteration: 319 | Classification loss: 0.04575 | Regression loss: 0.22970 | Running loss: 0.21590\n",
      "Epoch: 20 | Iteration: 320 | Classification loss: 0.05255 | Regression loss: 0.13170 | Running loss: 0.21609\n",
      "Epoch: 20 | Iteration: 321 | Classification loss: 0.01032 | Regression loss: 0.12202 | Running loss: 0.21589\n",
      "Epoch: 20 | Iteration: 322 | Classification loss: 0.02672 | Regression loss: 0.09185 | Running loss: 0.21573\n",
      "Epoch: 20 | Iteration: 323 | Classification loss: 0.32588 | Regression loss: 0.50082 | Running loss: 0.21643\n",
      "Epoch: 20 | Iteration: 324 | Classification loss: 0.02298 | Regression loss: 0.08581 | Running loss: 0.21593\n",
      "Epoch: 20 | Iteration: 325 | Classification loss: 0.03448 | Regression loss: 0.09351 | Running loss: 0.21601\n",
      "Epoch: 20 | Iteration: 326 | Classification loss: 0.01799 | Regression loss: 0.14095 | Running loss: 0.21607\n",
      "Epoch: 20 | Iteration: 327 | Classification loss: 0.03600 | Regression loss: 0.19294 | Running loss: 0.21609\n",
      "Epoch: 20 | Iteration: 328 | Classification loss: 0.06426 | Regression loss: 0.09109 | Running loss: 0.21605\n",
      "Epoch: 20 | Iteration: 329 | Classification loss: 0.02641 | Regression loss: 0.14675 | Running loss: 0.21586\n",
      "Epoch: 20 | Iteration: 330 | Classification loss: 0.02402 | Regression loss: 0.09878 | Running loss: 0.21580\n",
      "Epoch: 20 | Iteration: 331 | Classification loss: 0.01537 | Regression loss: 0.10637 | Running loss: 0.21569\n",
      "Epoch: 20 | Iteration: 332 | Classification loss: 0.02400 | Regression loss: 0.08333 | Running loss: 0.21564\n",
      "Epoch: 20 | Iteration: 333 | Classification loss: 0.02671 | Regression loss: 0.12802 | Running loss: 0.21570\n",
      "Epoch: 20 | Iteration: 334 | Classification loss: 0.01159 | Regression loss: 0.13580 | Running loss: 0.21541\n",
      "Epoch: 20 | Iteration: 335 | Classification loss: 0.05766 | Regression loss: 0.13984 | Running loss: 0.21550\n",
      "Epoch: 20 | Iteration: 336 | Classification loss: 0.04352 | Regression loss: 0.16198 | Running loss: 0.21552\n",
      "Epoch: 20 | Iteration: 337 | Classification loss: 0.01797 | Regression loss: 0.18497 | Running loss: 0.21559\n",
      "Epoch: 20 | Iteration: 338 | Classification loss: 0.01931 | Regression loss: 0.18597 | Running loss: 0.21564\n",
      "Epoch: 20 | Iteration: 339 | Classification loss: 0.01858 | Regression loss: 0.08815 | Running loss: 0.21528\n",
      "Epoch: 20 | Iteration: 340 | Classification loss: 0.03643 | Regression loss: 0.19772 | Running loss: 0.21550\n",
      "Epoch: 20 | Iteration: 341 | Classification loss: 0.03264 | Regression loss: 0.15719 | Running loss: 0.21539\n",
      "Epoch: 20 | Iteration: 342 | Classification loss: 0.03215 | Regression loss: 0.10149 | Running loss: 0.21536\n",
      "Epoch: 20 | Iteration: 343 | Classification loss: 0.03773 | Regression loss: 0.18335 | Running loss: 0.21560\n",
      "Epoch: 20 | Iteration: 344 | Classification loss: 0.00784 | Regression loss: 0.13135 | Running loss: 0.21537\n",
      "Epoch: 20 | Iteration: 345 | Classification loss: 0.01674 | Regression loss: 0.17749 | Running loss: 0.21533\n",
      "Epoch: 20 | Iteration: 346 | Classification loss: 0.01342 | Regression loss: 0.08400 | Running loss: 0.21490\n",
      "Epoch: 20 | Iteration: 347 | Classification loss: 0.00940 | Regression loss: 0.10352 | Running loss: 0.21477\n",
      "Epoch: 20 | Iteration: 348 | Classification loss: 0.01344 | Regression loss: 0.09627 | Running loss: 0.21427\n",
      "Epoch: 20 | Iteration: 349 | Classification loss: 0.04722 | Regression loss: 0.14806 | Running loss: 0.21445\n",
      "Epoch: 20 | Iteration: 350 | Classification loss: 0.01971 | Regression loss: 0.11945 | Running loss: 0.21451\n",
      "Epoch: 20 | Iteration: 351 | Classification loss: 0.03998 | Regression loss: 0.15481 | Running loss: 0.21473\n",
      "Epoch: 20 | Iteration: 352 | Classification loss: 0.02360 | Regression loss: 0.13249 | Running loss: 0.21488\n",
      "Epoch: 20 | Iteration: 353 | Classification loss: 0.02187 | Regression loss: 0.09546 | Running loss: 0.21479\n",
      "Epoch: 20 | Iteration: 354 | Classification loss: 0.04798 | Regression loss: 0.23943 | Running loss: 0.21506\n",
      "Epoch: 20 | Iteration: 355 | Classification loss: 0.01301 | Regression loss: 0.13066 | Running loss: 0.21509\n",
      "Epoch: 20 | Iteration: 356 | Classification loss: 0.01538 | Regression loss: 0.09560 | Running loss: 0.21513\n",
      "Epoch: 20 | Iteration: 357 | Classification loss: 0.02062 | Regression loss: 0.07576 | Running loss: 0.21509\n",
      "Epoch: 20 | Iteration: 358 | Classification loss: 0.00826 | Regression loss: 0.14330 | Running loss: 0.21463\n",
      "Epoch: 20 | Iteration: 359 | Classification loss: 0.00600 | Regression loss: 0.07438 | Running loss: 0.21452\n",
      "Epoch: 20 | Iteration: 360 | Classification loss: 0.00954 | Regression loss: 0.04308 | Running loss: 0.21426\n",
      "Epoch: 20 | Iteration: 361 | Classification loss: 0.01619 | Regression loss: 0.10228 | Running loss: 0.21373\n",
      "Epoch: 20 | Iteration: 362 | Classification loss: 0.01447 | Regression loss: 0.20387 | Running loss: 0.21403\n",
      "Epoch: 20 | Iteration: 363 | Classification loss: 0.02391 | Regression loss: 0.14624 | Running loss: 0.21364\n",
      "Epoch: 20 | Iteration: 364 | Classification loss: 0.02786 | Regression loss: 0.18991 | Running loss: 0.21319\n",
      "Epoch: 20 | Iteration: 365 | Classification loss: 0.02197 | Regression loss: 0.18629 | Running loss: 0.21303\n",
      "Epoch: 20 | Iteration: 366 | Classification loss: 0.01493 | Regression loss: 0.11319 | Running loss: 0.21287\n",
      "Epoch: 20 | Iteration: 367 | Classification loss: 0.02421 | Regression loss: 0.11911 | Running loss: 0.21277\n",
      "Epoch: 20 | Iteration: 368 | Classification loss: 0.02180 | Regression loss: 0.17571 | Running loss: 0.21274\n",
      "Epoch: 20 | Iteration: 369 | Classification loss: 0.00963 | Regression loss: 0.14620 | Running loss: 0.21275\n",
      "Epoch: 20 | Iteration: 370 | Classification loss: 0.35326 | Regression loss: 0.57921 | Running loss: 0.21424\n",
      "Epoch: 20 | Iteration: 371 | Classification loss: 0.01523 | Regression loss: 0.12222 | Running loss: 0.21415\n",
      "Epoch: 20 | Iteration: 372 | Classification loss: 0.02772 | Regression loss: 0.13108 | Running loss: 0.21429\n",
      "Epoch: 20 | Iteration: 373 | Classification loss: 0.00957 | Regression loss: 0.13556 | Running loss: 0.21401\n",
      "Epoch: 20 | Iteration: 374 | Classification loss: 0.02411 | Regression loss: 0.08691 | Running loss: 0.21377\n",
      "Epoch: 20 | Iteration: 375 | Classification loss: 0.02662 | Regression loss: 0.09295 | Running loss: 0.21345\n",
      "Epoch: 20 | Iteration: 376 | Classification loss: 0.01126 | Regression loss: 0.15811 | Running loss: 0.21344\n",
      "Epoch: 20 | Iteration: 377 | Classification loss: 0.08823 | Regression loss: 0.26941 | Running loss: 0.21356\n",
      "Epoch: 20 | Iteration: 378 | Classification loss: 0.03115 | Regression loss: 0.27029 | Running loss: 0.21352\n",
      "Epoch: 20 | Iteration: 379 | Classification loss: 0.03751 | Regression loss: 0.15271 | Running loss: 0.21361\n",
      "Epoch: 20 | Iteration: 380 | Classification loss: 0.05878 | Regression loss: 0.23031 | Running loss: 0.21306\n",
      "Epoch: 20 | Iteration: 381 | Classification loss: 0.03992 | Regression loss: 0.18524 | Running loss: 0.21313\n",
      "Epoch: 20 | Iteration: 382 | Classification loss: 0.01611 | Regression loss: 0.16455 | Running loss: 0.21280\n",
      "Epoch: 20 | Iteration: 383 | Classification loss: 0.01596 | Regression loss: 0.15486 | Running loss: 0.21274\n",
      "Epoch: 20 | Iteration: 384 | Classification loss: 0.05072 | Regression loss: 0.21479 | Running loss: 0.21273\n",
      "Epoch: 20 | Iteration: 385 | Classification loss: 0.00702 | Regression loss: 0.12855 | Running loss: 0.21227\n",
      "Epoch: 20 | Iteration: 386 | Classification loss: 0.01112 | Regression loss: 0.08627 | Running loss: 0.21221\n",
      "Epoch: 20 | Iteration: 387 | Classification loss: 0.02272 | Regression loss: 0.05637 | Running loss: 0.21192\n",
      "Epoch: 20 | Iteration: 388 | Classification loss: 0.01674 | Regression loss: 0.15414 | Running loss: 0.21151\n",
      "Epoch: 20 | Iteration: 389 | Classification loss: 0.07937 | Regression loss: 0.17047 | Running loss: 0.21152\n",
      "Epoch: 20 | Iteration: 390 | Classification loss: 0.01433 | Regression loss: 0.11889 | Running loss: 0.21150\n",
      "Epoch: 20 | Iteration: 391 | Classification loss: 0.03506 | Regression loss: 0.15222 | Running loss: 0.21145\n",
      "Epoch: 20 | Iteration: 392 | Classification loss: 0.15386 | Regression loss: 0.27631 | Running loss: 0.21145\n",
      "Epoch: 20 | Iteration: 393 | Classification loss: 0.04545 | Regression loss: 0.12958 | Running loss: 0.21128\n",
      "Epoch: 20 | Iteration: 394 | Classification loss: 0.09781 | Regression loss: 0.38406 | Running loss: 0.21188\n",
      "Epoch: 20 | Iteration: 395 | Classification loss: 0.01142 | Regression loss: 0.09360 | Running loss: 0.21180\n",
      "Epoch: 20 | Iteration: 396 | Classification loss: 0.17175 | Regression loss: 0.23573 | Running loss: 0.21181\n",
      "Epoch: 20 | Iteration: 397 | Classification loss: 0.01266 | Regression loss: 0.11539 | Running loss: 0.21169\n",
      "Epoch: 20 | Iteration: 398 | Classification loss: 0.06632 | Regression loss: 0.25446 | Running loss: 0.21168\n",
      "Epoch: 20 | Iteration: 399 | Classification loss: 0.00675 | Regression loss: 0.08055 | Running loss: 0.21163\n",
      "Epoch: 20 | Iteration: 400 | Classification loss: 0.00813 | Regression loss: 0.11522 | Running loss: 0.21174\n",
      "Epoch: 20 | Iteration: 401 | Classification loss: 0.02227 | Regression loss: 0.14972 | Running loss: 0.21178\n",
      "Epoch: 20 | Iteration: 402 | Classification loss: 0.00652 | Regression loss: 0.07826 | Running loss: 0.21131\n",
      "Epoch: 20 | Iteration: 403 | Classification loss: 0.05699 | Regression loss: 0.27943 | Running loss: 0.21094\n",
      "Epoch: 20 | Iteration: 404 | Classification loss: 0.02523 | Regression loss: 0.10084 | Running loss: 0.21104\n",
      "Epoch: 20 | Iteration: 405 | Classification loss: 0.00910 | Regression loss: 0.07326 | Running loss: 0.21107\n",
      "Epoch: 20 | Iteration: 406 | Classification loss: 0.02726 | Regression loss: 0.19455 | Running loss: 0.21113\n",
      "Epoch: 20 | Iteration: 407 | Classification loss: 0.00944 | Regression loss: 0.07349 | Running loss: 0.21077\n",
      "Epoch: 20 | Iteration: 408 | Classification loss: 0.01569 | Regression loss: 0.12529 | Running loss: 0.21053\n",
      "Epoch: 20 | Iteration: 409 | Classification loss: 0.08007 | Regression loss: 0.06391 | Running loss: 0.21049\n",
      "Epoch: 20 | Iteration: 410 | Classification loss: 0.01303 | Regression loss: 0.07293 | Running loss: 0.21031\n",
      "Epoch: 20 | Iteration: 411 | Classification loss: 0.02237 | Regression loss: 0.18654 | Running loss: 0.21050\n",
      "Epoch: 20 | Iteration: 412 | Classification loss: 0.02268 | Regression loss: 0.18482 | Running loss: 0.21071\n",
      "Epoch: 20 | Iteration: 413 | Classification loss: 0.02700 | Regression loss: 0.13947 | Running loss: 0.21044\n",
      "Epoch: 20 | Iteration: 414 | Classification loss: 0.01561 | Regression loss: 0.16423 | Running loss: 0.21045\n",
      "Epoch: 20 | Iteration: 415 | Classification loss: 0.01738 | Regression loss: 0.10752 | Running loss: 0.20991\n",
      "Epoch: 20 | Iteration: 416 | Classification loss: 0.07034 | Regression loss: 0.05780 | Running loss: 0.20968\n",
      "Epoch: 20 | Iteration: 417 | Classification loss: 0.05935 | Regression loss: 0.17823 | Running loss: 0.21007\n",
      "Epoch: 20 | Iteration: 418 | Classification loss: 0.01713 | Regression loss: 0.09000 | Running loss: 0.21007\n",
      "Epoch: 20 | Iteration: 419 | Classification loss: 0.08256 | Regression loss: 0.33295 | Running loss: 0.21042\n",
      "Epoch: 20 | Iteration: 420 | Classification loss: 0.00728 | Regression loss: 0.07968 | Running loss: 0.21023\n",
      "Epoch: 20 | Iteration: 421 | Classification loss: 0.02216 | Regression loss: 0.14365 | Running loss: 0.21031\n",
      "Epoch: 20 | Iteration: 422 | Classification loss: 0.01405 | Regression loss: 0.13815 | Running loss: 0.20981\n",
      "Epoch: 20 | Iteration: 423 | Classification loss: 0.03017 | Regression loss: 0.16721 | Running loss: 0.20978\n",
      "Epoch: 20 | Iteration: 424 | Classification loss: 0.01508 | Regression loss: 0.06043 | Running loss: 0.20954\n",
      "Epoch: 20 | Iteration: 425 | Classification loss: 0.01592 | Regression loss: 0.14625 | Running loss: 0.20953\n",
      "Epoch: 20 | Iteration: 426 | Classification loss: 0.09723 | Regression loss: 0.21467 | Running loss: 0.20994\n",
      "Epoch: 20 | Iteration: 427 | Classification loss: 0.01081 | Regression loss: 0.05820 | Running loss: 0.20964\n",
      "Epoch: 20 | Iteration: 428 | Classification loss: 0.00952 | Regression loss: 0.13341 | Running loss: 0.20959\n",
      "Epoch: 20 | Iteration: 429 | Classification loss: 0.03108 | Regression loss: 0.10023 | Running loss: 0.20944\n",
      "Epoch: 20 | Iteration: 430 | Classification loss: 0.02789 | Regression loss: 0.13255 | Running loss: 0.20944\n",
      "Epoch: 20 | Iteration: 431 | Classification loss: 0.01214 | Regression loss: 0.08740 | Running loss: 0.20947\n",
      "Epoch: 20 | Iteration: 432 | Classification loss: 0.00818 | Regression loss: 0.08196 | Running loss: 0.20945\n",
      "Epoch: 20 | Iteration: 433 | Classification loss: 0.01416 | Regression loss: 0.13549 | Running loss: 0.20935\n",
      "Epoch: 20 | Iteration: 434 | Classification loss: 0.12358 | Regression loss: 0.07385 | Running loss: 0.20931\n",
      "Epoch: 20 | Iteration: 435 | Classification loss: 0.02816 | Regression loss: 0.14834 | Running loss: 0.20937\n",
      "Epoch: 20 | Iteration: 436 | Classification loss: 0.05126 | Regression loss: 0.23996 | Running loss: 0.20950\n",
      "Epoch: 20 | Iteration: 437 | Classification loss: 0.04449 | Regression loss: 0.20280 | Running loss: 0.20840\n",
      "Epoch: 20 | Iteration: 438 | Classification loss: 0.00927 | Regression loss: 0.08013 | Running loss: 0.20823\n",
      "Epoch: 20 | Iteration: 439 | Classification loss: 0.18010 | Regression loss: 0.40556 | Running loss: 0.20921\n",
      "Epoch: 20 | Iteration: 440 | Classification loss: 0.01122 | Regression loss: 0.06557 | Running loss: 0.20888\n",
      "Epoch: 20 | Iteration: 441 | Classification loss: 0.02539 | Regression loss: 0.11515 | Running loss: 0.20834\n",
      "Epoch: 20 | Iteration: 442 | Classification loss: 0.01511 | Regression loss: 0.10683 | Running loss: 0.20793\n",
      "Epoch: 20 | Iteration: 443 | Classification loss: 0.01517 | Regression loss: 0.11972 | Running loss: 0.20714\n",
      "Epoch: 20 | Iteration: 444 | Classification loss: 0.04687 | Regression loss: 0.14979 | Running loss: 0.20722\n",
      "Epoch: 20 | Iteration: 445 | Classification loss: 0.02269 | Regression loss: 0.18567 | Running loss: 0.20717\n",
      "Epoch: 20 | Iteration: 446 | Classification loss: 0.09299 | Regression loss: 0.21286 | Running loss: 0.20753\n",
      "Epoch: 20 | Iteration: 447 | Classification loss: 0.07482 | Regression loss: 0.28200 | Running loss: 0.20804\n",
      "Epoch: 20 | Iteration: 448 | Classification loss: 0.02121 | Regression loss: 0.13856 | Running loss: 0.20772\n",
      "Epoch: 20 | Iteration: 449 | Classification loss: 0.03425 | Regression loss: 0.18194 | Running loss: 0.20759\n",
      "Epoch: 20 | Iteration: 450 | Classification loss: 0.08280 | Regression loss: 0.13589 | Running loss: 0.20776\n",
      "Epoch: 20 | Iteration: 451 | Classification loss: 0.08735 | Regression loss: 0.23837 | Running loss: 0.20814\n",
      "Epoch: 20 | Iteration: 452 | Classification loss: 0.18602 | Regression loss: 0.05141 | Running loss: 0.20808\n",
      "Epoch: 20 | Iteration: 453 | Classification loss: 0.03605 | Regression loss: 0.20014 | Running loss: 0.20833\n",
      "Epoch: 20 | Iteration: 454 | Classification loss: 0.01974 | Regression loss: 0.09672 | Running loss: 0.20828\n",
      "Epoch: 20 | Iteration: 455 | Classification loss: 0.03212 | Regression loss: 0.16848 | Running loss: 0.20814\n",
      "Epoch: 20 | Iteration: 456 | Classification loss: 0.00387 | Regression loss: 0.06691 | Running loss: 0.20788\n",
      "Epoch: 20 | Iteration: 457 | Classification loss: 0.09050 | Regression loss: 0.38416 | Running loss: 0.20849\n",
      "Epoch: 20 | Iteration: 458 | Classification loss: 0.04663 | Regression loss: 0.19235 | Running loss: 0.20833\n",
      "Epoch: 20 | Iteration: 459 | Classification loss: 0.04706 | Regression loss: 0.13498 | Running loss: 0.20814\n",
      "Epoch: 20 | Iteration: 460 | Classification loss: 0.07630 | Regression loss: 0.22019 | Running loss: 0.20866\n",
      "Epoch: 20 | Iteration: 461 | Classification loss: 0.06847 | Regression loss: 0.29503 | Running loss: 0.20898\n",
      "Epoch: 20 | Iteration: 462 | Classification loss: 0.03221 | Regression loss: 0.19326 | Running loss: 0.20900\n",
      "Epoch: 20 | Iteration: 463 | Classification loss: 0.01760 | Regression loss: 0.17046 | Running loss: 0.20878\n",
      "Epoch: 20 | Iteration: 464 | Classification loss: 0.31337 | Regression loss: 0.16790 | Running loss: 0.20953\n",
      "Epoch: 20 | Iteration: 465 | Classification loss: 0.02034 | Regression loss: 0.13884 | Running loss: 0.20949\n",
      "Epoch: 20 | Iteration: 466 | Classification loss: 0.01860 | Regression loss: 0.09312 | Running loss: 0.20957\n",
      "Epoch: 20 | Iteration: 467 | Classification loss: 0.00688 | Regression loss: 0.07586 | Running loss: 0.20915\n",
      "Epoch: 20 | Iteration: 468 | Classification loss: 0.03826 | Regression loss: 0.28419 | Running loss: 0.20911\n",
      "Epoch: 20 | Iteration: 469 | Classification loss: 0.02069 | Regression loss: 0.18383 | Running loss: 0.20919\n",
      "Epoch: 20 | Iteration: 470 | Classification loss: 0.02148 | Regression loss: 0.19108 | Running loss: 0.20911\n",
      "Epoch: 20 | Iteration: 471 | Classification loss: 0.04781 | Regression loss: 0.14939 | Running loss: 0.20930\n",
      "Epoch: 20 | Iteration: 472 | Classification loss: 0.02122 | Regression loss: 0.17386 | Running loss: 0.20940\n",
      "Epoch: 20 | Iteration: 473 | Classification loss: 0.00574 | Regression loss: 0.09758 | Running loss: 0.20919\n",
      "Epoch: 20 | Iteration: 474 | Classification loss: 0.02268 | Regression loss: 0.13925 | Running loss: 0.20902\n",
      "Epoch: 20 | Iteration: 475 | Classification loss: 0.00545 | Regression loss: 0.06170 | Running loss: 0.20871\n",
      "Epoch: 20 | Iteration: 476 | Classification loss: 0.01953 | Regression loss: 0.17631 | Running loss: 0.20849\n",
      "Epoch: 20 | Iteration: 477 | Classification loss: 0.01494 | Regression loss: 0.12851 | Running loss: 0.20835\n",
      "Epoch: 20 | Iteration: 478 | Classification loss: 0.17819 | Regression loss: 0.13821 | Running loss: 0.20859\n",
      "Epoch: 20 | Iteration: 479 | Classification loss: 0.01309 | Regression loss: 0.12398 | Running loss: 0.20849\n",
      "Epoch: 20 | Iteration: 480 | Classification loss: 0.02607 | Regression loss: 0.14229 | Running loss: 0.20771\n",
      "Epoch: 20 | Iteration: 481 | Classification loss: 0.01830 | Regression loss: 0.15823 | Running loss: 0.20734\n",
      "Epoch: 20 | Iteration: 482 | Classification loss: 0.04280 | Regression loss: 0.28848 | Running loss: 0.20768\n",
      "Epoch: 20 | Iteration: 483 | Classification loss: 0.04926 | Regression loss: 0.25478 | Running loss: 0.20793\n",
      "Epoch: 20 | Iteration: 484 | Classification loss: 0.01926 | Regression loss: 0.10561 | Running loss: 0.20727\n",
      "Epoch: 20 | Iteration: 485 | Classification loss: 0.02259 | Regression loss: 0.23989 | Running loss: 0.20768\n",
      "Epoch: 20 | Iteration: 486 | Classification loss: 0.05464 | Regression loss: 0.12291 | Running loss: 0.20774\n",
      "Epoch: 20 | Iteration: 487 | Classification loss: 0.02310 | Regression loss: 0.15307 | Running loss: 0.20769\n",
      "Epoch: 20 | Iteration: 488 | Classification loss: 0.03733 | Regression loss: 0.06077 | Running loss: 0.20756\n",
      "Epoch: 20 | Iteration: 489 | Classification loss: 0.01062 | Regression loss: 0.12316 | Running loss: 0.20738\n",
      "Epoch: 20 | Iteration: 490 | Classification loss: 0.02269 | Regression loss: 0.12553 | Running loss: 0.20729\n",
      "Epoch: 20 | Iteration: 491 | Classification loss: 0.03303 | Regression loss: 0.08659 | Running loss: 0.20622\n",
      "Epoch: 20 | Iteration: 492 | Classification loss: 0.01484 | Regression loss: 0.15841 | Running loss: 0.20594\n",
      "Epoch: 20 | Iteration: 493 | Classification loss: 0.01705 | Regression loss: 0.13523 | Running loss: 0.20612\n",
      "Epoch: 20 | Iteration: 494 | Classification loss: 0.00985 | Regression loss: 0.12599 | Running loss: 0.20612\n",
      "Epoch: 20 | Iteration: 495 | Classification loss: 0.04399 | Regression loss: 0.17578 | Running loss: 0.20602\n",
      "Epoch: 20 | Iteration: 496 | Classification loss: 0.00689 | Regression loss: 0.11832 | Running loss: 0.20543\n",
      "Epoch: 20 | Iteration: 497 | Classification loss: 0.06118 | Regression loss: 0.21835 | Running loss: 0.20568\n",
      "Epoch: 20 | Iteration: 498 | Classification loss: 0.01834 | Regression loss: 0.09962 | Running loss: 0.20555\n",
      "Epoch: 20 | Iteration: 499 | Classification loss: 0.11294 | Regression loss: 0.34112 | Running loss: 0.20625\n",
      "Epoch: 20 | Iteration: 500 | Classification loss: 0.03882 | Regression loss: 0.21179 | Running loss: 0.20634\n",
      "Epoch: 20 | Iteration: 501 | Classification loss: 0.05955 | Regression loss: 0.22423 | Running loss: 0.20668\n",
      "Epoch: 20 | Iteration: 502 | Classification loss: 0.00450 | Regression loss: 0.04547 | Running loss: 0.20644\n",
      "Epoch: 20 | Iteration: 503 | Classification loss: 0.00807 | Regression loss: 0.07115 | Running loss: 0.20545\n",
      "Epoch: 20 | Iteration: 504 | Classification loss: 0.01366 | Regression loss: 0.14778 | Running loss: 0.20531\n",
      "Epoch: 20 | Iteration: 505 | Classification loss: 0.06326 | Regression loss: 0.21978 | Running loss: 0.20549\n",
      "Epoch: 20 | Iteration: 506 | Classification loss: 0.06327 | Regression loss: 0.28819 | Running loss: 0.20603\n",
      "Epoch: 20 | Iteration: 507 | Classification loss: 0.02160 | Regression loss: 0.11318 | Running loss: 0.20604\n",
      "Epoch: 20 | Iteration: 508 | Classification loss: 0.03159 | Regression loss: 0.23409 | Running loss: 0.20627\n",
      "Epoch: 20 | Iteration: 509 | Classification loss: 0.02584 | Regression loss: 0.22966 | Running loss: 0.20601\n",
      "Epoch: 20 | Iteration: 510 | Classification loss: 0.03792 | Regression loss: 0.24464 | Running loss: 0.20632\n",
      "Epoch: 20 | Iteration: 511 | Classification loss: 0.02467 | Regression loss: 0.12504 | Running loss: 0.20628\n",
      "Epoch: 20 | Iteration: 512 | Classification loss: 0.10886 | Regression loss: 0.27184 | Running loss: 0.20653\n",
      "Epoch: 20 | Iteration: 513 | Classification loss: 0.00598 | Regression loss: 0.07581 | Running loss: 0.20647\n",
      "Epoch: 20 | Iteration: 514 | Classification loss: 0.00956 | Regression loss: 0.06326 | Running loss: 0.20635\n",
      "Epoch: 20 | Iteration: 515 | Classification loss: 0.05568 | Regression loss: 0.30804 | Running loss: 0.20680\n",
      "Epoch: 20 | Iteration: 516 | Classification loss: 0.01755 | Regression loss: 0.12817 | Running loss: 0.20665\n",
      "Epoch: 20 | Iteration: 517 | Classification loss: 0.02124 | Regression loss: 0.14321 | Running loss: 0.20671\n",
      "Epoch: 20 | Iteration: 518 | Classification loss: 0.01005 | Regression loss: 0.12564 | Running loss: 0.20667\n",
      "Epoch: 20 | Iteration: 519 | Classification loss: 0.02315 | Regression loss: 0.07161 | Running loss: 0.20647\n",
      "Epoch: 20 | Iteration: 520 | Classification loss: 0.01571 | Regression loss: 0.08146 | Running loss: 0.20603\n",
      "Epoch: 20 | Iteration: 521 | Classification loss: 0.01137 | Regression loss: 0.14827 | Running loss: 0.20596\n",
      "Epoch: 20 | Iteration: 522 | Classification loss: 0.00797 | Regression loss: 0.13898 | Running loss: 0.20581\n",
      "Epoch: 20 | Iteration: 523 | Classification loss: 0.00677 | Regression loss: 0.07466 | Running loss: 0.20538\n",
      "Epoch: 20 | Iteration: 524 | Classification loss: 0.30021 | Regression loss: 0.45089 | Running loss: 0.20596\n",
      "Epoch: 20 | Iteration: 525 | Classification loss: 0.02142 | Regression loss: 0.19025 | Running loss: 0.20616\n",
      "Epoch: 20 | Iteration: 526 | Classification loss: 0.01800 | Regression loss: 0.17458 | Running loss: 0.20606\n",
      "Epoch: 20 | Iteration: 527 | Classification loss: 0.01392 | Regression loss: 0.09983 | Running loss: 0.20595\n",
      "Epoch: 20 | Iteration: 528 | Classification loss: 0.01466 | Regression loss: 0.18952 | Running loss: 0.20579\n",
      "Epoch: 20 | Iteration: 529 | Classification loss: 0.02146 | Regression loss: 0.27231 | Running loss: 0.20600\n",
      "Epoch: 20 | Iteration: 530 | Classification loss: 0.01216 | Regression loss: 0.09495 | Running loss: 0.20589\n",
      "Epoch: 20 | Iteration: 531 | Classification loss: 0.13714 | Regression loss: 0.26991 | Running loss: 0.20599\n",
      "Epoch: 20 | Iteration: 532 | Classification loss: 0.02589 | Regression loss: 0.12173 | Running loss: 0.20582\n",
      "Epoch: 20 | Iteration: 533 | Classification loss: 0.01876 | Regression loss: 0.19618 | Running loss: 0.20593\n",
      "Epoch: 20 | Iteration: 534 | Classification loss: 0.00437 | Regression loss: 0.04327 | Running loss: 0.20540\n",
      "Epoch: 20 | Iteration: 535 | Classification loss: 0.34104 | Regression loss: 0.22144 | Running loss: 0.20586\n",
      "Epoch: 20 | Iteration: 536 | Classification loss: 0.03925 | Regression loss: 0.20422 | Running loss: 0.20604\n",
      "Epoch: 20 | Iteration: 537 | Classification loss: 0.00874 | Regression loss: 0.14226 | Running loss: 0.20576\n",
      "Epoch: 20 | Iteration: 538 | Classification loss: 0.01093 | Regression loss: 0.08786 | Running loss: 0.20553\n",
      "Epoch: 20 | Iteration: 539 | Classification loss: 0.01842 | Regression loss: 0.11412 | Running loss: 0.20541\n",
      "Epoch: 20 | Iteration: 540 | Classification loss: 0.02480 | Regression loss: 0.20396 | Running loss: 0.20569\n",
      "Epoch: 20 | Iteration: 541 | Classification loss: 0.03894 | Regression loss: 0.27620 | Running loss: 0.20614\n",
      "Epoch: 20 | Iteration: 542 | Classification loss: 0.02233 | Regression loss: 0.18614 | Running loss: 0.20620\n",
      "Epoch: 20 | Iteration: 543 | Classification loss: 0.02943 | Regression loss: 0.17441 | Running loss: 0.20630\n",
      "Epoch: 20 | Iteration: 544 | Classification loss: 0.01544 | Regression loss: 0.09946 | Running loss: 0.20617\n",
      "Epoch: 20 | Iteration: 545 | Classification loss: 0.02316 | Regression loss: 0.09887 | Running loss: 0.20595\n",
      "Epoch: 20 | Iteration: 546 | Classification loss: 0.02051 | Regression loss: 0.08713 | Running loss: 0.20564\n",
      "Epoch: 20 | Iteration: 547 | Classification loss: 0.04770 | Regression loss: 0.21599 | Running loss: 0.20572\n",
      "Epoch: 20 | Iteration: 548 | Classification loss: 0.01555 | Regression loss: 0.24306 | Running loss: 0.20610\n",
      "Epoch: 20 | Iteration: 549 | Classification loss: 0.03935 | Regression loss: 0.12431 | Running loss: 0.20600\n",
      "Epoch: 20 | Iteration: 550 | Classification loss: 0.02613 | Regression loss: 0.21664 | Running loss: 0.20598\n",
      "Epoch: 20 | Iteration: 551 | Classification loss: 0.04535 | Regression loss: 0.07967 | Running loss: 0.20598\n",
      "Epoch: 20 | Iteration: 552 | Classification loss: 0.02290 | Regression loss: 0.16043 | Running loss: 0.20600\n",
      "Epoch: 20 | Iteration: 553 | Classification loss: 0.01935 | Regression loss: 0.12931 | Running loss: 0.20574\n",
      "Epoch: 20 | Iteration: 554 | Classification loss: 0.03505 | Regression loss: 0.12529 | Running loss: 0.20550\n",
      "Epoch: 20 | Iteration: 555 | Classification loss: 0.01710 | Regression loss: 0.10412 | Running loss: 0.20529\n",
      "Epoch: 20 | Iteration: 556 | Classification loss: 0.12755 | Regression loss: 0.22907 | Running loss: 0.20555\n",
      "Epoch: 20 | Iteration: 557 | Classification loss: 0.01803 | Regression loss: 0.14941 | Running loss: 0.20528\n",
      "Epoch: 20 | Iteration: 558 | Classification loss: 0.06044 | Regression loss: 0.12856 | Running loss: 0.20550\n",
      "Epoch: 20 | Iteration: 559 | Classification loss: 0.01331 | Regression loss: 0.10872 | Running loss: 0.20552\n",
      "Epoch: 20 | Iteration: 560 | Classification loss: 0.11866 | Regression loss: 0.38085 | Running loss: 0.20585\n",
      "Epoch: 20 | Iteration: 561 | Classification loss: 0.01052 | Regression loss: 0.12876 | Running loss: 0.20591\n",
      "Epoch: 20 | Iteration: 562 | Classification loss: 0.01910 | Regression loss: 0.18965 | Running loss: 0.20503\n",
      "Epoch: 20 | Iteration: 563 | Classification loss: 0.01452 | Regression loss: 0.11381 | Running loss: 0.20511\n",
      "Epoch: 20 | Iteration: 564 | Classification loss: 0.02775 | Regression loss: 0.16919 | Running loss: 0.20528\n",
      "Epoch: 20 | Iteration: 565 | Classification loss: 0.03239 | Regression loss: 0.14877 | Running loss: 0.20483\n",
      "Epoch: 20 | Iteration: 566 | Classification loss: 0.02063 | Regression loss: 0.12310 | Running loss: 0.20464\n",
      "Epoch: 20 | Iteration: 567 | Classification loss: 0.02390 | Regression loss: 0.23673 | Running loss: 0.20495\n",
      "Epoch: 20 | Iteration: 568 | Classification loss: 0.04072 | Regression loss: 0.25159 | Running loss: 0.20525\n",
      "Epoch: 20 | Iteration: 569 | Classification loss: 0.01306 | Regression loss: 0.18117 | Running loss: 0.20535\n",
      "Epoch: 20 | Iteration: 570 | Classification loss: 0.03108 | Regression loss: 0.15097 | Running loss: 0.20516\n",
      "Epoch: 20 | Iteration: 571 | Classification loss: 0.15646 | Regression loss: 0.34520 | Running loss: 0.20604\n",
      "Epoch: 20 | Iteration: 572 | Classification loss: 0.03714 | Regression loss: 0.10195 | Running loss: 0.20605\n",
      "Epoch: 20 | Iteration: 573 | Classification loss: 0.00520 | Regression loss: 0.04618 | Running loss: 0.20593\n",
      "Epoch: 20 | Iteration: 574 | Classification loss: 0.01247 | Regression loss: 0.06819 | Running loss: 0.20553\n",
      "Epoch: 20 | Iteration: 575 | Classification loss: 0.00848 | Regression loss: 0.08529 | Running loss: 0.20511\n",
      "Epoch: 20 | Iteration: 576 | Classification loss: 0.01266 | Regression loss: 0.17427 | Running loss: 0.20518\n",
      "Epoch: 20 | Iteration: 577 | Classification loss: 0.07656 | Regression loss: 0.12288 | Running loss: 0.20544\n",
      "Epoch: 20 | Iteration: 578 | Classification loss: 0.09595 | Regression loss: 0.20953 | Running loss: 0.20530\n",
      "Epoch: 20 | Iteration: 579 | Classification loss: 0.01810 | Regression loss: 0.12717 | Running loss: 0.20520\n",
      "Epoch: 20 | Iteration: 580 | Classification loss: 0.04088 | Regression loss: 0.11146 | Running loss: 0.20495\n",
      "Epoch: 20 | Iteration: 581 | Classification loss: 0.03303 | Regression loss: 0.22020 | Running loss: 0.20519\n",
      "Epoch: 20 | Iteration: 582 | Classification loss: 0.06347 | Regression loss: 0.18031 | Running loss: 0.20508\n",
      "Epoch: 20 | Iteration: 583 | Classification loss: 0.02506 | Regression loss: 0.21762 | Running loss: 0.20460\n",
      "Epoch: 20 | Iteration: 584 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.20371\n",
      "Epoch: 20 | Iteration: 585 | Classification loss: 0.00548 | Regression loss: 0.06928 | Running loss: 0.20265\n",
      "Epoch: 20 | Iteration: 586 | Classification loss: 0.05981 | Regression loss: 0.17380 | Running loss: 0.20291\n",
      "Epoch: 20 | Iteration: 587 | Classification loss: 0.02605 | Regression loss: 0.11024 | Running loss: 0.20264\n",
      "Epoch: 20 | Iteration: 588 | Classification loss: 0.02526 | Regression loss: 0.16104 | Running loss: 0.20273\n",
      "Epoch: 20 | Iteration: 589 | Classification loss: 0.01157 | Regression loss: 0.10331 | Running loss: 0.20266\n",
      "Epoch: 20 | Iteration: 590 | Classification loss: 0.05185 | Regression loss: 0.25908 | Running loss: 0.20306\n",
      "Epoch: 20 | Iteration: 591 | Classification loss: 0.00930 | Regression loss: 0.06791 | Running loss: 0.20303\n",
      "Epoch: 20 | Iteration: 592 | Classification loss: 0.09468 | Regression loss: 0.19992 | Running loss: 0.20313\n",
      "Epoch: 20 | Iteration: 593 | Classification loss: 0.04225 | Regression loss: 0.14150 | Running loss: 0.20299\n",
      "Epoch: 20 | Iteration: 594 | Classification loss: 0.02434 | Regression loss: 0.13391 | Running loss: 0.20289\n",
      "Epoch: 20 | Iteration: 595 | Classification loss: 0.00392 | Regression loss: 0.15565 | Running loss: 0.20217\n",
      "Epoch: 20 | Iteration: 596 | Classification loss: 0.01695 | Regression loss: 0.16174 | Running loss: 0.20228\n",
      "Epoch: 20 | Iteration: 597 | Classification loss: 0.02200 | Regression loss: 0.25596 | Running loss: 0.20228\n",
      "Epoch: 20 | Iteration: 598 | Classification loss: 0.04545 | Regression loss: 0.14718 | Running loss: 0.20166\n",
      "Epoch: 20 | Iteration: 599 | Classification loss: 0.04997 | Regression loss: 0.22823 | Running loss: 0.20184\n",
      "Epoch: 20 | Iteration: 600 | Classification loss: 0.01586 | Regression loss: 0.03888 | Running loss: 0.20160\n",
      "Epoch: 20 | Iteration: 601 | Classification loss: 0.02769 | Regression loss: 0.11040 | Running loss: 0.20155\n",
      "Epoch: 20 | Iteration: 602 | Classification loss: 0.03677 | Regression loss: 0.19593 | Running loss: 0.20140\n",
      "Epoch: 20 | Iteration: 603 | Classification loss: 0.02373 | Regression loss: 0.12311 | Running loss: 0.20125\n",
      "Epoch: 20 | Iteration: 604 | Classification loss: 0.01482 | Regression loss: 0.09492 | Running loss: 0.20116\n",
      "Epoch: 20 | Iteration: 605 | Classification loss: 0.03023 | Regression loss: 0.18046 | Running loss: 0.20112\n",
      "Epoch: 20 | Iteration: 606 | Classification loss: 0.01759 | Regression loss: 0.14511 | Running loss: 0.20107\n",
      "Epoch: 20 | Iteration: 607 | Classification loss: 0.01062 | Regression loss: 0.08772 | Running loss: 0.20077\n",
      "Epoch: 20 | Iteration: 608 | Classification loss: 0.02245 | Regression loss: 0.17007 | Running loss: 0.20098\n",
      "Epoch: 20 | Iteration: 609 | Classification loss: 0.07652 | Regression loss: 0.22925 | Running loss: 0.20128\n",
      "Epoch: 20 | Iteration: 610 | Classification loss: 0.00947 | Regression loss: 0.15460 | Running loss: 0.20107\n",
      "Epoch: 20 | Iteration: 611 | Classification loss: 0.01623 | Regression loss: 0.12571 | Running loss: 0.20121\n",
      "Epoch: 20 | Iteration: 612 | Classification loss: 0.01859 | Regression loss: 0.13840 | Running loss: 0.20124\n",
      "Epoch: 20 | Iteration: 613 | Classification loss: 0.03398 | Regression loss: 0.23702 | Running loss: 0.20127\n",
      "Epoch: 20 | Iteration: 614 | Classification loss: 0.02985 | Regression loss: 0.09806 | Running loss: 0.20101\n",
      "Epoch: 20 | Iteration: 615 | Classification loss: 0.03044 | Regression loss: 0.12647 | Running loss: 0.20061\n",
      "Epoch: 20 | Iteration: 616 | Classification loss: 0.02018 | Regression loss: 0.18557 | Running loss: 0.20086\n",
      "Epoch: 20 | Iteration: 617 | Classification loss: 0.04184 | Regression loss: 0.23545 | Running loss: 0.20069\n",
      "Epoch: 20 | Iteration: 618 | Classification loss: 0.03739 | Regression loss: 0.17861 | Running loss: 0.20080\n",
      "Epoch: 20 | Iteration: 619 | Classification loss: 0.02146 | Regression loss: 0.14555 | Running loss: 0.20073\n",
      "Epoch: 20 | Iteration: 620 | Classification loss: 0.04572 | Regression loss: 0.16276 | Running loss: 0.20079\n",
      "Epoch: 20 | Iteration: 621 | Classification loss: 0.06828 | Regression loss: 0.17832 | Running loss: 0.20070\n",
      "Epoch: 20 | Iteration: 622 | Classification loss: 0.01598 | Regression loss: 0.05473 | Running loss: 0.20033\n",
      "Epoch: 20 | Iteration: 623 | Classification loss: 0.04022 | Regression loss: 0.19055 | Running loss: 0.20022\n",
      "Epoch: 20 | Iteration: 624 | Classification loss: 0.04631 | Regression loss: 0.08097 | Running loss: 0.20003\n",
      "Epoch: 20 | Iteration: 625 | Classification loss: 0.05414 | Regression loss: 0.27575 | Running loss: 0.20005\n",
      "Epoch: 20 | Iteration: 626 | Classification loss: 0.01043 | Regression loss: 0.10582 | Running loss: 0.19940\n",
      "Epoch: 20 | Iteration: 627 | Classification loss: 0.04399 | Regression loss: 0.12461 | Running loss: 0.19937\n",
      "Epoch: 20 | Iteration: 628 | Classification loss: 0.01828 | Regression loss: 0.09163 | Running loss: 0.19930\n",
      "Epoch: 20 | Iteration: 629 | Classification loss: 0.02472 | Regression loss: 0.15357 | Running loss: 0.19943\n",
      "Epoch: 20 | Iteration: 630 | Classification loss: 0.00996 | Regression loss: 0.09118 | Running loss: 0.19937\n",
      "Epoch: 20 | Iteration: 631 | Classification loss: 0.03010 | Regression loss: 0.22212 | Running loss: 0.19880\n",
      "Epoch: 20 | Iteration: 632 | Classification loss: 0.06057 | Regression loss: 0.17401 | Running loss: 0.19841\n",
      "Epoch: 20 | Iteration: 633 | Classification loss: 0.01354 | Regression loss: 0.12094 | Running loss: 0.19836\n",
      "Epoch: 20 | Iteration: 634 | Classification loss: 0.00859 | Regression loss: 0.11246 | Running loss: 0.19809\n",
      "Epoch: 20 | Iteration: 635 | Classification loss: 0.00461 | Regression loss: 0.12703 | Running loss: 0.19729\n",
      "Epoch: 20 | Iteration: 636 | Classification loss: 0.08384 | Regression loss: 0.28414 | Running loss: 0.19750\n",
      "Epoch: 20 | Iteration: 637 | Classification loss: 0.07014 | Regression loss: 0.24963 | Running loss: 0.19775\n",
      "Epoch: 20 | Iteration: 638 | Classification loss: 0.01710 | Regression loss: 0.12774 | Running loss: 0.19772\n",
      "Epoch: 20 | Iteration: 639 | Classification loss: 0.02743 | Regression loss: 0.17525 | Running loss: 0.19767\n",
      "Epoch: 20 | Iteration: 640 | Classification loss: 0.03264 | Regression loss: 0.20806 | Running loss: 0.19776\n",
      "Epoch: 20 | Iteration: 641 | Classification loss: 0.01429 | Regression loss: 0.10172 | Running loss: 0.19770\n",
      "Epoch: 20 | Iteration: 642 | Classification loss: 0.01310 | Regression loss: 0.15904 | Running loss: 0.19773\n",
      "Epoch: 20 | Iteration: 643 | Classification loss: 0.00928 | Regression loss: 0.10130 | Running loss: 0.19750\n",
      "Epoch: 20 | Iteration: 644 | Classification loss: 0.07627 | Regression loss: 0.24375 | Running loss: 0.19742\n",
      "Epoch: 20 | Iteration: 645 | Classification loss: 0.00660 | Regression loss: 0.14893 | Running loss: 0.19727\n",
      "Epoch: 20 | Iteration: 646 | Classification loss: 0.03050 | Regression loss: 0.21769 | Running loss: 0.19751\n",
      "Epoch: 20 | Iteration: 647 | Classification loss: 0.02256 | Regression loss: 0.15426 | Running loss: 0.19763\n",
      "Epoch: 20 | Iteration: 648 | Classification loss: 0.08738 | Regression loss: 0.33164 | Running loss: 0.19846\n",
      "Epoch: 20 | Iteration: 649 | Classification loss: 0.03122 | Regression loss: 0.19615 | Running loss: 0.19871\n",
      "Epoch: 20 | Iteration: 650 | Classification loss: 0.03798 | Regression loss: 0.22385 | Running loss: 0.19846\n",
      "Epoch: 20 | Iteration: 651 | Classification loss: 0.01378 | Regression loss: 0.17484 | Running loss: 0.19819\n",
      "Epoch: 20 | Iteration: 652 | Classification loss: 0.03930 | Regression loss: 0.23505 | Running loss: 0.19820\n",
      "Epoch: 20 | Iteration: 653 | Classification loss: 0.02805 | Regression loss: 0.13149 | Running loss: 0.19821\n",
      "Epoch: 20 | Iteration: 654 | Classification loss: 0.06112 | Regression loss: 0.06927 | Running loss: 0.19792\n",
      "Epoch: 20 | Iteration: 655 | Classification loss: 0.21112 | Regression loss: 0.31093 | Running loss: 0.19773\n",
      "Epoch: 20 | Iteration: 656 | Classification loss: 0.02489 | Regression loss: 0.19438 | Running loss: 0.19770\n",
      "Epoch: 20 | Iteration: 657 | Classification loss: 0.01150 | Regression loss: 0.14644 | Running loss: 0.19764\n",
      "Epoch: 20 | Iteration: 658 | Classification loss: 0.10697 | Regression loss: 0.15720 | Running loss: 0.19761\n",
      "Epoch: 20 | Iteration: 659 | Classification loss: 0.01330 | Regression loss: 0.13848 | Running loss: 0.19744\n",
      "Epoch: 20 | Iteration: 660 | Classification loss: 0.01943 | Regression loss: 0.19824 | Running loss: 0.19753\n",
      "Epoch: 20 | Iteration: 661 | Classification loss: 0.04637 | Regression loss: 0.21591 | Running loss: 0.19778\n",
      "Epoch: 20 | Iteration: 662 | Classification loss: 0.01858 | Regression loss: 0.16374 | Running loss: 0.19790\n",
      "Epoch: 20 | Iteration: 663 | Classification loss: 0.01835 | Regression loss: 0.08819 | Running loss: 0.19780\n",
      "Epoch: 20 | Iteration: 664 | Classification loss: 0.10057 | Regression loss: 0.33523 | Running loss: 0.19843\n",
      "Epoch: 20 | Iteration: 665 | Classification loss: 0.14383 | Regression loss: 0.36810 | Running loss: 0.19901\n",
      "Epoch: 20 | Iteration: 666 | Classification loss: 0.01833 | Regression loss: 0.09568 | Running loss: 0.19903\n",
      "Epoch: 20 | Iteration: 667 | Classification loss: 0.07593 | Regression loss: 0.31634 | Running loss: 0.19905\n",
      "Epoch: 20 | Iteration: 668 | Classification loss: 0.04491 | Regression loss: 0.12899 | Running loss: 0.19898\n",
      "Epoch: 20 | Iteration: 669 | Classification loss: 0.17155 | Regression loss: 0.19587 | Running loss: 0.19937\n",
      "Epoch: 20 | Iteration: 670 | Classification loss: 0.02540 | Regression loss: 0.09354 | Running loss: 0.19934\n",
      "Epoch: 20 | Iteration: 671 | Classification loss: 0.01742 | Regression loss: 0.07796 | Running loss: 0.19925\n",
      "Epoch: 20 | Iteration: 672 | Classification loss: 0.01296 | Regression loss: 0.13154 | Running loss: 0.19938\n",
      "Epoch: 20 | Iteration: 673 | Classification loss: 0.02147 | Regression loss: 0.07564 | Running loss: 0.19943\n",
      "Epoch: 20 | Iteration: 674 | Classification loss: 0.05695 | Regression loss: 0.24407 | Running loss: 0.19953\n",
      "Epoch: 20 | Iteration: 675 | Classification loss: 0.08340 | Regression loss: 0.30376 | Running loss: 0.20008\n",
      "Epoch: 20 | Iteration: 676 | Classification loss: 0.01061 | Regression loss: 0.10126 | Running loss: 0.20009\n",
      "Epoch: 20 | Iteration: 677 | Classification loss: 0.04817 | Regression loss: 0.17168 | Running loss: 0.20000\n",
      "Epoch: 20 | Iteration: 678 | Classification loss: 0.03529 | Regression loss: 0.12211 | Running loss: 0.19982\n",
      "Epoch: 20 | Iteration: 679 | Classification loss: 0.02064 | Regression loss: 0.14447 | Running loss: 0.19988\n",
      "Epoch: 20 | Iteration: 680 | Classification loss: 0.20313 | Regression loss: 0.34767 | Running loss: 0.20075\n",
      "Epoch: 20 | Iteration: 681 | Classification loss: 0.03719 | Regression loss: 0.22694 | Running loss: 0.20083\n",
      "Epoch: 20 | Iteration: 682 | Classification loss: 0.04161 | Regression loss: 0.18026 | Running loss: 0.20090\n",
      "Epoch: 20 | Iteration: 683 | Classification loss: 0.03046 | Regression loss: 0.24198 | Running loss: 0.20106\n",
      "Epoch: 20 | Iteration: 684 | Classification loss: 0.01426 | Regression loss: 0.10701 | Running loss: 0.20070\n",
      "Epoch: 20 | Iteration: 685 | Classification loss: 0.01359 | Regression loss: 0.05955 | Running loss: 0.20059\n",
      "Epoch: 20 | Iteration: 686 | Classification loss: 0.05975 | Regression loss: 0.11238 | Running loss: 0.20032\n",
      "Epoch: 20 | Iteration: 687 | Classification loss: 0.01507 | Regression loss: 0.13266 | Running loss: 0.19996\n",
      "Epoch: 20 | Iteration: 688 | Classification loss: 0.03377 | Regression loss: 0.15740 | Running loss: 0.20008\n",
      "Epoch: 20 | Iteration: 689 | Classification loss: 0.03361 | Regression loss: 0.12321 | Running loss: 0.19982\n",
      "Epoch: 20 | Iteration: 690 | Classification loss: 0.04902 | Regression loss: 0.19717 | Running loss: 0.19998\n",
      "Epoch: 20 | Iteration: 691 | Classification loss: 0.02116 | Regression loss: 0.17869 | Running loss: 0.20001\n",
      "Epoch: 20 | Iteration: 692 | Classification loss: 0.05425 | Regression loss: 0.22107 | Running loss: 0.20020\n",
      "Epoch: 20 | Iteration: 693 | Classification loss: 0.01963 | Regression loss: 0.11861 | Running loss: 0.20010\n",
      "Epoch: 20 | Iteration: 694 | Classification loss: 0.01792 | Regression loss: 0.09312 | Running loss: 0.20007\n",
      "Epoch: 20 | Iteration: 695 | Classification loss: 0.05913 | Regression loss: 0.18863 | Running loss: 0.20041\n",
      "Epoch: 20 | Iteration: 696 | Classification loss: 0.01342 | Regression loss: 0.14775 | Running loss: 0.20042\n",
      "Epoch: 20 | Iteration: 697 | Classification loss: 0.00561 | Regression loss: 0.10124 | Running loss: 0.20034\n",
      "Epoch: 20 | Iteration: 698 | Classification loss: 0.01794 | Regression loss: 0.22002 | Running loss: 0.20022\n",
      "Epoch: 20 | Iteration: 699 | Classification loss: 0.00726 | Regression loss: 0.11661 | Running loss: 0.20010\n",
      "Epoch: 20 | Iteration: 700 | Classification loss: 0.01411 | Regression loss: 0.13547 | Running loss: 0.20028\n",
      "Epoch: 20 | Iteration: 701 | Classification loss: 0.01240 | Regression loss: 0.06758 | Running loss: 0.20018\n",
      "Epoch: 20 | Iteration: 702 | Classification loss: 0.04429 | Regression loss: 0.17063 | Running loss: 0.20038\n",
      "Epoch: 20 | Iteration: 703 | Classification loss: 0.03708 | Regression loss: 0.22074 | Running loss: 0.20058\n",
      "Epoch: 20 | Iteration: 704 | Classification loss: 0.01451 | Regression loss: 0.10118 | Running loss: 0.20053\n",
      "Epoch: 20 | Iteration: 705 | Classification loss: 0.03318 | Regression loss: 0.21655 | Running loss: 0.20066\n",
      "Epoch: 20 | Iteration: 706 | Classification loss: 0.02129 | Regression loss: 0.17269 | Running loss: 0.20087\n",
      "Epoch: 20 | Iteration: 707 | Classification loss: 0.01040 | Regression loss: 0.15431 | Running loss: 0.20076\n",
      "Epoch: 20 | Iteration: 708 | Classification loss: 0.04180 | Regression loss: 0.22763 | Running loss: 0.20067\n",
      "Epoch: 20 | Iteration: 709 | Classification loss: 0.01968 | Regression loss: 0.17165 | Running loss: 0.20076\n",
      "Epoch: 20 | Iteration: 710 | Classification loss: 0.01915 | Regression loss: 0.17708 | Running loss: 0.20088\n",
      "Epoch: 20 | Iteration: 711 | Classification loss: 0.05447 | Regression loss: 0.14005 | Running loss: 0.20106\n",
      "Epoch: 20 | Iteration: 712 | Classification loss: 0.05536 | Regression loss: 0.21346 | Running loss: 0.20138\n",
      "Epoch: 20 | Iteration: 713 | Classification loss: 0.03158 | Regression loss: 0.08237 | Running loss: 0.20119\n",
      "Epoch: 20 | Iteration: 714 | Classification loss: 0.01072 | Regression loss: 0.12512 | Running loss: 0.20110\n",
      "Epoch: 20 | Iteration: 715 | Classification loss: 0.09929 | Regression loss: 0.24600 | Running loss: 0.20137\n",
      "Epoch: 20 | Iteration: 716 | Classification loss: 0.01654 | Regression loss: 0.15453 | Running loss: 0.20109\n",
      "Epoch: 20 | Iteration: 717 | Classification loss: 0.09067 | Regression loss: 0.32792 | Running loss: 0.20156\n",
      "Epoch: 20 | Iteration: 718 | Classification loss: 0.03813 | Regression loss: 0.21007 | Running loss: 0.20163\n",
      "Epoch: 20 | Iteration: 719 | Classification loss: 0.02715 | Regression loss: 0.09209 | Running loss: 0.20165\n",
      "Epoch: 20 | Iteration: 720 | Classification loss: 0.03470 | Regression loss: 0.19003 | Running loss: 0.20174\n",
      "Epoch: 20 | Iteration: 721 | Classification loss: 0.05162 | Regression loss: 0.21309 | Running loss: 0.20196\n",
      "Epoch: 20 | Iteration: 722 | Classification loss: 0.03965 | Regression loss: 0.07783 | Running loss: 0.20186\n",
      "Epoch: 20 | Iteration: 723 | Classification loss: 0.05638 | Regression loss: 0.18940 | Running loss: 0.20193\n",
      "Epoch: 20 | Iteration: 724 | Classification loss: 0.01548 | Regression loss: 0.11657 | Running loss: 0.20183\n",
      "Epoch: 20 | Iteration: 725 | Classification loss: 0.04883 | Regression loss: 0.16051 | Running loss: 0.20187\n",
      "Epoch: 20 | Iteration: 726 | Classification loss: 0.07270 | Regression loss: 0.08058 | Running loss: 0.20172\n",
      "Epoch: 20 | Iteration: 727 | Classification loss: 0.03824 | Regression loss: 0.08246 | Running loss: 0.20160\n",
      "Epoch: 20 | Iteration: 728 | Classification loss: 0.01152 | Regression loss: 0.11345 | Running loss: 0.20150\n",
      "Epoch: 20 | Iteration: 729 | Classification loss: 0.04292 | Regression loss: 0.16484 | Running loss: 0.20163\n",
      "Epoch: 20 | Iteration: 730 | Classification loss: 0.01178 | Regression loss: 0.06455 | Running loss: 0.20172\n",
      "Epoch: 20 | Iteration: 731 | Classification loss: 0.00976 | Regression loss: 0.11409 | Running loss: 0.20162\n",
      "Epoch: 20 | Iteration: 732 | Classification loss: 0.06372 | Regression loss: 0.11672 | Running loss: 0.20166\n",
      "Epoch: 20 | Iteration: 733 | Classification loss: 0.00711 | Regression loss: 0.09974 | Running loss: 0.20150\n",
      "Epoch: 20 | Iteration: 734 | Classification loss: 0.02079 | Regression loss: 0.10328 | Running loss: 0.20107\n",
      "Epoch: 20 | Iteration: 735 | Classification loss: 0.03201 | Regression loss: 0.16260 | Running loss: 0.20120\n",
      "Epoch: 20 | Iteration: 736 | Classification loss: 0.00449 | Regression loss: 0.10374 | Running loss: 0.20069\n",
      "Epoch: 20 | Iteration: 737 | Classification loss: 0.12594 | Regression loss: 0.20811 | Running loss: 0.20084\n",
      "Epoch: 20 | Iteration: 738 | Classification loss: 0.01400 | Regression loss: 0.15070 | Running loss: 0.19894\n",
      "Epoch: 20 | Iteration: 739 | Classification loss: 0.19967 | Regression loss: 0.19435 | Running loss: 0.19946\n",
      "Epoch: 20 | Iteration: 740 | Classification loss: 0.01031 | Regression loss: 0.07984 | Running loss: 0.19882\n",
      "Epoch: 20 | Iteration: 741 | Classification loss: 0.02805 | Regression loss: 0.09326 | Running loss: 0.19855\n",
      "Epoch: 20 | Iteration: 742 | Classification loss: 0.01235 | Regression loss: 0.14011 | Running loss: 0.19849\n",
      "Epoch: 20 | Iteration: 743 | Classification loss: 0.02353 | Regression loss: 0.11715 | Running loss: 0.19836\n",
      "Epoch: 20 | Iteration: 744 | Classification loss: 0.01154 | Regression loss: 0.14048 | Running loss: 0.19820\n",
      "Epoch: 20 | Iteration: 745 | Classification loss: 0.03254 | Regression loss: 0.24132 | Running loss: 0.19865\n",
      "Epoch: 20 | Iteration: 746 | Classification loss: 0.05404 | Regression loss: 0.13444 | Running loss: 0.19869\n",
      "Epoch: 20 | Iteration: 747 | Classification loss: 0.00644 | Regression loss: 0.12920 | Running loss: 0.19873\n",
      "Epoch: 20 | Iteration: 748 | Classification loss: 0.14482 | Regression loss: 0.37835 | Running loss: 0.19956\n",
      "Epoch: 20 | Iteration: 749 | Classification loss: 0.03309 | Regression loss: 0.18775 | Running loss: 0.19972\n",
      "Epoch: 20 | Iteration: 750 | Classification loss: 0.01426 | Regression loss: 0.14935 | Running loss: 0.19974\n",
      "Epoch: 20 | Iteration: 751 | Classification loss: 0.01210 | Regression loss: 0.15514 | Running loss: 0.19970\n",
      "Epoch: 20 | Iteration: 752 | Classification loss: 0.01685 | Regression loss: 0.19421 | Running loss: 0.19974\n",
      "Epoch: 20 | Iteration: 753 | Classification loss: 0.23592 | Regression loss: 0.31533 | Running loss: 0.20020\n",
      "Epoch: 20 | Iteration: 754 | Classification loss: 0.02877 | Regression loss: 0.12710 | Running loss: 0.20027\n",
      "Epoch: 20 | Iteration: 755 | Classification loss: 0.06560 | Regression loss: 0.18903 | Running loss: 0.20041\n",
      "Epoch: 20 | Iteration: 756 | Classification loss: 0.00680 | Regression loss: 0.09085 | Running loss: 0.20034\n",
      "Epoch: 20 | Iteration: 757 | Classification loss: 0.03517 | Regression loss: 0.10360 | Running loss: 0.20027\n",
      "Epoch: 20 | Iteration: 758 | Classification loss: 0.07243 | Regression loss: 0.26252 | Running loss: 0.20035\n",
      "Epoch: 20 | Iteration: 759 | Classification loss: 0.02252 | Regression loss: 0.19105 | Running loss: 0.20054\n",
      "Epoch: 20 | Iteration: 760 | Classification loss: 0.01179 | Regression loss: 0.13719 | Running loss: 0.20053\n",
      "Epoch: 20 | Iteration: 761 | Classification loss: 0.02225 | Regression loss: 0.13778 | Running loss: 0.19994\n",
      "Epoch: 20 | Iteration: 762 | Classification loss: 0.01827 | Regression loss: 0.06404 | Running loss: 0.19976\n",
      "Epoch: 20 | Iteration: 763 | Classification loss: 0.07554 | Regression loss: 0.06145 | Running loss: 0.19971\n",
      "Epoch: 20 | Iteration: 764 | Classification loss: 0.07191 | Regression loss: 0.11452 | Running loss: 0.19969\n",
      "Epoch: 20 | Iteration: 765 | Classification loss: 0.02877 | Regression loss: 0.11291 | Running loss: 0.19963\n",
      "Epoch: 20 | Iteration: 766 | Classification loss: 0.06203 | Regression loss: 0.18712 | Running loss: 0.19982\n",
      "Epoch: 20 | Iteration: 767 | Classification loss: 0.02888 | Regression loss: 0.15825 | Running loss: 0.19986\n",
      "Epoch: 20 | Iteration: 768 | Classification loss: 0.10709 | Regression loss: 0.24150 | Running loss: 0.20001\n",
      "Epoch: 20 | Iteration: 769 | Classification loss: 0.01984 | Regression loss: 0.15280 | Running loss: 0.19991\n",
      "Epoch: 20 | Iteration: 770 | Classification loss: 0.02259 | Regression loss: 0.11476 | Running loss: 0.19952\n",
      "Epoch: 20 | Iteration: 771 | Classification loss: 0.08245 | Regression loss: 0.34005 | Running loss: 0.20010\n",
      "Epoch: 20 | Iteration: 772 | Classification loss: 0.04920 | Regression loss: 0.17637 | Running loss: 0.20016\n",
      "Epoch: 20 | Iteration: 773 | Classification loss: 0.04777 | Regression loss: 0.24570 | Running loss: 0.20043\n",
      "Epoch: 20 | Iteration: 774 | Classification loss: 0.00955 | Regression loss: 0.10429 | Running loss: 0.20021\n",
      "Epoch: 20 | Iteration: 775 | Classification loss: 0.00896 | Regression loss: 0.05537 | Running loss: 0.20016\n",
      "Epoch: 20 | Iteration: 776 | Classification loss: 0.03322 | Regression loss: 0.11220 | Running loss: 0.19986\n",
      "Epoch: 20 | Iteration: 777 | Classification loss: 0.01001 | Regression loss: 0.09681 | Running loss: 0.19966\n",
      "Epoch: 20 | Iteration: 778 | Classification loss: 0.07276 | Regression loss: 0.21201 | Running loss: 0.19970\n",
      "Epoch: 20 | Iteration: 779 | Classification loss: 0.02786 | Regression loss: 0.19307 | Running loss: 0.20002\n",
      "Epoch: 20 | Iteration: 780 | Classification loss: 0.12142 | Regression loss: 0.20308 | Running loss: 0.20029\n",
      "Epoch: 20 | Iteration: 781 | Classification loss: 0.00938 | Regression loss: 0.13109 | Running loss: 0.20029\n",
      "Epoch: 20 | Iteration: 782 | Classification loss: 0.05400 | Regression loss: 0.27281 | Running loss: 0.20070\n",
      "Epoch: 20 | Iteration: 783 | Classification loss: 0.01007 | Regression loss: 0.09853 | Running loss: 0.20057\n",
      "Epoch: 20 | Iteration: 784 | Classification loss: 0.03092 | Regression loss: 0.21808 | Running loss: 0.20057\n",
      "Epoch: 20 | Iteration: 785 | Classification loss: 0.06090 | Regression loss: 0.22995 | Running loss: 0.20076\n",
      "Epoch: 20 | Iteration: 786 | Classification loss: 0.01624 | Regression loss: 0.13568 | Running loss: 0.20045\n",
      "Epoch: 20 | Iteration: 787 | Classification loss: 0.07311 | Regression loss: 0.16047 | Running loss: 0.20069\n",
      "Epoch: 20 | Iteration: 788 | Classification loss: 0.05282 | Regression loss: 0.32596 | Running loss: 0.20121\n",
      "Epoch: 20 | Iteration: 789 | Classification loss: 0.00986 | Regression loss: 0.10211 | Running loss: 0.20119\n",
      "Epoch: 20 | Iteration: 790 | Classification loss: 0.01038 | Regression loss: 0.14773 | Running loss: 0.20097\n",
      "Epoch: 20 | Iteration: 791 | Classification loss: 0.03352 | Regression loss: 0.44840 | Running loss: 0.20174\n",
      "Epoch: 20 | Iteration: 792 | Classification loss: 0.01809 | Regression loss: 0.18740 | Running loss: 0.20156\n",
      "Epoch: 20 | Iteration: 793 | Classification loss: 0.04558 | Regression loss: 0.22211 | Running loss: 0.20185\n",
      "Epoch: 20 | Iteration: 794 | Classification loss: 0.12003 | Regression loss: 0.13667 | Running loss: 0.20144\n",
      "Epoch: 20 | Iteration: 795 | Classification loss: 0.04398 | Regression loss: 0.25337 | Running loss: 0.20124\n",
      "Epoch: 20 | Iteration: 796 | Classification loss: 0.03288 | Regression loss: 0.25866 | Running loss: 0.20118\n",
      "Epoch: 20 | Iteration: 797 | Classification loss: 0.07128 | Regression loss: 0.09613 | Running loss: 0.20109\n",
      "Epoch: 20 | Iteration: 798 | Classification loss: 0.02804 | Regression loss: 0.19457 | Running loss: 0.20130\n",
      "Epoch: 20 | Iteration: 799 | Classification loss: 0.06003 | Regression loss: 0.17154 | Running loss: 0.20144\n",
      "Epoch: 20 | Iteration: 800 | Classification loss: 0.03155 | Regression loss: 0.14407 | Running loss: 0.20151\n",
      "Epoch: 20 | Iteration: 801 | Classification loss: 0.02936 | Regression loss: 0.09117 | Running loss: 0.20131\n",
      "Epoch: 20 | Iteration: 802 | Classification loss: 0.08340 | Regression loss: 0.26576 | Running loss: 0.20157\n",
      "Epoch: 20 | Iteration: 803 | Classification loss: 0.00655 | Regression loss: 0.11642 | Running loss: 0.20142\n",
      "Epoch: 20 | Iteration: 804 | Classification loss: 0.02591 | Regression loss: 0.05133 | Running loss: 0.20068\n",
      "Epoch: 20 | Iteration: 805 | Classification loss: 0.02256 | Regression loss: 0.10396 | Running loss: 0.20063\n",
      "Epoch: 20 | Iteration: 806 | Classification loss: 0.01319 | Regression loss: 0.09862 | Running loss: 0.19981\n",
      "Epoch: 20 | Iteration: 807 | Classification loss: 0.05186 | Regression loss: 0.26245 | Running loss: 0.20006\n",
      "Epoch: 20 | Iteration: 808 | Classification loss: 0.04764 | Regression loss: 0.11436 | Running loss: 0.19974\n",
      "Epoch: 20 | Iteration: 809 | Classification loss: 0.01117 | Regression loss: 0.08518 | Running loss: 0.19942\n",
      "Epoch: 20 | Iteration: 810 | Classification loss: 0.00865 | Regression loss: 0.07178 | Running loss: 0.19894\n",
      "Epoch: 20 | Iteration: 811 | Classification loss: 0.02065 | Regression loss: 0.15190 | Running loss: 0.19903\n",
      "Epoch: 20 | Iteration: 812 | Classification loss: 0.27642 | Regression loss: 0.11323 | Running loss: 0.19950\n",
      "Epoch: 20 | Iteration: 813 | Classification loss: 0.04111 | Regression loss: 0.15103 | Running loss: 0.19956\n",
      "Epoch: 20 | Iteration: 814 | Classification loss: 0.06323 | Regression loss: 0.08986 | Running loss: 0.19895\n",
      "Epoch: 20 | Iteration: 815 | Classification loss: 0.01429 | Regression loss: 0.11766 | Running loss: 0.19871\n",
      "Epoch: 20 | Iteration: 816 | Classification loss: 0.01622 | Regression loss: 0.07598 | Running loss: 0.19844\n",
      "Epoch: 20 | Iteration: 817 | Classification loss: 0.03622 | Regression loss: 0.15468 | Running loss: 0.19866\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.597\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.510\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 21 | Iteration: 0 | Classification loss: 0.05094 | Regression loss: 0.14430 | Running loss: 0.19877\n",
      "Epoch: 21 | Iteration: 1 | Classification loss: 0.00449 | Regression loss: 0.11003 | Running loss: 0.19845\n",
      "Epoch: 21 | Iteration: 2 | Classification loss: 0.01389 | Regression loss: 0.18224 | Running loss: 0.19848\n",
      "Epoch: 21 | Iteration: 3 | Classification loss: 0.01871 | Regression loss: 0.22895 | Running loss: 0.19871\n",
      "Epoch: 21 | Iteration: 4 | Classification loss: 0.03475 | Regression loss: 0.16126 | Running loss: 0.19886\n",
      "Epoch: 21 | Iteration: 5 | Classification loss: 0.01474 | Regression loss: 0.16655 | Running loss: 0.19757\n",
      "Epoch: 21 | Iteration: 6 | Classification loss: 0.01608 | Regression loss: 0.10422 | Running loss: 0.19759\n",
      "Epoch: 21 | Iteration: 7 | Classification loss: 0.02268 | Regression loss: 0.13359 | Running loss: 0.19765\n",
      "Epoch: 21 | Iteration: 8 | Classification loss: 0.01411 | Regression loss: 0.11967 | Running loss: 0.19760\n",
      "Epoch: 21 | Iteration: 9 | Classification loss: 0.02469 | Regression loss: 0.11570 | Running loss: 0.19742\n",
      "Epoch: 21 | Iteration: 10 | Classification loss: 0.05206 | Regression loss: 0.13153 | Running loss: 0.19748\n",
      "Epoch: 21 | Iteration: 11 | Classification loss: 0.06267 | Regression loss: 0.13684 | Running loss: 0.19753\n",
      "Epoch: 21 | Iteration: 12 | Classification loss: 0.01225 | Regression loss: 0.15776 | Running loss: 0.19763\n",
      "Epoch: 21 | Iteration: 13 | Classification loss: 0.01868 | Regression loss: 0.10525 | Running loss: 0.19763\n",
      "Epoch: 21 | Iteration: 14 | Classification loss: 0.04845 | Regression loss: 0.25538 | Running loss: 0.19802\n",
      "Epoch: 21 | Iteration: 15 | Classification loss: 0.02107 | Regression loss: 0.14798 | Running loss: 0.19805\n",
      "Epoch: 21 | Iteration: 16 | Classification loss: 0.10169 | Regression loss: 0.16962 | Running loss: 0.19830\n",
      "Epoch: 21 | Iteration: 17 | Classification loss: 0.01272 | Regression loss: 0.15362 | Running loss: 0.19824\n",
      "Epoch: 21 | Iteration: 18 | Classification loss: 0.01185 | Regression loss: 0.12004 | Running loss: 0.19809\n",
      "Epoch: 21 | Iteration: 19 | Classification loss: 0.02739 | Regression loss: 0.21579 | Running loss: 0.19817\n",
      "Epoch: 21 | Iteration: 20 | Classification loss: 0.28210 | Regression loss: 0.34603 | Running loss: 0.19902\n",
      "Epoch: 21 | Iteration: 21 | Classification loss: 0.03861 | Regression loss: 0.24896 | Running loss: 0.19938\n",
      "Epoch: 21 | Iteration: 22 | Classification loss: 0.01184 | Regression loss: 0.12958 | Running loss: 0.19919\n",
      "Epoch: 21 | Iteration: 23 | Classification loss: 0.01301 | Regression loss: 0.13712 | Running loss: 0.19911\n",
      "Epoch: 21 | Iteration: 24 | Classification loss: 0.03549 | Regression loss: 0.22239 | Running loss: 0.19936\n",
      "Epoch: 21 | Iteration: 25 | Classification loss: 0.01103 | Regression loss: 0.13417 | Running loss: 0.19921\n",
      "Epoch: 21 | Iteration: 26 | Classification loss: 0.03747 | Regression loss: 0.12553 | Running loss: 0.19926\n",
      "Epoch: 21 | Iteration: 27 | Classification loss: 0.02777 | Regression loss: 0.20246 | Running loss: 0.19933\n",
      "Epoch: 21 | Iteration: 28 | Classification loss: 0.04648 | Regression loss: 0.20915 | Running loss: 0.19965\n",
      "Epoch: 21 | Iteration: 29 | Classification loss: 0.01559 | Regression loss: 0.12332 | Running loss: 0.19970\n",
      "Epoch: 21 | Iteration: 30 | Classification loss: 0.01521 | Regression loss: 0.12109 | Running loss: 0.19975\n",
      "Epoch: 21 | Iteration: 31 | Classification loss: 0.00500 | Regression loss: 0.15299 | Running loss: 0.19968\n",
      "Epoch: 21 | Iteration: 32 | Classification loss: 0.02230 | Regression loss: 0.16667 | Running loss: 0.19978\n",
      "Epoch: 21 | Iteration: 33 | Classification loss: 0.08440 | Regression loss: 0.09411 | Running loss: 0.19974\n",
      "Epoch: 21 | Iteration: 34 | Classification loss: 0.02498 | Regression loss: 0.16876 | Running loss: 0.19982\n",
      "Epoch: 21 | Iteration: 35 | Classification loss: 0.02678 | Regression loss: 0.23038 | Running loss: 0.20010\n",
      "Epoch: 21 | Iteration: 36 | Classification loss: 0.01865 | Regression loss: 0.22065 | Running loss: 0.20000\n",
      "Epoch: 21 | Iteration: 37 | Classification loss: 0.01499 | Regression loss: 0.14024 | Running loss: 0.20003\n",
      "Epoch: 21 | Iteration: 38 | Classification loss: 0.04567 | Regression loss: 0.26682 | Running loss: 0.20043\n",
      "Epoch: 21 | Iteration: 39 | Classification loss: 0.08633 | Regression loss: 0.27900 | Running loss: 0.20097\n",
      "Epoch: 21 | Iteration: 40 | Classification loss: 0.02624 | Regression loss: 0.17119 | Running loss: 0.20106\n",
      "Epoch: 21 | Iteration: 41 | Classification loss: 0.01917 | Regression loss: 0.15004 | Running loss: 0.20124\n",
      "Epoch: 21 | Iteration: 42 | Classification loss: 0.01046 | Regression loss: 0.11345 | Running loss: 0.20138\n",
      "Epoch: 21 | Iteration: 43 | Classification loss: 0.03424 | Regression loss: 0.12150 | Running loss: 0.20145\n",
      "Epoch: 21 | Iteration: 44 | Classification loss: 0.00559 | Regression loss: 0.05599 | Running loss: 0.20114\n",
      "Epoch: 21 | Iteration: 45 | Classification loss: 0.01808 | Regression loss: 0.11424 | Running loss: 0.20106\n",
      "Epoch: 21 | Iteration: 46 | Classification loss: 0.07414 | Regression loss: 0.22459 | Running loss: 0.20123\n",
      "Epoch: 21 | Iteration: 47 | Classification loss: 0.03357 | Regression loss: 0.07549 | Running loss: 0.20103\n",
      "Epoch: 21 | Iteration: 48 | Classification loss: 0.12470 | Regression loss: 0.24931 | Running loss: 0.20152\n",
      "Epoch: 21 | Iteration: 49 | Classification loss: 0.01936 | Regression loss: 0.20556 | Running loss: 0.20168\n",
      "Epoch: 21 | Iteration: 50 | Classification loss: 0.00518 | Regression loss: 0.09504 | Running loss: 0.20149\n",
      "Epoch: 21 | Iteration: 51 | Classification loss: 0.02409 | Regression loss: 0.06878 | Running loss: 0.20136\n",
      "Epoch: 21 | Iteration: 52 | Classification loss: 0.02641 | Regression loss: 0.18985 | Running loss: 0.19993\n",
      "Epoch: 21 | Iteration: 53 | Classification loss: 0.03820 | Regression loss: 0.23900 | Running loss: 0.20021\n",
      "Epoch: 21 | Iteration: 54 | Classification loss: 0.01523 | Regression loss: 0.10130 | Running loss: 0.20012\n",
      "Epoch: 21 | Iteration: 55 | Classification loss: 0.28045 | Regression loss: 0.14404 | Running loss: 0.20068\n",
      "Epoch: 21 | Iteration: 56 | Classification loss: 0.03214 | Regression loss: 0.16585 | Running loss: 0.20086\n",
      "Epoch: 21 | Iteration: 57 | Classification loss: 0.00652 | Regression loss: 0.07615 | Running loss: 0.20078\n",
      "Epoch: 21 | Iteration: 58 | Classification loss: 0.01294 | Regression loss: 0.09100 | Running loss: 0.20065\n",
      "Epoch: 21 | Iteration: 59 | Classification loss: 0.00734 | Regression loss: 0.10244 | Running loss: 0.20016\n",
      "Epoch: 21 | Iteration: 60 | Classification loss: 0.00689 | Regression loss: 0.11014 | Running loss: 0.19979\n",
      "Epoch: 21 | Iteration: 61 | Classification loss: 0.09978 | Regression loss: 0.14075 | Running loss: 0.19989\n",
      "Epoch: 21 | Iteration: 62 | Classification loss: 0.03623 | Regression loss: 0.17903 | Running loss: 0.19974\n",
      "Epoch: 21 | Iteration: 63 | Classification loss: 0.01111 | Regression loss: 0.07302 | Running loss: 0.19946\n",
      "Epoch: 21 | Iteration: 64 | Classification loss: 0.09501 | Regression loss: 0.24600 | Running loss: 0.19978\n",
      "Epoch: 21 | Iteration: 65 | Classification loss: 0.03232 | Regression loss: 0.12904 | Running loss: 0.19976\n",
      "Epoch: 21 | Iteration: 66 | Classification loss: 0.02161 | Regression loss: 0.08349 | Running loss: 0.19944\n",
      "Epoch: 21 | Iteration: 67 | Classification loss: 0.01166 | Regression loss: 0.16267 | Running loss: 0.19952\n",
      "Epoch: 21 | Iteration: 68 | Classification loss: 0.04887 | Regression loss: 0.23806 | Running loss: 0.19990\n",
      "Epoch: 21 | Iteration: 69 | Classification loss: 0.01556 | Regression loss: 0.13075 | Running loss: 0.20003\n",
      "Epoch: 21 | Iteration: 70 | Classification loss: 0.03359 | Regression loss: 0.18565 | Running loss: 0.20013\n",
      "Epoch: 21 | Iteration: 71 | Classification loss: 0.01086 | Regression loss: 0.08908 | Running loss: 0.19983\n",
      "Epoch: 21 | Iteration: 72 | Classification loss: 0.04293 | Regression loss: 0.20043 | Running loss: 0.20005\n",
      "Epoch: 21 | Iteration: 73 | Classification loss: 0.00534 | Regression loss: 0.07045 | Running loss: 0.19983\n",
      "Epoch: 21 | Iteration: 74 | Classification loss: 0.00847 | Regression loss: 0.12090 | Running loss: 0.19922\n",
      "Epoch: 21 | Iteration: 75 | Classification loss: 0.01001 | Regression loss: 0.11092 | Running loss: 0.19912\n",
      "Epoch: 21 | Iteration: 76 | Classification loss: 0.02629 | Regression loss: 0.16377 | Running loss: 0.19853\n",
      "Epoch: 21 | Iteration: 77 | Classification loss: 0.00283 | Regression loss: 0.09747 | Running loss: 0.19852\n",
      "Epoch: 21 | Iteration: 78 | Classification loss: 0.03050 | Regression loss: 0.24645 | Running loss: 0.19826\n",
      "Epoch: 21 | Iteration: 79 | Classification loss: 0.02519 | Regression loss: 0.24234 | Running loss: 0.19854\n",
      "Epoch: 21 | Iteration: 80 | Classification loss: 0.03461 | Regression loss: 0.18784 | Running loss: 0.19834\n",
      "Epoch: 21 | Iteration: 81 | Classification loss: 0.01189 | Regression loss: 0.16596 | Running loss: 0.19852\n",
      "Epoch: 21 | Iteration: 82 | Classification loss: 0.00530 | Regression loss: 0.16864 | Running loss: 0.19863\n",
      "Epoch: 21 | Iteration: 83 | Classification loss: 0.17217 | Regression loss: 0.28437 | Running loss: 0.19919\n",
      "Epoch: 21 | Iteration: 84 | Classification loss: 0.03456 | Regression loss: 0.21421 | Running loss: 0.19952\n",
      "Epoch: 21 | Iteration: 85 | Classification loss: 0.01065 | Regression loss: 0.13527 | Running loss: 0.19914\n",
      "Epoch: 21 | Iteration: 86 | Classification loss: 0.05699 | Regression loss: 0.24585 | Running loss: 0.19950\n",
      "Epoch: 21 | Iteration: 87 | Classification loss: 0.00999 | Regression loss: 0.08748 | Running loss: 0.19953\n",
      "Epoch: 21 | Iteration: 88 | Classification loss: 0.03658 | Regression loss: 0.21436 | Running loss: 0.19958\n",
      "Epoch: 21 | Iteration: 89 | Classification loss: 0.01240 | Regression loss: 0.11163 | Running loss: 0.19967\n",
      "Epoch: 21 | Iteration: 90 | Classification loss: 0.03925 | Regression loss: 0.24375 | Running loss: 0.19995\n",
      "Epoch: 21 | Iteration: 91 | Classification loss: 0.01674 | Regression loss: 0.16340 | Running loss: 0.20002\n",
      "Epoch: 21 | Iteration: 92 | Classification loss: 0.00375 | Regression loss: 0.05706 | Running loss: 0.19997\n",
      "Epoch: 21 | Iteration: 93 | Classification loss: 0.10713 | Regression loss: 0.25969 | Running loss: 0.20029\n",
      "Epoch: 21 | Iteration: 94 | Classification loss: 0.04084 | Regression loss: 0.10245 | Running loss: 0.20016\n",
      "Epoch: 21 | Iteration: 95 | Classification loss: 0.02323 | Regression loss: 0.18929 | Running loss: 0.20025\n",
      "Epoch: 21 | Iteration: 96 | Classification loss: 0.00638 | Regression loss: 0.10115 | Running loss: 0.20011\n",
      "Epoch: 21 | Iteration: 97 | Classification loss: 0.01707 | Regression loss: 0.05047 | Running loss: 0.19999\n",
      "Epoch: 21 | Iteration: 98 | Classification loss: 0.03361 | Regression loss: 0.11886 | Running loss: 0.20004\n",
      "Epoch: 21 | Iteration: 99 | Classification loss: 0.04190 | Regression loss: 0.10885 | Running loss: 0.19987\n",
      "Epoch: 21 | Iteration: 100 | Classification loss: 0.00727 | Regression loss: 0.07097 | Running loss: 0.19981\n",
      "Epoch: 21 | Iteration: 101 | Classification loss: 0.02516 | Regression loss: 0.14918 | Running loss: 0.19933\n",
      "Epoch: 21 | Iteration: 102 | Classification loss: 0.02515 | Regression loss: 0.13796 | Running loss: 0.19948\n",
      "Epoch: 21 | Iteration: 103 | Classification loss: 0.02527 | Regression loss: 0.10989 | Running loss: 0.19942\n",
      "Epoch: 21 | Iteration: 104 | Classification loss: 0.00801 | Regression loss: 0.10804 | Running loss: 0.19935\n",
      "Epoch: 21 | Iteration: 105 | Classification loss: 0.09368 | Regression loss: 0.33528 | Running loss: 0.19981\n",
      "Epoch: 21 | Iteration: 106 | Classification loss: 0.01017 | Regression loss: 0.14246 | Running loss: 0.19996\n",
      "Epoch: 21 | Iteration: 107 | Classification loss: 0.01847 | Regression loss: 0.29111 | Running loss: 0.20026\n",
      "Epoch: 21 | Iteration: 108 | Classification loss: 0.00967 | Regression loss: 0.15230 | Running loss: 0.19996\n",
      "Epoch: 21 | Iteration: 109 | Classification loss: 0.02417 | Regression loss: 0.12947 | Running loss: 0.20013\n",
      "Epoch: 21 | Iteration: 110 | Classification loss: 0.03122 | Regression loss: 0.15658 | Running loss: 0.20022\n",
      "Epoch: 21 | Iteration: 111 | Classification loss: 0.01115 | Regression loss: 0.09008 | Running loss: 0.20016\n",
      "Epoch: 21 | Iteration: 112 | Classification loss: 0.05609 | Regression loss: 0.21184 | Running loss: 0.20037\n",
      "Epoch: 21 | Iteration: 113 | Classification loss: 0.03052 | Regression loss: 0.14749 | Running loss: 0.20053\n",
      "Epoch: 21 | Iteration: 114 | Classification loss: 0.04252 | Regression loss: 0.13511 | Running loss: 0.20070\n",
      "Epoch: 21 | Iteration: 115 | Classification loss: 0.05930 | Regression loss: 0.19235 | Running loss: 0.20091\n",
      "Epoch: 21 | Iteration: 116 | Classification loss: 0.01598 | Regression loss: 0.12048 | Running loss: 0.20079\n",
      "Epoch: 21 | Iteration: 117 | Classification loss: 0.01547 | Regression loss: 0.08696 | Running loss: 0.20064\n",
      "Epoch: 21 | Iteration: 118 | Classification loss: 0.07466 | Regression loss: 0.29772 | Running loss: 0.20080\n",
      "Epoch: 21 | Iteration: 119 | Classification loss: 0.01738 | Regression loss: 0.23943 | Running loss: 0.20082\n",
      "Epoch: 21 | Iteration: 120 | Classification loss: 0.02051 | Regression loss: 0.14962 | Running loss: 0.20098\n",
      "Epoch: 21 | Iteration: 121 | Classification loss: 0.03823 | Regression loss: 0.17315 | Running loss: 0.20023\n",
      "Epoch: 21 | Iteration: 122 | Classification loss: 0.00420 | Regression loss: 0.07113 | Running loss: 0.20023\n",
      "Epoch: 21 | Iteration: 123 | Classification loss: 0.02381 | Regression loss: 0.10015 | Running loss: 0.20020\n",
      "Epoch: 21 | Iteration: 124 | Classification loss: 0.03056 | Regression loss: 0.10172 | Running loss: 0.20022\n",
      "Epoch: 21 | Iteration: 125 | Classification loss: 0.01767 | Regression loss: 0.17435 | Running loss: 0.20033\n",
      "Epoch: 21 | Iteration: 126 | Classification loss: 0.01257 | Regression loss: 0.11915 | Running loss: 0.20020\n",
      "Epoch: 21 | Iteration: 127 | Classification loss: 0.00964 | Regression loss: 0.23171 | Running loss: 0.20027\n",
      "Epoch: 21 | Iteration: 128 | Classification loss: 0.01088 | Regression loss: 0.08434 | Running loss: 0.19985\n",
      "Epoch: 21 | Iteration: 129 | Classification loss: 0.01474 | Regression loss: 0.12489 | Running loss: 0.19941\n",
      "Epoch: 21 | Iteration: 130 | Classification loss: 0.00186 | Regression loss: 0.06263 | Running loss: 0.19922\n",
      "Epoch: 21 | Iteration: 131 | Classification loss: 0.02629 | Regression loss: 0.18421 | Running loss: 0.19921\n",
      "Epoch: 21 | Iteration: 132 | Classification loss: 0.04738 | Regression loss: 0.22041 | Running loss: 0.19931\n",
      "Epoch: 21 | Iteration: 133 | Classification loss: 0.00514 | Regression loss: 0.07572 | Running loss: 0.19882\n",
      "Epoch: 21 | Iteration: 134 | Classification loss: 0.00775 | Regression loss: 0.18723 | Running loss: 0.19873\n",
      "Epoch: 21 | Iteration: 135 | Classification loss: 0.03464 | Regression loss: 0.16843 | Running loss: 0.19867\n",
      "Epoch: 21 | Iteration: 136 | Classification loss: 0.02608 | Regression loss: 0.22025 | Running loss: 0.19893\n",
      "Epoch: 21 | Iteration: 137 | Classification loss: 0.06544 | Regression loss: 0.29590 | Running loss: 0.19925\n",
      "Epoch: 21 | Iteration: 138 | Classification loss: 0.05555 | Regression loss: 0.25800 | Running loss: 0.19973\n",
      "Epoch: 21 | Iteration: 139 | Classification loss: 0.05391 | Regression loss: 0.14232 | Running loss: 0.19918\n",
      "Epoch: 21 | Iteration: 140 | Classification loss: 0.02759 | Regression loss: 0.17315 | Running loss: 0.19910\n",
      "Epoch: 21 | Iteration: 141 | Classification loss: 0.61717 | Regression loss: 0.46169 | Running loss: 0.20089\n",
      "Epoch: 21 | Iteration: 142 | Classification loss: 0.00675 | Regression loss: 0.16535 | Running loss: 0.20065\n",
      "Epoch: 21 | Iteration: 143 | Classification loss: 0.07601 | Regression loss: 0.21762 | Running loss: 0.20051\n",
      "Epoch: 21 | Iteration: 144 | Classification loss: 0.00373 | Regression loss: 0.10945 | Running loss: 0.20028\n",
      "Epoch: 21 | Iteration: 145 | Classification loss: 0.00718 | Regression loss: 0.18546 | Running loss: 0.20029\n",
      "Epoch: 21 | Iteration: 146 | Classification loss: 0.13575 | Regression loss: 0.25836 | Running loss: 0.20012\n",
      "Epoch: 21 | Iteration: 147 | Classification loss: 0.02195 | Regression loss: 0.11145 | Running loss: 0.20006\n",
      "Epoch: 21 | Iteration: 148 | Classification loss: 0.01914 | Regression loss: 0.09945 | Running loss: 0.20008\n",
      "Epoch: 21 | Iteration: 149 | Classification loss: 0.01757 | Regression loss: 0.07857 | Running loss: 0.20010\n",
      "Epoch: 21 | Iteration: 150 | Classification loss: 0.00739 | Regression loss: 0.09430 | Running loss: 0.19966\n",
      "Epoch: 21 | Iteration: 151 | Classification loss: 0.07098 | Regression loss: 0.27475 | Running loss: 0.19995\n",
      "Epoch: 21 | Iteration: 152 | Classification loss: 0.05873 | Regression loss: 0.27017 | Running loss: 0.20018\n",
      "Epoch: 21 | Iteration: 153 | Classification loss: 0.01736 | Regression loss: 0.15520 | Running loss: 0.20013\n",
      "Epoch: 21 | Iteration: 154 | Classification loss: 0.02295 | Regression loss: 0.12822 | Running loss: 0.20004\n",
      "Epoch: 21 | Iteration: 155 | Classification loss: 0.10814 | Regression loss: 0.23067 | Running loss: 0.20051\n",
      "Epoch: 21 | Iteration: 156 | Classification loss: 0.01463 | Regression loss: 0.08950 | Running loss: 0.20040\n",
      "Epoch: 21 | Iteration: 157 | Classification loss: 0.00736 | Regression loss: 0.12486 | Running loss: 0.20053\n",
      "Epoch: 21 | Iteration: 158 | Classification loss: 0.03472 | Regression loss: 0.21932 | Running loss: 0.20064\n",
      "Epoch: 21 | Iteration: 159 | Classification loss: 0.07983 | Regression loss: 0.12345 | Running loss: 0.20076\n",
      "Epoch: 21 | Iteration: 160 | Classification loss: 0.01550 | Regression loss: 0.14439 | Running loss: 0.20045\n",
      "Epoch: 21 | Iteration: 161 | Classification loss: 0.00938 | Regression loss: 0.06341 | Running loss: 0.20032\n",
      "Epoch: 21 | Iteration: 162 | Classification loss: 0.05474 | Regression loss: 0.18253 | Running loss: 0.20046\n",
      "Epoch: 21 | Iteration: 163 | Classification loss: 0.00881 | Regression loss: 0.12018 | Running loss: 0.20036\n",
      "Epoch: 21 | Iteration: 164 | Classification loss: 0.03974 | Regression loss: 0.08763 | Running loss: 0.19996\n",
      "Epoch: 21 | Iteration: 165 | Classification loss: 0.01365 | Regression loss: 0.11891 | Running loss: 0.19961\n",
      "Epoch: 21 | Iteration: 166 | Classification loss: 0.10652 | Regression loss: 0.36546 | Running loss: 0.20031\n",
      "Epoch: 21 | Iteration: 167 | Classification loss: 0.02648 | Regression loss: 0.29668 | Running loss: 0.20043\n",
      "Epoch: 21 | Iteration: 168 | Classification loss: 0.04586 | Regression loss: 0.15184 | Running loss: 0.20047\n",
      "Epoch: 21 | Iteration: 169 | Classification loss: 0.01759 | Regression loss: 0.18515 | Running loss: 0.20052\n",
      "Epoch: 21 | Iteration: 170 | Classification loss: 0.08871 | Regression loss: 0.31167 | Running loss: 0.20113\n",
      "Epoch: 21 | Iteration: 171 | Classification loss: 0.02522 | Regression loss: 0.20313 | Running loss: 0.20132\n",
      "Epoch: 21 | Iteration: 172 | Classification loss: 0.00567 | Regression loss: 0.12179 | Running loss: 0.20127\n",
      "Epoch: 21 | Iteration: 173 | Classification loss: 0.02512 | Regression loss: 0.15950 | Running loss: 0.20140\n",
      "Epoch: 21 | Iteration: 174 | Classification loss: 0.16835 | Regression loss: 0.23613 | Running loss: 0.20187\n",
      "Epoch: 21 | Iteration: 175 | Classification loss: 0.05683 | Regression loss: 0.30873 | Running loss: 0.20229\n",
      "Epoch: 21 | Iteration: 176 | Classification loss: 0.16645 | Regression loss: 0.36613 | Running loss: 0.20309\n",
      "Epoch: 21 | Iteration: 177 | Classification loss: 0.06052 | Regression loss: 0.31875 | Running loss: 0.20341\n",
      "Epoch: 21 | Iteration: 178 | Classification loss: 0.05790 | Regression loss: 0.18421 | Running loss: 0.20364\n",
      "Epoch: 21 | Iteration: 179 | Classification loss: 0.01160 | Regression loss: 0.12850 | Running loss: 0.20336\n",
      "Epoch: 21 | Iteration: 180 | Classification loss: 0.01304 | Regression loss: 0.10780 | Running loss: 0.20337\n",
      "Epoch: 21 | Iteration: 181 | Classification loss: 0.01350 | Regression loss: 0.04992 | Running loss: 0.20259\n",
      "Epoch: 21 | Iteration: 182 | Classification loss: 0.01648 | Regression loss: 0.11094 | Running loss: 0.20234\n",
      "Epoch: 21 | Iteration: 183 | Classification loss: 0.02294 | Regression loss: 0.13691 | Running loss: 0.20209\n",
      "Epoch: 21 | Iteration: 184 | Classification loss: 0.01171 | Regression loss: 0.15473 | Running loss: 0.20232\n",
      "Epoch: 21 | Iteration: 185 | Classification loss: 0.01346 | Regression loss: 0.09789 | Running loss: 0.20239\n",
      "Epoch: 21 | Iteration: 186 | Classification loss: 0.01555 | Regression loss: 0.14290 | Running loss: 0.20238\n",
      "Epoch: 21 | Iteration: 187 | Classification loss: 0.01588 | Regression loss: 0.09773 | Running loss: 0.20204\n",
      "Epoch: 21 | Iteration: 188 | Classification loss: 0.00786 | Regression loss: 0.06714 | Running loss: 0.20149\n",
      "Epoch: 21 | Iteration: 189 | Classification loss: 0.07307 | Regression loss: 0.24060 | Running loss: 0.20185\n",
      "Epoch: 21 | Iteration: 190 | Classification loss: 0.12370 | Regression loss: 0.34487 | Running loss: 0.20225\n",
      "Epoch: 21 | Iteration: 191 | Classification loss: 0.03413 | Regression loss: 0.18833 | Running loss: 0.20219\n",
      "Epoch: 21 | Iteration: 192 | Classification loss: 0.03247 | Regression loss: 0.29132 | Running loss: 0.20227\n",
      "Epoch: 21 | Iteration: 193 | Classification loss: 0.00976 | Regression loss: 0.09824 | Running loss: 0.20219\n",
      "Epoch: 21 | Iteration: 194 | Classification loss: 0.05320 | Regression loss: 0.22279 | Running loss: 0.20198\n",
      "Epoch: 21 | Iteration: 195 | Classification loss: 0.01140 | Regression loss: 0.12435 | Running loss: 0.20209\n",
      "Epoch: 21 | Iteration: 196 | Classification loss: 0.04220 | Regression loss: 0.27483 | Running loss: 0.20257\n",
      "Epoch: 21 | Iteration: 197 | Classification loss: 0.02755 | Regression loss: 0.14272 | Running loss: 0.20219\n",
      "Epoch: 21 | Iteration: 198 | Classification loss: 0.01553 | Regression loss: 0.19094 | Running loss: 0.20231\n",
      "Epoch: 21 | Iteration: 199 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.20198\n",
      "Epoch: 21 | Iteration: 200 | Classification loss: 0.09004 | Regression loss: 0.17064 | Running loss: 0.20223\n",
      "Epoch: 21 | Iteration: 201 | Classification loss: 0.02375 | Regression loss: 0.17686 | Running loss: 0.20244\n",
      "Epoch: 21 | Iteration: 202 | Classification loss: 0.02097 | Regression loss: 0.07701 | Running loss: 0.20244\n",
      "Epoch: 21 | Iteration: 203 | Classification loss: 0.03044 | Regression loss: 0.13266 | Running loss: 0.20245\n",
      "Epoch: 21 | Iteration: 204 | Classification loss: 0.01515 | Regression loss: 0.19616 | Running loss: 0.20258\n",
      "Epoch: 21 | Iteration: 205 | Classification loss: 0.00704 | Regression loss: 0.10666 | Running loss: 0.20264\n",
      "Epoch: 21 | Iteration: 206 | Classification loss: 0.00908 | Regression loss: 0.10985 | Running loss: 0.20138\n",
      "Epoch: 21 | Iteration: 207 | Classification loss: 0.12334 | Regression loss: 0.27287 | Running loss: 0.20175\n",
      "Epoch: 21 | Iteration: 208 | Classification loss: 0.05617 | Regression loss: 0.19289 | Running loss: 0.20186\n",
      "Epoch: 21 | Iteration: 209 | Classification loss: 0.01153 | Regression loss: 0.23271 | Running loss: 0.20212\n",
      "Epoch: 21 | Iteration: 210 | Classification loss: 0.10128 | Regression loss: 0.33518 | Running loss: 0.20259\n",
      "Epoch: 21 | Iteration: 211 | Classification loss: 0.01191 | Regression loss: 0.21846 | Running loss: 0.20246\n",
      "Epoch: 21 | Iteration: 212 | Classification loss: 0.10461 | Regression loss: 0.33196 | Running loss: 0.20312\n",
      "Epoch: 21 | Iteration: 213 | Classification loss: 0.01286 | Regression loss: 0.19272 | Running loss: 0.20272\n",
      "Epoch: 21 | Iteration: 214 | Classification loss: 0.01367 | Regression loss: 0.11144 | Running loss: 0.20267\n",
      "Epoch: 21 | Iteration: 215 | Classification loss: 0.02289 | Regression loss: 0.16832 | Running loss: 0.20262\n",
      "Epoch: 21 | Iteration: 216 | Classification loss: 0.10213 | Regression loss: 0.27197 | Running loss: 0.20328\n",
      "Epoch: 21 | Iteration: 217 | Classification loss: 0.00540 | Regression loss: 0.04761 | Running loss: 0.20226\n",
      "Epoch: 21 | Iteration: 218 | Classification loss: 0.02713 | Regression loss: 0.20288 | Running loss: 0.20223\n",
      "Epoch: 21 | Iteration: 219 | Classification loss: 0.13972 | Regression loss: 0.29628 | Running loss: 0.20280\n",
      "Epoch: 21 | Iteration: 220 | Classification loss: 0.05764 | Regression loss: 0.17934 | Running loss: 0.20308\n",
      "Epoch: 21 | Iteration: 221 | Classification loss: 0.01955 | Regression loss: 0.18982 | Running loss: 0.20323\n",
      "Epoch: 21 | Iteration: 222 | Classification loss: 0.08472 | Regression loss: 0.20263 | Running loss: 0.20335\n",
      "Epoch: 21 | Iteration: 223 | Classification loss: 0.04759 | Regression loss: 0.22963 | Running loss: 0.20327\n",
      "Epoch: 21 | Iteration: 224 | Classification loss: 0.00340 | Regression loss: 0.09823 | Running loss: 0.20306\n",
      "Epoch: 21 | Iteration: 225 | Classification loss: 0.02575 | Regression loss: 0.15139 | Running loss: 0.20300\n",
      "Epoch: 21 | Iteration: 226 | Classification loss: 0.04595 | Regression loss: 0.20456 | Running loss: 0.20328\n",
      "Epoch: 21 | Iteration: 227 | Classification loss: 0.02696 | Regression loss: 0.13412 | Running loss: 0.20335\n",
      "Epoch: 21 | Iteration: 228 | Classification loss: 0.04408 | Regression loss: 0.24740 | Running loss: 0.20372\n",
      "Epoch: 21 | Iteration: 229 | Classification loss: 0.02106 | Regression loss: 0.23185 | Running loss: 0.20370\n",
      "Epoch: 21 | Iteration: 230 | Classification loss: 0.00290 | Regression loss: 0.05859 | Running loss: 0.20331\n",
      "Epoch: 21 | Iteration: 231 | Classification loss: 0.02761 | Regression loss: 0.16609 | Running loss: 0.20337\n",
      "Epoch: 21 | Iteration: 232 | Classification loss: 0.05202 | Regression loss: 0.19190 | Running loss: 0.20337\n",
      "Epoch: 21 | Iteration: 233 | Classification loss: 0.01229 | Regression loss: 0.19785 | Running loss: 0.20354\n",
      "Epoch: 21 | Iteration: 234 | Classification loss: 0.01193 | Regression loss: 0.13238 | Running loss: 0.20346\n",
      "Epoch: 21 | Iteration: 235 | Classification loss: 0.07373 | Regression loss: 0.20547 | Running loss: 0.20372\n",
      "Epoch: 21 | Iteration: 236 | Classification loss: 0.01448 | Regression loss: 0.11654 | Running loss: 0.20366\n",
      "Epoch: 21 | Iteration: 237 | Classification loss: 0.05287 | Regression loss: 0.13127 | Running loss: 0.20379\n",
      "Epoch: 21 | Iteration: 238 | Classification loss: 0.01761 | Regression loss: 0.08342 | Running loss: 0.20328\n",
      "Epoch: 21 | Iteration: 239 | Classification loss: 0.02309 | Regression loss: 0.09577 | Running loss: 0.20318\n",
      "Epoch: 21 | Iteration: 240 | Classification loss: 0.02642 | Regression loss: 0.20471 | Running loss: 0.20326\n",
      "Epoch: 21 | Iteration: 241 | Classification loss: 0.01487 | Regression loss: 0.12397 | Running loss: 0.20330\n",
      "Epoch: 21 | Iteration: 242 | Classification loss: 0.05317 | Regression loss: 0.27187 | Running loss: 0.20295\n",
      "Epoch: 21 | Iteration: 243 | Classification loss: 0.01368 | Regression loss: 0.09349 | Running loss: 0.20288\n",
      "Epoch: 21 | Iteration: 244 | Classification loss: 0.01238 | Regression loss: 0.09202 | Running loss: 0.20268\n",
      "Epoch: 21 | Iteration: 245 | Classification loss: 0.01856 | Regression loss: 0.12565 | Running loss: 0.20271\n",
      "Epoch: 21 | Iteration: 246 | Classification loss: 0.01361 | Regression loss: 0.08302 | Running loss: 0.20251\n",
      "Epoch: 21 | Iteration: 247 | Classification loss: 0.01036 | Regression loss: 0.12284 | Running loss: 0.20241\n",
      "Epoch: 21 | Iteration: 248 | Classification loss: 0.00866 | Regression loss: 0.14805 | Running loss: 0.20244\n",
      "Epoch: 21 | Iteration: 249 | Classification loss: 0.03877 | Regression loss: 0.18623 | Running loss: 0.20237\n",
      "Epoch: 21 | Iteration: 250 | Classification loss: 0.03218 | Regression loss: 0.14170 | Running loss: 0.20213\n",
      "Epoch: 21 | Iteration: 251 | Classification loss: 0.07112 | Regression loss: 0.12160 | Running loss: 0.20213\n",
      "Epoch: 21 | Iteration: 252 | Classification loss: 0.07272 | Regression loss: 0.15232 | Running loss: 0.20221\n",
      "Epoch: 21 | Iteration: 253 | Classification loss: 0.00183 | Regression loss: 0.06846 | Running loss: 0.20135\n",
      "Epoch: 21 | Iteration: 254 | Classification loss: 0.02037 | Regression loss: 0.13424 | Running loss: 0.20138\n",
      "Epoch: 21 | Iteration: 255 | Classification loss: 0.02654 | Regression loss: 0.20362 | Running loss: 0.20174\n",
      "Epoch: 21 | Iteration: 256 | Classification loss: 0.03850 | Regression loss: 0.20356 | Running loss: 0.20206\n",
      "Epoch: 21 | Iteration: 257 | Classification loss: 0.02315 | Regression loss: 0.09981 | Running loss: 0.20212\n",
      "Epoch: 21 | Iteration: 258 | Classification loss: 0.00751 | Regression loss: 0.10778 | Running loss: 0.20198\n",
      "Epoch: 21 | Iteration: 259 | Classification loss: 0.00865 | Regression loss: 0.12042 | Running loss: 0.20184\n",
      "Epoch: 21 | Iteration: 260 | Classification loss: 0.00655 | Regression loss: 0.09747 | Running loss: 0.20143\n",
      "Epoch: 21 | Iteration: 261 | Classification loss: 0.00436 | Regression loss: 0.05584 | Running loss: 0.20126\n",
      "Epoch: 21 | Iteration: 262 | Classification loss: 0.02675 | Regression loss: 0.13706 | Running loss: 0.20129\n",
      "Epoch: 21 | Iteration: 263 | Classification loss: 0.01615 | Regression loss: 0.12516 | Running loss: 0.20106\n",
      "Epoch: 21 | Iteration: 264 | Classification loss: 0.00849 | Regression loss: 0.12101 | Running loss: 0.20083\n",
      "Epoch: 21 | Iteration: 265 | Classification loss: 0.01066 | Regression loss: 0.12341 | Running loss: 0.20062\n",
      "Epoch: 21 | Iteration: 266 | Classification loss: 0.01930 | Regression loss: 0.14153 | Running loss: 0.20094\n",
      "Epoch: 21 | Iteration: 267 | Classification loss: 0.04264 | Regression loss: 0.26829 | Running loss: 0.20141\n",
      "Epoch: 21 | Iteration: 268 | Classification loss: 0.02527 | Regression loss: 0.14920 | Running loss: 0.20129\n",
      "Epoch: 21 | Iteration: 269 | Classification loss: 0.00685 | Regression loss: 0.07409 | Running loss: 0.20118\n",
      "Epoch: 21 | Iteration: 270 | Classification loss: 0.00901 | Regression loss: 0.11230 | Running loss: 0.20105\n",
      "Epoch: 21 | Iteration: 271 | Classification loss: 0.00560 | Regression loss: 0.05702 | Running loss: 0.20095\n",
      "Epoch: 21 | Iteration: 272 | Classification loss: 0.00889 | Regression loss: 0.18053 | Running loss: 0.20070\n",
      "Epoch: 21 | Iteration: 273 | Classification loss: 0.02454 | Regression loss: 0.13019 | Running loss: 0.20086\n",
      "Epoch: 21 | Iteration: 274 | Classification loss: 0.12009 | Regression loss: 0.26977 | Running loss: 0.20105\n",
      "Epoch: 21 | Iteration: 275 | Classification loss: 0.03027 | Regression loss: 0.19135 | Running loss: 0.20112\n",
      "Epoch: 21 | Iteration: 276 | Classification loss: 0.03821 | Regression loss: 0.14911 | Running loss: 0.20118\n",
      "Epoch: 21 | Iteration: 277 | Classification loss: 0.03008 | Regression loss: 0.17519 | Running loss: 0.20127\n",
      "Epoch: 21 | Iteration: 278 | Classification loss: 0.10266 | Regression loss: 0.24381 | Running loss: 0.20161\n",
      "Epoch: 21 | Iteration: 279 | Classification loss: 0.01175 | Regression loss: 0.14580 | Running loss: 0.20137\n",
      "Epoch: 21 | Iteration: 280 | Classification loss: 0.01832 | Regression loss: 0.20533 | Running loss: 0.20143\n",
      "Epoch: 21 | Iteration: 281 | Classification loss: 0.00563 | Regression loss: 0.05310 | Running loss: 0.20099\n",
      "Epoch: 21 | Iteration: 282 | Classification loss: 0.01088 | Regression loss: 0.12373 | Running loss: 0.20115\n",
      "Epoch: 21 | Iteration: 283 | Classification loss: 0.24629 | Regression loss: 0.18382 | Running loss: 0.20174\n",
      "Epoch: 21 | Iteration: 284 | Classification loss: 0.01902 | Regression loss: 0.17038 | Running loss: 0.20165\n",
      "Epoch: 21 | Iteration: 285 | Classification loss: 0.02578 | Regression loss: 0.12612 | Running loss: 0.20166\n",
      "Epoch: 21 | Iteration: 286 | Classification loss: 0.13388 | Regression loss: 0.27345 | Running loss: 0.20225\n",
      "Epoch: 21 | Iteration: 287 | Classification loss: 0.01765 | Regression loss: 0.11862 | Running loss: 0.20211\n",
      "Epoch: 21 | Iteration: 288 | Classification loss: 0.02365 | Regression loss: 0.14443 | Running loss: 0.20212\n",
      "Epoch: 21 | Iteration: 289 | Classification loss: 0.00701 | Regression loss: 0.10269 | Running loss: 0.20214\n",
      "Epoch: 21 | Iteration: 290 | Classification loss: 0.04209 | Regression loss: 0.07864 | Running loss: 0.20200\n",
      "Epoch: 21 | Iteration: 291 | Classification loss: 0.02504 | Regression loss: 0.18357 | Running loss: 0.20180\n",
      "Epoch: 21 | Iteration: 292 | Classification loss: 0.00801 | Regression loss: 0.11803 | Running loss: 0.20172\n",
      "Epoch: 21 | Iteration: 293 | Classification loss: 0.14969 | Regression loss: 0.26540 | Running loss: 0.20227\n",
      "Epoch: 21 | Iteration: 294 | Classification loss: 0.00900 | Regression loss: 0.11768 | Running loss: 0.20221\n",
      "Epoch: 21 | Iteration: 295 | Classification loss: 0.01208 | Regression loss: 0.18425 | Running loss: 0.20206\n",
      "Epoch: 21 | Iteration: 296 | Classification loss: 0.01209 | Regression loss: 0.12137 | Running loss: 0.20207\n",
      "Epoch: 21 | Iteration: 297 | Classification loss: 0.05704 | Regression loss: 0.21421 | Running loss: 0.20230\n",
      "Epoch: 21 | Iteration: 298 | Classification loss: 0.05000 | Regression loss: 0.19451 | Running loss: 0.20238\n",
      "Epoch: 21 | Iteration: 299 | Classification loss: 0.02229 | Regression loss: 0.13427 | Running loss: 0.20214\n",
      "Epoch: 21 | Iteration: 300 | Classification loss: 0.06942 | Regression loss: 0.12571 | Running loss: 0.20210\n",
      "Epoch: 21 | Iteration: 301 | Classification loss: 0.04282 | Regression loss: 0.17935 | Running loss: 0.20221\n",
      "Epoch: 21 | Iteration: 302 | Classification loss: 0.03077 | Regression loss: 0.28179 | Running loss: 0.20241\n",
      "Epoch: 21 | Iteration: 303 | Classification loss: 0.01112 | Regression loss: 0.11256 | Running loss: 0.20217\n",
      "Epoch: 21 | Iteration: 304 | Classification loss: 0.01014 | Regression loss: 0.10892 | Running loss: 0.20226\n",
      "Epoch: 21 | Iteration: 305 | Classification loss: 0.00618 | Regression loss: 0.11620 | Running loss: 0.20205\n",
      "Epoch: 21 | Iteration: 306 | Classification loss: 0.00983 | Regression loss: 0.08368 | Running loss: 0.20198\n",
      "Epoch: 21 | Iteration: 307 | Classification loss: 0.04165 | Regression loss: 0.27823 | Running loss: 0.20196\n",
      "Epoch: 21 | Iteration: 308 | Classification loss: 0.06189 | Regression loss: 0.23038 | Running loss: 0.20231\n",
      "Epoch: 21 | Iteration: 309 | Classification loss: 0.12457 | Regression loss: 0.30392 | Running loss: 0.20283\n",
      "Epoch: 21 | Iteration: 310 | Classification loss: 0.00832 | Regression loss: 0.13389 | Running loss: 0.20290\n",
      "Epoch: 21 | Iteration: 311 | Classification loss: 0.00785 | Regression loss: 0.08301 | Running loss: 0.20272\n",
      "Epoch: 21 | Iteration: 312 | Classification loss: 0.00898 | Regression loss: 0.12583 | Running loss: 0.20279\n",
      "Epoch: 21 | Iteration: 313 | Classification loss: 0.03833 | Regression loss: 0.13969 | Running loss: 0.20264\n",
      "Epoch: 21 | Iteration: 314 | Classification loss: 0.02109 | Regression loss: 0.14751 | Running loss: 0.20251\n",
      "Epoch: 21 | Iteration: 315 | Classification loss: 0.04173 | Regression loss: 0.13896 | Running loss: 0.20260\n",
      "Epoch: 21 | Iteration: 316 | Classification loss: 0.00702 | Regression loss: 0.10383 | Running loss: 0.20258\n",
      "Epoch: 21 | Iteration: 317 | Classification loss: 0.04769 | Regression loss: 0.10247 | Running loss: 0.20262\n",
      "Epoch: 21 | Iteration: 318 | Classification loss: 0.02699 | Regression loss: 0.14768 | Running loss: 0.20223\n",
      "Epoch: 21 | Iteration: 319 | Classification loss: 0.02662 | Regression loss: 0.14308 | Running loss: 0.20193\n",
      "Epoch: 21 | Iteration: 320 | Classification loss: 0.02248 | Regression loss: 0.10124 | Running loss: 0.20189\n",
      "Epoch: 21 | Iteration: 321 | Classification loss: 0.01128 | Regression loss: 0.12180 | Running loss: 0.20175\n",
      "Epoch: 21 | Iteration: 322 | Classification loss: 0.18465 | Regression loss: 0.37947 | Running loss: 0.20240\n",
      "Epoch: 21 | Iteration: 323 | Classification loss: 0.00687 | Regression loss: 0.18265 | Running loss: 0.20254\n",
      "Epoch: 21 | Iteration: 324 | Classification loss: 0.02530 | Regression loss: 0.13984 | Running loss: 0.20253\n",
      "Epoch: 21 | Iteration: 325 | Classification loss: 0.02719 | Regression loss: 0.13723 | Running loss: 0.20264\n",
      "Epoch: 21 | Iteration: 326 | Classification loss: 0.03629 | Regression loss: 0.21214 | Running loss: 0.20249\n",
      "Epoch: 21 | Iteration: 327 | Classification loss: 0.05610 | Regression loss: 0.30506 | Running loss: 0.20291\n",
      "Epoch: 21 | Iteration: 328 | Classification loss: 0.02385 | Regression loss: 0.15195 | Running loss: 0.20276\n",
      "Epoch: 21 | Iteration: 329 | Classification loss: 0.03088 | Regression loss: 0.10593 | Running loss: 0.20268\n",
      "Epoch: 21 | Iteration: 330 | Classification loss: 0.03685 | Regression loss: 0.25071 | Running loss: 0.20242\n",
      "Epoch: 21 | Iteration: 331 | Classification loss: 0.02357 | Regression loss: 0.24355 | Running loss: 0.20250\n",
      "Epoch: 21 | Iteration: 332 | Classification loss: 0.01365 | Regression loss: 0.09271 | Running loss: 0.20219\n",
      "Epoch: 21 | Iteration: 333 | Classification loss: 0.01237 | Regression loss: 0.10780 | Running loss: 0.20205\n",
      "Epoch: 21 | Iteration: 334 | Classification loss: 0.08200 | Regression loss: 0.16279 | Running loss: 0.20199\n",
      "Epoch: 21 | Iteration: 335 | Classification loss: 0.02904 | Regression loss: 0.19707 | Running loss: 0.20212\n",
      "Epoch: 21 | Iteration: 336 | Classification loss: 0.05616 | Regression loss: 0.15620 | Running loss: 0.20229\n",
      "Epoch: 21 | Iteration: 337 | Classification loss: 0.03230 | Regression loss: 0.13979 | Running loss: 0.20159\n",
      "Epoch: 21 | Iteration: 338 | Classification loss: 0.01097 | Regression loss: 0.13062 | Running loss: 0.20143\n",
      "Epoch: 21 | Iteration: 339 | Classification loss: 0.00586 | Regression loss: 0.13327 | Running loss: 0.20139\n",
      "Epoch: 21 | Iteration: 340 | Classification loss: 0.02040 | Regression loss: 0.04272 | Running loss: 0.20099\n",
      "Epoch: 21 | Iteration: 341 | Classification loss: 0.01641 | Regression loss: 0.22389 | Running loss: 0.20117\n",
      "Epoch: 21 | Iteration: 342 | Classification loss: 0.13719 | Regression loss: 0.20103 | Running loss: 0.20141\n",
      "Epoch: 21 | Iteration: 343 | Classification loss: 0.07214 | Regression loss: 0.32054 | Running loss: 0.20167\n",
      "Epoch: 21 | Iteration: 344 | Classification loss: 0.00507 | Regression loss: 0.10464 | Running loss: 0.20153\n",
      "Epoch: 21 | Iteration: 345 | Classification loss: 0.06174 | Regression loss: 0.22212 | Running loss: 0.20188\n",
      "Epoch: 21 | Iteration: 346 | Classification loss: 0.01652 | Regression loss: 0.11131 | Running loss: 0.20126\n",
      "Epoch: 21 | Iteration: 347 | Classification loss: 0.01073 | Regression loss: 0.12492 | Running loss: 0.20051\n",
      "Epoch: 21 | Iteration: 348 | Classification loss: 0.02397 | Regression loss: 0.12034 | Running loss: 0.20057\n",
      "Epoch: 21 | Iteration: 349 | Classification loss: 0.02149 | Regression loss: 0.18698 | Running loss: 0.20021\n",
      "Epoch: 21 | Iteration: 350 | Classification loss: 0.02928 | Regression loss: 0.08645 | Running loss: 0.20009\n",
      "Epoch: 21 | Iteration: 351 | Classification loss: 0.00495 | Regression loss: 0.03788 | Running loss: 0.19944\n",
      "Epoch: 21 | Iteration: 352 | Classification loss: 0.03080 | Regression loss: 0.10550 | Running loss: 0.19947\n",
      "Epoch: 21 | Iteration: 353 | Classification loss: 0.02308 | Regression loss: 0.13188 | Running loss: 0.19959\n",
      "Epoch: 21 | Iteration: 354 | Classification loss: 0.02296 | Regression loss: 0.12681 | Running loss: 0.19960\n",
      "Epoch: 21 | Iteration: 355 | Classification loss: 0.07286 | Regression loss: 0.22008 | Running loss: 0.20000\n",
      "Epoch: 21 | Iteration: 356 | Classification loss: 0.02137 | Regression loss: 0.09025 | Running loss: 0.19962\n",
      "Epoch: 21 | Iteration: 357 | Classification loss: 0.02120 | Regression loss: 0.13815 | Running loss: 0.19916\n",
      "Epoch: 21 | Iteration: 358 | Classification loss: 0.09810 | Regression loss: 0.19780 | Running loss: 0.19953\n",
      "Epoch: 21 | Iteration: 359 | Classification loss: 0.00671 | Regression loss: 0.09499 | Running loss: 0.19929\n",
      "Epoch: 21 | Iteration: 360 | Classification loss: 0.02897 | Regression loss: 0.14981 | Running loss: 0.19934\n",
      "Epoch: 21 | Iteration: 361 | Classification loss: 0.01941 | Regression loss: 0.14260 | Running loss: 0.19933\n",
      "Epoch: 21 | Iteration: 362 | Classification loss: 0.01287 | Regression loss: 0.06469 | Running loss: 0.19838\n",
      "Epoch: 21 | Iteration: 363 | Classification loss: 0.01885 | Regression loss: 0.16354 | Running loss: 0.19822\n",
      "Epoch: 21 | Iteration: 364 | Classification loss: 0.02003 | Regression loss: 0.11834 | Running loss: 0.19805\n",
      "Epoch: 21 | Iteration: 365 | Classification loss: 0.03960 | Regression loss: 0.15220 | Running loss: 0.19789\n",
      "Epoch: 21 | Iteration: 366 | Classification loss: 0.02680 | Regression loss: 0.09342 | Running loss: 0.19789\n",
      "Epoch: 21 | Iteration: 367 | Classification loss: 0.02326 | Regression loss: 0.08162 | Running loss: 0.19795\n",
      "Epoch: 21 | Iteration: 368 | Classification loss: 0.03946 | Regression loss: 0.13217 | Running loss: 0.19795\n",
      "Epoch: 21 | Iteration: 369 | Classification loss: 0.00631 | Regression loss: 0.11084 | Running loss: 0.19789\n",
      "Epoch: 21 | Iteration: 370 | Classification loss: 0.02381 | Regression loss: 0.17748 | Running loss: 0.19791\n",
      "Epoch: 21 | Iteration: 371 | Classification loss: 0.01278 | Regression loss: 0.16645 | Running loss: 0.19796\n",
      "Epoch: 21 | Iteration: 372 | Classification loss: 0.03477 | Regression loss: 0.24126 | Running loss: 0.19802\n",
      "Epoch: 21 | Iteration: 373 | Classification loss: 0.01132 | Regression loss: 0.18275 | Running loss: 0.19800\n",
      "Epoch: 21 | Iteration: 374 | Classification loss: 0.03136 | Regression loss: 0.14229 | Running loss: 0.19780\n",
      "Epoch: 21 | Iteration: 375 | Classification loss: 0.02294 | Regression loss: 0.17265 | Running loss: 0.19792\n",
      "Epoch: 21 | Iteration: 376 | Classification loss: 0.03704 | Regression loss: 0.09051 | Running loss: 0.19795\n",
      "Epoch: 21 | Iteration: 377 | Classification loss: 0.02284 | Regression loss: 0.19492 | Running loss: 0.19789\n",
      "Epoch: 21 | Iteration: 378 | Classification loss: 0.08921 | Regression loss: 0.27492 | Running loss: 0.19829\n",
      "Epoch: 21 | Iteration: 379 | Classification loss: 0.03635 | Regression loss: 0.18250 | Running loss: 0.19852\n",
      "Epoch: 21 | Iteration: 380 | Classification loss: 0.01571 | Regression loss: 0.13964 | Running loss: 0.19835\n",
      "Epoch: 21 | Iteration: 381 | Classification loss: 0.03866 | Regression loss: 0.19751 | Running loss: 0.19858\n",
      "Epoch: 21 | Iteration: 382 | Classification loss: 0.02085 | Regression loss: 0.12225 | Running loss: 0.19856\n",
      "Epoch: 21 | Iteration: 383 | Classification loss: 0.03202 | Regression loss: 0.17996 | Running loss: 0.19883\n",
      "Epoch: 21 | Iteration: 384 | Classification loss: 0.10264 | Regression loss: 0.40381 | Running loss: 0.19941\n",
      "Epoch: 21 | Iteration: 385 | Classification loss: 0.00770 | Regression loss: 0.13307 | Running loss: 0.19918\n",
      "Epoch: 21 | Iteration: 386 | Classification loss: 0.01589 | Regression loss: 0.14076 | Running loss: 0.19926\n",
      "Epoch: 21 | Iteration: 387 | Classification loss: 0.01115 | Regression loss: 0.12389 | Running loss: 0.19903\n",
      "Epoch: 21 | Iteration: 388 | Classification loss: 0.01535 | Regression loss: 0.09804 | Running loss: 0.19887\n",
      "Epoch: 21 | Iteration: 389 | Classification loss: 0.05794 | Regression loss: 0.18332 | Running loss: 0.19902\n",
      "Epoch: 21 | Iteration: 390 | Classification loss: 0.01023 | Regression loss: 0.16093 | Running loss: 0.19883\n",
      "Epoch: 21 | Iteration: 391 | Classification loss: 0.01521 | Regression loss: 0.16403 | Running loss: 0.19880\n",
      "Epoch: 21 | Iteration: 392 | Classification loss: 0.00539 | Regression loss: 0.10635 | Running loss: 0.19863\n",
      "Epoch: 21 | Iteration: 393 | Classification loss: 0.01254 | Regression loss: 0.18298 | Running loss: 0.19863\n",
      "Epoch: 21 | Iteration: 394 | Classification loss: 0.00879 | Regression loss: 0.07207 | Running loss: 0.19826\n",
      "Epoch: 21 | Iteration: 395 | Classification loss: 0.00651 | Regression loss: 0.10264 | Running loss: 0.19825\n",
      "Epoch: 21 | Iteration: 396 | Classification loss: 0.01507 | Regression loss: 0.11198 | Running loss: 0.19823\n",
      "Epoch: 21 | Iteration: 397 | Classification loss: 0.03389 | Regression loss: 0.16374 | Running loss: 0.19794\n",
      "Epoch: 21 | Iteration: 398 | Classification loss: 0.06592 | Regression loss: 0.26572 | Running loss: 0.19826\n",
      "Epoch: 21 | Iteration: 399 | Classification loss: 0.01961 | Regression loss: 0.16704 | Running loss: 0.19779\n",
      "Epoch: 21 | Iteration: 400 | Classification loss: 0.02744 | Regression loss: 0.08164 | Running loss: 0.19751\n",
      "Epoch: 21 | Iteration: 401 | Classification loss: 0.02127 | Regression loss: 0.10264 | Running loss: 0.19752\n",
      "Epoch: 21 | Iteration: 402 | Classification loss: 0.01755 | Regression loss: 0.18524 | Running loss: 0.19748\n",
      "Epoch: 21 | Iteration: 403 | Classification loss: 0.29315 | Regression loss: 0.16592 | Running loss: 0.19787\n",
      "Epoch: 21 | Iteration: 404 | Classification loss: 0.00865 | Regression loss: 0.05825 | Running loss: 0.19777\n",
      "Epoch: 21 | Iteration: 405 | Classification loss: 0.02812 | Regression loss: 0.17074 | Running loss: 0.19767\n",
      "Epoch: 21 | Iteration: 406 | Classification loss: 0.08218 | Regression loss: 0.29636 | Running loss: 0.19817\n",
      "Epoch: 21 | Iteration: 407 | Classification loss: 0.00870 | Regression loss: 0.12561 | Running loss: 0.19802\n",
      "Epoch: 21 | Iteration: 408 | Classification loss: 0.05641 | Regression loss: 0.13902 | Running loss: 0.19810\n",
      "Epoch: 21 | Iteration: 409 | Classification loss: 0.01225 | Regression loss: 0.15209 | Running loss: 0.19819\n",
      "Epoch: 21 | Iteration: 410 | Classification loss: 0.00709 | Regression loss: 0.09459 | Running loss: 0.19814\n",
      "Epoch: 21 | Iteration: 411 | Classification loss: 0.04314 | Regression loss: 0.26546 | Running loss: 0.19834\n",
      "Epoch: 21 | Iteration: 412 | Classification loss: 0.02459 | Regression loss: 0.10588 | Running loss: 0.19845\n",
      "Epoch: 21 | Iteration: 413 | Classification loss: 0.05153 | Regression loss: 0.23929 | Running loss: 0.19879\n",
      "Epoch: 21 | Iteration: 414 | Classification loss: 0.00830 | Regression loss: 0.11584 | Running loss: 0.19867\n",
      "Epoch: 21 | Iteration: 415 | Classification loss: 0.00788 | Regression loss: 0.10603 | Running loss: 0.19869\n",
      "Epoch: 21 | Iteration: 416 | Classification loss: 0.00226 | Regression loss: 0.06201 | Running loss: 0.19857\n",
      "Epoch: 21 | Iteration: 417 | Classification loss: 0.00873 | Regression loss: 0.08637 | Running loss: 0.19837\n",
      "Epoch: 21 | Iteration: 418 | Classification loss: 0.02112 | Regression loss: 0.14507 | Running loss: 0.19848\n",
      "Epoch: 21 | Iteration: 419 | Classification loss: 0.00943 | Regression loss: 0.08533 | Running loss: 0.19801\n",
      "Epoch: 21 | Iteration: 420 | Classification loss: 0.02069 | Regression loss: 0.24955 | Running loss: 0.19822\n",
      "Epoch: 21 | Iteration: 421 | Classification loss: 0.01666 | Regression loss: 0.13789 | Running loss: 0.19774\n",
      "Epoch: 21 | Iteration: 422 | Classification loss: 0.02678 | Regression loss: 0.18844 | Running loss: 0.19799\n",
      "Epoch: 21 | Iteration: 423 | Classification loss: 0.03164 | Regression loss: 0.12438 | Running loss: 0.19806\n",
      "Epoch: 21 | Iteration: 424 | Classification loss: 0.01210 | Regression loss: 0.10059 | Running loss: 0.19798\n",
      "Epoch: 21 | Iteration: 425 | Classification loss: 0.03725 | Regression loss: 0.17435 | Running loss: 0.19812\n",
      "Epoch: 21 | Iteration: 426 | Classification loss: 0.01650 | Regression loss: 0.13455 | Running loss: 0.19812\n",
      "Epoch: 21 | Iteration: 427 | Classification loss: 0.03610 | Regression loss: 0.23528 | Running loss: 0.19811\n",
      "Epoch: 21 | Iteration: 428 | Classification loss: 0.00964 | Regression loss: 0.05641 | Running loss: 0.19787\n",
      "Epoch: 21 | Iteration: 429 | Classification loss: 0.07820 | Regression loss: 0.29646 | Running loss: 0.19835\n",
      "Epoch: 21 | Iteration: 430 | Classification loss: 0.01841 | Regression loss: 0.15464 | Running loss: 0.19765\n",
      "Epoch: 21 | Iteration: 431 | Classification loss: 0.00654 | Regression loss: 0.11844 | Running loss: 0.19745\n",
      "Epoch: 21 | Iteration: 432 | Classification loss: 0.00859 | Regression loss: 0.15508 | Running loss: 0.19745\n",
      "Epoch: 21 | Iteration: 433 | Classification loss: 0.06081 | Regression loss: 0.19486 | Running loss: 0.19763\n",
      "Epoch: 21 | Iteration: 434 | Classification loss: 0.01083 | Regression loss: 0.23486 | Running loss: 0.19770\n",
      "Epoch: 21 | Iteration: 435 | Classification loss: 0.02787 | Regression loss: 0.10356 | Running loss: 0.19686\n",
      "Epoch: 21 | Iteration: 436 | Classification loss: 0.07679 | Regression loss: 0.35452 | Running loss: 0.19741\n",
      "Epoch: 21 | Iteration: 437 | Classification loss: 0.00387 | Regression loss: 0.12007 | Running loss: 0.19715\n",
      "Epoch: 21 | Iteration: 438 | Classification loss: 0.02860 | Regression loss: 0.10287 | Running loss: 0.19722\n",
      "Epoch: 21 | Iteration: 439 | Classification loss: 0.00622 | Regression loss: 0.05874 | Running loss: 0.19707\n",
      "Epoch: 21 | Iteration: 440 | Classification loss: 0.01367 | Regression loss: 0.17366 | Running loss: 0.19678\n",
      "Epoch: 21 | Iteration: 441 | Classification loss: 0.03819 | Regression loss: 0.19461 | Running loss: 0.19681\n",
      "Epoch: 21 | Iteration: 442 | Classification loss: 0.02070 | Regression loss: 0.10970 | Running loss: 0.19678\n",
      "Epoch: 21 | Iteration: 443 | Classification loss: 0.01232 | Regression loss: 0.06856 | Running loss: 0.19662\n",
      "Epoch: 21 | Iteration: 444 | Classification loss: 0.00719 | Regression loss: 0.08468 | Running loss: 0.19664\n",
      "Epoch: 21 | Iteration: 445 | Classification loss: 0.01753 | Regression loss: 0.18673 | Running loss: 0.19677\n",
      "Epoch: 21 | Iteration: 446 | Classification loss: 0.04696 | Regression loss: 0.19007 | Running loss: 0.19687\n",
      "Epoch: 21 | Iteration: 447 | Classification loss: 0.01109 | Regression loss: 0.15953 | Running loss: 0.19693\n",
      "Epoch: 21 | Iteration: 448 | Classification loss: 0.03176 | Regression loss: 0.22559 | Running loss: 0.19695\n",
      "Epoch: 21 | Iteration: 449 | Classification loss: 0.00704 | Regression loss: 0.12695 | Running loss: 0.19684\n",
      "Epoch: 21 | Iteration: 450 | Classification loss: 0.03846 | Regression loss: 0.21040 | Running loss: 0.19664\n",
      "Epoch: 21 | Iteration: 451 | Classification loss: 0.00762 | Regression loss: 0.14368 | Running loss: 0.19660\n",
      "Epoch: 21 | Iteration: 452 | Classification loss: 0.01912 | Regression loss: 0.16545 | Running loss: 0.19669\n",
      "Epoch: 21 | Iteration: 453 | Classification loss: 0.02592 | Regression loss: 0.15478 | Running loss: 0.19621\n",
      "Epoch: 21 | Iteration: 454 | Classification loss: 0.01629 | Regression loss: 0.16417 | Running loss: 0.19612\n",
      "Epoch: 21 | Iteration: 455 | Classification loss: 0.02349 | Regression loss: 0.28846 | Running loss: 0.19616\n",
      "Epoch: 21 | Iteration: 456 | Classification loss: 0.03846 | Regression loss: 0.28661 | Running loss: 0.19658\n",
      "Epoch: 21 | Iteration: 457 | Classification loss: 0.02134 | Regression loss: 0.21496 | Running loss: 0.19692\n",
      "Epoch: 21 | Iteration: 458 | Classification loss: 0.03191 | Regression loss: 0.18531 | Running loss: 0.19707\n",
      "Epoch: 21 | Iteration: 459 | Classification loss: 0.00848 | Regression loss: 0.13676 | Running loss: 0.19714\n",
      "Epoch: 21 | Iteration: 460 | Classification loss: 0.05493 | Regression loss: 0.15568 | Running loss: 0.19700\n",
      "Epoch: 21 | Iteration: 461 | Classification loss: 0.00984 | Regression loss: 0.09935 | Running loss: 0.19677\n",
      "Epoch: 21 | Iteration: 462 | Classification loss: 0.02299 | Regression loss: 0.13886 | Running loss: 0.19645\n",
      "Epoch: 21 | Iteration: 463 | Classification loss: 0.01336 | Regression loss: 0.16419 | Running loss: 0.19652\n",
      "Epoch: 21 | Iteration: 464 | Classification loss: 0.02872 | Regression loss: 0.12208 | Running loss: 0.19617\n",
      "Epoch: 21 | Iteration: 465 | Classification loss: 0.01033 | Regression loss: 0.10258 | Running loss: 0.19618\n",
      "Epoch: 21 | Iteration: 466 | Classification loss: 0.00896 | Regression loss: 0.05921 | Running loss: 0.19582\n",
      "Epoch: 21 | Iteration: 467 | Classification loss: 0.02736 | Regression loss: 0.12323 | Running loss: 0.19553\n",
      "Epoch: 21 | Iteration: 468 | Classification loss: 0.01357 | Regression loss: 0.09203 | Running loss: 0.19544\n",
      "Epoch: 21 | Iteration: 469 | Classification loss: 0.00705 | Regression loss: 0.15017 | Running loss: 0.19529\n",
      "Epoch: 21 | Iteration: 470 | Classification loss: 0.03226 | Regression loss: 0.15962 | Running loss: 0.19492\n",
      "Epoch: 21 | Iteration: 471 | Classification loss: 0.00904 | Regression loss: 0.18620 | Running loss: 0.19508\n",
      "Epoch: 21 | Iteration: 472 | Classification loss: 0.03804 | Regression loss: 0.13744 | Running loss: 0.19512\n",
      "Epoch: 21 | Iteration: 473 | Classification loss: 0.01889 | Regression loss: 0.20100 | Running loss: 0.19459\n",
      "Epoch: 21 | Iteration: 474 | Classification loss: 0.01420 | Regression loss: 0.09022 | Running loss: 0.19439\n",
      "Epoch: 21 | Iteration: 475 | Classification loss: 0.00555 | Regression loss: 0.07139 | Running loss: 0.19401\n",
      "Epoch: 21 | Iteration: 476 | Classification loss: 0.00538 | Regression loss: 0.03952 | Running loss: 0.19359\n",
      "Epoch: 21 | Iteration: 477 | Classification loss: 0.00681 | Regression loss: 0.10921 | Running loss: 0.19322\n",
      "Epoch: 21 | Iteration: 478 | Classification loss: 0.04741 | Regression loss: 0.13997 | Running loss: 0.19301\n",
      "Epoch: 21 | Iteration: 479 | Classification loss: 0.00842 | Regression loss: 0.08180 | Running loss: 0.19286\n",
      "Epoch: 21 | Iteration: 480 | Classification loss: 0.07306 | Regression loss: 0.11084 | Running loss: 0.19278\n",
      "Epoch: 21 | Iteration: 481 | Classification loss: 0.00826 | Regression loss: 0.12031 | Running loss: 0.19258\n",
      "Epoch: 21 | Iteration: 482 | Classification loss: 0.00204 | Regression loss: 0.02458 | Running loss: 0.19228\n",
      "Epoch: 21 | Iteration: 483 | Classification loss: 0.05722 | Regression loss: 0.09811 | Running loss: 0.19235\n",
      "Epoch: 21 | Iteration: 484 | Classification loss: 0.01179 | Regression loss: 0.12563 | Running loss: 0.19192\n",
      "Epoch: 21 | Iteration: 485 | Classification loss: 0.04428 | Regression loss: 0.19553 | Running loss: 0.19216\n",
      "Epoch: 21 | Iteration: 486 | Classification loss: 0.00162 | Regression loss: 0.08301 | Running loss: 0.19217\n",
      "Epoch: 21 | Iteration: 487 | Classification loss: 0.04513 | Regression loss: 0.19485 | Running loss: 0.19240\n",
      "Epoch: 21 | Iteration: 488 | Classification loss: 0.01522 | Regression loss: 0.13752 | Running loss: 0.19248\n",
      "Epoch: 21 | Iteration: 489 | Classification loss: 0.01755 | Regression loss: 0.13570 | Running loss: 0.19216\n",
      "Epoch: 21 | Iteration: 490 | Classification loss: 0.02278 | Regression loss: 0.20355 | Running loss: 0.19229\n",
      "Epoch: 21 | Iteration: 491 | Classification loss: 0.11873 | Regression loss: 0.24102 | Running loss: 0.19282\n",
      "Epoch: 21 | Iteration: 492 | Classification loss: 0.03472 | Regression loss: 0.19860 | Running loss: 0.19312\n",
      "Epoch: 21 | Iteration: 493 | Classification loss: 0.02429 | Regression loss: 0.15140 | Running loss: 0.19313\n",
      "Epoch: 21 | Iteration: 494 | Classification loss: 0.10010 | Regression loss: 0.23643 | Running loss: 0.19302\n",
      "Epoch: 21 | Iteration: 495 | Classification loss: 0.03775 | Regression loss: 0.18199 | Running loss: 0.19308\n",
      "Epoch: 21 | Iteration: 496 | Classification loss: 0.02078 | Regression loss: 0.13920 | Running loss: 0.19309\n",
      "Epoch: 21 | Iteration: 497 | Classification loss: 0.00386 | Regression loss: 0.07344 | Running loss: 0.19298\n",
      "Epoch: 21 | Iteration: 498 | Classification loss: 0.00869 | Regression loss: 0.12690 | Running loss: 0.19307\n",
      "Epoch: 21 | Iteration: 499 | Classification loss: 0.01501 | Regression loss: 0.19834 | Running loss: 0.19311\n",
      "Epoch: 21 | Iteration: 500 | Classification loss: 0.06377 | Regression loss: 0.28214 | Running loss: 0.19341\n",
      "Epoch: 21 | Iteration: 501 | Classification loss: 0.00738 | Regression loss: 0.08126 | Running loss: 0.19336\n",
      "Epoch: 21 | Iteration: 502 | Classification loss: 0.05656 | Regression loss: 0.25768 | Running loss: 0.19360\n",
      "Epoch: 21 | Iteration: 503 | Classification loss: 0.00828 | Regression loss: 0.10109 | Running loss: 0.19332\n",
      "Epoch: 21 | Iteration: 504 | Classification loss: 0.04944 | Regression loss: 0.18795 | Running loss: 0.19340\n",
      "Epoch: 21 | Iteration: 505 | Classification loss: 0.02315 | Regression loss: 0.23795 | Running loss: 0.19356\n",
      "Epoch: 21 | Iteration: 506 | Classification loss: 0.01499 | Regression loss: 0.25700 | Running loss: 0.19387\n",
      "Epoch: 21 | Iteration: 507 | Classification loss: 0.00643 | Regression loss: 0.06991 | Running loss: 0.19371\n",
      "Epoch: 21 | Iteration: 508 | Classification loss: 0.01369 | Regression loss: 0.08656 | Running loss: 0.19364\n",
      "Epoch: 21 | Iteration: 509 | Classification loss: 0.03399 | Regression loss: 0.21620 | Running loss: 0.19386\n",
      "Epoch: 21 | Iteration: 510 | Classification loss: 0.02304 | Regression loss: 0.20568 | Running loss: 0.19395\n",
      "Epoch: 21 | Iteration: 511 | Classification loss: 0.00842 | Regression loss: 0.12258 | Running loss: 0.19381\n",
      "Epoch: 21 | Iteration: 512 | Classification loss: 0.01387 | Regression loss: 0.13030 | Running loss: 0.19376\n",
      "Epoch: 21 | Iteration: 513 | Classification loss: 0.01338 | Regression loss: 0.18624 | Running loss: 0.19391\n",
      "Epoch: 21 | Iteration: 514 | Classification loss: 0.01233 | Regression loss: 0.21932 | Running loss: 0.19377\n",
      "Epoch: 21 | Iteration: 515 | Classification loss: 0.01576 | Regression loss: 0.19353 | Running loss: 0.19385\n",
      "Epoch: 21 | Iteration: 516 | Classification loss: 0.01619 | Regression loss: 0.09780 | Running loss: 0.19353\n",
      "Epoch: 21 | Iteration: 517 | Classification loss: 0.01469 | Regression loss: 0.15602 | Running loss: 0.19354\n",
      "Epoch: 21 | Iteration: 518 | Classification loss: 0.09222 | Regression loss: 0.15877 | Running loss: 0.19378\n",
      "Epoch: 21 | Iteration: 519 | Classification loss: 0.02279 | Regression loss: 0.11656 | Running loss: 0.19357\n",
      "Epoch: 21 | Iteration: 520 | Classification loss: 0.10459 | Regression loss: 0.29305 | Running loss: 0.19311\n",
      "Epoch: 21 | Iteration: 521 | Classification loss: 0.03807 | Regression loss: 0.25069 | Running loss: 0.19312\n",
      "Epoch: 21 | Iteration: 522 | Classification loss: 0.03042 | Regression loss: 0.19707 | Running loss: 0.19329\n",
      "Epoch: 21 | Iteration: 523 | Classification loss: 0.00726 | Regression loss: 0.07949 | Running loss: 0.19316\n",
      "Epoch: 21 | Iteration: 524 | Classification loss: 0.04831 | Regression loss: 0.15597 | Running loss: 0.19305\n",
      "Epoch: 21 | Iteration: 525 | Classification loss: 0.00937 | Regression loss: 0.08237 | Running loss: 0.19295\n",
      "Epoch: 21 | Iteration: 526 | Classification loss: 0.02123 | Regression loss: 0.05436 | Running loss: 0.19277\n",
      "Epoch: 21 | Iteration: 527 | Classification loss: 0.01648 | Regression loss: 0.11001 | Running loss: 0.19256\n",
      "Epoch: 21 | Iteration: 528 | Classification loss: 0.04240 | Regression loss: 0.08119 | Running loss: 0.19230\n",
      "Epoch: 21 | Iteration: 529 | Classification loss: 0.00925 | Regression loss: 0.10999 | Running loss: 0.19226\n",
      "Epoch: 21 | Iteration: 530 | Classification loss: 0.00380 | Regression loss: 0.09981 | Running loss: 0.19220\n",
      "Epoch: 21 | Iteration: 531 | Classification loss: 0.03003 | Regression loss: 0.11167 | Running loss: 0.19216\n",
      "Epoch: 21 | Iteration: 532 | Classification loss: 0.07113 | Regression loss: 0.14498 | Running loss: 0.19222\n",
      "Epoch: 21 | Iteration: 533 | Classification loss: 0.04129 | Regression loss: 0.13555 | Running loss: 0.19221\n",
      "Epoch: 21 | Iteration: 534 | Classification loss: 0.02631 | Regression loss: 0.11216 | Running loss: 0.19210\n",
      "Epoch: 21 | Iteration: 535 | Classification loss: 0.02599 | Regression loss: 0.11556 | Running loss: 0.19187\n",
      "Epoch: 21 | Iteration: 536 | Classification loss: 0.01627 | Regression loss: 0.11438 | Running loss: 0.19166\n",
      "Epoch: 21 | Iteration: 537 | Classification loss: 0.02071 | Regression loss: 0.08302 | Running loss: 0.19155\n",
      "Epoch: 21 | Iteration: 538 | Classification loss: 0.01458 | Regression loss: 0.11787 | Running loss: 0.19119\n",
      "Epoch: 21 | Iteration: 539 | Classification loss: 0.03577 | Regression loss: 0.17816 | Running loss: 0.19089\n",
      "Epoch: 21 | Iteration: 540 | Classification loss: 0.01527 | Regression loss: 0.14491 | Running loss: 0.19081\n",
      "Epoch: 21 | Iteration: 541 | Classification loss: 0.01282 | Regression loss: 0.18487 | Running loss: 0.19087\n",
      "Epoch: 21 | Iteration: 542 | Classification loss: 0.01035 | Regression loss: 0.12867 | Running loss: 0.19090\n",
      "Epoch: 21 | Iteration: 543 | Classification loss: 0.01787 | Regression loss: 0.12618 | Running loss: 0.19088\n",
      "Epoch: 21 | Iteration: 544 | Classification loss: 0.03245 | Regression loss: 0.20070 | Running loss: 0.19122\n",
      "Epoch: 21 | Iteration: 545 | Classification loss: 0.02161 | Regression loss: 0.13139 | Running loss: 0.19126\n",
      "Epoch: 21 | Iteration: 546 | Classification loss: 0.02198 | Regression loss: 0.13175 | Running loss: 0.19097\n",
      "Epoch: 21 | Iteration: 547 | Classification loss: 0.09314 | Regression loss: 0.32128 | Running loss: 0.19158\n",
      "Epoch: 21 | Iteration: 548 | Classification loss: 0.04056 | Regression loss: 0.24098 | Running loss: 0.19140\n",
      "Epoch: 21 | Iteration: 549 | Classification loss: 0.07772 | Regression loss: 0.34909 | Running loss: 0.19180\n",
      "Epoch: 21 | Iteration: 550 | Classification loss: 0.05606 | Regression loss: 0.18148 | Running loss: 0.19208\n",
      "Epoch: 21 | Iteration: 551 | Classification loss: 0.07082 | Regression loss: 0.23154 | Running loss: 0.19250\n",
      "Epoch: 21 | Iteration: 552 | Classification loss: 0.02145 | Regression loss: 0.15657 | Running loss: 0.19242\n",
      "Epoch: 21 | Iteration: 553 | Classification loss: 0.00484 | Regression loss: 0.05537 | Running loss: 0.19199\n",
      "Epoch: 21 | Iteration: 554 | Classification loss: 0.04795 | Regression loss: 0.16960 | Running loss: 0.19219\n",
      "Epoch: 21 | Iteration: 555 | Classification loss: 0.02049 | Regression loss: 0.15520 | Running loss: 0.19169\n",
      "Epoch: 21 | Iteration: 556 | Classification loss: 0.02069 | Regression loss: 0.11186 | Running loss: 0.19156\n",
      "Epoch: 21 | Iteration: 557 | Classification loss: 0.15700 | Regression loss: 0.08414 | Running loss: 0.19188\n",
      "Epoch: 21 | Iteration: 558 | Classification loss: 0.00949 | Regression loss: 0.08782 | Running loss: 0.19186\n",
      "Epoch: 21 | Iteration: 559 | Classification loss: 0.02546 | Regression loss: 0.18559 | Running loss: 0.19207\n",
      "Epoch: 21 | Iteration: 560 | Classification loss: 0.00930 | Regression loss: 0.08444 | Running loss: 0.19202\n",
      "Epoch: 21 | Iteration: 561 | Classification loss: 0.05164 | Regression loss: 0.15105 | Running loss: 0.19194\n",
      "Epoch: 21 | Iteration: 562 | Classification loss: 0.01709 | Regression loss: 0.18580 | Running loss: 0.19192\n",
      "Epoch: 21 | Iteration: 563 | Classification loss: 0.04634 | Regression loss: 0.10980 | Running loss: 0.19206\n",
      "Epoch: 21 | Iteration: 564 | Classification loss: 0.01226 | Regression loss: 0.11219 | Running loss: 0.19163\n",
      "Epoch: 21 | Iteration: 565 | Classification loss: 0.00822 | Regression loss: 0.08623 | Running loss: 0.19150\n",
      "Epoch: 21 | Iteration: 566 | Classification loss: 0.00441 | Regression loss: 0.07734 | Running loss: 0.19145\n",
      "Epoch: 21 | Iteration: 567 | Classification loss: 0.11549 | Regression loss: 0.19486 | Running loss: 0.19172\n",
      "Epoch: 21 | Iteration: 568 | Classification loss: 0.02340 | Regression loss: 0.12448 | Running loss: 0.19144\n",
      "Epoch: 21 | Iteration: 569 | Classification loss: 0.01025 | Regression loss: 0.05531 | Running loss: 0.19128\n",
      "Epoch: 21 | Iteration: 570 | Classification loss: 0.04131 | Regression loss: 0.13308 | Running loss: 0.19119\n",
      "Epoch: 21 | Iteration: 571 | Classification loss: 0.05265 | Regression loss: 0.12949 | Running loss: 0.19136\n",
      "Epoch: 21 | Iteration: 572 | Classification loss: 0.25015 | Regression loss: 0.45147 | Running loss: 0.19227\n",
      "Epoch: 21 | Iteration: 573 | Classification loss: 0.01284 | Regression loss: 0.10708 | Running loss: 0.19236\n",
      "Epoch: 21 | Iteration: 574 | Classification loss: 0.07055 | Regression loss: 0.10575 | Running loss: 0.19245\n",
      "Epoch: 21 | Iteration: 575 | Classification loss: 0.00630 | Regression loss: 0.09904 | Running loss: 0.19242\n",
      "Epoch: 21 | Iteration: 576 | Classification loss: 0.07353 | Regression loss: 0.28882 | Running loss: 0.19277\n",
      "Epoch: 21 | Iteration: 577 | Classification loss: 0.03245 | Regression loss: 0.15039 | Running loss: 0.19293\n",
      "Epoch: 21 | Iteration: 578 | Classification loss: 0.04436 | Regression loss: 0.09779 | Running loss: 0.19266\n",
      "Epoch: 21 | Iteration: 579 | Classification loss: 0.00720 | Regression loss: 0.08994 | Running loss: 0.19232\n",
      "Epoch: 21 | Iteration: 580 | Classification loss: 0.02130 | Regression loss: 0.09938 | Running loss: 0.19212\n",
      "Epoch: 21 | Iteration: 581 | Classification loss: 0.01003 | Regression loss: 0.18321 | Running loss: 0.19215\n",
      "Epoch: 21 | Iteration: 582 | Classification loss: 0.03900 | Regression loss: 0.12905 | Running loss: 0.19214\n",
      "Epoch: 21 | Iteration: 583 | Classification loss: 0.00862 | Regression loss: 0.05173 | Running loss: 0.19135\n",
      "Epoch: 21 | Iteration: 584 | Classification loss: 0.04350 | Regression loss: 0.22284 | Running loss: 0.19138\n",
      "Epoch: 21 | Iteration: 585 | Classification loss: 0.04739 | Regression loss: 0.17542 | Running loss: 0.19153\n",
      "Epoch: 21 | Iteration: 586 | Classification loss: 0.01296 | Regression loss: 0.07438 | Running loss: 0.19110\n",
      "Epoch: 21 | Iteration: 587 | Classification loss: 0.00677 | Regression loss: 0.12601 | Running loss: 0.19117\n",
      "Epoch: 21 | Iteration: 588 | Classification loss: 0.00469 | Regression loss: 0.10540 | Running loss: 0.19089\n",
      "Epoch: 21 | Iteration: 589 | Classification loss: 0.03323 | Regression loss: 0.20442 | Running loss: 0.19112\n",
      "Epoch: 21 | Iteration: 590 | Classification loss: 0.01983 | Regression loss: 0.17151 | Running loss: 0.19094\n",
      "Epoch: 21 | Iteration: 591 | Classification loss: 0.02942 | Regression loss: 0.20739 | Running loss: 0.19105\n",
      "Epoch: 21 | Iteration: 592 | Classification loss: 0.01308 | Regression loss: 0.10575 | Running loss: 0.19117\n",
      "Epoch: 21 | Iteration: 593 | Classification loss: 0.04422 | Regression loss: 0.11876 | Running loss: 0.19076\n",
      "Epoch: 21 | Iteration: 594 | Classification loss: 0.00421 | Regression loss: 0.15011 | Running loss: 0.19078\n",
      "Epoch: 21 | Iteration: 595 | Classification loss: 0.00909 | Regression loss: 0.06317 | Running loss: 0.19050\n",
      "Epoch: 21 | Iteration: 596 | Classification loss: 0.02417 | Regression loss: 0.22041 | Running loss: 0.19077\n",
      "Epoch: 21 | Iteration: 597 | Classification loss: 0.19735 | Regression loss: 0.37666 | Running loss: 0.19179\n",
      "Epoch: 21 | Iteration: 598 | Classification loss: 0.01325 | Regression loss: 0.17893 | Running loss: 0.19187\n",
      "Epoch: 21 | Iteration: 599 | Classification loss: 0.00901 | Regression loss: 0.11015 | Running loss: 0.19180\n",
      "Epoch: 21 | Iteration: 600 | Classification loss: 0.00643 | Regression loss: 0.08090 | Running loss: 0.19182\n",
      "Epoch: 21 | Iteration: 601 | Classification loss: 0.01826 | Regression loss: 0.14180 | Running loss: 0.19179\n",
      "Epoch: 21 | Iteration: 602 | Classification loss: 0.06659 | Regression loss: 0.29164 | Running loss: 0.19218\n",
      "Epoch: 21 | Iteration: 603 | Classification loss: 0.02198 | Regression loss: 0.16258 | Running loss: 0.19228\n",
      "Epoch: 21 | Iteration: 604 | Classification loss: 0.02419 | Regression loss: 0.13038 | Running loss: 0.19236\n",
      "Epoch: 21 | Iteration: 605 | Classification loss: 0.04587 | Regression loss: 0.15508 | Running loss: 0.19190\n",
      "Epoch: 21 | Iteration: 606 | Classification loss: 0.03534 | Regression loss: 0.10384 | Running loss: 0.19188\n",
      "Epoch: 21 | Iteration: 607 | Classification loss: 0.04307 | Regression loss: 0.20144 | Running loss: 0.19175\n",
      "Epoch: 21 | Iteration: 608 | Classification loss: 0.01726 | Regression loss: 0.14822 | Running loss: 0.19175\n",
      "Epoch: 21 | Iteration: 609 | Classification loss: 0.16362 | Regression loss: 0.07865 | Running loss: 0.19193\n",
      "Epoch: 21 | Iteration: 610 | Classification loss: 0.02769 | Regression loss: 0.15949 | Running loss: 0.19193\n",
      "Epoch: 21 | Iteration: 611 | Classification loss: 0.00429 | Regression loss: 0.22919 | Running loss: 0.19219\n",
      "Epoch: 21 | Iteration: 612 | Classification loss: 0.02434 | Regression loss: 0.19310 | Running loss: 0.19209\n",
      "Epoch: 21 | Iteration: 613 | Classification loss: 0.03324 | Regression loss: 0.13244 | Running loss: 0.19207\n",
      "Epoch: 21 | Iteration: 614 | Classification loss: 0.01507 | Regression loss: 0.13192 | Running loss: 0.19201\n",
      "Epoch: 21 | Iteration: 615 | Classification loss: 0.02208 | Regression loss: 0.17115 | Running loss: 0.19189\n",
      "Epoch: 21 | Iteration: 616 | Classification loss: 0.01501 | Regression loss: 0.11646 | Running loss: 0.19188\n",
      "Epoch: 21 | Iteration: 617 | Classification loss: 0.02062 | Regression loss: 0.23399 | Running loss: 0.19218\n",
      "Epoch: 21 | Iteration: 618 | Classification loss: 0.07276 | Regression loss: 0.20434 | Running loss: 0.19199\n",
      "Epoch: 21 | Iteration: 619 | Classification loss: 0.01890 | Regression loss: 0.09476 | Running loss: 0.19171\n",
      "Epoch: 21 | Iteration: 620 | Classification loss: 0.09871 | Regression loss: 0.28869 | Running loss: 0.19214\n",
      "Epoch: 21 | Iteration: 621 | Classification loss: 0.05801 | Regression loss: 0.16050 | Running loss: 0.19216\n",
      "Epoch: 21 | Iteration: 622 | Classification loss: 0.01792 | Regression loss: 0.12597 | Running loss: 0.19229\n",
      "Epoch: 21 | Iteration: 623 | Classification loss: 0.01001 | Regression loss: 0.17568 | Running loss: 0.19242\n",
      "Epoch: 21 | Iteration: 624 | Classification loss: 0.02374 | Regression loss: 0.17159 | Running loss: 0.19254\n",
      "Epoch: 21 | Iteration: 625 | Classification loss: 0.03755 | Regression loss: 0.20165 | Running loss: 0.19264\n",
      "Epoch: 21 | Iteration: 626 | Classification loss: 0.01539 | Regression loss: 0.25669 | Running loss: 0.19292\n",
      "Epoch: 21 | Iteration: 627 | Classification loss: 0.02444 | Regression loss: 0.17801 | Running loss: 0.19284\n",
      "Epoch: 21 | Iteration: 628 | Classification loss: 0.07303 | Regression loss: 0.23604 | Running loss: 0.19327\n",
      "Epoch: 21 | Iteration: 629 | Classification loss: 0.01542 | Regression loss: 0.18772 | Running loss: 0.19339\n",
      "Epoch: 21 | Iteration: 630 | Classification loss: 0.04154 | Regression loss: 0.14796 | Running loss: 0.19364\n",
      "Epoch: 21 | Iteration: 631 | Classification loss: 0.01694 | Regression loss: 0.14363 | Running loss: 0.19354\n",
      "Epoch: 21 | Iteration: 632 | Classification loss: 0.04364 | Regression loss: 0.21957 | Running loss: 0.19354\n",
      "Epoch: 21 | Iteration: 633 | Classification loss: 0.00755 | Regression loss: 0.12389 | Running loss: 0.19364\n",
      "Epoch: 21 | Iteration: 634 | Classification loss: 0.07481 | Regression loss: 0.23120 | Running loss: 0.19386\n",
      "Epoch: 21 | Iteration: 635 | Classification loss: 0.02745 | Regression loss: 0.11118 | Running loss: 0.19373\n",
      "Epoch: 21 | Iteration: 636 | Classification loss: 0.06405 | Regression loss: 0.22208 | Running loss: 0.19381\n",
      "Epoch: 21 | Iteration: 637 | Classification loss: 0.01419 | Regression loss: 0.05262 | Running loss: 0.19322\n",
      "Epoch: 21 | Iteration: 638 | Classification loss: 0.02107 | Regression loss: 0.13501 | Running loss: 0.19291\n",
      "Epoch: 21 | Iteration: 639 | Classification loss: 0.06288 | Regression loss: 0.21210 | Running loss: 0.19306\n",
      "Epoch: 21 | Iteration: 640 | Classification loss: 0.01543 | Regression loss: 0.09772 | Running loss: 0.19289\n",
      "Epoch: 21 | Iteration: 641 | Classification loss: 0.00894 | Regression loss: 0.15749 | Running loss: 0.19106\n",
      "Epoch: 21 | Iteration: 642 | Classification loss: 0.00673 | Regression loss: 0.09696 | Running loss: 0.19093\n",
      "Epoch: 21 | Iteration: 643 | Classification loss: 0.02939 | Regression loss: 0.20854 | Running loss: 0.19081\n",
      "Epoch: 21 | Iteration: 644 | Classification loss: 0.03996 | Regression loss: 0.16448 | Running loss: 0.19100\n",
      "Epoch: 21 | Iteration: 645 | Classification loss: 0.01619 | Regression loss: 0.21363 | Running loss: 0.19107\n",
      "Epoch: 21 | Iteration: 646 | Classification loss: 0.02019 | Regression loss: 0.19775 | Running loss: 0.19072\n",
      "Epoch: 21 | Iteration: 647 | Classification loss: 0.13913 | Regression loss: 0.28062 | Running loss: 0.19129\n",
      "Epoch: 21 | Iteration: 648 | Classification loss: 0.05856 | Regression loss: 0.20843 | Running loss: 0.19159\n",
      "Epoch: 21 | Iteration: 649 | Classification loss: 0.07644 | Regression loss: 0.24756 | Running loss: 0.19204\n",
      "Epoch: 21 | Iteration: 650 | Classification loss: 0.03989 | Regression loss: 0.13047 | Running loss: 0.19218\n",
      "Epoch: 21 | Iteration: 651 | Classification loss: 0.04278 | Regression loss: 0.20813 | Running loss: 0.19199\n",
      "Epoch: 21 | Iteration: 652 | Classification loss: 0.04126 | Regression loss: 0.24380 | Running loss: 0.19190\n",
      "Epoch: 21 | Iteration: 653 | Classification loss: 0.01398 | Regression loss: 0.10792 | Running loss: 0.19180\n",
      "Epoch: 21 | Iteration: 654 | Classification loss: 0.05243 | Regression loss: 0.18239 | Running loss: 0.19197\n",
      "Epoch: 21 | Iteration: 655 | Classification loss: 0.01362 | Regression loss: 0.09224 | Running loss: 0.19150\n",
      "Epoch: 21 | Iteration: 656 | Classification loss: 0.05265 | Regression loss: 0.18924 | Running loss: 0.19178\n",
      "Epoch: 21 | Iteration: 657 | Classification loss: 0.02071 | Regression loss: 0.11769 | Running loss: 0.19179\n",
      "Epoch: 21 | Iteration: 658 | Classification loss: 0.01115 | Regression loss: 0.17872 | Running loss: 0.19166\n",
      "Epoch: 21 | Iteration: 659 | Classification loss: 0.00871 | Regression loss: 0.09045 | Running loss: 0.19146\n",
      "Epoch: 21 | Iteration: 660 | Classification loss: 0.01908 | Regression loss: 0.11939 | Running loss: 0.19141\n",
      "Epoch: 21 | Iteration: 661 | Classification loss: 0.00756 | Regression loss: 0.11533 | Running loss: 0.19151\n",
      "Epoch: 21 | Iteration: 662 | Classification loss: 0.00792 | Regression loss: 0.09452 | Running loss: 0.19124\n",
      "Epoch: 21 | Iteration: 663 | Classification loss: 0.02275 | Regression loss: 0.10885 | Running loss: 0.19125\n",
      "Epoch: 21 | Iteration: 664 | Classification loss: 0.00851 | Regression loss: 0.06339 | Running loss: 0.19114\n",
      "Epoch: 21 | Iteration: 665 | Classification loss: 0.01476 | Regression loss: 0.13484 | Running loss: 0.19117\n",
      "Epoch: 21 | Iteration: 666 | Classification loss: 0.08766 | Regression loss: 0.15930 | Running loss: 0.19072\n",
      "Epoch: 21 | Iteration: 667 | Classification loss: 0.00901 | Regression loss: 0.10657 | Running loss: 0.19031\n",
      "Epoch: 21 | Iteration: 668 | Classification loss: 0.02957 | Regression loss: 0.11987 | Running loss: 0.19021\n",
      "Epoch: 21 | Iteration: 669 | Classification loss: 0.01271 | Regression loss: 0.17277 | Running loss: 0.19018\n",
      "Epoch: 21 | Iteration: 670 | Classification loss: 0.00861 | Regression loss: 0.13225 | Running loss: 0.18966\n",
      "Epoch: 21 | Iteration: 671 | Classification loss: 0.06256 | Regression loss: 0.25670 | Running loss: 0.18984\n",
      "Epoch: 21 | Iteration: 672 | Classification loss: 0.01300 | Regression loss: 0.09225 | Running loss: 0.18979\n",
      "Epoch: 21 | Iteration: 673 | Classification loss: 0.02587 | Regression loss: 0.07939 | Running loss: 0.18964\n",
      "Epoch: 21 | Iteration: 674 | Classification loss: 0.10399 | Regression loss: 0.10970 | Running loss: 0.18925\n",
      "Epoch: 21 | Iteration: 675 | Classification loss: 0.01972 | Regression loss: 0.11370 | Running loss: 0.18879\n",
      "Epoch: 21 | Iteration: 676 | Classification loss: 0.01828 | Regression loss: 0.16760 | Running loss: 0.18810\n",
      "Epoch: 21 | Iteration: 677 | Classification loss: 0.04845 | Regression loss: 0.19041 | Running loss: 0.18782\n",
      "Epoch: 21 | Iteration: 678 | Classification loss: 0.01011 | Regression loss: 0.10271 | Running loss: 0.18756\n",
      "Epoch: 21 | Iteration: 679 | Classification loss: 0.03027 | Regression loss: 0.31363 | Running loss: 0.18796\n",
      "Epoch: 21 | Iteration: 680 | Classification loss: 0.01113 | Regression loss: 0.13081 | Running loss: 0.18801\n",
      "Epoch: 21 | Iteration: 681 | Classification loss: 0.02142 | Regression loss: 0.13777 | Running loss: 0.18820\n",
      "Epoch: 21 | Iteration: 682 | Classification loss: 0.01220 | Regression loss: 0.12003 | Running loss: 0.18821\n",
      "Epoch: 21 | Iteration: 683 | Classification loss: 0.00320 | Regression loss: 0.07625 | Running loss: 0.18805\n",
      "Epoch: 21 | Iteration: 684 | Classification loss: 0.02432 | Regression loss: 0.19879 | Running loss: 0.18816\n",
      "Epoch: 21 | Iteration: 685 | Classification loss: 0.06469 | Regression loss: 0.21751 | Running loss: 0.18850\n",
      "Epoch: 21 | Iteration: 686 | Classification loss: 0.01088 | Regression loss: 0.06749 | Running loss: 0.18834\n",
      "Epoch: 21 | Iteration: 687 | Classification loss: 0.02456 | Regression loss: 0.13514 | Running loss: 0.18843\n",
      "Epoch: 21 | Iteration: 688 | Classification loss: 0.06669 | Regression loss: 0.07666 | Running loss: 0.18857\n",
      "Epoch: 21 | Iteration: 689 | Classification loss: 0.02683 | Regression loss: 0.09641 | Running loss: 0.18819\n",
      "Epoch: 21 | Iteration: 690 | Classification loss: 0.01856 | Regression loss: 0.38482 | Running loss: 0.18806\n",
      "Epoch: 21 | Iteration: 691 | Classification loss: 0.02780 | Regression loss: 0.20199 | Running loss: 0.18807\n",
      "Epoch: 21 | Iteration: 692 | Classification loss: 0.00639 | Regression loss: 0.16963 | Running loss: 0.18778\n",
      "Epoch: 21 | Iteration: 693 | Classification loss: 0.03712 | Regression loss: 0.23015 | Running loss: 0.18810\n",
      "Epoch: 21 | Iteration: 694 | Classification loss: 0.01565 | Regression loss: 0.14837 | Running loss: 0.18787\n",
      "Epoch: 21 | Iteration: 695 | Classification loss: 0.01220 | Regression loss: 0.03739 | Running loss: 0.18770\n",
      "Epoch: 21 | Iteration: 696 | Classification loss: 0.12563 | Regression loss: 0.34075 | Running loss: 0.18800\n",
      "Epoch: 21 | Iteration: 697 | Classification loss: 0.03364 | Regression loss: 0.21177 | Running loss: 0.18815\n",
      "Epoch: 21 | Iteration: 698 | Classification loss: 0.03064 | Regression loss: 0.11151 | Running loss: 0.18802\n",
      "Epoch: 21 | Iteration: 699 | Classification loss: 0.02097 | Regression loss: 0.10960 | Running loss: 0.18828\n",
      "Epoch: 21 | Iteration: 700 | Classification loss: 0.00863 | Regression loss: 0.10198 | Running loss: 0.18798\n",
      "Epoch: 21 | Iteration: 701 | Classification loss: 0.01427 | Regression loss: 0.11019 | Running loss: 0.18783\n",
      "Epoch: 21 | Iteration: 702 | Classification loss: 0.00622 | Regression loss: 0.05768 | Running loss: 0.18776\n",
      "Epoch: 21 | Iteration: 703 | Classification loss: 0.01059 | Regression loss: 0.12511 | Running loss: 0.18771\n",
      "Epoch: 21 | Iteration: 704 | Classification loss: 0.00956 | Regression loss: 0.08337 | Running loss: 0.18747\n",
      "Epoch: 21 | Iteration: 705 | Classification loss: 0.05791 | Regression loss: 0.35665 | Running loss: 0.18807\n",
      "Epoch: 21 | Iteration: 706 | Classification loss: 0.01219 | Regression loss: 0.11843 | Running loss: 0.18810\n",
      "Epoch: 21 | Iteration: 707 | Classification loss: 0.00514 | Regression loss: 0.08238 | Running loss: 0.18748\n",
      "Epoch: 21 | Iteration: 708 | Classification loss: 0.02421 | Regression loss: 0.20212 | Running loss: 0.18743\n",
      "Epoch: 21 | Iteration: 709 | Classification loss: 0.12288 | Regression loss: 0.11623 | Running loss: 0.18742\n",
      "Epoch: 21 | Iteration: 710 | Classification loss: 0.02519 | Regression loss: 0.09943 | Running loss: 0.18680\n",
      "Epoch: 21 | Iteration: 711 | Classification loss: 0.01470 | Regression loss: 0.13759 | Running loss: 0.18664\n",
      "Epoch: 21 | Iteration: 712 | Classification loss: 0.04429 | Regression loss: 0.14715 | Running loss: 0.18615\n",
      "Epoch: 21 | Iteration: 713 | Classification loss: 0.03754 | Regression loss: 0.21097 | Running loss: 0.18624\n",
      "Epoch: 21 | Iteration: 714 | Classification loss: 0.05577 | Regression loss: 0.17780 | Running loss: 0.18645\n",
      "Epoch: 21 | Iteration: 715 | Classification loss: 0.08032 | Regression loss: 0.22498 | Running loss: 0.18668\n",
      "Epoch: 21 | Iteration: 716 | Classification loss: 0.05072 | Regression loss: 0.23785 | Running loss: 0.18651\n",
      "Epoch: 21 | Iteration: 717 | Classification loss: 0.02942 | Regression loss: 0.15190 | Running loss: 0.18677\n",
      "Epoch: 21 | Iteration: 718 | Classification loss: 0.01560 | Regression loss: 0.09188 | Running loss: 0.18652\n",
      "Epoch: 21 | Iteration: 719 | Classification loss: 0.04271 | Regression loss: 0.14005 | Running loss: 0.18602\n",
      "Epoch: 21 | Iteration: 720 | Classification loss: 0.01179 | Regression loss: 0.17976 | Running loss: 0.18593\n",
      "Epoch: 21 | Iteration: 721 | Classification loss: 0.01043 | Regression loss: 0.11414 | Running loss: 0.18576\n",
      "Epoch: 21 | Iteration: 722 | Classification loss: 0.02361 | Regression loss: 0.14784 | Running loss: 0.18552\n",
      "Epoch: 21 | Iteration: 723 | Classification loss: 0.03629 | Regression loss: 0.15724 | Running loss: 0.18536\n",
      "Epoch: 21 | Iteration: 724 | Classification loss: 0.20746 | Regression loss: 0.10441 | Running loss: 0.18578\n",
      "Epoch: 21 | Iteration: 725 | Classification loss: 0.00715 | Regression loss: 0.11638 | Running loss: 0.18567\n",
      "Epoch: 21 | Iteration: 726 | Classification loss: 0.02507 | Regression loss: 0.12518 | Running loss: 0.18547\n",
      "Epoch: 21 | Iteration: 727 | Classification loss: 0.02499 | Regression loss: 0.16401 | Running loss: 0.18553\n",
      "Epoch: 21 | Iteration: 728 | Classification loss: 0.02777 | Regression loss: 0.12539 | Running loss: 0.18525\n",
      "Epoch: 21 | Iteration: 729 | Classification loss: 0.03400 | Regression loss: 0.19867 | Running loss: 0.18521\n",
      "Epoch: 21 | Iteration: 730 | Classification loss: 0.07845 | Regression loss: 0.19191 | Running loss: 0.18563\n",
      "Epoch: 21 | Iteration: 731 | Classification loss: 0.02798 | Regression loss: 0.23678 | Running loss: 0.18577\n",
      "Epoch: 21 | Iteration: 732 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.18528\n",
      "Epoch: 21 | Iteration: 733 | Classification loss: 0.03186 | Regression loss: 0.15653 | Running loss: 0.18524\n",
      "Epoch: 21 | Iteration: 734 | Classification loss: 0.05340 | Regression loss: 0.17752 | Running loss: 0.18541\n",
      "Epoch: 21 | Iteration: 735 | Classification loss: 0.00786 | Regression loss: 0.09174 | Running loss: 0.18505\n",
      "Epoch: 21 | Iteration: 736 | Classification loss: 0.10028 | Regression loss: 0.28882 | Running loss: 0.18557\n",
      "Epoch: 21 | Iteration: 737 | Classification loss: 0.09777 | Regression loss: 0.27138 | Running loss: 0.18594\n",
      "Epoch: 21 | Iteration: 738 | Classification loss: 0.05062 | Regression loss: 0.17852 | Running loss: 0.18619\n",
      "Epoch: 21 | Iteration: 739 | Classification loss: 0.05732 | Regression loss: 0.14475 | Running loss: 0.18636\n",
      "Epoch: 21 | Iteration: 740 | Classification loss: 0.04153 | Regression loss: 0.13514 | Running loss: 0.18625\n",
      "Epoch: 21 | Iteration: 741 | Classification loss: 0.02412 | Regression loss: 0.11255 | Running loss: 0.18625\n",
      "Epoch: 21 | Iteration: 742 | Classification loss: 0.04341 | Regression loss: 0.25802 | Running loss: 0.18620\n",
      "Epoch: 21 | Iteration: 743 | Classification loss: 0.00907 | Regression loss: 0.14606 | Running loss: 0.18630\n",
      "Epoch: 21 | Iteration: 744 | Classification loss: 0.04874 | Regression loss: 0.24936 | Running loss: 0.18668\n",
      "Epoch: 21 | Iteration: 745 | Classification loss: 0.10284 | Regression loss: 0.11900 | Running loss: 0.18684\n",
      "Epoch: 21 | Iteration: 746 | Classification loss: 0.03973 | Regression loss: 0.27849 | Running loss: 0.18728\n",
      "Epoch: 21 | Iteration: 747 | Classification loss: 0.00994 | Regression loss: 0.14951 | Running loss: 0.18733\n",
      "Epoch: 21 | Iteration: 748 | Classification loss: 0.01594 | Regression loss: 0.18091 | Running loss: 0.18741\n",
      "Epoch: 21 | Iteration: 749 | Classification loss: 0.09147 | Regression loss: 0.32560 | Running loss: 0.18780\n",
      "Epoch: 21 | Iteration: 750 | Classification loss: 0.02589 | Regression loss: 0.10366 | Running loss: 0.18771\n",
      "Epoch: 21 | Iteration: 751 | Classification loss: 0.01334 | Regression loss: 0.15653 | Running loss: 0.18766\n",
      "Epoch: 21 | Iteration: 752 | Classification loss: 0.02525 | Regression loss: 0.13399 | Running loss: 0.18753\n",
      "Epoch: 21 | Iteration: 753 | Classification loss: 0.11854 | Regression loss: 0.16161 | Running loss: 0.18795\n",
      "Epoch: 21 | Iteration: 754 | Classification loss: 0.01518 | Regression loss: 0.09443 | Running loss: 0.18786\n",
      "Epoch: 21 | Iteration: 755 | Classification loss: 0.03755 | Regression loss: 0.15260 | Running loss: 0.18778\n",
      "Epoch: 21 | Iteration: 756 | Classification loss: 0.11771 | Regression loss: 0.30612 | Running loss: 0.18815\n",
      "Epoch: 21 | Iteration: 757 | Classification loss: 0.04279 | Regression loss: 0.24433 | Running loss: 0.18847\n",
      "Epoch: 21 | Iteration: 758 | Classification loss: 0.00515 | Regression loss: 0.13846 | Running loss: 0.18853\n",
      "Epoch: 21 | Iteration: 759 | Classification loss: 0.01302 | Regression loss: 0.19047 | Running loss: 0.18868\n",
      "Epoch: 21 | Iteration: 760 | Classification loss: 0.04277 | Regression loss: 0.19329 | Running loss: 0.18894\n",
      "Epoch: 21 | Iteration: 761 | Classification loss: 0.01422 | Regression loss: 0.25666 | Running loss: 0.18936\n",
      "Epoch: 21 | Iteration: 762 | Classification loss: 0.01963 | Regression loss: 0.21423 | Running loss: 0.18950\n",
      "Epoch: 21 | Iteration: 763 | Classification loss: 0.04892 | Regression loss: 0.19951 | Running loss: 0.18972\n",
      "Epoch: 21 | Iteration: 764 | Classification loss: 0.03407 | Regression loss: 0.17964 | Running loss: 0.18989\n",
      "Epoch: 21 | Iteration: 765 | Classification loss: 0.02399 | Regression loss: 0.16091 | Running loss: 0.18999\n",
      "Epoch: 21 | Iteration: 766 | Classification loss: 0.11374 | Regression loss: 0.34658 | Running loss: 0.19059\n",
      "Epoch: 21 | Iteration: 767 | Classification loss: 0.03491 | Regression loss: 0.11965 | Running loss: 0.19028\n",
      "Epoch: 21 | Iteration: 768 | Classification loss: 0.02296 | Regression loss: 0.06528 | Running loss: 0.19010\n",
      "Epoch: 21 | Iteration: 769 | Classification loss: 0.00918 | Regression loss: 0.13198 | Running loss: 0.19022\n",
      "Epoch: 21 | Iteration: 770 | Classification loss: 0.02426 | Regression loss: 0.27722 | Running loss: 0.19058\n",
      "Epoch: 21 | Iteration: 771 | Classification loss: 0.01455 | Regression loss: 0.13262 | Running loss: 0.19075\n",
      "Epoch: 21 | Iteration: 772 | Classification loss: 0.08678 | Regression loss: 0.22931 | Running loss: 0.19101\n",
      "Epoch: 21 | Iteration: 773 | Classification loss: 0.05095 | Regression loss: 0.12882 | Running loss: 0.19106\n",
      "Epoch: 21 | Iteration: 774 | Classification loss: 0.06216 | Regression loss: 0.21882 | Running loss: 0.19084\n",
      "Epoch: 21 | Iteration: 775 | Classification loss: 0.02218 | Regression loss: 0.13252 | Running loss: 0.19070\n",
      "Epoch: 21 | Iteration: 776 | Classification loss: 0.00887 | Regression loss: 0.16650 | Running loss: 0.19068\n",
      "Epoch: 21 | Iteration: 777 | Classification loss: 0.02100 | Regression loss: 0.13830 | Running loss: 0.19059\n",
      "Epoch: 21 | Iteration: 778 | Classification loss: 0.12224 | Regression loss: 0.27635 | Running loss: 0.19069\n",
      "Epoch: 21 | Iteration: 779 | Classification loss: 0.04751 | Regression loss: 0.15507 | Running loss: 0.19078\n",
      "Epoch: 21 | Iteration: 780 | Classification loss: 0.03422 | Regression loss: 0.17954 | Running loss: 0.19076\n",
      "Epoch: 21 | Iteration: 781 | Classification loss: 0.01204 | Regression loss: 0.12057 | Running loss: 0.19091\n",
      "Epoch: 21 | Iteration: 782 | Classification loss: 0.02172 | Regression loss: 0.19749 | Running loss: 0.19108\n",
      "Epoch: 21 | Iteration: 783 | Classification loss: 0.05569 | Regression loss: 0.23719 | Running loss: 0.19081\n",
      "Epoch: 21 | Iteration: 784 | Classification loss: 0.04394 | Regression loss: 0.17304 | Running loss: 0.19086\n",
      "Epoch: 21 | Iteration: 785 | Classification loss: 0.11344 | Regression loss: 0.33812 | Running loss: 0.19146\n",
      "Epoch: 21 | Iteration: 786 | Classification loss: 0.01943 | Regression loss: 0.20459 | Running loss: 0.19109\n",
      "Epoch: 21 | Iteration: 787 | Classification loss: 0.01442 | Regression loss: 0.13579 | Running loss: 0.19112\n",
      "Epoch: 21 | Iteration: 788 | Classification loss: 0.01532 | Regression loss: 0.07137 | Running loss: 0.19096\n",
      "Epoch: 21 | Iteration: 789 | Classification loss: 0.01666 | Regression loss: 0.15738 | Running loss: 0.19109\n",
      "Epoch: 21 | Iteration: 790 | Classification loss: 0.01611 | Regression loss: 0.09944 | Running loss: 0.19108\n",
      "Epoch: 21 | Iteration: 791 | Classification loss: 0.07746 | Regression loss: 0.21190 | Running loss: 0.19124\n",
      "Epoch: 21 | Iteration: 792 | Classification loss: 0.05692 | Regression loss: 0.21715 | Running loss: 0.19153\n",
      "Epoch: 21 | Iteration: 793 | Classification loss: 0.05640 | Regression loss: 0.26481 | Running loss: 0.19135\n",
      "Epoch: 21 | Iteration: 794 | Classification loss: 0.00967 | Regression loss: 0.10308 | Running loss: 0.19132\n",
      "Epoch: 21 | Iteration: 795 | Classification loss: 0.01619 | Regression loss: 0.13154 | Running loss: 0.19122\n",
      "Epoch: 21 | Iteration: 796 | Classification loss: 0.06332 | Regression loss: 0.30835 | Running loss: 0.19170\n",
      "Epoch: 21 | Iteration: 797 | Classification loss: 0.06501 | Regression loss: 0.15676 | Running loss: 0.19160\n",
      "Epoch: 21 | Iteration: 798 | Classification loss: 0.01607 | Regression loss: 0.08348 | Running loss: 0.19131\n",
      "Epoch: 21 | Iteration: 799 | Classification loss: 0.10804 | Regression loss: 0.30475 | Running loss: 0.19182\n",
      "Epoch: 21 | Iteration: 800 | Classification loss: 0.06427 | Regression loss: 0.16391 | Running loss: 0.19189\n",
      "Epoch: 21 | Iteration: 801 | Classification loss: 0.02334 | Regression loss: 0.08289 | Running loss: 0.19166\n",
      "Epoch: 21 | Iteration: 802 | Classification loss: 0.02913 | Regression loss: 0.14125 | Running loss: 0.19137\n",
      "Epoch: 21 | Iteration: 803 | Classification loss: 0.01292 | Regression loss: 0.11284 | Running loss: 0.19138\n",
      "Epoch: 21 | Iteration: 804 | Classification loss: 0.01059 | Regression loss: 0.08040 | Running loss: 0.19132\n",
      "Epoch: 21 | Iteration: 805 | Classification loss: 0.00970 | Regression loss: 0.06123 | Running loss: 0.19122\n",
      "Epoch: 21 | Iteration: 806 | Classification loss: 0.10136 | Regression loss: 0.34447 | Running loss: 0.19192\n",
      "Epoch: 21 | Iteration: 807 | Classification loss: 0.02854 | Regression loss: 0.08593 | Running loss: 0.19151\n",
      "Epoch: 21 | Iteration: 808 | Classification loss: 0.01412 | Regression loss: 0.20712 | Running loss: 0.19137\n",
      "Epoch: 21 | Iteration: 809 | Classification loss: 0.03104 | Regression loss: 0.18014 | Running loss: 0.19093\n",
      "Epoch: 21 | Iteration: 810 | Classification loss: 0.04593 | Regression loss: 0.05470 | Running loss: 0.19085\n",
      "Epoch: 21 | Iteration: 811 | Classification loss: 0.05306 | Regression loss: 0.29493 | Running loss: 0.19137\n",
      "Epoch: 21 | Iteration: 812 | Classification loss: 0.06252 | Regression loss: 0.22362 | Running loss: 0.19167\n",
      "Epoch: 21 | Iteration: 813 | Classification loss: 0.00788 | Regression loss: 0.11060 | Running loss: 0.19155\n",
      "Epoch: 21 | Iteration: 814 | Classification loss: 0.04706 | Regression loss: 0.14971 | Running loss: 0.19161\n",
      "Epoch: 21 | Iteration: 815 | Classification loss: 0.00656 | Regression loss: 0.11203 | Running loss: 0.19148\n",
      "Epoch: 21 | Iteration: 816 | Classification loss: 0.02106 | Regression loss: 0.11220 | Running loss: 0.19153\n",
      "Epoch: 21 | Iteration: 817 | Classification loss: 0.02218 | Regression loss: 0.08463 | Running loss: 0.19144\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.593\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 22 | Iteration: 0 | Classification loss: 0.00522 | Regression loss: 0.05705 | Running loss: 0.19121\n",
      "Epoch: 22 | Iteration: 1 | Classification loss: 0.00541 | Regression loss: 0.06800 | Running loss: 0.19102\n",
      "Epoch: 22 | Iteration: 2 | Classification loss: 0.02341 | Regression loss: 0.18772 | Running loss: 0.19120\n",
      "Epoch: 22 | Iteration: 3 | Classification loss: 0.01270 | Regression loss: 0.19285 | Running loss: 0.19134\n",
      "Epoch: 22 | Iteration: 4 | Classification loss: 0.01523 | Regression loss: 0.13399 | Running loss: 0.19051\n",
      "Epoch: 22 | Iteration: 5 | Classification loss: 0.01652 | Regression loss: 0.10281 | Running loss: 0.19037\n",
      "Epoch: 22 | Iteration: 6 | Classification loss: 0.06955 | Regression loss: 0.11816 | Running loss: 0.19042\n",
      "Epoch: 22 | Iteration: 7 | Classification loss: 0.01311 | Regression loss: 0.17061 | Running loss: 0.19045\n",
      "Epoch: 22 | Iteration: 8 | Classification loss: 0.00329 | Regression loss: 0.05064 | Running loss: 0.19007\n",
      "Epoch: 22 | Iteration: 9 | Classification loss: 0.01874 | Regression loss: 0.17485 | Running loss: 0.18973\n",
      "Epoch: 22 | Iteration: 10 | Classification loss: 0.06172 | Regression loss: 0.11848 | Running loss: 0.18974\n",
      "Epoch: 22 | Iteration: 11 | Classification loss: 0.05535 | Regression loss: 0.20168 | Running loss: 0.18998\n",
      "Epoch: 22 | Iteration: 12 | Classification loss: 0.01257 | Regression loss: 0.08476 | Running loss: 0.18960\n",
      "Epoch: 22 | Iteration: 13 | Classification loss: 0.03337 | Regression loss: 0.22719 | Running loss: 0.18959\n",
      "Epoch: 22 | Iteration: 14 | Classification loss: 0.00605 | Regression loss: 0.08270 | Running loss: 0.18955\n",
      "Epoch: 22 | Iteration: 15 | Classification loss: 0.02956 | Regression loss: 0.18591 | Running loss: 0.18974\n",
      "Epoch: 22 | Iteration: 16 | Classification loss: 0.01180 | Regression loss: 0.13467 | Running loss: 0.18955\n",
      "Epoch: 22 | Iteration: 17 | Classification loss: 0.20247 | Regression loss: 0.18692 | Running loss: 0.18987\n",
      "Epoch: 22 | Iteration: 18 | Classification loss: 0.00855 | Regression loss: 0.17836 | Running loss: 0.18982\n",
      "Epoch: 22 | Iteration: 19 | Classification loss: 0.09158 | Regression loss: 0.39706 | Running loss: 0.19045\n",
      "Epoch: 22 | Iteration: 20 | Classification loss: 0.01969 | Regression loss: 0.16687 | Running loss: 0.19054\n",
      "Epoch: 22 | Iteration: 21 | Classification loss: 0.01996 | Regression loss: 0.11909 | Running loss: 0.19054\n",
      "Epoch: 22 | Iteration: 22 | Classification loss: 0.03768 | Regression loss: 0.22553 | Running loss: 0.19094\n",
      "Epoch: 22 | Iteration: 23 | Classification loss: 0.01126 | Regression loss: 0.12190 | Running loss: 0.19073\n",
      "Epoch: 22 | Iteration: 24 | Classification loss: 0.02887 | Regression loss: 0.16349 | Running loss: 0.19044\n",
      "Epoch: 22 | Iteration: 25 | Classification loss: 0.03132 | Regression loss: 0.19064 | Running loss: 0.19010\n",
      "Epoch: 22 | Iteration: 26 | Classification loss: 0.03547 | Regression loss: 0.09492 | Running loss: 0.19014\n",
      "Epoch: 22 | Iteration: 27 | Classification loss: 0.01977 | Regression loss: 0.14062 | Running loss: 0.18989\n",
      "Epoch: 22 | Iteration: 28 | Classification loss: 0.03690 | Regression loss: 0.24431 | Running loss: 0.19020\n",
      "Epoch: 22 | Iteration: 29 | Classification loss: 0.00798 | Regression loss: 0.15846 | Running loss: 0.19026\n",
      "Epoch: 22 | Iteration: 30 | Classification loss: 0.05415 | Regression loss: 0.15948 | Running loss: 0.19040\n",
      "Epoch: 22 | Iteration: 31 | Classification loss: 0.06241 | Regression loss: 0.20529 | Running loss: 0.19052\n",
      "Epoch: 22 | Iteration: 32 | Classification loss: 0.02169 | Regression loss: 0.16360 | Running loss: 0.19066\n",
      "Epoch: 22 | Iteration: 33 | Classification loss: 0.00656 | Regression loss: 0.10709 | Running loss: 0.19080\n",
      "Epoch: 22 | Iteration: 34 | Classification loss: 0.01761 | Regression loss: 0.20406 | Running loss: 0.19097\n",
      "Epoch: 22 | Iteration: 35 | Classification loss: 0.03465 | Regression loss: 0.18692 | Running loss: 0.19110\n",
      "Epoch: 22 | Iteration: 36 | Classification loss: 0.01378 | Regression loss: 0.13400 | Running loss: 0.19110\n",
      "Epoch: 22 | Iteration: 37 | Classification loss: 0.04952 | Regression loss: 0.17576 | Running loss: 0.19096\n",
      "Epoch: 22 | Iteration: 38 | Classification loss: 0.01497 | Regression loss: 0.12431 | Running loss: 0.19102\n",
      "Epoch: 22 | Iteration: 39 | Classification loss: 0.01946 | Regression loss: 0.16020 | Running loss: 0.19106\n",
      "Epoch: 22 | Iteration: 40 | Classification loss: 0.13936 | Regression loss: 0.08527 | Running loss: 0.19092\n",
      "Epoch: 22 | Iteration: 41 | Classification loss: 0.11080 | Regression loss: 0.34771 | Running loss: 0.19163\n",
      "Epoch: 22 | Iteration: 42 | Classification loss: 0.00828 | Regression loss: 0.10866 | Running loss: 0.19151\n",
      "Epoch: 22 | Iteration: 43 | Classification loss: 0.01131 | Regression loss: 0.13509 | Running loss: 0.19147\n",
      "Epoch: 22 | Iteration: 44 | Classification loss: 0.01293 | Regression loss: 0.11891 | Running loss: 0.19158\n",
      "Epoch: 22 | Iteration: 45 | Classification loss: 0.06579 | Regression loss: 0.38604 | Running loss: 0.19212\n",
      "Epoch: 22 | Iteration: 46 | Classification loss: 0.04327 | Regression loss: 0.08162 | Running loss: 0.19209\n",
      "Epoch: 22 | Iteration: 47 | Classification loss: 0.03806 | Regression loss: 0.16663 | Running loss: 0.19212\n",
      "Epoch: 22 | Iteration: 48 | Classification loss: 0.01240 | Regression loss: 0.08874 | Running loss: 0.19208\n",
      "Epoch: 22 | Iteration: 49 | Classification loss: 0.01279 | Regression loss: 0.10470 | Running loss: 0.19211\n",
      "Epoch: 22 | Iteration: 50 | Classification loss: 0.19175 | Regression loss: 0.19120 | Running loss: 0.19253\n",
      "Epoch: 22 | Iteration: 51 | Classification loss: 0.06253 | Regression loss: 0.24072 | Running loss: 0.19290\n",
      "Epoch: 22 | Iteration: 52 | Classification loss: 0.02147 | Regression loss: 0.14661 | Running loss: 0.19284\n",
      "Epoch: 22 | Iteration: 53 | Classification loss: 0.01453 | Regression loss: 0.13601 | Running loss: 0.19278\n",
      "Epoch: 22 | Iteration: 54 | Classification loss: 0.04327 | Regression loss: 0.14915 | Running loss: 0.19261\n",
      "Epoch: 22 | Iteration: 55 | Classification loss: 0.00983 | Regression loss: 0.15034 | Running loss: 0.19254\n",
      "Epoch: 22 | Iteration: 56 | Classification loss: 0.07603 | Regression loss: 0.30702 | Running loss: 0.19296\n",
      "Epoch: 22 | Iteration: 57 | Classification loss: 0.03592 | Regression loss: 0.21043 | Running loss: 0.19306\n",
      "Epoch: 22 | Iteration: 58 | Classification loss: 0.07735 | Regression loss: 0.10818 | Running loss: 0.19318\n",
      "Epoch: 22 | Iteration: 59 | Classification loss: 0.00718 | Regression loss: 0.06980 | Running loss: 0.19290\n",
      "Epoch: 22 | Iteration: 60 | Classification loss: 0.01258 | Regression loss: 0.12779 | Running loss: 0.19245\n",
      "Epoch: 22 | Iteration: 61 | Classification loss: 0.02347 | Regression loss: 0.13813 | Running loss: 0.19234\n",
      "Epoch: 22 | Iteration: 62 | Classification loss: 0.03011 | Regression loss: 0.16308 | Running loss: 0.19241\n",
      "Epoch: 22 | Iteration: 63 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.19194\n",
      "Epoch: 22 | Iteration: 64 | Classification loss: 0.05860 | Regression loss: 0.19844 | Running loss: 0.19217\n",
      "Epoch: 22 | Iteration: 65 | Classification loss: 0.02579 | Regression loss: 0.22538 | Running loss: 0.19225\n",
      "Epoch: 22 | Iteration: 66 | Classification loss: 0.00966 | Regression loss: 0.17807 | Running loss: 0.19161\n",
      "Epoch: 22 | Iteration: 67 | Classification loss: 0.00465 | Regression loss: 0.10149 | Running loss: 0.19154\n",
      "Epoch: 22 | Iteration: 68 | Classification loss: 0.01740 | Regression loss: 0.12637 | Running loss: 0.19151\n",
      "Epoch: 22 | Iteration: 69 | Classification loss: 0.02236 | Regression loss: 0.18198 | Running loss: 0.19165\n",
      "Epoch: 22 | Iteration: 70 | Classification loss: 0.06004 | Regression loss: 0.19394 | Running loss: 0.19193\n",
      "Epoch: 22 | Iteration: 71 | Classification loss: 0.04630 | Regression loss: 0.20344 | Running loss: 0.19195\n",
      "Epoch: 22 | Iteration: 72 | Classification loss: 0.02675 | Regression loss: 0.23386 | Running loss: 0.19213\n",
      "Epoch: 22 | Iteration: 73 | Classification loss: 0.01043 | Regression loss: 0.23348 | Running loss: 0.19226\n",
      "Epoch: 22 | Iteration: 74 | Classification loss: 0.02049 | Regression loss: 0.14325 | Running loss: 0.19236\n",
      "Epoch: 22 | Iteration: 75 | Classification loss: 0.02880 | Regression loss: 0.16838 | Running loss: 0.19237\n",
      "Epoch: 22 | Iteration: 76 | Classification loss: 0.00617 | Regression loss: 0.10074 | Running loss: 0.19242\n",
      "Epoch: 22 | Iteration: 77 | Classification loss: 0.01722 | Regression loss: 0.24002 | Running loss: 0.19271\n",
      "Epoch: 22 | Iteration: 78 | Classification loss: 0.05588 | Regression loss: 0.14017 | Running loss: 0.19285\n",
      "Epoch: 22 | Iteration: 79 | Classification loss: 0.01123 | Regression loss: 0.10419 | Running loss: 0.19269\n",
      "Epoch: 22 | Iteration: 80 | Classification loss: 0.00681 | Regression loss: 0.22424 | Running loss: 0.19249\n",
      "Epoch: 22 | Iteration: 81 | Classification loss: 0.01099 | Regression loss: 0.09576 | Running loss: 0.19233\n",
      "Epoch: 22 | Iteration: 82 | Classification loss: 0.01995 | Regression loss: 0.12803 | Running loss: 0.19240\n",
      "Epoch: 22 | Iteration: 83 | Classification loss: 0.03377 | Regression loss: 0.21209 | Running loss: 0.19265\n",
      "Epoch: 22 | Iteration: 84 | Classification loss: 0.01203 | Regression loss: 0.12544 | Running loss: 0.19252\n",
      "Epoch: 22 | Iteration: 85 | Classification loss: 0.01160 | Regression loss: 0.04013 | Running loss: 0.19170\n",
      "Epoch: 22 | Iteration: 86 | Classification loss: 0.02259 | Regression loss: 0.08559 | Running loss: 0.19179\n",
      "Epoch: 22 | Iteration: 87 | Classification loss: 0.18291 | Regression loss: 0.31090 | Running loss: 0.19238\n",
      "Epoch: 22 | Iteration: 88 | Classification loss: 0.01915 | Regression loss: 0.12673 | Running loss: 0.19191\n",
      "Epoch: 22 | Iteration: 89 | Classification loss: 0.01102 | Regression loss: 0.11232 | Running loss: 0.19189\n",
      "Epoch: 22 | Iteration: 90 | Classification loss: 0.06793 | Regression loss: 0.28593 | Running loss: 0.19220\n",
      "Epoch: 22 | Iteration: 91 | Classification loss: 0.02994 | Regression loss: 0.12185 | Running loss: 0.19218\n",
      "Epoch: 22 | Iteration: 92 | Classification loss: 0.00737 | Regression loss: 0.13701 | Running loss: 0.19227\n",
      "Epoch: 22 | Iteration: 93 | Classification loss: 0.01940 | Regression loss: 0.15236 | Running loss: 0.19199\n",
      "Epoch: 22 | Iteration: 94 | Classification loss: 0.00667 | Regression loss: 0.14621 | Running loss: 0.19204\n",
      "Epoch: 22 | Iteration: 95 | Classification loss: 0.01888 | Regression loss: 0.13888 | Running loss: 0.19177\n",
      "Epoch: 22 | Iteration: 96 | Classification loss: 0.01070 | Regression loss: 0.15066 | Running loss: 0.19184\n",
      "Epoch: 22 | Iteration: 97 | Classification loss: 0.07286 | Regression loss: 0.37059 | Running loss: 0.19250\n",
      "Epoch: 22 | Iteration: 98 | Classification loss: 0.01950 | Regression loss: 0.16589 | Running loss: 0.19275\n",
      "Epoch: 22 | Iteration: 99 | Classification loss: 0.04019 | Regression loss: 0.20070 | Running loss: 0.19304\n",
      "Epoch: 22 | Iteration: 100 | Classification loss: 0.05000 | Regression loss: 0.15272 | Running loss: 0.19311\n",
      "Epoch: 22 | Iteration: 101 | Classification loss: 0.02599 | Regression loss: 0.07889 | Running loss: 0.19313\n",
      "Epoch: 22 | Iteration: 102 | Classification loss: 0.00599 | Regression loss: 0.10475 | Running loss: 0.19281\n",
      "Epoch: 22 | Iteration: 103 | Classification loss: 0.03518 | Regression loss: 0.12194 | Running loss: 0.19282\n",
      "Epoch: 22 | Iteration: 104 | Classification loss: 0.19138 | Regression loss: 0.33339 | Running loss: 0.19344\n",
      "Epoch: 22 | Iteration: 105 | Classification loss: 0.02922 | Regression loss: 0.16852 | Running loss: 0.19352\n",
      "Epoch: 22 | Iteration: 106 | Classification loss: 0.01940 | Regression loss: 0.09722 | Running loss: 0.19353\n",
      "Epoch: 22 | Iteration: 107 | Classification loss: 0.03763 | Regression loss: 0.20260 | Running loss: 0.19358\n",
      "Epoch: 22 | Iteration: 108 | Classification loss: 0.00728 | Regression loss: 0.09698 | Running loss: 0.19349\n",
      "Epoch: 22 | Iteration: 109 | Classification loss: 0.01760 | Regression loss: 0.10498 | Running loss: 0.19319\n",
      "Epoch: 22 | Iteration: 110 | Classification loss: 0.03954 | Regression loss: 0.15765 | Running loss: 0.19346\n",
      "Epoch: 22 | Iteration: 111 | Classification loss: 0.04128 | Regression loss: 0.23406 | Running loss: 0.19326\n",
      "Epoch: 22 | Iteration: 112 | Classification loss: 0.01348 | Regression loss: 0.17246 | Running loss: 0.19328\n",
      "Epoch: 22 | Iteration: 113 | Classification loss: 0.06558 | Regression loss: 0.29001 | Running loss: 0.19374\n",
      "Epoch: 22 | Iteration: 114 | Classification loss: 0.00690 | Regression loss: 0.16352 | Running loss: 0.19376\n",
      "Epoch: 22 | Iteration: 115 | Classification loss: 0.01141 | Regression loss: 0.12748 | Running loss: 0.19352\n",
      "Epoch: 22 | Iteration: 116 | Classification loss: 0.00283 | Regression loss: 0.08223 | Running loss: 0.19320\n",
      "Epoch: 22 | Iteration: 117 | Classification loss: 0.01368 | Regression loss: 0.10617 | Running loss: 0.19318\n",
      "Epoch: 22 | Iteration: 118 | Classification loss: 0.00949 | Regression loss: 0.07896 | Running loss: 0.19249\n",
      "Epoch: 22 | Iteration: 119 | Classification loss: 0.00763 | Regression loss: 0.09033 | Running loss: 0.19244\n",
      "Epoch: 22 | Iteration: 120 | Classification loss: 0.01783 | Regression loss: 0.09449 | Running loss: 0.19240\n",
      "Epoch: 22 | Iteration: 121 | Classification loss: 0.02004 | Regression loss: 0.17282 | Running loss: 0.19266\n",
      "Epoch: 22 | Iteration: 122 | Classification loss: 0.03082 | Regression loss: 0.18224 | Running loss: 0.19271\n",
      "Epoch: 22 | Iteration: 123 | Classification loss: 0.04097 | Regression loss: 0.26212 | Running loss: 0.19285\n",
      "Epoch: 22 | Iteration: 124 | Classification loss: 0.00739 | Regression loss: 0.07401 | Running loss: 0.19275\n",
      "Epoch: 22 | Iteration: 125 | Classification loss: 0.00961 | Regression loss: 0.12936 | Running loss: 0.19287\n",
      "Epoch: 22 | Iteration: 126 | Classification loss: 0.01704 | Regression loss: 0.15665 | Running loss: 0.19303\n",
      "Epoch: 22 | Iteration: 127 | Classification loss: 0.00696 | Regression loss: 0.08397 | Running loss: 0.19281\n",
      "Epoch: 22 | Iteration: 128 | Classification loss: 0.04314 | Regression loss: 0.12038 | Running loss: 0.19266\n",
      "Epoch: 22 | Iteration: 129 | Classification loss: 0.01911 | Regression loss: 0.08166 | Running loss: 0.19252\n",
      "Epoch: 22 | Iteration: 130 | Classification loss: 0.01284 | Regression loss: 0.09386 | Running loss: 0.19222\n",
      "Epoch: 22 | Iteration: 131 | Classification loss: 0.02236 | Regression loss: 0.16161 | Running loss: 0.19232\n",
      "Epoch: 22 | Iteration: 132 | Classification loss: 0.00905 | Regression loss: 0.13675 | Running loss: 0.19211\n",
      "Epoch: 22 | Iteration: 133 | Classification loss: 0.00971 | Regression loss: 0.07534 | Running loss: 0.19198\n",
      "Epoch: 22 | Iteration: 134 | Classification loss: 0.05918 | Regression loss: 0.23771 | Running loss: 0.19220\n",
      "Epoch: 22 | Iteration: 135 | Classification loss: 0.01902 | Regression loss: 0.23625 | Running loss: 0.19235\n",
      "Epoch: 22 | Iteration: 136 | Classification loss: 0.05829 | Regression loss: 0.26061 | Running loss: 0.19263\n",
      "Epoch: 22 | Iteration: 137 | Classification loss: 0.03522 | Regression loss: 0.17277 | Running loss: 0.19242\n",
      "Epoch: 22 | Iteration: 138 | Classification loss: 0.01545 | Regression loss: 0.11500 | Running loss: 0.19203\n",
      "Epoch: 22 | Iteration: 139 | Classification loss: 0.00505 | Regression loss: 0.11433 | Running loss: 0.19180\n",
      "Epoch: 22 | Iteration: 140 | Classification loss: 0.01010 | Regression loss: 0.19132 | Running loss: 0.19177\n",
      "Epoch: 22 | Iteration: 141 | Classification loss: 0.02116 | Regression loss: 0.17019 | Running loss: 0.19186\n",
      "Epoch: 22 | Iteration: 142 | Classification loss: 0.04492 | Regression loss: 0.18992 | Running loss: 0.19191\n",
      "Epoch: 22 | Iteration: 143 | Classification loss: 0.00980 | Regression loss: 0.08590 | Running loss: 0.19188\n",
      "Epoch: 22 | Iteration: 144 | Classification loss: 0.02755 | Regression loss: 0.13077 | Running loss: 0.19187\n",
      "Epoch: 22 | Iteration: 145 | Classification loss: 0.06385 | Regression loss: 0.26673 | Running loss: 0.19218\n",
      "Epoch: 22 | Iteration: 146 | Classification loss: 0.01549 | Regression loss: 0.09891 | Running loss: 0.19211\n",
      "Epoch: 22 | Iteration: 147 | Classification loss: 0.03484 | Regression loss: 0.24248 | Running loss: 0.19244\n",
      "Epoch: 22 | Iteration: 148 | Classification loss: 0.03107 | Regression loss: 0.13211 | Running loss: 0.19263\n",
      "Epoch: 22 | Iteration: 149 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.19233\n",
      "Epoch: 22 | Iteration: 150 | Classification loss: 0.01450 | Regression loss: 0.15307 | Running loss: 0.19245\n",
      "Epoch: 22 | Iteration: 151 | Classification loss: 0.03485 | Regression loss: 0.19022 | Running loss: 0.19259\n",
      "Epoch: 22 | Iteration: 152 | Classification loss: 0.01643 | Regression loss: 0.05590 | Running loss: 0.19235\n",
      "Epoch: 22 | Iteration: 153 | Classification loss: 0.04742 | Regression loss: 0.25224 | Running loss: 0.19255\n",
      "Epoch: 22 | Iteration: 154 | Classification loss: 0.01824 | Regression loss: 0.11465 | Running loss: 0.19247\n",
      "Epoch: 22 | Iteration: 155 | Classification loss: 0.01351 | Regression loss: 0.12453 | Running loss: 0.19231\n",
      "Epoch: 22 | Iteration: 156 | Classification loss: 0.01240 | Regression loss: 0.06912 | Running loss: 0.19226\n",
      "Epoch: 22 | Iteration: 157 | Classification loss: 0.05254 | Regression loss: 0.29906 | Running loss: 0.19281\n",
      "Epoch: 22 | Iteration: 158 | Classification loss: 0.01992 | Regression loss: 0.14894 | Running loss: 0.19306\n",
      "Epoch: 22 | Iteration: 159 | Classification loss: 0.01388 | Regression loss: 0.12427 | Running loss: 0.19310\n",
      "Epoch: 22 | Iteration: 160 | Classification loss: 0.02207 | Regression loss: 0.15184 | Running loss: 0.19307\n",
      "Epoch: 22 | Iteration: 161 | Classification loss: 0.01023 | Regression loss: 0.06053 | Running loss: 0.19304\n",
      "Epoch: 22 | Iteration: 162 | Classification loss: 0.03286 | Regression loss: 0.15151 | Running loss: 0.19304\n",
      "Epoch: 22 | Iteration: 163 | Classification loss: 0.02238 | Regression loss: 0.18522 | Running loss: 0.19319\n",
      "Epoch: 22 | Iteration: 164 | Classification loss: 0.02113 | Regression loss: 0.16480 | Running loss: 0.19351\n",
      "Epoch: 22 | Iteration: 165 | Classification loss: 0.05917 | Regression loss: 0.14128 | Running loss: 0.19360\n",
      "Epoch: 22 | Iteration: 166 | Classification loss: 0.05252 | Regression loss: 0.16162 | Running loss: 0.19376\n",
      "Epoch: 22 | Iteration: 167 | Classification loss: 0.00924 | Regression loss: 0.16821 | Running loss: 0.19363\n",
      "Epoch: 22 | Iteration: 168 | Classification loss: 0.02203 | Regression loss: 0.22251 | Running loss: 0.19395\n",
      "Epoch: 22 | Iteration: 169 | Classification loss: 0.01814 | Regression loss: 0.15298 | Running loss: 0.19381\n",
      "Epoch: 22 | Iteration: 170 | Classification loss: 0.00779 | Regression loss: 0.10777 | Running loss: 0.19374\n",
      "Epoch: 22 | Iteration: 171 | Classification loss: 0.05517 | Regression loss: 0.23804 | Running loss: 0.19402\n",
      "Epoch: 22 | Iteration: 172 | Classification loss: 0.06489 | Regression loss: 0.24488 | Running loss: 0.19419\n",
      "Epoch: 22 | Iteration: 173 | Classification loss: 0.03762 | Regression loss: 0.22906 | Running loss: 0.19400\n",
      "Epoch: 22 | Iteration: 174 | Classification loss: 0.06436 | Regression loss: 0.13384 | Running loss: 0.19393\n",
      "Epoch: 22 | Iteration: 175 | Classification loss: 0.01602 | Regression loss: 0.13282 | Running loss: 0.19388\n",
      "Epoch: 22 | Iteration: 176 | Classification loss: 0.00776 | Regression loss: 0.14597 | Running loss: 0.19351\n",
      "Epoch: 22 | Iteration: 177 | Classification loss: 0.03013 | Regression loss: 0.10567 | Running loss: 0.19334\n",
      "Epoch: 22 | Iteration: 178 | Classification loss: 0.01653 | Regression loss: 0.09379 | Running loss: 0.19324\n",
      "Epoch: 22 | Iteration: 179 | Classification loss: 0.00702 | Regression loss: 0.15852 | Running loss: 0.19342\n",
      "Epoch: 22 | Iteration: 180 | Classification loss: 0.10073 | Regression loss: 0.38291 | Running loss: 0.19412\n",
      "Epoch: 22 | Iteration: 181 | Classification loss: 0.01067 | Regression loss: 0.09214 | Running loss: 0.19390\n",
      "Epoch: 22 | Iteration: 182 | Classification loss: 0.04479 | Regression loss: 0.20034 | Running loss: 0.19369\n",
      "Epoch: 22 | Iteration: 183 | Classification loss: 0.00945 | Regression loss: 0.09874 | Running loss: 0.19373\n",
      "Epoch: 22 | Iteration: 184 | Classification loss: 0.09420 | Regression loss: 0.37951 | Running loss: 0.19405\n",
      "Epoch: 22 | Iteration: 185 | Classification loss: 0.00686 | Regression loss: 0.07845 | Running loss: 0.19400\n",
      "Epoch: 22 | Iteration: 186 | Classification loss: 0.01414 | Regression loss: 0.24029 | Running loss: 0.19404\n",
      "Epoch: 22 | Iteration: 187 | Classification loss: 0.00758 | Regression loss: 0.07744 | Running loss: 0.19369\n",
      "Epoch: 22 | Iteration: 188 | Classification loss: 0.02485 | Regression loss: 0.15972 | Running loss: 0.19351\n",
      "Epoch: 22 | Iteration: 189 | Classification loss: 0.00387 | Regression loss: 0.09714 | Running loss: 0.19356\n",
      "Epoch: 22 | Iteration: 190 | Classification loss: 0.06424 | Regression loss: 0.32873 | Running loss: 0.19415\n",
      "Epoch: 22 | Iteration: 191 | Classification loss: 0.04341 | Regression loss: 0.10538 | Running loss: 0.19394\n",
      "Epoch: 22 | Iteration: 192 | Classification loss: 0.05424 | Regression loss: 0.20119 | Running loss: 0.19400\n",
      "Epoch: 22 | Iteration: 193 | Classification loss: 0.02620 | Regression loss: 0.21510 | Running loss: 0.19422\n",
      "Epoch: 22 | Iteration: 194 | Classification loss: 0.02260 | Regression loss: 0.16580 | Running loss: 0.19431\n",
      "Epoch: 22 | Iteration: 195 | Classification loss: 0.14395 | Regression loss: 0.36924 | Running loss: 0.19493\n",
      "Epoch: 22 | Iteration: 196 | Classification loss: 0.03304 | Regression loss: 0.18967 | Running loss: 0.19491\n",
      "Epoch: 22 | Iteration: 197 | Classification loss: 0.03261 | Regression loss: 0.11126 | Running loss: 0.19478\n",
      "Epoch: 22 | Iteration: 198 | Classification loss: 0.04756 | Regression loss: 0.16038 | Running loss: 0.19497\n",
      "Epoch: 22 | Iteration: 199 | Classification loss: 0.04156 | Regression loss: 0.10018 | Running loss: 0.19491\n",
      "Epoch: 22 | Iteration: 200 | Classification loss: 0.01580 | Regression loss: 0.13065 | Running loss: 0.19470\n",
      "Epoch: 22 | Iteration: 201 | Classification loss: 0.01097 | Regression loss: 0.12230 | Running loss: 0.19469\n",
      "Epoch: 22 | Iteration: 202 | Classification loss: 0.02854 | Regression loss: 0.15161 | Running loss: 0.19426\n",
      "Epoch: 22 | Iteration: 203 | Classification loss: 0.00675 | Regression loss: 0.10919 | Running loss: 0.19391\n",
      "Epoch: 22 | Iteration: 204 | Classification loss: 0.02134 | Regression loss: 0.21110 | Running loss: 0.19392\n",
      "Epoch: 22 | Iteration: 205 | Classification loss: 0.07713 | Regression loss: 0.22402 | Running loss: 0.19435\n",
      "Epoch: 22 | Iteration: 206 | Classification loss: 0.05894 | Regression loss: 0.33678 | Running loss: 0.19473\n",
      "Epoch: 22 | Iteration: 207 | Classification loss: 0.00216 | Regression loss: 0.08705 | Running loss: 0.19473\n",
      "Epoch: 22 | Iteration: 208 | Classification loss: 0.00261 | Regression loss: 0.10194 | Running loss: 0.19479\n",
      "Epoch: 22 | Iteration: 209 | Classification loss: 0.22129 | Regression loss: 0.17186 | Running loss: 0.19532\n",
      "Epoch: 22 | Iteration: 210 | Classification loss: 0.02250 | Regression loss: 0.11822 | Running loss: 0.19535\n",
      "Epoch: 22 | Iteration: 211 | Classification loss: 0.00902 | Regression loss: 0.15612 | Running loss: 0.19545\n",
      "Epoch: 22 | Iteration: 212 | Classification loss: 0.01941 | Regression loss: 0.13828 | Running loss: 0.19555\n",
      "Epoch: 22 | Iteration: 213 | Classification loss: 0.15252 | Regression loss: 0.15590 | Running loss: 0.19589\n",
      "Epoch: 22 | Iteration: 214 | Classification loss: 0.00643 | Regression loss: 0.09810 | Running loss: 0.19566\n",
      "Epoch: 22 | Iteration: 215 | Classification loss: 0.01869 | Regression loss: 0.13937 | Running loss: 0.19563\n",
      "Epoch: 22 | Iteration: 216 | Classification loss: 0.00373 | Regression loss: 0.03521 | Running loss: 0.19543\n",
      "Epoch: 22 | Iteration: 217 | Classification loss: 0.02195 | Regression loss: 0.11191 | Running loss: 0.19541\n",
      "Epoch: 22 | Iteration: 218 | Classification loss: 0.02851 | Regression loss: 0.11369 | Running loss: 0.19544\n",
      "Epoch: 22 | Iteration: 219 | Classification loss: 0.04205 | Regression loss: 0.40113 | Running loss: 0.19611\n",
      "Epoch: 22 | Iteration: 220 | Classification loss: 0.01522 | Regression loss: 0.17833 | Running loss: 0.19624\n",
      "Epoch: 22 | Iteration: 221 | Classification loss: 0.01419 | Regression loss: 0.22023 | Running loss: 0.19628\n",
      "Epoch: 22 | Iteration: 222 | Classification loss: 0.00762 | Regression loss: 0.07455 | Running loss: 0.19612\n",
      "Epoch: 22 | Iteration: 223 | Classification loss: 0.01924 | Regression loss: 0.19037 | Running loss: 0.19615\n",
      "Epoch: 22 | Iteration: 224 | Classification loss: 0.05554 | Regression loss: 0.10144 | Running loss: 0.19618\n",
      "Epoch: 22 | Iteration: 225 | Classification loss: 0.04282 | Regression loss: 0.22205 | Running loss: 0.19642\n",
      "Epoch: 22 | Iteration: 226 | Classification loss: 0.00822 | Regression loss: 0.12191 | Running loss: 0.19622\n",
      "Epoch: 22 | Iteration: 227 | Classification loss: 0.02573 | Regression loss: 0.10414 | Running loss: 0.19617\n",
      "Epoch: 22 | Iteration: 228 | Classification loss: 0.49824 | Regression loss: 0.27123 | Running loss: 0.19740\n",
      "Epoch: 22 | Iteration: 229 | Classification loss: 0.01226 | Regression loss: 0.13406 | Running loss: 0.19687\n",
      "Epoch: 22 | Iteration: 230 | Classification loss: 0.04361 | Regression loss: 0.23250 | Running loss: 0.19685\n",
      "Epoch: 22 | Iteration: 231 | Classification loss: 0.08079 | Regression loss: 0.19153 | Running loss: 0.19655\n",
      "Epoch: 22 | Iteration: 232 | Classification loss: 0.04201 | Regression loss: 0.11136 | Running loss: 0.19638\n",
      "Epoch: 22 | Iteration: 233 | Classification loss: 0.00763 | Regression loss: 0.08598 | Running loss: 0.19596\n",
      "Epoch: 22 | Iteration: 234 | Classification loss: 0.05748 | Regression loss: 0.28700 | Running loss: 0.19629\n",
      "Epoch: 22 | Iteration: 235 | Classification loss: 0.05301 | Regression loss: 0.08596 | Running loss: 0.19645\n",
      "Epoch: 22 | Iteration: 236 | Classification loss: 0.00823 | Regression loss: 0.09748 | Running loss: 0.19623\n",
      "Epoch: 22 | Iteration: 237 | Classification loss: 0.02146 | Regression loss: 0.16506 | Running loss: 0.19625\n",
      "Epoch: 22 | Iteration: 238 | Classification loss: 0.02266 | Regression loss: 0.22727 | Running loss: 0.19648\n",
      "Epoch: 22 | Iteration: 239 | Classification loss: 0.00953 | Regression loss: 0.14081 | Running loss: 0.19630\n",
      "Epoch: 22 | Iteration: 240 | Classification loss: 0.00473 | Regression loss: 0.09018 | Running loss: 0.19630\n",
      "Epoch: 22 | Iteration: 241 | Classification loss: 0.02529 | Regression loss: 0.14870 | Running loss: 0.19622\n",
      "Epoch: 22 | Iteration: 242 | Classification loss: 0.00981 | Regression loss: 0.08999 | Running loss: 0.19623\n",
      "Epoch: 22 | Iteration: 243 | Classification loss: 0.01032 | Regression loss: 0.08293 | Running loss: 0.19602\n",
      "Epoch: 22 | Iteration: 244 | Classification loss: 0.39330 | Regression loss: 0.10116 | Running loss: 0.19660\n",
      "Epoch: 22 | Iteration: 245 | Classification loss: 0.04515 | Regression loss: 0.09578 | Running loss: 0.19657\n",
      "Epoch: 22 | Iteration: 246 | Classification loss: 0.04932 | Regression loss: 0.15028 | Running loss: 0.19672\n",
      "Epoch: 22 | Iteration: 247 | Classification loss: 0.00494 | Regression loss: 0.06852 | Running loss: 0.19668\n",
      "Epoch: 22 | Iteration: 248 | Classification loss: 0.06550 | Regression loss: 0.19461 | Running loss: 0.19703\n",
      "Epoch: 22 | Iteration: 249 | Classification loss: 0.01449 | Regression loss: 0.13411 | Running loss: 0.19671\n",
      "Epoch: 22 | Iteration: 250 | Classification loss: 0.01522 | Regression loss: 0.16345 | Running loss: 0.19677\n",
      "Epoch: 22 | Iteration: 251 | Classification loss: 0.01598 | Regression loss: 0.13560 | Running loss: 0.19694\n",
      "Epoch: 22 | Iteration: 252 | Classification loss: 0.19812 | Regression loss: 0.25103 | Running loss: 0.19749\n",
      "Epoch: 22 | Iteration: 253 | Classification loss: 0.15467 | Regression loss: 0.19791 | Running loss: 0.19783\n",
      "Epoch: 22 | Iteration: 254 | Classification loss: 0.03126 | Regression loss: 0.07464 | Running loss: 0.19664\n",
      "Epoch: 22 | Iteration: 255 | Classification loss: 0.01152 | Regression loss: 0.09583 | Running loss: 0.19662\n",
      "Epoch: 22 | Iteration: 256 | Classification loss: 0.02767 | Regression loss: 0.13841 | Running loss: 0.19660\n",
      "Epoch: 22 | Iteration: 257 | Classification loss: 0.00814 | Regression loss: 0.12704 | Running loss: 0.19666\n",
      "Epoch: 22 | Iteration: 258 | Classification loss: 0.05080 | Regression loss: 0.15407 | Running loss: 0.19634\n",
      "Epoch: 22 | Iteration: 259 | Classification loss: 0.17291 | Regression loss: 0.16229 | Running loss: 0.19665\n",
      "Epoch: 22 | Iteration: 260 | Classification loss: 0.02222 | Regression loss: 0.17229 | Running loss: 0.19675\n",
      "Epoch: 22 | Iteration: 261 | Classification loss: 0.03310 | Regression loss: 0.15304 | Running loss: 0.19693\n",
      "Epoch: 22 | Iteration: 262 | Classification loss: 0.01846 | Regression loss: 0.07419 | Running loss: 0.19687\n",
      "Epoch: 22 | Iteration: 263 | Classification loss: 0.01601 | Regression loss: 0.13424 | Running loss: 0.19679\n",
      "Epoch: 22 | Iteration: 264 | Classification loss: 0.01567 | Regression loss: 0.17168 | Running loss: 0.19683\n",
      "Epoch: 22 | Iteration: 265 | Classification loss: 0.01455 | Regression loss: 0.09297 | Running loss: 0.19692\n",
      "Epoch: 22 | Iteration: 266 | Classification loss: 0.01255 | Regression loss: 0.16077 | Running loss: 0.19673\n",
      "Epoch: 22 | Iteration: 267 | Classification loss: 0.10540 | Regression loss: 0.11610 | Running loss: 0.19673\n",
      "Epoch: 22 | Iteration: 268 | Classification loss: 0.04638 | Regression loss: 0.15221 | Running loss: 0.19695\n",
      "Epoch: 22 | Iteration: 269 | Classification loss: 0.17740 | Regression loss: 0.26485 | Running loss: 0.19757\n",
      "Epoch: 22 | Iteration: 270 | Classification loss: 0.04142 | Regression loss: 0.20129 | Running loss: 0.19784\n",
      "Epoch: 22 | Iteration: 271 | Classification loss: 0.03222 | Regression loss: 0.14237 | Running loss: 0.19771\n",
      "Epoch: 22 | Iteration: 272 | Classification loss: 0.00810 | Regression loss: 0.04035 | Running loss: 0.19743\n",
      "Epoch: 22 | Iteration: 273 | Classification loss: 0.00649 | Regression loss: 0.14593 | Running loss: 0.19726\n",
      "Epoch: 22 | Iteration: 274 | Classification loss: 1.19584 | Regression loss: 0.13429 | Running loss: 0.19968\n",
      "Epoch: 22 | Iteration: 275 | Classification loss: 0.04864 | Regression loss: 0.07988 | Running loss: 0.19961\n",
      "Epoch: 22 | Iteration: 276 | Classification loss: 0.01205 | Regression loss: 0.13410 | Running loss: 0.19959\n",
      "Epoch: 22 | Iteration: 277 | Classification loss: 0.04061 | Regression loss: 0.08386 | Running loss: 0.19970\n",
      "Epoch: 22 | Iteration: 278 | Classification loss: 0.04117 | Regression loss: 0.15441 | Running loss: 0.19960\n",
      "Epoch: 22 | Iteration: 279 | Classification loss: 0.07381 | Regression loss: 0.18274 | Running loss: 0.19897\n",
      "Epoch: 22 | Iteration: 280 | Classification loss: 0.01245 | Regression loss: 0.09371 | Running loss: 0.19879\n",
      "Epoch: 22 | Iteration: 281 | Classification loss: 0.00937 | Regression loss: 0.15268 | Running loss: 0.19888\n",
      "Epoch: 22 | Iteration: 282 | Classification loss: 0.03212 | Regression loss: 0.15105 | Running loss: 0.19907\n",
      "Epoch: 22 | Iteration: 283 | Classification loss: 0.01417 | Regression loss: 0.16299 | Running loss: 0.19911\n",
      "Epoch: 22 | Iteration: 284 | Classification loss: 0.03648 | Regression loss: 0.11797 | Running loss: 0.19870\n",
      "Epoch: 22 | Iteration: 285 | Classification loss: 0.02948 | Regression loss: 0.18067 | Running loss: 0.19875\n",
      "Epoch: 22 | Iteration: 286 | Classification loss: 0.06950 | Regression loss: 0.11119 | Running loss: 0.19880\n",
      "Epoch: 22 | Iteration: 287 | Classification loss: 0.12397 | Regression loss: 0.13287 | Running loss: 0.19891\n",
      "Epoch: 22 | Iteration: 288 | Classification loss: 0.32225 | Regression loss: 0.13161 | Running loss: 0.19954\n",
      "Epoch: 22 | Iteration: 289 | Classification loss: 0.05307 | Regression loss: 0.19388 | Running loss: 0.19955\n",
      "Epoch: 22 | Iteration: 290 | Classification loss: 0.03321 | Regression loss: 0.18787 | Running loss: 0.19966\n",
      "Epoch: 22 | Iteration: 291 | Classification loss: 0.00814 | Regression loss: 0.15674 | Running loss: 0.19950\n",
      "Epoch: 22 | Iteration: 292 | Classification loss: 0.04510 | Regression loss: 0.13887 | Running loss: 0.19950\n",
      "Epoch: 22 | Iteration: 293 | Classification loss: 0.03307 | Regression loss: 0.21318 | Running loss: 0.19952\n",
      "Epoch: 22 | Iteration: 294 | Classification loss: 0.07686 | Regression loss: 0.25219 | Running loss: 0.19975\n",
      "Epoch: 22 | Iteration: 295 | Classification loss: 0.09848 | Regression loss: 0.09446 | Running loss: 0.19980\n",
      "Epoch: 22 | Iteration: 296 | Classification loss: 0.17747 | Regression loss: 0.13003 | Running loss: 0.20012\n",
      "Epoch: 22 | Iteration: 297 | Classification loss: 0.03020 | Regression loss: 0.08463 | Running loss: 0.19997\n",
      "Epoch: 22 | Iteration: 298 | Classification loss: 0.01260 | Regression loss: 0.10020 | Running loss: 0.19993\n",
      "Epoch: 22 | Iteration: 299 | Classification loss: 0.01284 | Regression loss: 0.12544 | Running loss: 0.19970\n",
      "Epoch: 22 | Iteration: 300 | Classification loss: 0.02386 | Regression loss: 0.16787 | Running loss: 0.19952\n",
      "Epoch: 22 | Iteration: 301 | Classification loss: 0.03118 | Regression loss: 0.10211 | Running loss: 0.19956\n",
      "Epoch: 22 | Iteration: 302 | Classification loss: 0.02329 | Regression loss: 0.11955 | Running loss: 0.19907\n",
      "Epoch: 22 | Iteration: 303 | Classification loss: 0.01588 | Regression loss: 0.13533 | Running loss: 0.19894\n",
      "Epoch: 22 | Iteration: 304 | Classification loss: 0.00593 | Regression loss: 0.10207 | Running loss: 0.19887\n",
      "Epoch: 22 | Iteration: 305 | Classification loss: 0.01187 | Regression loss: 0.07138 | Running loss: 0.19866\n",
      "Epoch: 22 | Iteration: 306 | Classification loss: 0.00854 | Regression loss: 0.11554 | Running loss: 0.19852\n",
      "Epoch: 22 | Iteration: 307 | Classification loss: 0.02357 | Regression loss: 0.08559 | Running loss: 0.19826\n",
      "Epoch: 22 | Iteration: 308 | Classification loss: 0.01145 | Regression loss: 0.14642 | Running loss: 0.19803\n",
      "Epoch: 22 | Iteration: 309 | Classification loss: 0.17985 | Regression loss: 0.31513 | Running loss: 0.19862\n",
      "Epoch: 22 | Iteration: 310 | Classification loss: 0.04091 | Regression loss: 0.16522 | Running loss: 0.19841\n",
      "Epoch: 22 | Iteration: 311 | Classification loss: 0.01459 | Regression loss: 0.13341 | Running loss: 0.19830\n",
      "Epoch: 22 | Iteration: 312 | Classification loss: 0.01965 | Regression loss: 0.09787 | Running loss: 0.19816\n",
      "Epoch: 22 | Iteration: 313 | Classification loss: 0.02782 | Regression loss: 0.18604 | Running loss: 0.19826\n",
      "Epoch: 22 | Iteration: 314 | Classification loss: 0.06136 | Regression loss: 0.22056 | Running loss: 0.19830\n",
      "Epoch: 22 | Iteration: 315 | Classification loss: 0.02640 | Regression loss: 0.22500 | Running loss: 0.19854\n",
      "Epoch: 22 | Iteration: 316 | Classification loss: 0.02160 | Regression loss: 0.23066 | Running loss: 0.19843\n",
      "Epoch: 22 | Iteration: 317 | Classification loss: 0.02897 | Regression loss: 0.20119 | Running loss: 0.19862\n",
      "Epoch: 22 | Iteration: 318 | Classification loss: 0.02011 | Regression loss: 0.18045 | Running loss: 0.19845\n",
      "Epoch: 22 | Iteration: 319 | Classification loss: 0.25704 | Regression loss: 0.14125 | Running loss: 0.19911\n",
      "Epoch: 22 | Iteration: 320 | Classification loss: 0.04322 | Regression loss: 0.22877 | Running loss: 0.19934\n",
      "Epoch: 22 | Iteration: 321 | Classification loss: 0.07083 | Regression loss: 0.09947 | Running loss: 0.19913\n",
      "Epoch: 22 | Iteration: 322 | Classification loss: 0.01878 | Regression loss: 0.20838 | Running loss: 0.19936\n",
      "Epoch: 22 | Iteration: 323 | Classification loss: 0.03646 | Regression loss: 0.20256 | Running loss: 0.19950\n",
      "Epoch: 22 | Iteration: 324 | Classification loss: 0.02778 | Regression loss: 0.20771 | Running loss: 0.19977\n",
      "Epoch: 22 | Iteration: 325 | Classification loss: 0.02904 | Regression loss: 0.16330 | Running loss: 0.19968\n",
      "Epoch: 22 | Iteration: 326 | Classification loss: 0.03620 | Regression loss: 0.17253 | Running loss: 0.19969\n",
      "Epoch: 22 | Iteration: 327 | Classification loss: 0.00529 | Regression loss: 0.08961 | Running loss: 0.19942\n",
      "Epoch: 22 | Iteration: 328 | Classification loss: 0.02357 | Regression loss: 0.14964 | Running loss: 0.19933\n",
      "Epoch: 22 | Iteration: 329 | Classification loss: 0.23114 | Regression loss: 0.37150 | Running loss: 0.19969\n",
      "Epoch: 22 | Iteration: 330 | Classification loss: 0.01116 | Regression loss: 0.18442 | Running loss: 0.19955\n",
      "Epoch: 22 | Iteration: 331 | Classification loss: 0.02231 | Regression loss: 0.13706 | Running loss: 0.19922\n",
      "Epoch: 22 | Iteration: 332 | Classification loss: 0.09268 | Regression loss: 0.14958 | Running loss: 0.19936\n",
      "Epoch: 22 | Iteration: 333 | Classification loss: 0.08007 | Regression loss: 0.34949 | Running loss: 0.19972\n",
      "Epoch: 22 | Iteration: 334 | Classification loss: 0.02520 | Regression loss: 0.11851 | Running loss: 0.19944\n",
      "Epoch: 22 | Iteration: 335 | Classification loss: 0.01885 | Regression loss: 0.04569 | Running loss: 0.19932\n",
      "Epoch: 22 | Iteration: 336 | Classification loss: 0.08190 | Regression loss: 0.27238 | Running loss: 0.19956\n",
      "Epoch: 22 | Iteration: 337 | Classification loss: 0.00939 | Regression loss: 0.08984 | Running loss: 0.19955\n",
      "Epoch: 22 | Iteration: 338 | Classification loss: 0.02507 | Regression loss: 0.09312 | Running loss: 0.19930\n",
      "Epoch: 22 | Iteration: 339 | Classification loss: 0.03202 | Regression loss: 0.19586 | Running loss: 0.19948\n",
      "Epoch: 22 | Iteration: 340 | Classification loss: 0.00599 | Regression loss: 0.09015 | Running loss: 0.19929\n",
      "Epoch: 22 | Iteration: 341 | Classification loss: 0.01193 | Regression loss: 0.13342 | Running loss: 0.19939\n",
      "Epoch: 22 | Iteration: 342 | Classification loss: 0.00396 | Regression loss: 0.09608 | Running loss: 0.19931\n",
      "Epoch: 22 | Iteration: 343 | Classification loss: 0.00393 | Regression loss: 0.08579 | Running loss: 0.19924\n",
      "Epoch: 22 | Iteration: 344 | Classification loss: 0.05111 | Regression loss: 0.19314 | Running loss: 0.19953\n",
      "Epoch: 22 | Iteration: 345 | Classification loss: 0.01046 | Regression loss: 0.10754 | Running loss: 0.19950\n",
      "Epoch: 22 | Iteration: 346 | Classification loss: 0.06787 | Regression loss: 0.24257 | Running loss: 0.19998\n",
      "Epoch: 22 | Iteration: 347 | Classification loss: 0.06735 | Regression loss: 0.17991 | Running loss: 0.20017\n",
      "Epoch: 22 | Iteration: 348 | Classification loss: 0.00737 | Regression loss: 0.11719 | Running loss: 0.19993\n",
      "Epoch: 22 | Iteration: 349 | Classification loss: 0.04984 | Regression loss: 0.11222 | Running loss: 0.20002\n",
      "Epoch: 22 | Iteration: 350 | Classification loss: 0.01679 | Regression loss: 0.20087 | Running loss: 0.20016\n",
      "Epoch: 22 | Iteration: 351 | Classification loss: 0.06990 | Regression loss: 0.05950 | Running loss: 0.20004\n",
      "Epoch: 22 | Iteration: 352 | Classification loss: 0.01048 | Regression loss: 0.09727 | Running loss: 0.19998\n",
      "Epoch: 22 | Iteration: 353 | Classification loss: 0.09604 | Regression loss: 0.23221 | Running loss: 0.20000\n",
      "Epoch: 22 | Iteration: 354 | Classification loss: 0.01422 | Regression loss: 0.07248 | Running loss: 0.19996\n",
      "Epoch: 22 | Iteration: 355 | Classification loss: 0.02823 | Regression loss: 0.19155 | Running loss: 0.20019\n",
      "Epoch: 22 | Iteration: 356 | Classification loss: 0.01891 | Regression loss: 0.06357 | Running loss: 0.19993\n",
      "Epoch: 22 | Iteration: 357 | Classification loss: 0.22076 | Regression loss: 0.43459 | Running loss: 0.20097\n",
      "Epoch: 22 | Iteration: 358 | Classification loss: 0.01281 | Regression loss: 0.14592 | Running loss: 0.20091\n",
      "Epoch: 22 | Iteration: 359 | Classification loss: 0.02599 | Regression loss: 0.19596 | Running loss: 0.20088\n",
      "Epoch: 22 | Iteration: 360 | Classification loss: 0.04584 | Regression loss: 0.14626 | Running loss: 0.20104\n",
      "Epoch: 22 | Iteration: 361 | Classification loss: 0.03042 | Regression loss: 0.22234 | Running loss: 0.20086\n",
      "Epoch: 22 | Iteration: 362 | Classification loss: 0.04122 | Regression loss: 0.22820 | Running loss: 0.20111\n",
      "Epoch: 22 | Iteration: 363 | Classification loss: 0.03024 | Regression loss: 0.09779 | Running loss: 0.20105\n",
      "Epoch: 22 | Iteration: 364 | Classification loss: 0.03868 | Regression loss: 0.12361 | Running loss: 0.20111\n",
      "Epoch: 22 | Iteration: 365 | Classification loss: 0.00364 | Regression loss: 0.15731 | Running loss: 0.20127\n",
      "Epoch: 22 | Iteration: 366 | Classification loss: 0.01145 | Regression loss: 0.07686 | Running loss: 0.20100\n",
      "Epoch: 22 | Iteration: 367 | Classification loss: 0.00956 | Regression loss: 0.08911 | Running loss: 0.20064\n",
      "Epoch: 22 | Iteration: 368 | Classification loss: 0.02694 | Regression loss: 0.22191 | Running loss: 0.20098\n",
      "Epoch: 22 | Iteration: 369 | Classification loss: 0.11177 | Regression loss: 0.29913 | Running loss: 0.20148\n",
      "Epoch: 22 | Iteration: 370 | Classification loss: 0.01532 | Regression loss: 0.08891 | Running loss: 0.20140\n",
      "Epoch: 22 | Iteration: 371 | Classification loss: 0.00798 | Regression loss: 0.08000 | Running loss: 0.20133\n",
      "Epoch: 22 | Iteration: 372 | Classification loss: 0.25595 | Regression loss: 0.50314 | Running loss: 0.20204\n",
      "Epoch: 22 | Iteration: 373 | Classification loss: 0.03019 | Regression loss: 0.13777 | Running loss: 0.20192\n",
      "Epoch: 22 | Iteration: 374 | Classification loss: 0.03849 | Regression loss: 0.20049 | Running loss: 0.20204\n",
      "Epoch: 22 | Iteration: 375 | Classification loss: 0.01298 | Regression loss: 0.08035 | Running loss: 0.20170\n",
      "Epoch: 22 | Iteration: 376 | Classification loss: 0.02236 | Regression loss: 0.17582 | Running loss: 0.20176\n",
      "Epoch: 22 | Iteration: 377 | Classification loss: 0.04930 | Regression loss: 0.24884 | Running loss: 0.20226\n",
      "Epoch: 22 | Iteration: 378 | Classification loss: 0.00828 | Regression loss: 0.12254 | Running loss: 0.20159\n",
      "Epoch: 22 | Iteration: 379 | Classification loss: 0.02472 | Regression loss: 0.13317 | Running loss: 0.20142\n",
      "Epoch: 22 | Iteration: 380 | Classification loss: 0.06804 | Regression loss: 0.16303 | Running loss: 0.20159\n",
      "Epoch: 22 | Iteration: 381 | Classification loss: 0.03086 | Regression loss: 0.17779 | Running loss: 0.20175\n",
      "Epoch: 22 | Iteration: 382 | Classification loss: 0.06470 | Regression loss: 0.20880 | Running loss: 0.20208\n",
      "Epoch: 22 | Iteration: 383 | Classification loss: 0.01536 | Regression loss: 0.10778 | Running loss: 0.20207\n",
      "Epoch: 22 | Iteration: 384 | Classification loss: 0.01721 | Regression loss: 0.12313 | Running loss: 0.20223\n",
      "Epoch: 22 | Iteration: 385 | Classification loss: 0.03429 | Regression loss: 0.16788 | Running loss: 0.20236\n",
      "Epoch: 22 | Iteration: 386 | Classification loss: 0.08122 | Regression loss: 0.15773 | Running loss: 0.20265\n",
      "Epoch: 22 | Iteration: 387 | Classification loss: 0.02857 | Regression loss: 0.07359 | Running loss: 0.20203\n",
      "Epoch: 22 | Iteration: 388 | Classification loss: 0.03284 | Regression loss: 0.08597 | Running loss: 0.20200\n",
      "Epoch: 22 | Iteration: 389 | Classification loss: 0.02343 | Regression loss: 0.09863 | Running loss: 0.20207\n",
      "Epoch: 22 | Iteration: 390 | Classification loss: 0.02699 | Regression loss: 0.12090 | Running loss: 0.20191\n",
      "Epoch: 22 | Iteration: 391 | Classification loss: 0.00452 | Regression loss: 0.08225 | Running loss: 0.20161\n",
      "Epoch: 22 | Iteration: 392 | Classification loss: 0.01654 | Regression loss: 0.18025 | Running loss: 0.20175\n",
      "Epoch: 22 | Iteration: 393 | Classification loss: 0.01107 | Regression loss: 0.08363 | Running loss: 0.20164\n",
      "Epoch: 22 | Iteration: 394 | Classification loss: 0.03606 | Regression loss: 0.21432 | Running loss: 0.20176\n",
      "Epoch: 22 | Iteration: 395 | Classification loss: 0.11602 | Regression loss: 0.13544 | Running loss: 0.20176\n",
      "Epoch: 22 | Iteration: 396 | Classification loss: 0.11095 | Regression loss: 0.34673 | Running loss: 0.20221\n",
      "Epoch: 22 | Iteration: 397 | Classification loss: 0.00761 | Regression loss: 0.08557 | Running loss: 0.20179\n",
      "Epoch: 22 | Iteration: 398 | Classification loss: 0.04642 | Regression loss: 0.11090 | Running loss: 0.20152\n",
      "Epoch: 22 | Iteration: 399 | Classification loss: 0.00563 | Regression loss: 0.08296 | Running loss: 0.20134\n",
      "Epoch: 22 | Iteration: 400 | Classification loss: 0.07892 | Regression loss: 0.30566 | Running loss: 0.20189\n",
      "Epoch: 22 | Iteration: 401 | Classification loss: 0.01744 | Regression loss: 0.09321 | Running loss: 0.20175\n",
      "Epoch: 22 | Iteration: 402 | Classification loss: 0.03135 | Regression loss: 0.20467 | Running loss: 0.20184\n",
      "Epoch: 22 | Iteration: 403 | Classification loss: 0.01974 | Regression loss: 0.14731 | Running loss: 0.20192\n",
      "Epoch: 22 | Iteration: 404 | Classification loss: 0.01090 | Regression loss: 0.17819 | Running loss: 0.20196\n",
      "Epoch: 22 | Iteration: 405 | Classification loss: 0.02050 | Regression loss: 0.12883 | Running loss: 0.20187\n",
      "Epoch: 22 | Iteration: 406 | Classification loss: 0.01786 | Regression loss: 0.12276 | Running loss: 0.20153\n",
      "Epoch: 22 | Iteration: 407 | Classification loss: 0.04030 | Regression loss: 0.10546 | Running loss: 0.20157\n",
      "Epoch: 22 | Iteration: 408 | Classification loss: 0.01310 | Regression loss: 0.18327 | Running loss: 0.20166\n",
      "Epoch: 22 | Iteration: 409 | Classification loss: 0.02334 | Regression loss: 0.22726 | Running loss: 0.20179\n",
      "Epoch: 22 | Iteration: 410 | Classification loss: 0.00871 | Regression loss: 0.09715 | Running loss: 0.20169\n",
      "Epoch: 22 | Iteration: 411 | Classification loss: 0.02018 | Regression loss: 0.15305 | Running loss: 0.20157\n",
      "Epoch: 22 | Iteration: 412 | Classification loss: 0.01434 | Regression loss: 0.12392 | Running loss: 0.20131\n",
      "Epoch: 22 | Iteration: 413 | Classification loss: 0.01136 | Regression loss: 0.14727 | Running loss: 0.20110\n",
      "Epoch: 22 | Iteration: 414 | Classification loss: 0.02838 | Regression loss: 0.16041 | Running loss: 0.20147\n",
      "Epoch: 22 | Iteration: 415 | Classification loss: 0.02017 | Regression loss: 0.10296 | Running loss: 0.20134\n",
      "Epoch: 22 | Iteration: 416 | Classification loss: 0.09285 | Regression loss: 0.19573 | Running loss: 0.20146\n",
      "Epoch: 22 | Iteration: 417 | Classification loss: 0.02508 | Regression loss: 0.16290 | Running loss: 0.20164\n",
      "Epoch: 22 | Iteration: 418 | Classification loss: 0.02095 | Regression loss: 0.10832 | Running loss: 0.20112\n",
      "Epoch: 22 | Iteration: 419 | Classification loss: 0.01885 | Regression loss: 0.13834 | Running loss: 0.20069\n",
      "Epoch: 22 | Iteration: 420 | Classification loss: 0.03789 | Regression loss: 0.26589 | Running loss: 0.20084\n",
      "Epoch: 22 | Iteration: 421 | Classification loss: 0.01113 | Regression loss: 0.12689 | Running loss: 0.20071\n",
      "Epoch: 22 | Iteration: 422 | Classification loss: 0.01832 | Regression loss: 0.08682 | Running loss: 0.20057\n",
      "Epoch: 22 | Iteration: 423 | Classification loss: 0.01519 | Regression loss: 0.12716 | Running loss: 0.20058\n",
      "Epoch: 22 | Iteration: 424 | Classification loss: 0.01227 | Regression loss: 0.10856 | Running loss: 0.20022\n",
      "Epoch: 22 | Iteration: 425 | Classification loss: 0.02085 | Regression loss: 0.29097 | Running loss: 0.20053\n",
      "Epoch: 22 | Iteration: 426 | Classification loss: 0.01432 | Regression loss: 0.09562 | Running loss: 0.20016\n",
      "Epoch: 22 | Iteration: 427 | Classification loss: 0.05595 | Regression loss: 0.17213 | Running loss: 0.20017\n",
      "Epoch: 22 | Iteration: 428 | Classification loss: 0.01440 | Regression loss: 0.07940 | Running loss: 0.19972\n",
      "Epoch: 22 | Iteration: 429 | Classification loss: 0.08801 | Regression loss: 0.22664 | Running loss: 0.20003\n",
      "Epoch: 22 | Iteration: 430 | Classification loss: 0.01942 | Regression loss: 0.09298 | Running loss: 0.19986\n",
      "Epoch: 22 | Iteration: 431 | Classification loss: 0.03082 | Regression loss: 0.21456 | Running loss: 0.19952\n",
      "Epoch: 22 | Iteration: 432 | Classification loss: 0.02427 | Regression loss: 0.32145 | Running loss: 0.19995\n",
      "Epoch: 22 | Iteration: 433 | Classification loss: 0.02927 | Regression loss: 0.11655 | Running loss: 0.19990\n",
      "Epoch: 22 | Iteration: 434 | Classification loss: 0.02781 | Regression loss: 0.19109 | Running loss: 0.20002\n",
      "Epoch: 22 | Iteration: 435 | Classification loss: 0.15530 | Regression loss: 0.24737 | Running loss: 0.20027\n",
      "Epoch: 22 | Iteration: 436 | Classification loss: 0.01102 | Regression loss: 0.08106 | Running loss: 0.20023\n",
      "Epoch: 22 | Iteration: 437 | Classification loss: 0.11319 | Regression loss: 0.15216 | Running loss: 0.20038\n",
      "Epoch: 22 | Iteration: 438 | Classification loss: 0.02366 | Regression loss: 0.10248 | Running loss: 0.19979\n",
      "Epoch: 22 | Iteration: 439 | Classification loss: 0.00669 | Regression loss: 0.14002 | Running loss: 0.19951\n",
      "Epoch: 22 | Iteration: 440 | Classification loss: 0.02443 | Regression loss: 0.17486 | Running loss: 0.19962\n",
      "Epoch: 22 | Iteration: 441 | Classification loss: 0.01501 | Regression loss: 0.11465 | Running loss: 0.19947\n",
      "Epoch: 22 | Iteration: 442 | Classification loss: 0.02447 | Regression loss: 0.20536 | Running loss: 0.19946\n",
      "Epoch: 22 | Iteration: 443 | Classification loss: 0.12182 | Regression loss: 0.17406 | Running loss: 0.19951\n",
      "Epoch: 22 | Iteration: 444 | Classification loss: 0.01975 | Regression loss: 0.16824 | Running loss: 0.19942\n",
      "Epoch: 22 | Iteration: 445 | Classification loss: 0.04569 | Regression loss: 0.13153 | Running loss: 0.19927\n",
      "Epoch: 22 | Iteration: 446 | Classification loss: 0.01369 | Regression loss: 0.17425 | Running loss: 0.19922\n",
      "Epoch: 22 | Iteration: 447 | Classification loss: 0.02506 | Regression loss: 0.12973 | Running loss: 0.19916\n",
      "Epoch: 22 | Iteration: 448 | Classification loss: 0.01334 | Regression loss: 0.12732 | Running loss: 0.19852\n",
      "Epoch: 22 | Iteration: 449 | Classification loss: 0.09157 | Regression loss: 0.16631 | Running loss: 0.19873\n",
      "Epoch: 22 | Iteration: 450 | Classification loss: 0.04593 | Regression loss: 0.16067 | Running loss: 0.19897\n",
      "Epoch: 22 | Iteration: 451 | Classification loss: 0.07310 | Regression loss: 0.24715 | Running loss: 0.19933\n",
      "Epoch: 22 | Iteration: 452 | Classification loss: 0.03724 | Regression loss: 0.09282 | Running loss: 0.19898\n",
      "Epoch: 22 | Iteration: 453 | Classification loss: 0.04655 | Regression loss: 0.18557 | Running loss: 0.19915\n",
      "Epoch: 22 | Iteration: 454 | Classification loss: 0.05054 | Regression loss: 0.17643 | Running loss: 0.19897\n",
      "Epoch: 22 | Iteration: 455 | Classification loss: 0.01461 | Regression loss: 0.10021 | Running loss: 0.19884\n",
      "Epoch: 22 | Iteration: 456 | Classification loss: 0.00748 | Regression loss: 0.08998 | Running loss: 0.19848\n",
      "Epoch: 22 | Iteration: 457 | Classification loss: 0.02062 | Regression loss: 0.20936 | Running loss: 0.19863\n",
      "Epoch: 22 | Iteration: 458 | Classification loss: 0.02082 | Regression loss: 0.05124 | Running loss: 0.19842\n",
      "Epoch: 22 | Iteration: 459 | Classification loss: 0.02519 | Regression loss: 0.13257 | Running loss: 0.19842\n",
      "Epoch: 22 | Iteration: 460 | Classification loss: 0.02624 | Regression loss: 0.16875 | Running loss: 0.19801\n",
      "Epoch: 22 | Iteration: 461 | Classification loss: 0.00740 | Regression loss: 0.06022 | Running loss: 0.19774\n",
      "Epoch: 22 | Iteration: 462 | Classification loss: 0.02435 | Regression loss: 0.10227 | Running loss: 0.19757\n",
      "Epoch: 22 | Iteration: 463 | Classification loss: 0.07140 | Regression loss: 0.21554 | Running loss: 0.19787\n",
      "Epoch: 22 | Iteration: 464 | Classification loss: 0.01632 | Regression loss: 0.24036 | Running loss: 0.19795\n",
      "Epoch: 22 | Iteration: 465 | Classification loss: 0.00661 | Regression loss: 0.07998 | Running loss: 0.19754\n",
      "Epoch: 22 | Iteration: 466 | Classification loss: 0.00454 | Regression loss: 0.06044 | Running loss: 0.19723\n",
      "Epoch: 22 | Iteration: 467 | Classification loss: 0.03339 | Regression loss: 0.11078 | Running loss: 0.19662\n",
      "Epoch: 22 | Iteration: 468 | Classification loss: 0.02103 | Regression loss: 0.14289 | Running loss: 0.19650\n",
      "Epoch: 22 | Iteration: 469 | Classification loss: 0.02074 | Regression loss: 0.13424 | Running loss: 0.19651\n",
      "Epoch: 22 | Iteration: 470 | Classification loss: 0.01469 | Regression loss: 0.15722 | Running loss: 0.19668\n",
      "Epoch: 22 | Iteration: 471 | Classification loss: 0.01565 | Regression loss: 0.12869 | Running loss: 0.19662\n",
      "Epoch: 22 | Iteration: 472 | Classification loss: 0.00862 | Regression loss: 0.08136 | Running loss: 0.19657\n",
      "Epoch: 22 | Iteration: 473 | Classification loss: 0.05533 | Regression loss: 0.23555 | Running loss: 0.19657\n",
      "Epoch: 22 | Iteration: 474 | Classification loss: 0.01593 | Regression loss: 0.14372 | Running loss: 0.19634\n",
      "Epoch: 22 | Iteration: 475 | Classification loss: 0.07008 | Regression loss: 0.20895 | Running loss: 0.19626\n",
      "Epoch: 22 | Iteration: 476 | Classification loss: 0.01171 | Regression loss: 0.20484 | Running loss: 0.19647\n",
      "Epoch: 22 | Iteration: 477 | Classification loss: 0.04917 | Regression loss: 0.27251 | Running loss: 0.19681\n",
      "Epoch: 22 | Iteration: 478 | Classification loss: 0.01369 | Regression loss: 0.16582 | Running loss: 0.19643\n",
      "Epoch: 22 | Iteration: 479 | Classification loss: 0.06552 | Regression loss: 0.29681 | Running loss: 0.19671\n",
      "Epoch: 22 | Iteration: 480 | Classification loss: 0.62767 | Regression loss: 0.21632 | Running loss: 0.19820\n",
      "Epoch: 22 | Iteration: 481 | Classification loss: 0.03300 | Regression loss: 0.16945 | Running loss: 0.19778\n",
      "Epoch: 22 | Iteration: 482 | Classification loss: 0.02842 | Regression loss: 0.11971 | Running loss: 0.19762\n",
      "Epoch: 22 | Iteration: 483 | Classification loss: 0.03839 | Regression loss: 0.36685 | Running loss: 0.19822\n",
      "Epoch: 22 | Iteration: 484 | Classification loss: 0.06874 | Regression loss: 0.17502 | Running loss: 0.19836\n",
      "Epoch: 22 | Iteration: 485 | Classification loss: 0.07170 | Regression loss: 0.31147 | Running loss: 0.19888\n",
      "Epoch: 22 | Iteration: 486 | Classification loss: 0.03466 | Regression loss: 0.10688 | Running loss: 0.19898\n",
      "Epoch: 22 | Iteration: 487 | Classification loss: 0.05670 | Regression loss: 0.20611 | Running loss: 0.19936\n",
      "Epoch: 22 | Iteration: 488 | Classification loss: 0.05072 | Regression loss: 0.31285 | Running loss: 0.19920\n",
      "Epoch: 22 | Iteration: 489 | Classification loss: 0.01136 | Regression loss: 0.15573 | Running loss: 0.19930\n",
      "Epoch: 22 | Iteration: 490 | Classification loss: 0.02705 | Regression loss: 0.27173 | Running loss: 0.19946\n",
      "Epoch: 22 | Iteration: 491 | Classification loss: 0.01403 | Regression loss: 0.19063 | Running loss: 0.19945\n",
      "Epoch: 22 | Iteration: 492 | Classification loss: 0.00906 | Regression loss: 0.05392 | Running loss: 0.19937\n",
      "Epoch: 22 | Iteration: 493 | Classification loss: 0.02061 | Regression loss: 0.12458 | Running loss: 0.19896\n",
      "Epoch: 22 | Iteration: 494 | Classification loss: 0.10020 | Regression loss: 0.25964 | Running loss: 0.19911\n",
      "Epoch: 22 | Iteration: 495 | Classification loss: 0.04290 | Regression loss: 0.24476 | Running loss: 0.19945\n",
      "Epoch: 22 | Iteration: 496 | Classification loss: 0.03473 | Regression loss: 0.13459 | Running loss: 0.19940\n",
      "Epoch: 22 | Iteration: 497 | Classification loss: 0.02638 | Regression loss: 0.18417 | Running loss: 0.19958\n",
      "Epoch: 22 | Iteration: 498 | Classification loss: 0.01968 | Regression loss: 0.08247 | Running loss: 0.19952\n",
      "Epoch: 22 | Iteration: 499 | Classification loss: 0.02769 | Regression loss: 0.11780 | Running loss: 0.19959\n",
      "Epoch: 22 | Iteration: 500 | Classification loss: 0.01739 | Regression loss: 0.11450 | Running loss: 0.19973\n",
      "Epoch: 22 | Iteration: 501 | Classification loss: 0.01007 | Regression loss: 0.11400 | Running loss: 0.19983\n",
      "Epoch: 22 | Iteration: 502 | Classification loss: 0.00733 | Regression loss: 0.11597 | Running loss: 0.19966\n",
      "Epoch: 22 | Iteration: 503 | Classification loss: 0.03143 | Regression loss: 0.21910 | Running loss: 0.19975\n",
      "Epoch: 22 | Iteration: 504 | Classification loss: 0.06319 | Regression loss: 0.25092 | Running loss: 0.20008\n",
      "Epoch: 22 | Iteration: 505 | Classification loss: 0.07116 | Regression loss: 0.36953 | Running loss: 0.20072\n",
      "Epoch: 22 | Iteration: 506 | Classification loss: 0.01488 | Regression loss: 0.11325 | Running loss: 0.20060\n",
      "Epoch: 22 | Iteration: 507 | Classification loss: 0.00716 | Regression loss: 0.08408 | Running loss: 0.20042\n",
      "Epoch: 22 | Iteration: 508 | Classification loss: 0.01838 | Regression loss: 0.08860 | Running loss: 0.20052\n",
      "Epoch: 22 | Iteration: 509 | Classification loss: 0.01102 | Regression loss: 0.10821 | Running loss: 0.20037\n",
      "Epoch: 22 | Iteration: 510 | Classification loss: 0.08136 | Regression loss: 0.15191 | Running loss: 0.20048\n",
      "Epoch: 22 | Iteration: 511 | Classification loss: 0.01985 | Regression loss: 0.17604 | Running loss: 0.20036\n",
      "Epoch: 22 | Iteration: 512 | Classification loss: 0.01757 | Regression loss: 0.10925 | Running loss: 0.20042\n",
      "Epoch: 22 | Iteration: 513 | Classification loss: 0.01134 | Regression loss: 0.09977 | Running loss: 0.20012\n",
      "Epoch: 22 | Iteration: 514 | Classification loss: 0.00695 | Regression loss: 0.09732 | Running loss: 0.20015\n",
      "Epoch: 22 | Iteration: 515 | Classification loss: 0.01951 | Regression loss: 0.16202 | Running loss: 0.20008\n",
      "Epoch: 22 | Iteration: 516 | Classification loss: 0.00940 | Regression loss: 0.09385 | Running loss: 0.20000\n",
      "Epoch: 22 | Iteration: 517 | Classification loss: 0.01284 | Regression loss: 0.04999 | Running loss: 0.19934\n",
      "Epoch: 22 | Iteration: 518 | Classification loss: 0.01638 | Regression loss: 0.10747 | Running loss: 0.19922\n",
      "Epoch: 22 | Iteration: 519 | Classification loss: 0.03926 | Regression loss: 0.08819 | Running loss: 0.19849\n",
      "Epoch: 22 | Iteration: 520 | Classification loss: 0.06127 | Regression loss: 0.21863 | Running loss: 0.19868\n",
      "Epoch: 22 | Iteration: 521 | Classification loss: 0.00992 | Regression loss: 0.10086 | Running loss: 0.19862\n",
      "Epoch: 22 | Iteration: 522 | Classification loss: 0.01616 | Regression loss: 0.11036 | Running loss: 0.19835\n",
      "Epoch: 22 | Iteration: 523 | Classification loss: 0.01960 | Regression loss: 0.11012 | Running loss: 0.19834\n",
      "Epoch: 22 | Iteration: 524 | Classification loss: 0.01075 | Regression loss: 0.13512 | Running loss: 0.19825\n",
      "Epoch: 22 | Iteration: 525 | Classification loss: 0.07931 | Regression loss: 0.15850 | Running loss: 0.19828\n",
      "Epoch: 22 | Iteration: 526 | Classification loss: 0.07941 | Regression loss: 0.25220 | Running loss: 0.19868\n",
      "Epoch: 22 | Iteration: 527 | Classification loss: 0.04675 | Regression loss: 0.12093 | Running loss: 0.19870\n",
      "Epoch: 22 | Iteration: 528 | Classification loss: 0.02037 | Regression loss: 0.17092 | Running loss: 0.19852\n",
      "Epoch: 22 | Iteration: 529 | Classification loss: 0.01775 | Regression loss: 0.15286 | Running loss: 0.19853\n",
      "Epoch: 22 | Iteration: 530 | Classification loss: 0.00542 | Regression loss: 0.15771 | Running loss: 0.19843\n",
      "Epoch: 22 | Iteration: 531 | Classification loss: 0.00783 | Regression loss: 0.06053 | Running loss: 0.19803\n",
      "Epoch: 22 | Iteration: 532 | Classification loss: 0.01116 | Regression loss: 0.17626 | Running loss: 0.19803\n",
      "Epoch: 22 | Iteration: 533 | Classification loss: 0.01627 | Regression loss: 0.13594 | Running loss: 0.19811\n",
      "Epoch: 22 | Iteration: 534 | Classification loss: 0.02329 | Regression loss: 0.10484 | Running loss: 0.19792\n",
      "Epoch: 22 | Iteration: 535 | Classification loss: 0.11078 | Regression loss: 0.38058 | Running loss: 0.19846\n",
      "Epoch: 22 | Iteration: 536 | Classification loss: 0.09879 | Regression loss: 0.25454 | Running loss: 0.19887\n",
      "Epoch: 22 | Iteration: 537 | Classification loss: 0.04686 | Regression loss: 0.10902 | Running loss: 0.19873\n",
      "Epoch: 22 | Iteration: 538 | Classification loss: 0.07245 | Regression loss: 0.48180 | Running loss: 0.19956\n",
      "Epoch: 22 | Iteration: 539 | Classification loss: 0.01811 | Regression loss: 0.07120 | Running loss: 0.19938\n",
      "Epoch: 22 | Iteration: 540 | Classification loss: 0.00884 | Regression loss: 0.19052 | Running loss: 0.19933\n",
      "Epoch: 22 | Iteration: 541 | Classification loss: 0.06922 | Regression loss: 0.12225 | Running loss: 0.19880\n",
      "Epoch: 22 | Iteration: 542 | Classification loss: 0.00994 | Regression loss: 0.11659 | Running loss: 0.19882\n",
      "Epoch: 22 | Iteration: 543 | Classification loss: 0.06377 | Regression loss: 0.19544 | Running loss: 0.19904\n",
      "Epoch: 22 | Iteration: 544 | Classification loss: 0.00641 | Regression loss: 0.16321 | Running loss: 0.19912\n",
      "Epoch: 22 | Iteration: 545 | Classification loss: 0.01936 | Regression loss: 0.11237 | Running loss: 0.19848\n",
      "Epoch: 22 | Iteration: 546 | Classification loss: 0.00715 | Regression loss: 0.04321 | Running loss: 0.19833\n",
      "Epoch: 22 | Iteration: 547 | Classification loss: 0.03215 | Regression loss: 0.20680 | Running loss: 0.19840\n",
      "Epoch: 22 | Iteration: 548 | Classification loss: 0.01204 | Regression loss: 0.14450 | Running loss: 0.19851\n",
      "Epoch: 22 | Iteration: 549 | Classification loss: 0.01235 | Regression loss: 0.12945 | Running loss: 0.19856\n",
      "Epoch: 22 | Iteration: 550 | Classification loss: 0.02204 | Regression loss: 0.16989 | Running loss: 0.19818\n",
      "Epoch: 22 | Iteration: 551 | Classification loss: 0.02027 | Regression loss: 0.10991 | Running loss: 0.19783\n",
      "Epoch: 22 | Iteration: 552 | Classification loss: 0.01547 | Regression loss: 0.07497 | Running loss: 0.19767\n",
      "Epoch: 22 | Iteration: 553 | Classification loss: 0.04356 | Regression loss: 0.22034 | Running loss: 0.19790\n",
      "Epoch: 22 | Iteration: 554 | Classification loss: 0.01764 | Regression loss: 0.12853 | Running loss: 0.19781\n",
      "Epoch: 22 | Iteration: 555 | Classification loss: 0.05082 | Regression loss: 0.30061 | Running loss: 0.19819\n",
      "Epoch: 22 | Iteration: 556 | Classification loss: 0.01597 | Regression loss: 0.13352 | Running loss: 0.19772\n",
      "Epoch: 22 | Iteration: 557 | Classification loss: 0.00534 | Regression loss: 0.11746 | Running loss: 0.19748\n",
      "Epoch: 22 | Iteration: 558 | Classification loss: 0.00599 | Regression loss: 0.13207 | Running loss: 0.19738\n",
      "Epoch: 22 | Iteration: 559 | Classification loss: 0.04195 | Regression loss: 0.09321 | Running loss: 0.19750\n",
      "Epoch: 22 | Iteration: 560 | Classification loss: 0.01854 | Regression loss: 0.10080 | Running loss: 0.19746\n",
      "Epoch: 22 | Iteration: 561 | Classification loss: 0.01735 | Regression loss: 0.15369 | Running loss: 0.19748\n",
      "Epoch: 22 | Iteration: 562 | Classification loss: 0.00582 | Regression loss: 0.04650 | Running loss: 0.19719\n",
      "Epoch: 22 | Iteration: 563 | Classification loss: 0.03944 | Regression loss: 0.09585 | Running loss: 0.19746\n",
      "Epoch: 22 | Iteration: 564 | Classification loss: 0.02243 | Regression loss: 0.12050 | Running loss: 0.19724\n",
      "Epoch: 22 | Iteration: 565 | Classification loss: 0.05460 | Regression loss: 0.08520 | Running loss: 0.19701\n",
      "Epoch: 22 | Iteration: 566 | Classification loss: 0.02080 | Regression loss: 0.11231 | Running loss: 0.19690\n",
      "Epoch: 22 | Iteration: 567 | Classification loss: 0.00770 | Regression loss: 0.14518 | Running loss: 0.19700\n",
      "Epoch: 22 | Iteration: 568 | Classification loss: 0.00497 | Regression loss: 0.05247 | Running loss: 0.19682\n",
      "Epoch: 22 | Iteration: 569 | Classification loss: 0.02621 | Regression loss: 0.21696 | Running loss: 0.19690\n",
      "Epoch: 22 | Iteration: 570 | Classification loss: 0.10328 | Regression loss: 0.35013 | Running loss: 0.19730\n",
      "Epoch: 22 | Iteration: 571 | Classification loss: 0.00979 | Regression loss: 0.09536 | Running loss: 0.19701\n",
      "Epoch: 22 | Iteration: 572 | Classification loss: 0.03347 | Regression loss: 0.20635 | Running loss: 0.19697\n",
      "Epoch: 22 | Iteration: 573 | Classification loss: 0.01837 | Regression loss: 0.17771 | Running loss: 0.19687\n",
      "Epoch: 22 | Iteration: 574 | Classification loss: 0.01485 | Regression loss: 0.14864 | Running loss: 0.19687\n",
      "Epoch: 22 | Iteration: 575 | Classification loss: 0.04600 | Regression loss: 0.10217 | Running loss: 0.19678\n",
      "Epoch: 22 | Iteration: 576 | Classification loss: 0.03294 | Regression loss: 0.17036 | Running loss: 0.19697\n",
      "Epoch: 22 | Iteration: 577 | Classification loss: 0.00764 | Regression loss: 0.10562 | Running loss: 0.19668\n",
      "Epoch: 22 | Iteration: 578 | Classification loss: 0.01320 | Regression loss: 0.07880 | Running loss: 0.19647\n",
      "Epoch: 22 | Iteration: 579 | Classification loss: 0.01865 | Regression loss: 0.21552 | Running loss: 0.19671\n",
      "Epoch: 22 | Iteration: 580 | Classification loss: 0.05364 | Regression loss: 0.29126 | Running loss: 0.19694\n",
      "Epoch: 22 | Iteration: 581 | Classification loss: 0.01387 | Regression loss: 0.10138 | Running loss: 0.19696\n",
      "Epoch: 22 | Iteration: 582 | Classification loss: 0.01405 | Regression loss: 0.09225 | Running loss: 0.19687\n",
      "Epoch: 22 | Iteration: 583 | Classification loss: 0.02305 | Regression loss: 0.15061 | Running loss: 0.19673\n",
      "Epoch: 22 | Iteration: 584 | Classification loss: 0.04083 | Regression loss: 0.16240 | Running loss: 0.19686\n",
      "Epoch: 22 | Iteration: 585 | Classification loss: 0.13575 | Regression loss: 0.30853 | Running loss: 0.19764\n",
      "Epoch: 22 | Iteration: 586 | Classification loss: 0.00976 | Regression loss: 0.09145 | Running loss: 0.19763\n",
      "Epoch: 22 | Iteration: 587 | Classification loss: 0.02091 | Regression loss: 0.16986 | Running loss: 0.19702\n",
      "Epoch: 22 | Iteration: 588 | Classification loss: 0.11692 | Regression loss: 0.31637 | Running loss: 0.19760\n",
      "Epoch: 22 | Iteration: 589 | Classification loss: 0.01241 | Regression loss: 0.10718 | Running loss: 0.19759\n",
      "Epoch: 22 | Iteration: 590 | Classification loss: 0.01151 | Regression loss: 0.14689 | Running loss: 0.19720\n",
      "Epoch: 22 | Iteration: 591 | Classification loss: 0.02785 | Regression loss: 0.16455 | Running loss: 0.19728\n",
      "Epoch: 22 | Iteration: 592 | Classification loss: 0.04409 | Regression loss: 0.29296 | Running loss: 0.19767\n",
      "Epoch: 22 | Iteration: 593 | Classification loss: 0.01030 | Regression loss: 0.15451 | Running loss: 0.19765\n",
      "Epoch: 22 | Iteration: 594 | Classification loss: 0.08547 | Regression loss: 0.26775 | Running loss: 0.19805\n",
      "Epoch: 22 | Iteration: 595 | Classification loss: 0.02237 | Regression loss: 0.13677 | Running loss: 0.19806\n",
      "Epoch: 22 | Iteration: 596 | Classification loss: 0.02371 | Regression loss: 0.07771 | Running loss: 0.19794\n",
      "Epoch: 22 | Iteration: 597 | Classification loss: 0.02668 | Regression loss: 0.05569 | Running loss: 0.19721\n",
      "Epoch: 22 | Iteration: 598 | Classification loss: 0.02915 | Regression loss: 0.18931 | Running loss: 0.19728\n",
      "Epoch: 22 | Iteration: 599 | Classification loss: 0.00930 | Regression loss: 0.08622 | Running loss: 0.19699\n",
      "Epoch: 22 | Iteration: 600 | Classification loss: 0.03046 | Regression loss: 0.35077 | Running loss: 0.19735\n",
      "Epoch: 22 | Iteration: 601 | Classification loss: 0.04604 | Regression loss: 0.23274 | Running loss: 0.19769\n",
      "Epoch: 22 | Iteration: 602 | Classification loss: 0.16288 | Regression loss: 0.42240 | Running loss: 0.19864\n",
      "Epoch: 22 | Iteration: 603 | Classification loss: 0.04709 | Regression loss: 0.23638 | Running loss: 0.19890\n",
      "Epoch: 22 | Iteration: 604 | Classification loss: 0.02140 | Regression loss: 0.14452 | Running loss: 0.19818\n",
      "Epoch: 22 | Iteration: 605 | Classification loss: 0.02673 | Regression loss: 0.21247 | Running loss: 0.19826\n",
      "Epoch: 22 | Iteration: 606 | Classification loss: 0.06956 | Regression loss: 0.20770 | Running loss: 0.19858\n",
      "Epoch: 22 | Iteration: 607 | Classification loss: 0.04976 | Regression loss: 0.16440 | Running loss: 0.19853\n",
      "Epoch: 22 | Iteration: 608 | Classification loss: 0.01164 | Regression loss: 0.13041 | Running loss: 0.19861\n",
      "Epoch: 22 | Iteration: 609 | Classification loss: 0.00912 | Regression loss: 0.06787 | Running loss: 0.19852\n",
      "Epoch: 22 | Iteration: 610 | Classification loss: 0.02080 | Regression loss: 0.16755 | Running loss: 0.19850\n",
      "Epoch: 22 | Iteration: 611 | Classification loss: 0.03058 | Regression loss: 0.14059 | Running loss: 0.19829\n",
      "Epoch: 22 | Iteration: 612 | Classification loss: 0.03398 | Regression loss: 0.16842 | Running loss: 0.19832\n",
      "Epoch: 22 | Iteration: 613 | Classification loss: 0.02638 | Regression loss: 0.25336 | Running loss: 0.19817\n",
      "Epoch: 22 | Iteration: 614 | Classification loss: 0.01133 | Regression loss: 0.11148 | Running loss: 0.19808\n",
      "Epoch: 22 | Iteration: 615 | Classification loss: 0.01272 | Regression loss: 0.04644 | Running loss: 0.19792\n",
      "Epoch: 22 | Iteration: 616 | Classification loss: 0.01886 | Regression loss: 0.16484 | Running loss: 0.19811\n",
      "Epoch: 22 | Iteration: 617 | Classification loss: 0.04563 | Regression loss: 0.14693 | Running loss: 0.19826\n",
      "Epoch: 22 | Iteration: 618 | Classification loss: 0.04240 | Regression loss: 0.24271 | Running loss: 0.19865\n",
      "Epoch: 22 | Iteration: 619 | Classification loss: 0.01086 | Regression loss: 0.08686 | Running loss: 0.19865\n",
      "Epoch: 22 | Iteration: 620 | Classification loss: 0.01441 | Regression loss: 0.10193 | Running loss: 0.19866\n",
      "Epoch: 22 | Iteration: 621 | Classification loss: 0.02308 | Regression loss: 0.17596 | Running loss: 0.19867\n",
      "Epoch: 22 | Iteration: 622 | Classification loss: 0.06731 | Regression loss: 0.21783 | Running loss: 0.19882\n",
      "Epoch: 22 | Iteration: 623 | Classification loss: 0.03639 | Regression loss: 0.19284 | Running loss: 0.19867\n",
      "Epoch: 22 | Iteration: 624 | Classification loss: 0.01545 | Regression loss: 0.06901 | Running loss: 0.19867\n",
      "Epoch: 22 | Iteration: 625 | Classification loss: 0.01864 | Regression loss: 0.18705 | Running loss: 0.19881\n",
      "Epoch: 22 | Iteration: 626 | Classification loss: 0.00339 | Regression loss: 0.05415 | Running loss: 0.19858\n",
      "Epoch: 22 | Iteration: 627 | Classification loss: 0.09130 | Regression loss: 0.31306 | Running loss: 0.19920\n",
      "Epoch: 22 | Iteration: 628 | Classification loss: 0.00266 | Regression loss: 0.07759 | Running loss: 0.19904\n",
      "Epoch: 22 | Iteration: 629 | Classification loss: 0.02067 | Regression loss: 0.27882 | Running loss: 0.19943\n",
      "Epoch: 22 | Iteration: 630 | Classification loss: 0.05373 | Regression loss: 0.18521 | Running loss: 0.19970\n",
      "Epoch: 22 | Iteration: 631 | Classification loss: 0.07166 | Regression loss: 0.26361 | Running loss: 0.20000\n",
      "Epoch: 22 | Iteration: 632 | Classification loss: 0.04149 | Regression loss: 0.23129 | Running loss: 0.20025\n",
      "Epoch: 22 | Iteration: 633 | Classification loss: 0.00379 | Regression loss: 0.04975 | Running loss: 0.20019\n",
      "Epoch: 22 | Iteration: 634 | Classification loss: 0.00737 | Regression loss: 0.08987 | Running loss: 0.19979\n",
      "Epoch: 22 | Iteration: 635 | Classification loss: 0.03247 | Regression loss: 0.12882 | Running loss: 0.19960\n",
      "Epoch: 22 | Iteration: 636 | Classification loss: 0.01883 | Regression loss: 0.15087 | Running loss: 0.19931\n",
      "Epoch: 22 | Iteration: 637 | Classification loss: 0.01725 | Regression loss: 0.12238 | Running loss: 0.19917\n",
      "Epoch: 22 | Iteration: 638 | Classification loss: 0.01452 | Regression loss: 0.05524 | Running loss: 0.19905\n",
      "Epoch: 22 | Iteration: 639 | Classification loss: 0.02725 | Regression loss: 0.18603 | Running loss: 0.19924\n",
      "Epoch: 22 | Iteration: 640 | Classification loss: 0.03059 | Regression loss: 0.11025 | Running loss: 0.19911\n",
      "Epoch: 22 | Iteration: 641 | Classification loss: 0.01842 | Regression loss: 0.17637 | Running loss: 0.19912\n",
      "Epoch: 22 | Iteration: 642 | Classification loss: 0.01149 | Regression loss: 0.06170 | Running loss: 0.19880\n",
      "Epoch: 22 | Iteration: 643 | Classification loss: 0.00904 | Regression loss: 0.05514 | Running loss: 0.19873\n",
      "Epoch: 22 | Iteration: 644 | Classification loss: 0.00726 | Regression loss: 0.10863 | Running loss: 0.19865\n",
      "Epoch: 22 | Iteration: 645 | Classification loss: 0.03039 | Regression loss: 0.11962 | Running loss: 0.19829\n",
      "Epoch: 22 | Iteration: 646 | Classification loss: 0.01232 | Regression loss: 0.13705 | Running loss: 0.19836\n",
      "Epoch: 22 | Iteration: 647 | Classification loss: 0.01514 | Regression loss: 0.05325 | Running loss: 0.19794\n",
      "Epoch: 22 | Iteration: 648 | Classification loss: 0.00817 | Regression loss: 0.11438 | Running loss: 0.19786\n",
      "Epoch: 22 | Iteration: 649 | Classification loss: 0.03055 | Regression loss: 0.12114 | Running loss: 0.19816\n",
      "Epoch: 22 | Iteration: 650 | Classification loss: 0.01751 | Regression loss: 0.12845 | Running loss: 0.19812\n",
      "Epoch: 22 | Iteration: 651 | Classification loss: 0.01057 | Regression loss: 0.11241 | Running loss: 0.19792\n",
      "Epoch: 22 | Iteration: 652 | Classification loss: 0.00804 | Regression loss: 0.07547 | Running loss: 0.19794\n",
      "Epoch: 22 | Iteration: 653 | Classification loss: 0.00747 | Regression loss: 0.06304 | Running loss: 0.19748\n",
      "Epoch: 22 | Iteration: 654 | Classification loss: 0.01584 | Regression loss: 0.13523 | Running loss: 0.19752\n",
      "Epoch: 22 | Iteration: 655 | Classification loss: 0.00720 | Regression loss: 0.09749 | Running loss: 0.19745\n",
      "Epoch: 22 | Iteration: 656 | Classification loss: 0.02059 | Regression loss: 0.12493 | Running loss: 0.19758\n",
      "Epoch: 22 | Iteration: 657 | Classification loss: 0.05717 | Regression loss: 0.23564 | Running loss: 0.19746\n",
      "Epoch: 22 | Iteration: 658 | Classification loss: 0.05244 | Regression loss: 0.16918 | Running loss: 0.19757\n",
      "Epoch: 22 | Iteration: 659 | Classification loss: 0.04387 | Regression loss: 0.21114 | Running loss: 0.19780\n",
      "Epoch: 22 | Iteration: 660 | Classification loss: 0.00894 | Regression loss: 0.12698 | Running loss: 0.19772\n",
      "Epoch: 22 | Iteration: 661 | Classification loss: 0.01079 | Regression loss: 0.09993 | Running loss: 0.19780\n",
      "Epoch: 22 | Iteration: 662 | Classification loss: 0.04290 | Regression loss: 0.19306 | Running loss: 0.19791\n",
      "Epoch: 22 | Iteration: 663 | Classification loss: 0.02201 | Regression loss: 0.17377 | Running loss: 0.19788\n",
      "Epoch: 22 | Iteration: 664 | Classification loss: 0.03348 | Regression loss: 0.20601 | Running loss: 0.19799\n",
      "Epoch: 22 | Iteration: 665 | Classification loss: 0.03594 | Regression loss: 0.21571 | Running loss: 0.19809\n",
      "Epoch: 22 | Iteration: 666 | Classification loss: 0.00690 | Regression loss: 0.03392 | Running loss: 0.19775\n",
      "Epoch: 22 | Iteration: 667 | Classification loss: 0.00884 | Regression loss: 0.14828 | Running loss: 0.19770\n",
      "Epoch: 22 | Iteration: 668 | Classification loss: 0.02469 | Regression loss: 0.13410 | Running loss: 0.19753\n",
      "Epoch: 22 | Iteration: 669 | Classification loss: 0.01479 | Regression loss: 0.10868 | Running loss: 0.19744\n",
      "Epoch: 22 | Iteration: 670 | Classification loss: 0.01082 | Regression loss: 0.12003 | Running loss: 0.19747\n",
      "Epoch: 22 | Iteration: 671 | Classification loss: 0.00868 | Regression loss: 0.08933 | Running loss: 0.19708\n",
      "Epoch: 22 | Iteration: 672 | Classification loss: 0.00721 | Regression loss: 0.03924 | Running loss: 0.19655\n",
      "Epoch: 22 | Iteration: 673 | Classification loss: 0.01506 | Regression loss: 0.10038 | Running loss: 0.19625\n",
      "Epoch: 22 | Iteration: 674 | Classification loss: 0.01169 | Regression loss: 0.15496 | Running loss: 0.19619\n",
      "Epoch: 22 | Iteration: 675 | Classification loss: 0.01655 | Regression loss: 0.16855 | Running loss: 0.19626\n",
      "Epoch: 22 | Iteration: 676 | Classification loss: 0.00872 | Regression loss: 0.11537 | Running loss: 0.19620\n",
      "Epoch: 22 | Iteration: 677 | Classification loss: 0.03095 | Regression loss: 0.16951 | Running loss: 0.19633\n",
      "Epoch: 22 | Iteration: 678 | Classification loss: 0.00499 | Regression loss: 0.09179 | Running loss: 0.19630\n",
      "Epoch: 22 | Iteration: 679 | Classification loss: 0.07142 | Regression loss: 0.16027 | Running loss: 0.19643\n",
      "Epoch: 22 | Iteration: 680 | Classification loss: 0.04607 | Regression loss: 0.19798 | Running loss: 0.19595\n",
      "Epoch: 22 | Iteration: 681 | Classification loss: 0.02068 | Regression loss: 0.14706 | Running loss: 0.19608\n",
      "Epoch: 22 | Iteration: 682 | Classification loss: 0.02668 | Regression loss: 0.12793 | Running loss: 0.19590\n",
      "Epoch: 22 | Iteration: 683 | Classification loss: 0.01855 | Regression loss: 0.16282 | Running loss: 0.19605\n",
      "Epoch: 22 | Iteration: 684 | Classification loss: 0.03446 | Regression loss: 0.11015 | Running loss: 0.19539\n",
      "Epoch: 22 | Iteration: 685 | Classification loss: 0.01480 | Regression loss: 0.10892 | Running loss: 0.19547\n",
      "Epoch: 22 | Iteration: 686 | Classification loss: 0.03763 | Regression loss: 0.18127 | Running loss: 0.19540\n",
      "Epoch: 22 | Iteration: 687 | Classification loss: 0.01268 | Regression loss: 0.13105 | Running loss: 0.19551\n",
      "Epoch: 22 | Iteration: 688 | Classification loss: 0.01025 | Regression loss: 0.08228 | Running loss: 0.19533\n",
      "Epoch: 22 | Iteration: 689 | Classification loss: 0.03331 | Regression loss: 0.13202 | Running loss: 0.19546\n",
      "Epoch: 22 | Iteration: 690 | Classification loss: 0.05570 | Regression loss: 0.23683 | Running loss: 0.19526\n",
      "Epoch: 22 | Iteration: 691 | Classification loss: 0.00875 | Regression loss: 0.11998 | Running loss: 0.19522\n",
      "Epoch: 22 | Iteration: 692 | Classification loss: 0.05640 | Regression loss: 0.21943 | Running loss: 0.19526\n",
      "Epoch: 22 | Iteration: 693 | Classification loss: 0.02185 | Regression loss: 0.09435 | Running loss: 0.19501\n",
      "Epoch: 22 | Iteration: 694 | Classification loss: 0.02139 | Regression loss: 0.32236 | Running loss: 0.19532\n",
      "Epoch: 22 | Iteration: 695 | Classification loss: 0.02599 | Regression loss: 0.10991 | Running loss: 0.19456\n",
      "Epoch: 22 | Iteration: 696 | Classification loss: 0.01437 | Regression loss: 0.25391 | Running loss: 0.19466\n",
      "Epoch: 22 | Iteration: 697 | Classification loss: 0.02199 | Regression loss: 0.10458 | Running loss: 0.19462\n",
      "Epoch: 22 | Iteration: 698 | Classification loss: 0.03466 | Regression loss: 0.14723 | Running loss: 0.19457\n",
      "Epoch: 22 | Iteration: 699 | Classification loss: 0.01811 | Regression loss: 0.16008 | Running loss: 0.19464\n",
      "Epoch: 22 | Iteration: 700 | Classification loss: 0.06300 | Regression loss: 0.32519 | Running loss: 0.19513\n",
      "Epoch: 22 | Iteration: 701 | Classification loss: 0.03964 | Regression loss: 0.22400 | Running loss: 0.19539\n",
      "Epoch: 22 | Iteration: 702 | Classification loss: 0.09342 | Regression loss: 0.33415 | Running loss: 0.19588\n",
      "Epoch: 22 | Iteration: 703 | Classification loss: 0.03022 | Regression loss: 0.16376 | Running loss: 0.19604\n",
      "Epoch: 22 | Iteration: 704 | Classification loss: 0.01232 | Regression loss: 0.11761 | Running loss: 0.19583\n",
      "Epoch: 22 | Iteration: 705 | Classification loss: 0.00516 | Regression loss: 0.10898 | Running loss: 0.19546\n",
      "Epoch: 22 | Iteration: 706 | Classification loss: 0.01160 | Regression loss: 0.14438 | Running loss: 0.19498\n",
      "Epoch: 22 | Iteration: 707 | Classification loss: 0.00860 | Regression loss: 0.09918 | Running loss: 0.19502\n",
      "Epoch: 22 | Iteration: 708 | Classification loss: 0.09106 | Regression loss: 0.40180 | Running loss: 0.19579\n",
      "Epoch: 22 | Iteration: 709 | Classification loss: 0.00920 | Regression loss: 0.10905 | Running loss: 0.19524\n",
      "Epoch: 22 | Iteration: 710 | Classification loss: 0.00793 | Regression loss: 0.12036 | Running loss: 0.19522\n",
      "Epoch: 22 | Iteration: 711 | Classification loss: 0.04921 | Regression loss: 0.25428 | Running loss: 0.19549\n",
      "Epoch: 22 | Iteration: 712 | Classification loss: 0.03778 | Regression loss: 0.07264 | Running loss: 0.19540\n",
      "Epoch: 22 | Iteration: 713 | Classification loss: 0.00767 | Regression loss: 0.12104 | Running loss: 0.19504\n",
      "Epoch: 22 | Iteration: 714 | Classification loss: 0.00930 | Regression loss: 0.15786 | Running loss: 0.19517\n",
      "Epoch: 22 | Iteration: 715 | Classification loss: 0.05424 | Regression loss: 0.24069 | Running loss: 0.19544\n",
      "Epoch: 22 | Iteration: 716 | Classification loss: 0.01257 | Regression loss: 0.10804 | Running loss: 0.19560\n",
      "Epoch: 22 | Iteration: 717 | Classification loss: 0.00731 | Regression loss: 0.15606 | Running loss: 0.19566\n",
      "Epoch: 22 | Iteration: 718 | Classification loss: 0.02586 | Regression loss: 0.14939 | Running loss: 0.19573\n",
      "Epoch: 22 | Iteration: 719 | Classification loss: 0.03953 | Regression loss: 0.25470 | Running loss: 0.19543\n",
      "Epoch: 22 | Iteration: 720 | Classification loss: 0.00921 | Regression loss: 0.11998 | Running loss: 0.19530\n",
      "Epoch: 22 | Iteration: 721 | Classification loss: 0.00566 | Regression loss: 0.11954 | Running loss: 0.19508\n",
      "Epoch: 22 | Iteration: 722 | Classification loss: 0.07729 | Regression loss: 0.16349 | Running loss: 0.19540\n",
      "Epoch: 22 | Iteration: 723 | Classification loss: 0.01893 | Regression loss: 0.22307 | Running loss: 0.19547\n",
      "Epoch: 22 | Iteration: 724 | Classification loss: 0.05797 | Regression loss: 0.22493 | Running loss: 0.19572\n",
      "Epoch: 22 | Iteration: 725 | Classification loss: 0.02884 | Regression loss: 0.14985 | Running loss: 0.19554\n",
      "Epoch: 22 | Iteration: 726 | Classification loss: 0.01354 | Regression loss: 0.09951 | Running loss: 0.19551\n",
      "Epoch: 22 | Iteration: 727 | Classification loss: 0.05835 | Regression loss: 0.26187 | Running loss: 0.19589\n",
      "Epoch: 22 | Iteration: 728 | Classification loss: 0.01788 | Regression loss: 0.14181 | Running loss: 0.19467\n",
      "Epoch: 22 | Iteration: 729 | Classification loss: 0.01430 | Regression loss: 0.11297 | Running loss: 0.19463\n",
      "Epoch: 22 | Iteration: 730 | Classification loss: 0.02288 | Regression loss: 0.17213 | Running loss: 0.19447\n",
      "Epoch: 22 | Iteration: 731 | Classification loss: 0.03762 | Regression loss: 0.24186 | Running loss: 0.19449\n",
      "Epoch: 22 | Iteration: 732 | Classification loss: 0.01713 | Regression loss: 0.14350 | Running loss: 0.19450\n",
      "Epoch: 22 | Iteration: 733 | Classification loss: 0.01933 | Regression loss: 0.10713 | Running loss: 0.19457\n",
      "Epoch: 22 | Iteration: 734 | Classification loss: 0.04925 | Regression loss: 0.26450 | Running loss: 0.19450\n",
      "Epoch: 22 | Iteration: 735 | Classification loss: 0.02595 | Regression loss: 0.16472 | Running loss: 0.19461\n",
      "Epoch: 22 | Iteration: 736 | Classification loss: 0.02821 | Regression loss: 0.12963 | Running loss: 0.19471\n",
      "Epoch: 22 | Iteration: 737 | Classification loss: 0.01125 | Regression loss: 0.07310 | Running loss: 0.19451\n",
      "Epoch: 22 | Iteration: 738 | Classification loss: 0.03965 | Regression loss: 0.09375 | Running loss: 0.19427\n",
      "Epoch: 22 | Iteration: 739 | Classification loss: 0.00949 | Regression loss: 0.06548 | Running loss: 0.19412\n",
      "Epoch: 22 | Iteration: 740 | Classification loss: 0.00664 | Regression loss: 0.08253 | Running loss: 0.19411\n",
      "Epoch: 22 | Iteration: 741 | Classification loss: 0.05394 | Regression loss: 0.17419 | Running loss: 0.19422\n",
      "Epoch: 22 | Iteration: 742 | Classification loss: 0.09262 | Regression loss: 0.33885 | Running loss: 0.19488\n",
      "Epoch: 22 | Iteration: 743 | Classification loss: 0.03523 | Regression loss: 0.08712 | Running loss: 0.19494\n",
      "Epoch: 22 | Iteration: 744 | Classification loss: 0.07150 | Regression loss: 0.27589 | Running loss: 0.19465\n",
      "Epoch: 22 | Iteration: 745 | Classification loss: 0.01823 | Regression loss: 0.14859 | Running loss: 0.19470\n",
      "Epoch: 22 | Iteration: 746 | Classification loss: 0.00781 | Regression loss: 0.11861 | Running loss: 0.19455\n",
      "Epoch: 22 | Iteration: 747 | Classification loss: 0.00561 | Regression loss: 0.06116 | Running loss: 0.19454\n",
      "Epoch: 22 | Iteration: 748 | Classification loss: 0.02779 | Regression loss: 0.18257 | Running loss: 0.19444\n",
      "Epoch: 22 | Iteration: 749 | Classification loss: 0.04976 | Regression loss: 0.14149 | Running loss: 0.19453\n",
      "Epoch: 22 | Iteration: 750 | Classification loss: 0.02627 | Regression loss: 0.15381 | Running loss: 0.19453\n",
      "Epoch: 22 | Iteration: 751 | Classification loss: 0.02208 | Regression loss: 0.17969 | Running loss: 0.19463\n",
      "Epoch: 22 | Iteration: 752 | Classification loss: 0.04286 | Regression loss: 0.12853 | Running loss: 0.19407\n",
      "Epoch: 22 | Iteration: 753 | Classification loss: 0.00879 | Regression loss: 0.05629 | Running loss: 0.19350\n",
      "Epoch: 22 | Iteration: 754 | Classification loss: 0.01519 | Regression loss: 0.13789 | Running loss: 0.19359\n",
      "Epoch: 22 | Iteration: 755 | Classification loss: 0.03829 | Regression loss: 0.14401 | Running loss: 0.19374\n",
      "Epoch: 22 | Iteration: 756 | Classification loss: 0.02811 | Regression loss: 0.07722 | Running loss: 0.19362\n",
      "Epoch: 22 | Iteration: 757 | Classification loss: 0.08435 | Regression loss: 0.25741 | Running loss: 0.19403\n",
      "Epoch: 22 | Iteration: 758 | Classification loss: 0.00718 | Regression loss: 0.10899 | Running loss: 0.19386\n",
      "Epoch: 22 | Iteration: 759 | Classification loss: 0.01160 | Regression loss: 0.06061 | Running loss: 0.19333\n",
      "Epoch: 22 | Iteration: 760 | Classification loss: 0.00841 | Regression loss: 0.09587 | Running loss: 0.19315\n",
      "Epoch: 22 | Iteration: 761 | Classification loss: 0.01373 | Regression loss: 0.05629 | Running loss: 0.19292\n",
      "Epoch: 22 | Iteration: 762 | Classification loss: 0.03618 | Regression loss: 0.22712 | Running loss: 0.19326\n",
      "Epoch: 22 | Iteration: 763 | Classification loss: 0.03681 | Regression loss: 0.11485 | Running loss: 0.19326\n",
      "Epoch: 22 | Iteration: 764 | Classification loss: 0.00732 | Regression loss: 0.10236 | Running loss: 0.19311\n",
      "Epoch: 22 | Iteration: 765 | Classification loss: 0.02290 | Regression loss: 0.09659 | Running loss: 0.19313\n",
      "Epoch: 22 | Iteration: 766 | Classification loss: 0.05416 | Regression loss: 0.20556 | Running loss: 0.19330\n",
      "Epoch: 22 | Iteration: 767 | Classification loss: 0.07867 | Regression loss: 0.07660 | Running loss: 0.19317\n",
      "Epoch: 22 | Iteration: 768 | Classification loss: 0.00904 | Regression loss: 0.10493 | Running loss: 0.19300\n",
      "Epoch: 22 | Iteration: 769 | Classification loss: 0.01540 | Regression loss: 0.17530 | Running loss: 0.19250\n",
      "Epoch: 22 | Iteration: 770 | Classification loss: 0.05162 | Regression loss: 0.13683 | Running loss: 0.19239\n",
      "Epoch: 22 | Iteration: 771 | Classification loss: 0.01047 | Regression loss: 0.08324 | Running loss: 0.19223\n",
      "Epoch: 22 | Iteration: 772 | Classification loss: 0.03260 | Regression loss: 0.07275 | Running loss: 0.19234\n",
      "Epoch: 22 | Iteration: 773 | Classification loss: 0.02803 | Regression loss: 0.08272 | Running loss: 0.19226\n",
      "Epoch: 22 | Iteration: 774 | Classification loss: 0.01410 | Regression loss: 0.21547 | Running loss: 0.19006\n",
      "Epoch: 22 | Iteration: 775 | Classification loss: 0.02052 | Regression loss: 0.06499 | Running loss: 0.18997\n",
      "Epoch: 22 | Iteration: 776 | Classification loss: 0.06199 | Regression loss: 0.11042 | Running loss: 0.19002\n",
      "Epoch: 22 | Iteration: 777 | Classification loss: 0.04634 | Regression loss: 0.21423 | Running loss: 0.19030\n",
      "Epoch: 22 | Iteration: 778 | Classification loss: 0.06045 | Regression loss: 0.23363 | Running loss: 0.19049\n",
      "Epoch: 22 | Iteration: 779 | Classification loss: 0.03599 | Regression loss: 0.14711 | Running loss: 0.19035\n",
      "Epoch: 22 | Iteration: 780 | Classification loss: 0.02050 | Regression loss: 0.12248 | Running loss: 0.19042\n",
      "Epoch: 22 | Iteration: 781 | Classification loss: 0.00855 | Regression loss: 0.11378 | Running loss: 0.19034\n",
      "Epoch: 22 | Iteration: 782 | Classification loss: 0.01846 | Regression loss: 0.21422 | Running loss: 0.19044\n",
      "Epoch: 22 | Iteration: 783 | Classification loss: 0.00712 | Regression loss: 0.10260 | Running loss: 0.19031\n",
      "Epoch: 22 | Iteration: 784 | Classification loss: 0.05924 | Regression loss: 0.13299 | Running loss: 0.19038\n",
      "Epoch: 22 | Iteration: 785 | Classification loss: 0.03682 | Regression loss: 0.17420 | Running loss: 0.19038\n",
      "Epoch: 22 | Iteration: 786 | Classification loss: 0.01205 | Regression loss: 0.11034 | Running loss: 0.19027\n",
      "Epoch: 22 | Iteration: 787 | Classification loss: 0.01896 | Regression loss: 0.15474 | Running loss: 0.19010\n",
      "Epoch: 22 | Iteration: 788 | Classification loss: 0.00866 | Regression loss: 0.16932 | Running loss: 0.18955\n",
      "Epoch: 22 | Iteration: 789 | Classification loss: 0.00606 | Regression loss: 0.15436 | Running loss: 0.18938\n",
      "Epoch: 22 | Iteration: 790 | Classification loss: 0.02872 | Regression loss: 0.19426 | Running loss: 0.18938\n",
      "Epoch: 22 | Iteration: 791 | Classification loss: 0.01311 | Regression loss: 0.11871 | Running loss: 0.18931\n",
      "Epoch: 22 | Iteration: 792 | Classification loss: 0.00726 | Regression loss: 0.07015 | Running loss: 0.18910\n",
      "Epoch: 22 | Iteration: 793 | Classification loss: 0.07801 | Regression loss: 0.20021 | Running loss: 0.18916\n",
      "Epoch: 22 | Iteration: 794 | Classification loss: 0.01563 | Regression loss: 0.11119 | Running loss: 0.18876\n",
      "Epoch: 22 | Iteration: 795 | Classification loss: 0.02189 | Regression loss: 0.05805 | Running loss: 0.18853\n",
      "Epoch: 22 | Iteration: 796 | Classification loss: 0.08446 | Regression loss: 0.29665 | Running loss: 0.18868\n",
      "Epoch: 22 | Iteration: 797 | Classification loss: 0.00930 | Regression loss: 0.09918 | Running loss: 0.18867\n",
      "Epoch: 22 | Iteration: 798 | Classification loss: 0.02056 | Regression loss: 0.19317 | Running loss: 0.18887\n",
      "Epoch: 22 | Iteration: 799 | Classification loss: 0.02650 | Regression loss: 0.20799 | Running loss: 0.18906\n",
      "Epoch: 22 | Iteration: 800 | Classification loss: 0.00815 | Regression loss: 0.08644 | Running loss: 0.18887\n",
      "Epoch: 22 | Iteration: 801 | Classification loss: 0.00516 | Regression loss: 0.08838 | Running loss: 0.18879\n",
      "Epoch: 22 | Iteration: 802 | Classification loss: 0.00926 | Regression loss: 0.12157 | Running loss: 0.18876\n",
      "Epoch: 22 | Iteration: 803 | Classification loss: 0.01498 | Regression loss: 0.09367 | Running loss: 0.18868\n",
      "Epoch: 22 | Iteration: 804 | Classification loss: 0.04059 | Regression loss: 0.29071 | Running loss: 0.18913\n",
      "Epoch: 22 | Iteration: 805 | Classification loss: 0.09666 | Regression loss: 0.23536 | Running loss: 0.18962\n",
      "Epoch: 22 | Iteration: 806 | Classification loss: 0.09505 | Regression loss: 0.29949 | Running loss: 0.19016\n",
      "Epoch: 22 | Iteration: 807 | Classification loss: 0.00650 | Regression loss: 0.11065 | Running loss: 0.19018\n",
      "Epoch: 22 | Iteration: 808 | Classification loss: 0.19347 | Regression loss: 0.28465 | Running loss: 0.19082\n",
      "Epoch: 22 | Iteration: 809 | Classification loss: 0.02068 | Regression loss: 0.19304 | Running loss: 0.19026\n",
      "Epoch: 22 | Iteration: 810 | Classification loss: 0.01137 | Regression loss: 0.13665 | Running loss: 0.19014\n",
      "Epoch: 22 | Iteration: 811 | Classification loss: 0.05062 | Regression loss: 0.26068 | Running loss: 0.19047\n",
      "Epoch: 22 | Iteration: 812 | Classification loss: 0.02366 | Regression loss: 0.19492 | Running loss: 0.19067\n",
      "Epoch: 22 | Iteration: 813 | Classification loss: 0.04921 | Regression loss: 0.17590 | Running loss: 0.19069\n",
      "Epoch: 22 | Iteration: 814 | Classification loss: 0.05227 | Regression loss: 0.20365 | Running loss: 0.19064\n",
      "Epoch: 22 | Iteration: 815 | Classification loss: 0.00898 | Regression loss: 0.10548 | Running loss: 0.19037\n",
      "Epoch: 22 | Iteration: 816 | Classification loss: 0.00490 | Regression loss: 0.04647 | Running loss: 0.18997\n",
      "Epoch: 22 | Iteration: 817 | Classification loss: 0.13415 | Regression loss: 0.32877 | Running loss: 0.19043\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.598\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 23 | Iteration: 0 | Classification loss: 0.01971 | Regression loss: 0.18992 | Running loss: 0.19045\n",
      "Epoch: 23 | Iteration: 1 | Classification loss: 0.02625 | Regression loss: 0.19831 | Running loss: 0.19010\n",
      "Epoch: 23 | Iteration: 2 | Classification loss: 0.00223 | Regression loss: 0.07846 | Running loss: 0.18972\n",
      "Epoch: 23 | Iteration: 3 | Classification loss: 0.01995 | Regression loss: 0.14846 | Running loss: 0.18972\n",
      "Epoch: 23 | Iteration: 4 | Classification loss: 0.01858 | Regression loss: 0.12327 | Running loss: 0.18954\n",
      "Epoch: 23 | Iteration: 5 | Classification loss: 0.00802 | Regression loss: 0.10577 | Running loss: 0.18929\n",
      "Epoch: 23 | Iteration: 6 | Classification loss: 0.05735 | Regression loss: 0.33075 | Running loss: 0.18960\n",
      "Epoch: 23 | Iteration: 7 | Classification loss: 0.01302 | Regression loss: 0.07916 | Running loss: 0.18940\n",
      "Epoch: 23 | Iteration: 8 | Classification loss: 0.01035 | Regression loss: 0.15103 | Running loss: 0.18930\n",
      "Epoch: 23 | Iteration: 9 | Classification loss: 0.00478 | Regression loss: 0.08682 | Running loss: 0.18930\n",
      "Epoch: 23 | Iteration: 10 | Classification loss: 0.00294 | Regression loss: 0.13286 | Running loss: 0.18922\n",
      "Epoch: 23 | Iteration: 11 | Classification loss: 0.00421 | Regression loss: 0.06421 | Running loss: 0.18815\n",
      "Epoch: 23 | Iteration: 12 | Classification loss: 0.02882 | Regression loss: 0.07445 | Running loss: 0.18797\n",
      "Epoch: 23 | Iteration: 13 | Classification loss: 0.01528 | Regression loss: 0.13395 | Running loss: 0.18795\n",
      "Epoch: 23 | Iteration: 14 | Classification loss: 0.02161 | Regression loss: 0.13541 | Running loss: 0.18778\n",
      "Epoch: 23 | Iteration: 15 | Classification loss: 0.07454 | Regression loss: 0.26571 | Running loss: 0.18760\n",
      "Epoch: 23 | Iteration: 16 | Classification loss: 0.02662 | Regression loss: 0.16922 | Running loss: 0.18770\n",
      "Epoch: 23 | Iteration: 17 | Classification loss: 0.01331 | Regression loss: 0.12104 | Running loss: 0.18784\n",
      "Epoch: 23 | Iteration: 18 | Classification loss: 0.01487 | Regression loss: 0.17891 | Running loss: 0.18752\n",
      "Epoch: 23 | Iteration: 19 | Classification loss: 0.04424 | Regression loss: 0.29151 | Running loss: 0.18800\n",
      "Epoch: 23 | Iteration: 20 | Classification loss: 0.01088 | Regression loss: 0.18049 | Running loss: 0.18814\n",
      "Epoch: 23 | Iteration: 21 | Classification loss: 0.05057 | Regression loss: 0.10537 | Running loss: 0.18800\n",
      "Epoch: 23 | Iteration: 22 | Classification loss: 0.02449 | Regression loss: 0.16664 | Running loss: 0.18819\n",
      "Epoch: 23 | Iteration: 23 | Classification loss: 0.03804 | Regression loss: 0.25039 | Running loss: 0.18848\n",
      "Epoch: 23 | Iteration: 24 | Classification loss: 0.11291 | Regression loss: 0.33914 | Running loss: 0.18918\n",
      "Epoch: 23 | Iteration: 25 | Classification loss: 0.00878 | Regression loss: 0.10581 | Running loss: 0.18923\n",
      "Epoch: 23 | Iteration: 26 | Classification loss: 0.00896 | Regression loss: 0.07686 | Running loss: 0.18891\n",
      "Epoch: 23 | Iteration: 27 | Classification loss: 0.00584 | Regression loss: 0.07434 | Running loss: 0.18884\n",
      "Epoch: 23 | Iteration: 28 | Classification loss: 0.01151 | Regression loss: 0.10570 | Running loss: 0.18845\n",
      "Epoch: 23 | Iteration: 29 | Classification loss: 0.04010 | Regression loss: 0.20517 | Running loss: 0.18845\n",
      "Epoch: 23 | Iteration: 30 | Classification loss: 0.05630 | Regression loss: 0.23176 | Running loss: 0.18877\n",
      "Epoch: 23 | Iteration: 31 | Classification loss: 0.02244 | Regression loss: 0.26544 | Running loss: 0.18902\n",
      "Epoch: 23 | Iteration: 32 | Classification loss: 0.03539 | Regression loss: 0.25112 | Running loss: 0.18916\n",
      "Epoch: 23 | Iteration: 33 | Classification loss: 0.04422 | Regression loss: 0.15344 | Running loss: 0.18930\n",
      "Epoch: 23 | Iteration: 34 | Classification loss: 0.02761 | Regression loss: 0.16848 | Running loss: 0.18948\n",
      "Epoch: 23 | Iteration: 35 | Classification loss: 0.00837 | Regression loss: 0.07830 | Running loss: 0.18899\n",
      "Epoch: 23 | Iteration: 36 | Classification loss: 0.02820 | Regression loss: 0.18324 | Running loss: 0.18924\n",
      "Epoch: 23 | Iteration: 37 | Classification loss: 0.02049 | Regression loss: 0.06878 | Running loss: 0.18898\n",
      "Epoch: 23 | Iteration: 38 | Classification loss: 0.01068 | Regression loss: 0.16180 | Running loss: 0.18916\n",
      "Epoch: 23 | Iteration: 39 | Classification loss: 0.01096 | Regression loss: 0.14406 | Running loss: 0.18816\n",
      "Epoch: 23 | Iteration: 40 | Classification loss: 0.01357 | Regression loss: 0.14330 | Running loss: 0.18816\n",
      "Epoch: 23 | Iteration: 41 | Classification loss: 0.01576 | Regression loss: 0.14158 | Running loss: 0.18803\n",
      "Epoch: 23 | Iteration: 42 | Classification loss: 0.02758 | Regression loss: 0.17119 | Running loss: 0.18804\n",
      "Epoch: 23 | Iteration: 43 | Classification loss: 0.00635 | Regression loss: 0.10400 | Running loss: 0.18776\n",
      "Epoch: 23 | Iteration: 44 | Classification loss: 0.00793 | Regression loss: 0.07695 | Running loss: 0.18739\n",
      "Epoch: 23 | Iteration: 45 | Classification loss: 0.01157 | Regression loss: 0.18953 | Running loss: 0.18753\n",
      "Epoch: 23 | Iteration: 46 | Classification loss: 0.00367 | Regression loss: 0.12258 | Running loss: 0.18746\n",
      "Epoch: 23 | Iteration: 47 | Classification loss: 0.00827 | Regression loss: 0.16626 | Running loss: 0.18749\n",
      "Epoch: 23 | Iteration: 48 | Classification loss: 0.01136 | Regression loss: 0.07189 | Running loss: 0.18748\n",
      "Epoch: 23 | Iteration: 49 | Classification loss: 0.01522 | Regression loss: 0.09793 | Running loss: 0.18751\n",
      "Epoch: 23 | Iteration: 50 | Classification loss: 0.02306 | Regression loss: 0.16884 | Running loss: 0.18739\n",
      "Epoch: 23 | Iteration: 51 | Classification loss: 0.01226 | Regression loss: 0.10588 | Running loss: 0.18681\n",
      "Epoch: 23 | Iteration: 52 | Classification loss: 0.03001 | Regression loss: 0.11347 | Running loss: 0.18689\n",
      "Epoch: 23 | Iteration: 53 | Classification loss: 0.00516 | Regression loss: 0.08870 | Running loss: 0.18690\n",
      "Epoch: 23 | Iteration: 54 | Classification loss: 0.03833 | Regression loss: 0.13059 | Running loss: 0.18572\n",
      "Epoch: 23 | Iteration: 55 | Classification loss: 0.01579 | Regression loss: 0.10282 | Running loss: 0.18562\n",
      "Epoch: 23 | Iteration: 56 | Classification loss: 0.13698 | Regression loss: 0.31715 | Running loss: 0.18605\n",
      "Epoch: 23 | Iteration: 57 | Classification loss: 0.01745 | Regression loss: 0.08182 | Running loss: 0.18606\n",
      "Epoch: 23 | Iteration: 58 | Classification loss: 0.01342 | Regression loss: 0.12819 | Running loss: 0.18595\n",
      "Epoch: 23 | Iteration: 59 | Classification loss: 0.03234 | Regression loss: 0.21450 | Running loss: 0.18585\n",
      "Epoch: 23 | Iteration: 60 | Classification loss: 0.01850 | Regression loss: 0.19737 | Running loss: 0.18602\n",
      "Epoch: 23 | Iteration: 61 | Classification loss: 0.01486 | Regression loss: 0.15411 | Running loss: 0.18604\n",
      "Epoch: 23 | Iteration: 62 | Classification loss: 0.03755 | Regression loss: 0.16695 | Running loss: 0.18598\n",
      "Epoch: 23 | Iteration: 63 | Classification loss: 0.01652 | Regression loss: 0.17545 | Running loss: 0.18595\n",
      "Epoch: 23 | Iteration: 64 | Classification loss: 0.00781 | Regression loss: 0.13436 | Running loss: 0.18569\n",
      "Epoch: 23 | Iteration: 65 | Classification loss: 0.03289 | Regression loss: 0.11665 | Running loss: 0.18574\n",
      "Epoch: 23 | Iteration: 66 | Classification loss: 0.05229 | Regression loss: 0.28864 | Running loss: 0.18614\n",
      "Epoch: 23 | Iteration: 67 | Classification loss: 0.03203 | Regression loss: 0.10742 | Running loss: 0.18602\n",
      "Epoch: 23 | Iteration: 68 | Classification loss: 0.04232 | Regression loss: 0.24042 | Running loss: 0.18610\n",
      "Epoch: 23 | Iteration: 69 | Classification loss: 0.01525 | Regression loss: 0.18576 | Running loss: 0.18630\n",
      "Epoch: 23 | Iteration: 70 | Classification loss: 0.02006 | Regression loss: 0.13568 | Running loss: 0.18638\n",
      "Epoch: 23 | Iteration: 71 | Classification loss: 0.00757 | Regression loss: 0.15577 | Running loss: 0.18646\n",
      "Epoch: 23 | Iteration: 72 | Classification loss: 0.01480 | Regression loss: 0.13564 | Running loss: 0.18646\n",
      "Epoch: 23 | Iteration: 73 | Classification loss: 0.07221 | Regression loss: 0.35223 | Running loss: 0.18714\n",
      "Epoch: 23 | Iteration: 74 | Classification loss: 0.00671 | Regression loss: 0.07753 | Running loss: 0.18691\n",
      "Epoch: 23 | Iteration: 75 | Classification loss: 0.02865 | Regression loss: 0.14712 | Running loss: 0.18708\n",
      "Epoch: 23 | Iteration: 76 | Classification loss: 0.03213 | Regression loss: 0.17014 | Running loss: 0.18698\n",
      "Epoch: 23 | Iteration: 77 | Classification loss: 0.01072 | Regression loss: 0.10739 | Running loss: 0.18671\n",
      "Epoch: 23 | Iteration: 78 | Classification loss: 0.03241 | Regression loss: 0.22063 | Running loss: 0.18630\n",
      "Epoch: 23 | Iteration: 79 | Classification loss: 0.02397 | Regression loss: 0.12585 | Running loss: 0.18642\n",
      "Epoch: 23 | Iteration: 80 | Classification loss: 0.02011 | Regression loss: 0.10062 | Running loss: 0.18634\n",
      "Epoch: 23 | Iteration: 81 | Classification loss: 0.03666 | Regression loss: 0.12426 | Running loss: 0.18649\n",
      "Epoch: 23 | Iteration: 82 | Classification loss: 0.01103 | Regression loss: 0.12696 | Running loss: 0.18600\n",
      "Epoch: 23 | Iteration: 83 | Classification loss: 0.03900 | Regression loss: 0.26628 | Running loss: 0.18638\n",
      "Epoch: 23 | Iteration: 84 | Classification loss: 0.00656 | Regression loss: 0.07495 | Running loss: 0.18608\n",
      "Epoch: 23 | Iteration: 85 | Classification loss: 0.05403 | Regression loss: 0.22263 | Running loss: 0.18629\n",
      "Epoch: 23 | Iteration: 86 | Classification loss: 0.01887 | Regression loss: 0.16479 | Running loss: 0.18628\n",
      "Epoch: 23 | Iteration: 87 | Classification loss: 0.02268 | Regression loss: 0.08587 | Running loss: 0.18620\n",
      "Epoch: 23 | Iteration: 88 | Classification loss: 0.01204 | Regression loss: 0.10711 | Running loss: 0.18616\n",
      "Epoch: 23 | Iteration: 89 | Classification loss: 0.08427 | Regression loss: 0.11380 | Running loss: 0.18626\n",
      "Epoch: 23 | Iteration: 90 | Classification loss: 0.01321 | Regression loss: 0.18198 | Running loss: 0.18626\n",
      "Epoch: 23 | Iteration: 91 | Classification loss: 0.01218 | Regression loss: 0.12639 | Running loss: 0.18604\n",
      "Epoch: 23 | Iteration: 92 | Classification loss: 0.02556 | Regression loss: 0.15214 | Running loss: 0.18618\n",
      "Epoch: 23 | Iteration: 93 | Classification loss: 0.05649 | Regression loss: 0.31929 | Running loss: 0.18659\n",
      "Epoch: 23 | Iteration: 94 | Classification loss: 0.01791 | Regression loss: 0.25897 | Running loss: 0.18686\n",
      "Epoch: 23 | Iteration: 95 | Classification loss: 0.01314 | Regression loss: 0.14734 | Running loss: 0.18687\n",
      "Epoch: 23 | Iteration: 96 | Classification loss: 0.01164 | Regression loss: 0.11616 | Running loss: 0.18675\n",
      "Epoch: 23 | Iteration: 97 | Classification loss: 0.00341 | Regression loss: 0.05839 | Running loss: 0.18662\n",
      "Epoch: 23 | Iteration: 98 | Classification loss: 0.02841 | Regression loss: 0.13227 | Running loss: 0.18637\n",
      "Epoch: 23 | Iteration: 99 | Classification loss: 0.02174 | Regression loss: 0.08517 | Running loss: 0.18620\n",
      "Epoch: 23 | Iteration: 100 | Classification loss: 0.03559 | Regression loss: 0.08736 | Running loss: 0.18619\n",
      "Epoch: 23 | Iteration: 101 | Classification loss: 0.04985 | Regression loss: 0.21943 | Running loss: 0.18642\n",
      "Epoch: 23 | Iteration: 102 | Classification loss: 0.05945 | Regression loss: 0.11071 | Running loss: 0.18615\n",
      "Epoch: 23 | Iteration: 103 | Classification loss: 0.01827 | Regression loss: 0.13439 | Running loss: 0.18618\n",
      "Epoch: 23 | Iteration: 104 | Classification loss: 0.04537 | Regression loss: 0.21991 | Running loss: 0.18650\n",
      "Epoch: 23 | Iteration: 105 | Classification loss: 0.01224 | Regression loss: 0.10602 | Running loss: 0.18645\n",
      "Epoch: 23 | Iteration: 106 | Classification loss: 0.02397 | Regression loss: 0.16344 | Running loss: 0.18658\n",
      "Epoch: 23 | Iteration: 107 | Classification loss: 0.12574 | Regression loss: 0.20350 | Running loss: 0.18662\n",
      "Epoch: 23 | Iteration: 108 | Classification loss: 0.07183 | Regression loss: 0.18864 | Running loss: 0.18692\n",
      "Epoch: 23 | Iteration: 109 | Classification loss: 0.01627 | Regression loss: 0.10372 | Running loss: 0.18670\n",
      "Epoch: 23 | Iteration: 110 | Classification loss: 0.11551 | Regression loss: 0.28291 | Running loss: 0.18731\n",
      "Epoch: 23 | Iteration: 111 | Classification loss: 0.01083 | Regression loss: 0.22050 | Running loss: 0.18715\n",
      "Epoch: 23 | Iteration: 112 | Classification loss: 0.00492 | Regression loss: 0.08600 | Running loss: 0.18710\n",
      "Epoch: 23 | Iteration: 113 | Classification loss: 0.06258 | Regression loss: 0.25582 | Running loss: 0.18725\n",
      "Epoch: 23 | Iteration: 114 | Classification loss: 0.03137 | Regression loss: 0.07533 | Running loss: 0.18677\n",
      "Epoch: 23 | Iteration: 115 | Classification loss: 0.00711 | Regression loss: 0.08846 | Running loss: 0.18667\n",
      "Epoch: 23 | Iteration: 116 | Classification loss: 0.05566 | Regression loss: 0.23262 | Running loss: 0.18681\n",
      "Epoch: 23 | Iteration: 117 | Classification loss: 0.04539 | Regression loss: 0.32622 | Running loss: 0.18675\n",
      "Epoch: 23 | Iteration: 118 | Classification loss: 0.01655 | Regression loss: 0.12981 | Running loss: 0.18686\n",
      "Epoch: 23 | Iteration: 119 | Classification loss: 0.01761 | Regression loss: 0.20025 | Running loss: 0.18676\n",
      "Epoch: 23 | Iteration: 120 | Classification loss: 0.00212 | Regression loss: 0.04484 | Running loss: 0.18660\n",
      "Epoch: 23 | Iteration: 121 | Classification loss: 0.01756 | Regression loss: 0.11471 | Running loss: 0.18657\n",
      "Epoch: 23 | Iteration: 122 | Classification loss: 0.00317 | Regression loss: 0.05384 | Running loss: 0.18629\n",
      "Epoch: 23 | Iteration: 123 | Classification loss: 0.17101 | Regression loss: 0.35898 | Running loss: 0.18709\n",
      "Epoch: 23 | Iteration: 124 | Classification loss: 0.02062 | Regression loss: 0.22517 | Running loss: 0.18712\n",
      "Epoch: 23 | Iteration: 125 | Classification loss: 0.00864 | Regression loss: 0.08376 | Running loss: 0.18671\n",
      "Epoch: 23 | Iteration: 126 | Classification loss: 0.00418 | Regression loss: 0.05880 | Running loss: 0.18646\n",
      "Epoch: 23 | Iteration: 127 | Classification loss: 0.01027 | Regression loss: 0.12938 | Running loss: 0.18639\n",
      "Epoch: 23 | Iteration: 128 | Classification loss: 0.01554 | Regression loss: 0.12390 | Running loss: 0.18629\n",
      "Epoch: 23 | Iteration: 129 | Classification loss: 0.03880 | Regression loss: 0.17943 | Running loss: 0.18642\n",
      "Epoch: 23 | Iteration: 130 | Classification loss: 0.01818 | Regression loss: 0.14476 | Running loss: 0.18646\n",
      "Epoch: 23 | Iteration: 131 | Classification loss: 0.07203 | Regression loss: 0.23479 | Running loss: 0.18656\n",
      "Epoch: 23 | Iteration: 132 | Classification loss: 0.03761 | Regression loss: 0.10575 | Running loss: 0.18644\n",
      "Epoch: 23 | Iteration: 133 | Classification loss: 0.02587 | Regression loss: 0.18095 | Running loss: 0.18621\n",
      "Epoch: 23 | Iteration: 134 | Classification loss: 0.00702 | Regression loss: 0.08488 | Running loss: 0.18613\n",
      "Epoch: 23 | Iteration: 135 | Classification loss: 0.04014 | Regression loss: 0.24552 | Running loss: 0.18624\n",
      "Epoch: 23 | Iteration: 136 | Classification loss: 0.03403 | Regression loss: 0.12393 | Running loss: 0.18610\n",
      "Epoch: 23 | Iteration: 137 | Classification loss: 0.02304 | Regression loss: 0.12826 | Running loss: 0.18617\n",
      "Epoch: 23 | Iteration: 138 | Classification loss: 0.04549 | Regression loss: 0.07119 | Running loss: 0.18621\n",
      "Epoch: 23 | Iteration: 139 | Classification loss: 0.03219 | Regression loss: 0.14531 | Running loss: 0.18611\n",
      "Epoch: 23 | Iteration: 140 | Classification loss: 0.10278 | Regression loss: 0.23789 | Running loss: 0.18664\n",
      "Epoch: 23 | Iteration: 141 | Classification loss: 0.15729 | Regression loss: 0.39259 | Running loss: 0.18743\n",
      "Epoch: 23 | Iteration: 142 | Classification loss: 0.00819 | Regression loss: 0.14607 | Running loss: 0.18735\n",
      "Epoch: 23 | Iteration: 143 | Classification loss: 0.01071 | Regression loss: 0.07460 | Running loss: 0.18738\n",
      "Epoch: 23 | Iteration: 144 | Classification loss: 0.00605 | Regression loss: 0.13906 | Running loss: 0.18742\n",
      "Epoch: 23 | Iteration: 145 | Classification loss: 0.01634 | Regression loss: 0.09984 | Running loss: 0.18708\n",
      "Epoch: 23 | Iteration: 146 | Classification loss: 0.03472 | Regression loss: 0.07431 | Running loss: 0.18678\n",
      "Epoch: 23 | Iteration: 147 | Classification loss: 0.02388 | Regression loss: 0.17223 | Running loss: 0.18700\n",
      "Epoch: 23 | Iteration: 148 | Classification loss: 0.02224 | Regression loss: 0.17046 | Running loss: 0.18726\n",
      "Epoch: 23 | Iteration: 149 | Classification loss: 0.00711 | Regression loss: 0.04852 | Running loss: 0.18708\n",
      "Epoch: 23 | Iteration: 150 | Classification loss: 0.03501 | Regression loss: 0.19389 | Running loss: 0.18721\n",
      "Epoch: 23 | Iteration: 151 | Classification loss: 0.06503 | Regression loss: 0.19638 | Running loss: 0.18742\n",
      "Epoch: 23 | Iteration: 152 | Classification loss: 0.03189 | Regression loss: 0.22334 | Running loss: 0.18759\n",
      "Epoch: 23 | Iteration: 153 | Classification loss: 0.02958 | Regression loss: 0.23876 | Running loss: 0.18784\n",
      "Epoch: 23 | Iteration: 154 | Classification loss: 0.01206 | Regression loss: 0.15250 | Running loss: 0.18799\n",
      "Epoch: 23 | Iteration: 155 | Classification loss: 0.01768 | Regression loss: 0.08947 | Running loss: 0.18762\n",
      "Epoch: 23 | Iteration: 156 | Classification loss: 0.03298 | Regression loss: 0.22416 | Running loss: 0.18781\n",
      "Epoch: 23 | Iteration: 157 | Classification loss: 0.00315 | Regression loss: 0.11065 | Running loss: 0.18748\n",
      "Epoch: 23 | Iteration: 158 | Classification loss: 0.00723 | Regression loss: 0.12702 | Running loss: 0.18732\n",
      "Epoch: 23 | Iteration: 159 | Classification loss: 0.08496 | Regression loss: 0.12606 | Running loss: 0.18710\n",
      "Epoch: 23 | Iteration: 160 | Classification loss: 0.00855 | Regression loss: 0.10590 | Running loss: 0.18697\n",
      "Epoch: 23 | Iteration: 161 | Classification loss: 0.02642 | Regression loss: 0.24618 | Running loss: 0.18679\n",
      "Epoch: 23 | Iteration: 162 | Classification loss: 0.00452 | Regression loss: 0.06795 | Running loss: 0.18525\n",
      "Epoch: 23 | Iteration: 163 | Classification loss: 0.04006 | Regression loss: 0.17549 | Running loss: 0.18527\n",
      "Epoch: 23 | Iteration: 164 | Classification loss: 0.01584 | Regression loss: 0.08050 | Running loss: 0.18517\n",
      "Epoch: 23 | Iteration: 165 | Classification loss: 0.01239 | Regression loss: 0.10778 | Running loss: 0.18460\n",
      "Epoch: 23 | Iteration: 166 | Classification loss: 0.00736 | Regression loss: 0.11657 | Running loss: 0.18436\n",
      "Epoch: 23 | Iteration: 167 | Classification loss: 0.02149 | Regression loss: 0.07424 | Running loss: 0.18378\n",
      "Epoch: 23 | Iteration: 168 | Classification loss: 0.16102 | Regression loss: 0.31281 | Running loss: 0.18445\n",
      "Epoch: 23 | Iteration: 169 | Classification loss: 0.03651 | Regression loss: 0.18003 | Running loss: 0.18436\n",
      "Epoch: 23 | Iteration: 170 | Classification loss: 0.00901 | Regression loss: 0.11271 | Running loss: 0.18387\n",
      "Epoch: 23 | Iteration: 171 | Classification loss: 0.04425 | Regression loss: 0.17303 | Running loss: 0.18397\n",
      "Epoch: 23 | Iteration: 172 | Classification loss: 0.00851 | Regression loss: 0.09929 | Running loss: 0.18359\n",
      "Epoch: 23 | Iteration: 173 | Classification loss: 0.02322 | Regression loss: 0.15600 | Running loss: 0.18354\n",
      "Epoch: 23 | Iteration: 174 | Classification loss: 0.01142 | Regression loss: 0.15986 | Running loss: 0.18376\n",
      "Epoch: 23 | Iteration: 175 | Classification loss: 0.01486 | Regression loss: 0.17391 | Running loss: 0.18384\n",
      "Epoch: 23 | Iteration: 176 | Classification loss: 0.00491 | Regression loss: 0.03442 | Running loss: 0.18320\n",
      "Epoch: 23 | Iteration: 177 | Classification loss: 0.01538 | Regression loss: 0.11984 | Running loss: 0.18290\n",
      "Epoch: 23 | Iteration: 178 | Classification loss: 0.02089 | Regression loss: 0.08809 | Running loss: 0.18278\n",
      "Epoch: 23 | Iteration: 179 | Classification loss: 0.01028 | Regression loss: 0.11824 | Running loss: 0.18261\n",
      "Epoch: 23 | Iteration: 180 | Classification loss: 0.01575 | Regression loss: 0.09200 | Running loss: 0.18262\n",
      "Epoch: 23 | Iteration: 181 | Classification loss: 0.02086 | Regression loss: 0.11318 | Running loss: 0.18260\n",
      "Epoch: 23 | Iteration: 182 | Classification loss: 0.03370 | Regression loss: 0.06561 | Running loss: 0.18254\n",
      "Epoch: 23 | Iteration: 183 | Classification loss: 0.00176 | Regression loss: 0.05612 | Running loss: 0.18240\n",
      "Epoch: 23 | Iteration: 184 | Classification loss: 0.00003 | Regression loss: 0.00000 | Running loss: 0.18216\n",
      "Epoch: 23 | Iteration: 185 | Classification loss: 0.19598 | Regression loss: 0.20948 | Running loss: 0.18247\n",
      "Epoch: 23 | Iteration: 186 | Classification loss: 0.02368 | Regression loss: 0.10458 | Running loss: 0.18209\n",
      "Epoch: 23 | Iteration: 187 | Classification loss: 0.02439 | Regression loss: 0.11957 | Running loss: 0.18150\n",
      "Epoch: 23 | Iteration: 188 | Classification loss: 0.07502 | Regression loss: 0.31941 | Running loss: 0.18203\n",
      "Epoch: 23 | Iteration: 189 | Classification loss: 0.00682 | Regression loss: 0.12867 | Running loss: 0.18212\n",
      "Epoch: 23 | Iteration: 190 | Classification loss: 0.00311 | Regression loss: 0.09290 | Running loss: 0.18210\n",
      "Epoch: 23 | Iteration: 191 | Classification loss: 0.00616 | Regression loss: 0.06509 | Running loss: 0.18200\n",
      "Epoch: 23 | Iteration: 192 | Classification loss: 0.04027 | Regression loss: 0.25523 | Running loss: 0.18213\n",
      "Epoch: 23 | Iteration: 193 | Classification loss: 0.04233 | Regression loss: 0.17271 | Running loss: 0.18217\n",
      "Epoch: 23 | Iteration: 194 | Classification loss: 0.00554 | Regression loss: 0.13552 | Running loss: 0.18220\n",
      "Epoch: 23 | Iteration: 195 | Classification loss: 0.00285 | Regression loss: 0.05511 | Running loss: 0.18209\n",
      "Epoch: 23 | Iteration: 196 | Classification loss: 0.02796 | Regression loss: 0.18530 | Running loss: 0.18231\n",
      "Epoch: 23 | Iteration: 197 | Classification loss: 0.02265 | Regression loss: 0.06771 | Running loss: 0.18213\n",
      "Epoch: 23 | Iteration: 198 | Classification loss: 0.02598 | Regression loss: 0.12398 | Running loss: 0.18222\n",
      "Epoch: 23 | Iteration: 199 | Classification loss: 0.01533 | Regression loss: 0.08092 | Running loss: 0.18229\n",
      "Epoch: 23 | Iteration: 200 | Classification loss: 0.02067 | Regression loss: 0.18649 | Running loss: 0.18245\n",
      "Epoch: 23 | Iteration: 201 | Classification loss: 0.01004 | Regression loss: 0.12835 | Running loss: 0.18247\n",
      "Epoch: 23 | Iteration: 202 | Classification loss: 0.00540 | Regression loss: 0.08933 | Running loss: 0.18210\n",
      "Epoch: 23 | Iteration: 203 | Classification loss: 0.03092 | Regression loss: 0.06414 | Running loss: 0.18207\n",
      "Epoch: 23 | Iteration: 204 | Classification loss: 0.03217 | Regression loss: 0.22193 | Running loss: 0.18233\n",
      "Epoch: 23 | Iteration: 205 | Classification loss: 0.00728 | Regression loss: 0.06669 | Running loss: 0.18222\n",
      "Epoch: 23 | Iteration: 206 | Classification loss: 0.01671 | Regression loss: 0.18518 | Running loss: 0.18233\n",
      "Epoch: 23 | Iteration: 207 | Classification loss: 0.01776 | Regression loss: 0.12394 | Running loss: 0.18214\n",
      "Epoch: 23 | Iteration: 208 | Classification loss: 0.00466 | Regression loss: 0.10462 | Running loss: 0.18169\n",
      "Epoch: 23 | Iteration: 209 | Classification loss: 0.20539 | Regression loss: 0.18218 | Running loss: 0.18213\n",
      "Epoch: 23 | Iteration: 210 | Classification loss: 0.01838 | Regression loss: 0.07709 | Running loss: 0.18194\n",
      "Epoch: 23 | Iteration: 211 | Classification loss: 0.01095 | Regression loss: 0.12924 | Running loss: 0.18188\n",
      "Epoch: 23 | Iteration: 212 | Classification loss: 0.04300 | Regression loss: 0.18451 | Running loss: 0.18201\n",
      "Epoch: 23 | Iteration: 213 | Classification loss: 0.01968 | Regression loss: 0.09410 | Running loss: 0.18210\n",
      "Epoch: 23 | Iteration: 214 | Classification loss: 0.02008 | Regression loss: 0.18930 | Running loss: 0.18214\n",
      "Epoch: 23 | Iteration: 215 | Classification loss: 0.01982 | Regression loss: 0.14355 | Running loss: 0.18216\n",
      "Epoch: 23 | Iteration: 216 | Classification loss: 0.01160 | Regression loss: 0.18874 | Running loss: 0.18231\n",
      "Epoch: 23 | Iteration: 217 | Classification loss: 0.02531 | Regression loss: 0.10351 | Running loss: 0.18158\n",
      "Epoch: 23 | Iteration: 218 | Classification loss: 0.09685 | Regression loss: 0.26589 | Running loss: 0.18160\n",
      "Epoch: 23 | Iteration: 219 | Classification loss: 0.06956 | Regression loss: 0.16371 | Running loss: 0.18176\n",
      "Epoch: 23 | Iteration: 220 | Classification loss: 0.00403 | Regression loss: 0.09243 | Running loss: 0.18084\n",
      "Epoch: 23 | Iteration: 221 | Classification loss: 0.06184 | Regression loss: 0.14193 | Running loss: 0.18107\n",
      "Epoch: 23 | Iteration: 222 | Classification loss: 0.16225 | Regression loss: 0.32222 | Running loss: 0.18164\n",
      "Epoch: 23 | Iteration: 223 | Classification loss: 0.00509 | Regression loss: 0.09694 | Running loss: 0.18146\n",
      "Epoch: 23 | Iteration: 224 | Classification loss: 0.03282 | Regression loss: 0.07758 | Running loss: 0.18143\n",
      "Epoch: 23 | Iteration: 225 | Classification loss: 0.00943 | Regression loss: 0.10338 | Running loss: 0.18114\n",
      "Epoch: 23 | Iteration: 226 | Classification loss: 0.00930 | Regression loss: 0.16218 | Running loss: 0.18114\n",
      "Epoch: 23 | Iteration: 227 | Classification loss: 0.11249 | Regression loss: 0.25845 | Running loss: 0.18162\n",
      "Epoch: 23 | Iteration: 228 | Classification loss: 0.03239 | Regression loss: 0.08444 | Running loss: 0.18175\n",
      "Epoch: 23 | Iteration: 229 | Classification loss: 0.02695 | Regression loss: 0.08126 | Running loss: 0.18149\n",
      "Epoch: 23 | Iteration: 230 | Classification loss: 0.01959 | Regression loss: 0.10397 | Running loss: 0.18142\n",
      "Epoch: 23 | Iteration: 231 | Classification loss: 0.03618 | Regression loss: 0.14896 | Running loss: 0.18151\n",
      "Epoch: 23 | Iteration: 232 | Classification loss: 0.02072 | Regression loss: 0.13704 | Running loss: 0.18144\n",
      "Epoch: 23 | Iteration: 233 | Classification loss: 0.03198 | Regression loss: 0.21652 | Running loss: 0.18168\n",
      "Epoch: 23 | Iteration: 234 | Classification loss: 0.00835 | Regression loss: 0.11926 | Running loss: 0.18175\n",
      "Epoch: 23 | Iteration: 235 | Classification loss: 0.09283 | Regression loss: 0.26483 | Running loss: 0.18194\n",
      "Epoch: 23 | Iteration: 236 | Classification loss: 0.03065 | Regression loss: 0.14122 | Running loss: 0.18199\n",
      "Epoch: 23 | Iteration: 237 | Classification loss: 0.92465 | Regression loss: 0.10018 | Running loss: 0.18334\n",
      "Epoch: 23 | Iteration: 238 | Classification loss: 0.01240 | Regression loss: 0.12911 | Running loss: 0.18332\n",
      "Epoch: 23 | Iteration: 239 | Classification loss: 0.06234 | Regression loss: 0.20334 | Running loss: 0.18361\n",
      "Epoch: 23 | Iteration: 240 | Classification loss: 0.03447 | Regression loss: 0.11820 | Running loss: 0.18364\n",
      "Epoch: 23 | Iteration: 241 | Classification loss: 0.08020 | Regression loss: 0.18482 | Running loss: 0.18390\n",
      "Epoch: 23 | Iteration: 242 | Classification loss: 0.00929 | Regression loss: 0.10673 | Running loss: 0.18389\n",
      "Epoch: 23 | Iteration: 243 | Classification loss: 0.03344 | Regression loss: 0.20270 | Running loss: 0.18402\n",
      "Epoch: 23 | Iteration: 244 | Classification loss: 0.08135 | Regression loss: 0.18260 | Running loss: 0.18445\n",
      "Epoch: 23 | Iteration: 245 | Classification loss: 0.09472 | Regression loss: 0.25353 | Running loss: 0.18487\n",
      "Epoch: 23 | Iteration: 246 | Classification loss: 0.02163 | Regression loss: 0.12048 | Running loss: 0.18487\n",
      "Epoch: 23 | Iteration: 247 | Classification loss: 0.00330 | Regression loss: 0.13483 | Running loss: 0.18487\n",
      "Epoch: 23 | Iteration: 248 | Classification loss: 0.00826 | Regression loss: 0.10179 | Running loss: 0.18482\n",
      "Epoch: 23 | Iteration: 249 | Classification loss: 0.02265 | Regression loss: 0.13254 | Running loss: 0.18482\n",
      "Epoch: 23 | Iteration: 250 | Classification loss: 0.01125 | Regression loss: 0.15179 | Running loss: 0.18504\n",
      "Epoch: 23 | Iteration: 251 | Classification loss: 0.02729 | Regression loss: 0.11646 | Running loss: 0.18484\n",
      "Epoch: 23 | Iteration: 252 | Classification loss: 0.01523 | Regression loss: 0.26408 | Running loss: 0.18449\n",
      "Epoch: 23 | Iteration: 253 | Classification loss: 0.04265 | Regression loss: 0.19974 | Running loss: 0.18476\n",
      "Epoch: 23 | Iteration: 254 | Classification loss: 0.00728 | Regression loss: 0.10451 | Running loss: 0.18451\n",
      "Epoch: 23 | Iteration: 255 | Classification loss: 0.03046 | Regression loss: 0.15771 | Running loss: 0.18449\n",
      "Epoch: 23 | Iteration: 256 | Classification loss: 0.02231 | Regression loss: 0.08175 | Running loss: 0.18437\n",
      "Epoch: 23 | Iteration: 257 | Classification loss: 0.01666 | Regression loss: 0.05578 | Running loss: 0.18422\n",
      "Epoch: 23 | Iteration: 258 | Classification loss: 0.01259 | Regression loss: 0.09274 | Running loss: 0.18402\n",
      "Epoch: 23 | Iteration: 259 | Classification loss: 0.03611 | Regression loss: 0.17972 | Running loss: 0.18423\n",
      "Epoch: 23 | Iteration: 260 | Classification loss: 0.03948 | Regression loss: 0.14837 | Running loss: 0.18442\n",
      "Epoch: 23 | Iteration: 261 | Classification loss: 0.06593 | Regression loss: 0.14636 | Running loss: 0.18438\n",
      "Epoch: 23 | Iteration: 262 | Classification loss: 0.02031 | Regression loss: 0.14664 | Running loss: 0.18402\n",
      "Epoch: 23 | Iteration: 263 | Classification loss: 0.01495 | Regression loss: 0.18505 | Running loss: 0.18419\n",
      "Epoch: 23 | Iteration: 264 | Classification loss: 0.02535 | Regression loss: 0.15344 | Running loss: 0.18434\n",
      "Epoch: 23 | Iteration: 265 | Classification loss: 0.16222 | Regression loss: 0.40737 | Running loss: 0.18513\n",
      "Epoch: 23 | Iteration: 266 | Classification loss: 0.02702 | Regression loss: 0.24382 | Running loss: 0.18526\n",
      "Epoch: 23 | Iteration: 267 | Classification loss: 0.05507 | Regression loss: 0.22696 | Running loss: 0.18494\n",
      "Epoch: 23 | Iteration: 268 | Classification loss: 0.04803 | Regression loss: 0.12203 | Running loss: 0.18508\n",
      "Epoch: 23 | Iteration: 269 | Classification loss: 0.06603 | Regression loss: 0.21240 | Running loss: 0.18525\n",
      "Epoch: 23 | Iteration: 270 | Classification loss: 0.07347 | Regression loss: 0.21460 | Running loss: 0.18496\n",
      "Epoch: 23 | Iteration: 271 | Classification loss: 0.01550 | Regression loss: 0.18450 | Running loss: 0.18512\n",
      "Epoch: 23 | Iteration: 272 | Classification loss: 0.01423 | Regression loss: 0.10767 | Running loss: 0.18505\n",
      "Epoch: 23 | Iteration: 273 | Classification loss: 0.04381 | Regression loss: 0.15876 | Running loss: 0.18507\n",
      "Epoch: 23 | Iteration: 274 | Classification loss: 0.01723 | Regression loss: 0.10547 | Running loss: 0.18464\n",
      "Epoch: 23 | Iteration: 275 | Classification loss: 0.03544 | Regression loss: 0.21226 | Running loss: 0.18481\n",
      "Epoch: 23 | Iteration: 276 | Classification loss: 0.12605 | Regression loss: 0.24302 | Running loss: 0.18484\n",
      "Epoch: 23 | Iteration: 277 | Classification loss: 0.00268 | Regression loss: 0.09080 | Running loss: 0.18471\n",
      "Epoch: 23 | Iteration: 278 | Classification loss: 0.00427 | Regression loss: 0.06502 | Running loss: 0.18464\n",
      "Epoch: 23 | Iteration: 279 | Classification loss: 0.00998 | Regression loss: 0.15425 | Running loss: 0.18481\n",
      "Epoch: 23 | Iteration: 280 | Classification loss: 0.03545 | Regression loss: 0.15816 | Running loss: 0.18476\n",
      "Epoch: 23 | Iteration: 281 | Classification loss: 0.01784 | Regression loss: 0.04927 | Running loss: 0.18470\n",
      "Epoch: 23 | Iteration: 282 | Classification loss: 0.19529 | Regression loss: 0.20617 | Running loss: 0.18474\n",
      "Epoch: 23 | Iteration: 283 | Classification loss: 0.09199 | Regression loss: 0.04880 | Running loss: 0.18446\n",
      "Epoch: 23 | Iteration: 284 | Classification loss: 0.03357 | Regression loss: 0.17377 | Running loss: 0.18371\n",
      "Epoch: 23 | Iteration: 285 | Classification loss: 0.02145 | Regression loss: 0.17380 | Running loss: 0.18353\n",
      "Epoch: 23 | Iteration: 286 | Classification loss: 0.03301 | Regression loss: 0.20723 | Running loss: 0.18368\n",
      "Epoch: 23 | Iteration: 287 | Classification loss: 0.04280 | Regression loss: 0.28312 | Running loss: 0.18385\n",
      "Epoch: 23 | Iteration: 288 | Classification loss: 0.01873 | Regression loss: 0.17882 | Running loss: 0.18370\n",
      "Epoch: 23 | Iteration: 289 | Classification loss: 0.07267 | Regression loss: 0.22587 | Running loss: 0.18386\n",
      "Epoch: 23 | Iteration: 290 | Classification loss: 0.01496 | Regression loss: 0.16566 | Running loss: 0.18394\n",
      "Epoch: 23 | Iteration: 291 | Classification loss: 0.02657 | Regression loss: 0.12893 | Running loss: 0.18410\n",
      "Epoch: 23 | Iteration: 292 | Classification loss: 0.04314 | Regression loss: 0.12857 | Running loss: 0.18406\n",
      "Epoch: 23 | Iteration: 293 | Classification loss: 0.02889 | Regression loss: 0.20182 | Running loss: 0.18418\n",
      "Epoch: 23 | Iteration: 294 | Classification loss: 0.02376 | Regression loss: 0.11372 | Running loss: 0.18405\n",
      "Epoch: 23 | Iteration: 295 | Classification loss: 0.03046 | Regression loss: 0.08618 | Running loss: 0.18373\n",
      "Epoch: 23 | Iteration: 296 | Classification loss: 0.02570 | Regression loss: 0.17277 | Running loss: 0.18388\n",
      "Epoch: 23 | Iteration: 297 | Classification loss: 0.01031 | Regression loss: 0.14442 | Running loss: 0.18407\n",
      "Epoch: 23 | Iteration: 298 | Classification loss: 0.03550 | Regression loss: 0.21800 | Running loss: 0.18421\n",
      "Epoch: 23 | Iteration: 299 | Classification loss: 0.01204 | Regression loss: 0.09306 | Running loss: 0.18403\n",
      "Epoch: 23 | Iteration: 300 | Classification loss: 0.01191 | Regression loss: 0.16180 | Running loss: 0.18381\n",
      "Epoch: 23 | Iteration: 301 | Classification loss: 0.02959 | Regression loss: 0.13912 | Running loss: 0.18395\n",
      "Epoch: 23 | Iteration: 302 | Classification loss: 0.01838 | Regression loss: 0.09214 | Running loss: 0.18394\n",
      "Epoch: 23 | Iteration: 303 | Classification loss: 0.03248 | Regression loss: 0.18714 | Running loss: 0.18398\n",
      "Epoch: 23 | Iteration: 304 | Classification loss: 0.00961 | Regression loss: 0.11372 | Running loss: 0.18366\n",
      "Epoch: 23 | Iteration: 305 | Classification loss: 0.03828 | Regression loss: 0.09792 | Running loss: 0.18347\n",
      "Epoch: 23 | Iteration: 306 | Classification loss: 0.00392 | Regression loss: 0.05170 | Running loss: 0.18342\n",
      "Epoch: 23 | Iteration: 307 | Classification loss: 0.01902 | Regression loss: 0.13486 | Running loss: 0.18331\n",
      "Epoch: 23 | Iteration: 308 | Classification loss: 0.00773 | Regression loss: 0.09666 | Running loss: 0.18341\n",
      "Epoch: 23 | Iteration: 309 | Classification loss: 0.10862 | Regression loss: 0.41380 | Running loss: 0.18364\n",
      "Epoch: 23 | Iteration: 310 | Classification loss: 0.00353 | Regression loss: 0.07523 | Running loss: 0.18364\n",
      "Epoch: 23 | Iteration: 311 | Classification loss: 0.02002 | Regression loss: 0.14262 | Running loss: 0.18337\n",
      "Epoch: 23 | Iteration: 312 | Classification loss: 0.00140 | Regression loss: 0.08210 | Running loss: 0.18305\n",
      "Epoch: 23 | Iteration: 313 | Classification loss: 0.00177 | Regression loss: 0.05634 | Running loss: 0.18250\n",
      "Epoch: 23 | Iteration: 314 | Classification loss: 0.03402 | Regression loss: 0.13035 | Running loss: 0.18228\n",
      "Epoch: 23 | Iteration: 315 | Classification loss: 0.00253 | Regression loss: 0.10235 | Running loss: 0.18239\n",
      "Epoch: 23 | Iteration: 316 | Classification loss: 0.06230 | Regression loss: 0.32369 | Running loss: 0.18296\n",
      "Epoch: 23 | Iteration: 317 | Classification loss: 0.05116 | Regression loss: 0.12514 | Running loss: 0.18299\n",
      "Epoch: 23 | Iteration: 318 | Classification loss: 0.00885 | Regression loss: 0.14903 | Running loss: 0.18297\n",
      "Epoch: 23 | Iteration: 319 | Classification loss: 0.04092 | Regression loss: 0.26119 | Running loss: 0.18330\n",
      "Epoch: 23 | Iteration: 320 | Classification loss: 0.08866 | Regression loss: 0.12347 | Running loss: 0.18358\n",
      "Epoch: 23 | Iteration: 321 | Classification loss: 0.02459 | Regression loss: 0.19282 | Running loss: 0.18359\n",
      "Epoch: 23 | Iteration: 322 | Classification loss: 0.00885 | Regression loss: 0.14628 | Running loss: 0.18362\n",
      "Epoch: 23 | Iteration: 323 | Classification loss: 0.02467 | Regression loss: 0.20790 | Running loss: 0.18369\n",
      "Epoch: 23 | Iteration: 324 | Classification loss: 0.00411 | Regression loss: 0.09341 | Running loss: 0.18374\n",
      "Epoch: 23 | Iteration: 325 | Classification loss: 0.01368 | Regression loss: 0.10892 | Running loss: 0.18386\n",
      "Epoch: 23 | Iteration: 326 | Classification loss: 0.02088 | Regression loss: 0.10427 | Running loss: 0.18388\n",
      "Epoch: 23 | Iteration: 327 | Classification loss: 0.05875 | Regression loss: 0.26540 | Running loss: 0.18422\n",
      "Epoch: 23 | Iteration: 328 | Classification loss: 0.04266 | Regression loss: 0.21704 | Running loss: 0.18445\n",
      "Epoch: 23 | Iteration: 329 | Classification loss: 0.01831 | Regression loss: 0.26127 | Running loss: 0.18487\n",
      "Epoch: 23 | Iteration: 330 | Classification loss: 0.01390 | Regression loss: 0.13719 | Running loss: 0.18492\n",
      "Epoch: 23 | Iteration: 331 | Classification loss: 0.01261 | Regression loss: 0.12089 | Running loss: 0.18489\n",
      "Epoch: 23 | Iteration: 332 | Classification loss: 0.01512 | Regression loss: 0.19120 | Running loss: 0.18501\n",
      "Epoch: 23 | Iteration: 333 | Classification loss: 0.02463 | Regression loss: 0.14640 | Running loss: 0.18511\n",
      "Epoch: 23 | Iteration: 334 | Classification loss: 0.01047 | Regression loss: 0.10555 | Running loss: 0.18517\n",
      "Epoch: 23 | Iteration: 335 | Classification loss: 0.05458 | Regression loss: 0.18038 | Running loss: 0.18550\n",
      "Epoch: 23 | Iteration: 336 | Classification loss: 0.01244 | Regression loss: 0.10203 | Running loss: 0.18543\n",
      "Epoch: 23 | Iteration: 337 | Classification loss: 0.00896 | Regression loss: 0.16761 | Running loss: 0.18557\n",
      "Epoch: 23 | Iteration: 338 | Classification loss: 0.05918 | Regression loss: 0.37091 | Running loss: 0.18614\n",
      "Epoch: 23 | Iteration: 339 | Classification loss: 0.02384 | Regression loss: 0.12572 | Running loss: 0.18585\n",
      "Epoch: 23 | Iteration: 340 | Classification loss: 0.00818 | Regression loss: 0.12499 | Running loss: 0.18568\n",
      "Epoch: 23 | Iteration: 341 | Classification loss: 0.01206 | Regression loss: 0.07666 | Running loss: 0.18534\n",
      "Epoch: 23 | Iteration: 342 | Classification loss: 0.09140 | Regression loss: 0.18677 | Running loss: 0.18563\n",
      "Epoch: 23 | Iteration: 343 | Classification loss: 0.01733 | Regression loss: 0.20207 | Running loss: 0.18584\n",
      "Epoch: 23 | Iteration: 344 | Classification loss: 0.01085 | Regression loss: 0.18940 | Running loss: 0.18577\n",
      "Epoch: 23 | Iteration: 345 | Classification loss: 0.00731 | Regression loss: 0.11480 | Running loss: 0.18563\n",
      "Epoch: 23 | Iteration: 346 | Classification loss: 0.07977 | Regression loss: 0.21712 | Running loss: 0.18574\n",
      "Epoch: 23 | Iteration: 347 | Classification loss: 0.08223 | Regression loss: 0.21516 | Running loss: 0.18583\n",
      "Epoch: 23 | Iteration: 348 | Classification loss: 0.01213 | Regression loss: 0.12908 | Running loss: 0.18603\n",
      "Epoch: 23 | Iteration: 349 | Classification loss: 0.01042 | Regression loss: 0.10162 | Running loss: 0.18594\n",
      "Epoch: 23 | Iteration: 350 | Classification loss: 0.03315 | Regression loss: 0.30713 | Running loss: 0.18631\n",
      "Epoch: 23 | Iteration: 351 | Classification loss: 0.05043 | Regression loss: 0.16664 | Running loss: 0.18649\n",
      "Epoch: 23 | Iteration: 352 | Classification loss: 0.00924 | Regression loss: 0.11552 | Running loss: 0.18648\n",
      "Epoch: 23 | Iteration: 353 | Classification loss: 0.00752 | Regression loss: 0.06572 | Running loss: 0.18643\n",
      "Epoch: 23 | Iteration: 354 | Classification loss: 0.07997 | Regression loss: 0.22921 | Running loss: 0.18696\n",
      "Epoch: 23 | Iteration: 355 | Classification loss: 0.01137 | Regression loss: 0.06448 | Running loss: 0.18688\n",
      "Epoch: 23 | Iteration: 356 | Classification loss: 0.00683 | Regression loss: 0.08527 | Running loss: 0.18673\n",
      "Epoch: 23 | Iteration: 357 | Classification loss: 0.00514 | Regression loss: 0.08207 | Running loss: 0.18653\n",
      "Epoch: 23 | Iteration: 358 | Classification loss: 0.04899 | Regression loss: 0.15210 | Running loss: 0.18669\n",
      "Epoch: 23 | Iteration: 359 | Classification loss: 0.04495 | Regression loss: 0.18110 | Running loss: 0.18674\n",
      "Epoch: 23 | Iteration: 360 | Classification loss: 0.01706 | Regression loss: 0.21730 | Running loss: 0.18701\n",
      "Epoch: 23 | Iteration: 361 | Classification loss: 0.11580 | Regression loss: 0.20566 | Running loss: 0.18719\n",
      "Epoch: 23 | Iteration: 362 | Classification loss: 0.00390 | Regression loss: 0.05990 | Running loss: 0.18683\n",
      "Epoch: 23 | Iteration: 363 | Classification loss: 0.02471 | Regression loss: 0.12798 | Running loss: 0.18680\n",
      "Epoch: 23 | Iteration: 364 | Classification loss: 0.01652 | Regression loss: 0.05519 | Running loss: 0.18664\n",
      "Epoch: 23 | Iteration: 365 | Classification loss: 0.00439 | Regression loss: 0.11682 | Running loss: 0.18652\n",
      "Epoch: 23 | Iteration: 366 | Classification loss: 0.04044 | Regression loss: 0.17314 | Running loss: 0.18665\n",
      "Epoch: 23 | Iteration: 367 | Classification loss: 0.01975 | Regression loss: 0.14091 | Running loss: 0.18673\n",
      "Epoch: 23 | Iteration: 368 | Classification loss: 0.00912 | Regression loss: 0.19212 | Running loss: 0.18669\n",
      "Epoch: 23 | Iteration: 369 | Classification loss: 0.00662 | Regression loss: 0.13418 | Running loss: 0.18669\n",
      "Epoch: 23 | Iteration: 370 | Classification loss: 0.03145 | Regression loss: 0.27811 | Running loss: 0.18712\n",
      "Epoch: 23 | Iteration: 371 | Classification loss: 0.02100 | Regression loss: 0.18607 | Running loss: 0.18720\n",
      "Epoch: 23 | Iteration: 372 | Classification loss: 0.01553 | Regression loss: 0.07729 | Running loss: 0.18680\n",
      "Epoch: 23 | Iteration: 373 | Classification loss: 0.01563 | Regression loss: 0.10326 | Running loss: 0.18679\n",
      "Epoch: 23 | Iteration: 374 | Classification loss: 0.00692 | Regression loss: 0.11708 | Running loss: 0.18648\n",
      "Epoch: 23 | Iteration: 375 | Classification loss: 0.03015 | Regression loss: 0.13705 | Running loss: 0.18658\n",
      "Epoch: 23 | Iteration: 376 | Classification loss: 0.02876 | Regression loss: 0.20072 | Running loss: 0.18635\n",
      "Epoch: 23 | Iteration: 377 | Classification loss: 0.04943 | Regression loss: 0.18209 | Running loss: 0.18655\n",
      "Epoch: 23 | Iteration: 378 | Classification loss: 0.00518 | Regression loss: 0.07463 | Running loss: 0.18617\n",
      "Epoch: 23 | Iteration: 379 | Classification loss: 0.00712 | Regression loss: 0.16209 | Running loss: 0.18625\n",
      "Epoch: 23 | Iteration: 380 | Classification loss: 0.00823 | Regression loss: 0.15492 | Running loss: 0.18622\n",
      "Epoch: 23 | Iteration: 381 | Classification loss: 0.01692 | Regression loss: 0.16050 | Running loss: 0.18622\n",
      "Epoch: 23 | Iteration: 382 | Classification loss: 0.01178 | Regression loss: 0.10326 | Running loss: 0.18567\n",
      "Epoch: 23 | Iteration: 383 | Classification loss: 0.02467 | Regression loss: 0.20208 | Running loss: 0.18560\n",
      "Epoch: 23 | Iteration: 384 | Classification loss: 0.00726 | Regression loss: 0.11706 | Running loss: 0.18499\n",
      "Epoch: 23 | Iteration: 385 | Classification loss: 0.02210 | Regression loss: 0.18766 | Running loss: 0.18502\n",
      "Epoch: 23 | Iteration: 386 | Classification loss: 0.01002 | Regression loss: 0.10947 | Running loss: 0.18500\n",
      "Epoch: 23 | Iteration: 387 | Classification loss: 0.02518 | Regression loss: 0.18788 | Running loss: 0.18520\n",
      "Epoch: 23 | Iteration: 388 | Classification loss: 0.01572 | Regression loss: 0.07823 | Running loss: 0.18507\n",
      "Epoch: 23 | Iteration: 389 | Classification loss: 0.01869 | Regression loss: 0.08163 | Running loss: 0.18506\n",
      "Epoch: 23 | Iteration: 390 | Classification loss: 0.01339 | Regression loss: 0.19502 | Running loss: 0.18449\n",
      "Epoch: 23 | Iteration: 391 | Classification loss: 0.01049 | Regression loss: 0.06518 | Running loss: 0.18440\n",
      "Epoch: 23 | Iteration: 392 | Classification loss: 0.01150 | Regression loss: 0.19403 | Running loss: 0.18456\n",
      "Epoch: 23 | Iteration: 393 | Classification loss: 0.01341 | Regression loss: 0.19726 | Running loss: 0.18437\n",
      "Epoch: 23 | Iteration: 394 | Classification loss: 0.01159 | Regression loss: 0.06843 | Running loss: 0.18431\n",
      "Epoch: 23 | Iteration: 395 | Classification loss: 0.00584 | Regression loss: 0.08467 | Running loss: 0.18424\n",
      "Epoch: 23 | Iteration: 396 | Classification loss: 0.00570 | Regression loss: 0.09209 | Running loss: 0.18410\n",
      "Epoch: 23 | Iteration: 397 | Classification loss: 0.01840 | Regression loss: 0.13991 | Running loss: 0.18382\n",
      "Epoch: 23 | Iteration: 398 | Classification loss: 0.03666 | Regression loss: 0.07056 | Running loss: 0.18380\n",
      "Epoch: 23 | Iteration: 399 | Classification loss: 0.01745 | Regression loss: 0.13556 | Running loss: 0.18378\n",
      "Epoch: 23 | Iteration: 400 | Classification loss: 0.01812 | Regression loss: 0.15559 | Running loss: 0.18377\n",
      "Epoch: 23 | Iteration: 401 | Classification loss: 0.07037 | Regression loss: 0.23535 | Running loss: 0.18380\n",
      "Epoch: 23 | Iteration: 402 | Classification loss: 0.01065 | Regression loss: 0.08892 | Running loss: 0.18374\n",
      "Epoch: 23 | Iteration: 403 | Classification loss: 0.00790 | Regression loss: 0.11293 | Running loss: 0.18373\n",
      "Epoch: 23 | Iteration: 404 | Classification loss: 0.01570 | Regression loss: 0.13301 | Running loss: 0.18354\n",
      "Epoch: 23 | Iteration: 405 | Classification loss: 0.02144 | Regression loss: 0.21477 | Running loss: 0.18353\n",
      "Epoch: 23 | Iteration: 406 | Classification loss: 0.00943 | Regression loss: 0.08790 | Running loss: 0.18316\n",
      "Epoch: 23 | Iteration: 407 | Classification loss: 0.00910 | Regression loss: 0.10344 | Running loss: 0.18303\n",
      "Epoch: 23 | Iteration: 408 | Classification loss: 0.01764 | Regression loss: 0.13405 | Running loss: 0.18311\n",
      "Epoch: 23 | Iteration: 409 | Classification loss: 0.05785 | Regression loss: 0.20414 | Running loss: 0.18299\n",
      "Epoch: 23 | Iteration: 410 | Classification loss: 0.00306 | Regression loss: 0.10102 | Running loss: 0.18288\n",
      "Epoch: 23 | Iteration: 411 | Classification loss: 0.01863 | Regression loss: 0.15069 | Running loss: 0.18296\n",
      "Epoch: 23 | Iteration: 412 | Classification loss: 0.01527 | Regression loss: 0.09228 | Running loss: 0.18279\n",
      "Epoch: 23 | Iteration: 413 | Classification loss: 0.00554 | Regression loss: 0.15391 | Running loss: 0.18255\n",
      "Epoch: 23 | Iteration: 414 | Classification loss: 0.08372 | Regression loss: 0.19742 | Running loss: 0.18279\n",
      "Epoch: 23 | Iteration: 415 | Classification loss: 0.09118 | Regression loss: 0.27135 | Running loss: 0.18326\n",
      "Epoch: 23 | Iteration: 416 | Classification loss: 0.00823 | Regression loss: 0.11754 | Running loss: 0.18289\n",
      "Epoch: 23 | Iteration: 417 | Classification loss: 0.00668 | Regression loss: 0.16463 | Running loss: 0.18285\n",
      "Epoch: 23 | Iteration: 418 | Classification loss: 0.02034 | Regression loss: 0.09222 | Running loss: 0.18276\n",
      "Epoch: 23 | Iteration: 419 | Classification loss: 0.01051 | Regression loss: 0.06763 | Running loss: 0.18274\n",
      "Epoch: 23 | Iteration: 420 | Classification loss: 0.03075 | Regression loss: 0.10852 | Running loss: 0.18276\n",
      "Epoch: 23 | Iteration: 421 | Classification loss: 0.02999 | Regression loss: 0.09558 | Running loss: 0.18286\n",
      "Epoch: 23 | Iteration: 422 | Classification loss: 0.00381 | Regression loss: 0.08747 | Running loss: 0.18286\n",
      "Epoch: 23 | Iteration: 423 | Classification loss: 0.00619 | Regression loss: 0.13572 | Running loss: 0.18269\n",
      "Epoch: 23 | Iteration: 424 | Classification loss: 0.00948 | Regression loss: 0.07694 | Running loss: 0.18200\n",
      "Epoch: 23 | Iteration: 425 | Classification loss: 0.00760 | Regression loss: 0.11045 | Running loss: 0.18199\n",
      "Epoch: 23 | Iteration: 426 | Classification loss: 0.03642 | Regression loss: 0.19002 | Running loss: 0.18175\n",
      "Epoch: 23 | Iteration: 427 | Classification loss: 0.01984 | Regression loss: 0.21276 | Running loss: 0.18188\n",
      "Epoch: 23 | Iteration: 428 | Classification loss: 0.01554 | Regression loss: 0.09894 | Running loss: 0.18186\n",
      "Epoch: 23 | Iteration: 429 | Classification loss: 0.04811 | Regression loss: 0.16742 | Running loss: 0.18215\n",
      "Epoch: 23 | Iteration: 430 | Classification loss: 0.17030 | Regression loss: 0.22210 | Running loss: 0.18252\n",
      "Epoch: 23 | Iteration: 431 | Classification loss: 0.00459 | Regression loss: 0.09723 | Running loss: 0.18234\n",
      "Epoch: 23 | Iteration: 432 | Classification loss: 0.03392 | Regression loss: 0.30083 | Running loss: 0.18265\n",
      "Epoch: 23 | Iteration: 433 | Classification loss: 0.37157 | Regression loss: 0.28688 | Running loss: 0.18356\n",
      "Epoch: 23 | Iteration: 434 | Classification loss: 0.02071 | Regression loss: 0.18195 | Running loss: 0.18362\n",
      "Epoch: 23 | Iteration: 435 | Classification loss: 0.00491 | Regression loss: 0.11267 | Running loss: 0.18373\n",
      "Epoch: 23 | Iteration: 436 | Classification loss: 0.00504 | Regression loss: 0.05739 | Running loss: 0.18355\n",
      "Epoch: 23 | Iteration: 437 | Classification loss: 0.05493 | Regression loss: 0.23226 | Running loss: 0.18376\n",
      "Epoch: 23 | Iteration: 438 | Classification loss: 0.00346 | Regression loss: 0.04444 | Running loss: 0.18364\n",
      "Epoch: 23 | Iteration: 439 | Classification loss: 0.03748 | Regression loss: 0.14553 | Running loss: 0.18332\n",
      "Epoch: 23 | Iteration: 440 | Classification loss: 0.00908 | Regression loss: 0.03127 | Running loss: 0.18317\n",
      "Epoch: 23 | Iteration: 441 | Classification loss: 0.03468 | Regression loss: 0.17932 | Running loss: 0.18346\n",
      "Epoch: 23 | Iteration: 442 | Classification loss: 0.04577 | Regression loss: 0.16351 | Running loss: 0.18367\n",
      "Epoch: 23 | Iteration: 443 | Classification loss: 0.05945 | Regression loss: 0.13701 | Running loss: 0.18392\n",
      "Epoch: 23 | Iteration: 444 | Classification loss: 0.01491 | Regression loss: 0.21771 | Running loss: 0.18386\n",
      "Epoch: 23 | Iteration: 445 | Classification loss: 0.02489 | Regression loss: 0.10063 | Running loss: 0.18381\n",
      "Epoch: 23 | Iteration: 446 | Classification loss: 0.02004 | Regression loss: 0.15661 | Running loss: 0.18394\n",
      "Epoch: 23 | Iteration: 447 | Classification loss: 0.00697 | Regression loss: 0.17771 | Running loss: 0.18407\n",
      "Epoch: 23 | Iteration: 448 | Classification loss: 0.00293 | Regression loss: 0.09623 | Running loss: 0.18375\n",
      "Epoch: 23 | Iteration: 449 | Classification loss: 0.05064 | Regression loss: 0.23658 | Running loss: 0.18401\n",
      "Epoch: 23 | Iteration: 450 | Classification loss: 0.02902 | Regression loss: 0.06633 | Running loss: 0.18398\n",
      "Epoch: 23 | Iteration: 451 | Classification loss: 0.00590 | Regression loss: 0.12776 | Running loss: 0.18386\n",
      "Epoch: 23 | Iteration: 452 | Classification loss: 0.01722 | Regression loss: 0.24873 | Running loss: 0.18402\n",
      "Epoch: 23 | Iteration: 453 | Classification loss: 0.03410 | Regression loss: 0.22077 | Running loss: 0.18434\n",
      "Epoch: 23 | Iteration: 454 | Classification loss: 0.03681 | Regression loss: 0.15190 | Running loss: 0.18451\n",
      "Epoch: 23 | Iteration: 455 | Classification loss: 0.03490 | Regression loss: 0.19141 | Running loss: 0.18474\n",
      "Epoch: 23 | Iteration: 456 | Classification loss: 0.04157 | Regression loss: 0.18365 | Running loss: 0.18473\n",
      "Epoch: 23 | Iteration: 457 | Classification loss: 0.02314 | Regression loss: 0.21939 | Running loss: 0.18504\n",
      "Epoch: 23 | Iteration: 458 | Classification loss: 0.02912 | Regression loss: 0.15002 | Running loss: 0.18506\n",
      "Epoch: 23 | Iteration: 459 | Classification loss: 0.12380 | Regression loss: 0.28737 | Running loss: 0.18536\n",
      "Epoch: 23 | Iteration: 460 | Classification loss: 0.01179 | Regression loss: 0.14545 | Running loss: 0.18508\n",
      "Epoch: 23 | Iteration: 461 | Classification loss: 0.00628 | Regression loss: 0.09669 | Running loss: 0.18492\n",
      "Epoch: 23 | Iteration: 462 | Classification loss: 0.03673 | Regression loss: 0.23092 | Running loss: 0.18517\n",
      "Epoch: 23 | Iteration: 463 | Classification loss: 0.03220 | Regression loss: 0.13947 | Running loss: 0.18527\n",
      "Epoch: 23 | Iteration: 464 | Classification loss: 0.02871 | Regression loss: 0.22618 | Running loss: 0.18531\n",
      "Epoch: 23 | Iteration: 465 | Classification loss: 0.09424 | Regression loss: 0.32012 | Running loss: 0.18592\n",
      "Epoch: 23 | Iteration: 466 | Classification loss: 0.15047 | Regression loss: 0.32965 | Running loss: 0.18650\n",
      "Epoch: 23 | Iteration: 467 | Classification loss: 0.01101 | Regression loss: 0.17561 | Running loss: 0.18645\n",
      "Epoch: 23 | Iteration: 468 | Classification loss: 0.01925 | Regression loss: 0.22983 | Running loss: 0.18670\n",
      "Epoch: 23 | Iteration: 469 | Classification loss: 0.17402 | Regression loss: 0.20907 | Running loss: 0.18712\n",
      "Epoch: 23 | Iteration: 470 | Classification loss: 0.11731 | Regression loss: 0.28075 | Running loss: 0.18756\n",
      "Epoch: 23 | Iteration: 471 | Classification loss: 0.05995 | Regression loss: 0.20009 | Running loss: 0.18776\n",
      "Epoch: 23 | Iteration: 472 | Classification loss: 0.02373 | Regression loss: 0.17186 | Running loss: 0.18771\n",
      "Epoch: 23 | Iteration: 473 | Classification loss: 0.04425 | Regression loss: 0.13764 | Running loss: 0.18781\n",
      "Epoch: 23 | Iteration: 474 | Classification loss: 0.07085 | Regression loss: 0.07739 | Running loss: 0.18795\n",
      "Epoch: 23 | Iteration: 475 | Classification loss: 0.01564 | Regression loss: 0.09744 | Running loss: 0.18762\n",
      "Epoch: 23 | Iteration: 476 | Classification loss: 0.02265 | Regression loss: 0.06921 | Running loss: 0.18755\n",
      "Epoch: 23 | Iteration: 477 | Classification loss: 0.21984 | Regression loss: 0.12765 | Running loss: 0.18808\n",
      "Epoch: 23 | Iteration: 478 | Classification loss: 0.00835 | Regression loss: 0.08224 | Running loss: 0.18750\n",
      "Epoch: 23 | Iteration: 479 | Classification loss: 0.04936 | Regression loss: 0.32170 | Running loss: 0.18803\n",
      "Epoch: 23 | Iteration: 480 | Classification loss: 0.03222 | Regression loss: 0.09082 | Running loss: 0.18785\n",
      "Epoch: 23 | Iteration: 481 | Classification loss: 0.02520 | Regression loss: 0.22169 | Running loss: 0.18787\n",
      "Epoch: 23 | Iteration: 482 | Classification loss: 0.01844 | Regression loss: 0.13328 | Running loss: 0.18799\n",
      "Epoch: 23 | Iteration: 483 | Classification loss: 0.02242 | Regression loss: 0.18576 | Running loss: 0.18822\n",
      "Epoch: 23 | Iteration: 484 | Classification loss: 0.01611 | Regression loss: 0.17095 | Running loss: 0.18833\n",
      "Epoch: 23 | Iteration: 485 | Classification loss: 0.06163 | Regression loss: 0.10019 | Running loss: 0.18843\n",
      "Epoch: 23 | Iteration: 486 | Classification loss: 0.01450 | Regression loss: 0.11428 | Running loss: 0.18803\n",
      "Epoch: 23 | Iteration: 487 | Classification loss: 0.02021 | Regression loss: 0.18936 | Running loss: 0.18778\n",
      "Epoch: 23 | Iteration: 488 | Classification loss: 0.00835 | Regression loss: 0.16994 | Running loss: 0.18735\n",
      "Epoch: 23 | Iteration: 489 | Classification loss: 0.02549 | Regression loss: 0.17621 | Running loss: 0.18752\n",
      "Epoch: 23 | Iteration: 490 | Classification loss: 0.05255 | Regression loss: 0.15677 | Running loss: 0.18698\n",
      "Epoch: 23 | Iteration: 491 | Classification loss: 0.02519 | Regression loss: 0.18057 | Running loss: 0.18697\n",
      "Epoch: 23 | Iteration: 492 | Classification loss: 0.02536 | Regression loss: 0.14734 | Running loss: 0.18702\n",
      "Epoch: 23 | Iteration: 493 | Classification loss: 0.13402 | Regression loss: 0.16489 | Running loss: 0.18699\n",
      "Epoch: 23 | Iteration: 494 | Classification loss: 0.02637 | Regression loss: 0.24022 | Running loss: 0.18709\n",
      "Epoch: 23 | Iteration: 495 | Classification loss: 0.02652 | Regression loss: 0.14151 | Running loss: 0.18697\n",
      "Epoch: 23 | Iteration: 496 | Classification loss: 0.01503 | Regression loss: 0.03893 | Running loss: 0.18657\n",
      "Epoch: 23 | Iteration: 497 | Classification loss: 0.01460 | Regression loss: 0.08822 | Running loss: 0.18655\n",
      "Epoch: 23 | Iteration: 498 | Classification loss: 0.01138 | Regression loss: 0.17649 | Running loss: 0.18682\n",
      "Epoch: 23 | Iteration: 499 | Classification loss: 0.04273 | Regression loss: 0.16109 | Running loss: 0.18630\n",
      "Epoch: 23 | Iteration: 500 | Classification loss: 0.00857 | Regression loss: 0.10254 | Running loss: 0.18610\n",
      "Epoch: 23 | Iteration: 501 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.18566\n",
      "Epoch: 23 | Iteration: 502 | Classification loss: 0.13826 | Regression loss: 0.31714 | Running loss: 0.18641\n",
      "Epoch: 23 | Iteration: 503 | Classification loss: 0.12073 | Regression loss: 0.18455 | Running loss: 0.18668\n",
      "Epoch: 23 | Iteration: 504 | Classification loss: 0.02655 | Regression loss: 0.09726 | Running loss: 0.18664\n",
      "Epoch: 23 | Iteration: 505 | Classification loss: 0.00676 | Regression loss: 0.06834 | Running loss: 0.18657\n",
      "Epoch: 23 | Iteration: 506 | Classification loss: 0.01021 | Regression loss: 0.14178 | Running loss: 0.18609\n",
      "Epoch: 23 | Iteration: 507 | Classification loss: 0.01427 | Regression loss: 0.15354 | Running loss: 0.18624\n",
      "Epoch: 23 | Iteration: 508 | Classification loss: 0.01923 | Regression loss: 0.12599 | Running loss: 0.18621\n",
      "Epoch: 23 | Iteration: 509 | Classification loss: 0.01509 | Regression loss: 0.16171 | Running loss: 0.18638\n",
      "Epoch: 23 | Iteration: 510 | Classification loss: 0.01094 | Regression loss: 0.14245 | Running loss: 0.18642\n",
      "Epoch: 23 | Iteration: 511 | Classification loss: 0.01241 | Regression loss: 0.10419 | Running loss: 0.18651\n",
      "Epoch: 23 | Iteration: 512 | Classification loss: 0.22062 | Regression loss: 0.31595 | Running loss: 0.18738\n",
      "Epoch: 23 | Iteration: 513 | Classification loss: 0.01894 | Regression loss: 0.16223 | Running loss: 0.18744\n",
      "Epoch: 23 | Iteration: 514 | Classification loss: 0.02760 | Regression loss: 0.25290 | Running loss: 0.18769\n",
      "Epoch: 23 | Iteration: 515 | Classification loss: 0.03227 | Regression loss: 0.20774 | Running loss: 0.18749\n",
      "Epoch: 23 | Iteration: 516 | Classification loss: 0.00411 | Regression loss: 0.12171 | Running loss: 0.18735\n",
      "Epoch: 23 | Iteration: 517 | Classification loss: 0.03232 | Regression loss: 0.14234 | Running loss: 0.18743\n",
      "Epoch: 23 | Iteration: 518 | Classification loss: 0.00523 | Regression loss: 0.09038 | Running loss: 0.18724\n",
      "Epoch: 23 | Iteration: 519 | Classification loss: 0.00156 | Regression loss: 0.07022 | Running loss: 0.18671\n",
      "Epoch: 23 | Iteration: 520 | Classification loss: 0.01673 | Regression loss: 0.12181 | Running loss: 0.18660\n",
      "Epoch: 23 | Iteration: 521 | Classification loss: 0.01214 | Regression loss: 0.06853 | Running loss: 0.18645\n",
      "Epoch: 23 | Iteration: 522 | Classification loss: 0.00833 | Regression loss: 0.08246 | Running loss: 0.18625\n",
      "Epoch: 23 | Iteration: 523 | Classification loss: 0.08105 | Regression loss: 0.26912 | Running loss: 0.18637\n",
      "Epoch: 23 | Iteration: 524 | Classification loss: 0.03872 | Regression loss: 0.15830 | Running loss: 0.18586\n",
      "Epoch: 23 | Iteration: 525 | Classification loss: 0.01635 | Regression loss: 0.11404 | Running loss: 0.18590\n",
      "Epoch: 23 | Iteration: 526 | Classification loss: 0.06955 | Regression loss: 0.31671 | Running loss: 0.18650\n",
      "Epoch: 23 | Iteration: 527 | Classification loss: 0.02504 | Regression loss: 0.10146 | Running loss: 0.18659\n",
      "Epoch: 23 | Iteration: 528 | Classification loss: 0.00960 | Regression loss: 0.13311 | Running loss: 0.18664\n",
      "Epoch: 23 | Iteration: 529 | Classification loss: 0.01006 | Regression loss: 0.11915 | Running loss: 0.18641\n",
      "Epoch: 23 | Iteration: 530 | Classification loss: 0.02151 | Regression loss: 0.15676 | Running loss: 0.18619\n",
      "Epoch: 23 | Iteration: 531 | Classification loss: 0.01406 | Regression loss: 0.08596 | Running loss: 0.18581\n",
      "Epoch: 23 | Iteration: 532 | Classification loss: 0.00596 | Regression loss: 0.09700 | Running loss: 0.18545\n",
      "Epoch: 23 | Iteration: 533 | Classification loss: 0.06033 | Regression loss: 0.14246 | Running loss: 0.18546\n",
      "Epoch: 23 | Iteration: 534 | Classification loss: 0.00858 | Regression loss: 0.08756 | Running loss: 0.18526\n",
      "Epoch: 23 | Iteration: 535 | Classification loss: 0.00846 | Regression loss: 0.08853 | Running loss: 0.18528\n",
      "Epoch: 23 | Iteration: 536 | Classification loss: 0.01679 | Regression loss: 0.22362 | Running loss: 0.18533\n",
      "Epoch: 23 | Iteration: 537 | Classification loss: 0.03030 | Regression loss: 0.18372 | Running loss: 0.18558\n",
      "Epoch: 23 | Iteration: 538 | Classification loss: 0.02164 | Regression loss: 0.24246 | Running loss: 0.18577\n",
      "Epoch: 23 | Iteration: 539 | Classification loss: 0.02835 | Regression loss: 0.19182 | Running loss: 0.18590\n",
      "Epoch: 23 | Iteration: 540 | Classification loss: 0.05699 | Regression loss: 0.19611 | Running loss: 0.18609\n",
      "Epoch: 23 | Iteration: 541 | Classification loss: 0.01447 | Regression loss: 0.09197 | Running loss: 0.18599\n",
      "Epoch: 23 | Iteration: 542 | Classification loss: 0.01140 | Regression loss: 0.08545 | Running loss: 0.18578\n",
      "Epoch: 23 | Iteration: 543 | Classification loss: 0.02642 | Regression loss: 0.16102 | Running loss: 0.18594\n",
      "Epoch: 23 | Iteration: 544 | Classification loss: 0.01797 | Regression loss: 0.08739 | Running loss: 0.18598\n",
      "Epoch: 23 | Iteration: 545 | Classification loss: 0.06228 | Regression loss: 0.30976 | Running loss: 0.18632\n",
      "Epoch: 23 | Iteration: 546 | Classification loss: 0.02363 | Regression loss: 0.21884 | Running loss: 0.18655\n",
      "Epoch: 23 | Iteration: 547 | Classification loss: 0.01555 | Regression loss: 0.12123 | Running loss: 0.18648\n",
      "Epoch: 23 | Iteration: 548 | Classification loss: 0.06401 | Regression loss: 0.25876 | Running loss: 0.18696\n",
      "Epoch: 23 | Iteration: 549 | Classification loss: 0.02106 | Regression loss: 0.07960 | Running loss: 0.18693\n",
      "Epoch: 23 | Iteration: 550 | Classification loss: 0.04420 | Regression loss: 0.23681 | Running loss: 0.18711\n",
      "Epoch: 23 | Iteration: 551 | Classification loss: 0.05590 | Regression loss: 0.22088 | Running loss: 0.18743\n",
      "Epoch: 23 | Iteration: 552 | Classification loss: 0.05500 | Regression loss: 0.27725 | Running loss: 0.18781\n",
      "Epoch: 23 | Iteration: 553 | Classification loss: 0.00663 | Regression loss: 0.09164 | Running loss: 0.18781\n",
      "Epoch: 23 | Iteration: 554 | Classification loss: 0.04224 | Regression loss: 0.16746 | Running loss: 0.18790\n",
      "Epoch: 23 | Iteration: 555 | Classification loss: 0.05821 | Regression loss: 0.11437 | Running loss: 0.18800\n",
      "Epoch: 23 | Iteration: 556 | Classification loss: 0.00384 | Regression loss: 0.04634 | Running loss: 0.18720\n",
      "Epoch: 23 | Iteration: 557 | Classification loss: 0.01378 | Regression loss: 0.17581 | Running loss: 0.18738\n",
      "Epoch: 23 | Iteration: 558 | Classification loss: 0.05415 | Regression loss: 0.12701 | Running loss: 0.18746\n",
      "Epoch: 23 | Iteration: 559 | Classification loss: 0.00710 | Regression loss: 0.03855 | Running loss: 0.18705\n",
      "Epoch: 23 | Iteration: 560 | Classification loss: 0.06521 | Regression loss: 0.28960 | Running loss: 0.18733\n",
      "Epoch: 23 | Iteration: 561 | Classification loss: 0.03977 | Regression loss: 0.14486 | Running loss: 0.18736\n",
      "Epoch: 23 | Iteration: 562 | Classification loss: 0.03954 | Regression loss: 0.17202 | Running loss: 0.18738\n",
      "Epoch: 23 | Iteration: 563 | Classification loss: 0.01022 | Regression loss: 0.05834 | Running loss: 0.18713\n",
      "Epoch: 23 | Iteration: 564 | Classification loss: 0.06199 | Regression loss: 0.31272 | Running loss: 0.18759\n",
      "Epoch: 23 | Iteration: 565 | Classification loss: 0.02877 | Regression loss: 0.22406 | Running loss: 0.18780\n",
      "Epoch: 23 | Iteration: 566 | Classification loss: 0.04404 | Regression loss: 0.15207 | Running loss: 0.18751\n",
      "Epoch: 23 | Iteration: 567 | Classification loss: 0.25600 | Regression loss: 0.15046 | Running loss: 0.18805\n",
      "Epoch: 23 | Iteration: 568 | Classification loss: 0.01499 | Regression loss: 0.13273 | Running loss: 0.18778\n",
      "Epoch: 23 | Iteration: 569 | Classification loss: 0.02301 | Regression loss: 0.23286 | Running loss: 0.18789\n",
      "Epoch: 23 | Iteration: 570 | Classification loss: 0.02777 | Regression loss: 0.13059 | Running loss: 0.18789\n",
      "Epoch: 23 | Iteration: 571 | Classification loss: 0.01316 | Regression loss: 0.13689 | Running loss: 0.18786\n",
      "Epoch: 23 | Iteration: 572 | Classification loss: 0.00431 | Regression loss: 0.09325 | Running loss: 0.18776\n",
      "Epoch: 23 | Iteration: 573 | Classification loss: 0.00657 | Regression loss: 0.09244 | Running loss: 0.18711\n",
      "Epoch: 23 | Iteration: 574 | Classification loss: 0.15412 | Regression loss: 0.32666 | Running loss: 0.18790\n",
      "Epoch: 23 | Iteration: 575 | Classification loss: 0.00580 | Regression loss: 0.06638 | Running loss: 0.18769\n",
      "Epoch: 23 | Iteration: 576 | Classification loss: 0.02889 | Regression loss: 0.10910 | Running loss: 0.18756\n",
      "Epoch: 23 | Iteration: 577 | Classification loss: 0.02759 | Regression loss: 0.05283 | Running loss: 0.18749\n",
      "Epoch: 23 | Iteration: 578 | Classification loss: 0.02985 | Regression loss: 0.16633 | Running loss: 0.18738\n",
      "Epoch: 23 | Iteration: 579 | Classification loss: 0.01211 | Regression loss: 0.09031 | Running loss: 0.18728\n",
      "Epoch: 23 | Iteration: 580 | Classification loss: 0.00301 | Regression loss: 0.08769 | Running loss: 0.18722\n",
      "Epoch: 23 | Iteration: 581 | Classification loss: 0.00745 | Regression loss: 0.17426 | Running loss: 0.18726\n",
      "Epoch: 23 | Iteration: 582 | Classification loss: 0.04551 | Regression loss: 0.20434 | Running loss: 0.18749\n",
      "Epoch: 23 | Iteration: 583 | Classification loss: 0.01716 | Regression loss: 0.17899 | Running loss: 0.18727\n",
      "Epoch: 23 | Iteration: 584 | Classification loss: 0.00891 | Regression loss: 0.08383 | Running loss: 0.18729\n",
      "Epoch: 23 | Iteration: 585 | Classification loss: 0.01108 | Regression loss: 0.06757 | Running loss: 0.18689\n",
      "Epoch: 23 | Iteration: 586 | Classification loss: 0.03284 | Regression loss: 0.20991 | Running loss: 0.18701\n",
      "Epoch: 23 | Iteration: 587 | Classification loss: 0.00918 | Regression loss: 0.11958 | Running loss: 0.18705\n",
      "Epoch: 23 | Iteration: 588 | Classification loss: 0.00788 | Regression loss: 0.08791 | Running loss: 0.18701\n",
      "Epoch: 23 | Iteration: 589 | Classification loss: 0.04610 | Regression loss: 0.10450 | Running loss: 0.18691\n",
      "Epoch: 23 | Iteration: 590 | Classification loss: 0.04532 | Regression loss: 0.21746 | Running loss: 0.18705\n",
      "Epoch: 23 | Iteration: 591 | Classification loss: 0.02792 | Regression loss: 0.20437 | Running loss: 0.18723\n",
      "Epoch: 23 | Iteration: 592 | Classification loss: 0.00626 | Regression loss: 0.07100 | Running loss: 0.18703\n",
      "Epoch: 23 | Iteration: 593 | Classification loss: 0.03992 | Regression loss: 0.16744 | Running loss: 0.18670\n",
      "Epoch: 23 | Iteration: 594 | Classification loss: 0.02316 | Regression loss: 0.11592 | Running loss: 0.18642\n",
      "Epoch: 23 | Iteration: 595 | Classification loss: 0.00869 | Regression loss: 0.15706 | Running loss: 0.18643\n",
      "Epoch: 23 | Iteration: 596 | Classification loss: 0.01094 | Regression loss: 0.21735 | Running loss: 0.18663\n",
      "Epoch: 23 | Iteration: 597 | Classification loss: 0.03095 | Regression loss: 0.22627 | Running loss: 0.18702\n",
      "Epoch: 23 | Iteration: 598 | Classification loss: 0.01009 | Regression loss: 0.10682 | Running loss: 0.18694\n",
      "Epoch: 23 | Iteration: 599 | Classification loss: 0.07572 | Regression loss: 0.35349 | Running loss: 0.18758\n",
      "Epoch: 23 | Iteration: 600 | Classification loss: 0.01165 | Regression loss: 0.17246 | Running loss: 0.18770\n",
      "Epoch: 23 | Iteration: 601 | Classification loss: 0.01333 | Regression loss: 0.15131 | Running loss: 0.18749\n",
      "Epoch: 23 | Iteration: 602 | Classification loss: 0.00456 | Regression loss: 0.10724 | Running loss: 0.18738\n",
      "Epoch: 23 | Iteration: 603 | Classification loss: 0.01361 | Regression loss: 0.16090 | Running loss: 0.18742\n",
      "Epoch: 23 | Iteration: 604 | Classification loss: 0.01035 | Regression loss: 0.13564 | Running loss: 0.18718\n",
      "Epoch: 23 | Iteration: 605 | Classification loss: 0.03241 | Regression loss: 0.15130 | Running loss: 0.18731\n",
      "Epoch: 23 | Iteration: 606 | Classification loss: 0.05987 | Regression loss: 0.21126 | Running loss: 0.18748\n",
      "Epoch: 23 | Iteration: 607 | Classification loss: 0.01867 | Regression loss: 0.08893 | Running loss: 0.18704\n",
      "Epoch: 23 | Iteration: 608 | Classification loss: 0.03532 | Regression loss: 0.15288 | Running loss: 0.18689\n",
      "Epoch: 23 | Iteration: 609 | Classification loss: 0.02735 | Regression loss: 0.08615 | Running loss: 0.18688\n",
      "Epoch: 23 | Iteration: 610 | Classification loss: 0.58222 | Regression loss: 0.53425 | Running loss: 0.18831\n",
      "Epoch: 23 | Iteration: 611 | Classification loss: 0.06597 | Regression loss: 0.31826 | Running loss: 0.18862\n",
      "Epoch: 23 | Iteration: 612 | Classification loss: 0.00577 | Regression loss: 0.17657 | Running loss: 0.18880\n",
      "Epoch: 23 | Iteration: 613 | Classification loss: 0.01476 | Regression loss: 0.09088 | Running loss: 0.18838\n",
      "Epoch: 23 | Iteration: 614 | Classification loss: 0.19748 | Regression loss: 0.29663 | Running loss: 0.18915\n",
      "Epoch: 23 | Iteration: 615 | Classification loss: 0.05277 | Regression loss: 0.25393 | Running loss: 0.18957\n",
      "Epoch: 23 | Iteration: 616 | Classification loss: 0.03215 | Regression loss: 0.13860 | Running loss: 0.18934\n",
      "Epoch: 23 | Iteration: 617 | Classification loss: 0.00963 | Regression loss: 0.07283 | Running loss: 0.18876\n",
      "Epoch: 23 | Iteration: 618 | Classification loss: 0.01023 | Regression loss: 0.13137 | Running loss: 0.18875\n",
      "Epoch: 23 | Iteration: 619 | Classification loss: 0.01057 | Regression loss: 0.08225 | Running loss: 0.18850\n",
      "Epoch: 23 | Iteration: 620 | Classification loss: 0.00970 | Regression loss: 0.14219 | Running loss: 0.18871\n",
      "Epoch: 23 | Iteration: 621 | Classification loss: 0.02619 | Regression loss: 0.14267 | Running loss: 0.18878\n",
      "Epoch: 23 | Iteration: 622 | Classification loss: 0.04430 | Regression loss: 0.15578 | Running loss: 0.18907\n",
      "Epoch: 23 | Iteration: 623 | Classification loss: 0.07757 | Regression loss: 0.32799 | Running loss: 0.18882\n",
      "Epoch: 23 | Iteration: 624 | Classification loss: 0.12945 | Regression loss: 0.30756 | Running loss: 0.18920\n",
      "Epoch: 23 | Iteration: 625 | Classification loss: 0.01205 | Regression loss: 0.11365 | Running loss: 0.18927\n",
      "Epoch: 23 | Iteration: 626 | Classification loss: 0.01672 | Regression loss: 0.07864 | Running loss: 0.18934\n",
      "Epoch: 23 | Iteration: 627 | Classification loss: 0.03355 | Regression loss: 0.14389 | Running loss: 0.18941\n",
      "Epoch: 23 | Iteration: 628 | Classification loss: 0.01217 | Regression loss: 0.14827 | Running loss: 0.18945\n",
      "Epoch: 23 | Iteration: 629 | Classification loss: 0.00690 | Regression loss: 0.11728 | Running loss: 0.18927\n",
      "Epoch: 23 | Iteration: 630 | Classification loss: 0.00623 | Regression loss: 0.08755 | Running loss: 0.18913\n",
      "Epoch: 23 | Iteration: 631 | Classification loss: 0.05837 | Regression loss: 0.10199 | Running loss: 0.18883\n",
      "Epoch: 23 | Iteration: 632 | Classification loss: 0.01324 | Regression loss: 0.14868 | Running loss: 0.18887\n",
      "Epoch: 23 | Iteration: 633 | Classification loss: 0.01863 | Regression loss: 0.09508 | Running loss: 0.18869\n",
      "Epoch: 23 | Iteration: 634 | Classification loss: 0.00797 | Regression loss: 0.14704 | Running loss: 0.18881\n",
      "Epoch: 23 | Iteration: 635 | Classification loss: 0.01250 | Regression loss: 0.10717 | Running loss: 0.18848\n",
      "Epoch: 23 | Iteration: 636 | Classification loss: 0.09708 | Regression loss: 0.33197 | Running loss: 0.18902\n",
      "Epoch: 23 | Iteration: 637 | Classification loss: 0.01023 | Regression loss: 0.11536 | Running loss: 0.18897\n",
      "Epoch: 23 | Iteration: 638 | Classification loss: 0.01550 | Regression loss: 0.11552 | Running loss: 0.18900\n",
      "Epoch: 23 | Iteration: 639 | Classification loss: 0.01219 | Regression loss: 0.10453 | Running loss: 0.18888\n",
      "Epoch: 23 | Iteration: 640 | Classification loss: 0.04453 | Regression loss: 0.15887 | Running loss: 0.18860\n",
      "Epoch: 23 | Iteration: 641 | Classification loss: 0.01943 | Regression loss: 0.14670 | Running loss: 0.18784\n",
      "Epoch: 23 | Iteration: 642 | Classification loss: 0.03326 | Regression loss: 0.22601 | Running loss: 0.18805\n",
      "Epoch: 23 | Iteration: 643 | Classification loss: 0.21942 | Regression loss: 0.14068 | Running loss: 0.18859\n",
      "Epoch: 23 | Iteration: 644 | Classification loss: 0.01344 | Regression loss: 0.12161 | Running loss: 0.18857\n",
      "Epoch: 23 | Iteration: 645 | Classification loss: 0.01362 | Regression loss: 0.12590 | Running loss: 0.18862\n",
      "Epoch: 23 | Iteration: 646 | Classification loss: 0.07251 | Regression loss: 0.13021 | Running loss: 0.18881\n",
      "Epoch: 23 | Iteration: 647 | Classification loss: 0.06762 | Regression loss: 0.14170 | Running loss: 0.18884\n",
      "Epoch: 23 | Iteration: 648 | Classification loss: 0.00576 | Regression loss: 0.05917 | Running loss: 0.18858\n",
      "Epoch: 23 | Iteration: 649 | Classification loss: 0.00692 | Regression loss: 0.06075 | Running loss: 0.18860\n",
      "Epoch: 23 | Iteration: 650 | Classification loss: 0.06443 | Regression loss: 0.11631 | Running loss: 0.18851\n",
      "Epoch: 23 | Iteration: 651 | Classification loss: 0.01543 | Regression loss: 0.17856 | Running loss: 0.18837\n",
      "Epoch: 23 | Iteration: 652 | Classification loss: 0.01718 | Regression loss: 0.17113 | Running loss: 0.18824\n",
      "Epoch: 23 | Iteration: 653 | Classification loss: 0.00418 | Regression loss: 0.08237 | Running loss: 0.18788\n",
      "Epoch: 23 | Iteration: 654 | Classification loss: 0.01537 | Regression loss: 0.17062 | Running loss: 0.18792\n",
      "Epoch: 23 | Iteration: 655 | Classification loss: 0.02348 | Regression loss: 0.15271 | Running loss: 0.18806\n",
      "Epoch: 23 | Iteration: 656 | Classification loss: 0.00600 | Regression loss: 0.05340 | Running loss: 0.18766\n",
      "Epoch: 23 | Iteration: 657 | Classification loss: 0.05567 | Regression loss: 0.21434 | Running loss: 0.18797\n",
      "Epoch: 23 | Iteration: 658 | Classification loss: 0.01783 | Regression loss: 0.07485 | Running loss: 0.18789\n",
      "Epoch: 23 | Iteration: 659 | Classification loss: 0.02231 | Regression loss: 0.17560 | Running loss: 0.18786\n",
      "Epoch: 23 | Iteration: 660 | Classification loss: 0.17642 | Regression loss: 0.39688 | Running loss: 0.18878\n",
      "Epoch: 23 | Iteration: 661 | Classification loss: 0.10946 | Regression loss: 0.18464 | Running loss: 0.18882\n",
      "Epoch: 23 | Iteration: 662 | Classification loss: 0.02653 | Regression loss: 0.11095 | Running loss: 0.18895\n",
      "Epoch: 23 | Iteration: 663 | Classification loss: 0.11968 | Regression loss: 0.22008 | Running loss: 0.18920\n",
      "Epoch: 23 | Iteration: 664 | Classification loss: 0.01367 | Regression loss: 0.14611 | Running loss: 0.18933\n",
      "Epoch: 23 | Iteration: 665 | Classification loss: 0.01986 | Regression loss: 0.13625 | Running loss: 0.18940\n",
      "Epoch: 23 | Iteration: 666 | Classification loss: 0.00810 | Regression loss: 0.08528 | Running loss: 0.18934\n",
      "Epoch: 23 | Iteration: 667 | Classification loss: 0.01244 | Regression loss: 0.09124 | Running loss: 0.18936\n",
      "Epoch: 23 | Iteration: 668 | Classification loss: 0.04497 | Regression loss: 0.13934 | Running loss: 0.18878\n",
      "Epoch: 23 | Iteration: 669 | Classification loss: 0.01141 | Regression loss: 0.11270 | Running loss: 0.18859\n",
      "Epoch: 23 | Iteration: 670 | Classification loss: 0.14138 | Regression loss: 0.27781 | Running loss: 0.18919\n",
      "Epoch: 23 | Iteration: 671 | Classification loss: 0.05072 | Regression loss: 0.25566 | Running loss: 0.18937\n",
      "Epoch: 23 | Iteration: 672 | Classification loss: 0.00889 | Regression loss: 0.12767 | Running loss: 0.18942\n",
      "Epoch: 23 | Iteration: 673 | Classification loss: 0.02025 | Regression loss: 0.12483 | Running loss: 0.18935\n",
      "Epoch: 23 | Iteration: 674 | Classification loss: 0.01053 | Regression loss: 0.11028 | Running loss: 0.18925\n",
      "Epoch: 23 | Iteration: 675 | Classification loss: 0.15092 | Regression loss: 0.23967 | Running loss: 0.18966\n",
      "Epoch: 23 | Iteration: 676 | Classification loss: 0.07645 | Regression loss: 0.27678 | Running loss: 0.19029\n",
      "Epoch: 23 | Iteration: 677 | Classification loss: 0.03433 | Regression loss: 0.24300 | Running loss: 0.19057\n",
      "Epoch: 23 | Iteration: 678 | Classification loss: 0.10918 | Regression loss: 0.20307 | Running loss: 0.19098\n",
      "Epoch: 23 | Iteration: 679 | Classification loss: 0.00861 | Regression loss: 0.13900 | Running loss: 0.19101\n",
      "Epoch: 23 | Iteration: 680 | Classification loss: 0.01381 | Regression loss: 0.07608 | Running loss: 0.19098\n",
      "Epoch: 23 | Iteration: 681 | Classification loss: 0.03246 | Regression loss: 0.11245 | Running loss: 0.19100\n",
      "Epoch: 23 | Iteration: 682 | Classification loss: 0.01804 | Regression loss: 0.13018 | Running loss: 0.19110\n",
      "Epoch: 23 | Iteration: 683 | Classification loss: 0.02552 | Regression loss: 0.11911 | Running loss: 0.19127\n",
      "Epoch: 23 | Iteration: 684 | Classification loss: 0.03766 | Regression loss: 0.21453 | Running loss: 0.19178\n",
      "Epoch: 23 | Iteration: 685 | Classification loss: 0.12311 | Regression loss: 0.10759 | Running loss: 0.19143\n",
      "Epoch: 23 | Iteration: 686 | Classification loss: 0.01285 | Regression loss: 0.08674 | Running loss: 0.19137\n",
      "Epoch: 23 | Iteration: 687 | Classification loss: 0.03981 | Regression loss: 0.11610 | Running loss: 0.19139\n",
      "Epoch: 23 | Iteration: 688 | Classification loss: 0.06773 | Regression loss: 0.05906 | Running loss: 0.19086\n",
      "Epoch: 23 | Iteration: 689 | Classification loss: 0.01015 | Regression loss: 0.10354 | Running loss: 0.19081\n",
      "Epoch: 23 | Iteration: 690 | Classification loss: 0.01988 | Regression loss: 0.18867 | Running loss: 0.19104\n",
      "Epoch: 23 | Iteration: 691 | Classification loss: 0.00748 | Regression loss: 0.20026 | Running loss: 0.19131\n",
      "Epoch: 23 | Iteration: 692 | Classification loss: 0.06192 | Regression loss: 0.22389 | Running loss: 0.19129\n",
      "Epoch: 23 | Iteration: 693 | Classification loss: 0.01625 | Regression loss: 0.08422 | Running loss: 0.19106\n",
      "Epoch: 23 | Iteration: 694 | Classification loss: 0.06936 | Regression loss: 0.24998 | Running loss: 0.19142\n",
      "Epoch: 23 | Iteration: 695 | Classification loss: 0.00916 | Regression loss: 0.10022 | Running loss: 0.19152\n",
      "Epoch: 23 | Iteration: 696 | Classification loss: 0.02055 | Regression loss: 0.16558 | Running loss: 0.19147\n",
      "Epoch: 23 | Iteration: 697 | Classification loss: 0.00742 | Regression loss: 0.07871 | Running loss: 0.19146\n",
      "Epoch: 23 | Iteration: 698 | Classification loss: 0.03548 | Regression loss: 0.08693 | Running loss: 0.19141\n",
      "Epoch: 23 | Iteration: 699 | Classification loss: 0.02250 | Regression loss: 0.14632 | Running loss: 0.19155\n",
      "Epoch: 23 | Iteration: 700 | Classification loss: 0.00478 | Regression loss: 0.09128 | Running loss: 0.19133\n",
      "Epoch: 23 | Iteration: 701 | Classification loss: 0.03017 | Regression loss: 0.13384 | Running loss: 0.19138\n",
      "Epoch: 23 | Iteration: 702 | Classification loss: 0.00310 | Regression loss: 0.06520 | Running loss: 0.19133\n",
      "Epoch: 23 | Iteration: 703 | Classification loss: 0.02072 | Regression loss: 0.19816 | Running loss: 0.19157\n",
      "Epoch: 23 | Iteration: 704 | Classification loss: 0.09264 | Regression loss: 0.30890 | Running loss: 0.19187\n",
      "Epoch: 23 | Iteration: 705 | Classification loss: 0.03959 | Regression loss: 0.10905 | Running loss: 0.19202\n",
      "Epoch: 23 | Iteration: 706 | Classification loss: 0.01369 | Regression loss: 0.09163 | Running loss: 0.19183\n",
      "Epoch: 23 | Iteration: 707 | Classification loss: 0.06066 | Regression loss: 0.16642 | Running loss: 0.19200\n",
      "Epoch: 23 | Iteration: 708 | Classification loss: 0.02302 | Regression loss: 0.21429 | Running loss: 0.19225\n",
      "Epoch: 23 | Iteration: 709 | Classification loss: 0.00625 | Regression loss: 0.07281 | Running loss: 0.19164\n",
      "Epoch: 23 | Iteration: 710 | Classification loss: 0.01477 | Regression loss: 0.13143 | Running loss: 0.19174\n",
      "Epoch: 23 | Iteration: 711 | Classification loss: 0.00142 | Regression loss: 0.08766 | Running loss: 0.19163\n",
      "Epoch: 23 | Iteration: 712 | Classification loss: 0.03252 | Regression loss: 0.23164 | Running loss: 0.19171\n",
      "Epoch: 23 | Iteration: 713 | Classification loss: 0.01813 | Regression loss: 0.10808 | Running loss: 0.19173\n",
      "Epoch: 23 | Iteration: 714 | Classification loss: 0.05878 | Regression loss: 0.14193 | Running loss: 0.19172\n",
      "Epoch: 23 | Iteration: 715 | Classification loss: 0.00863 | Regression loss: 0.16099 | Running loss: 0.19173\n",
      "Epoch: 23 | Iteration: 716 | Classification loss: 0.01765 | Regression loss: 0.23681 | Running loss: 0.19184\n",
      "Epoch: 23 | Iteration: 717 | Classification loss: 0.02540 | Regression loss: 0.17846 | Running loss: 0.19199\n",
      "Epoch: 23 | Iteration: 718 | Classification loss: 0.04800 | Regression loss: 0.08362 | Running loss: 0.19152\n",
      "Epoch: 23 | Iteration: 719 | Classification loss: 0.02563 | Regression loss: 0.10498 | Running loss: 0.19132\n",
      "Epoch: 23 | Iteration: 720 | Classification loss: 0.02398 | Regression loss: 0.20573 | Running loss: 0.19158\n",
      "Epoch: 23 | Iteration: 721 | Classification loss: 0.03214 | Regression loss: 0.18530 | Running loss: 0.19161\n",
      "Epoch: 23 | Iteration: 722 | Classification loss: 0.00967 | Regression loss: 0.08020 | Running loss: 0.19082\n",
      "Epoch: 23 | Iteration: 723 | Classification loss: 0.00683 | Regression loss: 0.04693 | Running loss: 0.19073\n",
      "Epoch: 23 | Iteration: 724 | Classification loss: 0.04352 | Regression loss: 0.29288 | Running loss: 0.19118\n",
      "Epoch: 23 | Iteration: 725 | Classification loss: 0.04560 | Regression loss: 0.28958 | Running loss: 0.19162\n",
      "Epoch: 23 | Iteration: 726 | Classification loss: 0.04401 | Regression loss: 0.18961 | Running loss: 0.19175\n",
      "Epoch: 23 | Iteration: 727 | Classification loss: 0.00286 | Regression loss: 0.04279 | Running loss: 0.19110\n",
      "Epoch: 23 | Iteration: 728 | Classification loss: 0.02149 | Regression loss: 0.12017 | Running loss: 0.19115\n",
      "Epoch: 23 | Iteration: 729 | Classification loss: 0.03281 | Regression loss: 0.24570 | Running loss: 0.19149\n",
      "Epoch: 23 | Iteration: 730 | Classification loss: 0.18222 | Regression loss: 0.41028 | Running loss: 0.19243\n",
      "Epoch: 23 | Iteration: 731 | Classification loss: 0.03659 | Regression loss: 0.23614 | Running loss: 0.19260\n",
      "Epoch: 23 | Iteration: 732 | Classification loss: 0.04403 | Regression loss: 0.22483 | Running loss: 0.19282\n",
      "Epoch: 23 | Iteration: 733 | Classification loss: 0.03000 | Regression loss: 0.14646 | Running loss: 0.19268\n",
      "Epoch: 23 | Iteration: 734 | Classification loss: 0.02740 | Regression loss: 0.24584 | Running loss: 0.19297\n",
      "Epoch: 23 | Iteration: 735 | Classification loss: 0.00673 | Regression loss: 0.11430 | Running loss: 0.19250\n",
      "Epoch: 23 | Iteration: 736 | Classification loss: 0.01557 | Regression loss: 0.08094 | Running loss: 0.19235\n",
      "Epoch: 23 | Iteration: 737 | Classification loss: 0.00806 | Regression loss: 0.09940 | Running loss: 0.19051\n",
      "Epoch: 23 | Iteration: 738 | Classification loss: 0.02715 | Regression loss: 0.21849 | Running loss: 0.19072\n",
      "Epoch: 23 | Iteration: 739 | Classification loss: 0.00990 | Regression loss: 0.16674 | Running loss: 0.19054\n",
      "Epoch: 23 | Iteration: 740 | Classification loss: 0.00947 | Regression loss: 0.08424 | Running loss: 0.19042\n",
      "Epoch: 23 | Iteration: 741 | Classification loss: 0.01651 | Regression loss: 0.18208 | Running loss: 0.19029\n",
      "Epoch: 23 | Iteration: 742 | Classification loss: 0.05013 | Regression loss: 0.21087 | Running loss: 0.19058\n",
      "Epoch: 23 | Iteration: 743 | Classification loss: 0.02339 | Regression loss: 0.08461 | Running loss: 0.19032\n",
      "Epoch: 23 | Iteration: 744 | Classification loss: 0.02926 | Regression loss: 0.23800 | Running loss: 0.19033\n",
      "Epoch: 23 | Iteration: 745 | Classification loss: 0.03300 | Regression loss: 0.06865 | Running loss: 0.18984\n",
      "Epoch: 23 | Iteration: 746 | Classification loss: 0.00400 | Regression loss: 0.06986 | Running loss: 0.18970\n",
      "Epoch: 23 | Iteration: 747 | Classification loss: 0.02025 | Regression loss: 0.09238 | Running loss: 0.18965\n",
      "Epoch: 23 | Iteration: 748 | Classification loss: 0.00650 | Regression loss: 0.09920 | Running loss: 0.18964\n",
      "Epoch: 23 | Iteration: 749 | Classification loss: 0.05253 | Regression loss: 0.11700 | Running loss: 0.18967\n",
      "Epoch: 23 | Iteration: 750 | Classification loss: 0.01047 | Regression loss: 0.15471 | Running loss: 0.18967\n",
      "Epoch: 23 | Iteration: 751 | Classification loss: 0.02534 | Regression loss: 0.14903 | Running loss: 0.18974\n",
      "Epoch: 23 | Iteration: 752 | Classification loss: 0.00393 | Regression loss: 0.12066 | Running loss: 0.18943\n",
      "Epoch: 23 | Iteration: 753 | Classification loss: 0.02279 | Regression loss: 0.14508 | Running loss: 0.18928\n",
      "Epoch: 23 | Iteration: 754 | Classification loss: 0.03385 | Regression loss: 0.23163 | Running loss: 0.18958\n",
      "Epoch: 23 | Iteration: 755 | Classification loss: 0.03737 | Regression loss: 0.27886 | Running loss: 0.18984\n",
      "Epoch: 23 | Iteration: 756 | Classification loss: 0.02614 | Regression loss: 0.11147 | Running loss: 0.18991\n",
      "Epoch: 23 | Iteration: 757 | Classification loss: 0.01887 | Regression loss: 0.12108 | Running loss: 0.19004\n",
      "Epoch: 23 | Iteration: 758 | Classification loss: 0.02281 | Regression loss: 0.12907 | Running loss: 0.19014\n",
      "Epoch: 23 | Iteration: 759 | Classification loss: 0.01330 | Regression loss: 0.17720 | Running loss: 0.19008\n",
      "Epoch: 23 | Iteration: 760 | Classification loss: 0.02227 | Regression loss: 0.14405 | Running loss: 0.19004\n",
      "Epoch: 23 | Iteration: 761 | Classification loss: 0.05449 | Regression loss: 0.12434 | Running loss: 0.18997\n",
      "Epoch: 23 | Iteration: 762 | Classification loss: 0.12825 | Regression loss: 0.22761 | Running loss: 0.19035\n",
      "Epoch: 23 | Iteration: 763 | Classification loss: 0.00532 | Regression loss: 0.08099 | Running loss: 0.19013\n",
      "Epoch: 23 | Iteration: 764 | Classification loss: 0.06555 | Regression loss: 0.31834 | Running loss: 0.19054\n",
      "Epoch: 23 | Iteration: 765 | Classification loss: 0.01769 | Regression loss: 0.10816 | Running loss: 0.18965\n",
      "Epoch: 23 | Iteration: 766 | Classification loss: 0.01938 | Regression loss: 0.13302 | Running loss: 0.18941\n",
      "Epoch: 23 | Iteration: 767 | Classification loss: 0.02159 | Regression loss: 0.14266 | Running loss: 0.18918\n",
      "Epoch: 23 | Iteration: 768 | Classification loss: 0.02928 | Regression loss: 0.15818 | Running loss: 0.18921\n",
      "Epoch: 23 | Iteration: 769 | Classification loss: 0.03441 | Regression loss: 0.11869 | Running loss: 0.18896\n",
      "Epoch: 23 | Iteration: 770 | Classification loss: 0.01489 | Regression loss: 0.20590 | Running loss: 0.18883\n",
      "Epoch: 23 | Iteration: 771 | Classification loss: 0.00357 | Regression loss: 0.09854 | Running loss: 0.18863\n",
      "Epoch: 23 | Iteration: 772 | Classification loss: 0.02525 | Regression loss: 0.27279 | Running loss: 0.18898\n",
      "Epoch: 23 | Iteration: 773 | Classification loss: 0.00959 | Regression loss: 0.17174 | Running loss: 0.18894\n",
      "Epoch: 23 | Iteration: 774 | Classification loss: 0.03346 | Regression loss: 0.28331 | Running loss: 0.18933\n",
      "Epoch: 23 | Iteration: 775 | Classification loss: 0.01058 | Regression loss: 0.20896 | Running loss: 0.18927\n",
      "Epoch: 23 | Iteration: 776 | Classification loss: 0.05120 | Regression loss: 0.32598 | Running loss: 0.18929\n",
      "Epoch: 23 | Iteration: 777 | Classification loss: 0.01338 | Regression loss: 0.07431 | Running loss: 0.18928\n",
      "Epoch: 23 | Iteration: 778 | Classification loss: 0.01694 | Regression loss: 0.17164 | Running loss: 0.18951\n",
      "Epoch: 23 | Iteration: 779 | Classification loss: 0.02148 | Regression loss: 0.10829 | Running loss: 0.18945\n",
      "Epoch: 23 | Iteration: 780 | Classification loss: 0.04770 | Regression loss: 0.19948 | Running loss: 0.18955\n",
      "Epoch: 23 | Iteration: 781 | Classification loss: 0.12684 | Regression loss: 0.09269 | Running loss: 0.18986\n",
      "Epoch: 23 | Iteration: 782 | Classification loss: 0.02292 | Regression loss: 0.11902 | Running loss: 0.18934\n",
      "Epoch: 23 | Iteration: 783 | Classification loss: 0.01041 | Regression loss: 0.13267 | Running loss: 0.18934\n",
      "Epoch: 23 | Iteration: 784 | Classification loss: 0.01178 | Regression loss: 0.15983 | Running loss: 0.18927\n",
      "Epoch: 23 | Iteration: 785 | Classification loss: 0.02045 | Regression loss: 0.18391 | Running loss: 0.18929\n",
      "Epoch: 23 | Iteration: 786 | Classification loss: 0.05246 | Regression loss: 0.16854 | Running loss: 0.18925\n",
      "Epoch: 23 | Iteration: 787 | Classification loss: 0.03469 | Regression loss: 0.21930 | Running loss: 0.18911\n",
      "Epoch: 23 | Iteration: 788 | Classification loss: 0.00979 | Regression loss: 0.07286 | Running loss: 0.18888\n",
      "Epoch: 23 | Iteration: 789 | Classification loss: 0.01224 | Regression loss: 0.11829 | Running loss: 0.18854\n",
      "Epoch: 23 | Iteration: 790 | Classification loss: 0.01532 | Regression loss: 0.23910 | Running loss: 0.18869\n",
      "Epoch: 23 | Iteration: 791 | Classification loss: 0.01567 | Regression loss: 0.11439 | Running loss: 0.18864\n",
      "Epoch: 23 | Iteration: 792 | Classification loss: 0.06159 | Regression loss: 0.36353 | Running loss: 0.18915\n",
      "Epoch: 23 | Iteration: 793 | Classification loss: 0.05537 | Regression loss: 0.17720 | Running loss: 0.18915\n",
      "Epoch: 23 | Iteration: 794 | Classification loss: 0.02524 | Regression loss: 0.15646 | Running loss: 0.18924\n",
      "Epoch: 23 | Iteration: 795 | Classification loss: 0.05114 | Regression loss: 0.17681 | Running loss: 0.18946\n",
      "Epoch: 23 | Iteration: 796 | Classification loss: 0.00933 | Regression loss: 0.22919 | Running loss: 0.18954\n",
      "Epoch: 23 | Iteration: 797 | Classification loss: 0.01534 | Regression loss: 0.15076 | Running loss: 0.18956\n",
      "Epoch: 23 | Iteration: 798 | Classification loss: 0.04545 | Regression loss: 0.38997 | Running loss: 0.18993\n",
      "Epoch: 23 | Iteration: 799 | Classification loss: 0.01605 | Regression loss: 0.17157 | Running loss: 0.19009\n",
      "Epoch: 23 | Iteration: 800 | Classification loss: 0.02159 | Regression loss: 0.11034 | Running loss: 0.19001\n",
      "Epoch: 23 | Iteration: 801 | Classification loss: 0.03843 | Regression loss: 0.16227 | Running loss: 0.19007\n",
      "Epoch: 23 | Iteration: 802 | Classification loss: 0.04221 | Regression loss: 0.16485 | Running loss: 0.19027\n",
      "Epoch: 23 | Iteration: 803 | Classification loss: 0.07069 | Regression loss: 0.19830 | Running loss: 0.19036\n",
      "Epoch: 23 | Iteration: 804 | Classification loss: 0.00500 | Regression loss: 0.10430 | Running loss: 0.19034\n",
      "Epoch: 23 | Iteration: 805 | Classification loss: 0.06265 | Regression loss: 0.13866 | Running loss: 0.19047\n",
      "Epoch: 23 | Iteration: 806 | Classification loss: 0.02279 | Regression loss: 0.16920 | Running loss: 0.19074\n",
      "Epoch: 23 | Iteration: 807 | Classification loss: 0.08236 | Regression loss: 0.07537 | Running loss: 0.19075\n",
      "Epoch: 23 | Iteration: 808 | Classification loss: 0.01165 | Regression loss: 0.09469 | Running loss: 0.19075\n",
      "Epoch: 23 | Iteration: 809 | Classification loss: 0.00601 | Regression loss: 0.09979 | Running loss: 0.18992\n",
      "Epoch: 23 | Iteration: 810 | Classification loss: 0.10635 | Regression loss: 0.36117 | Running loss: 0.19069\n",
      "Epoch: 23 | Iteration: 811 | Classification loss: 0.40215 | Regression loss: 0.27837 | Running loss: 0.19173\n",
      "Epoch: 23 | Iteration: 812 | Classification loss: 0.02129 | Regression loss: 0.13546 | Running loss: 0.19188\n",
      "Epoch: 23 | Iteration: 813 | Classification loss: 0.01168 | Regression loss: 0.08467 | Running loss: 0.19195\n",
      "Epoch: 23 | Iteration: 814 | Classification loss: 0.00455 | Regression loss: 0.06990 | Running loss: 0.19177\n",
      "Epoch: 23 | Iteration: 815 | Classification loss: 0.00709 | Regression loss: 0.07601 | Running loss: 0.19173\n",
      "Epoch: 23 | Iteration: 816 | Classification loss: 0.00613 | Regression loss: 0.11012 | Running loss: 0.19119\n",
      "Epoch: 23 | Iteration: 817 | Classification loss: 0.00847 | Regression loss: 0.09593 | Running loss: 0.19105\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.580\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "CUDA available: True\n",
      "Epoch: 24 | Iteration: 0 | Classification loss: 0.03539 | Regression loss: 0.14441 | Running loss: 0.19109\n",
      "Epoch: 24 | Iteration: 1 | Classification loss: 0.11225 | Regression loss: 0.14386 | Running loss: 0.19100\n",
      "Epoch: 24 | Iteration: 2 | Classification loss: 0.03062 | Regression loss: 0.10504 | Running loss: 0.19085\n",
      "Epoch: 24 | Iteration: 3 | Classification loss: 0.01091 | Regression loss: 0.16698 | Running loss: 0.19077\n",
      "Epoch: 24 | Iteration: 4 | Classification loss: 0.01020 | Regression loss: 0.14459 | Running loss: 0.19077\n",
      "Epoch: 24 | Iteration: 5 | Classification loss: 0.00375 | Regression loss: 0.06707 | Running loss: 0.19044\n",
      "Epoch: 24 | Iteration: 6 | Classification loss: 0.01739 | Regression loss: 0.10041 | Running loss: 0.19048\n",
      "Epoch: 24 | Iteration: 7 | Classification loss: 0.00924 | Regression loss: 0.10948 | Running loss: 0.19048\n",
      "Epoch: 24 | Iteration: 8 | Classification loss: 0.01477 | Regression loss: 0.10837 | Running loss: 0.19047\n",
      "Epoch: 24 | Iteration: 9 | Classification loss: 0.05799 | Regression loss: 0.15907 | Running loss: 0.19026\n",
      "Epoch: 24 | Iteration: 10 | Classification loss: 0.00692 | Regression loss: 0.17945 | Running loss: 0.19011\n",
      "Epoch: 24 | Iteration: 11 | Classification loss: 0.04103 | Regression loss: 0.09492 | Running loss: 0.18982\n",
      "Epoch: 24 | Iteration: 12 | Classification loss: 0.00776 | Regression loss: 0.11285 | Running loss: 0.18976\n",
      "Epoch: 24 | Iteration: 13 | Classification loss: 0.03054 | Regression loss: 0.18268 | Running loss: 0.18992\n",
      "Epoch: 24 | Iteration: 14 | Classification loss: 0.00480 | Regression loss: 0.08536 | Running loss: 0.18969\n",
      "Epoch: 24 | Iteration: 15 | Classification loss: 0.03369 | Regression loss: 0.08534 | Running loss: 0.18959\n",
      "Epoch: 24 | Iteration: 16 | Classification loss: 0.03773 | Regression loss: 0.33847 | Running loss: 0.19011\n",
      "Epoch: 24 | Iteration: 17 | Classification loss: 0.02956 | Regression loss: 0.16560 | Running loss: 0.19003\n",
      "Epoch: 24 | Iteration: 18 | Classification loss: 0.02739 | Regression loss: 0.12376 | Running loss: 0.19010\n",
      "Epoch: 24 | Iteration: 19 | Classification loss: 0.13945 | Regression loss: 0.16005 | Running loss: 0.19035\n",
      "Epoch: 24 | Iteration: 20 | Classification loss: 0.00781 | Regression loss: 0.06331 | Running loss: 0.18963\n",
      "Epoch: 24 | Iteration: 21 | Classification loss: 0.05050 | Regression loss: 0.11993 | Running loss: 0.18967\n",
      "Epoch: 24 | Iteration: 22 | Classification loss: 0.02640 | Regression loss: 0.23263 | Running loss: 0.18992\n",
      "Epoch: 24 | Iteration: 23 | Classification loss: 0.00604 | Regression loss: 0.07416 | Running loss: 0.18990\n",
      "Epoch: 24 | Iteration: 24 | Classification loss: 0.01213 | Regression loss: 0.15053 | Running loss: 0.18967\n",
      "Epoch: 24 | Iteration: 25 | Classification loss: 0.05582 | Regression loss: 0.18967 | Running loss: 0.18972\n",
      "Epoch: 24 | Iteration: 26 | Classification loss: 0.01826 | Regression loss: 0.14861 | Running loss: 0.18966\n",
      "Epoch: 24 | Iteration: 27 | Classification loss: 0.03951 | Regression loss: 0.08767 | Running loss: 0.18967\n",
      "Epoch: 24 | Iteration: 28 | Classification loss: 0.01216 | Regression loss: 0.15642 | Running loss: 0.18941\n",
      "Epoch: 24 | Iteration: 29 | Classification loss: 0.04742 | Regression loss: 0.11928 | Running loss: 0.18915\n",
      "Epoch: 24 | Iteration: 30 | Classification loss: 0.00377 | Regression loss: 0.12370 | Running loss: 0.18912\n",
      "Epoch: 24 | Iteration: 31 | Classification loss: 0.17829 | Regression loss: 0.14604 | Running loss: 0.18955\n",
      "Epoch: 24 | Iteration: 32 | Classification loss: 0.03399 | Regression loss: 0.20835 | Running loss: 0.18935\n",
      "Epoch: 24 | Iteration: 33 | Classification loss: 0.02708 | Regression loss: 0.18021 | Running loss: 0.18933\n",
      "Epoch: 24 | Iteration: 34 | Classification loss: 0.02734 | Regression loss: 0.10391 | Running loss: 0.18934\n",
      "Epoch: 24 | Iteration: 35 | Classification loss: 0.01922 | Regression loss: 0.10851 | Running loss: 0.18945\n",
      "Epoch: 24 | Iteration: 36 | Classification loss: 0.07106 | Regression loss: 0.34935 | Running loss: 0.18968\n",
      "Epoch: 24 | Iteration: 37 | Classification loss: 0.00972 | Regression loss: 0.09925 | Running loss: 0.18974\n",
      "Epoch: 24 | Iteration: 38 | Classification loss: 0.00973 | Regression loss: 0.09053 | Running loss: 0.18976\n",
      "Epoch: 24 | Iteration: 39 | Classification loss: 0.03785 | Regression loss: 0.18946 | Running loss: 0.19004\n",
      "Epoch: 24 | Iteration: 40 | Classification loss: 0.04433 | Regression loss: 0.25710 | Running loss: 0.19024\n",
      "Epoch: 24 | Iteration: 41 | Classification loss: 0.01901 | Regression loss: 0.21114 | Running loss: 0.19025\n",
      "Epoch: 24 | Iteration: 42 | Classification loss: 0.04411 | Regression loss: 0.21382 | Running loss: 0.19030\n",
      "Epoch: 24 | Iteration: 43 | Classification loss: 0.01152 | Regression loss: 0.16361 | Running loss: 0.19000\n",
      "Epoch: 24 | Iteration: 44 | Classification loss: 0.02519 | Regression loss: 0.20492 | Running loss: 0.19033\n",
      "Epoch: 24 | Iteration: 45 | Classification loss: 0.03052 | Regression loss: 0.20849 | Running loss: 0.19051\n",
      "Epoch: 24 | Iteration: 46 | Classification loss: 0.01234 | Regression loss: 0.14702 | Running loss: 0.19068\n",
      "Epoch: 24 | Iteration: 47 | Classification loss: 0.00772 | Regression loss: 0.12653 | Running loss: 0.19071\n",
      "Epoch: 24 | Iteration: 48 | Classification loss: 0.01588 | Regression loss: 0.06985 | Running loss: 0.19045\n",
      "Epoch: 24 | Iteration: 49 | Classification loss: 0.01727 | Regression loss: 0.09399 | Running loss: 0.19035\n",
      "Epoch: 24 | Iteration: 50 | Classification loss: 0.05843 | Regression loss: 0.22402 | Running loss: 0.19052\n",
      "Epoch: 24 | Iteration: 51 | Classification loss: 0.01615 | Regression loss: 0.10050 | Running loss: 0.19047\n",
      "Epoch: 24 | Iteration: 52 | Classification loss: 0.02075 | Regression loss: 0.14895 | Running loss: 0.19019\n",
      "Epoch: 24 | Iteration: 53 | Classification loss: 0.01779 | Regression loss: 0.05141 | Running loss: 0.18991\n",
      "Epoch: 24 | Iteration: 54 | Classification loss: 0.01885 | Regression loss: 0.14067 | Running loss: 0.19005\n",
      "Epoch: 24 | Iteration: 55 | Classification loss: 0.01033 | Regression loss: 0.12890 | Running loss: 0.19009\n",
      "Epoch: 24 | Iteration: 56 | Classification loss: 0.00847 | Regression loss: 0.13923 | Running loss: 0.19013\n",
      "Epoch: 24 | Iteration: 57 | Classification loss: 0.02757 | Regression loss: 0.09940 | Running loss: 0.19005\n",
      "Epoch: 24 | Iteration: 58 | Classification loss: 0.01365 | Regression loss: 0.10855 | Running loss: 0.18984\n",
      "Epoch: 24 | Iteration: 59 | Classification loss: 0.00490 | Regression loss: 0.05493 | Running loss: 0.18950\n",
      "Epoch: 24 | Iteration: 60 | Classification loss: 0.02449 | Regression loss: 0.21250 | Running loss: 0.18981\n",
      "Epoch: 24 | Iteration: 61 | Classification loss: 0.03779 | Regression loss: 0.14538 | Running loss: 0.18984\n",
      "Epoch: 24 | Iteration: 62 | Classification loss: 0.00752 | Regression loss: 0.07664 | Running loss: 0.18968\n",
      "Epoch: 24 | Iteration: 63 | Classification loss: 0.02797 | Regression loss: 0.20325 | Running loss: 0.18979\n",
      "Epoch: 24 | Iteration: 64 | Classification loss: 0.00405 | Regression loss: 0.08181 | Running loss: 0.18973\n",
      "Epoch: 24 | Iteration: 65 | Classification loss: 0.03376 | Regression loss: 0.15206 | Running loss: 0.18965\n",
      "Epoch: 24 | Iteration: 66 | Classification loss: 0.00831 | Regression loss: 0.09528 | Running loss: 0.18961\n",
      "Epoch: 24 | Iteration: 67 | Classification loss: 0.01199 | Regression loss: 0.15347 | Running loss: 0.18952\n",
      "Epoch: 24 | Iteration: 68 | Classification loss: 0.02222 | Regression loss: 0.14356 | Running loss: 0.18961\n",
      "Epoch: 24 | Iteration: 69 | Classification loss: 0.01647 | Regression loss: 0.12784 | Running loss: 0.18947\n",
      "Epoch: 24 | Iteration: 70 | Classification loss: 0.05471 | Regression loss: 0.24086 | Running loss: 0.18988\n",
      "Epoch: 24 | Iteration: 71 | Classification loss: 0.01662 | Regression loss: 0.11870 | Running loss: 0.18995\n",
      "Epoch: 24 | Iteration: 72 | Classification loss: 0.01642 | Regression loss: 0.10610 | Running loss: 0.18977\n",
      "Epoch: 24 | Iteration: 73 | Classification loss: 0.00732 | Regression loss: 0.07348 | Running loss: 0.18978\n",
      "Epoch: 24 | Iteration: 74 | Classification loss: 0.01196 | Regression loss: 0.13388 | Running loss: 0.18967\n",
      "Epoch: 24 | Iteration: 75 | Classification loss: 0.03450 | Regression loss: 0.15228 | Running loss: 0.18962\n",
      "Epoch: 24 | Iteration: 76 | Classification loss: 0.00881 | Regression loss: 0.15911 | Running loss: 0.18979\n",
      "Epoch: 24 | Iteration: 77 | Classification loss: 0.05728 | Regression loss: 0.21285 | Running loss: 0.19015\n",
      "Epoch: 24 | Iteration: 78 | Classification loss: 0.01533 | Regression loss: 0.12418 | Running loss: 0.19024\n",
      "Epoch: 24 | Iteration: 79 | Classification loss: 0.02837 | Regression loss: 0.17001 | Running loss: 0.19032\n",
      "Epoch: 24 | Iteration: 80 | Classification loss: 0.00731 | Regression loss: 0.07431 | Running loss: 0.19026\n",
      "Epoch: 24 | Iteration: 81 | Classification loss: 0.04579 | Regression loss: 0.12971 | Running loss: 0.19031\n",
      "Epoch: 24 | Iteration: 82 | Classification loss: 0.00590 | Regression loss: 0.08201 | Running loss: 0.19014\n",
      "Epoch: 24 | Iteration: 83 | Classification loss: 0.00534 | Regression loss: 0.04635 | Running loss: 0.18963\n",
      "Epoch: 24 | Iteration: 84 | Classification loss: 0.04336 | Regression loss: 0.15424 | Running loss: 0.18983\n",
      "Epoch: 24 | Iteration: 85 | Classification loss: 0.04107 | Regression loss: 0.14506 | Running loss: 0.18996\n",
      "Epoch: 24 | Iteration: 86 | Classification loss: 0.08587 | Regression loss: 0.20418 | Running loss: 0.19024\n",
      "Epoch: 24 | Iteration: 87 | Classification loss: 0.01863 | Regression loss: 0.18568 | Running loss: 0.19018\n",
      "Epoch: 24 | Iteration: 88 | Classification loss: 0.10339 | Regression loss: 0.16298 | Running loss: 0.19051\n",
      "Epoch: 24 | Iteration: 89 | Classification loss: 0.00808 | Regression loss: 0.10736 | Running loss: 0.19052\n",
      "Epoch: 24 | Iteration: 90 | Classification loss: 0.02836 | Regression loss: 0.12567 | Running loss: 0.19052\n",
      "Epoch: 24 | Iteration: 91 | Classification loss: 0.02092 | Regression loss: 0.14809 | Running loss: 0.19034\n",
      "Epoch: 24 | Iteration: 92 | Classification loss: 0.03137 | Regression loss: 0.19148 | Running loss: 0.19058\n",
      "Epoch: 24 | Iteration: 93 | Classification loss: 0.03876 | Regression loss: 0.07110 | Running loss: 0.19046\n",
      "Epoch: 24 | Iteration: 94 | Classification loss: 0.03555 | Regression loss: 0.15985 | Running loss: 0.19063\n",
      "Epoch: 24 | Iteration: 95 | Classification loss: 0.01482 | Regression loss: 0.17202 | Running loss: 0.19069\n",
      "Epoch: 24 | Iteration: 96 | Classification loss: 0.02731 | Regression loss: 0.15531 | Running loss: 0.19049\n",
      "Epoch: 24 | Iteration: 97 | Classification loss: 0.01254 | Regression loss: 0.10032 | Running loss: 0.18999\n",
      "Epoch: 24 | Iteration: 98 | Classification loss: 0.01708 | Regression loss: 0.16175 | Running loss: 0.19010\n",
      "Epoch: 24 | Iteration: 99 | Classification loss: 0.00646 | Regression loss: 0.11581 | Running loss: 0.19000\n",
      "Epoch: 24 | Iteration: 100 | Classification loss: 0.01736 | Regression loss: 0.16358 | Running loss: 0.19014\n",
      "Epoch: 24 | Iteration: 101 | Classification loss: 0.01505 | Regression loss: 0.12670 | Running loss: 0.19026\n",
      "Epoch: 24 | Iteration: 102 | Classification loss: 0.06058 | Regression loss: 0.28065 | Running loss: 0.19067\n",
      "Epoch: 24 | Iteration: 103 | Classification loss: 0.02413 | Regression loss: 0.14093 | Running loss: 0.19075\n",
      "Epoch: 24 | Iteration: 104 | Classification loss: 0.01382 | Regression loss: 0.14268 | Running loss: 0.19088\n",
      "Epoch: 24 | Iteration: 105 | Classification loss: 0.08100 | Regression loss: 0.17723 | Running loss: 0.19111\n",
      "Epoch: 24 | Iteration: 106 | Classification loss: 0.02317 | Regression loss: 0.09500 | Running loss: 0.19117\n",
      "Epoch: 24 | Iteration: 107 | Classification loss: 0.00656 | Regression loss: 0.08475 | Running loss: 0.19112\n",
      "Epoch: 24 | Iteration: 108 | Classification loss: 0.02828 | Regression loss: 0.18782 | Running loss: 0.19110\n",
      "Epoch: 24 | Iteration: 109 | Classification loss: 0.02692 | Regression loss: 0.26934 | Running loss: 0.19123\n",
      "Epoch: 24 | Iteration: 110 | Classification loss: 0.00573 | Regression loss: 0.12253 | Running loss: 0.19125\n",
      "Epoch: 24 | Iteration: 111 | Classification loss: 0.01203 | Regression loss: 0.13934 | Running loss: 0.19112\n",
      "Epoch: 24 | Iteration: 112 | Classification loss: 0.01951 | Regression loss: 0.20885 | Running loss: 0.19080\n",
      "Epoch: 24 | Iteration: 113 | Classification loss: 0.01137 | Regression loss: 0.18855 | Running loss: 0.19099\n",
      "Epoch: 24 | Iteration: 114 | Classification loss: 0.14255 | Regression loss: 0.32547 | Running loss: 0.19126\n",
      "Epoch: 24 | Iteration: 115 | Classification loss: 0.00322 | Regression loss: 0.06380 | Running loss: 0.19008\n",
      "Epoch: 24 | Iteration: 116 | Classification loss: 0.00680 | Regression loss: 0.10451 | Running loss: 0.18989\n",
      "Epoch: 24 | Iteration: 117 | Classification loss: 0.00803 | Regression loss: 0.09306 | Running loss: 0.18986\n",
      "Epoch: 24 | Iteration: 118 | Classification loss: 0.04641 | Regression loss: 0.27582 | Running loss: 0.19038\n",
      "Epoch: 24 | Iteration: 119 | Classification loss: 0.06317 | Regression loss: 0.36547 | Running loss: 0.19066\n",
      "Epoch: 24 | Iteration: 120 | Classification loss: 0.01779 | Regression loss: 0.11427 | Running loss: 0.19083\n",
      "Epoch: 24 | Iteration: 121 | Classification loss: 0.01974 | Regression loss: 0.14851 | Running loss: 0.19080\n",
      "Epoch: 24 | Iteration: 122 | Classification loss: 0.01085 | Regression loss: 0.11744 | Running loss: 0.19098\n",
      "Epoch: 24 | Iteration: 123 | Classification loss: 0.01714 | Regression loss: 0.18004 | Running loss: 0.19094\n",
      "Epoch: 24 | Iteration: 124 | Classification loss: 0.00805 | Regression loss: 0.08543 | Running loss: 0.19071\n",
      "Epoch: 24 | Iteration: 125 | Classification loss: 0.01495 | Regression loss: 0.15564 | Running loss: 0.19066\n",
      "Epoch: 24 | Iteration: 126 | Classification loss: 0.01331 | Regression loss: 0.10598 | Running loss: 0.19043\n",
      "Epoch: 24 | Iteration: 127 | Classification loss: 0.01006 | Regression loss: 0.07623 | Running loss: 0.19036\n",
      "Epoch: 24 | Iteration: 128 | Classification loss: 0.04027 | Regression loss: 0.31437 | Running loss: 0.19071\n",
      "Epoch: 24 | Iteration: 129 | Classification loss: 0.00524 | Regression loss: 0.16965 | Running loss: 0.19069\n",
      "Epoch: 24 | Iteration: 130 | Classification loss: 0.08089 | Regression loss: 0.30005 | Running loss: 0.19126\n",
      "Epoch: 24 | Iteration: 131 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.19068\n",
      "Epoch: 24 | Iteration: 132 | Classification loss: 0.03630 | Regression loss: 0.20904 | Running loss: 0.19098\n",
      "Epoch: 24 | Iteration: 133 | Classification loss: 0.00831 | Regression loss: 0.06356 | Running loss: 0.19086\n",
      "Epoch: 24 | Iteration: 134 | Classification loss: 0.01072 | Regression loss: 0.17999 | Running loss: 0.19071\n",
      "Epoch: 24 | Iteration: 135 | Classification loss: 0.02898 | Regression loss: 0.25899 | Running loss: 0.19077\n",
      "Epoch: 24 | Iteration: 136 | Classification loss: 0.00769 | Regression loss: 0.04864 | Running loss: 0.19051\n",
      "Epoch: 24 | Iteration: 137 | Classification loss: 0.01388 | Regression loss: 0.11546 | Running loss: 0.19032\n",
      "Epoch: 24 | Iteration: 138 | Classification loss: 0.00613 | Regression loss: 0.11533 | Running loss: 0.19011\n",
      "Epoch: 24 | Iteration: 139 | Classification loss: 0.04856 | Regression loss: 0.22939 | Running loss: 0.19018\n",
      "Epoch: 24 | Iteration: 140 | Classification loss: 0.01244 | Regression loss: 0.14375 | Running loss: 0.19013\n",
      "Epoch: 24 | Iteration: 141 | Classification loss: 0.03112 | Regression loss: 0.17835 | Running loss: 0.18973\n",
      "Epoch: 24 | Iteration: 142 | Classification loss: 0.01823 | Regression loss: 0.16093 | Running loss: 0.18977\n",
      "Epoch: 24 | Iteration: 143 | Classification loss: 0.06108 | Regression loss: 0.18143 | Running loss: 0.19005\n",
      "Epoch: 24 | Iteration: 144 | Classification loss: 0.04329 | Regression loss: 0.18779 | Running loss: 0.18998\n",
      "Epoch: 24 | Iteration: 145 | Classification loss: 0.01605 | Regression loss: 0.21732 | Running loss: 0.19010\n",
      "Epoch: 24 | Iteration: 146 | Classification loss: 0.00669 | Regression loss: 0.08568 | Running loss: 0.18978\n",
      "Epoch: 24 | Iteration: 147 | Classification loss: 0.00849 | Regression loss: 0.07653 | Running loss: 0.18912\n",
      "Epoch: 24 | Iteration: 148 | Classification loss: 0.01828 | Regression loss: 0.17163 | Running loss: 0.18854\n",
      "Epoch: 24 | Iteration: 149 | Classification loss: 0.01310 | Regression loss: 0.26163 | Running loss: 0.18871\n",
      "Epoch: 24 | Iteration: 150 | Classification loss: 0.00243 | Regression loss: 0.06726 | Running loss: 0.18836\n",
      "Epoch: 24 | Iteration: 151 | Classification loss: 0.04235 | Regression loss: 0.13582 | Running loss: 0.18795\n",
      "Epoch: 24 | Iteration: 152 | Classification loss: 0.04791 | Regression loss: 0.13084 | Running loss: 0.18751\n",
      "Epoch: 24 | Iteration: 153 | Classification loss: 0.00624 | Regression loss: 0.08894 | Running loss: 0.18718\n",
      "Epoch: 24 | Iteration: 154 | Classification loss: 0.03724 | Regression loss: 0.20125 | Running loss: 0.18726\n",
      "Epoch: 24 | Iteration: 155 | Classification loss: 0.00268 | Regression loss: 0.06037 | Running loss: 0.18703\n",
      "Epoch: 24 | Iteration: 156 | Classification loss: 0.00571 | Regression loss: 0.12286 | Running loss: 0.18699\n",
      "Epoch: 24 | Iteration: 157 | Classification loss: 0.00534 | Regression loss: 0.12508 | Running loss: 0.18702\n",
      "Epoch: 24 | Iteration: 158 | Classification loss: 0.00301 | Regression loss: 0.09970 | Running loss: 0.18704\n",
      "Epoch: 24 | Iteration: 159 | Classification loss: 0.01172 | Regression loss: 0.14646 | Running loss: 0.18666\n",
      "Epoch: 24 | Iteration: 160 | Classification loss: 0.01491 | Regression loss: 0.12313 | Running loss: 0.18676\n",
      "Epoch: 24 | Iteration: 161 | Classification loss: 0.02084 | Regression loss: 0.16795 | Running loss: 0.18639\n",
      "Epoch: 24 | Iteration: 162 | Classification loss: 0.01111 | Regression loss: 0.19195 | Running loss: 0.18655\n",
      "Epoch: 24 | Iteration: 163 | Classification loss: 0.01231 | Regression loss: 0.09534 | Running loss: 0.18628\n",
      "Epoch: 24 | Iteration: 164 | Classification loss: 0.00234 | Regression loss: 0.09037 | Running loss: 0.18616\n",
      "Epoch: 24 | Iteration: 165 | Classification loss: 0.07127 | Regression loss: 0.26617 | Running loss: 0.18642\n",
      "Epoch: 24 | Iteration: 166 | Classification loss: 0.01082 | Regression loss: 0.10917 | Running loss: 0.18628\n",
      "Epoch: 24 | Iteration: 167 | Classification loss: 0.02736 | Regression loss: 0.19718 | Running loss: 0.18641\n",
      "Epoch: 24 | Iteration: 168 | Classification loss: 0.02019 | Regression loss: 0.11055 | Running loss: 0.18641\n",
      "Epoch: 24 | Iteration: 169 | Classification loss: 0.00852 | Regression loss: 0.15980 | Running loss: 0.18633\n",
      "Epoch: 24 | Iteration: 170 | Classification loss: 0.04171 | Regression loss: 0.22771 | Running loss: 0.18651\n",
      "Epoch: 24 | Iteration: 171 | Classification loss: 0.01843 | Regression loss: 0.18938 | Running loss: 0.18652\n",
      "Epoch: 24 | Iteration: 172 | Classification loss: 0.00888 | Regression loss: 0.11463 | Running loss: 0.18635\n",
      "Epoch: 24 | Iteration: 173 | Classification loss: 0.00323 | Regression loss: 0.07238 | Running loss: 0.18609\n",
      "Epoch: 24 | Iteration: 174 | Classification loss: 0.00663 | Regression loss: 0.07207 | Running loss: 0.18590\n",
      "Epoch: 24 | Iteration: 175 | Classification loss: 0.04317 | Regression loss: 0.09348 | Running loss: 0.18558\n",
      "Epoch: 24 | Iteration: 176 | Classification loss: 0.01221 | Regression loss: 0.09779 | Running loss: 0.18527\n",
      "Epoch: 24 | Iteration: 177 | Classification loss: 0.04277 | Regression loss: 0.22765 | Running loss: 0.18547\n",
      "Epoch: 24 | Iteration: 178 | Classification loss: 0.01427 | Regression loss: 0.10711 | Running loss: 0.18561\n",
      "Epoch: 24 | Iteration: 179 | Classification loss: 0.00322 | Regression loss: 0.08028 | Running loss: 0.18557\n",
      "Epoch: 24 | Iteration: 180 | Classification loss: 0.00182 | Regression loss: 0.05970 | Running loss: 0.18531\n",
      "Epoch: 24 | Iteration: 181 | Classification loss: 0.00878 | Regression loss: 0.12999 | Running loss: 0.18518\n",
      "Epoch: 24 | Iteration: 182 | Classification loss: 0.02236 | Regression loss: 0.12092 | Running loss: 0.18525\n",
      "Epoch: 24 | Iteration: 183 | Classification loss: 0.01600 | Regression loss: 0.06741 | Running loss: 0.18542\n",
      "Epoch: 24 | Iteration: 184 | Classification loss: 0.04157 | Regression loss: 0.05405 | Running loss: 0.18470\n",
      "Epoch: 24 | Iteration: 185 | Classification loss: 0.01315 | Regression loss: 0.08785 | Running loss: 0.18429\n",
      "Epoch: 24 | Iteration: 186 | Classification loss: 0.00914 | Regression loss: 0.09000 | Running loss: 0.18424\n",
      "Epoch: 24 | Iteration: 187 | Classification loss: 0.01229 | Regression loss: 0.14647 | Running loss: 0.18441\n",
      "Epoch: 24 | Iteration: 188 | Classification loss: 0.00760 | Regression loss: 0.08782 | Running loss: 0.18429\n",
      "Epoch: 24 | Iteration: 189 | Classification loss: 0.04326 | Regression loss: 0.20528 | Running loss: 0.18445\n",
      "Epoch: 24 | Iteration: 190 | Classification loss: 0.05117 | Regression loss: 0.07600 | Running loss: 0.18442\n",
      "Epoch: 24 | Iteration: 191 | Classification loss: 0.00849 | Regression loss: 0.07250 | Running loss: 0.18423\n",
      "Epoch: 24 | Iteration: 192 | Classification loss: 0.01268 | Regression loss: 0.12379 | Running loss: 0.18419\n",
      "Epoch: 24 | Iteration: 193 | Classification loss: 0.02504 | Regression loss: 0.18738 | Running loss: 0.18438\n",
      "Epoch: 24 | Iteration: 194 | Classification loss: 0.04014 | Regression loss: 0.25947 | Running loss: 0.18391\n",
      "Epoch: 24 | Iteration: 195 | Classification loss: 0.01398 | Regression loss: 0.10731 | Running loss: 0.18379\n",
      "Epoch: 24 | Iteration: 196 | Classification loss: 0.00762 | Regression loss: 0.09429 | Running loss: 0.18343\n",
      "Epoch: 24 | Iteration: 197 | Classification loss: 0.00438 | Regression loss: 0.07480 | Running loss: 0.18311\n",
      "Epoch: 24 | Iteration: 198 | Classification loss: 0.03139 | Regression loss: 0.19521 | Running loss: 0.18331\n",
      "Epoch: 24 | Iteration: 199 | Classification loss: 0.00471 | Regression loss: 0.09153 | Running loss: 0.18316\n",
      "Epoch: 24 | Iteration: 200 | Classification loss: 0.01351 | Regression loss: 0.12137 | Running loss: 0.18323\n",
      "Epoch: 24 | Iteration: 201 | Classification loss: 0.00661 | Regression loss: 0.07976 | Running loss: 0.18326\n",
      "Epoch: 24 | Iteration: 202 | Classification loss: 0.01170 | Regression loss: 0.09262 | Running loss: 0.18320\n",
      "Epoch: 24 | Iteration: 203 | Classification loss: 0.00993 | Regression loss: 0.09415 | Running loss: 0.18324\n",
      "Epoch: 24 | Iteration: 204 | Classification loss: 0.03064 | Regression loss: 0.16996 | Running loss: 0.18346\n",
      "Epoch: 24 | Iteration: 205 | Classification loss: 0.03241 | Regression loss: 0.27209 | Running loss: 0.18337\n",
      "Epoch: 24 | Iteration: 206 | Classification loss: 0.00733 | Regression loss: 0.14147 | Running loss: 0.18327\n",
      "Epoch: 24 | Iteration: 207 | Classification loss: 0.02146 | Regression loss: 0.10552 | Running loss: 0.18327\n",
      "Epoch: 24 | Iteration: 208 | Classification loss: 0.00442 | Regression loss: 0.09274 | Running loss: 0.18269\n",
      "Epoch: 24 | Iteration: 209 | Classification loss: 0.02899 | Regression loss: 0.16322 | Running loss: 0.18282\n",
      "Epoch: 24 | Iteration: 210 | Classification loss: 0.00677 | Regression loss: 0.08534 | Running loss: 0.18272\n",
      "Epoch: 24 | Iteration: 211 | Classification loss: 0.01493 | Regression loss: 0.22304 | Running loss: 0.18294\n",
      "Epoch: 24 | Iteration: 212 | Classification loss: 0.04825 | Regression loss: 0.15949 | Running loss: 0.18300\n",
      "Epoch: 24 | Iteration: 213 | Classification loss: 0.05469 | Regression loss: 0.13744 | Running loss: 0.18318\n",
      "Epoch: 24 | Iteration: 214 | Classification loss: 0.07467 | Regression loss: 0.28827 | Running loss: 0.18370\n",
      "Epoch: 24 | Iteration: 215 | Classification loss: 0.00658 | Regression loss: 0.09164 | Running loss: 0.18349\n",
      "Epoch: 24 | Iteration: 216 | Classification loss: 0.02331 | Regression loss: 0.19916 | Running loss: 0.18374\n",
      "Epoch: 24 | Iteration: 217 | Classification loss: 0.01009 | Regression loss: 0.20334 | Running loss: 0.18398\n",
      "Epoch: 24 | Iteration: 218 | Classification loss: 0.01070 | Regression loss: 0.09070 | Running loss: 0.18370\n",
      "Epoch: 24 | Iteration: 219 | Classification loss: 0.02001 | Regression loss: 0.08950 | Running loss: 0.18349\n",
      "Epoch: 24 | Iteration: 220 | Classification loss: 0.00760 | Regression loss: 0.08250 | Running loss: 0.18314\n",
      "Epoch: 24 | Iteration: 221 | Classification loss: 0.00755 | Regression loss: 0.17871 | Running loss: 0.18307\n",
      "Epoch: 24 | Iteration: 222 | Classification loss: 0.01438 | Regression loss: 0.12789 | Running loss: 0.18285\n",
      "Epoch: 24 | Iteration: 223 | Classification loss: 0.01100 | Regression loss: 0.06982 | Running loss: 0.18280\n",
      "Epoch: 24 | Iteration: 224 | Classification loss: 0.00902 | Regression loss: 0.06607 | Running loss: 0.18276\n",
      "Epoch: 24 | Iteration: 225 | Classification loss: 0.00313 | Regression loss: 0.05087 | Running loss: 0.18249\n",
      "Epoch: 24 | Iteration: 226 | Classification loss: 0.01652 | Regression loss: 0.09521 | Running loss: 0.18250\n",
      "Epoch: 24 | Iteration: 227 | Classification loss: 0.00493 | Regression loss: 0.07764 | Running loss: 0.18192\n",
      "Epoch: 24 | Iteration: 228 | Classification loss: 0.02623 | Regression loss: 0.12351 | Running loss: 0.18174\n",
      "Epoch: 24 | Iteration: 229 | Classification loss: 0.00920 | Regression loss: 0.14329 | Running loss: 0.18177\n",
      "Epoch: 24 | Iteration: 230 | Classification loss: 0.03782 | Regression loss: 0.20088 | Running loss: 0.18160\n",
      "Epoch: 24 | Iteration: 231 | Classification loss: 0.01639 | Regression loss: 0.11769 | Running loss: 0.18167\n",
      "Epoch: 24 | Iteration: 232 | Classification loss: 0.01073 | Regression loss: 0.12436 | Running loss: 0.18138\n",
      "Epoch: 24 | Iteration: 233 | Classification loss: 0.00333 | Regression loss: 0.08073 | Running loss: 0.18099\n",
      "Epoch: 24 | Iteration: 234 | Classification loss: 0.02322 | Regression loss: 0.27081 | Running loss: 0.18091\n",
      "Epoch: 24 | Iteration: 235 | Classification loss: 0.02168 | Regression loss: 0.14501 | Running loss: 0.18105\n",
      "Epoch: 24 | Iteration: 236 | Classification loss: 0.02303 | Regression loss: 0.13654 | Running loss: 0.18095\n",
      "Epoch: 24 | Iteration: 237 | Classification loss: 0.00951 | Regression loss: 0.09519 | Running loss: 0.18082\n",
      "Epoch: 24 | Iteration: 238 | Classification loss: 0.01588 | Regression loss: 0.08493 | Running loss: 0.18092\n",
      "Epoch: 24 | Iteration: 239 | Classification loss: 0.02036 | Regression loss: 0.12323 | Running loss: 0.18082\n",
      "Epoch: 24 | Iteration: 240 | Classification loss: 0.02644 | Regression loss: 0.20866 | Running loss: 0.18093\n",
      "Epoch: 24 | Iteration: 241 | Classification loss: 0.02004 | Regression loss: 0.18622 | Running loss: 0.18125\n",
      "Epoch: 24 | Iteration: 242 | Classification loss: 0.01666 | Regression loss: 0.10883 | Running loss: 0.18080\n",
      "Epoch: 24 | Iteration: 243 | Classification loss: 0.01537 | Regression loss: 0.15891 | Running loss: 0.18077\n",
      "Epoch: 24 | Iteration: 244 | Classification loss: 0.00391 | Regression loss: 0.10910 | Running loss: 0.18058\n",
      "Epoch: 24 | Iteration: 245 | Classification loss: 0.02943 | Regression loss: 0.11556 | Running loss: 0.18073\n",
      "Epoch: 24 | Iteration: 246 | Classification loss: 0.00672 | Regression loss: 0.12471 | Running loss: 0.18024\n",
      "Epoch: 24 | Iteration: 247 | Classification loss: 0.02608 | Regression loss: 0.11586 | Running loss: 0.18002\n",
      "Epoch: 24 | Iteration: 248 | Classification loss: 0.00340 | Regression loss: 0.06123 | Running loss: 0.17976\n",
      "Epoch: 24 | Iteration: 249 | Classification loss: 0.01510 | Regression loss: 0.09116 | Running loss: 0.17916\n",
      "Epoch: 24 | Iteration: 250 | Classification loss: 0.00511 | Regression loss: 0.08947 | Running loss: 0.17905\n",
      "Epoch: 24 | Iteration: 251 | Classification loss: 0.02422 | Regression loss: 0.21921 | Running loss: 0.17903\n",
      "Epoch: 24 | Iteration: 252 | Classification loss: 0.12152 | Regression loss: 0.48712 | Running loss: 0.17993\n",
      "Epoch: 24 | Iteration: 253 | Classification loss: 0.21160 | Regression loss: 0.56834 | Running loss: 0.18119\n",
      "Epoch: 24 | Iteration: 254 | Classification loss: 0.00562 | Regression loss: 0.23273 | Running loss: 0.18147\n",
      "Epoch: 24 | Iteration: 255 | Classification loss: 0.00531 | Regression loss: 0.10522 | Running loss: 0.18149\n",
      "Epoch: 24 | Iteration: 256 | Classification loss: 0.05368 | Regression loss: 0.26584 | Running loss: 0.18117\n",
      "Epoch: 24 | Iteration: 257 | Classification loss: 0.00878 | Regression loss: 0.09019 | Running loss: 0.18122\n",
      "Epoch: 24 | Iteration: 258 | Classification loss: 0.00978 | Regression loss: 0.10356 | Running loss: 0.18117\n",
      "Epoch: 24 | Iteration: 259 | Classification loss: 0.01923 | Regression loss: 0.11104 | Running loss: 0.18127\n",
      "Epoch: 24 | Iteration: 260 | Classification loss: 0.00939 | Regression loss: 0.12557 | Running loss: 0.18115\n",
      "Epoch: 24 | Iteration: 261 | Classification loss: 0.04510 | Regression loss: 0.13152 | Running loss: 0.18130\n",
      "Epoch: 24 | Iteration: 262 | Classification loss: 0.03379 | Regression loss: 0.17164 | Running loss: 0.18153\n",
      "Epoch: 24 | Iteration: 263 | Classification loss: 0.00869 | Regression loss: 0.10148 | Running loss: 0.18139\n",
      "Epoch: 24 | Iteration: 264 | Classification loss: 0.02693 | Regression loss: 0.20734 | Running loss: 0.18135\n",
      "Epoch: 24 | Iteration: 265 | Classification loss: 0.02239 | Regression loss: 0.19516 | Running loss: 0.18140\n",
      "Epoch: 24 | Iteration: 266 | Classification loss: 0.01586 | Regression loss: 0.09706 | Running loss: 0.18144\n",
      "Epoch: 24 | Iteration: 267 | Classification loss: 0.00405 | Regression loss: 0.08096 | Running loss: 0.18145\n",
      "Epoch: 24 | Iteration: 268 | Classification loss: 0.02243 | Regression loss: 0.14473 | Running loss: 0.18130\n",
      "Epoch: 24 | Iteration: 269 | Classification loss: 0.01414 | Regression loss: 0.07830 | Running loss: 0.18123\n",
      "Epoch: 24 | Iteration: 270 | Classification loss: 0.00588 | Regression loss: 0.14539 | Running loss: 0.18134\n",
      "Epoch: 24 | Iteration: 271 | Classification loss: 0.00259 | Regression loss: 0.07077 | Running loss: 0.18118\n",
      "Epoch: 24 | Iteration: 272 | Classification loss: 0.01054 | Regression loss: 0.11873 | Running loss: 0.18092\n",
      "Epoch: 24 | Iteration: 273 | Classification loss: 0.01107 | Regression loss: 0.10110 | Running loss: 0.18068\n",
      "Epoch: 24 | Iteration: 274 | Classification loss: 0.02769 | Regression loss: 0.20365 | Running loss: 0.18098\n",
      "Epoch: 24 | Iteration: 275 | Classification loss: 0.02636 | Regression loss: 0.18052 | Running loss: 0.18098\n",
      "Epoch: 24 | Iteration: 276 | Classification loss: 0.13403 | Regression loss: 0.28313 | Running loss: 0.18154\n",
      "Epoch: 24 | Iteration: 277 | Classification loss: 0.00619 | Regression loss: 0.02375 | Running loss: 0.18127\n",
      "Epoch: 24 | Iteration: 278 | Classification loss: 0.03442 | Regression loss: 0.25452 | Running loss: 0.18139\n",
      "Epoch: 24 | Iteration: 279 | Classification loss: 0.03827 | Regression loss: 0.16455 | Running loss: 0.18128\n",
      "Epoch: 24 | Iteration: 280 | Classification loss: 0.02237 | Regression loss: 0.17950 | Running loss: 0.18145\n",
      "Epoch: 24 | Iteration: 281 | Classification loss: 0.00427 | Regression loss: 0.07637 | Running loss: 0.18075\n",
      "Epoch: 24 | Iteration: 282 | Classification loss: 0.00227 | Regression loss: 0.05372 | Running loss: 0.18050\n",
      "Epoch: 24 | Iteration: 283 | Classification loss: 0.01167 | Regression loss: 0.11242 | Running loss: 0.18042\n",
      "Epoch: 24 | Iteration: 284 | Classification loss: 0.02611 | Regression loss: 0.28716 | Running loss: 0.18082\n",
      "Epoch: 24 | Iteration: 285 | Classification loss: 0.01265 | Regression loss: 0.13211 | Running loss: 0.18076\n",
      "Epoch: 24 | Iteration: 286 | Classification loss: 0.02363 | Regression loss: 0.15303 | Running loss: 0.18082\n",
      "Epoch: 24 | Iteration: 287 | Classification loss: 0.01700 | Regression loss: 0.17687 | Running loss: 0.18084\n",
      "Epoch: 24 | Iteration: 288 | Classification loss: 0.01130 | Regression loss: 0.08820 | Running loss: 0.18050\n",
      "Epoch: 24 | Iteration: 289 | Classification loss: 0.87052 | Regression loss: 0.56381 | Running loss: 0.18315\n",
      "Epoch: 24 | Iteration: 290 | Classification loss: 0.01432 | Regression loss: 0.11189 | Running loss: 0.18303\n",
      "Epoch: 24 | Iteration: 291 | Classification loss: 0.01365 | Regression loss: 0.13298 | Running loss: 0.18309\n",
      "Epoch: 24 | Iteration: 292 | Classification loss: 0.01068 | Regression loss: 0.09924 | Running loss: 0.18108\n",
      "Epoch: 24 | Iteration: 293 | Classification loss: 0.02532 | Regression loss: 0.21115 | Running loss: 0.18078\n",
      "Epoch: 24 | Iteration: 294 | Classification loss: 0.02330 | Regression loss: 0.09526 | Running loss: 0.18066\n",
      "Epoch: 24 | Iteration: 295 | Classification loss: 0.01484 | Regression loss: 0.12848 | Running loss: 0.18073\n",
      "Epoch: 24 | Iteration: 296 | Classification loss: 0.02652 | Regression loss: 0.18572 | Running loss: 0.18017\n",
      "Epoch: 24 | Iteration: 297 | Classification loss: 0.01766 | Regression loss: 0.10096 | Running loss: 0.17979\n",
      "Epoch: 24 | Iteration: 298 | Classification loss: 0.01513 | Regression loss: 0.15224 | Running loss: 0.17979\n",
      "Epoch: 24 | Iteration: 299 | Classification loss: 0.01918 | Regression loss: 0.16483 | Running loss: 0.17999\n",
      "Epoch: 24 | Iteration: 300 | Classification loss: 0.01620 | Regression loss: 0.10241 | Running loss: 0.17994\n",
      "Epoch: 24 | Iteration: 301 | Classification loss: 0.00540 | Regression loss: 0.05994 | Running loss: 0.17989\n",
      "Epoch: 24 | Iteration: 302 | Classification loss: 0.00872 | Regression loss: 0.11782 | Running loss: 0.17984\n",
      "Epoch: 24 | Iteration: 303 | Classification loss: 0.00400 | Regression loss: 0.07233 | Running loss: 0.17965\n",
      "Epoch: 24 | Iteration: 304 | Classification loss: 0.02600 | Regression loss: 0.18517 | Running loss: 0.17967\n",
      "Epoch: 24 | Iteration: 305 | Classification loss: 0.00546 | Regression loss: 0.15694 | Running loss: 0.17919\n",
      "Epoch: 24 | Iteration: 306 | Classification loss: 0.02209 | Regression loss: 0.07491 | Running loss: 0.17851\n",
      "Epoch: 24 | Iteration: 307 | Classification loss: 0.02136 | Regression loss: 0.13863 | Running loss: 0.17858\n",
      "Epoch: 24 | Iteration: 308 | Classification loss: 0.02618 | Regression loss: 0.10637 | Running loss: 0.17865\n",
      "Epoch: 24 | Iteration: 309 | Classification loss: 0.01983 | Regression loss: 0.19477 | Running loss: 0.17873\n",
      "Epoch: 24 | Iteration: 310 | Classification loss: 0.00451 | Regression loss: 0.10054 | Running loss: 0.17861\n",
      "Epoch: 24 | Iteration: 311 | Classification loss: 0.17786 | Regression loss: 0.32871 | Running loss: 0.17938\n",
      "Epoch: 24 | Iteration: 312 | Classification loss: 0.00523 | Regression loss: 0.09818 | Running loss: 0.17940\n",
      "Epoch: 24 | Iteration: 313 | Classification loss: 0.09482 | Regression loss: 0.26360 | Running loss: 0.17979\n",
      "Epoch: 24 | Iteration: 314 | Classification loss: 0.01182 | Regression loss: 0.10332 | Running loss: 0.17970\n",
      "Epoch: 24 | Iteration: 315 | Classification loss: 0.01026 | Regression loss: 0.16013 | Running loss: 0.17981\n",
      "Epoch: 24 | Iteration: 316 | Classification loss: 0.03032 | Regression loss: 0.27564 | Running loss: 0.18012\n",
      "Epoch: 24 | Iteration: 317 | Classification loss: 0.01286 | Regression loss: 0.13497 | Running loss: 0.18017\n",
      "Epoch: 24 | Iteration: 318 | Classification loss: 0.15654 | Regression loss: 0.23264 | Running loss: 0.18009\n",
      "Epoch: 24 | Iteration: 319 | Classification loss: 0.01988 | Regression loss: 0.10448 | Running loss: 0.18009\n",
      "Epoch: 24 | Iteration: 320 | Classification loss: 0.00908 | Regression loss: 0.12198 | Running loss: 0.18009\n",
      "Epoch: 24 | Iteration: 321 | Classification loss: 0.08422 | Regression loss: 0.32096 | Running loss: 0.18067\n",
      "Epoch: 24 | Iteration: 322 | Classification loss: 0.03891 | Regression loss: 0.14373 | Running loss: 0.18063\n",
      "Epoch: 24 | Iteration: 323 | Classification loss: 0.00886 | Regression loss: 0.13171 | Running loss: 0.18057\n",
      "Epoch: 24 | Iteration: 324 | Classification loss: 0.01834 | Regression loss: 0.11567 | Running loss: 0.18032\n",
      "Epoch: 24 | Iteration: 325 | Classification loss: 0.00512 | Regression loss: 0.08709 | Running loss: 0.17979\n",
      "Epoch: 24 | Iteration: 326 | Classification loss: 0.01019 | Regression loss: 0.10229 | Running loss: 0.17974\n",
      "Epoch: 24 | Iteration: 327 | Classification loss: 0.03642 | Regression loss: 0.19237 | Running loss: 0.17992\n",
      "Epoch: 24 | Iteration: 328 | Classification loss: 0.01701 | Regression loss: 0.12702 | Running loss: 0.17980\n",
      "Epoch: 24 | Iteration: 329 | Classification loss: 0.05715 | Regression loss: 0.12043 | Running loss: 0.17974\n",
      "Epoch: 24 | Iteration: 330 | Classification loss: 0.03602 | Regression loss: 0.22165 | Running loss: 0.18013\n",
      "Epoch: 24 | Iteration: 331 | Classification loss: 0.01195 | Regression loss: 0.17348 | Running loss: 0.18036\n",
      "Epoch: 24 | Iteration: 332 | Classification loss: 0.00923 | Regression loss: 0.08398 | Running loss: 0.18019\n",
      "Epoch: 24 | Iteration: 333 | Classification loss: 0.01467 | Regression loss: 0.09688 | Running loss: 0.18002\n",
      "Epoch: 24 | Iteration: 334 | Classification loss: 0.02039 | Regression loss: 0.17672 | Running loss: 0.18004\n",
      "Epoch: 24 | Iteration: 335 | Classification loss: 0.02634 | Regression loss: 0.12443 | Running loss: 0.18017\n",
      "Epoch: 24 | Iteration: 336 | Classification loss: 0.04983 | Regression loss: 0.12232 | Running loss: 0.18014\n",
      "Epoch: 24 | Iteration: 337 | Classification loss: 0.05876 | Regression loss: 0.25086 | Running loss: 0.18041\n",
      "Epoch: 24 | Iteration: 338 | Classification loss: 0.01198 | Regression loss: 0.09829 | Running loss: 0.18051\n",
      "Epoch: 24 | Iteration: 339 | Classification loss: 0.02831 | Regression loss: 0.21642 | Running loss: 0.18046\n",
      "Epoch: 24 | Iteration: 340 | Classification loss: 0.02047 | Regression loss: 0.10851 | Running loss: 0.18053\n",
      "Epoch: 24 | Iteration: 341 | Classification loss: 0.02716 | Regression loss: 0.19797 | Running loss: 0.18059\n",
      "Epoch: 24 | Iteration: 342 | Classification loss: 0.02138 | Regression loss: 0.22101 | Running loss: 0.17992\n",
      "Epoch: 24 | Iteration: 343 | Classification loss: 0.00268 | Regression loss: 0.05715 | Running loss: 0.17946\n",
      "Epoch: 24 | Iteration: 344 | Classification loss: 0.00423 | Regression loss: 0.14506 | Running loss: 0.17948\n",
      "Epoch: 24 | Iteration: 345 | Classification loss: 0.00913 | Regression loss: 0.07925 | Running loss: 0.17898\n",
      "Epoch: 24 | Iteration: 346 | Classification loss: 0.04452 | Regression loss: 0.20790 | Running loss: 0.17916\n",
      "Epoch: 24 | Iteration: 347 | Classification loss: 0.00868 | Regression loss: 0.16949 | Running loss: 0.17921\n",
      "Epoch: 24 | Iteration: 348 | Classification loss: 0.00193 | Regression loss: 0.05382 | Running loss: 0.17913\n",
      "Epoch: 24 | Iteration: 349 | Classification loss: 0.01356 | Regression loss: 0.17627 | Running loss: 0.17930\n",
      "Epoch: 24 | Iteration: 350 | Classification loss: 0.00475 | Regression loss: 0.09152 | Running loss: 0.17913\n",
      "Epoch: 24 | Iteration: 351 | Classification loss: 0.02352 | Regression loss: 0.05401 | Running loss: 0.17903\n",
      "Epoch: 24 | Iteration: 352 | Classification loss: 0.02712 | Regression loss: 0.13145 | Running loss: 0.17851\n",
      "Epoch: 24 | Iteration: 353 | Classification loss: 0.01159 | Regression loss: 0.20367 | Running loss: 0.17833\n",
      "Epoch: 24 | Iteration: 354 | Classification loss: 0.02541 | Regression loss: 0.22061 | Running loss: 0.17855\n",
      "Epoch: 24 | Iteration: 355 | Classification loss: 0.00549 | Regression loss: 0.04834 | Running loss: 0.17837\n",
      "Epoch: 24 | Iteration: 356 | Classification loss: 0.00602 | Regression loss: 0.10702 | Running loss: 0.17835\n",
      "Epoch: 24 | Iteration: 357 | Classification loss: 0.00552 | Regression loss: 0.09507 | Running loss: 0.17777\n",
      "Epoch: 24 | Iteration: 358 | Classification loss: 0.01834 | Regression loss: 0.15158 | Running loss: 0.17740\n",
      "Epoch: 24 | Iteration: 359 | Classification loss: 0.01184 | Regression loss: 0.11835 | Running loss: 0.17711\n",
      "Epoch: 24 | Iteration: 360 | Classification loss: 0.05844 | Regression loss: 0.21404 | Running loss: 0.17703\n",
      "Epoch: 24 | Iteration: 361 | Classification loss: 0.03426 | Regression loss: 0.19411 | Running loss: 0.17719\n",
      "Epoch: 24 | Iteration: 362 | Classification loss: 0.00389 | Regression loss: 0.08468 | Running loss: 0.17719\n",
      "Epoch: 24 | Iteration: 363 | Classification loss: 0.02344 | Regression loss: 0.25418 | Running loss: 0.17745\n",
      "Epoch: 24 | Iteration: 364 | Classification loss: 0.00557 | Regression loss: 0.08490 | Running loss: 0.17734\n",
      "Epoch: 24 | Iteration: 365 | Classification loss: 0.01133 | Regression loss: 0.07843 | Running loss: 0.17723\n",
      "Epoch: 24 | Iteration: 366 | Classification loss: 0.00464 | Regression loss: 0.07201 | Running loss: 0.17688\n",
      "Epoch: 24 | Iteration: 367 | Classification loss: 0.00335 | Regression loss: 0.12659 | Running loss: 0.17668\n",
      "Epoch: 24 | Iteration: 368 | Classification loss: 0.00796 | Regression loss: 0.13912 | Running loss: 0.17677\n",
      "Epoch: 24 | Iteration: 369 | Classification loss: 0.04841 | Regression loss: 0.12740 | Running loss: 0.17681\n",
      "Epoch: 24 | Iteration: 370 | Classification loss: 0.00610 | Regression loss: 0.07432 | Running loss: 0.17672\n",
      "Epoch: 24 | Iteration: 371 | Classification loss: 0.01252 | Regression loss: 0.16192 | Running loss: 0.17684\n",
      "Epoch: 24 | Iteration: 372 | Classification loss: 0.03107 | Regression loss: 0.14910 | Running loss: 0.17678\n",
      "Epoch: 24 | Iteration: 373 | Classification loss: 0.00379 | Regression loss: 0.05725 | Running loss: 0.17649\n",
      "Epoch: 24 | Iteration: 374 | Classification loss: 0.05720 | Regression loss: 0.18728 | Running loss: 0.17641\n",
      "Epoch: 24 | Iteration: 375 | Classification loss: 0.02772 | Regression loss: 0.11348 | Running loss: 0.17649\n",
      "Epoch: 24 | Iteration: 376 | Classification loss: 0.01836 | Regression loss: 0.10172 | Running loss: 0.17609\n",
      "Epoch: 24 | Iteration: 377 | Classification loss: 0.03769 | Regression loss: 0.19442 | Running loss: 0.17634\n",
      "Epoch: 24 | Iteration: 378 | Classification loss: 0.00724 | Regression loss: 0.08585 | Running loss: 0.17615\n",
      "Epoch: 24 | Iteration: 379 | Classification loss: 0.01451 | Regression loss: 0.18557 | Running loss: 0.17638\n",
      "Epoch: 24 | Iteration: 380 | Classification loss: 0.01765 | Regression loss: 0.14399 | Running loss: 0.17646\n",
      "Epoch: 24 | Iteration: 381 | Classification loss: 0.01179 | Regression loss: 0.06998 | Running loss: 0.17628\n",
      "Epoch: 24 | Iteration: 382 | Classification loss: 0.00712 | Regression loss: 0.08391 | Running loss: 0.17627\n",
      "Epoch: 24 | Iteration: 383 | Classification loss: 0.08691 | Regression loss: 0.23801 | Running loss: 0.17659\n",
      "Epoch: 24 | Iteration: 384 | Classification loss: 0.01112 | Regression loss: 0.10358 | Running loss: 0.17669\n",
      "Epoch: 24 | Iteration: 385 | Classification loss: 0.02270 | Regression loss: 0.10860 | Running loss: 0.17651\n",
      "Epoch: 24 | Iteration: 386 | Classification loss: 0.04860 | Regression loss: 0.28248 | Running loss: 0.17637\n",
      "Epoch: 24 | Iteration: 387 | Classification loss: 0.06259 | Regression loss: 0.24913 | Running loss: 0.17670\n",
      "Epoch: 24 | Iteration: 388 | Classification loss: 0.01089 | Regression loss: 0.10029 | Running loss: 0.17671\n",
      "Epoch: 24 | Iteration: 389 | Classification loss: 0.02431 | Regression loss: 0.22876 | Running loss: 0.17676\n",
      "Epoch: 24 | Iteration: 390 | Classification loss: 0.02973 | Regression loss: 0.27076 | Running loss: 0.17689\n",
      "Epoch: 24 | Iteration: 391 | Classification loss: 0.00702 | Regression loss: 0.15949 | Running loss: 0.17706\n",
      "Epoch: 24 | Iteration: 392 | Classification loss: 0.00499 | Regression loss: 0.08888 | Running loss: 0.17696\n",
      "Epoch: 24 | Iteration: 393 | Classification loss: 0.00499 | Regression loss: 0.06774 | Running loss: 0.17692\n",
      "Epoch: 24 | Iteration: 394 | Classification loss: 0.01711 | Regression loss: 0.10806 | Running loss: 0.17665\n",
      "Epoch: 24 | Iteration: 395 | Classification loss: 0.01158 | Regression loss: 0.17225 | Running loss: 0.17676\n",
      "Epoch: 24 | Iteration: 396 | Classification loss: 0.06669 | Regression loss: 0.25788 | Running loss: 0.17701\n",
      "Epoch: 24 | Iteration: 397 | Classification loss: 0.02068 | Regression loss: 0.12206 | Running loss: 0.17696\n",
      "Epoch: 24 | Iteration: 398 | Classification loss: 0.00814 | Regression loss: 0.06491 | Running loss: 0.17659\n",
      "Epoch: 24 | Iteration: 399 | Classification loss: 0.01368 | Regression loss: 0.18724 | Running loss: 0.17659\n",
      "Epoch: 24 | Iteration: 400 | Classification loss: 0.00870 | Regression loss: 0.08800 | Running loss: 0.17652\n",
      "Epoch: 24 | Iteration: 401 | Classification loss: 0.03314 | Regression loss: 0.15407 | Running loss: 0.17663\n",
      "Epoch: 24 | Iteration: 402 | Classification loss: 0.00904 | Regression loss: 0.10999 | Running loss: 0.17641\n",
      "Epoch: 24 | Iteration: 403 | Classification loss: 0.00785 | Regression loss: 0.11588 | Running loss: 0.17622\n",
      "Epoch: 24 | Iteration: 404 | Classification loss: 0.07587 | Regression loss: 0.25729 | Running loss: 0.17671\n",
      "Epoch: 24 | Iteration: 405 | Classification loss: 0.06279 | Regression loss: 0.23736 | Running loss: 0.17720\n",
      "Epoch: 24 | Iteration: 406 | Classification loss: 0.11071 | Regression loss: 0.27990 | Running loss: 0.17731\n",
      "Epoch: 24 | Iteration: 407 | Classification loss: 0.01152 | Regression loss: 0.06944 | Running loss: 0.17680\n",
      "Epoch: 24 | Iteration: 408 | Classification loss: 0.02212 | Regression loss: 0.07048 | Running loss: 0.17652\n",
      "Epoch: 24 | Iteration: 409 | Classification loss: 0.00330 | Regression loss: 0.09685 | Running loss: 0.17663\n",
      "Epoch: 24 | Iteration: 410 | Classification loss: 0.05815 | Regression loss: 0.27762 | Running loss: 0.17702\n",
      "Epoch: 24 | Iteration: 411 | Classification loss: 0.01155 | Regression loss: 0.08861 | Running loss: 0.17666\n",
      "Epoch: 24 | Iteration: 412 | Classification loss: 0.00884 | Regression loss: 0.18223 | Running loss: 0.17586\n",
      "Epoch: 24 | Iteration: 413 | Classification loss: 0.01428 | Regression loss: 0.26436 | Running loss: 0.17587\n",
      "Epoch: 24 | Iteration: 414 | Classification loss: 0.01355 | Regression loss: 0.12932 | Running loss: 0.17562\n",
      "Epoch: 24 | Iteration: 415 | Classification loss: 0.00834 | Regression loss: 0.06914 | Running loss: 0.17542\n",
      "Epoch: 24 | Iteration: 416 | Classification loss: 0.00404 | Regression loss: 0.11159 | Running loss: 0.17510\n",
      "Epoch: 24 | Iteration: 417 | Classification loss: 0.01170 | Regression loss: 0.09189 | Running loss: 0.17507\n",
      "Epoch: 24 | Iteration: 418 | Classification loss: 0.00418 | Regression loss: 0.10116 | Running loss: 0.17509\n",
      "Epoch: 24 | Iteration: 419 | Classification loss: 0.08033 | Regression loss: 0.18279 | Running loss: 0.17540\n",
      "Epoch: 24 | Iteration: 420 | Classification loss: 0.01027 | Regression loss: 0.14161 | Running loss: 0.17521\n",
      "Epoch: 24 | Iteration: 421 | Classification loss: 0.00522 | Regression loss: 0.08339 | Running loss: 0.17503\n",
      "Epoch: 24 | Iteration: 422 | Classification loss: 0.00986 | Regression loss: 0.10214 | Running loss: 0.17507\n",
      "Epoch: 24 | Iteration: 423 | Classification loss: 0.01429 | Regression loss: 0.18679 | Running loss: 0.17508\n",
      "Epoch: 24 | Iteration: 424 | Classification loss: 0.01710 | Regression loss: 0.14965 | Running loss: 0.17489\n",
      "Epoch: 24 | Iteration: 425 | Classification loss: 0.00749 | Regression loss: 0.21323 | Running loss: 0.17511\n",
      "Epoch: 24 | Iteration: 426 | Classification loss: 0.02067 | Regression loss: 0.11977 | Running loss: 0.17486\n",
      "Epoch: 24 | Iteration: 427 | Classification loss: 0.02661 | Regression loss: 0.20222 | Running loss: 0.17511\n",
      "Epoch: 24 | Iteration: 428 | Classification loss: 0.00211 | Regression loss: 0.09388 | Running loss: 0.17516\n",
      "Epoch: 24 | Iteration: 429 | Classification loss: 0.04261 | Regression loss: 0.19947 | Running loss: 0.17542\n",
      "Epoch: 24 | Iteration: 430 | Classification loss: 0.00127 | Regression loss: 0.05326 | Running loss: 0.17531\n",
      "Epoch: 24 | Iteration: 431 | Classification loss: 0.00712 | Regression loss: 0.09248 | Running loss: 0.17517\n",
      "Epoch: 24 | Iteration: 432 | Classification loss: 0.01689 | Regression loss: 0.05349 | Running loss: 0.17498\n",
      "Epoch: 24 | Iteration: 433 | Classification loss: 0.02297 | Regression loss: 0.10799 | Running loss: 0.17490\n",
      "Epoch: 24 | Iteration: 434 | Classification loss: 0.01164 | Regression loss: 0.13679 | Running loss: 0.17495\n",
      "Epoch: 24 | Iteration: 435 | Classification loss: 0.01567 | Regression loss: 0.14866 | Running loss: 0.17494\n",
      "Epoch: 24 | Iteration: 436 | Classification loss: 0.00364 | Regression loss: 0.03929 | Running loss: 0.17449\n",
      "Epoch: 24 | Iteration: 437 | Classification loss: 0.02481 | Regression loss: 0.13321 | Running loss: 0.17418\n",
      "Epoch: 24 | Iteration: 438 | Classification loss: 0.01006 | Regression loss: 0.14705 | Running loss: 0.17422\n",
      "Epoch: 24 | Iteration: 439 | Classification loss: 0.01526 | Regression loss: 0.14046 | Running loss: 0.17425\n",
      "Epoch: 24 | Iteration: 440 | Classification loss: 0.00769 | Regression loss: 0.11095 | Running loss: 0.17418\n",
      "Epoch: 24 | Iteration: 441 | Classification loss: 0.01740 | Regression loss: 0.27463 | Running loss: 0.17438\n",
      "Epoch: 24 | Iteration: 442 | Classification loss: 0.00283 | Regression loss: 0.04919 | Running loss: 0.17416\n",
      "Epoch: 24 | Iteration: 443 | Classification loss: 0.03252 | Regression loss: 0.14339 | Running loss: 0.17415\n",
      "Epoch: 24 | Iteration: 444 | Classification loss: 0.00601 | Regression loss: 0.14747 | Running loss: 0.17374\n",
      "Epoch: 24 | Iteration: 445 | Classification loss: 0.02378 | Regression loss: 0.20456 | Running loss: 0.17403\n",
      "Epoch: 24 | Iteration: 446 | Classification loss: 0.02264 | Regression loss: 0.15956 | Running loss: 0.17363\n",
      "Epoch: 24 | Iteration: 447 | Classification loss: 0.00933 | Regression loss: 0.11524 | Running loss: 0.17362\n",
      "Epoch: 24 | Iteration: 448 | Classification loss: 0.01220 | Regression loss: 0.14557 | Running loss: 0.17363\n",
      "Epoch: 24 | Iteration: 449 | Classification loss: 0.00304 | Regression loss: 0.08867 | Running loss: 0.17349\n",
      "Epoch: 24 | Iteration: 450 | Classification loss: 0.08528 | Regression loss: 0.26473 | Running loss: 0.17381\n",
      "Epoch: 24 | Iteration: 451 | Classification loss: 0.05573 | Regression loss: 0.29666 | Running loss: 0.17421\n",
      "Epoch: 24 | Iteration: 452 | Classification loss: 0.01066 | Regression loss: 0.29402 | Running loss: 0.17438\n",
      "Epoch: 24 | Iteration: 453 | Classification loss: 0.04969 | Regression loss: 0.25229 | Running loss: 0.17478\n",
      "Epoch: 24 | Iteration: 454 | Classification loss: 0.00718 | Regression loss: 0.12515 | Running loss: 0.17445\n",
      "Epoch: 24 | Iteration: 455 | Classification loss: 0.00792 | Regression loss: 0.09200 | Running loss: 0.17429\n",
      "Epoch: 24 | Iteration: 456 | Classification loss: 0.02706 | Regression loss: 0.21708 | Running loss: 0.17414\n",
      "Epoch: 24 | Iteration: 457 | Classification loss: 0.01545 | Regression loss: 0.23569 | Running loss: 0.17420\n",
      "Epoch: 24 | Iteration: 458 | Classification loss: 0.01468 | Regression loss: 0.14857 | Running loss: 0.17378\n",
      "Epoch: 24 | Iteration: 459 | Classification loss: 0.00448 | Regression loss: 0.06388 | Running loss: 0.17374\n",
      "Epoch: 24 | Iteration: 460 | Classification loss: 0.03216 | Regression loss: 0.15709 | Running loss: 0.17374\n",
      "Epoch: 24 | Iteration: 461 | Classification loss: 0.00986 | Regression loss: 0.09876 | Running loss: 0.17370\n",
      "Epoch: 24 | Iteration: 462 | Classification loss: 0.01982 | Regression loss: 0.09642 | Running loss: 0.17343\n",
      "Epoch: 24 | Iteration: 463 | Classification loss: 0.00833 | Regression loss: 0.08827 | Running loss: 0.17319\n",
      "Epoch: 24 | Iteration: 464 | Classification loss: 0.01151 | Regression loss: 0.10669 | Running loss: 0.17314\n",
      "Epoch: 24 | Iteration: 465 | Classification loss: 0.00721 | Regression loss: 0.10510 | Running loss: 0.17308\n",
      "Epoch: 24 | Iteration: 466 | Classification loss: 0.08848 | Regression loss: 0.25991 | Running loss: 0.17343\n",
      "Epoch: 24 | Iteration: 467 | Classification loss: 0.00979 | Regression loss: 0.16634 | Running loss: 0.17338\n",
      "Epoch: 24 | Iteration: 468 | Classification loss: 0.02564 | Regression loss: 0.16152 | Running loss: 0.17331\n",
      "Epoch: 24 | Iteration: 469 | Classification loss: 0.01067 | Regression loss: 0.11236 | Running loss: 0.17305\n",
      "Epoch: 24 | Iteration: 470 | Classification loss: 0.01475 | Regression loss: 0.10041 | Running loss: 0.17311\n",
      "Epoch: 24 | Iteration: 471 | Classification loss: 0.02722 | Regression loss: 0.18660 | Running loss: 0.17328\n",
      "Epoch: 24 | Iteration: 472 | Classification loss: 0.01965 | Regression loss: 0.18169 | Running loss: 0.17317\n",
      "Epoch: 24 | Iteration: 473 | Classification loss: 0.02402 | Regression loss: 0.12703 | Running loss: 0.17321\n",
      "Epoch: 24 | Iteration: 474 | Classification loss: 0.00484 | Regression loss: 0.15870 | Running loss: 0.17269\n",
      "Epoch: 24 | Iteration: 475 | Classification loss: 0.01346 | Regression loss: 0.11655 | Running loss: 0.17249\n",
      "Epoch: 24 | Iteration: 476 | Classification loss: 0.12353 | Regression loss: 0.22738 | Running loss: 0.17282\n",
      "Epoch: 24 | Iteration: 477 | Classification loss: 0.05061 | Regression loss: 0.13360 | Running loss: 0.17274\n",
      "Epoch: 24 | Iteration: 478 | Classification loss: 0.01119 | Regression loss: 0.08320 | Running loss: 0.17245\n",
      "Epoch: 24 | Iteration: 479 | Classification loss: 0.02522 | Regression loss: 0.23714 | Running loss: 0.17264\n",
      "Epoch: 24 | Iteration: 480 | Classification loss: 0.03871 | Regression loss: 0.09632 | Running loss: 0.17204\n",
      "Epoch: 24 | Iteration: 481 | Classification loss: 0.02154 | Regression loss: 0.12748 | Running loss: 0.17196\n",
      "Epoch: 24 | Iteration: 482 | Classification loss: 0.02782 | Regression loss: 0.12462 | Running loss: 0.17200\n",
      "Epoch: 24 | Iteration: 483 | Classification loss: 0.00812 | Regression loss: 0.08563 | Running loss: 0.17179\n",
      "Epoch: 24 | Iteration: 484 | Classification loss: 0.00616 | Regression loss: 0.09993 | Running loss: 0.17159\n",
      "Epoch: 24 | Iteration: 485 | Classification loss: 0.00824 | Regression loss: 0.11049 | Running loss: 0.17129\n",
      "Epoch: 24 | Iteration: 486 | Classification loss: 0.05738 | Regression loss: 0.13260 | Running loss: 0.17145\n",
      "Epoch: 24 | Iteration: 487 | Classification loss: 0.06082 | Regression loss: 0.23373 | Running loss: 0.17164\n",
      "Epoch: 24 | Iteration: 488 | Classification loss: 0.02950 | Regression loss: 0.25576 | Running loss: 0.17182\n",
      "Epoch: 24 | Iteration: 489 | Classification loss: 0.00546 | Regression loss: 0.09806 | Running loss: 0.17171\n",
      "Epoch: 24 | Iteration: 490 | Classification loss: 0.00688 | Regression loss: 0.08051 | Running loss: 0.17168\n",
      "Epoch: 24 | Iteration: 491 | Classification loss: 0.01061 | Regression loss: 0.12178 | Running loss: 0.17173\n",
      "Epoch: 24 | Iteration: 492 | Classification loss: 0.01320 | Regression loss: 0.07117 | Running loss: 0.17096\n",
      "Epoch: 24 | Iteration: 493 | Classification loss: 0.01948 | Regression loss: 0.10051 | Running loss: 0.16984\n",
      "Epoch: 24 | Iteration: 494 | Classification loss: 0.01785 | Regression loss: 0.07738 | Running loss: 0.16972\n",
      "Epoch: 24 | Iteration: 495 | Classification loss: 0.03307 | Regression loss: 0.19404 | Running loss: 0.16998\n",
      "Epoch: 24 | Iteration: 496 | Classification loss: 0.01837 | Regression loss: 0.14416 | Running loss: 0.17016\n",
      "Epoch: 24 | Iteration: 497 | Classification loss: 0.03782 | Regression loss: 0.16070 | Running loss: 0.17039\n",
      "Epoch: 24 | Iteration: 498 | Classification loss: 0.05025 | Regression loss: 0.14271 | Running loss: 0.17054\n",
      "Epoch: 24 | Iteration: 499 | Classification loss: 0.00966 | Regression loss: 0.05939 | Running loss: 0.17047\n",
      "Epoch: 24 | Iteration: 500 | Classification loss: 0.01857 | Regression loss: 0.13170 | Running loss: 0.17041\n",
      "Epoch: 24 | Iteration: 501 | Classification loss: 0.03035 | Regression loss: 0.14517 | Running loss: 0.17025\n",
      "Epoch: 24 | Iteration: 502 | Classification loss: 0.00590 | Regression loss: 0.17286 | Running loss: 0.17034\n",
      "Epoch: 24 | Iteration: 503 | Classification loss: 0.02294 | Regression loss: 0.17793 | Running loss: 0.17038\n",
      "Epoch: 24 | Iteration: 504 | Classification loss: 0.01027 | Regression loss: 0.09190 | Running loss: 0.17028\n",
      "Epoch: 24 | Iteration: 505 | Classification loss: 0.02806 | Regression loss: 0.24528 | Running loss: 0.17068\n",
      "Epoch: 24 | Iteration: 506 | Classification loss: 0.04913 | Regression loss: 0.30501 | Running loss: 0.17115\n",
      "Epoch: 24 | Iteration: 507 | Classification loss: 0.03152 | Regression loss: 0.22228 | Running loss: 0.17142\n",
      "Epoch: 24 | Iteration: 508 | Classification loss: 0.01921 | Regression loss: 0.20992 | Running loss: 0.17164\n",
      "Epoch: 24 | Iteration: 509 | Classification loss: 0.03798 | Regression loss: 0.14091 | Running loss: 0.17156\n",
      "Epoch: 24 | Iteration: 510 | Classification loss: 0.01118 | Regression loss: 0.11268 | Running loss: 0.17143\n",
      "Epoch: 24 | Iteration: 511 | Classification loss: 0.11813 | Regression loss: 0.26129 | Running loss: 0.17192\n",
      "Epoch: 24 | Iteration: 512 | Classification loss: 0.00508 | Regression loss: 0.07258 | Running loss: 0.17184\n",
      "Epoch: 24 | Iteration: 513 | Classification loss: 0.02637 | Regression loss: 0.07579 | Running loss: 0.17161\n",
      "Epoch: 24 | Iteration: 514 | Classification loss: 0.02536 | Regression loss: 0.16076 | Running loss: 0.17181\n",
      "Epoch: 24 | Iteration: 515 | Classification loss: 0.07974 | Regression loss: 0.24630 | Running loss: 0.17222\n",
      "Epoch: 24 | Iteration: 516 | Classification loss: 0.02341 | Regression loss: 0.12073 | Running loss: 0.17176\n",
      "Epoch: 24 | Iteration: 517 | Classification loss: 0.01081 | Regression loss: 0.08043 | Running loss: 0.17155\n",
      "Epoch: 24 | Iteration: 518 | Classification loss: 0.05503 | Regression loss: 0.19943 | Running loss: 0.17175\n",
      "Epoch: 24 | Iteration: 519 | Classification loss: 0.02090 | Regression loss: 0.12615 | Running loss: 0.17145\n",
      "Epoch: 24 | Iteration: 520 | Classification loss: 0.02831 | Regression loss: 0.15225 | Running loss: 0.17167\n",
      "Epoch: 24 | Iteration: 521 | Classification loss: 0.06321 | Regression loss: 0.15849 | Running loss: 0.17177\n",
      "Epoch: 24 | Iteration: 522 | Classification loss: 0.00329 | Regression loss: 0.08943 | Running loss: 0.17144\n",
      "Epoch: 24 | Iteration: 523 | Classification loss: 0.02690 | Regression loss: 0.22055 | Running loss: 0.17177\n",
      "Epoch: 24 | Iteration: 524 | Classification loss: 0.03165 | Regression loss: 0.21313 | Running loss: 0.17194\n",
      "Epoch: 24 | Iteration: 525 | Classification loss: 0.01345 | Regression loss: 0.08015 | Running loss: 0.17163\n",
      "Epoch: 24 | Iteration: 526 | Classification loss: 0.01824 | Regression loss: 0.14313 | Running loss: 0.17162\n",
      "Epoch: 24 | Iteration: 527 | Classification loss: 0.00884 | Regression loss: 0.10851 | Running loss: 0.17160\n",
      "Epoch: 24 | Iteration: 528 | Classification loss: 0.00583 | Regression loss: 0.07909 | Running loss: 0.17144\n",
      "Epoch: 24 | Iteration: 529 | Classification loss: 0.01245 | Regression loss: 0.09772 | Running loss: 0.17132\n",
      "Epoch: 24 | Iteration: 530 | Classification loss: 0.03476 | Regression loss: 0.14554 | Running loss: 0.17143\n",
      "Epoch: 24 | Iteration: 531 | Classification loss: 0.01142 | Regression loss: 0.07252 | Running loss: 0.17095\n",
      "Epoch: 24 | Iteration: 532 | Classification loss: 0.01188 | Regression loss: 0.12313 | Running loss: 0.17073\n",
      "Epoch: 24 | Iteration: 533 | Classification loss: 0.00763 | Regression loss: 0.17492 | Running loss: 0.17068\n",
      "Epoch: 24 | Iteration: 534 | Classification loss: 0.01020 | Regression loss: 0.14476 | Running loss: 0.17073\n",
      "Epoch: 24 | Iteration: 535 | Classification loss: 0.00383 | Regression loss: 0.12947 | Running loss: 0.17074\n",
      "Epoch: 24 | Iteration: 536 | Classification loss: 0.01233 | Regression loss: 0.14037 | Running loss: 0.17021\n",
      "Epoch: 24 | Iteration: 537 | Classification loss: 0.00257 | Regression loss: 0.07709 | Running loss: 0.17015\n",
      "Epoch: 24 | Iteration: 538 | Classification loss: 0.02453 | Regression loss: 0.22584 | Running loss: 0.17045\n",
      "Epoch: 24 | Iteration: 539 | Classification loss: 0.02468 | Regression loss: 0.07659 | Running loss: 0.17020\n",
      "Epoch: 24 | Iteration: 540 | Classification loss: 0.00421 | Regression loss: 0.10257 | Running loss: 0.16981\n",
      "Epoch: 24 | Iteration: 541 | Classification loss: 0.00587 | Regression loss: 0.08538 | Running loss: 0.16953\n",
      "Epoch: 24 | Iteration: 542 | Classification loss: 0.00875 | Regression loss: 0.11362 | Running loss: 0.16926\n",
      "Epoch: 24 | Iteration: 543 | Classification loss: 0.02221 | Regression loss: 0.16585 | Running loss: 0.16928\n",
      "Epoch: 24 | Iteration: 544 | Classification loss: 0.00648 | Regression loss: 0.13851 | Running loss: 0.16911\n",
      "Epoch: 24 | Iteration: 545 | Classification loss: 0.00699 | Regression loss: 0.08001 | Running loss: 0.16881\n",
      "Epoch: 24 | Iteration: 546 | Classification loss: 0.01913 | Regression loss: 0.08317 | Running loss: 0.16869\n",
      "Epoch: 24 | Iteration: 547 | Classification loss: 0.02280 | Regression loss: 0.10950 | Running loss: 0.16869\n",
      "Epoch: 24 | Iteration: 548 | Classification loss: 0.02055 | Regression loss: 0.22360 | Running loss: 0.16901\n",
      "Epoch: 24 | Iteration: 549 | Classification loss: 0.00473 | Regression loss: 0.17292 | Running loss: 0.16914\n",
      "Epoch: 24 | Iteration: 550 | Classification loss: 0.02542 | Regression loss: 0.18424 | Running loss: 0.16899\n",
      "Epoch: 24 | Iteration: 551 | Classification loss: 0.01847 | Regression loss: 0.13602 | Running loss: 0.16907\n",
      "Epoch: 24 | Iteration: 552 | Classification loss: 0.01636 | Regression loss: 0.11497 | Running loss: 0.16899\n",
      "Epoch: 24 | Iteration: 553 | Classification loss: 0.03498 | Regression loss: 0.18171 | Running loss: 0.16929\n",
      "Epoch: 24 | Iteration: 554 | Classification loss: 0.00486 | Regression loss: 0.09764 | Running loss: 0.16917\n",
      "Epoch: 24 | Iteration: 555 | Classification loss: 0.02364 | Regression loss: 0.17287 | Running loss: 0.16929\n",
      "Epoch: 24 | Iteration: 556 | Classification loss: 0.00883 | Regression loss: 0.11609 | Running loss: 0.16924\n",
      "Epoch: 24 | Iteration: 557 | Classification loss: 0.00647 | Regression loss: 0.09481 | Running loss: 0.16919\n",
      "Epoch: 24 | Iteration: 558 | Classification loss: 0.00445 | Regression loss: 0.17527 | Running loss: 0.16931\n",
      "Epoch: 24 | Iteration: 559 | Classification loss: 0.00165 | Regression loss: 0.05668 | Running loss: 0.16930\n",
      "Epoch: 24 | Iteration: 560 | Classification loss: 0.00811 | Regression loss: 0.07646 | Running loss: 0.16900\n",
      "Epoch: 24 | Iteration: 561 | Classification loss: 0.05259 | Regression loss: 0.26664 | Running loss: 0.16927\n",
      "Epoch: 24 | Iteration: 562 | Classification loss: 0.00359 | Regression loss: 0.07983 | Running loss: 0.16927\n",
      "Epoch: 24 | Iteration: 563 | Classification loss: 0.00722 | Regression loss: 0.08709 | Running loss: 0.16900\n",
      "Epoch: 24 | Iteration: 564 | Classification loss: 0.02028 | Regression loss: 0.10451 | Running loss: 0.16907\n",
      "Epoch: 24 | Iteration: 565 | Classification loss: 0.00569 | Regression loss: 0.11565 | Running loss: 0.16895\n",
      "Epoch: 24 | Iteration: 566 | Classification loss: 0.06429 | Regression loss: 0.19604 | Running loss: 0.16926\n",
      "Epoch: 24 | Iteration: 567 | Classification loss: 0.04851 | Regression loss: 0.13982 | Running loss: 0.16930\n",
      "Epoch: 24 | Iteration: 568 | Classification loss: 0.02371 | Regression loss: 0.15195 | Running loss: 0.16932\n",
      "Epoch: 24 | Iteration: 569 | Classification loss: 0.00938 | Regression loss: 0.07385 | Running loss: 0.16920\n",
      "Epoch: 24 | Iteration: 570 | Classification loss: 0.03119 | Regression loss: 0.12825 | Running loss: 0.16893\n",
      "Epoch: 24 | Iteration: 571 | Classification loss: 0.01800 | Regression loss: 0.08634 | Running loss: 0.16887\n",
      "Epoch: 24 | Iteration: 572 | Classification loss: 0.01434 | Regression loss: 0.08054 | Running loss: 0.16881\n",
      "Epoch: 24 | Iteration: 573 | Classification loss: 0.01088 | Regression loss: 0.06439 | Running loss: 0.16880\n",
      "Epoch: 24 | Iteration: 574 | Classification loss: 0.00826 | Regression loss: 0.12077 | Running loss: 0.16877\n",
      "Epoch: 24 | Iteration: 575 | Classification loss: 0.01308 | Regression loss: 0.18482 | Running loss: 0.16879\n",
      "Epoch: 24 | Iteration: 576 | Classification loss: 0.00745 | Regression loss: 0.21310 | Running loss: 0.16890\n",
      "Epoch: 24 | Iteration: 577 | Classification loss: 0.00729 | Regression loss: 0.09120 | Running loss: 0.16855\n",
      "Epoch: 24 | Iteration: 578 | Classification loss: 0.00928 | Regression loss: 0.15023 | Running loss: 0.16859\n",
      "Epoch: 24 | Iteration: 579 | Classification loss: 0.00971 | Regression loss: 0.08576 | Running loss: 0.16839\n",
      "Epoch: 24 | Iteration: 580 | Classification loss: 0.01549 | Regression loss: 0.09030 | Running loss: 0.16843\n",
      "Epoch: 24 | Iteration: 581 | Classification loss: 0.01159 | Regression loss: 0.20607 | Running loss: 0.16852\n",
      "Epoch: 24 | Iteration: 582 | Classification loss: 0.06203 | Regression loss: 0.20547 | Running loss: 0.16888\n",
      "Epoch: 24 | Iteration: 583 | Classification loss: 0.01544 | Regression loss: 0.22197 | Running loss: 0.16925\n",
      "Epoch: 24 | Iteration: 584 | Classification loss: 0.01163 | Regression loss: 0.06201 | Running loss: 0.16900\n",
      "Epoch: 24 | Iteration: 585 | Classification loss: 0.01370 | Regression loss: 0.13413 | Running loss: 0.16893\n",
      "Epoch: 24 | Iteration: 586 | Classification loss: 0.00894 | Regression loss: 0.09512 | Running loss: 0.16855\n",
      "Epoch: 24 | Iteration: 587 | Classification loss: 0.01247 | Regression loss: 0.13195 | Running loss: 0.16843\n",
      "Epoch: 24 | Iteration: 588 | Classification loss: 0.01172 | Regression loss: 0.12645 | Running loss: 0.16818\n",
      "Epoch: 24 | Iteration: 589 | Classification loss: 0.01124 | Regression loss: 0.16728 | Running loss: 0.16830\n",
      "Epoch: 24 | Iteration: 590 | Classification loss: 0.00805 | Regression loss: 0.16220 | Running loss: 0.16834\n",
      "Epoch: 24 | Iteration: 591 | Classification loss: 0.02543 | Regression loss: 0.11014 | Running loss: 0.16827\n",
      "Epoch: 24 | Iteration: 592 | Classification loss: 0.01128 | Regression loss: 0.08524 | Running loss: 0.16802\n",
      "Epoch: 24 | Iteration: 593 | Classification loss: 0.01899 | Regression loss: 0.15346 | Running loss: 0.16814\n",
      "Epoch: 24 | Iteration: 594 | Classification loss: 0.00436 | Regression loss: 0.11065 | Running loss: 0.16798\n",
      "Epoch: 24 | Iteration: 595 | Classification loss: 0.06096 | Regression loss: 0.26778 | Running loss: 0.16826\n",
      "Epoch: 24 | Iteration: 596 | Classification loss: 0.00709 | Regression loss: 0.08603 | Running loss: 0.16809\n",
      "Epoch: 24 | Iteration: 597 | Classification loss: 0.01407 | Regression loss: 0.07140 | Running loss: 0.16803\n",
      "Epoch: 24 | Iteration: 598 | Classification loss: 0.01856 | Regression loss: 0.22186 | Running loss: 0.16815\n",
      "Epoch: 24 | Iteration: 599 | Classification loss: 0.00328 | Regression loss: 0.08081 | Running loss: 0.16808\n",
      "Epoch: 24 | Iteration: 600 | Classification loss: 0.02033 | Regression loss: 0.12336 | Running loss: 0.16800\n",
      "Epoch: 24 | Iteration: 601 | Classification loss: 0.00643 | Regression loss: 0.09840 | Running loss: 0.16793\n",
      "Epoch: 24 | Iteration: 602 | Classification loss: 0.01653 | Regression loss: 0.16274 | Running loss: 0.16760\n",
      "Epoch: 24 | Iteration: 603 | Classification loss: 0.01771 | Regression loss: 0.23265 | Running loss: 0.16778\n",
      "Epoch: 24 | Iteration: 604 | Classification loss: 0.00890 | Regression loss: 0.09458 | Running loss: 0.16767\n",
      "Epoch: 24 | Iteration: 605 | Classification loss: 0.05496 | Regression loss: 0.27379 | Running loss: 0.16781\n",
      "Epoch: 24 | Iteration: 606 | Classification loss: 0.00752 | Regression loss: 0.14726 | Running loss: 0.16788\n",
      "Epoch: 24 | Iteration: 607 | Classification loss: 0.01519 | Regression loss: 0.22923 | Running loss: 0.16819\n",
      "Epoch: 24 | Iteration: 608 | Classification loss: 0.02528 | Regression loss: 0.13803 | Running loss: 0.16808\n",
      "Epoch: 24 | Iteration: 609 | Classification loss: 0.00619 | Regression loss: 0.12048 | Running loss: 0.16775\n",
      "Epoch: 24 | Iteration: 610 | Classification loss: 0.03205 | Regression loss: 0.17880 | Running loss: 0.16791\n",
      "Epoch: 24 | Iteration: 611 | Classification loss: 0.00931 | Regression loss: 0.08801 | Running loss: 0.16780\n",
      "Epoch: 24 | Iteration: 612 | Classification loss: 0.00671 | Regression loss: 0.09799 | Running loss: 0.16755\n",
      "Epoch: 24 | Iteration: 613 | Classification loss: 0.04906 | Regression loss: 0.21554 | Running loss: 0.16768\n",
      "Epoch: 24 | Iteration: 614 | Classification loss: 0.03601 | Regression loss: 0.19021 | Running loss: 0.16720\n",
      "Epoch: 24 | Iteration: 615 | Classification loss: 0.04793 | Regression loss: 0.18167 | Running loss: 0.16753\n",
      "Epoch: 24 | Iteration: 616 | Classification loss: 0.03588 | Regression loss: 0.29841 | Running loss: 0.16797\n",
      "Epoch: 24 | Iteration: 617 | Classification loss: 0.02494 | Regression loss: 0.17018 | Running loss: 0.16816\n",
      "Epoch: 24 | Iteration: 618 | Classification loss: 0.01103 | Regression loss: 0.08715 | Running loss: 0.16771\n",
      "Epoch: 24 | Iteration: 619 | Classification loss: 0.02308 | Regression loss: 0.21411 | Running loss: 0.16733\n",
      "Epoch: 24 | Iteration: 620 | Classification loss: 0.01766 | Regression loss: 0.13639 | Running loss: 0.16737\n",
      "Epoch: 24 | Iteration: 621 | Classification loss: 0.00968 | Regression loss: 0.12336 | Running loss: 0.16730\n",
      "Epoch: 24 | Iteration: 622 | Classification loss: 0.00160 | Regression loss: 0.07338 | Running loss: 0.16720\n",
      "Epoch: 24 | Iteration: 623 | Classification loss: 0.05551 | Regression loss: 0.20411 | Running loss: 0.16732\n",
      "Epoch: 24 | Iteration: 624 | Classification loss: 0.02586 | Regression loss: 0.16493 | Running loss: 0.16752\n",
      "Epoch: 24 | Iteration: 625 | Classification loss: 0.00582 | Regression loss: 0.11471 | Running loss: 0.16742\n",
      "Epoch: 24 | Iteration: 626 | Classification loss: 0.01566 | Regression loss: 0.14636 | Running loss: 0.16750\n",
      "Epoch: 24 | Iteration: 627 | Classification loss: 0.01462 | Regression loss: 0.12065 | Running loss: 0.16760\n",
      "Epoch: 24 | Iteration: 628 | Classification loss: 0.05707 | Regression loss: 0.24644 | Running loss: 0.16750\n",
      "Epoch: 24 | Iteration: 629 | Classification loss: 0.01241 | Regression loss: 0.10545 | Running loss: 0.16738\n",
      "Epoch: 24 | Iteration: 630 | Classification loss: 0.00708 | Regression loss: 0.13466 | Running loss: 0.16690\n",
      "Epoch: 24 | Iteration: 631 | Classification loss: 0.01304 | Regression loss: 0.16992 | Running loss: 0.16727\n",
      "Epoch: 24 | Iteration: 632 | Classification loss: 0.02532 | Regression loss: 0.32384 | Running loss: 0.16748\n",
      "Epoch: 24 | Iteration: 633 | Classification loss: 0.00926 | Regression loss: 0.08300 | Running loss: 0.16752\n",
      "Epoch: 24 | Iteration: 634 | Classification loss: 0.02292 | Regression loss: 0.17030 | Running loss: 0.16752\n",
      "Epoch: 24 | Iteration: 635 | Classification loss: 0.00429 | Regression loss: 0.10893 | Running loss: 0.16717\n",
      "Epoch: 24 | Iteration: 636 | Classification loss: 0.00741 | Regression loss: 0.07307 | Running loss: 0.16722\n",
      "Epoch: 24 | Iteration: 637 | Classification loss: 0.00729 | Regression loss: 0.04172 | Running loss: 0.16706\n",
      "Epoch: 24 | Iteration: 638 | Classification loss: 0.04213 | Regression loss: 0.17372 | Running loss: 0.16725\n",
      "Epoch: 24 | Iteration: 639 | Classification loss: 0.00752 | Regression loss: 0.06362 | Running loss: 0.16684\n",
      "Epoch: 24 | Iteration: 640 | Classification loss: 0.00444 | Regression loss: 0.08152 | Running loss: 0.16670\n",
      "Epoch: 24 | Iteration: 641 | Classification loss: 0.00729 | Regression loss: 0.12398 | Running loss: 0.16654\n",
      "Epoch: 24 | Iteration: 642 | Classification loss: 0.01723 | Regression loss: 0.17142 | Running loss: 0.16656\n",
      "Epoch: 24 | Iteration: 643 | Classification loss: 0.00146 | Regression loss: 0.10040 | Running loss: 0.16628\n",
      "Epoch: 24 | Iteration: 644 | Classification loss: 0.03057 | Regression loss: 0.23413 | Running loss: 0.16634\n",
      "Epoch: 24 | Iteration: 645 | Classification loss: 0.00871 | Regression loss: 0.08997 | Running loss: 0.16608\n",
      "Epoch: 24 | Iteration: 646 | Classification loss: 0.00764 | Regression loss: 0.06817 | Running loss: 0.16604\n",
      "Epoch: 24 | Iteration: 647 | Classification loss: 0.02108 | Regression loss: 0.16573 | Running loss: 0.16625\n",
      "Epoch: 24 | Iteration: 648 | Classification loss: 0.03875 | Regression loss: 0.16995 | Running loss: 0.16628\n",
      "Epoch: 24 | Iteration: 649 | Classification loss: 0.00781 | Regression loss: 0.10037 | Running loss: 0.16595\n",
      "Epoch: 24 | Iteration: 650 | Classification loss: 0.00367 | Regression loss: 0.08817 | Running loss: 0.16599\n",
      "Epoch: 24 | Iteration: 651 | Classification loss: 0.01235 | Regression loss: 0.10800 | Running loss: 0.16588\n",
      "Epoch: 24 | Iteration: 652 | Classification loss: 0.03360 | Regression loss: 0.21776 | Running loss: 0.16602\n",
      "Epoch: 24 | Iteration: 653 | Classification loss: 0.00707 | Regression loss: 0.10576 | Running loss: 0.16606\n",
      "Epoch: 24 | Iteration: 654 | Classification loss: 0.12001 | Regression loss: 0.29863 | Running loss: 0.16642\n",
      "Epoch: 24 | Iteration: 655 | Classification loss: 0.00852 | Regression loss: 0.10981 | Running loss: 0.16653\n",
      "Epoch: 24 | Iteration: 656 | Classification loss: 0.00651 | Regression loss: 0.11945 | Running loss: 0.16653\n",
      "Epoch: 24 | Iteration: 657 | Classification loss: 0.00891 | Regression loss: 0.20580 | Running loss: 0.16669\n",
      "Epoch: 24 | Iteration: 658 | Classification loss: 0.01637 | Regression loss: 0.13029 | Running loss: 0.16678\n",
      "Epoch: 24 | Iteration: 659 | Classification loss: 0.12586 | Regression loss: 0.24670 | Running loss: 0.16721\n",
      "Epoch: 24 | Iteration: 660 | Classification loss: 0.00925 | Regression loss: 0.15650 | Running loss: 0.16727\n",
      "Epoch: 24 | Iteration: 661 | Classification loss: 0.10007 | Regression loss: 0.24954 | Running loss: 0.16759\n",
      "Epoch: 24 | Iteration: 662 | Classification loss: 0.00984 | Regression loss: 0.09076 | Running loss: 0.16738\n",
      "Epoch: 24 | Iteration: 663 | Classification loss: 0.02506 | Regression loss: 0.16715 | Running loss: 0.16755\n",
      "Epoch: 24 | Iteration: 664 | Classification loss: 0.01531 | Regression loss: 0.16831 | Running loss: 0.16773\n",
      "Epoch: 24 | Iteration: 665 | Classification loss: 0.01651 | Regression loss: 0.13950 | Running loss: 0.16737\n",
      "Epoch: 24 | Iteration: 666 | Classification loss: 0.00687 | Regression loss: 0.05223 | Running loss: 0.16725\n",
      "Epoch: 24 | Iteration: 667 | Classification loss: 0.03777 | Regression loss: 0.10730 | Running loss: 0.16709\n",
      "Epoch: 24 | Iteration: 668 | Classification loss: 0.02161 | Regression loss: 0.22027 | Running loss: 0.16731\n",
      "Epoch: 24 | Iteration: 669 | Classification loss: 0.00342 | Regression loss: 0.13051 | Running loss: 0.16724\n",
      "Epoch: 24 | Iteration: 670 | Classification loss: 0.00310 | Regression loss: 0.06207 | Running loss: 0.16683\n",
      "Epoch: 24 | Iteration: 671 | Classification loss: 0.01336 | Regression loss: 0.04121 | Running loss: 0.16653\n",
      "Epoch: 24 | Iteration: 672 | Classification loss: 0.03042 | Regression loss: 0.15008 | Running loss: 0.16664\n",
      "Epoch: 24 | Iteration: 673 | Classification loss: 0.00766 | Regression loss: 0.16292 | Running loss: 0.16683\n",
      "Epoch: 24 | Iteration: 674 | Classification loss: 0.00267 | Regression loss: 0.05202 | Running loss: 0.16678\n",
      "Epoch: 24 | Iteration: 675 | Classification loss: 0.01628 | Regression loss: 0.08748 | Running loss: 0.16672\n",
      "Epoch: 24 | Iteration: 676 | Classification loss: 0.01460 | Regression loss: 0.14721 | Running loss: 0.16682\n",
      "Epoch: 24 | Iteration: 677 | Classification loss: 0.01490 | Regression loss: 0.11825 | Running loss: 0.16655\n",
      "Epoch: 24 | Iteration: 678 | Classification loss: 0.00857 | Regression loss: 0.09465 | Running loss: 0.16651\n",
      "Epoch: 24 | Iteration: 679 | Classification loss: 0.01262 | Regression loss: 0.09891 | Running loss: 0.16657\n",
      "Epoch: 24 | Iteration: 680 | Classification loss: 0.01152 | Regression loss: 0.10358 | Running loss: 0.16667\n",
      "Epoch: 24 | Iteration: 681 | Classification loss: 0.03396 | Regression loss: 0.23195 | Running loss: 0.16693\n",
      "Epoch: 24 | Iteration: 682 | Classification loss: 0.00922 | Regression loss: 0.09887 | Running loss: 0.16686\n",
      "Epoch: 24 | Iteration: 683 | Classification loss: 0.00749 | Regression loss: 0.11420 | Running loss: 0.16693\n",
      "Epoch: 24 | Iteration: 684 | Classification loss: 0.02787 | Regression loss: 0.16725 | Running loss: 0.16713\n",
      "Epoch: 24 | Iteration: 685 | Classification loss: 0.00801 | Regression loss: 0.11314 | Running loss: 0.16717\n",
      "Epoch: 24 | Iteration: 686 | Classification loss: 0.01650 | Regression loss: 0.15765 | Running loss: 0.16732\n",
      "Epoch: 24 | Iteration: 687 | Classification loss: 0.01125 | Regression loss: 0.15985 | Running loss: 0.16735\n",
      "Epoch: 24 | Iteration: 688 | Classification loss: 0.02073 | Regression loss: 0.12242 | Running loss: 0.16744\n",
      "Epoch: 24 | Iteration: 689 | Classification loss: 0.00721 | Regression loss: 0.12273 | Running loss: 0.16721\n",
      "Epoch: 24 | Iteration: 690 | Classification loss: 0.01081 | Regression loss: 0.15392 | Running loss: 0.16728\n",
      "Epoch: 24 | Iteration: 691 | Classification loss: 0.01445 | Regression loss: 0.19861 | Running loss: 0.16755\n",
      "Epoch: 24 | Iteration: 692 | Classification loss: 0.00245 | Regression loss: 0.08332 | Running loss: 0.16744\n",
      "Epoch: 24 | Iteration: 693 | Classification loss: 0.03094 | Regression loss: 0.12232 | Running loss: 0.16733\n",
      "Epoch: 24 | Iteration: 694 | Classification loss: 0.02064 | Regression loss: 0.07138 | Running loss: 0.16691\n",
      "Epoch: 24 | Iteration: 695 | Classification loss: 0.00714 | Regression loss: 0.05163 | Running loss: 0.16679\n",
      "Epoch: 24 | Iteration: 696 | Classification loss: 0.00776 | Regression loss: 0.09217 | Running loss: 0.16678\n",
      "Epoch: 24 | Iteration: 697 | Classification loss: 0.01996 | Regression loss: 0.11103 | Running loss: 0.16689\n",
      "Epoch: 24 | Iteration: 698 | Classification loss: 0.01524 | Regression loss: 0.07888 | Running loss: 0.16662\n",
      "Epoch: 24 | Iteration: 699 | Classification loss: 0.00906 | Regression loss: 0.12090 | Running loss: 0.16669\n",
      "Epoch: 24 | Iteration: 700 | Classification loss: 0.01960 | Regression loss: 0.23220 | Running loss: 0.16692\n",
      "Epoch: 24 | Iteration: 701 | Classification loss: 0.00663 | Regression loss: 0.11369 | Running loss: 0.16699\n",
      "Epoch: 24 | Iteration: 702 | Classification loss: 0.01293 | Regression loss: 0.14027 | Running loss: 0.16709\n",
      "Epoch: 24 | Iteration: 703 | Classification loss: 0.00824 | Regression loss: 0.14836 | Running loss: 0.16719\n",
      "Epoch: 24 | Iteration: 704 | Classification loss: 0.01569 | Regression loss: 0.16656 | Running loss: 0.16716\n",
      "Epoch: 24 | Iteration: 705 | Classification loss: 0.00310 | Regression loss: 0.13047 | Running loss: 0.16681\n",
      "Epoch: 24 | Iteration: 706 | Classification loss: 0.01709 | Regression loss: 0.13405 | Running loss: 0.16682\n",
      "Epoch: 24 | Iteration: 707 | Classification loss: 0.03891 | Regression loss: 0.21974 | Running loss: 0.16708\n",
      "Epoch: 24 | Iteration: 708 | Classification loss: 0.00425 | Regression loss: 0.04627 | Running loss: 0.16699\n",
      "Epoch: 24 | Iteration: 709 | Classification loss: 0.00344 | Regression loss: 0.06614 | Running loss: 0.16674\n",
      "Epoch: 24 | Iteration: 710 | Classification loss: 0.02601 | Regression loss: 0.11093 | Running loss: 0.16683\n",
      "Epoch: 24 | Iteration: 711 | Classification loss: 0.02326 | Regression loss: 0.15222 | Running loss: 0.16671\n",
      "Epoch: 24 | Iteration: 712 | Classification loss: 0.05245 | Regression loss: 0.28963 | Running loss: 0.16698\n",
      "Epoch: 24 | Iteration: 713 | Classification loss: 0.05781 | Regression loss: 0.13344 | Running loss: 0.16698\n",
      "Epoch: 24 | Iteration: 714 | Classification loss: 0.01405 | Regression loss: 0.20914 | Running loss: 0.16670\n",
      "Epoch: 24 | Iteration: 715 | Classification loss: 0.03687 | Regression loss: 0.13393 | Running loss: 0.16684\n",
      "Epoch: 24 | Iteration: 716 | Classification loss: 0.01038 | Regression loss: 0.10661 | Running loss: 0.16663\n",
      "Epoch: 24 | Iteration: 717 | Classification loss: 0.00572 | Regression loss: 0.17707 | Running loss: 0.16657\n",
      "Epoch: 24 | Iteration: 718 | Classification loss: 0.01102 | Regression loss: 0.09087 | Running loss: 0.16657\n",
      "Epoch: 24 | Iteration: 719 | Classification loss: 0.01681 | Regression loss: 0.18217 | Running loss: 0.16675\n",
      "Epoch: 24 | Iteration: 720 | Classification loss: 0.00782 | Regression loss: 0.09619 | Running loss: 0.16678\n",
      "Epoch: 24 | Iteration: 721 | Classification loss: 0.00517 | Regression loss: 0.06012 | Running loss: 0.16653\n",
      "Epoch: 24 | Iteration: 722 | Classification loss: 0.03621 | Regression loss: 0.13651 | Running loss: 0.16660\n",
      "Epoch: 24 | Iteration: 723 | Classification loss: 0.00634 | Regression loss: 0.14941 | Running loss: 0.16675\n",
      "Epoch: 24 | Iteration: 724 | Classification loss: 0.04104 | Regression loss: 0.16300 | Running loss: 0.16700\n",
      "Epoch: 24 | Iteration: 725 | Classification loss: 0.00720 | Regression loss: 0.05587 | Running loss: 0.16702\n",
      "Epoch: 24 | Iteration: 726 | Classification loss: 0.01951 | Regression loss: 0.12083 | Running loss: 0.16708\n",
      "Epoch: 24 | Iteration: 727 | Classification loss: 0.02565 | Regression loss: 0.08693 | Running loss: 0.16714\n",
      "Epoch: 24 | Iteration: 728 | Classification loss: 0.07055 | Regression loss: 0.31699 | Running loss: 0.16761\n",
      "Epoch: 24 | Iteration: 729 | Classification loss: 0.01039 | Regression loss: 0.16717 | Running loss: 0.16766\n",
      "Epoch: 24 | Iteration: 730 | Classification loss: 0.00574 | Regression loss: 0.10947 | Running loss: 0.16742\n",
      "Epoch: 24 | Iteration: 731 | Classification loss: 0.04619 | Regression loss: 0.27810 | Running loss: 0.16780\n",
      "Epoch: 24 | Iteration: 732 | Classification loss: 0.00597 | Regression loss: 0.03790 | Running loss: 0.16762\n",
      "Epoch: 24 | Iteration: 733 | Classification loss: 0.01391 | Regression loss: 0.14825 | Running loss: 0.16777\n",
      "Epoch: 24 | Iteration: 734 | Classification loss: 0.01391 | Regression loss: 0.11033 | Running loss: 0.16743\n",
      "Epoch: 24 | Iteration: 735 | Classification loss: 0.00432 | Regression loss: 0.06682 | Running loss: 0.16724\n",
      "Epoch: 24 | Iteration: 736 | Classification loss: 0.00319 | Regression loss: 0.14922 | Running loss: 0.16723\n",
      "Epoch: 24 | Iteration: 737 | Classification loss: 0.00001 | Regression loss: 0.00000 | Running loss: 0.16702\n",
      "Epoch: 24 | Iteration: 738 | Classification loss: 0.00339 | Regression loss: 0.05023 | Running loss: 0.16692\n",
      "Epoch: 24 | Iteration: 739 | Classification loss: 0.02446 | Regression loss: 0.08903 | Running loss: 0.16686\n",
      "Epoch: 24 | Iteration: 740 | Classification loss: 0.01679 | Regression loss: 0.17218 | Running loss: 0.16677\n",
      "Epoch: 24 | Iteration: 741 | Classification loss: 0.06371 | Regression loss: 0.28026 | Running loss: 0.16705\n",
      "Epoch: 24 | Iteration: 742 | Classification loss: 0.02824 | Regression loss: 0.19111 | Running loss: 0.16723\n",
      "Epoch: 24 | Iteration: 743 | Classification loss: 0.03128 | Regression loss: 0.21227 | Running loss: 0.16737\n",
      "Epoch: 24 | Iteration: 744 | Classification loss: 0.04627 | Regression loss: 0.09979 | Running loss: 0.16744\n",
      "Epoch: 24 | Iteration: 745 | Classification loss: 0.12793 | Regression loss: 0.33391 | Running loss: 0.16807\n",
      "Epoch: 24 | Iteration: 746 | Classification loss: 0.00673 | Regression loss: 0.14939 | Running loss: 0.16812\n",
      "Epoch: 24 | Iteration: 747 | Classification loss: 0.04488 | Regression loss: 0.10689 | Running loss: 0.16814\n",
      "Epoch: 24 | Iteration: 748 | Classification loss: 0.01681 | Regression loss: 0.19194 | Running loss: 0.16843\n",
      "Epoch: 24 | Iteration: 749 | Classification loss: 0.01620 | Regression loss: 0.13532 | Running loss: 0.16852\n",
      "Epoch: 24 | Iteration: 750 | Classification loss: 0.01715 | Regression loss: 0.25042 | Running loss: 0.16887\n",
      "Epoch: 24 | Iteration: 751 | Classification loss: 0.01746 | Regression loss: 0.11291 | Running loss: 0.16864\n",
      "Epoch: 24 | Iteration: 752 | Classification loss: 0.02199 | Regression loss: 0.13775 | Running loss: 0.16774\n",
      "Epoch: 24 | Iteration: 753 | Classification loss: 0.01535 | Regression loss: 0.09886 | Running loss: 0.16641\n",
      "Epoch: 24 | Iteration: 754 | Classification loss: 0.07183 | Regression loss: 0.15343 | Running loss: 0.16638\n",
      "Epoch: 24 | Iteration: 755 | Classification loss: 0.03074 | Regression loss: 0.22738 | Running loss: 0.16668\n",
      "Epoch: 24 | Iteration: 756 | Classification loss: 0.01497 | Regression loss: 0.18466 | Running loss: 0.16644\n",
      "Epoch: 24 | Iteration: 757 | Classification loss: 0.03506 | Regression loss: 0.23185 | Running loss: 0.16678\n",
      "Epoch: 24 | Iteration: 758 | Classification loss: 0.01030 | Regression loss: 0.13387 | Running loss: 0.16684\n",
      "Epoch: 24 | Iteration: 759 | Classification loss: 0.01865 | Regression loss: 0.12927 | Running loss: 0.16687\n",
      "Epoch: 24 | Iteration: 760 | Classification loss: 0.04189 | Regression loss: 0.13776 | Running loss: 0.16696\n",
      "Epoch: 24 | Iteration: 761 | Classification loss: 0.01305 | Regression loss: 0.10195 | Running loss: 0.16684\n",
      "Epoch: 24 | Iteration: 762 | Classification loss: 0.00459 | Regression loss: 0.12019 | Running loss: 0.16668\n",
      "Epoch: 24 | Iteration: 763 | Classification loss: 0.01096 | Regression loss: 0.12633 | Running loss: 0.16673\n",
      "Epoch: 24 | Iteration: 764 | Classification loss: 0.03738 | Regression loss: 0.15858 | Running loss: 0.16665\n",
      "Epoch: 24 | Iteration: 765 | Classification loss: 0.07980 | Regression loss: 0.30229 | Running loss: 0.16698\n",
      "Epoch: 24 | Iteration: 766 | Classification loss: 0.01304 | Regression loss: 0.21245 | Running loss: 0.16721\n",
      "Epoch: 24 | Iteration: 767 | Classification loss: 0.03066 | Regression loss: 0.14988 | Running loss: 0.16740\n",
      "Epoch: 24 | Iteration: 768 | Classification loss: 0.01052 | Regression loss: 0.12510 | Running loss: 0.16734\n",
      "Epoch: 24 | Iteration: 769 | Classification loss: 0.03992 | Regression loss: 0.15476 | Running loss: 0.16754\n",
      "Epoch: 24 | Iteration: 770 | Classification loss: 0.05119 | Regression loss: 0.19063 | Running loss: 0.16772\n",
      "Epoch: 24 | Iteration: 771 | Classification loss: 0.01812 | Regression loss: 0.14569 | Running loss: 0.16790\n",
      "Epoch: 24 | Iteration: 772 | Classification loss: 0.00780 | Regression loss: 0.11628 | Running loss: 0.16789\n",
      "Epoch: 24 | Iteration: 773 | Classification loss: 0.06018 | Regression loss: 0.21418 | Running loss: 0.16822\n",
      "Epoch: 24 | Iteration: 774 | Classification loss: 0.00503 | Regression loss: 0.12597 | Running loss: 0.16802\n",
      "Epoch: 24 | Iteration: 775 | Classification loss: 0.03604 | Regression loss: 0.20967 | Running loss: 0.16809\n",
      "Epoch: 24 | Iteration: 776 | Classification loss: 0.01109 | Regression loss: 0.12204 | Running loss: 0.16753\n",
      "Epoch: 24 | Iteration: 777 | Classification loss: 0.01761 | Regression loss: 0.14024 | Running loss: 0.16778\n",
      "Epoch: 24 | Iteration: 778 | Classification loss: 0.03923 | Regression loss: 0.15515 | Running loss: 0.16759\n",
      "Epoch: 24 | Iteration: 779 | Classification loss: 0.00218 | Regression loss: 0.07493 | Running loss: 0.16734\n",
      "Epoch: 24 | Iteration: 780 | Classification loss: 0.13949 | Regression loss: 0.28791 | Running loss: 0.16779\n",
      "Epoch: 24 | Iteration: 781 | Classification loss: 0.00905 | Regression loss: 0.08876 | Running loss: 0.16783\n",
      "Epoch: 24 | Iteration: 782 | Classification loss: 0.01417 | Regression loss: 0.14957 | Running loss: 0.16804\n",
      "Epoch: 24 | Iteration: 783 | Classification loss: 0.01620 | Regression loss: 0.15963 | Running loss: 0.16815\n",
      "Epoch: 24 | Iteration: 784 | Classification loss: 0.01981 | Regression loss: 0.21516 | Running loss: 0.16799\n",
      "Epoch: 24 | Iteration: 785 | Classification loss: 0.00732 | Regression loss: 0.09996 | Running loss: 0.16791\n",
      "Epoch: 24 | Iteration: 786 | Classification loss: 0.01489 | Regression loss: 0.10797 | Running loss: 0.16781\n",
      "Epoch: 24 | Iteration: 787 | Classification loss: 0.05551 | Regression loss: 0.21479 | Running loss: 0.16796\n",
      "Epoch: 24 | Iteration: 788 | Classification loss: 0.01306 | Regression loss: 0.03231 | Running loss: 0.16785\n",
      "Epoch: 24 | Iteration: 789 | Classification loss: 0.01070 | Regression loss: 0.14346 | Running loss: 0.16529\n",
      "Epoch: 24 | Iteration: 790 | Classification loss: 0.01022 | Regression loss: 0.13281 | Running loss: 0.16532\n",
      "Epoch: 24 | Iteration: 791 | Classification loss: 0.01337 | Regression loss: 0.18341 | Running loss: 0.16543\n",
      "Epoch: 24 | Iteration: 792 | Classification loss: 0.03679 | Regression loss: 0.19697 | Running loss: 0.16567\n",
      "Epoch: 24 | Iteration: 793 | Classification loss: 0.01444 | Regression loss: 0.09313 | Running loss: 0.16542\n",
      "Epoch: 24 | Iteration: 794 | Classification loss: 0.01538 | Regression loss: 0.12792 | Running loss: 0.16546\n",
      "Epoch: 24 | Iteration: 795 | Classification loss: 0.04546 | Regression loss: 0.14479 | Running loss: 0.16556\n",
      "Epoch: 24 | Iteration: 796 | Classification loss: 0.01125 | Regression loss: 0.09125 | Running loss: 0.16534\n",
      "Epoch: 24 | Iteration: 797 | Classification loss: 0.02467 | Regression loss: 0.11772 | Running loss: 0.16539\n",
      "Epoch: 24 | Iteration: 798 | Classification loss: 0.08184 | Regression loss: 0.13045 | Running loss: 0.16548\n",
      "Epoch: 24 | Iteration: 799 | Classification loss: 0.29431 | Regression loss: 0.30093 | Running loss: 0.16630\n",
      "Epoch: 24 | Iteration: 800 | Classification loss: 0.01186 | Regression loss: 0.09033 | Running loss: 0.16627\n",
      "Epoch: 24 | Iteration: 801 | Classification loss: 0.00843 | Regression loss: 0.10981 | Running loss: 0.16637\n",
      "Epoch: 24 | Iteration: 802 | Classification loss: 0.01357 | Regression loss: 0.16048 | Running loss: 0.16647\n",
      "Epoch: 24 | Iteration: 803 | Classification loss: 0.05043 | Regression loss: 0.28810 | Running loss: 0.16699\n",
      "Epoch: 24 | Iteration: 804 | Classification loss: 0.04487 | Regression loss: 0.17621 | Running loss: 0.16701\n",
      "Epoch: 24 | Iteration: 805 | Classification loss: 0.01913 | Regression loss: 0.18598 | Running loss: 0.16710\n",
      "Epoch: 24 | Iteration: 806 | Classification loss: 0.01501 | Regression loss: 0.10265 | Running loss: 0.16714\n",
      "Epoch: 24 | Iteration: 807 | Classification loss: 0.03515 | Regression loss: 0.15755 | Running loss: 0.16720\n",
      "Epoch: 24 | Iteration: 808 | Classification loss: 0.02690 | Regression loss: 0.13995 | Running loss: 0.16727\n",
      "Epoch: 24 | Iteration: 809 | Classification loss: 0.00847 | Regression loss: 0.14760 | Running loss: 0.16715\n",
      "Epoch: 24 | Iteration: 810 | Classification loss: 0.07389 | Regression loss: 0.12944 | Running loss: 0.16735\n",
      "Epoch: 24 | Iteration: 811 | Classification loss: 0.05068 | Regression loss: 0.06366 | Running loss: 0.16657\n",
      "Epoch: 24 | Iteration: 812 | Classification loss: 0.01218 | Regression loss: 0.11278 | Running loss: 0.16661\n",
      "Epoch: 24 | Iteration: 813 | Classification loss: 0.01578 | Regression loss: 0.12146 | Running loss: 0.16617\n",
      "Epoch: 24 | Iteration: 814 | Classification loss: 0.02591 | Regression loss: 0.15279 | Running loss: 0.16629\n",
      "Epoch: 24 | Iteration: 815 | Classification loss: 0.01805 | Regression loss: 0.09296 | Running loss: 0.16618\n",
      "Epoch: 24 | Iteration: 816 | Classification loss: 0.02358 | Regression loss: 0.13308 | Running loss: 0.16588\n",
      "Epoch: 24 | Iteration: 817 | Classification loss: 0.02132 | Regression loss: 0.12974 | Running loss: 0.16588\n",
      "Evaluating dataset\n",
      "0/445\n",
      "1/445\n",
      "2/445\n",
      "3/445\n",
      "4/445\n",
      "5/445\n",
      "6/445\n",
      "7/445\n",
      "8/445\n",
      "9/445\n",
      "10/445\n",
      "11/445\n",
      "12/445\n",
      "13/445\n",
      "14/445\n",
      "15/445\n",
      "16/445\n",
      "17/445\n",
      "18/445\n",
      "19/445\n",
      "20/445\n",
      "21/445\n",
      "22/445\n",
      "23/445\n",
      "24/445\n",
      "25/445\n",
      "26/445\n",
      "27/445\n",
      "28/445\n",
      "29/445\n",
      "30/445\n",
      "31/445\n",
      "32/445\n",
      "33/445\n",
      "34/445\n",
      "35/445\n",
      "36/445\n",
      "37/445\n",
      "38/445\n",
      "39/445\n",
      "40/445\n",
      "41/445\n",
      "42/445\n",
      "43/445\n",
      "44/445\n",
      "45/445\n",
      "46/445\n",
      "47/445\n",
      "48/445\n",
      "49/445\n",
      "50/445\n",
      "51/445\n",
      "52/445\n",
      "53/445\n",
      "54/445\n",
      "55/445\n",
      "56/445\n",
      "57/445\n",
      "58/445\n",
      "59/445\n",
      "60/445\n",
      "61/445\n",
      "62/445\n",
      "63/445\n",
      "64/445\n",
      "65/445\n",
      "66/445\n",
      "67/445\n",
      "68/445\n",
      "69/445\n",
      "70/445\n",
      "71/445\n",
      "72/445\n",
      "73/445\n",
      "74/445\n",
      "75/445\n",
      "76/445\n",
      "77/445\n",
      "78/445\n",
      "79/445\n",
      "80/445\n",
      "81/445\n",
      "82/445\n",
      "83/445\n",
      "84/445\n",
      "85/445\n",
      "86/445\n",
      "87/445\n",
      "88/445\n",
      "89/445\n",
      "90/445\n",
      "91/445\n",
      "92/445\n",
      "93/445\n",
      "94/445\n",
      "95/445\n",
      "96/445\n",
      "97/445\n",
      "98/445\n",
      "99/445\n",
      "100/445\n",
      "101/445\n",
      "102/445\n",
      "103/445\n",
      "104/445\n",
      "105/445\n",
      "106/445\n",
      "107/445\n",
      "108/445\n",
      "109/445\n",
      "110/445\n",
      "111/445\n",
      "112/445\n",
      "113/445\n",
      "114/445\n",
      "115/445\n",
      "116/445\n",
      "117/445\n",
      "118/445\n",
      "119/445\n",
      "120/445\n",
      "121/445\n",
      "122/445\n",
      "123/445\n",
      "124/445\n",
      "125/445\n",
      "126/445\n",
      "127/445\n",
      "128/445\n",
      "129/445\n",
      "130/445\n",
      "131/445\n",
      "132/445\n",
      "133/445\n",
      "134/445\n",
      "135/445\n",
      "136/445\n",
      "137/445\n",
      "138/445\n",
      "139/445\n",
      "140/445\n",
      "141/445\n",
      "142/445\n",
      "143/445\n",
      "144/445\n",
      "145/445\n",
      "146/445\n",
      "147/445\n",
      "148/445\n",
      "149/445\n",
      "150/445\n",
      "151/445\n",
      "152/445\n",
      "153/445\n",
      "154/445\n",
      "155/445\n",
      "156/445\n",
      "157/445\n",
      "158/445\n",
      "159/445\n",
      "160/445\n",
      "161/445\n",
      "162/445\n",
      "163/445\n",
      "164/445\n",
      "165/445\n",
      "166/445\n",
      "167/445\n",
      "168/445\n",
      "169/445\n",
      "170/445\n",
      "171/445\n",
      "172/445\n",
      "173/445\n",
      "174/445\n",
      "175/445\n",
      "176/445\n",
      "177/445\n",
      "178/445\n",
      "179/445\n",
      "180/445\n",
      "181/445\n",
      "182/445\n",
      "183/445\n",
      "184/445\n",
      "185/445\n",
      "186/445\n",
      "187/445\n",
      "188/445\n",
      "189/445\n",
      "190/445\n",
      "191/445\n",
      "192/445\n",
      "193/445\n",
      "194/445\n",
      "195/445\n",
      "196/445\n",
      "197/445\n",
      "198/445\n",
      "199/445\n",
      "200/445\n",
      "201/445\n",
      "202/445\n",
      "203/445\n",
      "204/445\n",
      "205/445\n",
      "206/445\n",
      "207/445\n",
      "208/445\n",
      "209/445\n",
      "210/445\n",
      "211/445\n",
      "212/445\n",
      "213/445\n",
      "214/445\n",
      "215/445\n",
      "216/445\n",
      "217/445\n",
      "218/445\n",
      "219/445\n",
      "220/445\n",
      "221/445\n",
      "222/445\n",
      "223/445\n",
      "224/445\n",
      "225/445\n",
      "226/445\n",
      "227/445\n",
      "228/445\n",
      "229/445\n",
      "230/445\n",
      "231/445\n",
      "232/445\n",
      "233/445\n",
      "234/445\n",
      "235/445\n",
      "236/445\n",
      "237/445\n",
      "238/445\n",
      "239/445\n",
      "240/445\n",
      "241/445\n",
      "242/445\n",
      "243/445\n",
      "244/445\n",
      "245/445\n",
      "246/445\n",
      "247/445\n",
      "248/445\n",
      "249/445\n",
      "250/445\n",
      "251/445\n",
      "252/445\n",
      "253/445\n",
      "254/445\n",
      "255/445\n",
      "256/445\n",
      "257/445\n",
      "258/445\n",
      "259/445\n",
      "260/445\n",
      "261/445\n",
      "262/445\n",
      "263/445\n",
      "264/445\n",
      "265/445\n",
      "266/445\n",
      "267/445\n",
      "268/445\n",
      "269/445\n",
      "270/445\n",
      "271/445\n",
      "272/445\n",
      "273/445\n",
      "274/445\n",
      "275/445\n",
      "276/445\n",
      "277/445\n",
      "278/445\n",
      "279/445\n",
      "280/445\n",
      "281/445\n",
      "282/445\n",
      "283/445\n",
      "284/445\n",
      "285/445\n",
      "286/445\n",
      "287/445\n",
      "288/445\n",
      "289/445\n",
      "290/445\n",
      "291/445\n",
      "292/445\n",
      "293/445\n",
      "294/445\n",
      "295/445\n",
      "296/445\n",
      "297/445\n",
      "298/445\n",
      "299/445\n",
      "300/445\n",
      "301/445\n",
      "302/445\n",
      "303/445\n",
      "304/445\n",
      "305/445\n",
      "306/445\n",
      "307/445\n",
      "308/445\n",
      "309/445\n",
      "310/445\n",
      "311/445\n",
      "312/445\n",
      "313/445\n",
      "314/445\n",
      "315/445\n",
      "316/445\n",
      "317/445\n",
      "318/445\n",
      "319/445\n",
      "320/445\n",
      "321/445\n",
      "322/445\n",
      "323/445\n",
      "324/445\n",
      "325/445\n",
      "326/445\n",
      "327/445\n",
      "328/445\n",
      "329/445\n",
      "330/445\n",
      "331/445\n",
      "332/445\n",
      "333/445\n",
      "334/445\n",
      "335/445\n",
      "336/445\n",
      "337/445\n",
      "338/445\n",
      "339/445\n",
      "340/445\n",
      "341/445\n",
      "342/445\n",
      "343/445\n",
      "344/445\n",
      "345/445\n",
      "346/445\n",
      "347/445\n",
      "348/445\n",
      "349/445\n",
      "350/445\n",
      "351/445\n",
      "352/445\n",
      "353/445\n",
      "354/445\n",
      "355/445\n",
      "356/445\n",
      "357/445\n",
      "358/445\n",
      "359/445\n",
      "360/445\n",
      "361/445\n",
      "362/445\n",
      "363/445\n",
      "364/445\n",
      "365/445\n",
      "366/445\n",
      "367/445\n",
      "368/445\n",
      "369/445\n",
      "370/445\n",
      "371/445\n",
      "372/445\n",
      "373/445\n",
      "374/445\n",
      "375/445\n",
      "376/445\n",
      "377/445\n",
      "378/445\n",
      "379/445\n",
      "380/445\n",
      "381/445\n",
      "382/445\n",
      "383/445\n",
      "384/445\n",
      "385/445\n",
      "386/445\n",
      "387/445\n",
      "388/445\n",
      "389/445\n",
      "390/445\n",
      "391/445\n",
      "392/445\n",
      "393/445\n",
      "394/445\n",
      "395/445\n",
      "396/445\n",
      "397/445\n",
      "398/445\n",
      "399/445\n",
      "400/445\n",
      "401/445\n",
      "402/445\n",
      "403/445\n",
      "404/445\n",
      "405/445\n",
      "406/445\n",
      "407/445\n",
      "408/445\n",
      "409/445\n",
      "410/445\n",
      "411/445\n",
      "412/445\n",
      "413/445\n",
      "414/445\n",
      "415/445\n",
      "416/445\n",
      "417/445\n",
      "418/445\n",
      "419/445\n",
      "420/445\n",
      "421/445\n",
      "422/445\n",
      "423/445\n",
      "424/445\n",
      "425/445\n",
      "426/445\n",
      "427/445\n",
      "428/445\n",
      "429/445\n",
      "430/445\n",
      "431/445\n",
      "432/445\n",
      "433/445\n",
      "434/445\n",
      "435/445\n",
      "436/445\n",
      "437/445\n",
      "438/445\n",
      "439/445\n",
      "440/445\n",
      "441/445\n",
      "442/445\n",
      "443/445\n",
      "444/445\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.513\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Jerome\\anaconda3\\CPE313_MONTOJO\\pytorch-retinanet\n",
    "# Increased epochs to 50 for better training and also changed depth to 101 to make it more accurate.\n",
    "# Adam and ReduceLROnPlateau optimizer was used for better training.\n",
    "!python train.py --dataset coco --coco_path \"C:/Users/Jerome/anaconda3/CPE313_MONTOJO/COCO_DATASET_FIRE_2\" --depth 101 --epochs 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b40dc",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1e1c7ed6",
   "metadata": {},
   "source": [
    "Result of Adam\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Result of AdamW:\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Result of SGD:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0150b2",
   "metadata": {},
   "source": [
    "## RT-DETR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dade70",
   "metadata": {},
   "source": [
    "Since the model training and development were conducted in Google Colab, I am able to provide the link to the Colab notebook along with the image dataset, enabling replication of the entire modeling process within a single Jupyter notebook.\n",
    "\n",
    "Link to the colab notebook: https://colab.research.google.com/drive/1Bj2DJ6ZFIpuvtVImaQODrXMgEp8jXmIc?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43715282",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9bc46aee",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c90e9793",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d9f01",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "dd70f7ca",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "bbb6a8a9",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfd062",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9e7e8b6f",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "05caa9f9",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7f705fa7",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
